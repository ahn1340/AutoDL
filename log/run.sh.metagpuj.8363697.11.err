/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
WARNING:tensorflow:From /home/ahnj/repo/autodl/AutoDL/model.py:27: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /home/ahnj/repo/autodl/AutoDL/model.py:31: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-03-09 22:42:22.250622: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-03-09 22:42:22.254746: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299960000 Hz
2020-03-09 22:42:22.254973: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558664a40830 executing computations on platform Host. Devices:
2020-03-09 22:42:22.254986: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-03-09 22:42:22.255855: I tensorflow/core/common_runtime/direct_session.cc:296] Device mapping:
/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device

22:42:22 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7fb91e092668; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:30837>
22:42:22 WORKER: No dispatcher found. Waiting for one to initiate contact.
22:42:22 WORKER: start listening for jobs
22:42:22 wait_for_workers trying to get the condition
22:42:22 DISPATCHER: started the 'discover_worker' thread
22:42:22 DISPATCHER: started the 'job_runner' thread
22:42:22 DISPATCHER: Pyro daemon running on localhost:46103
22:42:22 HBMASTER: only 0 worker(s) available, waiting for at least 1.
22:42:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:42:22 DISPATCHER: Starting worker discovery
22:42:22 DISPATCHER: Found 1 potential workers, 0 currently in the pool.
22:42:22 DISPATCHER: discovered new worker, hpbandster.run_0.worker.metagpuj.13102140436472194880
22:42:22 HBMASTER: number of workers changed to 1
22:42:22 adjust_queue_size: lock accquired
22:42:22 HBMASTER: adjusted queue size to (0, 1)
22:42:22 DISPATCHER: Finished worker discovery
22:42:22 DISPATCHER: A new worker triggered discover_worker
22:42:22 DISPATCHER: Trying to submit another job.
22:42:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:42:22 Enough workers to start this run!
22:42:22 DISPATCHER: Starting worker discovery
22:42:22 HBMASTER: starting run at 1583790142.3465705
22:42:22 start sampling a new configuration.
22:42:22 done sampling a new configuration.
22:42:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:42:22 HBMASTER: schedule new run for iteration 0
22:42:22 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
22:42:22 HBMASTER: submitting job (0, 0, 0) to dispatcher
22:42:22 DISPATCHER: trying to submit job (0, 0, 0)
22:42:22 DISPATCHER: Finished worker discovery
22:42:22 DISPATCHER: trying to notify the job_runner thread.
22:42:22 HBMASTER: job (0, 0, 0) submitted to dispatcher
22:42:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:42:22 DISPATCHER: Trying to submit another job.
22:42:22 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:42:22 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:42:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:42:22 WORKER: start processing job (0, 0, 0)
22:42:22 WORKER: args: ()
22:42:22 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 709, 'last_n_outputs': 49, 'leak_rate': 0.7996827608527187, 'lr': 0.04072838871907892, 'optimizer': 'Adam', 'sparsity': 0.9747570150233876, 'steps_to_train': 63, 'weight_decay': 0.010445278544243448}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:43:22 DISPATCHER: Starting worker discovery
22:43:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:43:22 DISPATCHER: Finished worker discovery
22:43:33 WORKER: done with job (0, 0, 0), trying to register it.
22:43:33 WORKER: registered result for job (0, 0, 0) with dispatcher
22:43:33 DISPATCHER: job (0, 0, 0) finished
22:43:33 DISPATCHER: register_result: lock acquired
22:43:33 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:43:33 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 709, 'last_n_outputs': 49, 'leak_rate': 0.7996827608527187, 'lr': 0.04072838871907892, 'optimizer': 'Adam', 'sparsity': 0.9747570150233876, 'steps_to_train': 63, 'weight_decay': 0.010445278544243448}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.028196410493894458, 'info': {'data04': 0.028196410493894458, 'config': "{'batch_size': 128, 'hidden_dim': 709, 'last_n_outputs': 49, 'leak_rate': 0.7996827608527187, 'lr': 0.04072838871907892, 'optimizer': 'Adam', 'sparsity': 0.9747570150233876, 'steps_to_train': 63, 'weight_decay': 0.010445278544243448}"}}
exception: None

22:43:33 job_callback for (0, 0, 0) started
22:43:33 job_callback for (0, 0, 0) got condition
22:43:33 DISPATCHER: Trying to submit another job.
22:43:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:43:33 Only 1 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
22:43:33 HBMASTER: Trying to run another job!
22:43:33 job_callback for (0, 0, 0) finished
22:43:33 start sampling a new configuration.
22:43:33 done sampling a new configuration.
22:43:33 HBMASTER: schedule new run for iteration 0
22:43:33 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
22:43:33 HBMASTER: submitting job (0, 0, 1) to dispatcher
22:43:33 DISPATCHER: trying to submit job (0, 0, 1)
22:43:33 DISPATCHER: trying to notify the job_runner thread.
22:43:33 HBMASTER: job (0, 0, 1) submitted to dispatcher
22:43:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:43:33 DISPATCHER: Trying to submit another job.
22:43:33 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:43:33 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:43:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:43:33 WORKER: start processing job (0, 0, 1)
22:43:33 WORKER: args: ()
22:43:33 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 447, 'last_n_outputs': 43, 'leak_rate': 0.856564792492804, 'lr': 0.008532727963501368, 'optimizer': 'SGD', 'sparsity': 0.8799206321865392, 'steps_to_train': 74, 'weight_decay': 0.14973843329667766}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:44:22 DISPATCHER: Starting worker discovery
22:44:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:44:22 DISPATCHER: Finished worker discovery
22:44:35 WORKER: done with job (0, 0, 1), trying to register it.
22:44:35 WORKER: registered result for job (0, 0, 1) with dispatcher
22:44:35 DISPATCHER: job (0, 0, 1) finished
22:44:35 DISPATCHER: register_result: lock acquired
22:44:35 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:44:35 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 447, 'last_n_outputs': 43, 'leak_rate': 0.856564792492804, 'lr': 0.008532727963501368, 'optimizer': 'SGD', 'sparsity': 0.8799206321865392, 'steps_to_train': 74, 'weight_decay': 0.14973843329667766}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.15058088078907667, 'info': {'data04': 0.15058088078907667, 'config': "{'batch_size': 64, 'hidden_dim': 447, 'last_n_outputs': 43, 'leak_rate': 0.856564792492804, 'lr': 0.008532727963501368, 'optimizer': 'SGD', 'sparsity': 0.8799206321865392, 'steps_to_train': 74, 'weight_decay': 0.14973843329667766}"}}
exception: None

22:44:35 job_callback for (0, 0, 1) started
22:44:35 DISPATCHER: Trying to submit another job.
22:44:35 job_callback for (0, 0, 1) got condition
22:44:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:44:35 Only 2 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
22:44:35 HBMASTER: Trying to run another job!
22:44:35 job_callback for (0, 0, 1) finished
22:44:35 start sampling a new configuration.
22:44:35 done sampling a new configuration.
22:44:35 HBMASTER: schedule new run for iteration 0
22:44:35 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
22:44:35 HBMASTER: submitting job (0, 0, 2) to dispatcher
22:44:35 DISPATCHER: trying to submit job (0, 0, 2)
22:44:35 DISPATCHER: trying to notify the job_runner thread.
22:44:35 HBMASTER: job (0, 0, 2) submitted to dispatcher
22:44:35 DISPATCHER: Trying to submit another job.
22:44:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:44:35 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:44:35 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:44:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:44:35 WORKER: start processing job (0, 0, 2)
22:44:35 WORKER: args: ()
22:44:35 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 279, 'last_n_outputs': 34, 'leak_rate': 0.9746297304770752, 'lr': 0.00551869127705352, 'optimizer': 'Adam', 'sparsity': 0.8650308276317955, 'steps_to_train': 33, 'weight_decay': 0.048208022981328376}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:45:22 DISPATCHER: Starting worker discovery
22:45:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:45:22 DISPATCHER: Finished worker discovery
22:45:38 WORKER: done with job (0, 0, 2), trying to register it.
22:45:38 WORKER: registered result for job (0, 0, 2) with dispatcher
22:45:38 DISPATCHER: job (0, 0, 2) finished
22:45:38 DISPATCHER: register_result: lock acquired
22:45:38 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:45:38 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 279, 'last_n_outputs': 34, 'leak_rate': 0.9746297304770752, 'lr': 0.00551869127705352, 'optimizer': 'Adam', 'sparsity': 0.8650308276317955, 'steps_to_train': 33, 'weight_decay': 0.048208022981328376}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.08202497787503826, 'info': {'data04': 0.08202497787503826, 'config': "{'batch_size': 128, 'hidden_dim': 279, 'last_n_outputs': 34, 'leak_rate': 0.9746297304770752, 'lr': 0.00551869127705352, 'optimizer': 'Adam', 'sparsity': 0.8650308276317955, 'steps_to_train': 33, 'weight_decay': 0.048208022981328376}"}}
exception: None

22:45:38 job_callback for (0, 0, 2) started
22:45:38 DISPATCHER: Trying to submit another job.
22:45:38 job_callback for (0, 0, 2) got condition
22:45:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:45:38 Only 3 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
22:45:38 HBMASTER: Trying to run another job!
22:45:38 job_callback for (0, 0, 2) finished
22:45:38 start sampling a new configuration.
22:45:38 done sampling a new configuration.
22:45:38 HBMASTER: schedule new run for iteration 0
22:45:38 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
22:45:38 HBMASTER: submitting job (0, 0, 3) to dispatcher
22:45:38 DISPATCHER: trying to submit job (0, 0, 3)
22:45:38 DISPATCHER: trying to notify the job_runner thread.
22:45:38 HBMASTER: job (0, 0, 3) submitted to dispatcher
22:45:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:45:38 DISPATCHER: Trying to submit another job.
22:45:38 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:45:38 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:45:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:45:38 WORKER: start processing job (0, 0, 3)
22:45:38 WORKER: args: ()
22:45:38 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 754, 'last_n_outputs': 50, 'leak_rate': 0.9739044432088472, 'lr': 0.07806963984323186, 'optimizer': 'Adam', 'sparsity': 0.9833136118868191, 'steps_to_train': 50, 'weight_decay': 0.12953569339784976}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:46:22 DISPATCHER: Starting worker discovery
22:46:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:46:22 DISPATCHER: Finished worker discovery
22:46:39 WORKER: done with job (0, 0, 3), trying to register it.
22:46:39 WORKER: registered result for job (0, 0, 3) with dispatcher
22:46:39 DISPATCHER: job (0, 0, 3) finished
22:46:39 DISPATCHER: register_result: lock acquired
22:46:39 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:46:39 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 754, 'last_n_outputs': 50, 'leak_rate': 0.9739044432088472, 'lr': 0.07806963984323186, 'optimizer': 'Adam', 'sparsity': 0.9833136118868191, 'steps_to_train': 50, 'weight_decay': 0.12953569339784976}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.008029073683163749, 'info': {'data04': 0.008029073683163749, 'config': "{'batch_size': 128, 'hidden_dim': 754, 'last_n_outputs': 50, 'leak_rate': 0.9739044432088472, 'lr': 0.07806963984323186, 'optimizer': 'Adam', 'sparsity': 0.9833136118868191, 'steps_to_train': 50, 'weight_decay': 0.12953569339784976}"}}
exception: None

22:46:39 job_callback for (0, 0, 3) started
22:46:39 DISPATCHER: Trying to submit another job.
22:46:39 job_callback for (0, 0, 3) got condition
22:46:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:46:39 Only 4 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
22:46:39 HBMASTER: Trying to run another job!
22:46:39 job_callback for (0, 0, 3) finished
22:46:39 start sampling a new configuration.
22:46:39 done sampling a new configuration.
22:46:39 HBMASTER: schedule new run for iteration 0
22:46:39 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
22:46:39 HBMASTER: submitting job (0, 0, 4) to dispatcher
22:46:39 DISPATCHER: trying to submit job (0, 0, 4)
22:46:39 DISPATCHER: trying to notify the job_runner thread.
22:46:39 HBMASTER: job (0, 0, 4) submitted to dispatcher
22:46:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:46:39 DISPATCHER: Trying to submit another job.
22:46:39 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:46:39 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:46:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:46:39 WORKER: start processing job (0, 0, 4)
22:46:39 WORKER: args: ()
22:46:39 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 590, 'last_n_outputs': 17, 'leak_rate': 0.8747876355003881, 'lr': 0.0018501788180135311, 'optimizer': 'Adam', 'sparsity': 0.9027721715755098, 'steps_to_train': 59, 'weight_decay': 0.047696057743273096}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:47:22 DISPATCHER: Starting worker discovery
22:47:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:47:22 DISPATCHER: Finished worker discovery
22:47:39 WORKER: done with job (0, 0, 4), trying to register it.
22:47:39 WORKER: registered result for job (0, 0, 4) with dispatcher
22:47:39 DISPATCHER: job (0, 0, 4) finished
22:47:39 DISPATCHER: register_result: lock acquired
22:47:39 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:47:39 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 590, 'last_n_outputs': 17, 'leak_rate': 0.8747876355003881, 'lr': 0.0018501788180135311, 'optimizer': 'Adam', 'sparsity': 0.9027721715755098, 'steps_to_train': 59, 'weight_decay': 0.047696057743273096}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.044239366800281066, 'info': {'data04': 0.044239366800281066, 'config': "{'batch_size': 16, 'hidden_dim': 590, 'last_n_outputs': 17, 'leak_rate': 0.8747876355003881, 'lr': 0.0018501788180135311, 'optimizer': 'Adam', 'sparsity': 0.9027721715755098, 'steps_to_train': 59, 'weight_decay': 0.047696057743273096}"}}
exception: None

22:47:39 job_callback for (0, 0, 4) started
22:47:39 DISPATCHER: Trying to submit another job.
22:47:39 job_callback for (0, 0, 4) got condition
22:47:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:47:39 Only 5 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
22:47:39 HBMASTER: Trying to run another job!
22:47:39 job_callback for (0, 0, 4) finished
22:47:39 start sampling a new configuration.
22:47:39 done sampling a new configuration.
22:47:39 HBMASTER: schedule new run for iteration 0
22:47:39 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
22:47:39 HBMASTER: submitting job (0, 0, 5) to dispatcher
22:47:39 DISPATCHER: trying to submit job (0, 0, 5)
22:47:39 DISPATCHER: trying to notify the job_runner thread.
22:47:39 HBMASTER: job (0, 0, 5) submitted to dispatcher
22:47:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:47:39 DISPATCHER: Trying to submit another job.
22:47:39 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:47:39 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:47:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:47:39 WORKER: start processing job (0, 0, 5)
22:47:39 WORKER: args: ()
22:47:39 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 353, 'last_n_outputs': 39, 'leak_rate': 0.9785248474848329, 'lr': 0.02706830492329233, 'optimizer': 'SGD', 'sparsity': 0.9149404780468433, 'steps_to_train': 99, 'weight_decay': 0.09076270112052477}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:48:22 DISPATCHER: Starting worker discovery
22:48:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:48:22 DISPATCHER: Finished worker discovery
22:48:41 WORKER: done with job (0, 0, 5), trying to register it.
22:48:41 WORKER: registered result for job (0, 0, 5) with dispatcher
22:48:41 DISPATCHER: job (0, 0, 5) finished
22:48:41 DISPATCHER: register_result: lock acquired
22:48:41 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:48:41 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 353, 'last_n_outputs': 39, 'leak_rate': 0.9785248474848329, 'lr': 0.02706830492329233, 'optimizer': 'SGD', 'sparsity': 0.9149404780468433, 'steps_to_train': 99, 'weight_decay': 0.09076270112052477}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.15197786822101653, 'info': {'data04': 0.15197786822101653, 'config': "{'batch_size': 32, 'hidden_dim': 353, 'last_n_outputs': 39, 'leak_rate': 0.9785248474848329, 'lr': 0.02706830492329233, 'optimizer': 'SGD', 'sparsity': 0.9149404780468433, 'steps_to_train': 99, 'weight_decay': 0.09076270112052477}"}}
exception: None

22:48:41 job_callback for (0, 0, 5) started
22:48:41 job_callback for (0, 0, 5) got condition
22:48:41 DISPATCHER: Trying to submit another job.
22:48:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:48:41 Only 6 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
22:48:41 HBMASTER: Trying to run another job!
22:48:41 job_callback for (0, 0, 5) finished
22:48:41 start sampling a new configuration.
22:48:41 done sampling a new configuration.
22:48:41 HBMASTER: schedule new run for iteration 0
22:48:41 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
22:48:41 HBMASTER: submitting job (0, 0, 6) to dispatcher
22:48:41 DISPATCHER: trying to submit job (0, 0, 6)
22:48:41 DISPATCHER: trying to notify the job_runner thread.
22:48:41 HBMASTER: job (0, 0, 6) submitted to dispatcher
22:48:41 DISPATCHER: Trying to submit another job.
22:48:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:48:41 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:48:41 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:48:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:48:41 WORKER: start processing job (0, 0, 6)
22:48:41 WORKER: args: ()
22:48:41 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 729, 'last_n_outputs': 28, 'leak_rate': 0.891052347613573, 'lr': 0.0012949665014055046, 'optimizer': 'Adam', 'sparsity': 0.8017277866834676, 'steps_to_train': 58, 'weight_decay': 0.07128365315622283}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:49:22 DISPATCHER: Starting worker discovery
22:49:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:49:22 DISPATCHER: Finished worker discovery
22:49:41 WORKER: done with job (0, 0, 6), trying to register it.
22:49:41 WORKER: registered result for job (0, 0, 6) with dispatcher
22:49:41 DISPATCHER: job (0, 0, 6) finished
22:49:41 DISPATCHER: register_result: lock acquired
22:49:41 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:49:41 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 729, 'last_n_outputs': 28, 'leak_rate': 0.891052347613573, 'lr': 0.0012949665014055046, 'optimizer': 'Adam', 'sparsity': 0.8017277866834676, 'steps_to_train': 58, 'weight_decay': 0.07128365315622283}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.037629005963744105, 'info': {'data04': 0.037629005963744105, 'config': "{'batch_size': 16, 'hidden_dim': 729, 'last_n_outputs': 28, 'leak_rate': 0.891052347613573, 'lr': 0.0012949665014055046, 'optimizer': 'Adam', 'sparsity': 0.8017277866834676, 'steps_to_train': 58, 'weight_decay': 0.07128365315622283}"}}
exception: None

22:49:41 job_callback for (0, 0, 6) started
22:49:41 DISPATCHER: Trying to submit another job.
22:49:41 job_callback for (0, 0, 6) got condition
22:49:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:49:41 Only 7 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
22:49:41 HBMASTER: Trying to run another job!
22:49:41 job_callback for (0, 0, 6) finished
22:49:41 start sampling a new configuration.
22:49:41 done sampling a new configuration.
22:49:41 HBMASTER: schedule new run for iteration 0
22:49:41 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
22:49:41 HBMASTER: submitting job (0, 0, 7) to dispatcher
22:49:41 DISPATCHER: trying to submit job (0, 0, 7)
22:49:41 DISPATCHER: trying to notify the job_runner thread.
22:49:41 HBMASTER: job (0, 0, 7) submitted to dispatcher
22:49:41 DISPATCHER: Trying to submit another job.
22:49:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:49:41 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:49:41 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:49:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:49:41 WORKER: start processing job (0, 0, 7)
22:49:41 WORKER: args: ()
22:49:41 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 867, 'last_n_outputs': 35, 'leak_rate': 0.9013515152456588, 'lr': 0.010939551424379268, 'optimizer': 'SGD', 'sparsity': 0.8128063031560117, 'steps_to_train': 67, 'weight_decay': 0.010868052347680388}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:50:22 DISPATCHER: Starting worker discovery
22:50:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:50:22 DISPATCHER: Finished worker discovery
22:50:43 WORKER: done with job (0, 0, 7), trying to register it.
22:50:43 WORKER: registered result for job (0, 0, 7) with dispatcher
22:50:43 DISPATCHER: job (0, 0, 7) finished
22:50:43 DISPATCHER: register_result: lock acquired
22:50:43 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:50:43 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 867, 'last_n_outputs': 35, 'leak_rate': 0.9013515152456588, 'lr': 0.010939551424379268, 'optimizer': 'SGD', 'sparsity': 0.8128063031560117, 'steps_to_train': 67, 'weight_decay': 0.010868052347680388}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.18815709944799297, 'info': {'data04': 0.18815709944799297, 'config': "{'batch_size': 16, 'hidden_dim': 867, 'last_n_outputs': 35, 'leak_rate': 0.9013515152456588, 'lr': 0.010939551424379268, 'optimizer': 'SGD', 'sparsity': 0.8128063031560117, 'steps_to_train': 67, 'weight_decay': 0.010868052347680388}"}}
exception: None

22:50:43 job_callback for (0, 0, 7) started
22:50:43 DISPATCHER: Trying to submit another job.
22:50:43 job_callback for (0, 0, 7) got condition
22:50:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:50:43 Only 8 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
22:50:43 HBMASTER: Trying to run another job!
22:50:43 job_callback for (0, 0, 7) finished
22:50:43 start sampling a new configuration.
22:50:43 done sampling a new configuration.
22:50:43 HBMASTER: schedule new run for iteration 0
22:50:43 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
22:50:43 HBMASTER: submitting job (0, 0, 8) to dispatcher
22:50:43 DISPATCHER: trying to submit job (0, 0, 8)
22:50:43 DISPATCHER: trying to notify the job_runner thread.
22:50:43 HBMASTER: job (0, 0, 8) submitted to dispatcher
22:50:43 DISPATCHER: Trying to submit another job.
22:50:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:50:43 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:50:43 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:50:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:50:43 WORKER: start processing job (0, 0, 8)
22:50:43 WORKER: args: ()
22:50:43 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 743, 'last_n_outputs': 44, 'leak_rate': 0.8613778025805232, 'lr': 0.054594214182800034, 'optimizer': 'Adam', 'sparsity': 0.8023740886702551, 'steps_to_train': 88, 'weight_decay': 0.042223497620880235}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:51:22 DISPATCHER: Starting worker discovery
22:51:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:51:22 DISPATCHER: Finished worker discovery
22:51:44 WORKER: done with job (0, 0, 8), trying to register it.
22:51:44 WORKER: registered result for job (0, 0, 8) with dispatcher
22:51:44 DISPATCHER: job (0, 0, 8) finished
22:51:44 DISPATCHER: register_result: lock acquired
22:51:44 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:51:44 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 743, 'last_n_outputs': 44, 'leak_rate': 0.8613778025805232, 'lr': 0.054594214182800034, 'optimizer': 'Adam', 'sparsity': 0.8023740886702551, 'steps_to_train': 88, 'weight_decay': 0.042223497620880235}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.002570677322030583, 'info': {'data04': 0.002570677322030583, 'config': "{'batch_size': 64, 'hidden_dim': 743, 'last_n_outputs': 44, 'leak_rate': 0.8613778025805232, 'lr': 0.054594214182800034, 'optimizer': 'Adam', 'sparsity': 0.8023740886702551, 'steps_to_train': 88, 'weight_decay': 0.042223497620880235}"}}
exception: None

22:51:44 job_callback for (0, 0, 8) started
22:51:44 DISPATCHER: Trying to submit another job.
22:51:44 job_callback for (0, 0, 8) got condition
22:51:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:51:44 Only 9 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
22:51:44 HBMASTER: Trying to run another job!
22:51:44 job_callback for (0, 0, 8) finished
22:51:44 start sampling a new configuration.
22:51:44 done sampling a new configuration.
22:51:44 HBMASTER: schedule new run for iteration 0
22:51:44 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
22:51:44 HBMASTER: submitting job (0, 0, 9) to dispatcher
22:51:44 DISPATCHER: trying to submit job (0, 0, 9)
22:51:44 DISPATCHER: trying to notify the job_runner thread.
22:51:44 HBMASTER: job (0, 0, 9) submitted to dispatcher
22:51:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:51:44 DISPATCHER: Trying to submit another job.
22:51:44 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:51:44 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:51:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:51:44 WORKER: start processing job (0, 0, 9)
22:51:44 WORKER: args: ()
22:51:44 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 579, 'last_n_outputs': 11, 'leak_rate': 0.854196695782137, 'lr': 0.030021968080540837, 'optimizer': 'SGD', 'sparsity': 0.9834910391806241, 'steps_to_train': 73, 'weight_decay': 0.05180305704832722}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:52:22 DISPATCHER: Starting worker discovery
22:52:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:52:22 DISPATCHER: Finished worker discovery
22:52:46 WORKER: done with job (0, 0, 9), trying to register it.
22:52:46 WORKER: registered result for job (0, 0, 9) with dispatcher
22:52:46 DISPATCHER: job (0, 0, 9) finished
22:52:46 DISPATCHER: register_result: lock acquired
22:52:46 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:52:46 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 579, 'last_n_outputs': 11, 'leak_rate': 0.854196695782137, 'lr': 0.030021968080540837, 'optimizer': 'SGD', 'sparsity': 0.9834910391806241, 'steps_to_train': 73, 'weight_decay': 0.05180305704832722}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.14623881666071956, 'info': {'data04': 0.14623881666071956, 'config': "{'batch_size': 128, 'hidden_dim': 579, 'last_n_outputs': 11, 'leak_rate': 0.854196695782137, 'lr': 0.030021968080540837, 'optimizer': 'SGD', 'sparsity': 0.9834910391806241, 'steps_to_train': 73, 'weight_decay': 0.05180305704832722}"}}
exception: None

22:52:46 job_callback for (0, 0, 9) started
22:52:46 job_callback for (0, 0, 9) got condition
22:52:46 DISPATCHER: Trying to submit another job.
22:52:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:52:46 HBMASTER: Trying to run another job!
22:52:46 job_callback for (0, 0, 9) finished
22:52:46 start sampling a new configuration.
22:52:46 done sampling a new configuration.
22:52:46 HBMASTER: schedule new run for iteration 0
22:52:46 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
22:52:46 HBMASTER: submitting job (0, 0, 10) to dispatcher
22:52:46 DISPATCHER: trying to submit job (0, 0, 10)
22:52:46 DISPATCHER: trying to notify the job_runner thread.
22:52:46 HBMASTER: job (0, 0, 10) submitted to dispatcher
22:52:46 DISPATCHER: Trying to submit another job.
22:52:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:52:46 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:52:46 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:52:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:52:46 WORKER: start processing job (0, 0, 10)
22:52:46 WORKER: args: ()
22:52:46 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 935, 'last_n_outputs': 33, 'leak_rate': 0.9007701393318854, 'lr': 0.009259064102598231, 'optimizer': 'SGD', 'sparsity': 0.8643563073184608, 'steps_to_train': 75, 'weight_decay': 0.05316009720010779}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:53:22 DISPATCHER: Starting worker discovery
22:53:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:53:22 DISPATCHER: Finished worker discovery
22:53:48 WORKER: done with job (0, 0, 10), trying to register it.
22:53:48 WORKER: registered result for job (0, 0, 10) with dispatcher
22:53:48 DISPATCHER: job (0, 0, 10) finished
22:53:48 DISPATCHER: register_result: lock acquired
22:53:48 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:53:48 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 935, 'last_n_outputs': 33, 'leak_rate': 0.9007701393318854, 'lr': 0.009259064102598231, 'optimizer': 'SGD', 'sparsity': 0.8643563073184608, 'steps_to_train': 75, 'weight_decay': 0.05316009720010779}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.18666884133071182, 'info': {'data04': 0.18666884133071182, 'config': "{'batch_size': 128, 'hidden_dim': 935, 'last_n_outputs': 33, 'leak_rate': 0.9007701393318854, 'lr': 0.009259064102598231, 'optimizer': 'SGD', 'sparsity': 0.8643563073184608, 'steps_to_train': 75, 'weight_decay': 0.05316009720010779}"}}
exception: None

22:53:48 job_callback for (0, 0, 10) started
22:53:48 DISPATCHER: Trying to submit another job.
22:53:48 job_callback for (0, 0, 10) got condition
22:53:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:53:48 HBMASTER: Trying to run another job!
22:53:48 job_callback for (0, 0, 10) finished
22:53:48 start sampling a new configuration.
22:53:48 done sampling a new configuration.
22:53:48 HBMASTER: schedule new run for iteration 0
22:53:48 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
22:53:48 HBMASTER: submitting job (0, 0, 11) to dispatcher
22:53:48 DISPATCHER: trying to submit job (0, 0, 11)
22:53:48 DISPATCHER: trying to notify the job_runner thread.
22:53:48 HBMASTER: job (0, 0, 11) submitted to dispatcher
22:53:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:53:48 DISPATCHER: Trying to submit another job.
22:53:48 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:53:48 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:53:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:53:48 WORKER: start processing job (0, 0, 11)
22:53:48 WORKER: args: ()
22:53:48 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 238, 'last_n_outputs': 27, 'leak_rate': 0.9180522462805846, 'lr': 0.06862324911479009, 'optimizer': 'Adam', 'sparsity': 0.7977827290233408, 'steps_to_train': 63, 'weight_decay': 0.010224089686538651}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:54:22 DISPATCHER: Starting worker discovery
22:54:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:54:22 DISPATCHER: Finished worker discovery
22:54:49 WORKER: done with job (0, 0, 11), trying to register it.
22:54:49 WORKER: registered result for job (0, 0, 11) with dispatcher
22:54:49 DISPATCHER: job (0, 0, 11) finished
22:54:49 DISPATCHER: register_result: lock acquired
22:54:49 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:54:49 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 238, 'last_n_outputs': 27, 'leak_rate': 0.9180522462805846, 'lr': 0.06862324911479009, 'optimizer': 'Adam', 'sparsity': 0.7977827290233408, 'steps_to_train': 63, 'weight_decay': 0.010224089686538651}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.050965125718159, 'info': {'data04': 0.050965125718159, 'config': "{'batch_size': 128, 'hidden_dim': 238, 'last_n_outputs': 27, 'leak_rate': 0.9180522462805846, 'lr': 0.06862324911479009, 'optimizer': 'Adam', 'sparsity': 0.7977827290233408, 'steps_to_train': 63, 'weight_decay': 0.010224089686538651}"}}
exception: None

22:54:49 job_callback for (0, 0, 11) started
22:54:49 job_callback for (0, 0, 11) got condition
22:54:49 DISPATCHER: Trying to submit another job.
22:54:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:54:49 HBMASTER: Trying to run another job!
22:54:49 job_callback for (0, 0, 11) finished
22:54:49 start sampling a new configuration.
22:54:49 done sampling a new configuration.
22:54:49 HBMASTER: schedule new run for iteration 0
22:54:49 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
22:54:49 HBMASTER: submitting job (0, 0, 12) to dispatcher
22:54:49 DISPATCHER: trying to submit job (0, 0, 12)
22:54:49 DISPATCHER: trying to notify the job_runner thread.
22:54:49 HBMASTER: job (0, 0, 12) submitted to dispatcher
22:54:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:54:49 DISPATCHER: Trying to submit another job.
22:54:49 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:54:49 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:54:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:54:49 WORKER: start processing job (0, 0, 12)
22:54:49 WORKER: args: ()
22:54:49 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 479, 'last_n_outputs': 41, 'leak_rate': 0.8727858116237966, 'lr': 0.0017722140386417732, 'optimizer': 'Adam', 'sparsity': 0.7838109018745064, 'steps_to_train': 85, 'weight_decay': 0.05028240735369322}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:55:22 DISPATCHER: Starting worker discovery
22:55:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:55:22 DISPATCHER: Finished worker discovery
22:55:50 WORKER: done with job (0, 0, 12), trying to register it.
22:55:50 WORKER: registered result for job (0, 0, 12) with dispatcher
22:55:50 DISPATCHER: job (0, 0, 12) finished
22:55:50 DISPATCHER: register_result: lock acquired
22:55:50 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:55:50 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 479, 'last_n_outputs': 41, 'leak_rate': 0.8727858116237966, 'lr': 0.0017722140386417732, 'optimizer': 'Adam', 'sparsity': 0.7838109018745064, 'steps_to_train': 85, 'weight_decay': 0.05028240735369322}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.07491408590577124, 'info': {'data04': 0.07491408590577124, 'config': "{'batch_size': 128, 'hidden_dim': 479, 'last_n_outputs': 41, 'leak_rate': 0.8727858116237966, 'lr': 0.0017722140386417732, 'optimizer': 'Adam', 'sparsity': 0.7838109018745064, 'steps_to_train': 85, 'weight_decay': 0.05028240735369322}"}}
exception: None

22:55:50 job_callback for (0, 0, 12) started
22:55:50 DISPATCHER: Trying to submit another job.
22:55:50 job_callback for (0, 0, 12) got condition
22:55:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:55:50 HBMASTER: Trying to run another job!
22:55:50 job_callback for (0, 0, 12) finished
22:55:50 start sampling a new configuration.
22:55:50 done sampling a new configuration.
22:55:50 HBMASTER: schedule new run for iteration 0
22:55:50 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
22:55:50 HBMASTER: submitting job (0, 0, 13) to dispatcher
22:55:50 DISPATCHER: trying to submit job (0, 0, 13)
22:55:50 DISPATCHER: trying to notify the job_runner thread.
22:55:50 HBMASTER: job (0, 0, 13) submitted to dispatcher
22:55:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:55:50 DISPATCHER: Trying to submit another job.
22:55:50 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:55:50 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:55:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:55:50 WORKER: start processing job (0, 0, 13)
22:55:50 WORKER: args: ()
22:55:50 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 239, 'last_n_outputs': 17, 'leak_rate': 0.8466575891248749, 'lr': 0.048806038955806916, 'optimizer': 'SGD', 'sparsity': 0.9094486151912601, 'steps_to_train': 64, 'weight_decay': 0.024928231490706988}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:56:22 DISPATCHER: Starting worker discovery
22:56:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:56:22 DISPATCHER: Finished worker discovery
22:56:50 WORKER: done with job (0, 0, 13), trying to register it.
22:56:50 WORKER: registered result for job (0, 0, 13) with dispatcher
22:56:50 DISPATCHER: job (0, 0, 13) finished
22:56:50 DISPATCHER: register_result: lock acquired
22:56:50 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:56:50 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 239, 'last_n_outputs': 17, 'leak_rate': 0.8466575891248749, 'lr': 0.048806038955806916, 'optimizer': 'SGD', 'sparsity': 0.9094486151912601, 'steps_to_train': 64, 'weight_decay': 0.024928231490706988}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.146007530472213, 'info': {'data04': 0.146007530472213, 'config': "{'batch_size': 64, 'hidden_dim': 239, 'last_n_outputs': 17, 'leak_rate': 0.8466575891248749, 'lr': 0.048806038955806916, 'optimizer': 'SGD', 'sparsity': 0.9094486151912601, 'steps_to_train': 64, 'weight_decay': 0.024928231490706988}"}}
exception: None

22:56:50 job_callback for (0, 0, 13) started
22:56:50 job_callback for (0, 0, 13) got condition
22:56:50 DISPATCHER: Trying to submit another job.
22:56:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:56:50 HBMASTER: Trying to run another job!
22:56:50 job_callback for (0, 0, 13) finished
22:56:50 start sampling a new configuration.
22:56:50 done sampling a new configuration.
22:56:50 HBMASTER: schedule new run for iteration 0
22:56:50 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
22:56:50 HBMASTER: submitting job (0, 0, 14) to dispatcher
22:56:50 DISPATCHER: trying to submit job (0, 0, 14)
22:56:50 DISPATCHER: trying to notify the job_runner thread.
22:56:50 HBMASTER: job (0, 0, 14) submitted to dispatcher
22:56:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:56:50 DISPATCHER: Trying to submit another job.
22:56:50 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:56:50 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:56:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:56:50 WORKER: start processing job (0, 0, 14)
22:56:50 WORKER: args: ()
22:56:50 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 773, 'last_n_outputs': 12, 'leak_rate': 0.8341312445379898, 'lr': 0.004922493132326231, 'optimizer': 'Adam', 'sparsity': 0.9297530698468065, 'steps_to_train': 25, 'weight_decay': 0.020693869999780366}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:57:22 DISPATCHER: Starting worker discovery
22:57:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:57:22 DISPATCHER: Finished worker discovery
22:57:52 WORKER: done with job (0, 0, 14), trying to register it.
22:57:52 WORKER: registered result for job (0, 0, 14) with dispatcher
22:57:52 DISPATCHER: job (0, 0, 14) finished
22:57:52 DISPATCHER: register_result: lock acquired
22:57:52 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:57:52 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 773, 'last_n_outputs': 12, 'leak_rate': 0.8341312445379898, 'lr': 0.004922493132326231, 'optimizer': 'Adam', 'sparsity': 0.9297530698468065, 'steps_to_train': 25, 'weight_decay': 0.020693869999780366}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.061206601405937394, 'info': {'data04': 0.061206601405937394, 'config': "{'batch_size': 16, 'hidden_dim': 773, 'last_n_outputs': 12, 'leak_rate': 0.8341312445379898, 'lr': 0.004922493132326231, 'optimizer': 'Adam', 'sparsity': 0.9297530698468065, 'steps_to_train': 25, 'weight_decay': 0.020693869999780366}"}}
exception: None

22:57:52 job_callback for (0, 0, 14) started
22:57:52 job_callback for (0, 0, 14) got condition
22:57:52 DISPATCHER: Trying to submit another job.
22:57:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:57:52 HBMASTER: Trying to run another job!
22:57:52 job_callback for (0, 0, 14) finished
22:57:52 start sampling a new configuration.
22:57:52 done sampling a new configuration.
22:57:52 HBMASTER: schedule new run for iteration 0
22:57:52 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
22:57:52 HBMASTER: submitting job (0, 0, 15) to dispatcher
22:57:52 DISPATCHER: trying to submit job (0, 0, 15)
22:57:52 DISPATCHER: trying to notify the job_runner thread.
22:57:52 HBMASTER: job (0, 0, 15) submitted to dispatcher
22:57:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:57:52 DISPATCHER: Trying to submit another job.
22:57:52 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:57:52 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:57:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:57:52 WORKER: start processing job (0, 0, 15)
22:57:52 WORKER: args: ()
22:57:52 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 886, 'last_n_outputs': 17, 'leak_rate': 0.8761034793687865, 'lr': 0.004364711581983538, 'optimizer': 'Adam', 'sparsity': 0.8593554889314553, 'steps_to_train': 93, 'weight_decay': 0.012688112747339504}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:58:22 DISPATCHER: Starting worker discovery
22:58:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:58:22 DISPATCHER: Finished worker discovery
22:58:52 WORKER: done with job (0, 0, 15), trying to register it.
22:58:52 WORKER: registered result for job (0, 0, 15) with dispatcher
22:58:52 DISPATCHER: job (0, 0, 15) finished
22:58:52 DISPATCHER: register_result: lock acquired
22:58:52 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:58:52 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 886, 'last_n_outputs': 17, 'leak_rate': 0.8761034793687865, 'lr': 0.004364711581983538, 'optimizer': 'Adam', 'sparsity': 0.8593554889314553, 'steps_to_train': 93, 'weight_decay': 0.012688112747339504}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.11544528229933343, 'info': {'data04': 0.11544528229933343, 'config': "{'batch_size': 128, 'hidden_dim': 886, 'last_n_outputs': 17, 'leak_rate': 0.8761034793687865, 'lr': 0.004364711581983538, 'optimizer': 'Adam', 'sparsity': 0.8593554889314553, 'steps_to_train': 93, 'weight_decay': 0.012688112747339504}"}}
exception: None

22:58:52 job_callback for (0, 0, 15) started
22:58:52 DISPATCHER: Trying to submit another job.
22:58:52 job_callback for (0, 0, 15) got condition
22:58:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:58:52 HBMASTER: Trying to run another job!
22:58:52 job_callback for (0, 0, 15) finished
22:58:52 start sampling a new configuration.
22:58:52 done sampling a new configuration.
22:58:52 HBMASTER: schedule new run for iteration 0
22:58:52 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
22:58:52 HBMASTER: submitting job (0, 0, 16) to dispatcher
22:58:52 DISPATCHER: trying to submit job (0, 0, 16)
22:58:52 DISPATCHER: trying to notify the job_runner thread.
22:58:52 HBMASTER: job (0, 0, 16) submitted to dispatcher
22:58:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:58:52 DISPATCHER: Trying to submit another job.
22:58:52 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:58:52 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:58:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:58:52 WORKER: start processing job (0, 0, 16)
22:58:52 WORKER: args: ()
22:58:52 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 927, 'last_n_outputs': 26, 'leak_rate': 0.7944225655451056, 'lr': 0.03969869701863655, 'optimizer': 'SGD', 'sparsity': 0.9483954301771729, 'steps_to_train': 16, 'weight_decay': 0.03045929312827966}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:59:22 DISPATCHER: Starting worker discovery
22:59:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:59:22 DISPATCHER: Finished worker discovery
22:59:55 WORKER: done with job (0, 0, 16), trying to register it.
22:59:55 WORKER: registered result for job (0, 0, 16) with dispatcher
22:59:55 DISPATCHER: job (0, 0, 16) finished
22:59:55 DISPATCHER: register_result: lock acquired
22:59:55 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:59:55 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 927, 'last_n_outputs': 26, 'leak_rate': 0.7944225655451056, 'lr': 0.03969869701863655, 'optimizer': 'SGD', 'sparsity': 0.9483954301771729, 'steps_to_train': 16, 'weight_decay': 0.03045929312827966}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.12506166165400126, 'info': {'data04': 0.12506166165400126, 'config': "{'batch_size': 16, 'hidden_dim': 927, 'last_n_outputs': 26, 'leak_rate': 0.7944225655451056, 'lr': 0.03969869701863655, 'optimizer': 'SGD', 'sparsity': 0.9483954301771729, 'steps_to_train': 16, 'weight_decay': 0.03045929312827966}"}}
exception: None

22:59:55 job_callback for (0, 0, 16) started
22:59:55 DISPATCHER: Trying to submit another job.
22:59:55 job_callback for (0, 0, 16) got condition
22:59:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:59:55 HBMASTER: Trying to run another job!
22:59:55 job_callback for (0, 0, 16) finished
22:59:55 start sampling a new configuration.
22:59:55 done sampling a new configuration.
22:59:55 HBMASTER: schedule new run for iteration 0
22:59:55 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
22:59:55 HBMASTER: submitting job (0, 0, 17) to dispatcher
22:59:55 DISPATCHER: trying to submit job (0, 0, 17)
22:59:55 DISPATCHER: trying to notify the job_runner thread.
22:59:55 HBMASTER: job (0, 0, 17) submitted to dispatcher
22:59:55 DISPATCHER: Trying to submit another job.
22:59:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:59:55 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:59:55 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:59:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:59:55 WORKER: start processing job (0, 0, 17)
22:59:55 WORKER: args: ()
22:59:55 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 580, 'last_n_outputs': 23, 'leak_rate': 0.7919992401572555, 'lr': 0.0023491609410657643, 'optimizer': 'Adam', 'sparsity': 0.9701123354900282, 'steps_to_train': 67, 'weight_decay': 0.01618569700189219}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:00:22 DISPATCHER: Starting worker discovery
23:00:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:00:22 DISPATCHER: Finished worker discovery
23:00:56 WORKER: done with job (0, 0, 17), trying to register it.
23:00:56 WORKER: registered result for job (0, 0, 17) with dispatcher
23:00:56 DISPATCHER: job (0, 0, 17) finished
23:00:56 DISPATCHER: register_result: lock acquired
23:00:56 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
23:00:56 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 580, 'last_n_outputs': 23, 'leak_rate': 0.7919992401572555, 'lr': 0.0023491609410657643, 'optimizer': 'Adam', 'sparsity': 0.9701123354900282, 'steps_to_train': 67, 'weight_decay': 0.01618569700189219}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.12324172477174265, 'info': {'data04': 0.12324172477174265, 'config': "{'batch_size': 64, 'hidden_dim': 580, 'last_n_outputs': 23, 'leak_rate': 0.7919992401572555, 'lr': 0.0023491609410657643, 'optimizer': 'Adam', 'sparsity': 0.9701123354900282, 'steps_to_train': 67, 'weight_decay': 0.01618569700189219}"}}
exception: None

23:00:56 job_callback for (0, 0, 17) started
23:00:56 job_callback for (0, 0, 17) got condition
23:00:56 DISPATCHER: Trying to submit another job.
23:00:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:00:56 HBMASTER: Trying to run another job!
23:00:56 job_callback for (0, 0, 17) finished
23:00:56 start sampling a new configuration.
23:00:56 done sampling a new configuration.
23:00:56 HBMASTER: schedule new run for iteration 0
23:00:56 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
23:00:56 HBMASTER: submitting job (0, 0, 18) to dispatcher
23:00:56 DISPATCHER: trying to submit job (0, 0, 18)
23:00:56 DISPATCHER: trying to notify the job_runner thread.
23:00:56 HBMASTER: job (0, 0, 18) submitted to dispatcher
23:00:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:00:56 DISPATCHER: Trying to submit another job.
23:00:56 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:00:56 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:00:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:00:56 WORKER: start processing job (0, 0, 18)
23:00:56 WORKER: args: ()
23:00:56 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 206, 'last_n_outputs': 37, 'leak_rate': 0.92622873981803, 'lr': 0.01577144406655133, 'optimizer': 'Adam', 'sparsity': 0.784367993859477, 'steps_to_train': 12, 'weight_decay': 0.011374109306356767}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:01:22 DISPATCHER: Starting worker discovery
23:01:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:01:22 DISPATCHER: Finished worker discovery
23:02:00 WORKER: done with job (0, 0, 18), trying to register it.
23:02:00 WORKER: registered result for job (0, 0, 18) with dispatcher
23:02:00 DISPATCHER: job (0, 0, 18) finished
23:02:00 DISPATCHER: register_result: lock acquired
23:02:00 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
23:02:00 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 206, 'last_n_outputs': 37, 'leak_rate': 0.92622873981803, 'lr': 0.01577144406655133, 'optimizer': 'Adam', 'sparsity': 0.784367993859477, 'steps_to_train': 12, 'weight_decay': 0.011374109306356767}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.032740312865211535, 'info': {'data04': 0.032740312865211535, 'config': "{'batch_size': 128, 'hidden_dim': 206, 'last_n_outputs': 37, 'leak_rate': 0.92622873981803, 'lr': 0.01577144406655133, 'optimizer': 'Adam', 'sparsity': 0.784367993859477, 'steps_to_train': 12, 'weight_decay': 0.011374109306356767}"}}
exception: None

23:02:00 job_callback for (0, 0, 18) started
23:02:00 job_callback for (0, 0, 18) got condition
23:02:00 DISPATCHER: Trying to submit another job.
23:02:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:02:00 HBMASTER: Trying to run another job!
23:02:00 job_callback for (0, 0, 18) finished
23:02:00 start sampling a new configuration.
23:02:00 done sampling a new configuration.
23:02:00 HBMASTER: schedule new run for iteration 0
23:02:00 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
23:02:00 HBMASTER: submitting job (0, 0, 19) to dispatcher
23:02:00 DISPATCHER: trying to submit job (0, 0, 19)
23:02:00 DISPATCHER: trying to notify the job_runner thread.
23:02:00 HBMASTER: job (0, 0, 19) submitted to dispatcher
23:02:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:02:00 DISPATCHER: Trying to submit another job.
23:02:00 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:02:00 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:02:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:02:00 WORKER: start processing job (0, 0, 19)
23:02:00 WORKER: args: ()
23:02:00 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 472, 'last_n_outputs': 12, 'leak_rate': 0.9341841234292991, 'lr': 0.002488797252345932, 'optimizer': 'Adam', 'sparsity': 0.8033505959702218, 'steps_to_train': 85, 'weight_decay': 0.01582536276824825}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:02:22 DISPATCHER: Starting worker discovery
23:02:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:02:22 DISPATCHER: Finished worker discovery
23:03:00 WORKER: done with job (0, 0, 19), trying to register it.
23:03:00 WORKER: registered result for job (0, 0, 19) with dispatcher
23:03:00 DISPATCHER: job (0, 0, 19) finished
23:03:00 DISPATCHER: register_result: lock acquired
23:03:00 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
23:03:00 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 472, 'last_n_outputs': 12, 'leak_rate': 0.9341841234292991, 'lr': 0.002488797252345932, 'optimizer': 'Adam', 'sparsity': 0.8033505959702218, 'steps_to_train': 85, 'weight_decay': 0.01582536276824825}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.09462678210717647, 'info': {'data04': 0.09462678210717647, 'config': "{'batch_size': 32, 'hidden_dim': 472, 'last_n_outputs': 12, 'leak_rate': 0.9341841234292991, 'lr': 0.002488797252345932, 'optimizer': 'Adam', 'sparsity': 0.8033505959702218, 'steps_to_train': 85, 'weight_decay': 0.01582536276824825}"}}
exception: None

23:03:00 job_callback for (0, 0, 19) started
23:03:00 DISPATCHER: Trying to submit another job.
23:03:00 job_callback for (0, 0, 19) got condition
23:03:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:03:00 done building a new model for budget 44.444444 based on 10/17 split
Best loss for this budget:-0.188157





23:03:00 HBMASTER: Trying to run another job!
23:03:00 job_callback for (0, 0, 19) finished
23:03:00 start sampling a new configuration.
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/statsmodels/nonparametric/kernels.py:62: RuntimeWarning: divide by zero encountered in true_divide
  kernel_value = np.ones(Xi.size) * h / (num_levels - 1)
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/numpy/core/_methods.py:38: RuntimeWarning: invalid value encountered in reduce
  return umr_sum(a, axis, dtype, out, keepdims, initial, where)
23:03:00 sampled vector: [1, 0.9318133076145927, 0.3768343578433292, 0.9679735283884003, 0.168340020522041, 1, 0.5090496317159807, 0.9862522897589978, 0.5614950767627436] has EI value inf
23:03:00 data in the KDEs:
[[0.         0.83333334 0.62195128 0.60540606 0.51949976 1.
  0.26169293 0.63186816 0.027787  ]
 [3.         0.91822723 0.57317077 0.60308056 0.48328355 1.
  0.47648461 0.71978027 0.55770103]
 [1.         0.19163545 0.7195123  0.91409939 0.71623053 1.
  0.68725199 0.98351659 0.73626851]
 [2.         0.30898876 0.81707333 0.42625917 0.46554395 1.
  0.54133597 0.70879125 0.90338677]
 [3.         0.47378277 0.03658514 0.41678678 0.73871958 1.
  0.97287933 0.69780224 0.54906912]
 [2.         0.04931335 0.18292667 0.38663036 0.84423678 1.
  0.66436923 0.59890112 0.30490571]
 [0.         0.90823971 0.40243898 0.17769026 0.79938813 1.
  0.82664763 0.07142848 0.37179759]
 [2.         0.47503121 0.32926821 0.16799696 0.18545639 0.
  0.91713473 0.63186816 0.16074296]
 [3.         0.85705369 0.18292667 0.50441392 0.31997778 0.
  0.45564787 0.91758251 0.07947321]
 [1.         0.34019975 0.0609754  0.73673649 0.19799476 0.
  0.22229415 0.8296704  0.15322758]]
[[3.         0.09925093 0.59756102 0.89851892 0.37091805 0.
  0.47929512 0.25824171 0.52506039]
 [3.         0.34893882 0.76829281 0.49114325 0.12425809 0.
  0.14087876 0.8296704  0.53912367]
 [0.         0.71598003 0.0609754  0.33652498 0.34609256 0.
  0.74897112 0.1703296  0.24276282]
 [3.         0.04806491 0.42682923 0.67220899 0.91823564 0.
  0.1990947  0.58791211 0.00739772]
 [0.         0.48751561 0.18292667 0.49915054 0.13360685 0.
  0.63655071 0.54395605 0.52149642]
 [0.         0.66104869 0.45121949 0.56420939 0.05612927 0.
  0.21553244 0.53296704 0.65562666]
 [3.         0.00811484 0.67073179 0.70491496 0.59893573 0.
  0.14319997 0.02747242 0.04297933]
 [3.         0.6360799  0.96341486 0.19873104 0.80494861 0.
  0.93648756 0.58791211 0.01454234]
 [3.         0.69225968 0.98780512 0.89561777 0.94624109 0.
  0.97214005 0.44505493 0.85500677]
 [2.         0.67852685 0.84146358 0.44551121 0.86857331 0.
  0.21822537 0.86263744 0.48081459]]
23:03:00 bandwidth of the KDEs:
[0.97673213 0.2706467  0.23509615 0.19619851 0.20421939 0.40690445
 0.21737649 0.20923325 0.24805163]
[1.19129424e+00 2.43292482e-01 2.64969287e-01 1.90796499e-01
 2.97513241e-01 1.00000000e-03 2.79672285e-01 2.26333466e-01
 2.48343280e-01]
23:03:00 l(x) = 0.021751733653410592
23:03:00 g(x) = inf
23:03:00 best_vector: [1, 0.9318133076145927, 0.3768343578433292, 0.9679735283884003, 0.168340020522041, 1, 0.5090496317159807, 0.9862522897589978, 0.5614950767627436], 1.1041726191703413e-28, 0.021751733653410592, inf
23:03:00 done sampling a new configuration.
23:03:00 HBMASTER: schedule new run for iteration 0
23:03:00 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
23:03:00 HBMASTER: submitting job (0, 0, 20) to dispatcher
23:03:00 DISPATCHER: trying to submit job (0, 0, 20)
23:03:00 DISPATCHER: trying to notify the job_runner thread.
23:03:00 HBMASTER: job (0, 0, 20) submitted to dispatcher
23:03:00 DISPATCHER: Trying to submit another job.
23:03:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:03:00 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:03:00 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:03:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:03:00 WORKER: start processing job (0, 0, 20)
23:03:00 WORKER: args: ()
23:03:00 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 946, 'last_n_outputs': 25, 'leak_rate': 0.9919933820971001, 'lr': 0.0021711010683088464, 'optimizer': 'SGD', 'sparsity': 0.8721719116118354, 'steps_to_train': 99, 'weight_decay': 0.05376775918583}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:03:22 DISPATCHER: Starting worker discovery
23:03:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:03:22 DISPATCHER: Finished worker discovery
23:04:01 WORKER: done with job (0, 0, 20), trying to register it.
23:04:01 WORKER: registered result for job (0, 0, 20) with dispatcher
23:04:01 DISPATCHER: job (0, 0, 20) finished
23:04:01 DISPATCHER: register_result: lock acquired
23:04:01 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
23:04:01 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 946, 'last_n_outputs': 25, 'leak_rate': 0.9919933820971001, 'lr': 0.0021711010683088464, 'optimizer': 'SGD', 'sparsity': 0.8721719116118354, 'steps_to_train': 99, 'weight_decay': 0.05376775918583}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.15050956738437277, 'info': {'data04': 0.15050956738437277, 'config': "{'batch_size': 32, 'hidden_dim': 946, 'last_n_outputs': 25, 'leak_rate': 0.9919933820971001, 'lr': 0.0021711010683088464, 'optimizer': 'SGD', 'sparsity': 0.8721719116118354, 'steps_to_train': 99, 'weight_decay': 0.05376775918583}"}}
exception: None

23:04:01 job_callback for (0, 0, 20) started
23:04:01 DISPATCHER: Trying to submit another job.
23:04:01 job_callback for (0, 0, 20) got condition
23:04:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:04:01 done building a new model for budget 44.444444 based on 10/17 split
Best loss for this budget:-0.188157





23:04:01 HBMASTER: Trying to run another job!
23:04:01 job_callback for (0, 0, 20) finished
23:04:01 start sampling a new configuration.
23:04:01 done sampling a new configuration.
23:04:01 HBMASTER: schedule new run for iteration 0
23:04:01 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
23:04:01 HBMASTER: submitting job (0, 0, 21) to dispatcher
23:04:01 DISPATCHER: trying to submit job (0, 0, 21)
23:04:01 DISPATCHER: trying to notify the job_runner thread.
23:04:01 HBMASTER: job (0, 0, 21) submitted to dispatcher
23:04:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:04:01 DISPATCHER: Trying to submit another job.
23:04:01 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:04:01 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:04:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:04:01 WORKER: start processing job (0, 0, 21)
23:04:01 WORKER: args: ()
23:04:01 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 866, 'last_n_outputs': 20, 'leak_rate': 0.9747302115030109, 'lr': 0.002573808439593128, 'optimizer': 'Adam', 'sparsity': 0.840485933871795, 'steps_to_train': 100, 'weight_decay': 0.09751060521864398}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:04:22 DISPATCHER: Starting worker discovery
23:04:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:04:22 DISPATCHER: Finished worker discovery
23:05:01 WORKER: done with job (0, 0, 21), trying to register it.
23:05:01 WORKER: registered result for job (0, 0, 21) with dispatcher
23:05:01 DISPATCHER: job (0, 0, 21) finished
23:05:01 DISPATCHER: register_result: lock acquired
23:05:01 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
23:05:01 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 866, 'last_n_outputs': 20, 'leak_rate': 0.9747302115030109, 'lr': 0.002573808439593128, 'optimizer': 'Adam', 'sparsity': 0.840485933871795, 'steps_to_train': 100, 'weight_decay': 0.09751060521864398}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.09348880473489006, 'info': {'data04': 0.09348880473489006, 'config': "{'batch_size': 128, 'hidden_dim': 866, 'last_n_outputs': 20, 'leak_rate': 0.9747302115030109, 'lr': 0.002573808439593128, 'optimizer': 'Adam', 'sparsity': 0.840485933871795, 'steps_to_train': 100, 'weight_decay': 0.09751060521864398}"}}
exception: None

23:05:01 job_callback for (0, 0, 21) started
23:05:01 DISPATCHER: Trying to submit another job.
23:05:01 job_callback for (0, 0, 21) got condition
23:05:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:05:01 done building a new model for budget 44.444444 based on 10/18 split
Best loss for this budget:-0.188157





23:05:01 HBMASTER: Trying to run another job!
23:05:01 job_callback for (0, 0, 21) finished
23:05:01 start sampling a new configuration.
23:05:01 best_vector: [0, 0.8304908742330555, 0.636155223568406, 0.8750593629069219, 0.4779679122819969, 1, 0.4284337393923633, 0.8734133117890523, 0.47701046765395433], 1.9535715920258346e-32, 0.5118829553428395, nan
23:05:01 done sampling a new configuration.
23:05:01 HBMASTER: schedule new run for iteration 0
23:05:01 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
23:05:01 HBMASTER: submitting job (0, 0, 22) to dispatcher
23:05:01 DISPATCHER: trying to submit job (0, 0, 22)
23:05:01 DISPATCHER: trying to notify the job_runner thread.
23:05:01 HBMASTER: job (0, 0, 22) submitted to dispatcher
23:05:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:05:01 DISPATCHER: Trying to submit another job.
23:05:01 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:05:01 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:05:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:05:01 WORKER: start processing job (0, 0, 22)
23:05:01 WORKER: args: ()
23:05:01 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 865, 'last_n_outputs': 36, 'leak_rate': 0.9687648407267304, 'lr': 0.009035159518451626, 'optimizer': 'SGD', 'sparsity': 0.8528240974541672, 'steps_to_train': 89, 'weight_decay': 0.041745044338311235}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:05:22 DISPATCHER: Starting worker discovery
23:05:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:05:22 DISPATCHER: Finished worker discovery
23:06:04 WORKER: done with job (0, 0, 22), trying to register it.
23:06:04 WORKER: registered result for job (0, 0, 22) with dispatcher
23:06:04 DISPATCHER: job (0, 0, 22) finished
23:06:04 DISPATCHER: register_result: lock acquired
23:06:04 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
23:06:04 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 865, 'last_n_outputs': 36, 'leak_rate': 0.9687648407267304, 'lr': 0.009035159518451626, 'optimizer': 'SGD', 'sparsity': 0.8528240974541672, 'steps_to_train': 89, 'weight_decay': 0.041745044338311235}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1565386333948535, 'info': {'data04': 0.1565386333948535, 'config': "{'batch_size': 16, 'hidden_dim': 865, 'last_n_outputs': 36, 'leak_rate': 0.9687648407267304, 'lr': 0.009035159518451626, 'optimizer': 'SGD', 'sparsity': 0.8528240974541672, 'steps_to_train': 89, 'weight_decay': 0.041745044338311235}"}}
exception: None

23:06:04 job_callback for (0, 0, 22) started
23:06:04 DISPATCHER: Trying to submit another job.
23:06:04 job_callback for (0, 0, 22) got condition
23:06:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:06:04 done building a new model for budget 44.444444 based on 10/19 split
Best loss for this budget:-0.188157





23:06:04 HBMASTER: Trying to run another job!
23:06:04 job_callback for (0, 0, 22) finished
23:06:04 start sampling a new configuration.
23:06:04 done sampling a new configuration.
23:06:04 HBMASTER: schedule new run for iteration 0
23:06:04 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
23:06:04 HBMASTER: submitting job (0, 0, 23) to dispatcher
23:06:04 DISPATCHER: trying to submit job (0, 0, 23)
23:06:04 DISPATCHER: trying to notify the job_runner thread.
23:06:04 HBMASTER: job (0, 0, 23) submitted to dispatcher
23:06:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:06:04 DISPATCHER: Trying to submit another job.
23:06:04 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:06:04 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:06:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:06:04 WORKER: start processing job (0, 0, 23)
23:06:04 WORKER: args: ()
23:06:04 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 470, 'last_n_outputs': 23, 'leak_rate': 0.7814086525614874, 'lr': 0.0036115426910764132, 'optimizer': 'SGD', 'sparsity': 0.8656088957680196, 'steps_to_train': 53, 'weight_decay': 0.03360454464855042}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:06:22 DISPATCHER: Starting worker discovery
23:06:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:06:22 DISPATCHER: Finished worker discovery
23:07:04 WORKER: done with job (0, 0, 23), trying to register it.
23:07:04 WORKER: registered result for job (0, 0, 23) with dispatcher
23:07:04 DISPATCHER: job (0, 0, 23) finished
23:07:04 DISPATCHER: register_result: lock acquired
23:07:04 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
23:07:04 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 470, 'last_n_outputs': 23, 'leak_rate': 0.7814086525614874, 'lr': 0.0036115426910764132, 'optimizer': 'SGD', 'sparsity': 0.8656088957680196, 'steps_to_train': 53, 'weight_decay': 0.03360454464855042}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.12138970375228318, 'info': {'data04': 0.12138970375228318, 'config': "{'batch_size': 128, 'hidden_dim': 470, 'last_n_outputs': 23, 'leak_rate': 0.7814086525614874, 'lr': 0.0036115426910764132, 'optimizer': 'SGD', 'sparsity': 0.8656088957680196, 'steps_to_train': 53, 'weight_decay': 0.03360454464855042}"}}
exception: None

23:07:04 job_callback for (0, 0, 23) started
23:07:04 DISPATCHER: Trying to submit another job.
23:07:04 job_callback for (0, 0, 23) got condition
23:07:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:07:04 done building a new model for budget 44.444444 based on 10/20 split
Best loss for this budget:-0.188157





23:07:04 HBMASTER: Trying to run another job!
23:07:04 job_callback for (0, 0, 23) finished
23:07:04 start sampling a new configuration.
23:07:04 best_vector: [3, 0.2917365807070342, 0.10953330443640878, 0.17268955455722956, 0.7612921936297448, 1, 0.6077967481211921, 0.37868086248786786, 0.15306726464805182], 3.590825960307591e-32, 0.2784874597248205, -0.003683080246361626
23:07:04 done sampling a new configuration.
23:07:04 HBMASTER: schedule new run for iteration 0
23:07:04 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
23:07:04 HBMASTER: submitting job (0, 0, 24) to dispatcher
23:07:04 DISPATCHER: trying to submit job (0, 0, 24)
23:07:04 DISPATCHER: trying to notify the job_runner thread.
23:07:04 HBMASTER: job (0, 0, 24) submitted to dispatcher
23:07:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:07:04 DISPATCHER: Trying to submit another job.
23:07:04 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:07:04 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:07:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:07:04 WORKER: start processing job (0, 0, 24)
23:07:04 WORKER: args: ()
23:07:04 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 433, 'last_n_outputs': 14, 'leak_rate': 0.7931723886393074, 'lr': 0.03331074817510489, 'optimizer': 'SGD', 'sparsity': 0.8958712195490861, 'steps_to_train': 44, 'weight_decay': 0.015817764402572224}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:07:22 DISPATCHER: Starting worker discovery
23:07:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:07:22 DISPATCHER: Finished worker discovery
23:08:05 WORKER: done with job (0, 0, 24), trying to register it.
23:08:05 WORKER: registered result for job (0, 0, 24) with dispatcher
23:08:05 DISPATCHER: job (0, 0, 24) finished
23:08:05 DISPATCHER: register_result: lock acquired
23:08:05 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
23:08:05 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 433, 'last_n_outputs': 14, 'leak_rate': 0.7931723886393074, 'lr': 0.03331074817510489, 'optimizer': 'SGD', 'sparsity': 0.8958712195490861, 'steps_to_train': 44, 'weight_decay': 0.015817764402572224}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.15839163943740703, 'info': {'data04': 0.15839163943740703, 'config': "{'batch_size': 128, 'hidden_dim': 433, 'last_n_outputs': 14, 'leak_rate': 0.7931723886393074, 'lr': 0.03331074817510489, 'optimizer': 'SGD', 'sparsity': 0.8958712195490861, 'steps_to_train': 44, 'weight_decay': 0.015817764402572224}"}}
exception: None

23:08:05 job_callback for (0, 0, 24) started
23:08:05 job_callback for (0, 0, 24) got condition
23:08:05 DISPATCHER: Trying to submit another job.
23:08:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:08:05 done building a new model for budget 44.444444 based on 10/21 split
Best loss for this budget:-0.188157





23:08:05 HBMASTER: Trying to run another job!
23:08:05 job_callback for (0, 0, 24) finished
23:08:05 start sampling a new configuration.
23:08:05 best_vector: [3, 0.67658373925058, 0.3661641017614354, 0.8525800161563277, 0.8303763576323508, 1, 0.8359837142613442, 0.9409038567358656, 0.8416320993297624], 1.2746518320326283e-31, 0.07845279588272716, -7.827378572432759e-05
23:08:05 done sampling a new configuration.
23:08:05 HBMASTER: schedule new run for iteration 0
23:08:05 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
23:08:05 HBMASTER: submitting job (0, 0, 25) to dispatcher
23:08:05 DISPATCHER: trying to submit job (0, 0, 25)
23:08:05 DISPATCHER: trying to notify the job_runner thread.
23:08:05 HBMASTER: job (0, 0, 25) submitted to dispatcher
23:08:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:08:05 DISPATCHER: Trying to submit another job.
23:08:05 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:08:05 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:08:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:08:05 WORKER: start processing job (0, 0, 25)
23:08:05 WORKER: args: ()
23:08:05 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 741, 'last_n_outputs': 25, 'leak_rate': 0.9631450040390819, 'lr': 0.04578810976594836, 'optimizer': 'SGD', 'sparsity': 0.9506360914227225, 'steps_to_train': 95, 'weight_decay': 0.12444819630964146}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:08:22 DISPATCHER: Starting worker discovery
23:08:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:08:22 DISPATCHER: Finished worker discovery
23:09:07 WORKER: done with job (0, 0, 25), trying to register it.
23:09:07 WORKER: registered result for job (0, 0, 25) with dispatcher
23:09:07 DISPATCHER: job (0, 0, 25) finished
23:09:07 DISPATCHER: register_result: lock acquired
23:09:07 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
23:09:07 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 741, 'last_n_outputs': 25, 'leak_rate': 0.9631450040390819, 'lr': 0.04578810976594836, 'optimizer': 'SGD', 'sparsity': 0.9506360914227225, 'steps_to_train': 95, 'weight_decay': 0.12444819630964146}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.14972573816330853, 'info': {'data04': 0.14972573816330853, 'config': "{'batch_size': 128, 'hidden_dim': 741, 'last_n_outputs': 25, 'leak_rate': 0.9631450040390819, 'lr': 0.04578810976594836, 'optimizer': 'SGD', 'sparsity': 0.9506360914227225, 'steps_to_train': 95, 'weight_decay': 0.12444819630964146}"}}
exception: None

23:09:07 job_callback for (0, 0, 25) started
23:09:07 job_callback for (0, 0, 25) got condition
23:09:07 DISPATCHER: Trying to submit another job.
23:09:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:09:07 done building a new model for budget 44.444444 based on 10/22 split
Best loss for this budget:-0.188157





23:09:07 HBMASTER: Trying to run another job!
23:09:07 job_callback for (0, 0, 25) finished
23:09:07 start sampling a new configuration.
23:09:07 done sampling a new configuration.
23:09:07 HBMASTER: schedule new run for iteration 0
23:09:07 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
23:09:07 HBMASTER: submitting job (0, 0, 26) to dispatcher
23:09:07 DISPATCHER: trying to submit job (0, 0, 26)
23:09:07 DISPATCHER: trying to notify the job_runner thread.
23:09:07 HBMASTER: job (0, 0, 26) submitted to dispatcher
23:09:07 DISPATCHER: Trying to submit another job.
23:09:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:09:07 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:09:07 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:09:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:09:07 WORKER: start processing job (0, 0, 26)
23:09:07 WORKER: args: ()
23:09:07 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 573, 'last_n_outputs': 45, 'leak_rate': 0.9182805417779003, 'lr': 0.004192355813364481, 'optimizer': 'Adam', 'sparsity': 0.9295004839265808, 'steps_to_train': 71, 'weight_decay': 0.05491375692328609}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:09:22 DISPATCHER: Starting worker discovery
23:09:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:09:22 DISPATCHER: Finished worker discovery
23:10:07 WORKER: done with job (0, 0, 26), trying to register it.
23:10:07 WORKER: registered result for job (0, 0, 26) with dispatcher
23:10:07 DISPATCHER: job (0, 0, 26) finished
23:10:07 DISPATCHER: register_result: lock acquired
23:10:07 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
23:10:07 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 573, 'last_n_outputs': 45, 'leak_rate': 0.9182805417779003, 'lr': 0.004192355813364481, 'optimizer': 'Adam', 'sparsity': 0.9295004839265808, 'steps_to_train': 71, 'weight_decay': 0.05491375692328609}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.07256924103144266, 'info': {'data04': 0.07256924103144266, 'config': "{'batch_size': 128, 'hidden_dim': 573, 'last_n_outputs': 45, 'leak_rate': 0.9182805417779003, 'lr': 0.004192355813364481, 'optimizer': 'Adam', 'sparsity': 0.9295004839265808, 'steps_to_train': 71, 'weight_decay': 0.05491375692328609}"}}
exception: None

23:10:07 job_callback for (0, 0, 26) started
23:10:07 DISPATCHER: Trying to submit another job.
23:10:07 job_callback for (0, 0, 26) got condition
23:10:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:10:07 done building a new model for budget 44.444444 based on 10/22 split
Best loss for this budget:-0.188157





23:10:07 HBMASTER: Trying to run another job!
23:10:07 job_callback for (0, 0, 26) finished
23:10:07 ITERATION: Advancing config (0, 0, 1) to next budget 133.333333
23:10:07 ITERATION: Advancing config (0, 0, 5) to next budget 133.333333
23:10:07 ITERATION: Advancing config (0, 0, 7) to next budget 133.333333
23:10:07 ITERATION: Advancing config (0, 0, 9) to next budget 133.333333
23:10:07 ITERATION: Advancing config (0, 0, 10) to next budget 133.333333
23:10:07 ITERATION: Advancing config (0, 0, 20) to next budget 133.333333
23:10:07 ITERATION: Advancing config (0, 0, 22) to next budget 133.333333
23:10:07 ITERATION: Advancing config (0, 0, 24) to next budget 133.333333
23:10:07 ITERATION: Advancing config (0, 0, 25) to next budget 133.333333
23:10:07 HBMASTER: schedule new run for iteration 0
23:10:07 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
23:10:07 HBMASTER: submitting job (0, 0, 1) to dispatcher
23:10:07 DISPATCHER: trying to submit job (0, 0, 1)
23:10:07 DISPATCHER: trying to notify the job_runner thread.
23:10:07 HBMASTER: job (0, 0, 1) submitted to dispatcher
23:10:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:10:07 DISPATCHER: Trying to submit another job.
23:10:07 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:10:07 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:10:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:10:07 WORKER: start processing job (0, 0, 1)
23:10:07 WORKER: args: ()
23:10:07 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 447, 'last_n_outputs': 43, 'leak_rate': 0.856564792492804, 'lr': 0.008532727963501368, 'optimizer': 'SGD', 'sparsity': 0.8799206321865392, 'steps_to_train': 74, 'weight_decay': 0.14973843329667766}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:10:22 DISPATCHER: Starting worker discovery
23:10:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:10:22 DISPATCHER: Finished worker discovery
23:11:22 DISPATCHER: Starting worker discovery
23:11:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:11:22 DISPATCHER: Finished worker discovery
23:12:22 DISPATCHER: Starting worker discovery
23:12:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:12:22 DISPATCHER: Finished worker discovery
23:12:38 WORKER: done with job (0, 0, 1), trying to register it.
23:12:38 WORKER: registered result for job (0, 0, 1) with dispatcher
23:12:38 DISPATCHER: job (0, 0, 1) finished
23:12:38 DISPATCHER: register_result: lock acquired
23:12:38 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
23:12:38 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 447, 'last_n_outputs': 43, 'leak_rate': 0.856564792492804, 'lr': 0.008532727963501368, 'optimizer': 'SGD', 'sparsity': 0.8799206321865392, 'steps_to_train': 74, 'weight_decay': 0.14973843329667766}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.17395006988797754, 'info': {'data04': 0.17395006988797754, 'config': "{'batch_size': 64, 'hidden_dim': 447, 'last_n_outputs': 43, 'leak_rate': 0.856564792492804, 'lr': 0.008532727963501368, 'optimizer': 'SGD', 'sparsity': 0.8799206321865392, 'steps_to_train': 74, 'weight_decay': 0.14973843329667766}"}}
exception: None

23:12:38 job_callback for (0, 0, 1) started
23:12:38 DISPATCHER: Trying to submit another job.
23:12:38 job_callback for (0, 0, 1) got condition
23:12:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:12:38 Only 1 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
23:12:38 HBMASTER: Trying to run another job!
23:12:38 job_callback for (0, 0, 1) finished
23:12:38 HBMASTER: schedule new run for iteration 0
23:12:38 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
23:12:38 HBMASTER: submitting job (0, 0, 5) to dispatcher
23:12:38 DISPATCHER: trying to submit job (0, 0, 5)
23:12:38 DISPATCHER: trying to notify the job_runner thread.
23:12:38 HBMASTER: job (0, 0, 5) submitted to dispatcher
23:12:38 DISPATCHER: Trying to submit another job.
23:12:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:12:38 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:12:38 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:12:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:12:38 WORKER: start processing job (0, 0, 5)
23:12:38 WORKER: args: ()
23:12:38 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 353, 'last_n_outputs': 39, 'leak_rate': 0.9785248474848329, 'lr': 0.02706830492329233, 'optimizer': 'SGD', 'sparsity': 0.9149404780468433, 'steps_to_train': 99, 'weight_decay': 0.09076270112052477}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:13:22 DISPATCHER: Starting worker discovery
23:13:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:13:22 DISPATCHER: Finished worker discovery
23:14:22 DISPATCHER: Starting worker discovery
23:14:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:14:22 DISPATCHER: Finished worker discovery
23:15:10 WORKER: done with job (0, 0, 5), trying to register it.
23:15:10 WORKER: registered result for job (0, 0, 5) with dispatcher
23:15:10 DISPATCHER: job (0, 0, 5) finished
23:15:10 DISPATCHER: register_result: lock acquired
23:15:10 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
23:15:10 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 353, 'last_n_outputs': 39, 'leak_rate': 0.9785248474848329, 'lr': 0.02706830492329233, 'optimizer': 'SGD', 'sparsity': 0.9149404780468433, 'steps_to_train': 99, 'weight_decay': 0.09076270112052477}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.15143800635002855, 'info': {'data04': 0.15143800635002855, 'config': "{'batch_size': 32, 'hidden_dim': 353, 'last_n_outputs': 39, 'leak_rate': 0.9785248474848329, 'lr': 0.02706830492329233, 'optimizer': 'SGD', 'sparsity': 0.9149404780468433, 'steps_to_train': 99, 'weight_decay': 0.09076270112052477}"}}
exception: None

23:15:10 job_callback for (0, 0, 5) started
23:15:10 job_callback for (0, 0, 5) got condition
23:15:10 DISPATCHER: Trying to submit another job.
23:15:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:15:10 Only 2 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
23:15:10 HBMASTER: Trying to run another job!
23:15:10 job_callback for (0, 0, 5) finished
23:15:10 HBMASTER: schedule new run for iteration 0
23:15:10 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
23:15:10 HBMASTER: submitting job (0, 0, 7) to dispatcher
23:15:10 DISPATCHER: trying to submit job (0, 0, 7)
23:15:10 DISPATCHER: trying to notify the job_runner thread.
23:15:10 HBMASTER: job (0, 0, 7) submitted to dispatcher
23:15:10 DISPATCHER: Trying to submit another job.
23:15:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:15:10 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:15:10 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:15:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:15:10 WORKER: start processing job (0, 0, 7)
23:15:10 WORKER: args: ()
23:15:10 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 867, 'last_n_outputs': 35, 'leak_rate': 0.9013515152456588, 'lr': 0.010939551424379268, 'optimizer': 'SGD', 'sparsity': 0.8128063031560117, 'steps_to_train': 67, 'weight_decay': 0.010868052347680388}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:15:22 DISPATCHER: Starting worker discovery
23:15:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:15:22 DISPATCHER: Finished worker discovery
23:16:22 DISPATCHER: Starting worker discovery
23:16:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:16:22 DISPATCHER: Finished worker discovery
23:17:22 DISPATCHER: Starting worker discovery
23:17:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:17:22 DISPATCHER: Finished worker discovery
23:17:42 WORKER: done with job (0, 0, 7), trying to register it.
23:17:42 WORKER: registered result for job (0, 0, 7) with dispatcher
23:17:42 DISPATCHER: job (0, 0, 7) finished
23:17:42 DISPATCHER: register_result: lock acquired
23:17:42 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
23:17:42 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 867, 'last_n_outputs': 35, 'leak_rate': 0.9013515152456588, 'lr': 0.010939551424379268, 'optimizer': 'SGD', 'sparsity': 0.8128063031560117, 'steps_to_train': 67, 'weight_decay': 0.010868052347680388}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.17898701939824557, 'info': {'data04': 0.17898701939824557, 'config': "{'batch_size': 16, 'hidden_dim': 867, 'last_n_outputs': 35, 'leak_rate': 0.9013515152456588, 'lr': 0.010939551424379268, 'optimizer': 'SGD', 'sparsity': 0.8128063031560117, 'steps_to_train': 67, 'weight_decay': 0.010868052347680388}"}}
exception: None

23:17:42 job_callback for (0, 0, 7) started
23:17:42 DISPATCHER: Trying to submit another job.
23:17:42 job_callback for (0, 0, 7) got condition
23:17:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:17:42 Only 3 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
23:17:42 HBMASTER: Trying to run another job!
23:17:42 job_callback for (0, 0, 7) finished
23:17:42 HBMASTER: schedule new run for iteration 0
23:17:42 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
23:17:42 HBMASTER: submitting job (0, 0, 9) to dispatcher
23:17:42 DISPATCHER: trying to submit job (0, 0, 9)
23:17:42 DISPATCHER: trying to notify the job_runner thread.
23:17:42 HBMASTER: job (0, 0, 9) submitted to dispatcher
23:17:42 DISPATCHER: Trying to submit another job.
23:17:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:17:42 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:17:42 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:17:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:17:42 WORKER: start processing job (0, 0, 9)
23:17:42 WORKER: args: ()
23:17:42 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 579, 'last_n_outputs': 11, 'leak_rate': 0.854196695782137, 'lr': 0.030021968080540837, 'optimizer': 'SGD', 'sparsity': 0.9834910391806241, 'steps_to_train': 73, 'weight_decay': 0.05180305704832722}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:18:22 DISPATCHER: Starting worker discovery
23:18:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:18:22 DISPATCHER: Finished worker discovery
23:19:22 DISPATCHER: Starting worker discovery
23:19:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:19:22 DISPATCHER: Finished worker discovery
23:20:14 WORKER: done with job (0, 0, 9), trying to register it.
23:20:14 WORKER: registered result for job (0, 0, 9) with dispatcher
23:20:14 DISPATCHER: job (0, 0, 9) finished
23:20:14 DISPATCHER: register_result: lock acquired
23:20:14 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
23:20:14 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 579, 'last_n_outputs': 11, 'leak_rate': 0.854196695782137, 'lr': 0.030021968080540837, 'optimizer': 'SGD', 'sparsity': 0.9834910391806241, 'steps_to_train': 73, 'weight_decay': 0.05180305704832722}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.16516172642893223, 'info': {'data04': 0.16516172642893223, 'config': "{'batch_size': 128, 'hidden_dim': 579, 'last_n_outputs': 11, 'leak_rate': 0.854196695782137, 'lr': 0.030021968080540837, 'optimizer': 'SGD', 'sparsity': 0.9834910391806241, 'steps_to_train': 73, 'weight_decay': 0.05180305704832722}"}}
exception: None

23:20:14 job_callback for (0, 0, 9) started
23:20:14 job_callback for (0, 0, 9) got condition
23:20:14 DISPATCHER: Trying to submit another job.
23:20:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:20:14 Only 4 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
23:20:14 HBMASTER: Trying to run another job!
23:20:14 job_callback for (0, 0, 9) finished
23:20:14 HBMASTER: schedule new run for iteration 0
23:20:14 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
23:20:14 HBMASTER: submitting job (0, 0, 10) to dispatcher
23:20:14 DISPATCHER: trying to submit job (0, 0, 10)
23:20:14 DISPATCHER: trying to notify the job_runner thread.
23:20:14 HBMASTER: job (0, 0, 10) submitted to dispatcher
23:20:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:20:14 DISPATCHER: Trying to submit another job.
23:20:14 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:20:14 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:20:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:20:14 WORKER: start processing job (0, 0, 10)
23:20:14 WORKER: args: ()
23:20:14 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 935, 'last_n_outputs': 33, 'leak_rate': 0.9007701393318854, 'lr': 0.009259064102598231, 'optimizer': 'SGD', 'sparsity': 0.8643563073184608, 'steps_to_train': 75, 'weight_decay': 0.05316009720010779}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:20:22 DISPATCHER: Starting worker discovery
23:20:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:20:22 DISPATCHER: Finished worker discovery
23:21:22 DISPATCHER: Starting worker discovery
23:21:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:21:22 DISPATCHER: Finished worker discovery
23:22:22 DISPATCHER: Starting worker discovery
23:22:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:22:22 DISPATCHER: Finished worker discovery
23:22:47 WORKER: done with job (0, 0, 10), trying to register it.
23:22:47 WORKER: registered result for job (0, 0, 10) with dispatcher
23:22:47 DISPATCHER: job (0, 0, 10) finished
23:22:47 DISPATCHER: register_result: lock acquired
23:22:47 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
23:22:47 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 935, 'last_n_outputs': 33, 'leak_rate': 0.9007701393318854, 'lr': 0.009259064102598231, 'optimizer': 'SGD', 'sparsity': 0.8643563073184608, 'steps_to_train': 75, 'weight_decay': 0.05316009720010779}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.17598020568310016, 'info': {'data04': 0.17598020568310016, 'config': "{'batch_size': 128, 'hidden_dim': 935, 'last_n_outputs': 33, 'leak_rate': 0.9007701393318854, 'lr': 0.009259064102598231, 'optimizer': 'SGD', 'sparsity': 0.8643563073184608, 'steps_to_train': 75, 'weight_decay': 0.05316009720010779}"}}
exception: None

23:22:47 job_callback for (0, 0, 10) started
23:22:47 DISPATCHER: Trying to submit another job.
23:22:47 job_callback for (0, 0, 10) got condition
23:22:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:22:47 Only 5 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
23:22:47 HBMASTER: Trying to run another job!
23:22:47 job_callback for (0, 0, 10) finished
23:22:47 HBMASTER: schedule new run for iteration 0
23:22:47 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
23:22:47 HBMASTER: submitting job (0, 0, 20) to dispatcher
23:22:47 DISPATCHER: trying to submit job (0, 0, 20)
23:22:47 DISPATCHER: trying to notify the job_runner thread.
23:22:47 HBMASTER: job (0, 0, 20) submitted to dispatcher
23:22:47 DISPATCHER: Trying to submit another job.
23:22:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:22:47 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:22:47 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:22:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:22:47 WORKER: start processing job (0, 0, 20)
23:22:47 WORKER: args: ()
23:22:47 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 946, 'last_n_outputs': 25, 'leak_rate': 0.9919933820971001, 'lr': 0.0021711010683088464, 'optimizer': 'SGD', 'sparsity': 0.8721719116118354, 'steps_to_train': 99, 'weight_decay': 0.05376775918583}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:23:22 DISPATCHER: Starting worker discovery
23:23:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:23:22 DISPATCHER: Finished worker discovery
23:24:22 DISPATCHER: Starting worker discovery
23:24:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:24:22 DISPATCHER: Finished worker discovery
23:25:17 WORKER: done with job (0, 0, 20), trying to register it.
23:25:17 WORKER: registered result for job (0, 0, 20) with dispatcher
23:25:17 DISPATCHER: job (0, 0, 20) finished
23:25:17 DISPATCHER: register_result: lock acquired
23:25:17 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
23:25:17 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 946, 'last_n_outputs': 25, 'leak_rate': 0.9919933820971001, 'lr': 0.0021711010683088464, 'optimizer': 'SGD', 'sparsity': 0.8721719116118354, 'steps_to_train': 99, 'weight_decay': 0.05376775918583}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.155716033094679, 'info': {'data04': 0.155716033094679, 'config': "{'batch_size': 32, 'hidden_dim': 946, 'last_n_outputs': 25, 'leak_rate': 0.9919933820971001, 'lr': 0.0021711010683088464, 'optimizer': 'SGD', 'sparsity': 0.8721719116118354, 'steps_to_train': 99, 'weight_decay': 0.05376775918583}"}}
exception: None

23:25:17 job_callback for (0, 0, 20) started
23:25:17 DISPATCHER: Trying to submit another job.
23:25:17 job_callback for (0, 0, 20) got condition
23:25:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:25:17 Only 6 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
23:25:17 HBMASTER: Trying to run another job!
23:25:17 job_callback for (0, 0, 20) finished
23:25:17 HBMASTER: schedule new run for iteration 0
23:25:17 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
23:25:17 HBMASTER: submitting job (0, 0, 22) to dispatcher
23:25:17 DISPATCHER: trying to submit job (0, 0, 22)
23:25:17 DISPATCHER: trying to notify the job_runner thread.
23:25:17 HBMASTER: job (0, 0, 22) submitted to dispatcher
23:25:17 DISPATCHER: Trying to submit another job.
23:25:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:25:17 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:25:17 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:25:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:25:17 WORKER: start processing job (0, 0, 22)
23:25:17 WORKER: args: ()
23:25:17 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 865, 'last_n_outputs': 36, 'leak_rate': 0.9687648407267304, 'lr': 0.009035159518451626, 'optimizer': 'SGD', 'sparsity': 0.8528240974541672, 'steps_to_train': 89, 'weight_decay': 0.041745044338311235}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:25:22 DISPATCHER: Starting worker discovery
23:25:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:25:22 DISPATCHER: Finished worker discovery
23:26:22 DISPATCHER: Starting worker discovery
23:26:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:26:22 DISPATCHER: Finished worker discovery
23:27:22 DISPATCHER: Starting worker discovery
23:27:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:27:22 DISPATCHER: Finished worker discovery
23:27:49 WORKER: done with job (0, 0, 22), trying to register it.
23:27:49 WORKER: registered result for job (0, 0, 22) with dispatcher
23:27:49 DISPATCHER: job (0, 0, 22) finished
23:27:49 DISPATCHER: register_result: lock acquired
23:27:49 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
23:27:49 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 865, 'last_n_outputs': 36, 'leak_rate': 0.9687648407267304, 'lr': 0.009035159518451626, 'optimizer': 'SGD', 'sparsity': 0.8528240974541672, 'steps_to_train': 89, 'weight_decay': 0.041745044338311235}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.18609483830650908, 'info': {'data04': 0.18609483830650908, 'config': "{'batch_size': 16, 'hidden_dim': 865, 'last_n_outputs': 36, 'leak_rate': 0.9687648407267304, 'lr': 0.009035159518451626, 'optimizer': 'SGD', 'sparsity': 0.8528240974541672, 'steps_to_train': 89, 'weight_decay': 0.041745044338311235}"}}
exception: None

23:27:49 job_callback for (0, 0, 22) started
23:27:49 DISPATCHER: Trying to submit another job.
23:27:49 job_callback for (0, 0, 22) got condition
23:27:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:27:49 Only 7 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
23:27:49 HBMASTER: Trying to run another job!
23:27:49 job_callback for (0, 0, 22) finished
23:27:49 HBMASTER: schedule new run for iteration 0
23:27:49 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
23:27:49 HBMASTER: submitting job (0, 0, 24) to dispatcher
23:27:49 DISPATCHER: trying to submit job (0, 0, 24)
23:27:49 DISPATCHER: trying to notify the job_runner thread.
23:27:49 HBMASTER: job (0, 0, 24) submitted to dispatcher
23:27:49 DISPATCHER: Trying to submit another job.
23:27:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:27:49 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:27:49 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:27:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:27:49 WORKER: start processing job (0, 0, 24)
23:27:49 WORKER: args: ()
23:27:49 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 433, 'last_n_outputs': 14, 'leak_rate': 0.7931723886393074, 'lr': 0.03331074817510489, 'optimizer': 'SGD', 'sparsity': 0.8958712195490861, 'steps_to_train': 44, 'weight_decay': 0.015817764402572224}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:28:22 DISPATCHER: Starting worker discovery
23:28:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:28:22 DISPATCHER: Finished worker discovery
23:29:22 DISPATCHER: Starting worker discovery
23:29:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:29:22 DISPATCHER: Finished worker discovery
23:30:22 WORKER: done with job (0, 0, 24), trying to register it.
23:30:22 WORKER: registered result for job (0, 0, 24) with dispatcher
23:30:22 DISPATCHER: job (0, 0, 24) finished
23:30:22 DISPATCHER: register_result: lock acquired
23:30:22 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
23:30:22 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 433, 'last_n_outputs': 14, 'leak_rate': 0.7931723886393074, 'lr': 0.03331074817510489, 'optimizer': 'SGD', 'sparsity': 0.8958712195490861, 'steps_to_train': 44, 'weight_decay': 0.015817764402572224}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.15405680348569342, 'info': {'data04': 0.15405680348569342, 'config': "{'batch_size': 128, 'hidden_dim': 433, 'last_n_outputs': 14, 'leak_rate': 0.7931723886393074, 'lr': 0.03331074817510489, 'optimizer': 'SGD', 'sparsity': 0.8958712195490861, 'steps_to_train': 44, 'weight_decay': 0.015817764402572224}"}}
exception: None

23:30:22 job_callback for (0, 0, 24) started
23:30:22 job_callback for (0, 0, 24) got condition
23:30:22 DISPATCHER: Trying to submit another job.
23:30:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:30:22 Only 8 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
23:30:22 HBMASTER: Trying to run another job!
23:30:22 job_callback for (0, 0, 24) finished
23:30:22 HBMASTER: schedule new run for iteration 0
23:30:22 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
23:30:22 HBMASTER: submitting job (0, 0, 25) to dispatcher
23:30:22 DISPATCHER: trying to submit job (0, 0, 25)
23:30:22 DISPATCHER: trying to notify the job_runner thread.
23:30:22 HBMASTER: job (0, 0, 25) submitted to dispatcher
23:30:22 DISPATCHER: Trying to submit another job.
23:30:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:30:22 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:30:22 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:30:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:30:22 WORKER: start processing job (0, 0, 25)
23:30:22 WORKER: args: ()
23:30:22 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 741, 'last_n_outputs': 25, 'leak_rate': 0.9631450040390819, 'lr': 0.04578810976594836, 'optimizer': 'SGD', 'sparsity': 0.9506360914227225, 'steps_to_train': 95, 'weight_decay': 0.12444819630964146}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:30:22 DISPATCHER: Starting worker discovery
23:30:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:30:22 DISPATCHER: Finished worker discovery
23:31:22 DISPATCHER: Starting worker discovery
23:31:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:31:22 DISPATCHER: Finished worker discovery
23:32:22 DISPATCHER: Starting worker discovery
23:32:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:32:22 DISPATCHER: Finished worker discovery
23:32:53 WORKER: done with job (0, 0, 25), trying to register it.
23:32:53 WORKER: registered result for job (0, 0, 25) with dispatcher
23:32:53 DISPATCHER: job (0, 0, 25) finished
23:32:53 DISPATCHER: register_result: lock acquired
23:32:53 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
23:32:53 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 741, 'last_n_outputs': 25, 'leak_rate': 0.9631450040390819, 'lr': 0.04578810976594836, 'optimizer': 'SGD', 'sparsity': 0.9506360914227225, 'steps_to_train': 95, 'weight_decay': 0.12444819630964146}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.15295755658409832, 'info': {'data04': 0.15295755658409832, 'config': "{'batch_size': 128, 'hidden_dim': 741, 'last_n_outputs': 25, 'leak_rate': 0.9631450040390819, 'lr': 0.04578810976594836, 'optimizer': 'SGD', 'sparsity': 0.9506360914227225, 'steps_to_train': 95, 'weight_decay': 0.12444819630964146}"}}
exception: None

23:32:53 job_callback for (0, 0, 25) started
23:32:53 job_callback for (0, 0, 25) got condition
23:32:53 DISPATCHER: Trying to submit another job.
23:32:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:32:53 Only 9 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
23:32:53 HBMASTER: Trying to run another job!
23:32:53 job_callback for (0, 0, 25) finished
23:32:53 ITERATION: Advancing config (0, 0, 7) to next budget 400.000000
23:32:53 ITERATION: Advancing config (0, 0, 10) to next budget 400.000000
23:32:53 ITERATION: Advancing config (0, 0, 22) to next budget 400.000000
23:32:53 HBMASTER: schedule new run for iteration 0
23:32:53 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
23:32:53 HBMASTER: submitting job (0, 0, 7) to dispatcher
23:32:53 DISPATCHER: trying to submit job (0, 0, 7)
23:32:53 DISPATCHER: trying to notify the job_runner thread.
23:32:53 HBMASTER: job (0, 0, 7) submitted to dispatcher
23:32:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:32:53 DISPATCHER: Trying to submit another job.
23:32:53 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:32:53 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:32:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:32:53 WORKER: start processing job (0, 0, 7)
23:32:53 WORKER: args: ()
23:32:53 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 867, 'last_n_outputs': 35, 'leak_rate': 0.9013515152456588, 'lr': 0.010939551424379268, 'optimizer': 'SGD', 'sparsity': 0.8128063031560117, 'steps_to_train': 67, 'weight_decay': 0.010868052347680388}, 'budget': 400.0, 'working_directory': '.'}
23:33:22 DISPATCHER: Starting worker discovery
23:33:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:33:22 DISPATCHER: Finished worker discovery
23:34:22 DISPATCHER: Starting worker discovery
23:34:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:34:22 DISPATCHER: Finished worker discovery
23:35:22 DISPATCHER: Starting worker discovery
23:35:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:35:22 DISPATCHER: Finished worker discovery
23:36:22 DISPATCHER: Starting worker discovery
23:36:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:36:22 DISPATCHER: Finished worker discovery
23:37:22 DISPATCHER: Starting worker discovery
23:37:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:37:22 DISPATCHER: Finished worker discovery
23:38:22 DISPATCHER: Starting worker discovery
23:38:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:38:22 DISPATCHER: Finished worker discovery
23:39:22 DISPATCHER: Starting worker discovery
23:39:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:39:22 DISPATCHER: Finished worker discovery
23:39:58 WORKER: done with job (0, 0, 7), trying to register it.
23:39:58 WORKER: registered result for job (0, 0, 7) with dispatcher
23:39:58 DISPATCHER: job (0, 0, 7) finished
23:39:58 DISPATCHER: register_result: lock acquired
23:39:58 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
23:39:58 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 867, 'last_n_outputs': 35, 'leak_rate': 0.9013515152456588, 'lr': 0.010939551424379268, 'optimizer': 'SGD', 'sparsity': 0.8128063031560117, 'steps_to_train': 67, 'weight_decay': 0.010868052347680388}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.17247909060195982, 'info': {'data04': 0.17247909060195982, 'config': "{'batch_size': 16, 'hidden_dim': 867, 'last_n_outputs': 35, 'leak_rate': 0.9013515152456588, 'lr': 0.010939551424379268, 'optimizer': 'SGD', 'sparsity': 0.8128063031560117, 'steps_to_train': 67, 'weight_decay': 0.010868052347680388}"}}
exception: None

23:39:58 job_callback for (0, 0, 7) started
23:39:58 job_callback for (0, 0, 7) got condition
23:39:58 DISPATCHER: Trying to submit another job.
23:39:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:39:58 Only 1 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
23:39:58 HBMASTER: Trying to run another job!
23:39:58 job_callback for (0, 0, 7) finished
23:39:58 HBMASTER: schedule new run for iteration 0
23:39:58 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
23:39:58 HBMASTER: submitting job (0, 0, 10) to dispatcher
23:39:58 DISPATCHER: trying to submit job (0, 0, 10)
23:39:58 DISPATCHER: trying to notify the job_runner thread.
23:39:58 HBMASTER: job (0, 0, 10) submitted to dispatcher
23:39:58 DISPATCHER: Trying to submit another job.
23:39:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:39:58 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:39:58 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:39:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:39:58 WORKER: start processing job (0, 0, 10)
23:39:58 WORKER: args: ()
23:39:58 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 935, 'last_n_outputs': 33, 'leak_rate': 0.9007701393318854, 'lr': 0.009259064102598231, 'optimizer': 'SGD', 'sparsity': 0.8643563073184608, 'steps_to_train': 75, 'weight_decay': 0.05316009720010779}, 'budget': 400.0, 'working_directory': '.'}
23:40:22 DISPATCHER: Starting worker discovery
23:40:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:40:22 DISPATCHER: Finished worker discovery
23:41:22 DISPATCHER: Starting worker discovery
23:41:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:41:22 DISPATCHER: Finished worker discovery
23:42:22 DISPATCHER: Starting worker discovery
23:42:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:42:22 DISPATCHER: Finished worker discovery
23:43:22 DISPATCHER: Starting worker discovery
23:43:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:43:22 DISPATCHER: Finished worker discovery
23:44:22 DISPATCHER: Starting worker discovery
23:44:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:44:22 DISPATCHER: Finished worker discovery
23:45:22 DISPATCHER: Starting worker discovery
23:45:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:45:22 DISPATCHER: Finished worker discovery
23:46:22 DISPATCHER: Starting worker discovery
23:46:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:46:22 DISPATCHER: Finished worker discovery
23:47:01 WORKER: done with job (0, 0, 10), trying to register it.
23:47:01 WORKER: registered result for job (0, 0, 10) with dispatcher
23:47:01 DISPATCHER: job (0, 0, 10) finished
23:47:01 DISPATCHER: register_result: lock acquired
23:47:01 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
23:47:01 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 935, 'last_n_outputs': 33, 'leak_rate': 0.9007701393318854, 'lr': 0.009259064102598231, 'optimizer': 'SGD', 'sparsity': 0.8643563073184608, 'steps_to_train': 75, 'weight_decay': 0.05316009720010779}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.1721525327658136, 'info': {'data04': 0.1721525327658136, 'config': "{'batch_size': 128, 'hidden_dim': 935, 'last_n_outputs': 33, 'leak_rate': 0.9007701393318854, 'lr': 0.009259064102598231, 'optimizer': 'SGD', 'sparsity': 0.8643563073184608, 'steps_to_train': 75, 'weight_decay': 0.05316009720010779}"}}
exception: None

23:47:01 job_callback for (0, 0, 10) started
23:47:01 DISPATCHER: Trying to submit another job.
23:47:01 job_callback for (0, 0, 10) got condition
23:47:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:47:01 Only 2 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
23:47:01 HBMASTER: Trying to run another job!
23:47:01 job_callback for (0, 0, 10) finished
23:47:01 HBMASTER: schedule new run for iteration 0
23:47:01 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
23:47:01 HBMASTER: submitting job (0, 0, 22) to dispatcher
23:47:01 DISPATCHER: trying to submit job (0, 0, 22)
23:47:01 DISPATCHER: trying to notify the job_runner thread.
23:47:01 HBMASTER: job (0, 0, 22) submitted to dispatcher
23:47:01 DISPATCHER: Trying to submit another job.
23:47:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:47:01 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:47:01 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:47:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:47:01 WORKER: start processing job (0, 0, 22)
23:47:01 WORKER: args: ()
23:47:01 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 865, 'last_n_outputs': 36, 'leak_rate': 0.9687648407267304, 'lr': 0.009035159518451626, 'optimizer': 'SGD', 'sparsity': 0.8528240974541672, 'steps_to_train': 89, 'weight_decay': 0.041745044338311235}, 'budget': 400.0, 'working_directory': '.'}
23:47:22 DISPATCHER: Starting worker discovery
23:47:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:47:22 DISPATCHER: Finished worker discovery
23:48:22 DISPATCHER: Starting worker discovery
23:48:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:48:22 DISPATCHER: Finished worker discovery
23:49:22 DISPATCHER: Starting worker discovery
23:49:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:49:22 DISPATCHER: Finished worker discovery
23:50:22 DISPATCHER: Starting worker discovery
23:50:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:50:22 DISPATCHER: Finished worker discovery
23:51:22 DISPATCHER: Starting worker discovery
23:51:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:51:22 DISPATCHER: Finished worker discovery
23:52:22 DISPATCHER: Starting worker discovery
23:52:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:52:22 DISPATCHER: Finished worker discovery
23:53:22 DISPATCHER: Starting worker discovery
23:53:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:53:22 DISPATCHER: Finished worker discovery
23:54:03 WORKER: done with job (0, 0, 22), trying to register it.
23:54:03 WORKER: registered result for job (0, 0, 22) with dispatcher
23:54:03 DISPATCHER: job (0, 0, 22) finished
23:54:03 DISPATCHER: register_result: lock acquired
23:54:03 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
23:54:03 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 865, 'last_n_outputs': 36, 'leak_rate': 0.9687648407267304, 'lr': 0.009035159518451626, 'optimizer': 'SGD', 'sparsity': 0.8528240974541672, 'steps_to_train': 89, 'weight_decay': 0.041745044338311235}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.1809756001848791, 'info': {'data04': 0.1809756001848791, 'config': "{'batch_size': 16, 'hidden_dim': 865, 'last_n_outputs': 36, 'leak_rate': 0.9687648407267304, 'lr': 0.009035159518451626, 'optimizer': 'SGD', 'sparsity': 0.8528240974541672, 'steps_to_train': 89, 'weight_decay': 0.041745044338311235}"}}
exception: None

23:54:03 job_callback for (0, 0, 22) started
23:54:03 DISPATCHER: Trying to submit another job.
23:54:03 job_callback for (0, 0, 22) got condition
23:54:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:54:03 Only 3 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
23:54:03 HBMASTER: Trying to run another job!
23:54:03 job_callback for (0, 0, 22) finished
23:54:03 ITERATION: Advancing config (0, 0, 22) to next budget 1200.000000
23:54:03 HBMASTER: schedule new run for iteration 0
23:54:03 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
23:54:03 HBMASTER: submitting job (0, 0, 22) to dispatcher
23:54:03 DISPATCHER: trying to submit job (0, 0, 22)
23:54:03 DISPATCHER: trying to notify the job_runner thread.
23:54:03 HBMASTER: job (0, 0, 22) submitted to dispatcher
23:54:03 DISPATCHER: Trying to submit another job.
23:54:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:54:03 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:54:03 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:54:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:54:03 WORKER: start processing job (0, 0, 22)
23:54:03 WORKER: args: ()
23:54:03 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 865, 'last_n_outputs': 36, 'leak_rate': 0.9687648407267304, 'lr': 0.009035159518451626, 'optimizer': 'SGD', 'sparsity': 0.8528240974541672, 'steps_to_train': 89, 'weight_decay': 0.041745044338311235}, 'budget': 1200.0, 'working_directory': '.'}
23:54:22 DISPATCHER: Starting worker discovery
23:54:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:54:22 DISPATCHER: Finished worker discovery
23:55:22 DISPATCHER: Starting worker discovery
23:55:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:55:22 DISPATCHER: Finished worker discovery
23:56:22 DISPATCHER: Starting worker discovery
23:56:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:56:22 DISPATCHER: Finished worker discovery
23:57:22 DISPATCHER: Starting worker discovery
23:57:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:57:22 DISPATCHER: Finished worker discovery
23:58:22 DISPATCHER: Starting worker discovery
23:58:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:58:22 DISPATCHER: Finished worker discovery
23:59:22 DISPATCHER: Starting worker discovery
23:59:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:59:22 DISPATCHER: Finished worker discovery
00:00:22 DISPATCHER: Starting worker discovery
00:00:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:00:22 DISPATCHER: Finished worker discovery
00:01:22 DISPATCHER: Starting worker discovery
00:01:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:01:22 DISPATCHER: Finished worker discovery
00:02:22 DISPATCHER: Starting worker discovery
00:02:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:02:22 DISPATCHER: Finished worker discovery
00:03:22 DISPATCHER: Starting worker discovery
00:03:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:03:22 DISPATCHER: Finished worker discovery
00:04:22 DISPATCHER: Starting worker discovery
00:04:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:04:22 DISPATCHER: Finished worker discovery
00:05:22 DISPATCHER: Starting worker discovery
00:05:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:05:22 DISPATCHER: Finished worker discovery
00:06:22 DISPATCHER: Starting worker discovery
00:06:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:06:22 DISPATCHER: Finished worker discovery
00:07:22 DISPATCHER: Starting worker discovery
00:07:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:07:22 DISPATCHER: Finished worker discovery
00:08:22 DISPATCHER: Starting worker discovery
00:08:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:08:22 DISPATCHER: Finished worker discovery
00:09:22 DISPATCHER: Starting worker discovery
00:09:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:09:22 DISPATCHER: Finished worker discovery
00:10:22 DISPATCHER: Starting worker discovery
00:10:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:10:22 DISPATCHER: Finished worker discovery
00:11:22 DISPATCHER: Starting worker discovery
00:11:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:11:22 DISPATCHER: Finished worker discovery
00:12:22 DISPATCHER: Starting worker discovery
00:12:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:12:22 DISPATCHER: Finished worker discovery
00:13:22 DISPATCHER: Starting worker discovery
00:13:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:13:22 DISPATCHER: Finished worker discovery
00:14:22 DISPATCHER: Starting worker discovery
00:14:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:14:23 DISPATCHER: Finished worker discovery
00:14:38 WORKER: done with job (0, 0, 22), trying to register it.
00:14:38 WORKER: registered result for job (0, 0, 22) with dispatcher
00:14:38 DISPATCHER: job (0, 0, 22) finished
00:14:38 DISPATCHER: register_result: lock acquired
00:14:38 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:14:38 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 865, 'last_n_outputs': 36, 'leak_rate': 0.9687648407267304, 'lr': 0.009035159518451626, 'optimizer': 'SGD', 'sparsity': 0.8528240974541672, 'steps_to_train': 89, 'weight_decay': 0.041745044338311235}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.17763375818200222, 'info': {'data04': 0.17763375818200222, 'config': "{'batch_size': 16, 'hidden_dim': 865, 'last_n_outputs': 36, 'leak_rate': 0.9687648407267304, 'lr': 0.009035159518451626, 'optimizer': 'SGD', 'sparsity': 0.8528240974541672, 'steps_to_train': 89, 'weight_decay': 0.041745044338311235}"}}
exception: None

00:14:38 job_callback for (0, 0, 22) started
00:14:38 DISPATCHER: Trying to submit another job.
00:14:38 job_callback for (0, 0, 22) got condition
00:14:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:14:38 Only 1 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
00:14:38 HBMASTER: Trying to run another job!
00:14:38 job_callback for (0, 0, 22) finished
00:14:38 start sampling a new configuration.
00:14:38 best_vector: [3, 0.6962844216600104, 0.20853719839576645, 0.2928213806445785, 0.5249114107136467, 1, 0.24420371765065713, 0.7988785316004519, 0.1454108147325237], 8.845858698692512e-32, 0.11304725002534892, -0.004130074674318908
00:14:38 done sampling a new configuration.
00:14:38 HBMASTER: schedule new run for iteration 1
00:14:38 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
00:14:38 HBMASTER: submitting job (1, 0, 0) to dispatcher
00:14:38 DISPATCHER: trying to submit job (1, 0, 0)
00:14:38 DISPATCHER: trying to notify the job_runner thread.
00:14:38 HBMASTER: job (1, 0, 0) submitted to dispatcher
00:14:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:14:38 DISPATCHER: Trying to submit another job.
00:14:38 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:14:38 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:14:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:14:38 WORKER: start processing job (1, 0, 0)
00:14:38 WORKER: args: ()
00:14:38 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 757, 'last_n_outputs': 18, 'leak_rate': 0.8232053451611446, 'lr': 0.011215607992073889, 'optimizer': 'SGD', 'sparsity': 0.8086088922361577, 'steps_to_train': 82, 'weight_decay': 0.015459086657180056}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:15:23 DISPATCHER: Starting worker discovery
00:15:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:15:23 DISPATCHER: Finished worker discovery
00:16:23 DISPATCHER: Starting worker discovery
00:16:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:16:23 DISPATCHER: Finished worker discovery
00:17:09 WORKER: done with job (1, 0, 0), trying to register it.
00:17:09 WORKER: registered result for job (1, 0, 0) with dispatcher
00:17:09 DISPATCHER: job (1, 0, 0) finished
00:17:09 DISPATCHER: register_result: lock acquired
00:17:09 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:17:09 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 757, 'last_n_outputs': 18, 'leak_rate': 0.8232053451611446, 'lr': 0.011215607992073889, 'optimizer': 'SGD', 'sparsity': 0.8086088922361577, 'steps_to_train': 82, 'weight_decay': 0.015459086657180056}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1529466796693172, 'info': {'data04': 0.1529466796693172, 'config': "{'batch_size': 128, 'hidden_dim': 757, 'last_n_outputs': 18, 'leak_rate': 0.8232053451611446, 'lr': 0.011215607992073889, 'optimizer': 'SGD', 'sparsity': 0.8086088922361577, 'steps_to_train': 82, 'weight_decay': 0.015459086657180056}"}}
exception: None

00:17:09 job_callback for (1, 0, 0) started
00:17:09 job_callback for (1, 0, 0) got condition
00:17:09 DISPATCHER: Trying to submit another job.
00:17:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:17:09 HBMASTER: Trying to run another job!
00:17:09 job_callback for (1, 0, 0) finished
00:17:09 start sampling a new configuration.
00:17:09 done sampling a new configuration.
00:17:09 HBMASTER: schedule new run for iteration 1
00:17:09 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
00:17:09 HBMASTER: submitting job (1, 0, 1) to dispatcher
00:17:09 DISPATCHER: trying to submit job (1, 0, 1)
00:17:09 DISPATCHER: trying to notify the job_runner thread.
00:17:09 HBMASTER: job (1, 0, 1) submitted to dispatcher
00:17:09 DISPATCHER: Trying to submit another job.
00:17:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:17:09 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:17:09 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:17:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:17:09 WORKER: start processing job (1, 0, 1)
00:17:09 WORKER: args: ()
00:17:09 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 608, 'last_n_outputs': 13, 'leak_rate': 0.9925694428345939, 'lr': 0.001528161374269637, 'optimizer': 'SGD', 'sparsity': 0.7792554592606525, 'steps_to_train': 70, 'weight_decay': 0.011493544445543657}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:17:23 DISPATCHER: Starting worker discovery
00:17:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:17:23 DISPATCHER: Finished worker discovery
00:18:23 DISPATCHER: Starting worker discovery
00:18:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:18:23 DISPATCHER: Finished worker discovery
00:19:23 DISPATCHER: Starting worker discovery
00:19:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:19:23 DISPATCHER: Finished worker discovery
00:19:42 WORKER: done with job (1, 0, 1), trying to register it.
00:19:42 WORKER: registered result for job (1, 0, 1) with dispatcher
00:19:42 DISPATCHER: job (1, 0, 1) finished
00:19:42 DISPATCHER: register_result: lock acquired
00:19:42 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:19:42 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 608, 'last_n_outputs': 13, 'leak_rate': 0.9925694428345939, 'lr': 0.001528161374269637, 'optimizer': 'SGD', 'sparsity': 0.7792554592606525, 'steps_to_train': 70, 'weight_decay': 0.011493544445543657}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1296926906189998, 'info': {'data04': 0.1296926906189998, 'config': "{'batch_size': 16, 'hidden_dim': 608, 'last_n_outputs': 13, 'leak_rate': 0.9925694428345939, 'lr': 0.001528161374269637, 'optimizer': 'SGD', 'sparsity': 0.7792554592606525, 'steps_to_train': 70, 'weight_decay': 0.011493544445543657}"}}
exception: None

00:19:42 job_callback for (1, 0, 1) started
00:19:42 DISPATCHER: Trying to submit another job.
00:19:42 job_callback for (1, 0, 1) got condition
00:19:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:19:42 HBMASTER: Trying to run another job!
00:19:42 job_callback for (1, 0, 1) finished
00:19:42 start sampling a new configuration.
00:19:42 done sampling a new configuration.
00:19:42 HBMASTER: schedule new run for iteration 1
00:19:42 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
00:19:42 HBMASTER: submitting job (1, 0, 2) to dispatcher
00:19:42 DISPATCHER: trying to submit job (1, 0, 2)
00:19:42 DISPATCHER: trying to notify the job_runner thread.
00:19:42 HBMASTER: job (1, 0, 2) submitted to dispatcher
00:19:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:19:42 DISPATCHER: Trying to submit another job.
00:19:42 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:19:42 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:19:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:19:42 WORKER: start processing job (1, 0, 2)
00:19:42 WORKER: args: ()
00:19:42 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 223, 'last_n_outputs': 11, 'leak_rate': 0.9103097218070508, 'lr': 0.013721246228657204, 'optimizer': 'SGD', 'sparsity': 0.7820928525766606, 'steps_to_train': 27, 'weight_decay': 0.042950930267859094}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:20:23 DISPATCHER: Starting worker discovery
00:20:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:20:23 DISPATCHER: Finished worker discovery
00:21:23 DISPATCHER: Starting worker discovery
00:21:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:21:23 DISPATCHER: Finished worker discovery
00:22:18 WORKER: done with job (1, 0, 2), trying to register it.
00:22:18 WORKER: registered result for job (1, 0, 2) with dispatcher
00:22:18 DISPATCHER: job (1, 0, 2) finished
00:22:18 DISPATCHER: register_result: lock acquired
00:22:18 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:22:18 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 223, 'last_n_outputs': 11, 'leak_rate': 0.9103097218070508, 'lr': 0.013721246228657204, 'optimizer': 'SGD', 'sparsity': 0.7820928525766606, 'steps_to_train': 27, 'weight_decay': 0.042950930267859094}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1412456475433846, 'info': {'data04': 0.1412456475433846, 'config': "{'batch_size': 64, 'hidden_dim': 223, 'last_n_outputs': 11, 'leak_rate': 0.9103097218070508, 'lr': 0.013721246228657204, 'optimizer': 'SGD', 'sparsity': 0.7820928525766606, 'steps_to_train': 27, 'weight_decay': 0.042950930267859094}"}}
exception: None

00:22:18 job_callback for (1, 0, 2) started
00:22:18 DISPATCHER: Trying to submit another job.
00:22:18 job_callback for (1, 0, 2) got condition
00:22:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:22:18 HBMASTER: Trying to run another job!
00:22:18 job_callback for (1, 0, 2) finished
00:22:18 start sampling a new configuration.
00:22:18 best_vector: [3, 0.6480728747355355, 0.9138488313668418, 0.9653969764214604, 0.5503154617790857, 1, 0.5830900733947999, 0.9022373422919602, 0.6224729307084592], 1.1701589136002565e-32, 0.8545847819278457, -0.0031838225287061056
00:22:18 done sampling a new configuration.
00:22:18 HBMASTER: schedule new run for iteration 1
00:22:18 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
00:22:18 HBMASTER: submitting job (1, 0, 3) to dispatcher
00:22:18 DISPATCHER: trying to submit job (1, 0, 3)
00:22:18 DISPATCHER: trying to notify the job_runner thread.
00:22:18 HBMASTER: job (1, 0, 3) submitted to dispatcher
00:22:18 DISPATCHER: Trying to submit another job.
00:22:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:22:18 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:22:18 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:22:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:22:18 WORKER: start processing job (1, 0, 3)
00:22:18 WORKER: args: ()
00:22:18 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 719, 'last_n_outputs': 47, 'leak_rate': 0.9913492441053651, 'lr': 0.012607556513303043, 'optimizer': 'SGD', 'sparsity': 0.889941617614752, 'steps_to_train': 92, 'weight_decay': 0.06454401156365973}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:22:23 DISPATCHER: Starting worker discovery
00:22:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:22:23 DISPATCHER: Finished worker discovery
00:23:23 DISPATCHER: Starting worker discovery
00:23:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:23:23 DISPATCHER: Finished worker discovery
00:24:23 DISPATCHER: Starting worker discovery
00:24:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:24:23 DISPATCHER: Finished worker discovery
00:24:52 WORKER: done with job (1, 0, 3), trying to register it.
00:24:52 WORKER: registered result for job (1, 0, 3) with dispatcher
00:24:52 DISPATCHER: job (1, 0, 3) finished
00:24:52 DISPATCHER: register_result: lock acquired
00:24:52 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:24:52 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 719, 'last_n_outputs': 47, 'leak_rate': 0.9913492441053651, 'lr': 0.012607556513303043, 'optimizer': 'SGD', 'sparsity': 0.889941617614752, 'steps_to_train': 92, 'weight_decay': 0.06454401156365973}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.16630056788637682, 'info': {'data04': 0.16630056788637682, 'config': "{'batch_size': 128, 'hidden_dim': 719, 'last_n_outputs': 47, 'leak_rate': 0.9913492441053651, 'lr': 0.012607556513303043, 'optimizer': 'SGD', 'sparsity': 0.889941617614752, 'steps_to_train': 92, 'weight_decay': 0.06454401156365973}"}}
exception: None

00:24:52 job_callback for (1, 0, 3) started
00:24:52 job_callback for (1, 0, 3) got condition
00:24:52 DISPATCHER: Trying to submit another job.
00:24:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:24:52 HBMASTER: Trying to run another job!
00:24:52 job_callback for (1, 0, 3) finished
00:24:52 start sampling a new configuration.
00:24:52 best_vector: [3, 0.4844660396387166, 0.944903498036471, 0.8932588870560043, 0.5624319271250415, 1, 0.9355208236907788, 0.8897137805185862, 0.4514426701083571], 8.218659880982773e-32, 0.12167433796766655, -0.006961695466349509
00:24:52 done sampling a new configuration.
00:24:52 HBMASTER: schedule new run for iteration 1
00:24:52 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
00:24:52 HBMASTER: submitting job (1, 0, 4) to dispatcher
00:24:52 DISPATCHER: trying to submit job (1, 0, 4)
00:24:52 DISPATCHER: trying to notify the job_runner thread.
00:24:52 HBMASTER: job (1, 0, 4) submitted to dispatcher
00:24:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:24:52 DISPATCHER: Trying to submit another job.
00:24:52 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:24:52 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:24:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:24:52 WORKER: start processing job (1, 0, 4)
00:24:52 WORKER: args: ()
00:24:52 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 588, 'last_n_outputs': 48, 'leak_rate': 0.973314721764001, 'lr': 0.013331034558163115, 'optimizer': 'SGD', 'sparsity': 0.9745249976857869, 'steps_to_train': 90, 'weight_decay': 0.038666997927691946}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:25:23 DISPATCHER: Starting worker discovery
00:25:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:25:23 DISPATCHER: Finished worker discovery
00:26:23 DISPATCHER: Starting worker discovery
00:26:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:26:23 DISPATCHER: Finished worker discovery
00:27:23 DISPATCHER: Starting worker discovery
00:27:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:27:23 DISPATCHER: Finished worker discovery
00:27:25 WORKER: done with job (1, 0, 4), trying to register it.
00:27:25 WORKER: registered result for job (1, 0, 4) with dispatcher
00:27:25 DISPATCHER: job (1, 0, 4) finished
00:27:25 DISPATCHER: register_result: lock acquired
00:27:25 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:27:25 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 588, 'last_n_outputs': 48, 'leak_rate': 0.973314721764001, 'lr': 0.013331034558163115, 'optimizer': 'SGD', 'sparsity': 0.9745249976857869, 'steps_to_train': 90, 'weight_decay': 0.038666997927691946}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.15865540685384935, 'info': {'data04': 0.15865540685384935, 'config': "{'batch_size': 128, 'hidden_dim': 588, 'last_n_outputs': 48, 'leak_rate': 0.973314721764001, 'lr': 0.013331034558163115, 'optimizer': 'SGD', 'sparsity': 0.9745249976857869, 'steps_to_train': 90, 'weight_decay': 0.038666997927691946}"}}
exception: None

00:27:25 job_callback for (1, 0, 4) started
00:27:25 job_callback for (1, 0, 4) got condition
00:27:25 DISPATCHER: Trying to submit another job.
00:27:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:27:25 HBMASTER: Trying to run another job!
00:27:25 job_callback for (1, 0, 4) finished
00:27:25 start sampling a new configuration.
00:27:25 best_vector: [3, 0.010637239498048845, 0.32552908748744225, 0.6027094077397165, 0.9305611896669498, 1, 0.7249408484354469, 0.7331673467349169, 0.01044190373229889], 2.1609702200013324e-32, 0.46275510451013224, -0.003225522178188362
00:27:25 done sampling a new configuration.
00:27:25 HBMASTER: schedule new run for iteration 1
00:27:25 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
00:27:25 HBMASTER: submitting job (1, 0, 5) to dispatcher
00:27:25 DISPATCHER: trying to submit job (1, 0, 5)
00:27:25 DISPATCHER: trying to notify the job_runner thread.
00:27:25 HBMASTER: job (1, 0, 5) submitted to dispatcher
00:27:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:27:25 DISPATCHER: Trying to submit another job.
00:27:25 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:27:25 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:27:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:27:25 WORKER: start processing job (1, 0, 5)
00:27:25 WORKER: args: ()
00:27:25 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 208, 'last_n_outputs': 23, 'leak_rate': 0.9006773519349291, 'lr': 0.07263105948142144, 'optimizer': 'SGD', 'sparsity': 0.9239858036245072, 'steps_to_train': 76, 'weight_decay': 0.010317755447517145}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:28:23 DISPATCHER: Starting worker discovery
00:28:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:28:23 DISPATCHER: Finished worker discovery
00:29:23 DISPATCHER: Starting worker discovery
00:29:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:29:23 DISPATCHER: Finished worker discovery
00:29:57 WORKER: done with job (1, 0, 5), trying to register it.
00:29:57 WORKER: registered result for job (1, 0, 5) with dispatcher
00:29:57 DISPATCHER: job (1, 0, 5) finished
00:29:57 DISPATCHER: register_result: lock acquired
00:29:57 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:29:57 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 208, 'last_n_outputs': 23, 'leak_rate': 0.9006773519349291, 'lr': 0.07263105948142144, 'optimizer': 'SGD', 'sparsity': 0.9239858036245072, 'steps_to_train': 76, 'weight_decay': 0.010317755447517145}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1655277161687877, 'info': {'data04': 0.1655277161687877, 'config': "{'batch_size': 128, 'hidden_dim': 208, 'last_n_outputs': 23, 'leak_rate': 0.9006773519349291, 'lr': 0.07263105948142144, 'optimizer': 'SGD', 'sparsity': 0.9239858036245072, 'steps_to_train': 76, 'weight_decay': 0.010317755447517145}"}}
exception: None

00:29:57 job_callback for (1, 0, 5) started
00:29:57 DISPATCHER: Trying to submit another job.
00:29:57 job_callback for (1, 0, 5) got condition
00:29:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:29:57 HBMASTER: Trying to run another job!
00:29:57 job_callback for (1, 0, 5) finished
00:29:57 start sampling a new configuration.
00:29:57 done sampling a new configuration.
00:29:57 HBMASTER: schedule new run for iteration 1
00:29:57 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
00:29:57 HBMASTER: submitting job (1, 0, 6) to dispatcher
00:29:57 DISPATCHER: trying to submit job (1, 0, 6)
00:29:57 DISPATCHER: trying to notify the job_runner thread.
00:29:57 HBMASTER: job (1, 0, 6) submitted to dispatcher
00:29:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:29:57 DISPATCHER: Trying to submit another job.
00:29:57 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:29:57 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:29:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:29:57 WORKER: start processing job (1, 0, 6)
00:29:57 WORKER: args: ()
00:29:57 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 313, 'last_n_outputs': 22, 'leak_rate': 0.8616186376219395, 'lr': 0.004815497677308255, 'optimizer': 'SGD', 'sparsity': 0.8608024974023478, 'steps_to_train': 15, 'weight_decay': 0.027820812490060003}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:30:23 DISPATCHER: Starting worker discovery
00:30:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:30:23 DISPATCHER: Finished worker discovery
00:31:23 DISPATCHER: Starting worker discovery
00:31:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:31:23 DISPATCHER: Finished worker discovery
00:32:23 DISPATCHER: Starting worker discovery
00:32:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:32:23 DISPATCHER: Finished worker discovery
00:32:36 WORKER: done with job (1, 0, 6), trying to register it.
00:32:36 WORKER: registered result for job (1, 0, 6) with dispatcher
00:32:36 DISPATCHER: job (1, 0, 6) finished
00:32:36 DISPATCHER: register_result: lock acquired
00:32:36 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:32:36 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 313, 'last_n_outputs': 22, 'leak_rate': 0.8616186376219395, 'lr': 0.004815497677308255, 'optimizer': 'SGD', 'sparsity': 0.8608024974023478, 'steps_to_train': 15, 'weight_decay': 0.027820812490060003}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.16156659012536276, 'info': {'data04': 0.16156659012536276, 'config': "{'batch_size': 32, 'hidden_dim': 313, 'last_n_outputs': 22, 'leak_rate': 0.8616186376219395, 'lr': 0.004815497677308255, 'optimizer': 'SGD', 'sparsity': 0.8608024974023478, 'steps_to_train': 15, 'weight_decay': 0.027820812490060003}"}}
exception: None

00:32:36 job_callback for (1, 0, 6) started
00:32:36 job_callback for (1, 0, 6) got condition
00:32:36 DISPATCHER: Trying to submit another job.
00:32:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:32:36 HBMASTER: Trying to run another job!
00:32:36 job_callback for (1, 0, 6) finished
00:32:36 start sampling a new configuration.
00:32:36 best_vector: [3, 0.04994391527548914, 0.9206829982447332, 0.9127706591882528, 0.6009999524148883, 1, 0.7808259114116638, 0.48610199137258525, 0.883751172424971], 3.0788493564287304e-31, 0.032479666402384054, -0.0019519681847363862
00:32:36 done sampling a new configuration.
00:32:36 HBMASTER: schedule new run for iteration 1
00:32:36 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
00:32:36 HBMASTER: submitting job (1, 0, 7) to dispatcher
00:32:36 DISPATCHER: trying to submit job (1, 0, 7)
00:32:36 DISPATCHER: trying to notify the job_runner thread.
00:32:36 HBMASTER: job (1, 0, 7) submitted to dispatcher
00:32:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:32:36 DISPATCHER: Trying to submit another job.
00:32:36 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:32:36 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:32:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:32:36 WORKER: start processing job (1, 0, 7)
00:32:36 WORKER: args: ()
00:32:36 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 240, 'last_n_outputs': 47, 'leak_rate': 0.9781926647970632, 'lr': 0.01592208378138509, 'optimizer': 'SGD', 'sparsity': 0.9373982187387992, 'steps_to_train': 54, 'weight_decay': 0.14118442324594416}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:33:23 DISPATCHER: Starting worker discovery
00:33:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:33:23 DISPATCHER: Finished worker discovery
00:34:23 DISPATCHER: Starting worker discovery
00:34:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:34:23 DISPATCHER: Finished worker discovery
00:35:08 WORKER: done with job (1, 0, 7), trying to register it.
00:35:08 WORKER: registered result for job (1, 0, 7) with dispatcher
00:35:08 DISPATCHER: job (1, 0, 7) finished
00:35:08 DISPATCHER: register_result: lock acquired
00:35:08 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:35:08 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 240, 'last_n_outputs': 47, 'leak_rate': 0.9781926647970632, 'lr': 0.01592208378138509, 'optimizer': 'SGD', 'sparsity': 0.9373982187387992, 'steps_to_train': 54, 'weight_decay': 0.14118442324594416}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.16128286674846018, 'info': {'data04': 0.16128286674846018, 'config': "{'batch_size': 128, 'hidden_dim': 240, 'last_n_outputs': 47, 'leak_rate': 0.9781926647970632, 'lr': 0.01592208378138509, 'optimizer': 'SGD', 'sparsity': 0.9373982187387992, 'steps_to_train': 54, 'weight_decay': 0.14118442324594416}"}}
exception: None

00:35:08 job_callback for (1, 0, 7) started
00:35:08 DISPATCHER: Trying to submit another job.
00:35:08 job_callback for (1, 0, 7) got condition
00:35:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:35:08 HBMASTER: Trying to run another job!
00:35:08 job_callback for (1, 0, 7) finished
00:35:08 start sampling a new configuration.
00:35:08 done sampling a new configuration.
00:35:08 HBMASTER: schedule new run for iteration 1
00:35:08 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
00:35:08 HBMASTER: submitting job (1, 0, 8) to dispatcher
00:35:08 DISPATCHER: trying to submit job (1, 0, 8)
00:35:08 DISPATCHER: trying to notify the job_runner thread.
00:35:08 HBMASTER: job (1, 0, 8) submitted to dispatcher
00:35:08 DISPATCHER: Trying to submit another job.
00:35:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:35:08 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:35:08 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:35:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:35:08 WORKER: start processing job (1, 0, 8)
00:35:08 WORKER: args: ()
00:35:08 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 809, 'last_n_outputs': 12, 'leak_rate': 0.8794325699388114, 'lr': 0.018113029193549145, 'optimizer': 'Adam', 'sparsity': 0.9377213695164779, 'steps_to_train': 30, 'weight_decay': 0.025573288026442022}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:35:23 DISPATCHER: Starting worker discovery
00:35:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:35:23 DISPATCHER: Finished worker discovery
00:36:23 DISPATCHER: Starting worker discovery
00:36:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:36:23 DISPATCHER: Finished worker discovery
00:37:23 DISPATCHER: Starting worker discovery
00:37:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:37:23 DISPATCHER: Finished worker discovery
00:37:43 WORKER: done with job (1, 0, 8), trying to register it.
00:37:43 WORKER: registered result for job (1, 0, 8) with dispatcher
00:37:43 DISPATCHER: job (1, 0, 8) finished
00:37:43 DISPATCHER: register_result: lock acquired
00:37:43 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:37:43 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 809, 'last_n_outputs': 12, 'leak_rate': 0.8794325699388114, 'lr': 0.018113029193549145, 'optimizer': 'Adam', 'sparsity': 0.9377213695164779, 'steps_to_train': 30, 'weight_decay': 0.025573288026442022}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.02551724230651782, 'info': {'data04': 0.02551724230651782, 'config': "{'batch_size': 16, 'hidden_dim': 809, 'last_n_outputs': 12, 'leak_rate': 0.8794325699388114, 'lr': 0.018113029193549145, 'optimizer': 'Adam', 'sparsity': 0.9377213695164779, 'steps_to_train': 30, 'weight_decay': 0.025573288026442022}"}}
exception: None

00:37:43 job_callback for (1, 0, 8) started
00:37:43 DISPATCHER: Trying to submit another job.
00:37:43 job_callback for (1, 0, 8) got condition
00:37:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:37:43 HBMASTER: Trying to run another job!
00:37:43 job_callback for (1, 0, 8) finished
00:37:43 ITERATION: Advancing config (1, 0, 3) to next budget 400.000000
00:37:43 ITERATION: Advancing config (1, 0, 5) to next budget 400.000000
00:37:43 ITERATION: Advancing config (1, 0, 6) to next budget 400.000000
00:37:43 HBMASTER: schedule new run for iteration 1
00:37:43 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
00:37:43 HBMASTER: submitting job (1, 0, 3) to dispatcher
00:37:43 DISPATCHER: trying to submit job (1, 0, 3)
00:37:43 DISPATCHER: trying to notify the job_runner thread.
00:37:43 HBMASTER: job (1, 0, 3) submitted to dispatcher
00:37:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:37:43 DISPATCHER: Trying to submit another job.
00:37:43 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:37:43 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:37:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:37:43 WORKER: start processing job (1, 0, 3)
00:37:43 WORKER: args: ()
00:37:43 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 719, 'last_n_outputs': 47, 'leak_rate': 0.9913492441053651, 'lr': 0.012607556513303043, 'optimizer': 'SGD', 'sparsity': 0.889941617614752, 'steps_to_train': 92, 'weight_decay': 0.06454401156365973}, 'budget': 400.0, 'working_directory': '.'}
00:38:23 DISPATCHER: Starting worker discovery
00:38:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:38:23 DISPATCHER: Finished worker discovery
00:39:23 DISPATCHER: Starting worker discovery
00:39:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:39:23 DISPATCHER: Finished worker discovery
00:40:23 DISPATCHER: Starting worker discovery
00:40:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:40:23 DISPATCHER: Finished worker discovery
00:41:23 DISPATCHER: Starting worker discovery
00:41:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:41:23 DISPATCHER: Finished worker discovery
00:42:23 DISPATCHER: Starting worker discovery
00:42:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:42:23 DISPATCHER: Finished worker discovery
00:43:23 DISPATCHER: Starting worker discovery
00:43:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:43:23 DISPATCHER: Finished worker discovery
00:44:23 DISPATCHER: Starting worker discovery
00:44:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:44:23 DISPATCHER: Finished worker discovery
00:44:45 WORKER: done with job (1, 0, 3), trying to register it.
00:44:45 WORKER: registered result for job (1, 0, 3) with dispatcher
00:44:45 DISPATCHER: job (1, 0, 3) finished
00:44:45 DISPATCHER: register_result: lock acquired
00:44:45 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:44:45 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 719, 'last_n_outputs': 47, 'leak_rate': 0.9913492441053651, 'lr': 0.012607556513303043, 'optimizer': 'SGD', 'sparsity': 0.889941617614752, 'steps_to_train': 92, 'weight_decay': 0.06454401156365973}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.17124183181749522, 'info': {'data04': 0.17124183181749522, 'config': "{'batch_size': 128, 'hidden_dim': 719, 'last_n_outputs': 47, 'leak_rate': 0.9913492441053651, 'lr': 0.012607556513303043, 'optimizer': 'SGD', 'sparsity': 0.889941617614752, 'steps_to_train': 92, 'weight_decay': 0.06454401156365973}"}}
exception: None

00:44:45 job_callback for (1, 0, 3) started
00:44:45 DISPATCHER: Trying to submit another job.
00:44:45 job_callback for (1, 0, 3) got condition
00:44:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:44:45 Only 4 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
00:44:45 HBMASTER: Trying to run another job!
00:44:45 job_callback for (1, 0, 3) finished
00:44:45 HBMASTER: schedule new run for iteration 1
00:44:45 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
00:44:45 HBMASTER: submitting job (1, 0, 5) to dispatcher
00:44:45 DISPATCHER: trying to submit job (1, 0, 5)
00:44:45 DISPATCHER: trying to notify the job_runner thread.
00:44:45 HBMASTER: job (1, 0, 5) submitted to dispatcher
00:44:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:44:45 DISPATCHER: Trying to submit another job.
00:44:45 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:44:45 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:44:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:44:45 WORKER: start processing job (1, 0, 5)
00:44:45 WORKER: args: ()
00:44:45 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 208, 'last_n_outputs': 23, 'leak_rate': 0.9006773519349291, 'lr': 0.07263105948142144, 'optimizer': 'SGD', 'sparsity': 0.9239858036245072, 'steps_to_train': 76, 'weight_decay': 0.010317755447517145}, 'budget': 400.0, 'working_directory': '.'}
00:45:23 DISPATCHER: Starting worker discovery
00:45:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:45:23 DISPATCHER: Finished worker discovery
00:46:23 DISPATCHER: Starting worker discovery
00:46:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:46:23 DISPATCHER: Finished worker discovery
00:47:23 DISPATCHER: Starting worker discovery
00:47:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:47:23 DISPATCHER: Finished worker discovery
00:48:23 DISPATCHER: Starting worker discovery
00:48:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:48:23 DISPATCHER: Finished worker discovery
00:49:23 DISPATCHER: Starting worker discovery
00:49:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:49:23 DISPATCHER: Finished worker discovery
00:50:23 DISPATCHER: Starting worker discovery
00:50:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:50:23 DISPATCHER: Finished worker discovery
00:51:23 DISPATCHER: Starting worker discovery
00:51:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:51:23 DISPATCHER: Finished worker discovery
00:51:48 WORKER: done with job (1, 0, 5), trying to register it.
00:51:48 WORKER: registered result for job (1, 0, 5) with dispatcher
00:51:48 DISPATCHER: job (1, 0, 5) finished
00:51:48 DISPATCHER: register_result: lock acquired
00:51:48 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:51:48 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 208, 'last_n_outputs': 23, 'leak_rate': 0.9006773519349291, 'lr': 0.07263105948142144, 'optimizer': 'SGD', 'sparsity': 0.9239858036245072, 'steps_to_train': 76, 'weight_decay': 0.010317755447517145}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.16214420712058292, 'info': {'data04': 0.16214420712058292, 'config': "{'batch_size': 128, 'hidden_dim': 208, 'last_n_outputs': 23, 'leak_rate': 0.9006773519349291, 'lr': 0.07263105948142144, 'optimizer': 'SGD', 'sparsity': 0.9239858036245072, 'steps_to_train': 76, 'weight_decay': 0.010317755447517145}"}}
exception: None

00:51:48 job_callback for (1, 0, 5) started
00:51:48 DISPATCHER: Trying to submit another job.
00:51:48 job_callback for (1, 0, 5) got condition
00:51:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:51:48 Only 5 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
00:51:48 HBMASTER: Trying to run another job!
00:51:48 job_callback for (1, 0, 5) finished
00:51:48 HBMASTER: schedule new run for iteration 1
00:51:48 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
00:51:48 HBMASTER: submitting job (1, 0, 6) to dispatcher
00:51:48 DISPATCHER: trying to submit job (1, 0, 6)
00:51:48 DISPATCHER: trying to notify the job_runner thread.
00:51:48 HBMASTER: job (1, 0, 6) submitted to dispatcher
00:51:48 DISPATCHER: Trying to submit another job.
00:51:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:51:48 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:51:48 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:51:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:51:48 WORKER: start processing job (1, 0, 6)
00:51:48 WORKER: args: ()
00:51:48 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 313, 'last_n_outputs': 22, 'leak_rate': 0.8616186376219395, 'lr': 0.004815497677308255, 'optimizer': 'SGD', 'sparsity': 0.8608024974023478, 'steps_to_train': 15, 'weight_decay': 0.027820812490060003}, 'budget': 400.0, 'working_directory': '.'}
00:52:23 DISPATCHER: Starting worker discovery
00:52:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:52:23 DISPATCHER: Finished worker discovery
00:53:23 DISPATCHER: Starting worker discovery
00:53:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:53:23 DISPATCHER: Finished worker discovery
00:54:23 DISPATCHER: Starting worker discovery
00:54:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:54:23 DISPATCHER: Finished worker discovery
00:55:23 DISPATCHER: Starting worker discovery
00:55:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:55:23 DISPATCHER: Finished worker discovery
00:56:23 DISPATCHER: Starting worker discovery
00:56:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:56:23 DISPATCHER: Finished worker discovery
00:57:23 DISPATCHER: Starting worker discovery
00:57:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:57:23 DISPATCHER: Finished worker discovery
00:58:23 DISPATCHER: Starting worker discovery
00:58:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:58:23 DISPATCHER: Finished worker discovery
00:59:15 WORKER: done with job (1, 0, 6), trying to register it.
00:59:15 WORKER: registered result for job (1, 0, 6) with dispatcher
00:59:15 DISPATCHER: job (1, 0, 6) finished
00:59:15 DISPATCHER: register_result: lock acquired
00:59:15 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:59:15 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 313, 'last_n_outputs': 22, 'leak_rate': 0.8616186376219395, 'lr': 0.004815497677308255, 'optimizer': 'SGD', 'sparsity': 0.8608024974023478, 'steps_to_train': 15, 'weight_decay': 0.027820812490060003}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.13601355843409793, 'info': {'data04': 0.13601355843409793, 'config': "{'batch_size': 32, 'hidden_dim': 313, 'last_n_outputs': 22, 'leak_rate': 0.8616186376219395, 'lr': 0.004815497677308255, 'optimizer': 'SGD', 'sparsity': 0.8608024974023478, 'steps_to_train': 15, 'weight_decay': 0.027820812490060003}"}}
exception: None

00:59:15 job_callback for (1, 0, 6) started
00:59:15 DISPATCHER: Trying to submit another job.
00:59:15 job_callback for (1, 0, 6) got condition
00:59:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:59:15 Only 6 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
00:59:15 HBMASTER: Trying to run another job!
00:59:15 job_callback for (1, 0, 6) finished
00:59:15 ITERATION: Advancing config (1, 0, 3) to next budget 1200.000000
00:59:15 HBMASTER: schedule new run for iteration 1
00:59:15 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
00:59:15 HBMASTER: submitting job (1, 0, 3) to dispatcher
00:59:15 DISPATCHER: trying to submit job (1, 0, 3)
00:59:15 DISPATCHER: trying to notify the job_runner thread.
00:59:15 HBMASTER: job (1, 0, 3) submitted to dispatcher
00:59:15 DISPATCHER: Trying to submit another job.
00:59:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:59:15 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:59:15 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:59:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:59:15 WORKER: start processing job (1, 0, 3)
00:59:15 WORKER: args: ()
00:59:15 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 719, 'last_n_outputs': 47, 'leak_rate': 0.9913492441053651, 'lr': 0.012607556513303043, 'optimizer': 'SGD', 'sparsity': 0.889941617614752, 'steps_to_train': 92, 'weight_decay': 0.06454401156365973}, 'budget': 1200.0, 'working_directory': '.'}
00:59:23 DISPATCHER: Starting worker discovery
00:59:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:59:23 DISPATCHER: Finished worker discovery
01:00:23 DISPATCHER: Starting worker discovery
01:00:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:00:23 DISPATCHER: Finished worker discovery
01:01:23 DISPATCHER: Starting worker discovery
01:01:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:01:23 DISPATCHER: Finished worker discovery
01:02:23 DISPATCHER: Starting worker discovery
01:02:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:02:23 DISPATCHER: Finished worker discovery
01:03:23 DISPATCHER: Starting worker discovery
01:03:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:03:23 DISPATCHER: Finished worker discovery
01:04:23 DISPATCHER: Starting worker discovery
01:04:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:04:23 DISPATCHER: Finished worker discovery
01:05:23 DISPATCHER: Starting worker discovery
01:05:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:05:23 DISPATCHER: Finished worker discovery
01:06:23 DISPATCHER: Starting worker discovery
01:06:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:06:23 DISPATCHER: Finished worker discovery
01:07:23 DISPATCHER: Starting worker discovery
01:07:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:07:23 DISPATCHER: Finished worker discovery
01:08:23 DISPATCHER: Starting worker discovery
01:08:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:08:23 DISPATCHER: Finished worker discovery
01:09:23 DISPATCHER: Starting worker discovery
01:09:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:09:23 DISPATCHER: Finished worker discovery
01:10:23 DISPATCHER: Starting worker discovery
01:10:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:10:23 DISPATCHER: Finished worker discovery
01:11:23 DISPATCHER: Starting worker discovery
01:11:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:11:23 DISPATCHER: Finished worker discovery
01:12:23 DISPATCHER: Starting worker discovery
01:12:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:12:23 DISPATCHER: Finished worker discovery
01:13:23 DISPATCHER: Starting worker discovery
01:13:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:13:23 DISPATCHER: Finished worker discovery
01:14:23 DISPATCHER: Starting worker discovery
01:14:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:14:23 DISPATCHER: Finished worker discovery
01:15:23 DISPATCHER: Starting worker discovery
01:15:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:15:23 DISPATCHER: Finished worker discovery
01:16:23 DISPATCHER: Starting worker discovery
01:16:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:16:23 DISPATCHER: Finished worker discovery
01:17:23 DISPATCHER: Starting worker discovery
01:17:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:17:23 DISPATCHER: Finished worker discovery
01:18:23 DISPATCHER: Starting worker discovery
01:18:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:18:23 DISPATCHER: Finished worker discovery
01:19:23 DISPATCHER: Starting worker discovery
01:19:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:19:23 DISPATCHER: Finished worker discovery
01:19:49 WORKER: done with job (1, 0, 3), trying to register it.
01:19:49 WORKER: registered result for job (1, 0, 3) with dispatcher
01:19:49 DISPATCHER: job (1, 0, 3) finished
01:19:49 DISPATCHER: register_result: lock acquired
01:19:49 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
01:19:49 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 719, 'last_n_outputs': 47, 'leak_rate': 0.9913492441053651, 'lr': 0.012607556513303043, 'optimizer': 'SGD', 'sparsity': 0.889941617614752, 'steps_to_train': 92, 'weight_decay': 0.06454401156365973}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.16514129772484742, 'info': {'data04': 0.16514129772484742, 'config': "{'batch_size': 128, 'hidden_dim': 719, 'last_n_outputs': 47, 'leak_rate': 0.9913492441053651, 'lr': 0.012607556513303043, 'optimizer': 'SGD', 'sparsity': 0.889941617614752, 'steps_to_train': 92, 'weight_decay': 0.06454401156365973}"}}
exception: None

01:19:49 job_callback for (1, 0, 3) started
01:19:49 job_callback for (1, 0, 3) got condition
01:19:49 DISPATCHER: Trying to submit another job.
01:19:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:19:49 Only 2 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
01:19:49 HBMASTER: Trying to run another job!
01:19:49 job_callback for (1, 0, 3) finished
01:19:49 start sampling a new configuration.
01:19:49 best_vector: [3, 0.4830953947438265, 0.873045143931281, 0.792042213464712, 0.8776107467814088, 1, 0.6583816095320891, 0.7340295122419029, 0.7218709834188308], 3.392135786376042e-32, 0.294799519528769, -0.0024396076154359837
01:19:49 done sampling a new configuration.
01:19:49 HBMASTER: schedule new run for iteration 2
01:19:49 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
01:19:49 HBMASTER: submitting job (2, 0, 0) to dispatcher
01:19:49 DISPATCHER: trying to submit job (2, 0, 0)
01:19:49 DISPATCHER: trying to notify the job_runner thread.
01:19:49 HBMASTER: job (2, 0, 0) submitted to dispatcher
01:19:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:19:49 DISPATCHER: Trying to submit another job.
01:19:49 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:19:49 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:19:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:19:49 WORKER: start processing job (2, 0, 0)
01:19:49 WORKER: args: ()
01:19:49 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 586, 'last_n_outputs': 45, 'leak_rate': 0.948010553366178, 'lr': 0.056914312425609556, 'optimizer': 'SGD', 'sparsity': 0.9080115862877014, 'steps_to_train': 76, 'weight_decay': 0.086931225571513}, 'budget': 400.0, 'working_directory': '.'}
01:20:23 DISPATCHER: Starting worker discovery
01:20:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:20:23 DISPATCHER: Finished worker discovery
01:21:23 DISPATCHER: Starting worker discovery
01:21:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:21:23 DISPATCHER: Finished worker discovery
01:22:23 DISPATCHER: Starting worker discovery
01:22:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:22:23 DISPATCHER: Finished worker discovery
01:23:23 DISPATCHER: Starting worker discovery
01:23:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:23:23 DISPATCHER: Finished worker discovery
01:24:23 DISPATCHER: Starting worker discovery
01:24:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:24:23 DISPATCHER: Finished worker discovery
01:25:23 DISPATCHER: Starting worker discovery
01:25:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:25:23 DISPATCHER: Finished worker discovery
01:26:23 DISPATCHER: Starting worker discovery
01:26:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:26:23 DISPATCHER: Finished worker discovery
01:26:53 WORKER: done with job (2, 0, 0), trying to register it.
01:26:53 WORKER: registered result for job (2, 0, 0) with dispatcher
01:26:53 DISPATCHER: job (2, 0, 0) finished
01:26:53 DISPATCHER: register_result: lock acquired
01:26:53 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
01:26:53 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 586, 'last_n_outputs': 45, 'leak_rate': 0.948010553366178, 'lr': 0.056914312425609556, 'optimizer': 'SGD', 'sparsity': 0.9080115862877014, 'steps_to_train': 76, 'weight_decay': 0.086931225571513}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.09832298825105516, 'info': {'data04': 0.09832298825105516, 'config': "{'batch_size': 128, 'hidden_dim': 586, 'last_n_outputs': 45, 'leak_rate': 0.948010553366178, 'lr': 0.056914312425609556, 'optimizer': 'SGD', 'sparsity': 0.9080115862877014, 'steps_to_train': 76, 'weight_decay': 0.086931225571513}"}}
exception: None

01:26:53 job_callback for (2, 0, 0) started
01:26:53 DISPATCHER: Trying to submit another job.
01:26:53 job_callback for (2, 0, 0) got condition
01:26:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:26:53 Only 7 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
01:26:53 HBMASTER: Trying to run another job!
01:26:53 job_callback for (2, 0, 0) finished
01:26:53 start sampling a new configuration.
01:26:53 best_vector: [3, 0.41999928937280573, 0.621225423170366, 0.34909844708503696, 0.40992239933455926, 1, 0.7991026394491323, 0.9512576523692629, 0.7608515469810346], 5.369561482870783e-32, 0.18623494733975185, -0.0002130701406828413
01:26:53 done sampling a new configuration.
01:26:53 HBMASTER: schedule new run for iteration 2
01:26:53 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
01:26:53 HBMASTER: submitting job (2, 0, 1) to dispatcher
01:26:53 DISPATCHER: trying to submit job (2, 0, 1)
01:26:53 DISPATCHER: trying to notify the job_runner thread.
01:26:53 HBMASTER: job (2, 0, 1) submitted to dispatcher
01:26:53 DISPATCHER: Trying to submit another job.
01:26:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:26:53 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:26:53 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:26:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:26:53 WORKER: start processing job (2, 0, 1)
01:26:53 WORKER: args: ()
01:26:53 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 536, 'last_n_outputs': 35, 'leak_rate': 0.8372746117712593, 'lr': 0.006604573819585582, 'optimizer': 'SGD', 'sparsity': 0.9417846334677917, 'steps_to_train': 96, 'weight_decay': 0.0976991274080585}, 'budget': 400.0, 'working_directory': '.'}
01:27:23 DISPATCHER: Starting worker discovery
01:27:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:27:23 DISPATCHER: Finished worker discovery
01:28:23 DISPATCHER: Starting worker discovery
01:28:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:28:23 DISPATCHER: Finished worker discovery
01:29:23 DISPATCHER: Starting worker discovery
01:29:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:29:23 DISPATCHER: Finished worker discovery
01:30:23 DISPATCHER: Starting worker discovery
01:30:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:30:23 DISPATCHER: Finished worker discovery
01:31:23 DISPATCHER: Starting worker discovery
01:31:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:31:23 DISPATCHER: Finished worker discovery
01:32:23 DISPATCHER: Starting worker discovery
01:32:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:32:23 DISPATCHER: Finished worker discovery
01:33:23 DISPATCHER: Starting worker discovery
01:33:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:33:23 DISPATCHER: Finished worker discovery
01:33:54 WORKER: done with job (2, 0, 1), trying to register it.
01:33:54 WORKER: registered result for job (2, 0, 1) with dispatcher
01:33:54 DISPATCHER: job (2, 0, 1) finished
01:33:54 DISPATCHER: register_result: lock acquired
01:33:54 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
01:33:54 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 536, 'last_n_outputs': 35, 'leak_rate': 0.8372746117712593, 'lr': 0.006604573819585582, 'optimizer': 'SGD', 'sparsity': 0.9417846334677917, 'steps_to_train': 96, 'weight_decay': 0.0976991274080585}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.18317286910788202, 'info': {'data04': 0.18317286910788202, 'config': "{'batch_size': 128, 'hidden_dim': 536, 'last_n_outputs': 35, 'leak_rate': 0.8372746117712593, 'lr': 0.006604573819585582, 'optimizer': 'SGD', 'sparsity': 0.9417846334677917, 'steps_to_train': 96, 'weight_decay': 0.0976991274080585}"}}
exception: None

01:33:54 DISPATCHER: Trying to submit another job.
01:33:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:33:54 job_callback for (2, 0, 1) started
01:33:54 job_callback for (2, 0, 1) got condition
01:33:54 Only 8 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
01:33:54 HBMASTER: Trying to run another job!
01:33:54 job_callback for (2, 0, 1) finished
01:33:54 start sampling a new configuration.
01:33:54 best_vector: [3, 0.09675761596312099, 0.7251146867522662, 0.7710736920123571, 0.7122901096210099, 1, 0.7274569167537144, 0.7344953002981737, 0.6770291449024874], 1.1997789121171578e-32, 0.8334868948774711, -0.00319257476281368
01:33:54 done sampling a new configuration.
01:33:54 HBMASTER: schedule new run for iteration 2
01:33:54 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
01:33:54 HBMASTER: submitting job (2, 0, 2) to dispatcher
01:33:54 DISPATCHER: trying to submit job (2, 0, 2)
01:33:54 DISPATCHER: trying to notify the job_runner thread.
01:33:54 HBMASTER: job (2, 0, 2) submitted to dispatcher
01:33:54 DISPATCHER: Trying to submit another job.
01:33:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:33:54 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:33:54 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:33:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:33:54 WORKER: start processing job (2, 0, 2)
01:33:54 WORKER: args: ()
01:33:54 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 277, 'last_n_outputs': 39, 'leak_rate': 0.9427684230030893, 'lr': 0.02658154496263179, 'optimizer': 'SGD', 'sparsity': 0.9245896600208914, 'steps_to_train': 76, 'weight_decay': 0.07600378582367498}, 'budget': 400.0, 'working_directory': '.'}
01:34:23 DISPATCHER: Starting worker discovery
01:34:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:34:23 DISPATCHER: Finished worker discovery
01:35:23 DISPATCHER: Starting worker discovery
01:35:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:35:23 DISPATCHER: Finished worker discovery
01:36:23 DISPATCHER: Starting worker discovery
01:36:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:36:23 DISPATCHER: Finished worker discovery
01:37:23 DISPATCHER: Starting worker discovery
01:37:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:37:23 DISPATCHER: Finished worker discovery
01:38:23 DISPATCHER: Starting worker discovery
01:38:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:38:23 DISPATCHER: Finished worker discovery
01:39:23 DISPATCHER: Starting worker discovery
01:39:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:39:23 DISPATCHER: Finished worker discovery
01:40:23 DISPATCHER: Starting worker discovery
01:40:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:40:23 DISPATCHER: Finished worker discovery
01:40:57 WORKER: done with job (2, 0, 2), trying to register it.
01:40:57 WORKER: registered result for job (2, 0, 2) with dispatcher
01:40:57 DISPATCHER: job (2, 0, 2) finished
01:40:57 DISPATCHER: register_result: lock acquired
01:40:57 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
01:40:57 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 277, 'last_n_outputs': 39, 'leak_rate': 0.9427684230030893, 'lr': 0.02658154496263179, 'optimizer': 'SGD', 'sparsity': 0.9245896600208914, 'steps_to_train': 76, 'weight_decay': 0.07600378582367498}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.1770834717174808, 'info': {'data04': 0.1770834717174808, 'config': "{'batch_size': 128, 'hidden_dim': 277, 'last_n_outputs': 39, 'leak_rate': 0.9427684230030893, 'lr': 0.02658154496263179, 'optimizer': 'SGD', 'sparsity': 0.9245896600208914, 'steps_to_train': 76, 'weight_decay': 0.07600378582367498}"}}
exception: None

01:40:57 job_callback for (2, 0, 2) started
01:40:57 DISPATCHER: Trying to submit another job.
01:40:57 job_callback for (2, 0, 2) got condition
01:40:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:40:57 Only 9 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
01:40:57 HBMASTER: Trying to run another job!
01:40:57 job_callback for (2, 0, 2) finished
01:40:57 start sampling a new configuration.
01:40:58 best_vector: [3, 0.10350555954135354, 0.8050805783885094, 0.054596383147638816, 0.23954866785971218, 1, 0.28586371532436594, 0.6078359122531332, 0.7277431055517782], 1.6334163586499025e-31, 0.06122137780146566, -0.003358156843331287
01:40:58 done sampling a new configuration.
01:40:58 HBMASTER: schedule new run for iteration 2
01:40:58 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
01:40:58 HBMASTER: submitting job (2, 0, 3) to dispatcher
01:40:58 DISPATCHER: trying to submit job (2, 0, 3)
01:40:58 DISPATCHER: trying to notify the job_runner thread.
01:40:58 HBMASTER: job (2, 0, 3) submitted to dispatcher
01:40:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:40:58 DISPATCHER: Trying to submit another job.
01:40:58 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:40:58 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:40:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:40:58 WORKER: start processing job (2, 0, 3)
01:40:58 WORKER: args: ()
01:40:58 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 282, 'last_n_outputs': 43, 'leak_rate': 0.7636490957869098, 'lr': 0.003013681386154579, 'optimizer': 'SGD', 'sparsity': 0.8186072916778478, 'steps_to_train': 65, 'weight_decay': 0.08847398917185584}, 'budget': 400.0, 'working_directory': '.'}
01:41:23 DISPATCHER: Starting worker discovery
01:41:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:41:23 DISPATCHER: Finished worker discovery
01:42:23 DISPATCHER: Starting worker discovery
01:42:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:42:23 DISPATCHER: Finished worker discovery
01:43:23 DISPATCHER: Starting worker discovery
01:43:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:43:23 DISPATCHER: Finished worker discovery
01:44:23 DISPATCHER: Starting worker discovery
01:44:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:44:23 DISPATCHER: Finished worker discovery
01:45:23 DISPATCHER: Starting worker discovery
01:45:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:45:23 DISPATCHER: Finished worker discovery
01:46:23 DISPATCHER: Starting worker discovery
01:46:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:46:23 DISPATCHER: Finished worker discovery
01:47:23 DISPATCHER: Starting worker discovery
01:47:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:47:23 DISPATCHER: Finished worker discovery
01:48:02 WORKER: done with job (2, 0, 3), trying to register it.
01:48:02 WORKER: registered result for job (2, 0, 3) with dispatcher
01:48:02 DISPATCHER: job (2, 0, 3) finished
01:48:02 DISPATCHER: register_result: lock acquired
01:48:02 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
01:48:02 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 282, 'last_n_outputs': 43, 'leak_rate': 0.7636490957869098, 'lr': 0.003013681386154579, 'optimizer': 'SGD', 'sparsity': 0.8186072916778478, 'steps_to_train': 65, 'weight_decay': 0.08847398917185584}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.17458458886399103, 'info': {'data04': 0.17458458886399103, 'config': "{'batch_size': 128, 'hidden_dim': 282, 'last_n_outputs': 43, 'leak_rate': 0.7636490957869098, 'lr': 0.003013681386154579, 'optimizer': 'SGD', 'sparsity': 0.8186072916778478, 'steps_to_train': 65, 'weight_decay': 0.08847398917185584}"}}
exception: None

01:48:02 job_callback for (2, 0, 3) started
01:48:02 job_callback for (2, 0, 3) got condition
01:48:02 DISPATCHER: Trying to submit another job.
01:48:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:48:02 HBMASTER: Trying to run another job!
01:48:02 job_callback for (2, 0, 3) finished
01:48:02 start sampling a new configuration.
01:48:02 best_vector: [3, 0.16475285099254364, 0.46165849701713707, 0.22669614249589765, 0.6847378116747376, 1, 0.6159815808960359, 0.900284156405864, 0.8507775392379182], 7.089764668173768e-32, 0.14104840524383544, -0.00012522375914292408
01:48:02 done sampling a new configuration.
01:48:02 HBMASTER: schedule new run for iteration 2
01:48:02 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
01:48:02 HBMASTER: submitting job (2, 0, 4) to dispatcher
01:48:02 DISPATCHER: trying to submit job (2, 0, 4)
01:48:02 DISPATCHER: trying to notify the job_runner thread.
01:48:02 HBMASTER: job (2, 0, 4) submitted to dispatcher
01:48:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:48:02 DISPATCHER: Trying to submit another job.
01:48:02 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:48:02 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:48:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:48:02 WORKER: start processing job (2, 0, 4)
01:48:02 WORKER: args: ()
01:48:02 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 331, 'last_n_outputs': 28, 'leak_rate': 0.8066740356239744, 'lr': 0.023414000503067352, 'optimizer': 'SGD', 'sparsity': 0.8978355794150487, 'steps_to_train': 91, 'weight_decay': 0.12790487517012752}, 'budget': 400.0, 'working_directory': '.'}
01:48:23 DISPATCHER: Starting worker discovery
01:48:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:48:23 DISPATCHER: Finished worker discovery
01:49:23 DISPATCHER: Starting worker discovery
01:49:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:49:23 DISPATCHER: Finished worker discovery
01:50:23 DISPATCHER: Starting worker discovery
01:50:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:50:23 DISPATCHER: Finished worker discovery
01:51:23 DISPATCHER: Starting worker discovery
01:51:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:51:23 DISPATCHER: Finished worker discovery
01:52:23 DISPATCHER: Starting worker discovery
01:52:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:52:23 DISPATCHER: Finished worker discovery
01:53:23 DISPATCHER: Starting worker discovery
01:53:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:53:23 DISPATCHER: Finished worker discovery
01:54:23 DISPATCHER: Starting worker discovery
01:54:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:54:23 DISPATCHER: Finished worker discovery
01:55:03 WORKER: done with job (2, 0, 4), trying to register it.
01:55:03 WORKER: registered result for job (2, 0, 4) with dispatcher
01:55:03 DISPATCHER: job (2, 0, 4) finished
01:55:03 DISPATCHER: register_result: lock acquired
01:55:03 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
01:55:03 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 331, 'last_n_outputs': 28, 'leak_rate': 0.8066740356239744, 'lr': 0.023414000503067352, 'optimizer': 'SGD', 'sparsity': 0.8978355794150487, 'steps_to_train': 91, 'weight_decay': 0.12790487517012752}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.15729998639953663, 'info': {'data04': 0.15729998639953663, 'config': "{'batch_size': 128, 'hidden_dim': 331, 'last_n_outputs': 28, 'leak_rate': 0.8066740356239744, 'lr': 0.023414000503067352, 'optimizer': 'SGD', 'sparsity': 0.8978355794150487, 'steps_to_train': 91, 'weight_decay': 0.12790487517012752}"}}
exception: None

01:55:03 job_callback for (2, 0, 4) started
01:55:03 DISPATCHER: Trying to submit another job.
01:55:03 job_callback for (2, 0, 4) got condition
01:55:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:55:03 HBMASTER: Trying to run another job!
01:55:03 job_callback for (2, 0, 4) finished
01:55:03 start sampling a new configuration.
01:55:03 done sampling a new configuration.
01:55:03 HBMASTER: schedule new run for iteration 2
01:55:03 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
01:55:03 HBMASTER: submitting job (2, 0, 5) to dispatcher
01:55:03 DISPATCHER: trying to submit job (2, 0, 5)
01:55:03 DISPATCHER: trying to notify the job_runner thread.
01:55:03 HBMASTER: job (2, 0, 5) submitted to dispatcher
01:55:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:55:03 DISPATCHER: Trying to submit another job.
01:55:03 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:55:03 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:55:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:55:03 WORKER: start processing job (2, 0, 5)
01:55:03 WORKER: args: ()
01:55:03 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 597, 'last_n_outputs': 25, 'leak_rate': 0.927683785945245, 'lr': 0.04731258775606105, 'optimizer': 'SGD', 'sparsity': 0.8184478688983875, 'steps_to_train': 78, 'weight_decay': 0.05553356186013453}, 'budget': 400.0, 'working_directory': '.'}
01:55:23 DISPATCHER: Starting worker discovery
01:55:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:55:23 DISPATCHER: Finished worker discovery
01:56:23 DISPATCHER: Starting worker discovery
01:56:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:56:23 DISPATCHER: Finished worker discovery
01:57:23 DISPATCHER: Starting worker discovery
01:57:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:57:23 DISPATCHER: Finished worker discovery
01:58:23 DISPATCHER: Starting worker discovery
01:58:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:58:23 DISPATCHER: Finished worker discovery
01:59:23 DISPATCHER: Starting worker discovery
01:59:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:59:23 DISPATCHER: Finished worker discovery
02:00:23 DISPATCHER: Starting worker discovery
02:00:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:00:23 DISPATCHER: Finished worker discovery
02:01:23 DISPATCHER: Starting worker discovery
02:01:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:01:23 DISPATCHER: Finished worker discovery
02:02:08 WORKER: done with job (2, 0, 5), trying to register it.
02:02:08 WORKER: registered result for job (2, 0, 5) with dispatcher
02:02:08 DISPATCHER: job (2, 0, 5) finished
02:02:08 DISPATCHER: register_result: lock acquired
02:02:08 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
02:02:08 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 597, 'last_n_outputs': 25, 'leak_rate': 0.927683785945245, 'lr': 0.04731258775606105, 'optimizer': 'SGD', 'sparsity': 0.8184478688983875, 'steps_to_train': 78, 'weight_decay': 0.05553356186013453}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.13661456075237868, 'info': {'data04': 0.13661456075237868, 'config': "{'batch_size': 16, 'hidden_dim': 597, 'last_n_outputs': 25, 'leak_rate': 0.927683785945245, 'lr': 0.04731258775606105, 'optimizer': 'SGD', 'sparsity': 0.8184478688983875, 'steps_to_train': 78, 'weight_decay': 0.05553356186013453}"}}
exception: None

02:02:08 job_callback for (2, 0, 5) started
02:02:08 job_callback for (2, 0, 5) got condition
02:02:08 DISPATCHER: Trying to submit another job.
02:02:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:02:08 HBMASTER: Trying to run another job!
02:02:08 job_callback for (2, 0, 5) finished
02:02:08 ITERATION: Advancing config (2, 0, 1) to next budget 1200.000000
02:02:08 ITERATION: Advancing config (2, 0, 2) to next budget 1200.000000
02:02:08 HBMASTER: schedule new run for iteration 2
02:02:08 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
02:02:08 HBMASTER: submitting job (2, 0, 1) to dispatcher
02:02:08 DISPATCHER: trying to submit job (2, 0, 1)
02:02:08 DISPATCHER: trying to notify the job_runner thread.
02:02:08 HBMASTER: job (2, 0, 1) submitted to dispatcher
02:02:08 DISPATCHER: Trying to submit another job.
02:02:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:02:08 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
02:02:08 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
02:02:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:02:08 WORKER: start processing job (2, 0, 1)
02:02:08 WORKER: args: ()
02:02:08 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 536, 'last_n_outputs': 35, 'leak_rate': 0.8372746117712593, 'lr': 0.006604573819585582, 'optimizer': 'SGD', 'sparsity': 0.9417846334677917, 'steps_to_train': 96, 'weight_decay': 0.0976991274080585}, 'budget': 1200.0, 'working_directory': '.'}
02:02:23 DISPATCHER: Starting worker discovery
02:02:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:02:23 DISPATCHER: Finished worker discovery
02:03:23 DISPATCHER: Starting worker discovery
02:03:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:03:23 DISPATCHER: Finished worker discovery
02:04:23 DISPATCHER: Starting worker discovery
02:04:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:04:23 DISPATCHER: Finished worker discovery
02:05:23 DISPATCHER: Starting worker discovery
02:05:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:05:23 DISPATCHER: Finished worker discovery
02:06:23 DISPATCHER: Starting worker discovery
02:06:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:06:23 DISPATCHER: Finished worker discovery
02:07:23 DISPATCHER: Starting worker discovery
02:07:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:07:23 DISPATCHER: Finished worker discovery
02:08:23 DISPATCHER: Starting worker discovery
02:08:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:08:23 DISPATCHER: Finished worker discovery
02:09:23 DISPATCHER: Starting worker discovery
02:09:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:09:23 DISPATCHER: Finished worker discovery
02:10:23 DISPATCHER: Starting worker discovery
02:10:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:10:23 DISPATCHER: Finished worker discovery
02:11:23 DISPATCHER: Starting worker discovery
02:11:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:11:23 DISPATCHER: Finished worker discovery
02:12:23 DISPATCHER: Starting worker discovery
02:12:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:12:23 DISPATCHER: Finished worker discovery
02:13:23 DISPATCHER: Starting worker discovery
02:13:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:13:23 DISPATCHER: Finished worker discovery
02:14:23 DISPATCHER: Starting worker discovery
02:14:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:14:23 DISPATCHER: Finished worker discovery
02:15:23 DISPATCHER: Starting worker discovery
02:15:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:15:23 DISPATCHER: Finished worker discovery
02:16:23 DISPATCHER: Starting worker discovery
02:16:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:16:23 DISPATCHER: Finished worker discovery
02:17:23 DISPATCHER: Starting worker discovery
02:17:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:17:23 DISPATCHER: Finished worker discovery
02:18:23 DISPATCHER: Starting worker discovery
02:18:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:18:23 DISPATCHER: Finished worker discovery
02:19:23 DISPATCHER: Starting worker discovery
02:19:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:19:23 DISPATCHER: Finished worker discovery
02:20:23 DISPATCHER: Starting worker discovery
02:20:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:20:23 DISPATCHER: Finished worker discovery
02:21:23 DISPATCHER: Starting worker discovery
02:21:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:21:23 DISPATCHER: Finished worker discovery
02:22:23 DISPATCHER: Starting worker discovery
02:22:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:22:23 DISPATCHER: Finished worker discovery
02:22:39 WORKER: done with job (2, 0, 1), trying to register it.
02:22:39 WORKER: registered result for job (2, 0, 1) with dispatcher
02:22:39 DISPATCHER: job (2, 0, 1) finished
02:22:39 DISPATCHER: register_result: lock acquired
02:22:39 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
02:22:39 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 536, 'last_n_outputs': 35, 'leak_rate': 0.8372746117712593, 'lr': 0.006604573819585582, 'optimizer': 'SGD', 'sparsity': 0.9417846334677917, 'steps_to_train': 96, 'weight_decay': 0.0976991274080585}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.17905849609213292, 'info': {'data04': 0.17905849609213292, 'config': "{'batch_size': 128, 'hidden_dim': 536, 'last_n_outputs': 35, 'leak_rate': 0.8372746117712593, 'lr': 0.006604573819585582, 'optimizer': 'SGD', 'sparsity': 0.9417846334677917, 'steps_to_train': 96, 'weight_decay': 0.0976991274080585}"}}
exception: None

02:22:39 job_callback for (2, 0, 1) started
02:22:39 DISPATCHER: Trying to submit another job.
02:22:39 job_callback for (2, 0, 1) got condition
02:22:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:22:39 Only 3 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
02:22:39 HBMASTER: Trying to run another job!
02:22:39 job_callback for (2, 0, 1) finished
02:22:39 HBMASTER: schedule new run for iteration 2
02:22:39 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
02:22:39 HBMASTER: submitting job (2, 0, 2) to dispatcher
02:22:39 DISPATCHER: trying to submit job (2, 0, 2)
02:22:39 DISPATCHER: trying to notify the job_runner thread.
02:22:39 HBMASTER: job (2, 0, 2) submitted to dispatcher
02:22:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:22:39 DISPATCHER: Trying to submit another job.
02:22:39 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
02:22:39 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
02:22:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:22:39 WORKER: start processing job (2, 0, 2)
02:22:39 WORKER: args: ()
02:22:39 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 277, 'last_n_outputs': 39, 'leak_rate': 0.9427684230030893, 'lr': 0.02658154496263179, 'optimizer': 'SGD', 'sparsity': 0.9245896600208914, 'steps_to_train': 76, 'weight_decay': 0.07600378582367498}, 'budget': 1200.0, 'working_directory': '.'}
02:23:23 DISPATCHER: Starting worker discovery
02:23:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:23:23 DISPATCHER: Finished worker discovery
02:24:23 DISPATCHER: Starting worker discovery
02:24:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:24:23 DISPATCHER: Finished worker discovery
02:25:23 DISPATCHER: Starting worker discovery
02:25:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:25:23 DISPATCHER: Finished worker discovery
02:26:23 DISPATCHER: Starting worker discovery
02:26:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:26:23 DISPATCHER: Finished worker discovery
02:27:24 DISPATCHER: Starting worker discovery
02:27:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:27:24 DISPATCHER: Finished worker discovery
02:28:24 DISPATCHER: Starting worker discovery
02:28:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:28:24 DISPATCHER: Finished worker discovery
02:29:24 DISPATCHER: Starting worker discovery
02:29:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:29:24 DISPATCHER: Finished worker discovery
02:30:24 DISPATCHER: Starting worker discovery
02:30:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:30:24 DISPATCHER: Finished worker discovery
02:31:24 DISPATCHER: Starting worker discovery
02:31:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:31:24 DISPATCHER: Finished worker discovery
02:32:24 DISPATCHER: Starting worker discovery
02:32:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:32:24 DISPATCHER: Finished worker discovery
02:33:24 DISPATCHER: Starting worker discovery
02:33:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:33:24 DISPATCHER: Finished worker discovery
02:34:24 DISPATCHER: Starting worker discovery
02:34:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:34:24 DISPATCHER: Finished worker discovery
02:35:24 DISPATCHER: Starting worker discovery
02:35:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:35:24 DISPATCHER: Finished worker discovery
02:36:24 DISPATCHER: Starting worker discovery
02:36:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:36:24 DISPATCHER: Finished worker discovery
02:37:24 DISPATCHER: Starting worker discovery
02:37:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:37:24 DISPATCHER: Finished worker discovery
02:38:24 DISPATCHER: Starting worker discovery
02:38:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:38:24 DISPATCHER: Finished worker discovery
02:39:24 DISPATCHER: Starting worker discovery
02:39:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:39:24 DISPATCHER: Finished worker discovery
02:40:24 DISPATCHER: Starting worker discovery
02:40:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:40:24 DISPATCHER: Finished worker discovery
02:41:24 DISPATCHER: Starting worker discovery
02:41:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:41:24 DISPATCHER: Finished worker discovery
02:42:24 DISPATCHER: Starting worker discovery
02:42:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:42:24 DISPATCHER: Finished worker discovery
02:43:15 WORKER: done with job (2, 0, 2), trying to register it.
02:43:15 WORKER: registered result for job (2, 0, 2) with dispatcher
02:43:15 DISPATCHER: job (2, 0, 2) finished
02:43:15 DISPATCHER: register_result: lock acquired
02:43:15 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
02:43:15 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 277, 'last_n_outputs': 39, 'leak_rate': 0.9427684230030893, 'lr': 0.02658154496263179, 'optimizer': 'SGD', 'sparsity': 0.9245896600208914, 'steps_to_train': 76, 'weight_decay': 0.07600378582367498}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.1791472996547773, 'info': {'data04': 0.1791472996547773, 'config': "{'batch_size': 128, 'hidden_dim': 277, 'last_n_outputs': 39, 'leak_rate': 0.9427684230030893, 'lr': 0.02658154496263179, 'optimizer': 'SGD', 'sparsity': 0.9245896600208914, 'steps_to_train': 76, 'weight_decay': 0.07600378582367498}"}}
exception: None

02:43:15 job_callback for (2, 0, 2) started
02:43:15 job_callback for (2, 0, 2) got condition
02:43:15 DISPATCHER: Trying to submit another job.
02:43:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:43:15 Only 4 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
02:43:15 HBMASTER: Trying to run another job!
02:43:15 job_callback for (2, 0, 2) finished
02:43:15 start sampling a new configuration.
02:43:15 done sampling a new configuration.
02:43:15 HBMASTER: schedule new run for iteration 3
02:43:15 HBMASTER: trying submitting job (3, 0, 0) to dispatcher
02:43:15 HBMASTER: submitting job (3, 0, 0) to dispatcher
02:43:15 DISPATCHER: trying to submit job (3, 0, 0)
02:43:15 DISPATCHER: trying to notify the job_runner thread.
02:43:15 HBMASTER: job (3, 0, 0) submitted to dispatcher
02:43:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:43:15 DISPATCHER: Trying to submit another job.
02:43:15 DISPATCHER: starting job (3, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
02:43:15 DISPATCHER: job (3, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
02:43:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:43:15 WORKER: start processing job (3, 0, 0)
02:43:15 WORKER: args: ()
02:43:15 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 381, 'last_n_outputs': 28, 'leak_rate': 0.8590820968940627, 'lr': 0.014475814306225613, 'optimizer': 'Adam', 'sparsity': 0.83937777783972, 'steps_to_train': 30, 'weight_decay': 0.011275112887999685}, 'budget': 1200.0, 'working_directory': '.'}
02:43:24 DISPATCHER: Starting worker discovery
02:43:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:43:24 DISPATCHER: Finished worker discovery
02:44:24 DISPATCHER: Starting worker discovery
02:44:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:44:24 DISPATCHER: Finished worker discovery
02:45:24 DISPATCHER: Starting worker discovery
02:45:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:45:24 DISPATCHER: Finished worker discovery
02:46:24 DISPATCHER: Starting worker discovery
02:46:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:46:24 DISPATCHER: Finished worker discovery
02:47:24 DISPATCHER: Starting worker discovery
02:47:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:47:24 DISPATCHER: Finished worker discovery
02:48:24 DISPATCHER: Starting worker discovery
02:48:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:48:24 DISPATCHER: Finished worker discovery
02:49:24 DISPATCHER: Starting worker discovery
02:49:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:49:24 DISPATCHER: Finished worker discovery
02:50:24 DISPATCHER: Starting worker discovery
02:50:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:50:24 DISPATCHER: Finished worker discovery
02:51:24 DISPATCHER: Starting worker discovery
02:51:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:51:24 DISPATCHER: Finished worker discovery
02:52:24 DISPATCHER: Starting worker discovery
02:52:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:52:24 DISPATCHER: Finished worker discovery
02:53:24 DISPATCHER: Starting worker discovery
02:53:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:53:24 DISPATCHER: Finished worker discovery
02:54:24 DISPATCHER: Starting worker discovery
02:54:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:54:24 DISPATCHER: Finished worker discovery
02:55:24 DISPATCHER: Starting worker discovery
02:55:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:55:24 DISPATCHER: Finished worker discovery
02:56:24 DISPATCHER: Starting worker discovery
02:56:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:56:24 DISPATCHER: Finished worker discovery
02:57:24 DISPATCHER: Starting worker discovery
02:57:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:57:24 DISPATCHER: Finished worker discovery
02:58:24 DISPATCHER: Starting worker discovery
02:58:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:58:24 DISPATCHER: Finished worker discovery
02:59:24 DISPATCHER: Starting worker discovery
02:59:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:59:24 DISPATCHER: Finished worker discovery
03:00:24 DISPATCHER: Starting worker discovery
03:00:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:00:24 DISPATCHER: Finished worker discovery
03:01:24 DISPATCHER: Starting worker discovery
03:01:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:01:24 DISPATCHER: Finished worker discovery
03:02:24 DISPATCHER: Starting worker discovery
03:02:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:02:24 DISPATCHER: Finished worker discovery
03:03:24 DISPATCHER: Starting worker discovery
03:03:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:03:24 DISPATCHER: Finished worker discovery
03:04:21 WORKER: done with job (3, 0, 0), trying to register it.
03:04:21 WORKER: registered result for job (3, 0, 0) with dispatcher
03:04:21 DISPATCHER: job (3, 0, 0) finished
03:04:21 DISPATCHER: register_result: lock acquired
03:04:21 DISPATCHER: job (3, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:04:21 job_id: (3, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 381, 'last_n_outputs': 28, 'leak_rate': 0.8590820968940627, 'lr': 0.014475814306225613, 'optimizer': 'Adam', 'sparsity': 0.83937777783972, 'steps_to_train': 30, 'weight_decay': 0.011275112887999685}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.06946489887630461, 'info': {'data04': 0.06946489887630461, 'config': "{'batch_size': 128, 'hidden_dim': 381, 'last_n_outputs': 28, 'leak_rate': 0.8590820968940627, 'lr': 0.014475814306225613, 'optimizer': 'Adam', 'sparsity': 0.83937777783972, 'steps_to_train': 30, 'weight_decay': 0.011275112887999685}"}}
exception: None

03:04:21 job_callback for (3, 0, 0) started
03:04:21 DISPATCHER: Trying to submit another job.
03:04:21 job_callback for (3, 0, 0) got condition
03:04:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:04:21 Only 5 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
03:04:21 HBMASTER: Trying to run another job!
03:04:21 job_callback for (3, 0, 0) finished
03:04:21 start sampling a new configuration.
03:04:21 done sampling a new configuration.
03:04:21 HBMASTER: schedule new run for iteration 3
03:04:21 HBMASTER: trying submitting job (3, 0, 1) to dispatcher
03:04:21 HBMASTER: submitting job (3, 0, 1) to dispatcher
03:04:21 DISPATCHER: trying to submit job (3, 0, 1)
03:04:21 DISPATCHER: trying to notify the job_runner thread.
03:04:21 HBMASTER: job (3, 0, 1) submitted to dispatcher
03:04:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:04:21 DISPATCHER: Trying to submit another job.
03:04:21 DISPATCHER: starting job (3, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:04:21 DISPATCHER: job (3, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:04:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:04:21 WORKER: start processing job (3, 0, 1)
03:04:21 WORKER: args: ()
03:04:21 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 618, 'last_n_outputs': 15, 'leak_rate': 0.9616328868502707, 'lr': 0.014925368534496638, 'optimizer': 'SGD', 'sparsity': 0.8544103031055963, 'steps_to_train': 91, 'weight_decay': 0.06843469229272987}, 'budget': 1200.0, 'working_directory': '.'}
03:04:24 DISPATCHER: Starting worker discovery
03:04:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:04:24 DISPATCHER: Finished worker discovery
03:05:24 DISPATCHER: Starting worker discovery
03:05:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:05:24 DISPATCHER: Finished worker discovery
03:06:24 DISPATCHER: Starting worker discovery
03:06:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:06:24 DISPATCHER: Finished worker discovery
03:07:24 DISPATCHER: Starting worker discovery
03:07:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:07:24 DISPATCHER: Finished worker discovery
03:08:24 DISPATCHER: Starting worker discovery
03:08:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:08:24 DISPATCHER: Finished worker discovery
03:09:24 DISPATCHER: Starting worker discovery
03:09:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:09:24 DISPATCHER: Finished worker discovery
03:10:24 DISPATCHER: Starting worker discovery
03:10:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:10:24 DISPATCHER: Finished worker discovery
03:11:24 DISPATCHER: Starting worker discovery
03:11:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:11:24 DISPATCHER: Finished worker discovery
03:12:24 DISPATCHER: Starting worker discovery
03:12:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:12:24 DISPATCHER: Finished worker discovery
03:13:24 DISPATCHER: Starting worker discovery
03:13:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:13:24 DISPATCHER: Finished worker discovery
03:14:24 DISPATCHER: Starting worker discovery
03:14:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:14:24 DISPATCHER: Finished worker discovery
03:15:24 DISPATCHER: Starting worker discovery
03:15:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:15:24 DISPATCHER: Finished worker discovery
03:16:24 DISPATCHER: Starting worker discovery
03:16:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:16:24 DISPATCHER: Finished worker discovery
03:17:24 DISPATCHER: Starting worker discovery
03:17:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:17:24 DISPATCHER: Finished worker discovery
03:18:24 DISPATCHER: Starting worker discovery
03:18:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:18:24 DISPATCHER: Finished worker discovery
03:19:24 DISPATCHER: Starting worker discovery
03:19:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:19:24 DISPATCHER: Finished worker discovery
03:20:24 DISPATCHER: Starting worker discovery
03:20:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:20:24 DISPATCHER: Finished worker discovery
03:21:24 DISPATCHER: Starting worker discovery
03:21:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:21:24 DISPATCHER: Finished worker discovery
03:22:24 DISPATCHER: Starting worker discovery
03:22:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:22:24 DISPATCHER: Finished worker discovery
03:23:24 DISPATCHER: Starting worker discovery
03:23:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:23:24 DISPATCHER: Finished worker discovery
03:24:24 DISPATCHER: Starting worker discovery
03:24:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:24:24 DISPATCHER: Finished worker discovery
03:24:55 WORKER: done with job (3, 0, 1), trying to register it.
03:24:55 WORKER: registered result for job (3, 0, 1) with dispatcher
03:24:55 DISPATCHER: job (3, 0, 1) finished
03:24:55 DISPATCHER: register_result: lock acquired
03:24:55 DISPATCHER: job (3, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:24:55 job_id: (3, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 618, 'last_n_outputs': 15, 'leak_rate': 0.9616328868502707, 'lr': 0.014925368534496638, 'optimizer': 'SGD', 'sparsity': 0.8544103031055963, 'steps_to_train': 91, 'weight_decay': 0.06843469229272987}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.15485211828227494, 'info': {'data04': 0.15485211828227494, 'config': "{'batch_size': 128, 'hidden_dim': 618, 'last_n_outputs': 15, 'leak_rate': 0.9616328868502707, 'lr': 0.014925368534496638, 'optimizer': 'SGD', 'sparsity': 0.8544103031055963, 'steps_to_train': 91, 'weight_decay': 0.06843469229272987}"}}
exception: None

03:24:55 job_callback for (3, 0, 1) started
03:24:55 job_callback for (3, 0, 1) got condition
03:24:55 DISPATCHER: Trying to submit another job.
03:24:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:24:55 Only 6 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
03:24:55 HBMASTER: Trying to run another job!
03:24:55 job_callback for (3, 0, 1) finished
03:24:55 start sampling a new configuration.
03:24:55 best_vector: [3, 0.6131283453966783, 0.5833449586718948, 0.8155776848347411, 0.235216992241663, 1, 0.7334362349643301, 0.717669239547298, 0.7903549842829688], 6.463777013737798e-32, 0.1547083072133597, -0.0002572715356830585
03:24:55 done sampling a new configuration.
03:24:55 HBMASTER: schedule new run for iteration 3
03:24:55 HBMASTER: trying submitting job (3, 0, 2) to dispatcher
03:24:55 HBMASTER: submitting job (3, 0, 2) to dispatcher
03:24:55 DISPATCHER: trying to submit job (3, 0, 2)
03:24:55 DISPATCHER: trying to notify the job_runner thread.
03:24:55 HBMASTER: job (3, 0, 2) submitted to dispatcher
03:24:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:24:55 DISPATCHER: Trying to submit another job.
03:24:55 DISPATCHER: starting job (3, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:24:55 DISPATCHER: job (3, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:24:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:24:55 WORKER: start processing job (3, 0, 2)
03:24:55 WORKER: args: ()
03:24:55 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 691, 'last_n_outputs': 33, 'leak_rate': 0.9538944212086853, 'lr': 0.002954159803315241, 'optimizer': 'SGD', 'sparsity': 0.9260246963914393, 'steps_to_train': 75, 'weight_decay': 0.10672730467983499}, 'budget': 1200.0, 'working_directory': '.'}
03:25:24 DISPATCHER: Starting worker discovery
03:25:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:25:24 DISPATCHER: Finished worker discovery
03:26:24 DISPATCHER: Starting worker discovery
03:26:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:26:24 DISPATCHER: Finished worker discovery
03:27:24 DISPATCHER: Starting worker discovery
03:27:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:27:24 DISPATCHER: Finished worker discovery
03:28:24 DISPATCHER: Starting worker discovery
03:28:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:28:24 DISPATCHER: Finished worker discovery
03:29:24 DISPATCHER: Starting worker discovery
03:29:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:29:24 DISPATCHER: Finished worker discovery
03:30:24 DISPATCHER: Starting worker discovery
03:30:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:30:24 DISPATCHER: Finished worker discovery
03:31:24 DISPATCHER: Starting worker discovery
03:31:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:31:24 DISPATCHER: Finished worker discovery
03:32:24 DISPATCHER: Starting worker discovery
03:32:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:32:24 DISPATCHER: Finished worker discovery
03:33:24 DISPATCHER: Starting worker discovery
03:33:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:33:24 DISPATCHER: Finished worker discovery
03:34:24 DISPATCHER: Starting worker discovery
03:34:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:34:24 DISPATCHER: Finished worker discovery
03:35:24 DISPATCHER: Starting worker discovery
03:35:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:35:24 DISPATCHER: Finished worker discovery
03:36:24 DISPATCHER: Starting worker discovery
03:36:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:36:24 DISPATCHER: Finished worker discovery
03:37:24 DISPATCHER: Starting worker discovery
03:37:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:37:24 DISPATCHER: Finished worker discovery
03:38:24 DISPATCHER: Starting worker discovery
03:38:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:38:24 DISPATCHER: Finished worker discovery
03:39:24 DISPATCHER: Starting worker discovery
03:39:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:39:24 DISPATCHER: Finished worker discovery
03:40:24 DISPATCHER: Starting worker discovery
03:40:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:40:24 DISPATCHER: Finished worker discovery
03:41:24 DISPATCHER: Starting worker discovery
03:41:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:41:24 DISPATCHER: Finished worker discovery
03:42:24 DISPATCHER: Starting worker discovery
03:42:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:42:24 DISPATCHER: Finished worker discovery
03:43:24 DISPATCHER: Starting worker discovery
03:43:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:43:24 DISPATCHER: Finished worker discovery
03:44:24 DISPATCHER: Starting worker discovery
03:44:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:44:24 DISPATCHER: Finished worker discovery
03:45:24 DISPATCHER: Starting worker discovery
03:45:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:45:24 DISPATCHER: Finished worker discovery
03:45:32 WORKER: done with job (3, 0, 2), trying to register it.
03:45:32 WORKER: registered result for job (3, 0, 2) with dispatcher
03:45:32 DISPATCHER: job (3, 0, 2) finished
03:45:32 DISPATCHER: register_result: lock acquired
03:45:32 DISPATCHER: job (3, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:45:32 job_id: (3, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 691, 'last_n_outputs': 33, 'leak_rate': 0.9538944212086853, 'lr': 0.002954159803315241, 'optimizer': 'SGD', 'sparsity': 0.9260246963914393, 'steps_to_train': 75, 'weight_decay': 0.10672730467983499}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.17115542831373856, 'info': {'data04': 0.17115542831373856, 'config': "{'batch_size': 128, 'hidden_dim': 691, 'last_n_outputs': 33, 'leak_rate': 0.9538944212086853, 'lr': 0.002954159803315241, 'optimizer': 'SGD', 'sparsity': 0.9260246963914393, 'steps_to_train': 75, 'weight_decay': 0.10672730467983499}"}}
exception: None

03:45:32 job_callback for (3, 0, 2) started
03:45:32 DISPATCHER: Trying to submit another job.
03:45:32 job_callback for (3, 0, 2) got condition
03:45:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:45:32 Only 7 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
03:45:32 HBMASTER: Trying to run another job!
03:45:32 job_callback for (3, 0, 2) finished
03:45:32 start sampling a new configuration.
03:45:32 done sampling a new configuration.
03:45:32 HBMASTER: schedule new run for iteration 3
03:45:32 HBMASTER: trying submitting job (3, 0, 3) to dispatcher
03:45:32 HBMASTER: submitting job (3, 0, 3) to dispatcher
03:45:32 DISPATCHER: trying to submit job (3, 0, 3)
03:45:32 DISPATCHER: trying to notify the job_runner thread.
03:45:32 HBMASTER: job (3, 0, 3) submitted to dispatcher
03:45:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:45:32 DISPATCHER: Trying to submit another job.
03:45:32 DISPATCHER: starting job (3, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:45:32 DISPATCHER: job (3, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:45:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:45:32 WORKER: start processing job (3, 0, 3)
03:45:32 WORKER: args: ()
03:45:32 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 283, 'last_n_outputs': 43, 'leak_rate': 0.7679725526106542, 'lr': 0.00805384751445925, 'optimizer': 'Adam', 'sparsity': 0.8763698001082144, 'steps_to_train': 34, 'weight_decay': 0.01328852165053487}, 'budget': 1200.0, 'working_directory': '.'}
03:46:24 DISPATCHER: Starting worker discovery
03:46:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:46:24 DISPATCHER: Finished worker discovery
03:47:24 DISPATCHER: Starting worker discovery
03:47:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:47:24 DISPATCHER: Finished worker discovery
03:48:24 DISPATCHER: Starting worker discovery
03:48:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:48:24 DISPATCHER: Finished worker discovery
03:49:24 DISPATCHER: Starting worker discovery
03:49:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:49:24 DISPATCHER: Finished worker discovery
03:50:24 DISPATCHER: Starting worker discovery
03:50:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:50:24 DISPATCHER: Finished worker discovery
03:51:24 DISPATCHER: Starting worker discovery
03:51:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:51:24 DISPATCHER: Finished worker discovery
03:52:24 DISPATCHER: Starting worker discovery
03:52:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:52:24 DISPATCHER: Finished worker discovery
03:53:24 DISPATCHER: Starting worker discovery
03:53:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:53:24 DISPATCHER: Finished worker discovery
03:54:24 DISPATCHER: Starting worker discovery
03:54:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:54:24 DISPATCHER: Finished worker discovery
03:55:24 DISPATCHER: Starting worker discovery
03:55:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:55:24 DISPATCHER: Finished worker discovery
03:56:24 DISPATCHER: Starting worker discovery
03:56:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:56:24 DISPATCHER: Finished worker discovery
03:57:24 DISPATCHER: Starting worker discovery
03:57:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:57:24 DISPATCHER: Finished worker discovery
03:58:24 DISPATCHER: Starting worker discovery
03:58:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:58:24 DISPATCHER: Finished worker discovery
03:59:24 DISPATCHER: Starting worker discovery
03:59:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:59:24 DISPATCHER: Finished worker discovery
04:00:24 DISPATCHER: Starting worker discovery
04:00:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:00:24 DISPATCHER: Finished worker discovery
04:01:24 DISPATCHER: Starting worker discovery
04:01:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:01:24 DISPATCHER: Finished worker discovery
04:02:24 DISPATCHER: Starting worker discovery
04:02:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:02:24 DISPATCHER: Finished worker discovery
04:03:24 DISPATCHER: Starting worker discovery
04:03:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:03:24 DISPATCHER: Finished worker discovery
04:04:24 DISPATCHER: Starting worker discovery
04:04:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:04:24 DISPATCHER: Finished worker discovery
04:05:24 DISPATCHER: Starting worker discovery
04:05:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:05:24 DISPATCHER: Finished worker discovery
04:06:24 DISPATCHER: Starting worker discovery
04:06:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:06:24 DISPATCHER: Finished worker discovery
04:06:34 WORKER: done with job (3, 0, 3), trying to register it.
04:06:34 WORKER: registered result for job (3, 0, 3) with dispatcher
04:06:34 DISPATCHER: job (3, 0, 3) finished
04:06:34 DISPATCHER: register_result: lock acquired
04:06:34 DISPATCHER: job (3, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:06:34 job_id: (3, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 283, 'last_n_outputs': 43, 'leak_rate': 0.7679725526106542, 'lr': 0.00805384751445925, 'optimizer': 'Adam', 'sparsity': 0.8763698001082144, 'steps_to_train': 34, 'weight_decay': 0.01328852165053487}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.07097637592431488, 'info': {'data04': 0.07097637592431488, 'config': "{'batch_size': 16, 'hidden_dim': 283, 'last_n_outputs': 43, 'leak_rate': 0.7679725526106542, 'lr': 0.00805384751445925, 'optimizer': 'Adam', 'sparsity': 0.8763698001082144, 'steps_to_train': 34, 'weight_decay': 0.01328852165053487}"}}
exception: None

04:06:34 job_callback for (3, 0, 3) started
04:06:34 job_callback for (3, 0, 3) got condition
04:06:34 DISPATCHER: Trying to submit another job.
04:06:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:06:34 Only 8 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
04:06:34 HBMASTER: Trying to run another job!
04:06:34 job_callback for (3, 0, 3) finished
04:06:34 start sampling a new configuration.
04:06:34 best_vector: [3, 0.43301995793285114, 0.9329847188557949, 0.7435806917353275, 0.26746076365407206, 1, 0.3649843289804855, 0.9117998508145596, 0.5012916787627272], 4.032157121304553e-32, 0.24800620856670955, -0.011236561966249376
04:06:34 done sampling a new configuration.
04:06:34 HBMASTER: schedule new run for iteration 4
04:06:34 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
04:06:34 HBMASTER: submitting job (4, 0, 0) to dispatcher
04:06:34 DISPATCHER: trying to submit job (4, 0, 0)
04:06:34 DISPATCHER: trying to notify the job_runner thread.
04:06:34 HBMASTER: job (4, 0, 0) submitted to dispatcher
04:06:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:06:34 DISPATCHER: Trying to submit another job.
04:06:34 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:06:34 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:06:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:06:34 WORKER: start processing job (4, 0, 0)
04:06:34 WORKER: args: ()
04:06:34 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 546, 'last_n_outputs': 48, 'leak_rate': 0.9358951729338318, 'lr': 0.003427058574129559, 'optimizer': 'SGD', 'sparsity': 0.8375962389553165, 'steps_to_train': 92, 'weight_decay': 0.04489474515671764}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:07:24 DISPATCHER: Starting worker discovery
04:07:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:07:25 DISPATCHER: Finished worker discovery
04:07:37 WORKER: done with job (4, 0, 0), trying to register it.
04:07:37 WORKER: registered result for job (4, 0, 0) with dispatcher
04:07:37 DISPATCHER: job (4, 0, 0) finished
04:07:37 DISPATCHER: register_result: lock acquired
04:07:37 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:07:37 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 546, 'last_n_outputs': 48, 'leak_rate': 0.9358951729338318, 'lr': 0.003427058574129559, 'optimizer': 'SGD', 'sparsity': 0.8375962389553165, 'steps_to_train': 92, 'weight_decay': 0.04489474515671764}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.16784195327795726, 'info': {'data04': 0.16784195327795726, 'config': "{'batch_size': 128, 'hidden_dim': 546, 'last_n_outputs': 48, 'leak_rate': 0.9358951729338318, 'lr': 0.003427058574129559, 'optimizer': 'SGD', 'sparsity': 0.8375962389553165, 'steps_to_train': 92, 'weight_decay': 0.04489474515671764}"}}
exception: None

04:07:37 job_callback for (4, 0, 0) started
04:07:37 DISPATCHER: Trying to submit another job.
04:07:37 job_callback for (4, 0, 0) got condition
04:07:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:07:37 done building a new model for budget 44.444444 based on 10/23 split
Best loss for this budget:-0.188157





04:07:37 HBMASTER: Trying to run another job!
04:07:37 job_callback for (4, 0, 0) finished
04:07:37 start sampling a new configuration.
04:07:37 best_vector: [3, 0.285009333779204, 0.5879691677464433, 0.8844463319721738, 0.6125665846091997, 1, 0.15878639409108897, 0.20353346013520268, 0.15175894813305563], 4.7152533116969e-30, 0.0021207768361444094, -0.007588888513292591
04:07:37 done sampling a new configuration.
04:07:37 HBMASTER: schedule new run for iteration 4
04:07:37 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
04:07:37 HBMASTER: submitting job (4, 0, 1) to dispatcher
04:07:37 DISPATCHER: trying to submit job (4, 0, 1)
04:07:37 DISPATCHER: trying to notify the job_runner thread.
04:07:37 HBMASTER: job (4, 0, 1) submitted to dispatcher
04:07:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:07:37 DISPATCHER: Trying to submit another job.
04:07:37 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:07:37 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:07:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:07:37 WORKER: start processing job (4, 0, 1)
04:07:37 WORKER: args: ()
04:07:37 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 428, 'last_n_outputs': 34, 'leak_rate': 0.9711115829930435, 'lr': 0.016793188745345515, 'optimizer': 'SGD', 'sparsity': 0.7881087345818614, 'steps_to_train': 28, 'weight_decay': 0.015755890127621693}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:08:25 DISPATCHER: Starting worker discovery
04:08:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:08:25 DISPATCHER: Finished worker discovery
04:08:38 WORKER: done with job (4, 0, 1), trying to register it.
04:08:38 WORKER: registered result for job (4, 0, 1) with dispatcher
04:08:38 DISPATCHER: job (4, 0, 1) finished
04:08:38 DISPATCHER: register_result: lock acquired
04:08:38 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:08:38 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 428, 'last_n_outputs': 34, 'leak_rate': 0.9711115829930435, 'lr': 0.016793188745345515, 'optimizer': 'SGD', 'sparsity': 0.7881087345818614, 'steps_to_train': 28, 'weight_decay': 0.015755890127621693}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1892926839895466, 'info': {'data04': 0.1892926839895466, 'config': "{'batch_size': 128, 'hidden_dim': 428, 'last_n_outputs': 34, 'leak_rate': 0.9711115829930435, 'lr': 0.016793188745345515, 'optimizer': 'SGD', 'sparsity': 0.7881087345818614, 'steps_to_train': 28, 'weight_decay': 0.015755890127621693}"}}
exception: None

04:08:38 job_callback for (4, 0, 1) started
04:08:38 job_callback for (4, 0, 1) got condition
04:08:38 DISPATCHER: Trying to submit another job.
04:08:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:08:38 done building a new model for budget 44.444444 based on 10/24 split
Best loss for this budget:-0.189293





04:08:38 HBMASTER: Trying to run another job!
04:08:38 job_callback for (4, 0, 1) finished
04:08:38 start sampling a new configuration.
04:08:38 best_vector: [0, 0.9569561377098516, 0.14623673449743213, 0.014329953838921772, 0.5974958518352195, 1, 0.1492883985562442, 0.027203028033061377, 0.19666100904372386], 3.36563399991877e-29, 0.0002971208396468942, -8.873884853305452e-05
04:08:38 done sampling a new configuration.
04:08:38 HBMASTER: schedule new run for iteration 4
04:08:38 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
04:08:38 HBMASTER: submitting job (4, 0, 2) to dispatcher
04:08:38 DISPATCHER: trying to submit job (4, 0, 2)
04:08:38 DISPATCHER: trying to notify the job_runner thread.
04:08:38 HBMASTER: job (4, 0, 2) submitted to dispatcher
04:08:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:08:38 DISPATCHER: Trying to submit another job.
04:08:38 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:08:38 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:08:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:08:38 WORKER: start processing job (4, 0, 2)
04:08:38 WORKER: args: ()
04:08:38 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 966, 'last_n_outputs': 15, 'leak_rate': 0.7535824884597304, 'lr': 0.015667211407408496, 'optimizer': 'SGD', 'sparsity': 0.7858292156534986, 'steps_to_train': 12, 'weight_decay': 0.018024443785291302}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:09:25 DISPATCHER: Starting worker discovery
04:09:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:09:25 DISPATCHER: Finished worker discovery
04:09:43 WORKER: done with job (4, 0, 2), trying to register it.
04:09:43 WORKER: registered result for job (4, 0, 2) with dispatcher
04:09:43 DISPATCHER: job (4, 0, 2) finished
04:09:43 DISPATCHER: register_result: lock acquired
04:09:43 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:09:43 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 966, 'last_n_outputs': 15, 'leak_rate': 0.7535824884597304, 'lr': 0.015667211407408496, 'optimizer': 'SGD', 'sparsity': 0.7858292156534986, 'steps_to_train': 12, 'weight_decay': 0.018024443785291302}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.15821321294488336, 'info': {'data04': 0.15821321294488336, 'config': "{'batch_size': 16, 'hidden_dim': 966, 'last_n_outputs': 15, 'leak_rate': 0.7535824884597304, 'lr': 0.015667211407408496, 'optimizer': 'SGD', 'sparsity': 0.7858292156534986, 'steps_to_train': 12, 'weight_decay': 0.018024443785291302}"}}
exception: None

04:09:43 job_callback for (4, 0, 2) started
04:09:43 DISPATCHER: Trying to submit another job.
04:09:43 job_callback for (4, 0, 2) got condition
04:09:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:09:43 done building a new model for budget 44.444444 based on 10/25 split
Best loss for this budget:-0.189293





04:09:43 HBMASTER: Trying to run another job!
04:09:43 job_callback for (4, 0, 2) finished
04:09:43 start sampling a new configuration.
04:09:43 best_vector: [0, 0.9373673421094412, 0.687362290042924, 0.5653228428410512, 0.560771254582224, 1, 0.3019502248628415, 0.14002015498851367, 0.8343723119189695], 0.0045166782899136275, 0.056849169315737136, 0.0002567694088480139
04:09:43 done sampling a new configuration.
04:09:43 HBMASTER: schedule new run for iteration 4
04:09:43 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
04:09:43 HBMASTER: submitting job (4, 0, 3) to dispatcher
04:09:43 DISPATCHER: trying to submit job (4, 0, 3)
04:09:43 DISPATCHER: trying to notify the job_runner thread.
04:09:43 HBMASTER: job (4, 0, 3) submitted to dispatcher
04:09:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:09:43 DISPATCHER: Trying to submit another job.
04:09:43 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:09:43 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:09:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:09:43 WORKER: start processing job (4, 0, 3)
04:09:43 WORKER: args: ()
04:09:43 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 950, 'last_n_outputs': 38, 'leak_rate': 0.8913307107102628, 'lr': 0.013229471930251323, 'optimizer': 'SGD', 'sparsity': 0.822468053967082, 'steps_to_train': 22, 'weight_decay': 0.12177086900869571}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:10:25 DISPATCHER: Starting worker discovery
04:10:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:10:25 DISPATCHER: Finished worker discovery
04:10:46 WORKER: done with job (4, 0, 3), trying to register it.
04:10:46 WORKER: registered result for job (4, 0, 3) with dispatcher
04:10:46 DISPATCHER: job (4, 0, 3) finished
04:10:46 DISPATCHER: register_result: lock acquired
04:10:46 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:10:46 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 950, 'last_n_outputs': 38, 'leak_rate': 0.8913307107102628, 'lr': 0.013229471930251323, 'optimizer': 'SGD', 'sparsity': 0.822468053967082, 'steps_to_train': 22, 'weight_decay': 0.12177086900869571}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.14884793194030158, 'info': {'data04': 0.14884793194030158, 'config': "{'batch_size': 16, 'hidden_dim': 950, 'last_n_outputs': 38, 'leak_rate': 0.8913307107102628, 'lr': 0.013229471930251323, 'optimizer': 'SGD', 'sparsity': 0.822468053967082, 'steps_to_train': 22, 'weight_decay': 0.12177086900869571}"}}
exception: None

04:10:46 job_callback for (4, 0, 3) started
04:10:46 job_callback for (4, 0, 3) got condition
04:10:46 DISPATCHER: Trying to submit another job.
04:10:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:10:46 done building a new model for budget 44.444444 based on 10/26 split
Best loss for this budget:-0.189293





04:10:46 HBMASTER: Trying to run another job!
04:10:46 job_callback for (4, 0, 3) finished
04:10:46 start sampling a new configuration.
04:10:46 best_vector: [3, 0.18779559535803048, 0.7658309720699221, 0.9696462969790316, 0.5768641513698651, 1, 0.48481070975066215, 0.5694219239882139, 0.2732163610842826], 2.260961130047861e-31, 0.04422897796473094, -0.005106310599308029
04:10:46 done sampling a new configuration.
04:10:46 HBMASTER: schedule new run for iteration 4
04:10:46 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
04:10:46 HBMASTER: submitting job (4, 0, 4) to dispatcher
04:10:46 DISPATCHER: trying to submit job (4, 0, 4)
04:10:46 DISPATCHER: trying to notify the job_runner thread.
04:10:46 HBMASTER: job (4, 0, 4) submitted to dispatcher
04:10:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:10:46 DISPATCHER: Trying to submit another job.
04:10:46 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:10:46 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:10:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:10:46 WORKER: start processing job (4, 0, 4)
04:10:46 WORKER: args: ()
04:10:46 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 350, 'last_n_outputs': 41, 'leak_rate': 0.9924115742447579, 'lr': 0.014247160037716694, 'optimizer': 'SGD', 'sparsity': 0.866354570340159, 'steps_to_train': 61, 'weight_decay': 0.022670582604672508}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:11:25 DISPATCHER: Starting worker discovery
04:11:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:11:25 DISPATCHER: Finished worker discovery
04:11:46 WORKER: done with job (4, 0, 4), trying to register it.
04:11:46 WORKER: registered result for job (4, 0, 4) with dispatcher
04:11:46 DISPATCHER: job (4, 0, 4) finished
04:11:46 DISPATCHER: register_result: lock acquired
04:11:46 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:11:46 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 350, 'last_n_outputs': 41, 'leak_rate': 0.9924115742447579, 'lr': 0.014247160037716694, 'optimizer': 'SGD', 'sparsity': 0.866354570340159, 'steps_to_train': 61, 'weight_decay': 0.022670582604672508}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.18065135969782845, 'info': {'data04': 0.18065135969782845, 'config': "{'batch_size': 128, 'hidden_dim': 350, 'last_n_outputs': 41, 'leak_rate': 0.9924115742447579, 'lr': 0.014247160037716694, 'optimizer': 'SGD', 'sparsity': 0.866354570340159, 'steps_to_train': 61, 'weight_decay': 0.022670582604672508}"}}
exception: None

04:11:46 job_callback for (4, 0, 4) started
04:11:46 DISPATCHER: Trying to submit another job.
04:11:46 job_callback for (4, 0, 4) got condition
04:11:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:11:46 done building a new model for budget 44.444444 based on 10/27 split
Best loss for this budget:-0.189293





04:11:46 HBMASTER: Trying to run another job!
04:11:46 job_callback for (4, 0, 4) finished
04:11:46 start sampling a new configuration.
04:11:46 done sampling a new configuration.
04:11:46 HBMASTER: schedule new run for iteration 4
04:11:46 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
04:11:46 HBMASTER: submitting job (4, 0, 5) to dispatcher
04:11:46 DISPATCHER: trying to submit job (4, 0, 5)
04:11:46 DISPATCHER: trying to notify the job_runner thread.
04:11:46 HBMASTER: job (4, 0, 5) submitted to dispatcher
04:11:46 DISPATCHER: Trying to submit another job.
04:11:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:11:46 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:11:46 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:11:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:11:46 WORKER: start processing job (4, 0, 5)
04:11:46 WORKER: args: ()
04:11:46 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 942, 'last_n_outputs': 16, 'leak_rate': 0.9024054661175411, 'lr': 0.0036074554190170353, 'optimizer': 'SGD', 'sparsity': 0.9652569112559384, 'steps_to_train': 83, 'weight_decay': 0.029151579888156885}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:12:25 DISPATCHER: Starting worker discovery
04:12:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:12:25 DISPATCHER: Finished worker discovery
04:12:48 WORKER: done with job (4, 0, 5), trying to register it.
04:12:48 WORKER: registered result for job (4, 0, 5) with dispatcher
04:12:48 DISPATCHER: job (4, 0, 5) finished
04:12:48 DISPATCHER: register_result: lock acquired
04:12:48 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:12:48 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 942, 'last_n_outputs': 16, 'leak_rate': 0.9024054661175411, 'lr': 0.0036074554190170353, 'optimizer': 'SGD', 'sparsity': 0.9652569112559384, 'steps_to_train': 83, 'weight_decay': 0.029151579888156885}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.13949138868317426, 'info': {'data04': 0.13949138868317426, 'config': "{'batch_size': 64, 'hidden_dim': 942, 'last_n_outputs': 16, 'leak_rate': 0.9024054661175411, 'lr': 0.0036074554190170353, 'optimizer': 'SGD', 'sparsity': 0.9652569112559384, 'steps_to_train': 83, 'weight_decay': 0.029151579888156885}"}}
exception: None

04:12:48 job_callback for (4, 0, 5) started
04:12:48 DISPATCHER: Trying to submit another job.
04:12:48 job_callback for (4, 0, 5) got condition
04:12:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:12:48 done building a new model for budget 44.444444 based on 10/28 split
Best loss for this budget:-0.189293





04:12:48 HBMASTER: Trying to run another job!
04:12:48 job_callback for (4, 0, 5) finished
04:12:48 start sampling a new configuration.
04:12:48 done sampling a new configuration.
04:12:48 HBMASTER: schedule new run for iteration 4
04:12:48 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
04:12:48 HBMASTER: submitting job (4, 0, 6) to dispatcher
04:12:48 DISPATCHER: trying to submit job (4, 0, 6)
04:12:48 DISPATCHER: trying to notify the job_runner thread.
04:12:48 HBMASTER: job (4, 0, 6) submitted to dispatcher
04:12:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:12:48 DISPATCHER: Trying to submit another job.
04:12:48 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:12:48 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:12:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:12:48 WORKER: start processing job (4, 0, 6)
04:12:48 WORKER: args: ()
04:12:48 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 933, 'last_n_outputs': 28, 'leak_rate': 0.8525616211034198, 'lr': 0.005029674832692732, 'optimizer': 'Adam', 'sparsity': 0.8839264232691662, 'steps_to_train': 93, 'weight_decay': 0.023522403164039772}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:13:25 DISPATCHER: Starting worker discovery
04:13:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:13:25 DISPATCHER: Finished worker discovery
04:13:48 WORKER: done with job (4, 0, 6), trying to register it.
04:13:48 WORKER: registered result for job (4, 0, 6) with dispatcher
04:13:48 DISPATCHER: job (4, 0, 6) finished
04:13:48 DISPATCHER: register_result: lock acquired
04:13:48 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:13:48 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 933, 'last_n_outputs': 28, 'leak_rate': 0.8525616211034198, 'lr': 0.005029674832692732, 'optimizer': 'Adam', 'sparsity': 0.8839264232691662, 'steps_to_train': 93, 'weight_decay': 0.023522403164039772}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.09190088672119072, 'info': {'data04': 0.09190088672119072, 'config': "{'batch_size': 128, 'hidden_dim': 933, 'last_n_outputs': 28, 'leak_rate': 0.8525616211034198, 'lr': 0.005029674832692732, 'optimizer': 'Adam', 'sparsity': 0.8839264232691662, 'steps_to_train': 93, 'weight_decay': 0.023522403164039772}"}}
exception: None

04:13:48 job_callback for (4, 0, 6) started
04:13:48 job_callback for (4, 0, 6) got condition
04:13:48 DISPATCHER: Trying to submit another job.
04:13:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:13:48 done building a new model for budget 44.444444 based on 10/28 split
Best loss for this budget:-0.189293





04:13:48 HBMASTER: Trying to run another job!
04:13:48 job_callback for (4, 0, 6) finished
04:13:48 start sampling a new configuration.
04:13:48 best_vector: [3, 0.10156971812813359, 0.7392201932510843, 0.7570721378959197, 0.6384126920851523, 1, 0.7068577027425071, 0.9487965588718896, 0.8512849173720957], 4.4589599111104514e-05, 1.9691344193624096, 8.78029143552474e-05
04:13:48 done sampling a new configuration.
04:13:48 HBMASTER: schedule new run for iteration 4
04:13:48 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
04:13:48 HBMASTER: submitting job (4, 0, 7) to dispatcher
04:13:48 DISPATCHER: trying to submit job (4, 0, 7)
04:13:48 DISPATCHER: trying to notify the job_runner thread.
04:13:48 HBMASTER: job (4, 0, 7) submitted to dispatcher
04:13:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:13:48 DISPATCHER: Trying to submit another job.
04:13:48 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:13:48 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:13:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:13:48 WORKER: start processing job (4, 0, 7)
04:13:48 WORKER: args: ()
04:13:48 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 281, 'last_n_outputs': 40, 'leak_rate': 0.9392680344739799, 'lr': 0.018915829211334015, 'optimizer': 'SGD', 'sparsity': 0.9196458486582018, 'steps_to_train': 96, 'weight_decay': 0.1280994344464976}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:14:25 DISPATCHER: Starting worker discovery
04:14:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:14:25 DISPATCHER: Finished worker discovery
04:14:50 WORKER: done with job (4, 0, 7), trying to register it.
04:14:50 WORKER: registered result for job (4, 0, 7) with dispatcher
04:14:50 DISPATCHER: job (4, 0, 7) finished
04:14:50 DISPATCHER: register_result: lock acquired
04:14:50 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:14:50 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 281, 'last_n_outputs': 40, 'leak_rate': 0.9392680344739799, 'lr': 0.018915829211334015, 'optimizer': 'SGD', 'sparsity': 0.9196458486582018, 'steps_to_train': 96, 'weight_decay': 0.1280994344464976}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.17937653080623897, 'info': {'data04': 0.17937653080623897, 'config': "{'batch_size': 128, 'hidden_dim': 281, 'last_n_outputs': 40, 'leak_rate': 0.9392680344739799, 'lr': 0.018915829211334015, 'optimizer': 'SGD', 'sparsity': 0.9196458486582018, 'steps_to_train': 96, 'weight_decay': 0.1280994344464976}"}}
exception: None

04:14:50 job_callback for (4, 0, 7) started
04:14:50 job_callback for (4, 0, 7) got condition
04:14:50 DISPATCHER: Trying to submit another job.
04:14:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:14:50 done building a new model for budget 44.444444 based on 10/29 split
Best loss for this budget:-0.189293





04:14:50 HBMASTER: Trying to run another job!
04:14:50 job_callback for (4, 0, 7) finished
04:14:50 start sampling a new configuration.
04:14:50 done sampling a new configuration.
04:14:50 HBMASTER: schedule new run for iteration 4
04:14:50 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
04:14:50 HBMASTER: submitting job (4, 0, 8) to dispatcher
04:14:50 DISPATCHER: trying to submit job (4, 0, 8)
04:14:50 DISPATCHER: trying to notify the job_runner thread.
04:14:50 HBMASTER: job (4, 0, 8) submitted to dispatcher
04:14:50 DISPATCHER: Trying to submit another job.
04:14:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:14:50 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:14:50 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:14:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:14:50 WORKER: start processing job (4, 0, 8)
04:14:50 WORKER: args: ()
04:14:50 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 670, 'last_n_outputs': 34, 'leak_rate': 0.8155199354756968, 'lr': 0.05479565846683718, 'optimizer': 'SGD', 'sparsity': 0.8682429805471091, 'steps_to_train': 62, 'weight_decay': 0.09098702279105031}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:15:25 DISPATCHER: Starting worker discovery
04:15:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:15:25 DISPATCHER: Finished worker discovery
04:15:51 WORKER: done with job (4, 0, 8), trying to register it.
04:15:51 WORKER: registered result for job (4, 0, 8) with dispatcher
04:15:51 DISPATCHER: job (4, 0, 8) finished
04:15:51 DISPATCHER: register_result: lock acquired
04:15:51 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:15:51 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 670, 'last_n_outputs': 34, 'leak_rate': 0.8155199354756968, 'lr': 0.05479565846683718, 'optimizer': 'SGD', 'sparsity': 0.8682429805471091, 'steps_to_train': 62, 'weight_decay': 0.09098702279105031}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.09939523954689058, 'info': {'data04': 0.09939523954689058, 'config': "{'batch_size': 32, 'hidden_dim': 670, 'last_n_outputs': 34, 'leak_rate': 0.8155199354756968, 'lr': 0.05479565846683718, 'optimizer': 'SGD', 'sparsity': 0.8682429805471091, 'steps_to_train': 62, 'weight_decay': 0.09098702279105031}"}}
exception: None

04:15:51 job_callback for (4, 0, 8) started
04:15:51 job_callback for (4, 0, 8) got condition
04:15:51 DISPATCHER: Trying to submit another job.
04:15:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:15:51 done building a new model for budget 44.444444 based on 10/30 split
Best loss for this budget:-0.189293





04:15:51 HBMASTER: Trying to run another job!
04:15:51 job_callback for (4, 0, 8) finished
04:15:51 start sampling a new configuration.
04:15:51 best_vector: [2, 0.8960645350971355, 0.4517564403889527, 0.7319120673686874, 0.5896540810752384, 1, 0.30656622227041086, 0.6540396607442814, 0.6802483047923665], 0.02553669183910292, 1.8230718075187666, 0.046555222949163096
04:15:51 done sampling a new configuration.
04:15:51 HBMASTER: schedule new run for iteration 4
04:15:51 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
04:15:51 HBMASTER: submitting job (4, 0, 9) to dispatcher
04:15:51 DISPATCHER: trying to submit job (4, 0, 9)
04:15:51 DISPATCHER: trying to notify the job_runner thread.
04:15:51 HBMASTER: job (4, 0, 9) submitted to dispatcher
04:15:51 DISPATCHER: Trying to submit another job.
04:15:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:15:51 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:15:51 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:15:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:15:51 WORKER: start processing job (4, 0, 9)
04:15:51 WORKER: args: ()
04:15:51 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 917, 'last_n_outputs': 28, 'leak_rate': 0.9329780168421719, 'lr': 0.015111520413400026, 'optimizer': 'SGD', 'sparsity': 0.8235758933448986, 'steps_to_train': 69, 'weight_decay': 0.07674029229340344}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:16:25 DISPATCHER: Starting worker discovery
04:16:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:16:25 DISPATCHER: Finished worker discovery
04:16:52 WORKER: done with job (4, 0, 9), trying to register it.
04:16:52 WORKER: registered result for job (4, 0, 9) with dispatcher
04:16:52 DISPATCHER: job (4, 0, 9) finished
04:16:52 DISPATCHER: register_result: lock acquired
04:16:52 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:16:52 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 917, 'last_n_outputs': 28, 'leak_rate': 0.9329780168421719, 'lr': 0.015111520413400026, 'optimizer': 'SGD', 'sparsity': 0.8235758933448986, 'steps_to_train': 69, 'weight_decay': 0.07674029229340344}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.16937742951307025, 'info': {'data04': 0.16937742951307025, 'config': "{'batch_size': 64, 'hidden_dim': 917, 'last_n_outputs': 28, 'leak_rate': 0.9329780168421719, 'lr': 0.015111520413400026, 'optimizer': 'SGD', 'sparsity': 0.8235758933448986, 'steps_to_train': 69, 'weight_decay': 0.07674029229340344}"}}
exception: None

04:16:52 job_callback for (4, 0, 9) started
04:16:52 DISPATCHER: Trying to submit another job.
04:16:52 job_callback for (4, 0, 9) got condition
04:16:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:16:52 done building a new model for budget 44.444444 based on 10/31 split
Best loss for this budget:-0.189293





04:16:52 HBMASTER: Trying to run another job!
04:16:52 job_callback for (4, 0, 9) finished
04:16:52 start sampling a new configuration.
04:16:52 best_vector: [2, 0.44338351057493564, 0.8858564037943034, 0.8839560718693805, 0.5797261152343052, 1, 0.35201720623362787, 0.8464079993564495, 0.3779064036056682], 0.011164645057113424, 2.086192900803822, 0.023291603258144507
04:16:52 done sampling a new configuration.
04:16:52 HBMASTER: schedule new run for iteration 4
04:16:52 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
04:16:52 HBMASTER: submitting job (4, 0, 10) to dispatcher
04:16:52 DISPATCHER: trying to submit job (4, 0, 10)
04:16:52 DISPATCHER: trying to notify the job_runner thread.
04:16:52 HBMASTER: job (4, 0, 10) submitted to dispatcher
04:16:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:16:52 DISPATCHER: Trying to submit another job.
04:16:52 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:16:52 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:16:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:16:52 WORKER: start processing job (4, 0, 10)
04:16:52 WORKER: args: ()
04:16:52 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 555, 'last_n_outputs': 46, 'leak_rate': 0.9709890179673452, 'lr': 0.01443617807110969, 'optimizer': 'SGD', 'sparsity': 0.8344841294960706, 'steps_to_train': 87, 'weight_decay': 0.03102184093372876}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:17:25 DISPATCHER: Starting worker discovery
04:17:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:17:25 DISPATCHER: Finished worker discovery
04:17:52 WORKER: done with job (4, 0, 10), trying to register it.
04:17:52 WORKER: registered result for job (4, 0, 10) with dispatcher
04:17:52 DISPATCHER: job (4, 0, 10) finished
04:17:52 DISPATCHER: register_result: lock acquired
04:17:52 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:17:52 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 555, 'last_n_outputs': 46, 'leak_rate': 0.9709890179673452, 'lr': 0.01443617807110969, 'optimizer': 'SGD', 'sparsity': 0.8344841294960706, 'steps_to_train': 87, 'weight_decay': 0.03102184093372876}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.16205949989082405, 'info': {'data04': 0.16205949989082405, 'config': "{'batch_size': 64, 'hidden_dim': 555, 'last_n_outputs': 46, 'leak_rate': 0.9709890179673452, 'lr': 0.01443617807110969, 'optimizer': 'SGD', 'sparsity': 0.8344841294960706, 'steps_to_train': 87, 'weight_decay': 0.03102184093372876}"}}
exception: None

04:17:52 job_callback for (4, 0, 10) started
04:17:52 DISPATCHER: Trying to submit another job.
04:17:52 job_callback for (4, 0, 10) got condition
04:17:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:17:52 done building a new model for budget 44.444444 based on 10/32 split
Best loss for this budget:-0.189293





04:17:52 HBMASTER: Trying to run another job!
04:17:52 job_callback for (4, 0, 10) finished
04:17:52 start sampling a new configuration.
04:17:52 best_vector: [0, 0.7410429388807183, 0.45737364568285943, 0.9675757667084645, 0.7125021896331141, 1, 0.32922849764083256, 0.5972086871728963, 0.35390926005024526], 0.009332073351662258, 0.8405283089685037, 0.007843871833442715
04:17:52 done sampling a new configuration.
04:17:52 HBMASTER: schedule new run for iteration 4
04:17:52 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
04:17:52 HBMASTER: submitting job (4, 0, 11) to dispatcher
04:17:52 DISPATCHER: trying to submit job (4, 0, 11)
04:17:52 DISPATCHER: trying to notify the job_runner thread.
04:17:52 HBMASTER: job (4, 0, 11) submitted to dispatcher
04:17:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:17:52 DISPATCHER: Trying to submit another job.
04:17:52 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:17:52 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:17:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:17:52 WORKER: start processing job (4, 0, 11)
04:17:52 WORKER: args: ()
04:17:52 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 793, 'last_n_outputs': 28, 'leak_rate': 0.9918939416771161, 'lr': 0.026607518897094583, 'optimizer': 'SGD', 'sparsity': 0.8290148394337998, 'steps_to_train': 64, 'weight_decay': 0.02886998532137945}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:18:25 DISPATCHER: Starting worker discovery
04:18:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:18:25 DISPATCHER: Finished worker discovery
04:18:54 WORKER: done with job (4, 0, 11), trying to register it.
04:18:54 WORKER: registered result for job (4, 0, 11) with dispatcher
04:18:54 DISPATCHER: job (4, 0, 11) finished
04:18:54 DISPATCHER: register_result: lock acquired
04:18:54 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:18:54 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 793, 'last_n_outputs': 28, 'leak_rate': 0.9918939416771161, 'lr': 0.026607518897094583, 'optimizer': 'SGD', 'sparsity': 0.8290148394337998, 'steps_to_train': 64, 'weight_decay': 0.02886998532137945}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.14413677976275066, 'info': {'data04': 0.14413677976275066, 'config': "{'batch_size': 16, 'hidden_dim': 793, 'last_n_outputs': 28, 'leak_rate': 0.9918939416771161, 'lr': 0.026607518897094583, 'optimizer': 'SGD', 'sparsity': 0.8290148394337998, 'steps_to_train': 64, 'weight_decay': 0.02886998532137945}"}}
exception: None

04:18:54 job_callback for (4, 0, 11) started
04:18:54 job_callback for (4, 0, 11) got condition
04:18:54 DISPATCHER: Trying to submit another job.
04:18:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:18:54 done building a new model for budget 44.444444 based on 10/33 split
Best loss for this budget:-0.189293





04:18:54 HBMASTER: Trying to run another job!
04:18:54 job_callback for (4, 0, 11) finished
04:18:54 start sampling a new configuration.
04:18:54 best_vector: [0, 0.8819145468860572, 0.6318503693421087, 0.8699725318433018, 0.8750414446033326, 1, 0.06274081366781706, 0.02161653302885827, 0.11504903139713413], 0.003618760880227996, 0.016041630248989046, 5.805082400012364e-05
04:18:54 done sampling a new configuration.
04:18:54 HBMASTER: schedule new run for iteration 4
04:18:54 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
04:18:54 HBMASTER: submitting job (4, 0, 12) to dispatcher
04:18:54 DISPATCHER: trying to submit job (4, 0, 12)
04:18:54 DISPATCHER: trying to notify the job_runner thread.
04:18:54 HBMASTER: job (4, 0, 12) submitted to dispatcher
04:18:54 DISPATCHER: Trying to submit another job.
04:18:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:18:54 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:18:54 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:18:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:18:54 WORKER: start processing job (4, 0, 12)
04:18:54 WORKER: args: ()
04:18:54 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 906, 'last_n_outputs': 35, 'leak_rate': 0.9674931329608254, 'lr': 0.05624486635902566, 'optimizer': 'SGD', 'sparsity': 0.7650577952802761, 'steps_to_train': 11, 'weight_decay': 0.01411504414735854}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:19:25 DISPATCHER: Starting worker discovery
04:19:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:19:25 DISPATCHER: Finished worker discovery
04:19:59 WORKER: done with job (4, 0, 12), trying to register it.
04:19:59 WORKER: registered result for job (4, 0, 12) with dispatcher
04:19:59 DISPATCHER: job (4, 0, 12) finished
04:19:59 DISPATCHER: register_result: lock acquired
04:19:59 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:19:59 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 906, 'last_n_outputs': 35, 'leak_rate': 0.9674931329608254, 'lr': 0.05624486635902566, 'optimizer': 'SGD', 'sparsity': 0.7650577952802761, 'steps_to_train': 11, 'weight_decay': 0.01411504414735854}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1487588519751842, 'info': {'data04': 0.1487588519751842, 'config': "{'batch_size': 16, 'hidden_dim': 906, 'last_n_outputs': 35, 'leak_rate': 0.9674931329608254, 'lr': 0.05624486635902566, 'optimizer': 'SGD', 'sparsity': 0.7650577952802761, 'steps_to_train': 11, 'weight_decay': 0.01411504414735854}"}}
exception: None

04:19:59 job_callback for (4, 0, 12) started
04:19:59 job_callback for (4, 0, 12) got condition
04:19:59 DISPATCHER: Trying to submit another job.
04:19:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:19:59 done building a new model for budget 44.444444 based on 10/34 split
Best loss for this budget:-0.189293





04:19:59 HBMASTER: Trying to run another job!
04:19:59 job_callback for (4, 0, 12) finished
04:19:59 start sampling a new configuration.
04:19:59 done sampling a new configuration.
04:19:59 HBMASTER: schedule new run for iteration 4
04:19:59 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
04:19:59 HBMASTER: submitting job (4, 0, 13) to dispatcher
04:19:59 DISPATCHER: trying to submit job (4, 0, 13)
04:19:59 DISPATCHER: trying to notify the job_runner thread.
04:19:59 HBMASTER: job (4, 0, 13) submitted to dispatcher
04:19:59 DISPATCHER: Trying to submit another job.
04:19:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:19:59 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:19:59 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:19:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:19:59 WORKER: start processing job (4, 0, 13)
04:19:59 WORKER: args: ()
04:19:59 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 739, 'last_n_outputs': 38, 'leak_rate': 0.8931047845752151, 'lr': 0.06005123921899758, 'optimizer': 'Adam', 'sparsity': 0.7879075804796307, 'steps_to_train': 92, 'weight_decay': 0.013402441019365673}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:20:25 DISPATCHER: Starting worker discovery
04:20:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:20:25 DISPATCHER: Finished worker discovery
04:21:01 WORKER: done with job (4, 0, 13), trying to register it.
04:21:01 WORKER: registered result for job (4, 0, 13) with dispatcher
04:21:01 DISPATCHER: job (4, 0, 13) finished
04:21:01 DISPATCHER: register_result: lock acquired
04:21:01 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:21:01 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 739, 'last_n_outputs': 38, 'leak_rate': 0.8931047845752151, 'lr': 0.06005123921899758, 'optimizer': 'Adam', 'sparsity': 0.7879075804796307, 'steps_to_train': 92, 'weight_decay': 0.013402441019365673}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.019841678446936045, 'info': {'data04': 0.019841678446936045, 'config': "{'batch_size': 32, 'hidden_dim': 739, 'last_n_outputs': 38, 'leak_rate': 0.8931047845752151, 'lr': 0.06005123921899758, 'optimizer': 'Adam', 'sparsity': 0.7879075804796307, 'steps_to_train': 92, 'weight_decay': 0.013402441019365673}"}}
exception: None

04:21:01 job_callback for (4, 0, 13) started
04:21:01 job_callback for (4, 0, 13) got condition
04:21:01 DISPATCHER: Trying to submit another job.
04:21:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:21:01 done building a new model for budget 44.444444 based on 10/34 split
Best loss for this budget:-0.189293





04:21:01 HBMASTER: Trying to run another job!
04:21:01 job_callback for (4, 0, 13) finished
04:21:01 start sampling a new configuration.
04:21:01 sampled vector: [3, 0.24908709411111474, 0.47739812564165146, 0.026058996249466282, 0.6706139077660872, 0, 0.7265793186971325, 0.5992413678936397, 0.595017618771761] has EI value nan
04:21:01 data in the KDEs:
[[3.         0.28526841 0.59756102 0.88444633 0.61256658 1.
  0.15878639 0.20329664 0.15175895]
 [0.         0.83333334 0.62195128 0.60540606 0.51949976 1.
  0.26169293 0.63186816 0.027787  ]
 [3.         0.91822723 0.57317077 0.60308056 0.48328355 1.
  0.47648461 0.71978027 0.55770103]
 [3.         0.18789013 0.76829281 0.9696463  0.57686415 1.
  0.48481071 0.56593408 0.27321636]
 [3.         0.10174781 0.74390256 0.75707214 0.63841269 1.
  0.7068577  0.95054955 0.85128492]
 [2.         0.89575532 0.45121949 0.73191207 0.58965408 1.
  0.30656622 0.65384619 0.6802483 ]
 [3.         0.43258427 0.9390246  0.74358069 0.26746076 1.
  0.36498433 0.9065935  0.50129168]
 [2.         0.44382022 0.89024409 0.88395607 0.57972612 1.
  0.35201721 0.85164843 0.3779064 ]
 [3.         0.29151061 0.10975591 0.17268955 0.76129219 1.
  0.60779675 0.37912085 0.15306726]
 [0.         0.95692885 0.13414616 0.01432995 0.59749585 1.
  0.1492884  0.02747242 0.19666101]]
[[0.         0.83083646 0.64634153 0.87505936 0.47796791 1.
  0.42843374 0.87362646 0.47701047]
 [1.         0.19163545 0.7195123  0.91409939 0.71623053 1.
  0.68725199 0.98351659 0.73626851]
 [2.         0.30898876 0.81707333 0.42625917 0.46554395 1.
  0.54133597 0.70879125 0.90338677]
 [1.         0.93196006 0.37804872 0.96797353 0.16834002 1.
  0.50904963 0.98351659 0.56149508]
 [3.         0.67602997 0.37804872 0.85258002 0.83037636 1.
  0.83598371 0.93956054 0.8416321 ]
 [0.         0.93695382 0.69512205 0.56532284 0.56077125 1.
  0.30195022 0.13736256 0.83437231]
 [0.         0.88202248 0.62195128 0.86997253 0.87504144 1.
  0.06274081 0.01648341 0.11504903]
 [3.         0.47378277 0.03658514 0.41678678 0.73871958 1.
  0.97287933 0.69780224 0.54906912]
 [2.         0.04931335 0.18292667 0.38663036 0.84423678 1.
  0.66436923 0.59890112 0.30490571]
 [0.         0.74094882 0.45121949 0.96757577 0.71250219 1.
  0.3292285  0.59890112 0.35390926]
 [2.         0.9269663  0.15853642 0.60962186 0.27860049 1.
  0.8969038  0.80769238 0.35714941]
 [0.         0.90823971 0.40243898 0.17769026 0.79938813 1.
  0.82664763 0.07142848 0.37179759]
 [2.         0.47503121 0.32926821 0.16799696 0.18545639 0.
  0.91713473 0.63186816 0.16074296]
 [3.         0.33770287 0.32926821 0.12563461 0.27884638 1.
  0.48170373 0.47802197 0.40460098]
 [3.         0.85705369 0.18292667 0.50441392 0.31997778 0.
  0.45564787 0.91758251 0.07947321]
 [1.         0.58739076 0.59756102 0.26207974 0.86937308 1.
  0.49267909 0.57692309 0.7370925 ]
 [1.         0.34019975 0.0609754  0.73673649 0.19799476 0.
  0.22229415 0.8296704  0.15322758]
 [3.         0.8320849  0.25609744 0.89892085 0.20528811 0.
  0.37702472 0.9945056  0.7602068 ]
 [3.         0.91573035 0.45121949 0.41024648 0.35076995 0.
  0.55802676 0.91758251 0.28552892]
 [3.         0.09925093 0.59756102 0.89851892 0.37091805 0.
  0.47929512 0.25824171 0.52506039]
 [3.         0.34893882 0.76829281 0.49114325 0.12425809 0.
  0.14087876 0.8296704  0.53912367]
 [3.         0.46629213 0.86585384 0.67312217 0.31122907 0.
  0.74791868 0.67582421 0.56853505]
 [0.         0.71598003 0.0609754  0.33652498 0.34609256 0.
  0.74897112 0.1703296  0.24276282]
 [3.         0.04806491 0.42682923 0.67220899 0.91823564 0.
  0.1990947  0.58791211 0.00739772]
 [0.         0.48751561 0.18292667 0.49915054 0.13360685 0.
  0.63655071 0.54395605 0.52149642]
 [0.         0.66104869 0.45121949 0.56420939 0.05612927 0.
  0.21553244 0.53296704 0.65562666]
 [3.         0.00811484 0.67073179 0.70491496 0.59893573 0.
  0.14319997 0.02747242 0.04297933]
 [3.         0.6360799  0.96341486 0.19873104 0.80494861 0.
  0.93648756 0.58791211 0.01454234]
 [1.         0.67353309 0.69512205 0.57241914 0.88926099 0.
  0.15794825 0.9065935  0.09775632]
 [3.         0.69225968 0.98780512 0.89561777 0.94624109 0.
  0.97214005 0.44505493 0.85500677]
 [2.         0.67852685 0.84146358 0.44551121 0.86857331 0.
  0.21822537 0.86263744 0.48081459]]
04:21:01 bandwidth of the KDEs:
[1.03550510e+00 2.79761416e-01 2.39249062e-01 2.62371116e-01
 1.07078555e-01 1.00000000e-03 1.54077823e-01 2.56178383e-01
 2.23070540e-01]
[1.01212335 0.23294623 0.2202362  0.20763705 0.23494676 0.40505362
 0.22492779 0.23934392 0.21871005]
04:21:01 l(x) = nan
04:21:01 g(x) = 0.020505167173399626
04:21:01 best_vector: [0, 0.8993570532749421, 0.9986560798440849, 0.572326937227671, 0.5313077353237687, 1, 0.5263550398010959, 0.5289256459024434, 0.21961779470227644], 0.02844540741518154, 0.34547249070296643, 0.009827105748783397
04:21:01 done sampling a new configuration.
04:21:01 HBMASTER: schedule new run for iteration 4
04:21:01 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
04:21:01 HBMASTER: submitting job (4, 0, 14) to dispatcher
04:21:01 DISPATCHER: trying to submit job (4, 0, 14)
04:21:01 DISPATCHER: trying to notify the job_runner thread.
04:21:01 HBMASTER: job (4, 0, 14) submitted to dispatcher
04:21:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:21:01 DISPATCHER: Trying to submit another job.
04:21:01 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:21:01 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:21:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:21:01 WORKER: start processing job (4, 0, 14)
04:21:01 WORKER: args: ()
04:21:01 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 920, 'last_n_outputs': 50, 'leak_rate': 0.8930817343069177, 'lr': 0.011550890600896903, 'optimizer': 'SGD', 'sparsity': 0.876325209552263, 'steps_to_train': 58, 'weight_decay': 0.01930764648596214}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:21:25 DISPATCHER: Starting worker discovery
04:21:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:21:25 DISPATCHER: Finished worker discovery
04:22:02 WORKER: done with job (4, 0, 14), trying to register it.
04:22:02 WORKER: registered result for job (4, 0, 14) with dispatcher
04:22:02 DISPATCHER: job (4, 0, 14) finished
04:22:02 DISPATCHER: register_result: lock acquired
04:22:02 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:22:02 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 920, 'last_n_outputs': 50, 'leak_rate': 0.8930817343069177, 'lr': 0.011550890600896903, 'optimizer': 'SGD', 'sparsity': 0.876325209552263, 'steps_to_train': 58, 'weight_decay': 0.01930764648596214}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1406946594810153, 'info': {'data04': 0.1406946594810153, 'config': "{'batch_size': 16, 'hidden_dim': 920, 'last_n_outputs': 50, 'leak_rate': 0.8930817343069177, 'lr': 0.011550890600896903, 'optimizer': 'SGD', 'sparsity': 0.876325209552263, 'steps_to_train': 58, 'weight_decay': 0.01930764648596214}"}}
exception: None

04:22:02 job_callback for (4, 0, 14) started
04:22:02 DISPATCHER: Trying to submit another job.
04:22:02 job_callback for (4, 0, 14) got condition
04:22:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:22:02 done building a new model for budget 44.444444 based on 10/35 split
Best loss for this budget:-0.189293





04:22:02 HBMASTER: Trying to run another job!
04:22:02 job_callback for (4, 0, 14) finished
04:22:02 start sampling a new configuration.
04:22:02 done sampling a new configuration.
04:22:02 HBMASTER: schedule new run for iteration 4
04:22:02 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
04:22:02 HBMASTER: submitting job (4, 0, 15) to dispatcher
04:22:02 DISPATCHER: trying to submit job (4, 0, 15)
04:22:02 DISPATCHER: trying to notify the job_runner thread.
04:22:02 HBMASTER: job (4, 0, 15) submitted to dispatcher
04:22:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:22:02 DISPATCHER: Trying to submit another job.
04:22:02 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:22:02 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:22:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:22:02 WORKER: start processing job (4, 0, 15)
04:22:02 WORKER: args: ()
04:22:02 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 870, 'last_n_outputs': 24, 'leak_rate': 0.9608281808831473, 'lr': 0.0012597450116121857, 'optimizer': 'SGD', 'sparsity': 0.870470462141759, 'steps_to_train': 52, 'weight_decay': 0.09106375278315906}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:22:25 DISPATCHER: Starting worker discovery
04:22:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:22:25 DISPATCHER: Finished worker discovery
04:23:03 WORKER: done with job (4, 0, 15), trying to register it.
04:23:03 WORKER: registered result for job (4, 0, 15) with dispatcher
04:23:03 DISPATCHER: job (4, 0, 15) finished
04:23:03 DISPATCHER: register_result: lock acquired
04:23:03 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:23:03 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 870, 'last_n_outputs': 24, 'leak_rate': 0.9608281808831473, 'lr': 0.0012597450116121857, 'optimizer': 'SGD', 'sparsity': 0.870470462141759, 'steps_to_train': 52, 'weight_decay': 0.09106375278315906}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.12809728101814485, 'info': {'data04': 0.12809728101814485, 'config': "{'batch_size': 64, 'hidden_dim': 870, 'last_n_outputs': 24, 'leak_rate': 0.9608281808831473, 'lr': 0.0012597450116121857, 'optimizer': 'SGD', 'sparsity': 0.870470462141759, 'steps_to_train': 52, 'weight_decay': 0.09106375278315906}"}}
exception: None

04:23:03 job_callback for (4, 0, 15) started
04:23:03 job_callback for (4, 0, 15) got condition
04:23:03 DISPATCHER: Trying to submit another job.
04:23:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:23:03 done building a new model for budget 44.444444 based on 10/36 split
Best loss for this budget:-0.189293





04:23:03 HBMASTER: Trying to run another job!
04:23:03 job_callback for (4, 0, 15) finished
04:23:03 start sampling a new configuration.
04:23:03 best_vector: [1, 0.5546366791409076, 0.17991183014568163, 0.0898775795368425, 0.9170719791323, 1, 0.693461461806516, 0.5662733064443554, 0.03903433498154851], 0.017382623674510118, 0.5879390378654299, 0.010219923038768322
04:23:03 done sampling a new configuration.
04:23:03 HBMASTER: schedule new run for iteration 4
04:23:03 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
04:23:03 HBMASTER: submitting job (4, 0, 16) to dispatcher
04:23:03 DISPATCHER: trying to submit job (4, 0, 16)
04:23:03 DISPATCHER: trying to notify the job_runner thread.
04:23:03 HBMASTER: job (4, 0, 16) submitted to dispatcher
04:23:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:23:03 DISPATCHER: Trying to submit another job.
04:23:03 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:23:03 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:23:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:23:03 WORKER: start processing job (4, 0, 16)
04:23:03 WORKER: args: ()
04:23:03 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 644, 'last_n_outputs': 17, 'leak_rate': 0.7724693948842106, 'lr': 0.0682564910638401, 'optimizer': 'SGD', 'sparsity': 0.9164307508335638, 'steps_to_train': 61, 'weight_decay': 0.011240479571680678}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:23:25 DISPATCHER: Starting worker discovery
04:23:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:23:25 DISPATCHER: Finished worker discovery
04:24:03 WORKER: done with job (4, 0, 16), trying to register it.
04:24:03 WORKER: registered result for job (4, 0, 16) with dispatcher
04:24:03 DISPATCHER: job (4, 0, 16) finished
04:24:03 DISPATCHER: register_result: lock acquired
04:24:03 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:24:03 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 644, 'last_n_outputs': 17, 'leak_rate': 0.7724693948842106, 'lr': 0.0682564910638401, 'optimizer': 'SGD', 'sparsity': 0.9164307508335638, 'steps_to_train': 61, 'weight_decay': 0.011240479571680678}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.17042086777583126, 'info': {'data04': 0.17042086777583126, 'config': "{'batch_size': 32, 'hidden_dim': 644, 'last_n_outputs': 17, 'leak_rate': 0.7724693948842106, 'lr': 0.0682564910638401, 'optimizer': 'SGD', 'sparsity': 0.9164307508335638, 'steps_to_train': 61, 'weight_decay': 0.011240479571680678}"}}
exception: None

04:24:03 job_callback for (4, 0, 16) started
04:24:03 job_callback for (4, 0, 16) got condition
04:24:03 DISPATCHER: Trying to submit another job.
04:24:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:24:03 done building a new model for budget 44.444444 based on 10/37 split
Best loss for this budget:-0.189293





04:24:03 HBMASTER: Trying to run another job!
04:24:03 job_callback for (4, 0, 16) finished
04:24:03 start sampling a new configuration.
04:24:03 done sampling a new configuration.
04:24:03 HBMASTER: schedule new run for iteration 4
04:24:03 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
04:24:03 HBMASTER: submitting job (4, 0, 17) to dispatcher
04:24:03 DISPATCHER: trying to submit job (4, 0, 17)
04:24:03 DISPATCHER: trying to notify the job_runner thread.
04:24:03 HBMASTER: job (4, 0, 17) submitted to dispatcher
04:24:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:24:03 DISPATCHER: Trying to submit another job.
04:24:03 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:24:03 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:24:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:24:03 WORKER: start processing job (4, 0, 17)
04:24:03 WORKER: args: ()
04:24:03 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 842, 'last_n_outputs': 27, 'leak_rate': 0.9309907318374971, 'lr': 0.006141342556204983, 'optimizer': 'SGD', 'sparsity': 0.7559847334562515, 'steps_to_train': 16, 'weight_decay': 0.013031576387894959}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:24:25 DISPATCHER: Starting worker discovery
04:24:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:24:25 DISPATCHER: Finished worker discovery
04:25:06 WORKER: done with job (4, 0, 17), trying to register it.
04:25:06 WORKER: registered result for job (4, 0, 17) with dispatcher
04:25:06 DISPATCHER: job (4, 0, 17) finished
04:25:06 DISPATCHER: register_result: lock acquired
04:25:06 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:25:06 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 842, 'last_n_outputs': 27, 'leak_rate': 0.9309907318374971, 'lr': 0.006141342556204983, 'optimizer': 'SGD', 'sparsity': 0.7559847334562515, 'steps_to_train': 16, 'weight_decay': 0.013031576387894959}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.15829551786645676, 'info': {'data04': 0.15829551786645676, 'config': "{'batch_size': 128, 'hidden_dim': 842, 'last_n_outputs': 27, 'leak_rate': 0.9309907318374971, 'lr': 0.006141342556204983, 'optimizer': 'SGD', 'sparsity': 0.7559847334562515, 'steps_to_train': 16, 'weight_decay': 0.013031576387894959}"}}
exception: None

04:25:06 job_callback for (4, 0, 17) started
04:25:06 DISPATCHER: Trying to submit another job.
04:25:06 job_callback for (4, 0, 17) got condition
04:25:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:25:06 done building a new model for budget 44.444444 based on 10/38 split
Best loss for this budget:-0.189293





04:25:06 HBMASTER: Trying to run another job!
04:25:06 job_callback for (4, 0, 17) finished
04:25:06 start sampling a new configuration.
04:25:06 best_vector: [3, 0.0048486860566197, 0.5008882273974667, 0.7912514638344172, 0.49996765736568965, 1, 0.1303054121529133, 0.21525643909762837, 0.79223457854562], 9.611132397049304e-31, 0.010404601234158508, -0.00039358341391806657
04:25:06 done sampling a new configuration.
04:25:06 HBMASTER: schedule new run for iteration 4
04:25:06 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
04:25:06 HBMASTER: submitting job (4, 0, 18) to dispatcher
04:25:06 DISPATCHER: trying to submit job (4, 0, 18)
04:25:06 DISPATCHER: trying to notify the job_runner thread.
04:25:06 HBMASTER: job (4, 0, 18) submitted to dispatcher
04:25:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:25:06 DISPATCHER: Trying to submit another job.
04:25:06 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:25:06 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:25:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:25:06 WORKER: start processing job (4, 0, 18)
04:25:06 WORKER: args: ()
04:25:06 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 203, 'last_n_outputs': 30, 'leak_rate': 0.9478128659586043, 'lr': 0.009998510677562458, 'optimizer': 'SGD', 'sparsity': 0.7812732989166992, 'steps_to_train': 29, 'weight_decay': 0.10732995574518517}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:25:25 DISPATCHER: Starting worker discovery
04:25:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:25:25 DISPATCHER: Finished worker discovery
04:26:07 WORKER: done with job (4, 0, 18), trying to register it.
04:26:07 WORKER: registered result for job (4, 0, 18) with dispatcher
04:26:07 DISPATCHER: job (4, 0, 18) finished
04:26:07 DISPATCHER: register_result: lock acquired
04:26:07 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:26:07 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 203, 'last_n_outputs': 30, 'leak_rate': 0.9478128659586043, 'lr': 0.009998510677562458, 'optimizer': 'SGD', 'sparsity': 0.7812732989166992, 'steps_to_train': 29, 'weight_decay': 0.10732995574518517}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.13651330277769588, 'info': {'data04': 0.13651330277769588, 'config': "{'batch_size': 128, 'hidden_dim': 203, 'last_n_outputs': 30, 'leak_rate': 0.9478128659586043, 'lr': 0.009998510677562458, 'optimizer': 'SGD', 'sparsity': 0.7812732989166992, 'steps_to_train': 29, 'weight_decay': 0.10732995574518517}"}}
exception: None

04:26:07 job_callback for (4, 0, 18) started
04:26:07 DISPATCHER: Trying to submit another job.
04:26:07 job_callback for (4, 0, 18) got condition
04:26:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:26:07 done building a new model for budget 44.444444 based on 10/39 split
Best loss for this budget:-0.189293





04:26:07 HBMASTER: Trying to run another job!
04:26:07 job_callback for (4, 0, 18) finished
04:26:07 start sampling a new configuration.
04:26:07 best_vector: [2, 0.801705921766051, 0.12304945837239833, 0.6834219243140918, 0.4747807966102806, 0, 0.5900216428361263, 0.7259529565845703, 0.12119004515933249], 0.0, inf, 0.12799877674468593
04:26:07 done sampling a new configuration.
04:26:07 HBMASTER: schedule new run for iteration 4
04:26:07 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
04:26:07 HBMASTER: submitting job (4, 0, 19) to dispatcher
04:26:07 DISPATCHER: trying to submit job (4, 0, 19)
04:26:07 DISPATCHER: trying to notify the job_runner thread.
04:26:07 HBMASTER: job (4, 0, 19) submitted to dispatcher
04:26:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:26:07 DISPATCHER: Trying to submit another job.
04:26:07 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:26:07 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:26:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:26:07 WORKER: start processing job (4, 0, 19)
04:26:07 WORKER: args: ()
04:26:07 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 842, 'last_n_outputs': 15, 'leak_rate': 0.920855481078523, 'lr': 0.00890351701968073, 'optimizer': 'Adam', 'sparsity': 0.8916051942806703, 'steps_to_train': 76, 'weight_decay': 0.014377119546270896}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:26:25 DISPATCHER: Starting worker discovery
04:26:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:26:25 DISPATCHER: Finished worker discovery
04:27:08 WORKER: done with job (4, 0, 19), trying to register it.
04:27:08 WORKER: registered result for job (4, 0, 19) with dispatcher
04:27:08 DISPATCHER: job (4, 0, 19) finished
04:27:08 DISPATCHER: register_result: lock acquired
04:27:08 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:27:08 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 842, 'last_n_outputs': 15, 'leak_rate': 0.920855481078523, 'lr': 0.00890351701968073, 'optimizer': 'Adam', 'sparsity': 0.8916051942806703, 'steps_to_train': 76, 'weight_decay': 0.014377119546270896}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.08293244227202672, 'info': {'data04': 0.08293244227202672, 'config': "{'batch_size': 64, 'hidden_dim': 842, 'last_n_outputs': 15, 'leak_rate': 0.920855481078523, 'lr': 0.00890351701968073, 'optimizer': 'Adam', 'sparsity': 0.8916051942806703, 'steps_to_train': 76, 'weight_decay': 0.014377119546270896}"}}
exception: None

04:27:08 job_callback for (4, 0, 19) started
04:27:08 job_callback for (4, 0, 19) got condition
04:27:08 DISPATCHER: Trying to submit another job.
04:27:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:27:08 done building a new model for budget 44.444444 based on 10/39 split
Best loss for this budget:-0.189293





04:27:08 HBMASTER: Trying to run another job!
04:27:08 job_callback for (4, 0, 19) finished
04:27:08 start sampling a new configuration.
04:27:08 done sampling a new configuration.
04:27:08 HBMASTER: schedule new run for iteration 4
04:27:08 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
04:27:08 HBMASTER: submitting job (4, 0, 20) to dispatcher
04:27:08 DISPATCHER: trying to submit job (4, 0, 20)
04:27:08 DISPATCHER: trying to notify the job_runner thread.
04:27:08 HBMASTER: job (4, 0, 20) submitted to dispatcher
04:27:08 DISPATCHER: Trying to submit another job.
04:27:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:27:08 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:27:08 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:27:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:27:08 WORKER: start processing job (4, 0, 20)
04:27:08 WORKER: args: ()
04:27:08 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 983, 'last_n_outputs': 14, 'leak_rate': 0.9527318324369188, 'lr': 0.0010365776270927283, 'optimizer': 'SGD', 'sparsity': 0.8726156869323511, 'steps_to_train': 92, 'weight_decay': 0.07094032109298214}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:27:25 DISPATCHER: Starting worker discovery
04:27:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:27:25 DISPATCHER: Finished worker discovery
04:28:10 WORKER: done with job (4, 0, 20), trying to register it.
04:28:10 WORKER: registered result for job (4, 0, 20) with dispatcher
04:28:10 DISPATCHER: job (4, 0, 20) finished
04:28:10 DISPATCHER: register_result: lock acquired
04:28:10 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:28:10 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 983, 'last_n_outputs': 14, 'leak_rate': 0.9527318324369188, 'lr': 0.0010365776270927283, 'optimizer': 'SGD', 'sparsity': 0.8726156869323511, 'steps_to_train': 92, 'weight_decay': 0.07094032109298214}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.11058912565078173, 'info': {'data04': 0.11058912565078173, 'config': "{'batch_size': 16, 'hidden_dim': 983, 'last_n_outputs': 14, 'leak_rate': 0.9527318324369188, 'lr': 0.0010365776270927283, 'optimizer': 'SGD', 'sparsity': 0.8726156869323511, 'steps_to_train': 92, 'weight_decay': 0.07094032109298214}"}}
exception: None

04:28:10 job_callback for (4, 0, 20) started
04:28:10 job_callback for (4, 0, 20) got condition
04:28:10 DISPATCHER: Trying to submit another job.
04:28:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:28:10 done building a new model for budget 44.444444 based on 10/40 split
Best loss for this budget:-0.189293





04:28:10 HBMASTER: Trying to run another job!
04:28:10 job_callback for (4, 0, 20) finished
04:28:10 start sampling a new configuration.
04:28:10 best_vector: [3, 0.17138086432357952, 0.1515497807797807, 0.7070231418038708, 0.7307157676713617, 1, 0.08464824184408677, 0.21741049417982322, 0.47071944811915456], 0.023087978772260452, 0.03301285379966096, 0.00076220006773831
04:28:10 done sampling a new configuration.
04:28:10 HBMASTER: schedule new run for iteration 4
04:28:10 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
04:28:10 HBMASTER: submitting job (4, 0, 21) to dispatcher
04:28:10 DISPATCHER: trying to submit job (4, 0, 21)
04:28:10 DISPATCHER: trying to notify the job_runner thread.
04:28:10 HBMASTER: job (4, 0, 21) submitted to dispatcher
04:28:10 DISPATCHER: Trying to submit another job.
04:28:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:28:10 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:28:10 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:28:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:28:10 WORKER: start processing job (4, 0, 21)
04:28:10 WORKER: args: ()
04:28:10 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 337, 'last_n_outputs': 16, 'leak_rate': 0.9267557854509677, 'lr': 0.02893553624823134, 'optimizer': 'SGD', 'sparsity': 0.7703155780425808, 'steps_to_train': 29, 'weight_decay': 0.04096567559708777}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:28:25 DISPATCHER: Starting worker discovery
04:28:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:28:25 DISPATCHER: Finished worker discovery
04:29:12 WORKER: done with job (4, 0, 21), trying to register it.
04:29:12 WORKER: registered result for job (4, 0, 21) with dispatcher
04:29:12 DISPATCHER: job (4, 0, 21) finished
04:29:12 DISPATCHER: register_result: lock acquired
04:29:12 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:29:12 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 337, 'last_n_outputs': 16, 'leak_rate': 0.9267557854509677, 'lr': 0.02893553624823134, 'optimizer': 'SGD', 'sparsity': 0.7703155780425808, 'steps_to_train': 29, 'weight_decay': 0.04096567559708777}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.16107009251024812, 'info': {'data04': 0.16107009251024812, 'config': "{'batch_size': 128, 'hidden_dim': 337, 'last_n_outputs': 16, 'leak_rate': 0.9267557854509677, 'lr': 0.02893553624823134, 'optimizer': 'SGD', 'sparsity': 0.7703155780425808, 'steps_to_train': 29, 'weight_decay': 0.04096567559708777}"}}
exception: None

04:29:12 job_callback for (4, 0, 21) started
04:29:12 job_callback for (4, 0, 21) got condition
04:29:12 DISPATCHER: Trying to submit another job.
04:29:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:29:12 done building a new model for budget 44.444444 based on 10/41 split
Best loss for this budget:-0.189293





04:29:12 HBMASTER: Trying to run another job!
04:29:12 job_callback for (4, 0, 21) finished
04:29:12 start sampling a new configuration.
04:29:12 done sampling a new configuration.
04:29:12 HBMASTER: schedule new run for iteration 4
04:29:12 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
04:29:12 HBMASTER: submitting job (4, 0, 22) to dispatcher
04:29:12 DISPATCHER: trying to submit job (4, 0, 22)
04:29:12 DISPATCHER: trying to notify the job_runner thread.
04:29:12 HBMASTER: job (4, 0, 22) submitted to dispatcher
04:29:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:29:12 DISPATCHER: Trying to submit another job.
04:29:12 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:29:12 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:29:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:29:12 WORKER: start processing job (4, 0, 22)
04:29:12 WORKER: args: ()
04:29:12 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 647, 'last_n_outputs': 14, 'leak_rate': 0.9328545571268564, 'lr': 0.0030439895408173575, 'optimizer': 'Adam', 'sparsity': 0.8711567840348087, 'steps_to_train': 58, 'weight_decay': 0.0753511689224567}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:29:25 DISPATCHER: Starting worker discovery
04:29:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:29:25 DISPATCHER: Finished worker discovery
04:30:14 WORKER: done with job (4, 0, 22), trying to register it.
04:30:14 WORKER: registered result for job (4, 0, 22) with dispatcher
04:30:14 DISPATCHER: job (4, 0, 22) finished
04:30:14 DISPATCHER: register_result: lock acquired
04:30:14 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:30:14 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 647, 'last_n_outputs': 14, 'leak_rate': 0.9328545571268564, 'lr': 0.0030439895408173575, 'optimizer': 'Adam', 'sparsity': 0.8711567840348087, 'steps_to_train': 58, 'weight_decay': 0.0753511689224567}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.053534499036888894, 'info': {'data04': 0.053534499036888894, 'config': "{'batch_size': 64, 'hidden_dim': 647, 'last_n_outputs': 14, 'leak_rate': 0.9328545571268564, 'lr': 0.0030439895408173575, 'optimizer': 'Adam', 'sparsity': 0.8711567840348087, 'steps_to_train': 58, 'weight_decay': 0.0753511689224567}"}}
exception: None

04:30:14 job_callback for (4, 0, 22) started
04:30:14 DISPATCHER: Trying to submit another job.
04:30:14 job_callback for (4, 0, 22) got condition
04:30:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:30:14 done building a new model for budget 44.444444 based on 10/42 split
Best loss for this budget:-0.189293





04:30:14 HBMASTER: Trying to run another job!
04:30:14 job_callback for (4, 0, 22) finished
04:30:14 start sampling a new configuration.
04:30:14 best_vector: [3, 0.11206498713761703, 0.30354036972976006, 0.5657570350771507, 0.7026231819619188, 1, 0.06157530765727012, 0.20224675067951892, 0.6845025638703245], 0.0036518074991129827, 0.47059689720415526, 0.0017185292782694356
04:30:14 done sampling a new configuration.
04:30:14 HBMASTER: schedule new run for iteration 4
04:30:14 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
04:30:14 HBMASTER: submitting job (4, 0, 23) to dispatcher
04:30:14 DISPATCHER: trying to submit job (4, 0, 23)
04:30:14 DISPATCHER: trying to notify the job_runner thread.
04:30:14 HBMASTER: job (4, 0, 23) submitted to dispatcher
04:30:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:30:14 DISPATCHER: Trying to submit another job.
04:30:14 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:30:14 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:30:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:30:14 WORKER: start processing job (4, 0, 23)
04:30:14 WORKER: args: ()
04:30:14 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 289, 'last_n_outputs': 22, 'leak_rate': 0.8914392587692876, 'lr': 0.025424145419613298, 'optimizer': 'SGD', 'sparsity': 0.7647780738377449, 'steps_to_train': 28, 'weight_decay': 0.07772457709678376}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:30:25 DISPATCHER: Starting worker discovery
04:30:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:30:25 DISPATCHER: Finished worker discovery
04:31:16 WORKER: done with job (4, 0, 23), trying to register it.
04:31:16 WORKER: registered result for job (4, 0, 23) with dispatcher
04:31:16 DISPATCHER: job (4, 0, 23) finished
04:31:16 DISPATCHER: register_result: lock acquired
04:31:16 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:31:16 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 289, 'last_n_outputs': 22, 'leak_rate': 0.8914392587692876, 'lr': 0.025424145419613298, 'optimizer': 'SGD', 'sparsity': 0.7647780738377449, 'steps_to_train': 28, 'weight_decay': 0.07772457709678376}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.15094216612197667, 'info': {'data04': 0.15094216612197667, 'config': "{'batch_size': 128, 'hidden_dim': 289, 'last_n_outputs': 22, 'leak_rate': 0.8914392587692876, 'lr': 0.025424145419613298, 'optimizer': 'SGD', 'sparsity': 0.7647780738377449, 'steps_to_train': 28, 'weight_decay': 0.07772457709678376}"}}
exception: None

04:31:16 job_callback for (4, 0, 23) started
04:31:16 job_callback for (4, 0, 23) got condition
04:31:16 DISPATCHER: Trying to submit another job.
04:31:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:31:16 done building a new model for budget 44.444444 based on 10/43 split
Best loss for this budget:-0.189293





04:31:16 HBMASTER: Trying to run another job!
04:31:16 job_callback for (4, 0, 23) finished
04:31:16 start sampling a new configuration.
04:31:16 done sampling a new configuration.
04:31:16 HBMASTER: schedule new run for iteration 4
04:31:16 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
04:31:16 HBMASTER: submitting job (4, 0, 24) to dispatcher
04:31:16 DISPATCHER: trying to submit job (4, 0, 24)
04:31:16 DISPATCHER: trying to notify the job_runner thread.
04:31:16 HBMASTER: job (4, 0, 24) submitted to dispatcher
04:31:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:31:16 DISPATCHER: Trying to submit another job.
04:31:16 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:31:16 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:31:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:31:16 WORKER: start processing job (4, 0, 24)
04:31:16 WORKER: args: ()
04:31:16 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 465, 'last_n_outputs': 28, 'leak_rate': 0.9455416834725385, 'lr': 0.004281022175373701, 'optimizer': 'SGD', 'sparsity': 0.9187939720880405, 'steps_to_train': 68, 'weight_decay': 0.06699667887210543}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:31:25 DISPATCHER: Starting worker discovery
04:31:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:31:25 DISPATCHER: Finished worker discovery
04:32:16 WORKER: done with job (4, 0, 24), trying to register it.
04:32:16 WORKER: registered result for job (4, 0, 24) with dispatcher
04:32:16 DISPATCHER: job (4, 0, 24) finished
04:32:16 DISPATCHER: register_result: lock acquired
04:32:16 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:32:16 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 465, 'last_n_outputs': 28, 'leak_rate': 0.9455416834725385, 'lr': 0.004281022175373701, 'optimizer': 'SGD', 'sparsity': 0.9187939720880405, 'steps_to_train': 68, 'weight_decay': 0.06699667887210543}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.14764066487131858, 'info': {'data04': 0.14764066487131858, 'config': "{'batch_size': 16, 'hidden_dim': 465, 'last_n_outputs': 28, 'leak_rate': 0.9455416834725385, 'lr': 0.004281022175373701, 'optimizer': 'SGD', 'sparsity': 0.9187939720880405, 'steps_to_train': 68, 'weight_decay': 0.06699667887210543}"}}
exception: None

04:32:16 job_callback for (4, 0, 24) started
04:32:16 DISPATCHER: Trying to submit another job.
04:32:16 job_callback for (4, 0, 24) got condition
04:32:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:32:16 done building a new model for budget 44.444444 based on 10/44 split
Best loss for this budget:-0.189293





04:32:16 HBMASTER: Trying to run another job!
04:32:16 job_callback for (4, 0, 24) finished
04:32:16 start sampling a new configuration.
04:32:16 best_vector: [2, 0.14919100218802142, 0.8629325405884578, 0.8052198120546985, 0.4659365882017944, 1, 0.47613971568656704, 0.9881705880756939, 0.024335050109073886], 0.007597632529188629, 0.2711320953335873, 0.002059962027213535
04:32:16 done sampling a new configuration.
04:32:16 HBMASTER: schedule new run for iteration 4
04:32:16 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
04:32:16 HBMASTER: submitting job (4, 0, 25) to dispatcher
04:32:16 DISPATCHER: trying to submit job (4, 0, 25)
04:32:16 DISPATCHER: trying to notify the job_runner thread.
04:32:16 HBMASTER: job (4, 0, 25) submitted to dispatcher
04:32:16 DISPATCHER: Trying to submit another job.
04:32:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:32:16 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:32:16 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:32:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:32:16 WORKER: start processing job (4, 0, 25)
04:32:16 WORKER: args: ()
04:32:16 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 319, 'last_n_outputs': 45, 'leak_rate': 0.9513049530136746, 'lr': 0.008548170509434561, 'optimizer': 'SGD', 'sparsity': 0.8642735317647761, 'steps_to_train': 99, 'weight_decay': 0.010756243621617057}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:32:25 DISPATCHER: Starting worker discovery
04:32:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:32:25 DISPATCHER: Finished worker discovery
04:33:18 WORKER: done with job (4, 0, 25), trying to register it.
04:33:18 WORKER: registered result for job (4, 0, 25) with dispatcher
04:33:18 DISPATCHER: job (4, 0, 25) finished
04:33:18 DISPATCHER: register_result: lock acquired
04:33:18 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:33:18 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 319, 'last_n_outputs': 45, 'leak_rate': 0.9513049530136746, 'lr': 0.008548170509434561, 'optimizer': 'SGD', 'sparsity': 0.8642735317647761, 'steps_to_train': 99, 'weight_decay': 0.010756243621617057}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.16824474818180973, 'info': {'data04': 0.16824474818180973, 'config': "{'batch_size': 64, 'hidden_dim': 319, 'last_n_outputs': 45, 'leak_rate': 0.9513049530136746, 'lr': 0.008548170509434561, 'optimizer': 'SGD', 'sparsity': 0.8642735317647761, 'steps_to_train': 99, 'weight_decay': 0.010756243621617057}"}}
exception: None

04:33:18 job_callback for (4, 0, 25) started
04:33:18 job_callback for (4, 0, 25) got condition
04:33:18 DISPATCHER: Trying to submit another job.
04:33:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:33:18 done building a new model for budget 44.444444 based on 10/45 split
Best loss for this budget:-0.189293





04:33:18 HBMASTER: Trying to run another job!
04:33:18 job_callback for (4, 0, 25) finished
04:33:18 start sampling a new configuration.
04:33:18 best_vector: [3, 0.03191052569357364, 0.5111405585940807, 0.9423408063711509, 0.7190576898985233, 1, 0.3904871896890968, 0.0566203588020493, 0.1766952588839246], 0.0024020257478176202, 0.1903785117837718, 0.00045729408713582006
04:33:18 done sampling a new configuration.
04:33:18 HBMASTER: schedule new run for iteration 4
04:33:18 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
04:33:18 HBMASTER: submitting job (4, 0, 26) to dispatcher
04:33:18 DISPATCHER: trying to submit job (4, 0, 26)
04:33:18 DISPATCHER: trying to notify the job_runner thread.
04:33:18 HBMASTER: job (4, 0, 26) submitted to dispatcher
04:33:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:33:18 DISPATCHER: Trying to submit another job.
04:33:18 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:33:18 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:33:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:33:18 WORKER: start processing job (4, 0, 26)
04:33:18 WORKER: args: ()
04:33:18 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 225, 'last_n_outputs': 30, 'leak_rate': 0.9855852015927877, 'lr': 0.0274230262763571, 'optimizer': 'SGD', 'sparsity': 0.8437169255253832, 'steps_to_train': 15, 'weight_decay': 0.016977972738461213}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:33:25 DISPATCHER: Starting worker discovery
04:33:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:33:25 DISPATCHER: Finished worker discovery
04:34:21 WORKER: done with job (4, 0, 26), trying to register it.
04:34:21 WORKER: registered result for job (4, 0, 26) with dispatcher
04:34:21 DISPATCHER: job (4, 0, 26) finished
04:34:21 DISPATCHER: register_result: lock acquired
04:34:21 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:34:21 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 225, 'last_n_outputs': 30, 'leak_rate': 0.9855852015927877, 'lr': 0.0274230262763571, 'optimizer': 'SGD', 'sparsity': 0.8437169255253832, 'steps_to_train': 15, 'weight_decay': 0.016977972738461213}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1506254732025607, 'info': {'data04': 0.1506254732025607, 'config': "{'batch_size': 128, 'hidden_dim': 225, 'last_n_outputs': 30, 'leak_rate': 0.9855852015927877, 'lr': 0.0274230262763571, 'optimizer': 'SGD', 'sparsity': 0.8437169255253832, 'steps_to_train': 15, 'weight_decay': 0.016977972738461213}"}}
exception: None

04:34:21 job_callback for (4, 0, 26) started
04:34:21 job_callback for (4, 0, 26) got condition
04:34:21 DISPATCHER: Trying to submit another job.
04:34:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:34:21 done building a new model for budget 44.444444 based on 10/45 split
Best loss for this budget:-0.189293





04:34:21 HBMASTER: Trying to run another job!
04:34:21 job_callback for (4, 0, 26) finished
04:34:21 ITERATION: Advancing config (4, 0, 0) to next budget 133.333333
04:34:21 ITERATION: Advancing config (4, 0, 1) to next budget 133.333333
04:34:21 ITERATION: Advancing config (4, 0, 4) to next budget 133.333333
04:34:21 ITERATION: Advancing config (4, 0, 7) to next budget 133.333333
04:34:21 ITERATION: Advancing config (4, 0, 9) to next budget 133.333333
04:34:21 ITERATION: Advancing config (4, 0, 10) to next budget 133.333333
04:34:21 ITERATION: Advancing config (4, 0, 16) to next budget 133.333333
04:34:21 ITERATION: Advancing config (4, 0, 21) to next budget 133.333333
04:34:21 ITERATION: Advancing config (4, 0, 25) to next budget 133.333333
04:34:21 HBMASTER: schedule new run for iteration 4
04:34:21 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
04:34:21 HBMASTER: submitting job (4, 0, 0) to dispatcher
04:34:21 DISPATCHER: trying to submit job (4, 0, 0)
04:34:21 DISPATCHER: trying to notify the job_runner thread.
04:34:21 HBMASTER: job (4, 0, 0) submitted to dispatcher
04:34:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:34:21 DISPATCHER: Trying to submit another job.
04:34:21 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:34:21 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:34:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:34:21 WORKER: start processing job (4, 0, 0)
04:34:21 WORKER: args: ()
04:34:21 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 546, 'last_n_outputs': 48, 'leak_rate': 0.9358951729338318, 'lr': 0.003427058574129559, 'optimizer': 'SGD', 'sparsity': 0.8375962389553165, 'steps_to_train': 92, 'weight_decay': 0.04489474515671764}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:34:25 DISPATCHER: Starting worker discovery
04:34:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:34:25 DISPATCHER: Finished worker discovery
04:35:25 DISPATCHER: Starting worker discovery
04:35:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:35:25 DISPATCHER: Finished worker discovery
04:36:25 DISPATCHER: Starting worker discovery
04:36:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:36:25 DISPATCHER: Finished worker discovery
04:36:53 WORKER: done with job (4, 0, 0), trying to register it.
04:36:53 WORKER: registered result for job (4, 0, 0) with dispatcher
04:36:53 DISPATCHER: job (4, 0, 0) finished
04:36:53 DISPATCHER: register_result: lock acquired
04:36:53 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:36:53 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 546, 'last_n_outputs': 48, 'leak_rate': 0.9358951729338318, 'lr': 0.003427058574129559, 'optimizer': 'SGD', 'sparsity': 0.8375962389553165, 'steps_to_train': 92, 'weight_decay': 0.04489474515671764}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.18042668416568916, 'info': {'data04': 0.18042668416568916, 'config': "{'batch_size': 128, 'hidden_dim': 546, 'last_n_outputs': 48, 'leak_rate': 0.9358951729338318, 'lr': 0.003427058574129559, 'optimizer': 'SGD', 'sparsity': 0.8375962389553165, 'steps_to_train': 92, 'weight_decay': 0.04489474515671764}"}}
exception: None

04:36:53 job_callback for (4, 0, 0) started
04:36:53 DISPATCHER: Trying to submit another job.
04:36:53 job_callback for (4, 0, 0) got condition
04:36:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:36:53 HBMASTER: Trying to run another job!
04:36:53 job_callback for (4, 0, 0) finished
04:36:53 HBMASTER: schedule new run for iteration 4
04:36:53 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
04:36:53 HBMASTER: submitting job (4, 0, 1) to dispatcher
04:36:53 DISPATCHER: trying to submit job (4, 0, 1)
04:36:53 DISPATCHER: trying to notify the job_runner thread.
04:36:53 HBMASTER: job (4, 0, 1) submitted to dispatcher
04:36:53 DISPATCHER: Trying to submit another job.
04:36:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:36:53 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:36:53 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:36:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:36:53 WORKER: start processing job (4, 0, 1)
04:36:53 WORKER: args: ()
04:36:53 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 428, 'last_n_outputs': 34, 'leak_rate': 0.9711115829930435, 'lr': 0.016793188745345515, 'optimizer': 'SGD', 'sparsity': 0.7881087345818614, 'steps_to_train': 28, 'weight_decay': 0.015755890127621693}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:37:25 DISPATCHER: Starting worker discovery
04:37:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:37:25 DISPATCHER: Finished worker discovery
04:38:25 DISPATCHER: Starting worker discovery
04:38:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:38:25 DISPATCHER: Finished worker discovery
04:39:25 DISPATCHER: Starting worker discovery
04:39:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:39:25 DISPATCHER: Finished worker discovery
04:39:27 WORKER: done with job (4, 0, 1), trying to register it.
04:39:27 WORKER: registered result for job (4, 0, 1) with dispatcher
04:39:27 DISPATCHER: job (4, 0, 1) finished
04:39:27 DISPATCHER: register_result: lock acquired
04:39:27 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:39:27 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 428, 'last_n_outputs': 34, 'leak_rate': 0.9711115829930435, 'lr': 0.016793188745345515, 'optimizer': 'SGD', 'sparsity': 0.7881087345818614, 'steps_to_train': 28, 'weight_decay': 0.015755890127621693}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.15180020147349496, 'info': {'data04': 0.15180020147349496, 'config': "{'batch_size': 128, 'hidden_dim': 428, 'last_n_outputs': 34, 'leak_rate': 0.9711115829930435, 'lr': 0.016793188745345515, 'optimizer': 'SGD', 'sparsity': 0.7881087345818614, 'steps_to_train': 28, 'weight_decay': 0.015755890127621693}"}}
exception: None

04:39:27 job_callback for (4, 0, 1) started
04:39:27 job_callback for (4, 0, 1) got condition
04:39:27 DISPATCHER: Trying to submit another job.
04:39:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:39:27 done building a new model for budget 133.333333 based on 10/17 split
Best loss for this budget:-0.186095





04:39:27 HBMASTER: Trying to run another job!
04:39:27 job_callback for (4, 0, 1) finished
04:39:27 HBMASTER: schedule new run for iteration 4
04:39:27 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
04:39:27 HBMASTER: submitting job (4, 0, 4) to dispatcher
04:39:27 DISPATCHER: trying to submit job (4, 0, 4)
04:39:27 DISPATCHER: trying to notify the job_runner thread.
04:39:27 HBMASTER: job (4, 0, 4) submitted to dispatcher
04:39:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:39:27 DISPATCHER: Trying to submit another job.
04:39:27 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:39:27 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:39:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:39:27 WORKER: start processing job (4, 0, 4)
04:39:27 WORKER: args: ()
04:39:27 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 350, 'last_n_outputs': 41, 'leak_rate': 0.9924115742447579, 'lr': 0.014247160037716694, 'optimizer': 'SGD', 'sparsity': 0.866354570340159, 'steps_to_train': 61, 'weight_decay': 0.022670582604672508}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:40:25 DISPATCHER: Starting worker discovery
04:40:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:40:25 DISPATCHER: Finished worker discovery
04:41:25 DISPATCHER: Starting worker discovery
04:41:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:41:25 DISPATCHER: Finished worker discovery
04:41:58 WORKER: done with job (4, 0, 4), trying to register it.
04:41:58 WORKER: registered result for job (4, 0, 4) with dispatcher
04:41:58 DISPATCHER: job (4, 0, 4) finished
04:41:58 DISPATCHER: register_result: lock acquired
04:41:58 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:41:58 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 350, 'last_n_outputs': 41, 'leak_rate': 0.9924115742447579, 'lr': 0.014247160037716694, 'optimizer': 'SGD', 'sparsity': 0.866354570340159, 'steps_to_train': 61, 'weight_decay': 0.022670582604672508}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1749676779491287, 'info': {'data04': 0.1749676779491287, 'config': "{'batch_size': 128, 'hidden_dim': 350, 'last_n_outputs': 41, 'leak_rate': 0.9924115742447579, 'lr': 0.014247160037716694, 'optimizer': 'SGD', 'sparsity': 0.866354570340159, 'steps_to_train': 61, 'weight_decay': 0.022670582604672508}"}}
exception: None

04:41:58 job_callback for (4, 0, 4) started
04:41:58 DISPATCHER: Trying to submit another job.
04:41:58 job_callback for (4, 0, 4) got condition
04:41:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:41:58 done building a new model for budget 133.333333 based on 10/17 split
Best loss for this budget:-0.186095





04:41:58 HBMASTER: Trying to run another job!
04:41:58 job_callback for (4, 0, 4) finished
04:41:58 HBMASTER: schedule new run for iteration 4
04:41:58 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
04:41:58 HBMASTER: submitting job (4, 0, 7) to dispatcher
04:41:58 DISPATCHER: trying to submit job (4, 0, 7)
04:41:58 DISPATCHER: trying to notify the job_runner thread.
04:41:58 HBMASTER: job (4, 0, 7) submitted to dispatcher
04:41:58 DISPATCHER: Trying to submit another job.
04:41:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:41:58 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:41:58 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:41:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:41:58 WORKER: start processing job (4, 0, 7)
04:41:58 WORKER: args: ()
04:41:58 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 281, 'last_n_outputs': 40, 'leak_rate': 0.9392680344739799, 'lr': 0.018915829211334015, 'optimizer': 'SGD', 'sparsity': 0.9196458486582018, 'steps_to_train': 96, 'weight_decay': 0.1280994344464976}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:42:25 DISPATCHER: Starting worker discovery
04:42:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:42:25 DISPATCHER: Finished worker discovery
04:43:25 DISPATCHER: Starting worker discovery
04:43:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:43:25 DISPATCHER: Finished worker discovery
04:44:25 DISPATCHER: Starting worker discovery
04:44:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:44:25 DISPATCHER: Finished worker discovery
04:44:31 WORKER: done with job (4, 0, 7), trying to register it.
04:44:31 WORKER: registered result for job (4, 0, 7) with dispatcher
04:44:31 DISPATCHER: job (4, 0, 7) finished
04:44:31 DISPATCHER: register_result: lock acquired
04:44:31 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:44:31 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 281, 'last_n_outputs': 40, 'leak_rate': 0.9392680344739799, 'lr': 0.018915829211334015, 'optimizer': 'SGD', 'sparsity': 0.9196458486582018, 'steps_to_train': 96, 'weight_decay': 0.1280994344464976}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1568171358426983, 'info': {'data04': 0.1568171358426983, 'config': "{'batch_size': 128, 'hidden_dim': 281, 'last_n_outputs': 40, 'leak_rate': 0.9392680344739799, 'lr': 0.018915829211334015, 'optimizer': 'SGD', 'sparsity': 0.9196458486582018, 'steps_to_train': 96, 'weight_decay': 0.1280994344464976}"}}
exception: None

04:44:31 job_callback for (4, 0, 7) started
04:44:31 job_callback for (4, 0, 7) got condition
04:44:31 DISPATCHER: Trying to submit another job.
04:44:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:44:31 done building a new model for budget 133.333333 based on 10/18 split
Best loss for this budget:-0.186095





04:44:31 HBMASTER: Trying to run another job!
04:44:31 job_callback for (4, 0, 7) finished
04:44:31 HBMASTER: schedule new run for iteration 4
04:44:31 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
04:44:31 HBMASTER: submitting job (4, 0, 9) to dispatcher
04:44:31 DISPATCHER: trying to submit job (4, 0, 9)
04:44:31 DISPATCHER: trying to notify the job_runner thread.
04:44:31 HBMASTER: job (4, 0, 9) submitted to dispatcher
04:44:31 DISPATCHER: Trying to submit another job.
04:44:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:44:31 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:44:31 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:44:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:44:31 WORKER: start processing job (4, 0, 9)
04:44:31 WORKER: args: ()
04:44:31 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 917, 'last_n_outputs': 28, 'leak_rate': 0.9329780168421719, 'lr': 0.015111520413400026, 'optimizer': 'SGD', 'sparsity': 0.8235758933448986, 'steps_to_train': 69, 'weight_decay': 0.07674029229340344}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:45:25 DISPATCHER: Starting worker discovery
04:45:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:45:25 DISPATCHER: Finished worker discovery
04:46:25 DISPATCHER: Starting worker discovery
04:46:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:46:25 DISPATCHER: Finished worker discovery
04:47:04 WORKER: done with job (4, 0, 9), trying to register it.
04:47:04 WORKER: registered result for job (4, 0, 9) with dispatcher
04:47:04 DISPATCHER: job (4, 0, 9) finished
04:47:04 DISPATCHER: register_result: lock acquired
04:47:04 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:47:04 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 917, 'last_n_outputs': 28, 'leak_rate': 0.9329780168421719, 'lr': 0.015111520413400026, 'optimizer': 'SGD', 'sparsity': 0.8235758933448986, 'steps_to_train': 69, 'weight_decay': 0.07674029229340344}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1574343034961898, 'info': {'data04': 0.1574343034961898, 'config': "{'batch_size': 64, 'hidden_dim': 917, 'last_n_outputs': 28, 'leak_rate': 0.9329780168421719, 'lr': 0.015111520413400026, 'optimizer': 'SGD', 'sparsity': 0.8235758933448986, 'steps_to_train': 69, 'weight_decay': 0.07674029229340344}"}}
exception: None

04:47:04 job_callback for (4, 0, 9) started
04:47:04 job_callback for (4, 0, 9) got condition
04:47:04 DISPATCHER: Trying to submit another job.
04:47:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:47:04 done building a new model for budget 133.333333 based on 10/19 split
Best loss for this budget:-0.186095





04:47:04 HBMASTER: Trying to run another job!
04:47:04 job_callback for (4, 0, 9) finished
04:47:04 HBMASTER: schedule new run for iteration 4
04:47:04 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
04:47:04 HBMASTER: submitting job (4, 0, 10) to dispatcher
04:47:04 DISPATCHER: trying to submit job (4, 0, 10)
04:47:04 DISPATCHER: trying to notify the job_runner thread.
04:47:04 HBMASTER: job (4, 0, 10) submitted to dispatcher
04:47:04 DISPATCHER: Trying to submit another job.
04:47:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:47:04 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:47:04 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:47:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:47:04 WORKER: start processing job (4, 0, 10)
04:47:04 WORKER: args: ()
04:47:04 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 555, 'last_n_outputs': 46, 'leak_rate': 0.9709890179673452, 'lr': 0.01443617807110969, 'optimizer': 'SGD', 'sparsity': 0.8344841294960706, 'steps_to_train': 87, 'weight_decay': 0.03102184093372876}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:47:25 DISPATCHER: Starting worker discovery
04:47:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:47:25 DISPATCHER: Finished worker discovery
04:48:25 DISPATCHER: Starting worker discovery
04:48:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:48:25 DISPATCHER: Finished worker discovery
04:49:25 DISPATCHER: Starting worker discovery
04:49:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:49:25 DISPATCHER: Finished worker discovery
04:49:36 WORKER: done with job (4, 0, 10), trying to register it.
04:49:36 WORKER: registered result for job (4, 0, 10) with dispatcher
04:49:36 DISPATCHER: job (4, 0, 10) finished
04:49:36 DISPATCHER: register_result: lock acquired
04:49:36 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:49:36 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 555, 'last_n_outputs': 46, 'leak_rate': 0.9709890179673452, 'lr': 0.01443617807110969, 'optimizer': 'SGD', 'sparsity': 0.8344841294960706, 'steps_to_train': 87, 'weight_decay': 0.03102184093372876}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1741012007879832, 'info': {'data04': 0.1741012007879832, 'config': "{'batch_size': 64, 'hidden_dim': 555, 'last_n_outputs': 46, 'leak_rate': 0.9709890179673452, 'lr': 0.01443617807110969, 'optimizer': 'SGD', 'sparsity': 0.8344841294960706, 'steps_to_train': 87, 'weight_decay': 0.03102184093372876}"}}
exception: None

04:49:36 job_callback for (4, 0, 10) started
04:49:36 DISPATCHER: Trying to submit another job.
04:49:36 job_callback for (4, 0, 10) got condition
04:49:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:49:36 done building a new model for budget 133.333333 based on 10/20 split
Best loss for this budget:-0.186095





04:49:36 HBMASTER: Trying to run another job!
04:49:36 job_callback for (4, 0, 10) finished
04:49:36 HBMASTER: schedule new run for iteration 4
04:49:36 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
04:49:36 HBMASTER: submitting job (4, 0, 16) to dispatcher
04:49:36 DISPATCHER: trying to submit job (4, 0, 16)
04:49:36 DISPATCHER: trying to notify the job_runner thread.
04:49:36 HBMASTER: job (4, 0, 16) submitted to dispatcher
04:49:36 DISPATCHER: Trying to submit another job.
04:49:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:49:36 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:49:36 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:49:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:49:36 WORKER: start processing job (4, 0, 16)
04:49:36 WORKER: args: ()
04:49:36 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 644, 'last_n_outputs': 17, 'leak_rate': 0.7724693948842106, 'lr': 0.0682564910638401, 'optimizer': 'SGD', 'sparsity': 0.9164307508335638, 'steps_to_train': 61, 'weight_decay': 0.011240479571680678}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:50:25 DISPATCHER: Starting worker discovery
04:50:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:50:25 DISPATCHER: Finished worker discovery
04:51:25 DISPATCHER: Starting worker discovery
04:51:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:51:25 DISPATCHER: Finished worker discovery
04:52:07 WORKER: done with job (4, 0, 16), trying to register it.
04:52:07 WORKER: registered result for job (4, 0, 16) with dispatcher
04:52:07 DISPATCHER: job (4, 0, 16) finished
04:52:07 DISPATCHER: register_result: lock acquired
04:52:07 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:52:07 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 644, 'last_n_outputs': 17, 'leak_rate': 0.7724693948842106, 'lr': 0.0682564910638401, 'optimizer': 'SGD', 'sparsity': 0.9164307508335638, 'steps_to_train': 61, 'weight_decay': 0.011240479571680678}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.16206494514363914, 'info': {'data04': 0.16206494514363914, 'config': "{'batch_size': 32, 'hidden_dim': 644, 'last_n_outputs': 17, 'leak_rate': 0.7724693948842106, 'lr': 0.0682564910638401, 'optimizer': 'SGD', 'sparsity': 0.9164307508335638, 'steps_to_train': 61, 'weight_decay': 0.011240479571680678}"}}
exception: None

04:52:07 job_callback for (4, 0, 16) started
04:52:07 DISPATCHER: Trying to submit another job.
04:52:07 job_callback for (4, 0, 16) got condition
04:52:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:52:07 done building a new model for budget 133.333333 based on 10/21 split
Best loss for this budget:-0.186095





04:52:07 HBMASTER: Trying to run another job!
04:52:07 job_callback for (4, 0, 16) finished
04:52:07 HBMASTER: schedule new run for iteration 4
04:52:07 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
04:52:07 HBMASTER: submitting job (4, 0, 21) to dispatcher
04:52:07 DISPATCHER: trying to submit job (4, 0, 21)
04:52:07 DISPATCHER: trying to notify the job_runner thread.
04:52:07 HBMASTER: job (4, 0, 21) submitted to dispatcher
04:52:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:52:07 DISPATCHER: Trying to submit another job.
04:52:07 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:52:07 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:52:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:52:07 WORKER: start processing job (4, 0, 21)
04:52:07 WORKER: args: ()
04:52:07 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 337, 'last_n_outputs': 16, 'leak_rate': 0.9267557854509677, 'lr': 0.02893553624823134, 'optimizer': 'SGD', 'sparsity': 0.7703155780425808, 'steps_to_train': 29, 'weight_decay': 0.04096567559708777}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:52:25 DISPATCHER: Starting worker discovery
04:52:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:52:25 DISPATCHER: Finished worker discovery
04:53:25 DISPATCHER: Starting worker discovery
04:53:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:53:25 DISPATCHER: Finished worker discovery
04:54:25 DISPATCHER: Starting worker discovery
04:54:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:54:25 DISPATCHER: Finished worker discovery
04:54:41 WORKER: done with job (4, 0, 21), trying to register it.
04:54:41 WORKER: registered result for job (4, 0, 21) with dispatcher
04:54:41 DISPATCHER: job (4, 0, 21) finished
04:54:41 DISPATCHER: register_result: lock acquired
04:54:41 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:54:41 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 337, 'last_n_outputs': 16, 'leak_rate': 0.9267557854509677, 'lr': 0.02893553624823134, 'optimizer': 'SGD', 'sparsity': 0.7703155780425808, 'steps_to_train': 29, 'weight_decay': 0.04096567559708777}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.159817879809593, 'info': {'data04': 0.159817879809593, 'config': "{'batch_size': 128, 'hidden_dim': 337, 'last_n_outputs': 16, 'leak_rate': 0.9267557854509677, 'lr': 0.02893553624823134, 'optimizer': 'SGD', 'sparsity': 0.7703155780425808, 'steps_to_train': 29, 'weight_decay': 0.04096567559708777}"}}
exception: None

04:54:41 job_callback for (4, 0, 21) started
04:54:41 DISPATCHER: Trying to submit another job.
04:54:41 job_callback for (4, 0, 21) got condition
04:54:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:54:41 done building a new model for budget 133.333333 based on 10/22 split
Best loss for this budget:-0.186095





04:54:41 HBMASTER: Trying to run another job!
04:54:41 job_callback for (4, 0, 21) finished
04:54:41 HBMASTER: schedule new run for iteration 4
04:54:41 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
04:54:41 HBMASTER: submitting job (4, 0, 25) to dispatcher
04:54:41 DISPATCHER: trying to submit job (4, 0, 25)
04:54:41 DISPATCHER: trying to notify the job_runner thread.
04:54:41 HBMASTER: job (4, 0, 25) submitted to dispatcher
04:54:41 DISPATCHER: Trying to submit another job.
04:54:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:54:41 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:54:41 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:54:41 WORKER: start processing job (4, 0, 25)
04:54:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:54:41 WORKER: args: ()
04:54:41 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 319, 'last_n_outputs': 45, 'leak_rate': 0.9513049530136746, 'lr': 0.008548170509434561, 'optimizer': 'SGD', 'sparsity': 0.8642735317647761, 'steps_to_train': 99, 'weight_decay': 0.010756243621617057}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:55:25 DISPATCHER: Starting worker discovery
04:55:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:55:25 DISPATCHER: Finished worker discovery
04:56:25 DISPATCHER: Starting worker discovery
04:56:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:56:25 DISPATCHER: Finished worker discovery
04:57:11 WORKER: done with job (4, 0, 25), trying to register it.
04:57:11 WORKER: registered result for job (4, 0, 25) with dispatcher
04:57:11 DISPATCHER: job (4, 0, 25) finished
04:57:11 DISPATCHER: register_result: lock acquired
04:57:11 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:57:11 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 319, 'last_n_outputs': 45, 'leak_rate': 0.9513049530136746, 'lr': 0.008548170509434561, 'optimizer': 'SGD', 'sparsity': 0.8642735317647761, 'steps_to_train': 99, 'weight_decay': 0.010756243621617057}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.16262375182515312, 'info': {'data04': 0.16262375182515312, 'config': "{'batch_size': 64, 'hidden_dim': 319, 'last_n_outputs': 45, 'leak_rate': 0.9513049530136746, 'lr': 0.008548170509434561, 'optimizer': 'SGD', 'sparsity': 0.8642735317647761, 'steps_to_train': 99, 'weight_decay': 0.010756243621617057}"}}
exception: None

04:57:11 job_callback for (4, 0, 25) started
04:57:11 job_callback for (4, 0, 25) got condition
04:57:11 DISPATCHER: Trying to submit another job.
04:57:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:57:11 done building a new model for budget 133.333333 based on 10/22 split
Best loss for this budget:-0.186095





04:57:11 HBMASTER: Trying to run another job!
04:57:11 job_callback for (4, 0, 25) finished
04:57:11 ITERATION: Advancing config (4, 0, 0) to next budget 400.000000
04:57:11 ITERATION: Advancing config (4, 0, 4) to next budget 400.000000
04:57:11 ITERATION: Advancing config (4, 0, 10) to next budget 400.000000
04:57:11 HBMASTER: schedule new run for iteration 4
04:57:11 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
04:57:11 HBMASTER: submitting job (4, 0, 0) to dispatcher
04:57:11 DISPATCHER: trying to submit job (4, 0, 0)
04:57:11 DISPATCHER: trying to notify the job_runner thread.
04:57:11 HBMASTER: job (4, 0, 0) submitted to dispatcher
04:57:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:57:11 DISPATCHER: Trying to submit another job.
04:57:11 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:57:11 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:57:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:57:11 WORKER: start processing job (4, 0, 0)
04:57:11 WORKER: args: ()
04:57:11 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 546, 'last_n_outputs': 48, 'leak_rate': 0.9358951729338318, 'lr': 0.003427058574129559, 'optimizer': 'SGD', 'sparsity': 0.8375962389553165, 'steps_to_train': 92, 'weight_decay': 0.04489474515671764}, 'budget': 400.0, 'working_directory': '.'}
04:57:25 DISPATCHER: Starting worker discovery
04:57:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:57:25 DISPATCHER: Finished worker discovery
04:58:25 DISPATCHER: Starting worker discovery
04:58:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:58:25 DISPATCHER: Finished worker discovery
04:59:25 DISPATCHER: Starting worker discovery
04:59:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:59:25 DISPATCHER: Finished worker discovery
05:00:25 DISPATCHER: Starting worker discovery
05:00:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:00:25 DISPATCHER: Finished worker discovery
05:01:25 DISPATCHER: Starting worker discovery
05:01:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:01:25 DISPATCHER: Finished worker discovery
05:02:25 DISPATCHER: Starting worker discovery
05:02:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:02:25 DISPATCHER: Finished worker discovery
05:03:25 DISPATCHER: Starting worker discovery
05:03:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:03:25 DISPATCHER: Finished worker discovery
05:04:13 WORKER: done with job (4, 0, 0), trying to register it.
05:04:13 WORKER: registered result for job (4, 0, 0) with dispatcher
05:04:13 DISPATCHER: job (4, 0, 0) finished
05:04:13 DISPATCHER: register_result: lock acquired
05:04:13 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
05:04:13 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 546, 'last_n_outputs': 48, 'leak_rate': 0.9358951729338318, 'lr': 0.003427058574129559, 'optimizer': 'SGD', 'sparsity': 0.8375962389553165, 'steps_to_train': 92, 'weight_decay': 0.04489474515671764}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.15555194253002746, 'info': {'data04': 0.15555194253002746, 'config': "{'batch_size': 128, 'hidden_dim': 546, 'last_n_outputs': 48, 'leak_rate': 0.9358951729338318, 'lr': 0.003427058574129559, 'optimizer': 'SGD', 'sparsity': 0.8375962389553165, 'steps_to_train': 92, 'weight_decay': 0.04489474515671764}"}}
exception: None

05:04:13 job_callback for (4, 0, 0) started
05:04:13 job_callback for (4, 0, 0) got condition
05:04:13 DISPATCHER: Trying to submit another job.
05:04:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:04:13 HBMASTER: Trying to run another job!
05:04:13 job_callback for (4, 0, 0) finished
05:04:13 HBMASTER: schedule new run for iteration 4
05:04:13 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
05:04:13 HBMASTER: submitting job (4, 0, 4) to dispatcher
05:04:13 DISPATCHER: trying to submit job (4, 0, 4)
05:04:13 DISPATCHER: trying to notify the job_runner thread.
05:04:13 HBMASTER: job (4, 0, 4) submitted to dispatcher
05:04:13 DISPATCHER: Trying to submit another job.
05:04:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:04:13 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:04:13 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:04:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:04:13 WORKER: start processing job (4, 0, 4)
05:04:13 WORKER: args: ()
05:04:13 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 350, 'last_n_outputs': 41, 'leak_rate': 0.9924115742447579, 'lr': 0.014247160037716694, 'optimizer': 'SGD', 'sparsity': 0.866354570340159, 'steps_to_train': 61, 'weight_decay': 0.022670582604672508}, 'budget': 400.0, 'working_directory': '.'}
05:04:25 DISPATCHER: Starting worker discovery
05:04:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:04:25 DISPATCHER: Finished worker discovery
05:05:25 DISPATCHER: Starting worker discovery
05:05:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:05:25 DISPATCHER: Finished worker discovery
05:06:25 DISPATCHER: Starting worker discovery
05:06:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:06:25 DISPATCHER: Finished worker discovery
05:07:25 DISPATCHER: Starting worker discovery
05:07:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:07:25 DISPATCHER: Finished worker discovery
05:08:25 DISPATCHER: Starting worker discovery
05:08:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:08:25 DISPATCHER: Finished worker discovery
05:09:25 DISPATCHER: Starting worker discovery
05:09:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:09:25 DISPATCHER: Finished worker discovery
05:10:25 DISPATCHER: Starting worker discovery
05:10:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:10:25 DISPATCHER: Finished worker discovery
05:11:16 WORKER: done with job (4, 0, 4), trying to register it.
05:11:16 WORKER: registered result for job (4, 0, 4) with dispatcher
05:11:16 DISPATCHER: job (4, 0, 4) finished
05:11:16 DISPATCHER: register_result: lock acquired
05:11:16 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
05:11:16 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 350, 'last_n_outputs': 41, 'leak_rate': 0.9924115742447579, 'lr': 0.014247160037716694, 'optimizer': 'SGD', 'sparsity': 0.866354570340159, 'steps_to_train': 61, 'weight_decay': 0.022670582604672508}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.16235552258467661, 'info': {'data04': 0.16235552258467661, 'config': "{'batch_size': 128, 'hidden_dim': 350, 'last_n_outputs': 41, 'leak_rate': 0.9924115742447579, 'lr': 0.014247160037716694, 'optimizer': 'SGD', 'sparsity': 0.866354570340159, 'steps_to_train': 61, 'weight_decay': 0.022670582604672508}"}}
exception: None

05:11:16 job_callback for (4, 0, 4) started
05:11:16 job_callback for (4, 0, 4) got condition
05:11:16 DISPATCHER: Trying to submit another job.
05:11:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:11:16 HBMASTER: Trying to run another job!
05:11:16 job_callback for (4, 0, 4) finished
05:11:16 HBMASTER: schedule new run for iteration 4
05:11:16 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
05:11:16 HBMASTER: submitting job (4, 0, 10) to dispatcher
05:11:16 DISPATCHER: trying to submit job (4, 0, 10)
05:11:16 DISPATCHER: trying to notify the job_runner thread.
05:11:16 HBMASTER: job (4, 0, 10) submitted to dispatcher
05:11:16 DISPATCHER: Trying to submit another job.
05:11:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:11:16 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:11:16 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:11:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:11:16 WORKER: start processing job (4, 0, 10)
05:11:16 WORKER: args: ()
05:11:16 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 555, 'last_n_outputs': 46, 'leak_rate': 0.9709890179673452, 'lr': 0.01443617807110969, 'optimizer': 'SGD', 'sparsity': 0.8344841294960706, 'steps_to_train': 87, 'weight_decay': 0.03102184093372876}, 'budget': 400.0, 'working_directory': '.'}
05:11:25 DISPATCHER: Starting worker discovery
05:11:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:11:25 DISPATCHER: Finished worker discovery
05:12:25 DISPATCHER: Starting worker discovery
05:12:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:12:25 DISPATCHER: Finished worker discovery
05:13:25 DISPATCHER: Starting worker discovery
05:13:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:13:25 DISPATCHER: Finished worker discovery
05:14:25 DISPATCHER: Starting worker discovery
05:14:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:14:25 DISPATCHER: Finished worker discovery
05:15:25 DISPATCHER: Starting worker discovery
05:15:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:15:25 DISPATCHER: Finished worker discovery
05:16:25 DISPATCHER: Starting worker discovery
05:16:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:16:25 DISPATCHER: Finished worker discovery
05:17:25 DISPATCHER: Starting worker discovery
05:17:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:17:25 DISPATCHER: Finished worker discovery
05:18:19 WORKER: done with job (4, 0, 10), trying to register it.
05:18:19 WORKER: registered result for job (4, 0, 10) with dispatcher
05:18:19 DISPATCHER: job (4, 0, 10) finished
05:18:19 DISPATCHER: register_result: lock acquired
05:18:19 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
05:18:19 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 555, 'last_n_outputs': 46, 'leak_rate': 0.9709890179673452, 'lr': 0.01443617807110969, 'optimizer': 'SGD', 'sparsity': 0.8344841294960706, 'steps_to_train': 87, 'weight_decay': 0.03102184093372876}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.1718291667547527, 'info': {'data04': 0.1718291667547527, 'config': "{'batch_size': 64, 'hidden_dim': 555, 'last_n_outputs': 46, 'leak_rate': 0.9709890179673452, 'lr': 0.01443617807110969, 'optimizer': 'SGD', 'sparsity': 0.8344841294960706, 'steps_to_train': 87, 'weight_decay': 0.03102184093372876}"}}
exception: None

05:18:19 job_callback for (4, 0, 10) started
05:18:19 DISPATCHER: Trying to submit another job.
05:18:19 job_callback for (4, 0, 10) got condition
05:18:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:18:19 HBMASTER: Trying to run another job!
05:18:19 job_callback for (4, 0, 10) finished
05:18:19 ITERATION: Advancing config (4, 0, 10) to next budget 1200.000000
05:18:19 HBMASTER: schedule new run for iteration 4
05:18:19 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
05:18:19 HBMASTER: submitting job (4, 0, 10) to dispatcher
05:18:19 DISPATCHER: trying to submit job (4, 0, 10)
05:18:19 DISPATCHER: trying to notify the job_runner thread.
05:18:19 HBMASTER: job (4, 0, 10) submitted to dispatcher
05:18:19 DISPATCHER: Trying to submit another job.
05:18:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:18:19 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:18:19 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:18:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:18:19 WORKER: start processing job (4, 0, 10)
05:18:19 WORKER: args: ()
05:18:19 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 555, 'last_n_outputs': 46, 'leak_rate': 0.9709890179673452, 'lr': 0.01443617807110969, 'optimizer': 'SGD', 'sparsity': 0.8344841294960706, 'steps_to_train': 87, 'weight_decay': 0.03102184093372876}, 'budget': 1200.0, 'working_directory': '.'}
05:18:25 DISPATCHER: Starting worker discovery
05:18:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:18:25 DISPATCHER: Finished worker discovery
05:19:25 DISPATCHER: Starting worker discovery
05:19:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:19:25 DISPATCHER: Finished worker discovery
05:20:25 DISPATCHER: Starting worker discovery
05:20:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:20:25 DISPATCHER: Finished worker discovery
05:21:25 DISPATCHER: Starting worker discovery
05:21:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:21:25 DISPATCHER: Finished worker discovery
05:22:25 DISPATCHER: Starting worker discovery
05:22:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:22:25 DISPATCHER: Finished worker discovery
05:23:25 DISPATCHER: Starting worker discovery
05:23:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:23:25 DISPATCHER: Finished worker discovery
05:24:25 DISPATCHER: Starting worker discovery
05:24:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:24:25 DISPATCHER: Finished worker discovery
05:25:25 DISPATCHER: Starting worker discovery
05:25:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:25:25 DISPATCHER: Finished worker discovery
05:26:25 DISPATCHER: Starting worker discovery
05:26:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:26:25 DISPATCHER: Finished worker discovery
05:27:25 DISPATCHER: Starting worker discovery
05:27:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:27:25 DISPATCHER: Finished worker discovery
05:28:25 DISPATCHER: Starting worker discovery
05:28:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:28:25 DISPATCHER: Finished worker discovery
05:29:25 DISPATCHER: Starting worker discovery
05:29:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:29:25 DISPATCHER: Finished worker discovery
05:30:25 DISPATCHER: Starting worker discovery
05:30:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:30:25 DISPATCHER: Finished worker discovery
05:31:25 DISPATCHER: Starting worker discovery
05:31:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:31:25 DISPATCHER: Finished worker discovery
05:32:25 DISPATCHER: Starting worker discovery
05:32:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:32:25 DISPATCHER: Finished worker discovery
05:33:25 DISPATCHER: Starting worker discovery
05:33:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:33:25 DISPATCHER: Finished worker discovery
05:34:25 DISPATCHER: Starting worker discovery
05:34:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:34:25 DISPATCHER: Finished worker discovery
05:35:25 DISPATCHER: Starting worker discovery
05:35:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:35:25 DISPATCHER: Finished worker discovery
05:36:25 DISPATCHER: Starting worker discovery
05:36:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:36:25 DISPATCHER: Finished worker discovery
05:37:25 DISPATCHER: Starting worker discovery
05:37:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:37:25 DISPATCHER: Finished worker discovery
05:38:25 DISPATCHER: Starting worker discovery
05:38:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:38:25 DISPATCHER: Finished worker discovery
05:38:53 WORKER: done with job (4, 0, 10), trying to register it.
05:38:53 WORKER: registered result for job (4, 0, 10) with dispatcher
05:38:53 DISPATCHER: job (4, 0, 10) finished
05:38:53 DISPATCHER: register_result: lock acquired
05:38:53 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
05:38:53 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 555, 'last_n_outputs': 46, 'leak_rate': 0.9709890179673452, 'lr': 0.01443617807110969, 'optimizer': 'SGD', 'sparsity': 0.8344841294960706, 'steps_to_train': 87, 'weight_decay': 0.03102184093372876}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.15990618108111665, 'info': {'data04': 0.15990618108111665, 'config': "{'batch_size': 64, 'hidden_dim': 555, 'last_n_outputs': 46, 'leak_rate': 0.9709890179673452, 'lr': 0.01443617807110969, 'optimizer': 'SGD', 'sparsity': 0.8344841294960706, 'steps_to_train': 87, 'weight_decay': 0.03102184093372876}"}}
exception: None

05:38:53 job_callback for (4, 0, 10) started
05:38:53 job_callback for (4, 0, 10) got condition
05:38:53 DISPATCHER: Trying to submit another job.
05:38:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:38:53 Only 9 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
05:38:53 HBMASTER: Trying to run another job!
05:38:53 job_callback for (4, 0, 10) finished
05:38:53 start sampling a new configuration.
05:38:53 done sampling a new configuration.
05:38:53 HBMASTER: schedule new run for iteration 5
05:38:53 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
05:38:53 HBMASTER: submitting job (5, 0, 0) to dispatcher
05:38:53 DISPATCHER: trying to submit job (5, 0, 0)
05:38:53 DISPATCHER: trying to notify the job_runner thread.
05:38:53 HBMASTER: job (5, 0, 0) submitted to dispatcher
05:38:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:38:53 DISPATCHER: Trying to submit another job.
05:38:53 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:38:53 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:38:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:38:53 WORKER: start processing job (5, 0, 0)
05:38:53 WORKER: args: ()
05:38:53 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 211, 'last_n_outputs': 50, 'leak_rate': 0.973985261928082, 'lr': 0.002507545562766195, 'optimizer': 'SGD', 'sparsity': 0.9261877818121369, 'steps_to_train': 45, 'weight_decay': 0.1661944027058698}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:39:25 DISPATCHER: Starting worker discovery
05:39:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:39:25 DISPATCHER: Finished worker discovery
05:40:25 DISPATCHER: Starting worker discovery
05:40:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:40:25 DISPATCHER: Finished worker discovery
05:41:25 WORKER: done with job (5, 0, 0), trying to register it.
05:41:25 WORKER: registered result for job (5, 0, 0) with dispatcher
05:41:25 DISPATCHER: job (5, 0, 0) finished
05:41:25 DISPATCHER: register_result: lock acquired
05:41:25 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
05:41:25 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 211, 'last_n_outputs': 50, 'leak_rate': 0.973985261928082, 'lr': 0.002507545562766195, 'optimizer': 'SGD', 'sparsity': 0.9261877818121369, 'steps_to_train': 45, 'weight_decay': 0.1661944027058698}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.16374390276745393, 'info': {'data04': 0.16374390276745393, 'config': "{'batch_size': 16, 'hidden_dim': 211, 'last_n_outputs': 50, 'leak_rate': 0.973985261928082, 'lr': 0.002507545562766195, 'optimizer': 'SGD', 'sparsity': 0.9261877818121369, 'steps_to_train': 45, 'weight_decay': 0.1661944027058698}"}}
exception: None

05:41:25 job_callback for (5, 0, 0) started
05:41:25 DISPATCHER: Trying to submit another job.
05:41:25 job_callback for (5, 0, 0) got condition
05:41:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:41:25 done building a new model for budget 133.333333 based on 10/23 split
Best loss for this budget:-0.186095





05:41:25 HBMASTER: Trying to run another job!
05:41:25 job_callback for (5, 0, 0) finished
05:41:25 start sampling a new configuration.
05:41:25 best_vector: [3, 0.05804423817342963, 0.8052660303012942, 0.46863979942459466, 0.3011421485596709, 1, 0.6143827357476529, 0.8512034179945924, 0.8755297368128447], 0.013396373196781155, 1.3903777736191725, 0.01862601953991214
05:41:25 done sampling a new configuration.
05:41:25 HBMASTER: schedule new run for iteration 5
05:41:25 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
05:41:25 HBMASTER: submitting job (5, 0, 1) to dispatcher
05:41:25 DISPATCHER: trying to submit job (5, 0, 1)
05:41:25 DISPATCHER: trying to notify the job_runner thread.
05:41:25 HBMASTER: job (5, 0, 1) submitted to dispatcher
05:41:25 DISPATCHER: Trying to submit another job.
05:41:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:41:25 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:41:25 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:41:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:41:25 WORKER: start processing job (5, 0, 1)
05:41:25 WORKER: args: ()
05:41:25 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 246, 'last_n_outputs': 43, 'leak_rate': 0.8671599498561486, 'lr': 0.004002066466287604, 'optimizer': 'SGD', 'sparsity': 0.8974518565794367, 'steps_to_train': 87, 'weight_decay': 0.1377496327572666}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:41:25 DISPATCHER: Starting worker discovery
05:41:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:41:25 DISPATCHER: Finished worker discovery
05:42:25 DISPATCHER: Starting worker discovery
05:42:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:42:25 DISPATCHER: Finished worker discovery
05:43:25 DISPATCHER: Starting worker discovery
05:43:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:43:25 DISPATCHER: Finished worker discovery
05:43:55 WORKER: done with job (5, 0, 1), trying to register it.
05:43:55 WORKER: registered result for job (5, 0, 1) with dispatcher
05:43:55 DISPATCHER: job (5, 0, 1) finished
05:43:55 DISPATCHER: register_result: lock acquired
05:43:55 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
05:43:55 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 246, 'last_n_outputs': 43, 'leak_rate': 0.8671599498561486, 'lr': 0.004002066466287604, 'optimizer': 'SGD', 'sparsity': 0.8974518565794367, 'steps_to_train': 87, 'weight_decay': 0.1377496327572666}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.16938788331439236, 'info': {'data04': 0.16938788331439236, 'config': "{'batch_size': 128, 'hidden_dim': 246, 'last_n_outputs': 43, 'leak_rate': 0.8671599498561486, 'lr': 0.004002066466287604, 'optimizer': 'SGD', 'sparsity': 0.8974518565794367, 'steps_to_train': 87, 'weight_decay': 0.1377496327572666}"}}
exception: None

05:43:55 job_callback for (5, 0, 1) started
05:43:55 DISPATCHER: Trying to submit another job.
05:43:55 job_callback for (5, 0, 1) got condition
05:43:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:43:55 done building a new model for budget 133.333333 based on 10/24 split
Best loss for this budget:-0.186095





05:43:55 HBMASTER: Trying to run another job!
05:43:55 job_callback for (5, 0, 1) finished
05:43:55 start sampling a new configuration.
05:43:55 best_vector: [2, 0.9183762909546764, 0.7516906026103631, 0.6974126990209699, 0.3405643193091239, 1, 0.43256629630225235, 0.6549157391449858, 0.14263237522501848], 0.0035230173975142206, 3.9533823868044804, 0.013927834927738478
05:43:55 done sampling a new configuration.
05:43:55 HBMASTER: schedule new run for iteration 5
05:43:55 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
05:43:55 HBMASTER: submitting job (5, 0, 2) to dispatcher
05:43:55 DISPATCHER: trying to submit job (5, 0, 2)
05:43:55 DISPATCHER: trying to notify the job_runner thread.
05:43:55 HBMASTER: job (5, 0, 2) submitted to dispatcher
05:43:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:43:55 DISPATCHER: Trying to submit another job.
05:43:55 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:43:55 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:43:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:43:55 WORKER: start processing job (5, 0, 2)
05:43:55 WORKER: args: ()
05:43:55 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 935, 'last_n_outputs': 40, 'leak_rate': 0.9243531747552425, 'lr': 0.004798755673857418, 'optimizer': 'SGD', 'sparsity': 0.8538159111125405, 'steps_to_train': 69, 'weight_decay': 0.015330947573910429}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:44:25 DISPATCHER: Starting worker discovery
05:44:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:44:25 DISPATCHER: Finished worker discovery
05:45:25 DISPATCHER: Starting worker discovery
05:45:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:45:25 DISPATCHER: Finished worker discovery
05:46:25 DISPATCHER: Starting worker discovery
05:46:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:46:25 DISPATCHER: Finished worker discovery
05:46:27 WORKER: done with job (5, 0, 2), trying to register it.
05:46:27 WORKER: registered result for job (5, 0, 2) with dispatcher
05:46:27 DISPATCHER: job (5, 0, 2) finished
05:46:27 DISPATCHER: register_result: lock acquired
05:46:27 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
05:46:27 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 935, 'last_n_outputs': 40, 'leak_rate': 0.9243531747552425, 'lr': 0.004798755673857418, 'optimizer': 'SGD', 'sparsity': 0.8538159111125405, 'steps_to_train': 69, 'weight_decay': 0.015330947573910429}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1713906890844461, 'info': {'data04': 0.1713906890844461, 'config': "{'batch_size': 64, 'hidden_dim': 935, 'last_n_outputs': 40, 'leak_rate': 0.9243531747552425, 'lr': 0.004798755673857418, 'optimizer': 'SGD', 'sparsity': 0.8538159111125405, 'steps_to_train': 69, 'weight_decay': 0.015330947573910429}"}}
exception: None

05:46:27 job_callback for (5, 0, 2) started
05:46:27 DISPATCHER: Trying to submit another job.
05:46:27 job_callback for (5, 0, 2) got condition
05:46:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:46:27 done building a new model for budget 133.333333 based on 10/25 split
Best loss for this budget:-0.186095





05:46:27 HBMASTER: Trying to run another job!
05:46:27 job_callback for (5, 0, 2) finished
05:46:27 start sampling a new configuration.
05:46:27 best_vector: [2, 0.3033510059928973, 0.5753942265871517, 0.15747595432500294, 0.2046664320286892, 1, 0.5358069952551517, 0.9005149067036381, 0.7279966589390239], 0.00480600562291676, 0.2097981563766295, 0.001008291119223651
05:46:27 done sampling a new configuration.
05:46:27 HBMASTER: schedule new run for iteration 5
05:46:27 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
05:46:27 HBMASTER: submitting job (5, 0, 3) to dispatcher
05:46:27 DISPATCHER: trying to submit job (5, 0, 3)
05:46:27 DISPATCHER: trying to notify the job_runner thread.
05:46:27 HBMASTER: job (5, 0, 3) submitted to dispatcher
05:46:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:46:27 DISPATCHER: Trying to submit another job.
05:46:27 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:46:27 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:46:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:46:27 WORKER: start processing job (5, 0, 3)
05:46:27 WORKER: args: ()
05:46:27 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 442, 'last_n_outputs': 33, 'leak_rate': 0.7893689885812507, 'lr': 0.00256645033314361, 'optimizer': 'SGD', 'sparsity': 0.8785936788612364, 'steps_to_train': 91, 'weight_decay': 0.08854121760276354}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:47:25 DISPATCHER: Starting worker discovery
05:47:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:47:25 DISPATCHER: Finished worker discovery
05:48:25 DISPATCHER: Starting worker discovery
05:48:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:48:25 DISPATCHER: Finished worker discovery
05:49:00 WORKER: done with job (5, 0, 3), trying to register it.
05:49:00 WORKER: registered result for job (5, 0, 3) with dispatcher
05:49:00 DISPATCHER: job (5, 0, 3) finished
05:49:00 DISPATCHER: register_result: lock acquired
05:49:00 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
05:49:00 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 442, 'last_n_outputs': 33, 'leak_rate': 0.7893689885812507, 'lr': 0.00256645033314361, 'optimizer': 'SGD', 'sparsity': 0.8785936788612364, 'steps_to_train': 91, 'weight_decay': 0.08854121760276354}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.184337876741838, 'info': {'data04': 0.184337876741838, 'config': "{'batch_size': 64, 'hidden_dim': 442, 'last_n_outputs': 33, 'leak_rate': 0.7893689885812507, 'lr': 0.00256645033314361, 'optimizer': 'SGD', 'sparsity': 0.8785936788612364, 'steps_to_train': 91, 'weight_decay': 0.08854121760276354}"}}
exception: None

05:49:00 job_callback for (5, 0, 3) started
05:49:00 job_callback for (5, 0, 3) got condition
05:49:00 DISPATCHER: Trying to submit another job.
05:49:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:49:00 done building a new model for budget 133.333333 based on 10/26 split
Best loss for this budget:-0.186095





05:49:00 HBMASTER: Trying to run another job!
05:49:00 job_callback for (5, 0, 3) finished
05:49:00 start sampling a new configuration.
05:49:00 best_vector: [0, 0.31934156756212556, 0.4833626215829648, 0.29384951938357085, 0.36755466769028533, 1, 0.5579373704291961, 0.857018332319694, 0.7693897633088584], 0.0012405803774961962, 9.178347556773556, 0.011386477876773429
05:49:00 done sampling a new configuration.
05:49:00 HBMASTER: schedule new run for iteration 5
05:49:00 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
05:49:00 HBMASTER: submitting job (5, 0, 4) to dispatcher
05:49:00 DISPATCHER: trying to submit job (5, 0, 4)
05:49:00 DISPATCHER: trying to notify the job_runner thread.
05:49:00 HBMASTER: job (5, 0, 4) submitted to dispatcher
05:49:00 DISPATCHER: Trying to submit another job.
05:49:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:49:00 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:49:00 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:49:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:49:00 WORKER: start processing job (5, 0, 4)
05:49:00 WORKER: args: ()
05:49:00 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 455, 'last_n_outputs': 29, 'leak_rate': 0.8234623798458927, 'lr': 0.005433871141629327, 'optimizer': 'SGD', 'sparsity': 0.8839049689030071, 'steps_to_train': 87, 'weight_decay': 0.10023033004226586}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:49:25 DISPATCHER: Starting worker discovery
05:49:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:49:25 DISPATCHER: Finished worker discovery
05:50:25 DISPATCHER: Starting worker discovery
05:50:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:50:25 DISPATCHER: Finished worker discovery
05:51:25 DISPATCHER: Starting worker discovery
05:51:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:51:25 DISPATCHER: Finished worker discovery
05:51:30 WORKER: done with job (5, 0, 4), trying to register it.
05:51:30 WORKER: registered result for job (5, 0, 4) with dispatcher
05:51:30 DISPATCHER: job (5, 0, 4) finished
05:51:30 DISPATCHER: register_result: lock acquired
05:51:30 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
05:51:30 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 455, 'last_n_outputs': 29, 'leak_rate': 0.8234623798458927, 'lr': 0.005433871141629327, 'optimizer': 'SGD', 'sparsity': 0.8839049689030071, 'steps_to_train': 87, 'weight_decay': 0.10023033004226586}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.17271078184940372, 'info': {'data04': 0.17271078184940372, 'config': "{'batch_size': 16, 'hidden_dim': 455, 'last_n_outputs': 29, 'leak_rate': 0.8234623798458927, 'lr': 0.005433871141629327, 'optimizer': 'SGD', 'sparsity': 0.8839049689030071, 'steps_to_train': 87, 'weight_decay': 0.10023033004226586}"}}
exception: None

05:51:30 job_callback for (5, 0, 4) started
05:51:30 DISPATCHER: Trying to submit another job.
05:51:30 job_callback for (5, 0, 4) got condition
05:51:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:51:30 done building a new model for budget 133.333333 based on 10/27 split
Best loss for this budget:-0.186095





05:51:30 HBMASTER: Trying to run another job!
05:51:30 job_callback for (5, 0, 4) finished
05:51:30 start sampling a new configuration.
05:51:30 done sampling a new configuration.
05:51:30 HBMASTER: schedule new run for iteration 5
05:51:30 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
05:51:30 HBMASTER: submitting job (5, 0, 5) to dispatcher
05:51:30 DISPATCHER: trying to submit job (5, 0, 5)
05:51:30 DISPATCHER: trying to notify the job_runner thread.
05:51:30 HBMASTER: job (5, 0, 5) submitted to dispatcher
05:51:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:51:30 DISPATCHER: Trying to submit another job.
05:51:30 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:51:30 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:51:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:51:30 WORKER: start processing job (5, 0, 5)
05:51:30 WORKER: args: ()
05:51:30 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 661, 'last_n_outputs': 34, 'leak_rate': 0.9280920447152923, 'lr': 0.004512774770992619, 'optimizer': 'Adam', 'sparsity': 0.8275371270233924, 'steps_to_train': 76, 'weight_decay': 0.030838974175815048}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:52:25 DISPATCHER: Starting worker discovery
05:52:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:52:25 DISPATCHER: Finished worker discovery
05:53:25 DISPATCHER: Starting worker discovery
05:53:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:53:25 DISPATCHER: Finished worker discovery
05:54:02 WORKER: done with job (5, 0, 5), trying to register it.
05:54:02 WORKER: registered result for job (5, 0, 5) with dispatcher
05:54:02 DISPATCHER: job (5, 0, 5) finished
05:54:02 DISPATCHER: register_result: lock acquired
05:54:02 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
05:54:02 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 661, 'last_n_outputs': 34, 'leak_rate': 0.9280920447152923, 'lr': 0.004512774770992619, 'optimizer': 'Adam', 'sparsity': 0.8275371270233924, 'steps_to_train': 76, 'weight_decay': 0.030838974175815048}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.018256971379375223, 'info': {'data04': 0.018256971379375223, 'config': "{'batch_size': 16, 'hidden_dim': 661, 'last_n_outputs': 34, 'leak_rate': 0.9280920447152923, 'lr': 0.004512774770992619, 'optimizer': 'Adam', 'sparsity': 0.8275371270233924, 'steps_to_train': 76, 'weight_decay': 0.030838974175815048}"}}
exception: None

05:54:02 job_callback for (5, 0, 5) started
05:54:02 DISPATCHER: Trying to submit another job.
05:54:02 job_callback for (5, 0, 5) got condition
05:54:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:54:02 done building a new model for budget 133.333333 based on 10/28 split
Best loss for this budget:-0.186095





05:54:02 HBMASTER: Trying to run another job!
05:54:02 job_callback for (5, 0, 5) finished
05:54:02 start sampling a new configuration.
05:54:02 done sampling a new configuration.
05:54:02 HBMASTER: schedule new run for iteration 5
05:54:02 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
05:54:02 HBMASTER: submitting job (5, 0, 6) to dispatcher
05:54:02 DISPATCHER: trying to submit job (5, 0, 6)
05:54:02 DISPATCHER: trying to notify the job_runner thread.
05:54:02 HBMASTER: job (5, 0, 6) submitted to dispatcher
05:54:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:54:02 DISPATCHER: Trying to submit another job.
05:54:02 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:54:02 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:54:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:54:02 WORKER: start processing job (5, 0, 6)
05:54:02 WORKER: args: ()
05:54:02 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 303, 'last_n_outputs': 20, 'leak_rate': 0.8125246752041048, 'lr': 0.03527810248017529, 'optimizer': 'SGD', 'sparsity': 0.977773492926564, 'steps_to_train': 24, 'weight_decay': 0.03147430044204477}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:54:25 DISPATCHER: Starting worker discovery
05:54:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:54:25 DISPATCHER: Finished worker discovery
05:55:25 DISPATCHER: Starting worker discovery
05:55:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:55:25 DISPATCHER: Finished worker discovery
05:56:25 DISPATCHER: Starting worker discovery
05:56:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:56:25 DISPATCHER: Finished worker discovery
05:56:38 WORKER: done with job (5, 0, 6), trying to register it.
05:56:38 WORKER: registered result for job (5, 0, 6) with dispatcher
05:56:38 DISPATCHER: job (5, 0, 6) finished
05:56:38 DISPATCHER: register_result: lock acquired
05:56:38 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
05:56:38 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 303, 'last_n_outputs': 20, 'leak_rate': 0.8125246752041048, 'lr': 0.03527810248017529, 'optimizer': 'SGD', 'sparsity': 0.977773492926564, 'steps_to_train': 24, 'weight_decay': 0.03147430044204477}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1472649354686384, 'info': {'data04': 0.1472649354686384, 'config': "{'batch_size': 32, 'hidden_dim': 303, 'last_n_outputs': 20, 'leak_rate': 0.8125246752041048, 'lr': 0.03527810248017529, 'optimizer': 'SGD', 'sparsity': 0.977773492926564, 'steps_to_train': 24, 'weight_decay': 0.03147430044204477}"}}
exception: None

05:56:38 job_callback for (5, 0, 6) started
05:56:38 job_callback for (5, 0, 6) got condition
05:56:38 DISPATCHER: Trying to submit another job.
05:56:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:56:38 done building a new model for budget 133.333333 based on 10/28 split
Best loss for this budget:-0.186095





05:56:38 HBMASTER: Trying to run another job!
05:56:38 job_callback for (5, 0, 6) finished
05:56:38 start sampling a new configuration.
05:56:38 sampled vector: [0, 0.919883248132964, 0.7477123198968356, 0.9729667231849106, 0.3175902494886714, 0, 0.39219155177384607, 0.24126030264940768, 0.5156985685569196] has EI value nan
05:56:38 data in the KDEs:
[[0.         0.83083646 0.64634153 0.87505936 0.47796791 1.
  0.42843374 0.87362646 0.47701047]
 [2.         0.30274656 0.57317077 0.15747595 0.20466643 1.
  0.535807   0.89560448 0.72799666]
 [3.         0.43258427 0.9390246  0.74358069 0.26746076 1.
  0.36498433 0.9065935  0.50129168]
 [0.         0.83333334 0.62195128 0.60540606 0.51949976 1.
  0.26169293 0.63186816 0.027787  ]
 [3.         0.91822723 0.57317077 0.60308056 0.48328355 1.
  0.47648461 0.71978027 0.55770103]
 [3.         0.18789013 0.76829281 0.9696463  0.57686415 1.
  0.48481071 0.56593408 0.27321636]
 [2.         0.44382022 0.89024409 0.88395607 0.57972612 1.
  0.35201721 0.85164843 0.3779064 ]
 [2.         0.30898876 0.81707333 0.42625917 0.46554395 1.
  0.54133597 0.70879125 0.90338677]
 [0.         0.31897628 0.47560974 0.29384952 0.36755467 1.
  0.55793737 0.85164843 0.76938976]
 [2.         0.91822723 0.74390256 0.6974127  0.34056432 1.
  0.4325663  0.65384619 0.14263238]]
[[3.         0.05805242 0.81707333 0.4686398  0.30114215 1.
  0.61438274 0.85164843 0.87552974]
 [3.         0.6485643  0.91463435 0.96539698 0.55031546 1.
  0.58309007 0.9065935  0.62247293]
 [3.         0.01061172 0.32926821 0.60270941 0.93056119 1.
  0.72494085 0.73076928 0.0104419 ]
 [3.         0.47378277 0.03658514 0.41678678 0.73871958 1.
  0.97287933 0.69780224 0.54906912]
 [0.         0.01435704 0.98780512 0.89594105 0.19962442 1.
  0.73411576 0.39010987 0.93819235]
 [2.         0.14918851 0.86585384 0.80521981 0.46593659 1.
  0.47613972 0.98351659 0.02433505]
 [1.         0.55493134 0.18292667 0.08987758 0.91707198 1.
  0.69346146 0.56593408 0.03903433]
 [1.         0.14169787 0.30487795 0.44647455 0.34132059 1.
  0.46167707 0.06043946 0.34155232]
 [3.         0.05056179 0.91463435 0.91277066 0.60099995 1.
  0.78082591 0.48901099 0.88375117]
 [3.         0.17166042 0.15853642 0.70702314 0.73071577 1.
  0.08464824 0.21428565 0.47071945]
 [3.         0.48501873 0.9390246  0.89325889 0.56243193 1.
  0.93552082 0.88461547 0.45144267]
 [2.         0.89575532 0.45121949 0.73191207 0.58965408 1.
  0.30656622 0.65384619 0.6802483 ]
 [3.         0.10174781 0.74390256 0.75707214 0.63841269 1.
  0.7068577  0.95054955 0.85128492]
 [1.         0.93196006 0.37804872 0.96797353 0.16834002 1.
  0.50904963 0.98351659 0.56149508]
 [3.         0.29151061 0.10975591 0.17268955 0.76129219 1.
  0.60779675 0.37912085 0.15306726]
 [3.         0.67602997 0.37804872 0.85258002 0.83037636 1.
  0.83598371 0.93956054 0.8416321 ]
 [3.         0.696005   0.20731693 0.29282138 0.52491141 1.
  0.24420372 0.79670336 0.14541081]
 [3.         0.28526841 0.59756102 0.88444633 0.61256658 1.
  0.15878639 0.20329664 0.15175895]
 [1.         0.19163545 0.7195123  0.91409939 0.71623053 1.
  0.68725199 0.98351659 0.73626851]
 [1.         0.12921347 0.25609744 0.2500987  0.77375261 1.
  0.94905622 0.15934058 0.3827399 ]
 [2.         0.02933832 0.03658514 0.64123889 0.56869678 1.
  0.13372022 0.19230762 0.48651651]
 [0.         0.50998752 0.08536565 0.97027777 0.09208461 1.
  0.12189775 0.6648352  0.04646625]
 [0.         0.76092385 0.0609754  0.51773028 0.62899554 0.
  0.78217237 0.22527466 0.31343364]
 [0.         0.57615481 0.59756102 0.71236818 0.32722183 0.
  0.32307136 0.73076928 0.37593286]]
05:56:38 bandwidth of the KDEs:
[1.05436831e+00 2.44643417e-01 1.27095658e-01 2.23977464e-01
 1.07826772e-01 1.00000000e-03 8.03655171e-02 1.04620037e-01
 2.35316584e-01]
[0.97277583 0.24137114 0.26834173 0.21972966 0.18612921 0.22943035
 0.22453751 0.25186448 0.24708775]
05:56:38 l(x) = nan
05:56:38 g(x) = 0.00455062762797555
05:56:38 best_vector: [3, 0.06208441912667173, 0.6698220292413768, 0.2510512017845532, 0.6313759823075149, 1, 0.5349555723141628, 0.725717766916808, 0.6635643659693962], 0.002752897102102486, 2.5265968660004106, 0.006955461190593753
05:56:38 done sampling a new configuration.
05:56:38 HBMASTER: schedule new run for iteration 5
05:56:38 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
05:56:38 HBMASTER: submitting job (5, 0, 7) to dispatcher
05:56:38 DISPATCHER: trying to submit job (5, 0, 7)
05:56:38 DISPATCHER: trying to notify the job_runner thread.
05:56:38 HBMASTER: job (5, 0, 7) submitted to dispatcher
05:56:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:56:38 DISPATCHER: Trying to submit another job.
05:56:38 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:56:38 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:56:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:56:38 WORKER: start processing job (5, 0, 7)
05:56:38 WORKER: args: ()
05:56:38 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 249, 'last_n_outputs': 37, 'leak_rate': 0.8127628004461382, 'lr': 0.0183126824500719, 'optimizer': 'SGD', 'sparsity': 0.878389337355399, 'steps_to_train': 76, 'weight_decay': 0.072999039221244}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:57:25 DISPATCHER: Starting worker discovery
05:57:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:57:25 DISPATCHER: Finished worker discovery
05:58:25 DISPATCHER: Starting worker discovery
05:58:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:58:26 DISPATCHER: Finished worker discovery
05:59:10 WORKER: done with job (5, 0, 7), trying to register it.
05:59:10 WORKER: registered result for job (5, 0, 7) with dispatcher
05:59:10 DISPATCHER: job (5, 0, 7) finished
05:59:10 DISPATCHER: register_result: lock acquired
05:59:10 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
05:59:10 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 249, 'last_n_outputs': 37, 'leak_rate': 0.8127628004461382, 'lr': 0.0183126824500719, 'optimizer': 'SGD', 'sparsity': 0.878389337355399, 'steps_to_train': 76, 'weight_decay': 0.072999039221244}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.17525531458223584, 'info': {'data04': 0.17525531458223584, 'config': "{'batch_size': 128, 'hidden_dim': 249, 'last_n_outputs': 37, 'leak_rate': 0.8127628004461382, 'lr': 0.0183126824500719, 'optimizer': 'SGD', 'sparsity': 0.878389337355399, 'steps_to_train': 76, 'weight_decay': 0.072999039221244}"}}
exception: None

05:59:10 job_callback for (5, 0, 7) started
05:59:10 DISPATCHER: Trying to submit another job.
05:59:10 job_callback for (5, 0, 7) got condition
05:59:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:59:10 done building a new model for budget 133.333333 based on 10/29 split
Best loss for this budget:-0.186095





05:59:10 HBMASTER: Trying to run another job!
05:59:10 job_callback for (5, 0, 7) finished
05:59:10 start sampling a new configuration.
05:59:10 best_vector: [2, 0.8314509751689972, 0.5596290833782509, 0.40593940806238105, 0.39029351887971386, 1, 0.585248577933117, 0.590552678673424, 0.9409829168687649], 0.006169555187492029, 1.1163603556594686, 0.006887446823369321
05:59:10 done sampling a new configuration.
05:59:10 HBMASTER: schedule new run for iteration 5
05:59:10 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
05:59:10 HBMASTER: submitting job (5, 0, 8) to dispatcher
05:59:10 DISPATCHER: trying to submit job (5, 0, 8)
05:59:10 DISPATCHER: trying to notify the job_runner thread.
05:59:10 HBMASTER: job (5, 0, 8) submitted to dispatcher
05:59:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:59:10 DISPATCHER: Trying to submit another job.
05:59:10 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:59:10 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:59:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:59:10 WORKER: start processing job (5, 0, 8)
05:59:10 WORKER: args: ()
05:59:10 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 865, 'last_n_outputs': 32, 'leak_rate': 0.8514848520155953, 'lr': 0.006033746192322853, 'optimizer': 'SGD', 'sparsity': 0.890459658703948, 'steps_to_train': 63, 'weight_decay': 0.16758957524770451}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:59:26 DISPATCHER: Starting worker discovery
05:59:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:59:26 DISPATCHER: Finished worker discovery
06:00:26 DISPATCHER: Starting worker discovery
06:00:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:00:26 DISPATCHER: Finished worker discovery
06:01:26 DISPATCHER: Starting worker discovery
06:01:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:01:26 DISPATCHER: Finished worker discovery
06:01:43 WORKER: done with job (5, 0, 8), trying to register it.
06:01:43 WORKER: registered result for job (5, 0, 8) with dispatcher
06:01:43 DISPATCHER: job (5, 0, 8) finished
06:01:43 DISPATCHER: register_result: lock acquired
06:01:43 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
06:01:43 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 865, 'last_n_outputs': 32, 'leak_rate': 0.8514848520155953, 'lr': 0.006033746192322853, 'optimizer': 'SGD', 'sparsity': 0.890459658703948, 'steps_to_train': 63, 'weight_decay': 0.16758957524770451}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1837123763606051, 'info': {'data04': 0.1837123763606051, 'config': "{'batch_size': 64, 'hidden_dim': 865, 'last_n_outputs': 32, 'leak_rate': 0.8514848520155953, 'lr': 0.006033746192322853, 'optimizer': 'SGD', 'sparsity': 0.890459658703948, 'steps_to_train': 63, 'weight_decay': 0.16758957524770451}"}}
exception: None

06:01:43 job_callback for (5, 0, 8) started
06:01:43 DISPATCHER: Trying to submit another job.
06:01:43 job_callback for (5, 0, 8) got condition
06:01:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:01:43 done building a new model for budget 133.333333 based on 10/30 split
Best loss for this budget:-0.186095





06:01:43 HBMASTER: Trying to run another job!
06:01:43 job_callback for (5, 0, 8) finished
06:01:43 ITERATION: Advancing config (5, 0, 3) to next budget 400.000000
06:01:43 ITERATION: Advancing config (5, 0, 7) to next budget 400.000000
06:01:43 ITERATION: Advancing config (5, 0, 8) to next budget 400.000000
06:01:43 HBMASTER: schedule new run for iteration 5
06:01:43 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
06:01:43 HBMASTER: submitting job (5, 0, 3) to dispatcher
06:01:43 DISPATCHER: trying to submit job (5, 0, 3)
06:01:43 DISPATCHER: trying to notify the job_runner thread.
06:01:43 HBMASTER: job (5, 0, 3) submitted to dispatcher
06:01:43 DISPATCHER: Trying to submit another job.
06:01:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:01:43 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
06:01:43 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
06:01:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:01:43 WORKER: start processing job (5, 0, 3)
06:01:43 WORKER: args: ()
06:01:43 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 442, 'last_n_outputs': 33, 'leak_rate': 0.7893689885812507, 'lr': 0.00256645033314361, 'optimizer': 'SGD', 'sparsity': 0.8785936788612364, 'steps_to_train': 91, 'weight_decay': 0.08854121760276354}, 'budget': 400.0, 'working_directory': '.'}
06:02:26 DISPATCHER: Starting worker discovery
06:02:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:02:26 DISPATCHER: Finished worker discovery
06:03:26 DISPATCHER: Starting worker discovery
06:03:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:03:26 DISPATCHER: Finished worker discovery
06:04:26 DISPATCHER: Starting worker discovery
06:04:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:04:26 DISPATCHER: Finished worker discovery
06:05:26 DISPATCHER: Starting worker discovery
06:05:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:05:26 DISPATCHER: Finished worker discovery
06:06:26 DISPATCHER: Starting worker discovery
06:06:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:06:26 DISPATCHER: Finished worker discovery
06:07:26 DISPATCHER: Starting worker discovery
06:07:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:07:26 DISPATCHER: Finished worker discovery
06:08:26 DISPATCHER: Starting worker discovery
06:08:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:08:26 DISPATCHER: Finished worker discovery
06:08:45 WORKER: done with job (5, 0, 3), trying to register it.
06:08:45 WORKER: registered result for job (5, 0, 3) with dispatcher
06:08:45 DISPATCHER: job (5, 0, 3) finished
06:08:45 DISPATCHER: register_result: lock acquired
06:08:45 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
06:08:45 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 442, 'last_n_outputs': 33, 'leak_rate': 0.7893689885812507, 'lr': 0.00256645033314361, 'optimizer': 'SGD', 'sparsity': 0.8785936788612364, 'steps_to_train': 91, 'weight_decay': 0.08854121760276354}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.17348422191161134, 'info': {'data04': 0.17348422191161134, 'config': "{'batch_size': 64, 'hidden_dim': 442, 'last_n_outputs': 33, 'leak_rate': 0.7893689885812507, 'lr': 0.00256645033314361, 'optimizer': 'SGD', 'sparsity': 0.8785936788612364, 'steps_to_train': 91, 'weight_decay': 0.08854121760276354}"}}
exception: None

06:08:45 job_callback for (5, 0, 3) started
06:08:45 DISPATCHER: Trying to submit another job.
06:08:45 job_callback for (5, 0, 3) got condition
06:08:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:08:45 HBMASTER: Trying to run another job!
06:08:45 job_callback for (5, 0, 3) finished
06:08:45 HBMASTER: schedule new run for iteration 5
06:08:45 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
06:08:45 HBMASTER: submitting job (5, 0, 7) to dispatcher
06:08:45 DISPATCHER: trying to submit job (5, 0, 7)
06:08:45 DISPATCHER: trying to notify the job_runner thread.
06:08:45 HBMASTER: job (5, 0, 7) submitted to dispatcher
06:08:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:08:45 DISPATCHER: Trying to submit another job.
06:08:45 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880
06:08:45 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
06:08:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:08:45 WORKER: start processing job (5, 0, 7)
06:08:45 WORKER: args: ()
06:08:45 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 249, 'last_n_outputs': 37, 'leak_rate': 0.8127628004461382, 'lr': 0.0183126824500719, 'optimizer': 'SGD', 'sparsity': 0.878389337355399, 'steps_to_train': 76, 'weight_decay': 0.072999039221244}, 'budget': 400.0, 'working_directory': '.'}
06:09:26 DISPATCHER: Starting worker discovery
06:09:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:09:26 DISPATCHER: Finished worker discovery
06:10:26 DISPATCHER: Starting worker discovery
06:10:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:10:26 DISPATCHER: Finished worker discovery
06:11:26 DISPATCHER: Starting worker discovery
06:11:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:11:26 DISPATCHER: Finished worker discovery
06:12:26 DISPATCHER: Starting worker discovery
06:12:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:12:26 DISPATCHER: Finished worker discovery
06:13:26 DISPATCHER: Starting worker discovery
06:13:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:13:26 DISPATCHER: Finished worker discovery
06:14:26 DISPATCHER: Starting worker discovery
06:14:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:14:26 DISPATCHER: Finished worker discovery
06:15:26 DISPATCHER: Starting worker discovery
06:15:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:15:26 DISPATCHER: Finished worker discovery
06:15:49 WORKER: done with job (5, 0, 7), trying to register it.
06:15:49 WORKER: registered result for job (5, 0, 7) with dispatcher
06:15:49 DISPATCHER: job (5, 0, 7) finished
06:15:49 DISPATCHER: register_result: lock acquired
06:15:49 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
06:15:49 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 249, 'last_n_outputs': 37, 'leak_rate': 0.8127628004461382, 'lr': 0.0183126824500719, 'optimizer': 'SGD', 'sparsity': 0.878389337355399, 'steps_to_train': 76, 'weight_decay': 0.072999039221244}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.16259609633023434, 'info': {'data04': 0.16259609633023434, 'config': "{'batch_size': 128, 'hidden_dim': 249, 'last_n_outputs': 37, 'leak_rate': 0.8127628004461382, 'lr': 0.0183126824500719, 'optimizer': 'SGD', 'sparsity': 0.878389337355399, 'steps_to_train': 76, 'weight_decay': 0.072999039221244}"}}
exception: None

06:15:49 job_callback for (5, 0, 7) started
06:15:49 job_callback for (5, 0, 7) got condition
06:15:49 DISPATCHER: Trying to submit another job.
06:15:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:15:49 HBMASTER: Trying to run another job!
06:15:49 job_callback for (5, 0, 7) finished
06:15:49 HBMASTER: schedule new run for iteration 5
06:15:49 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
06:15:49 HBMASTER: submitting job (5, 0, 8) to dispatcher
06:15:49 DISPATCHER: trying to submit job (5, 0, 8)
06:15:49 DISPATCHER: trying to notify the job_runner thread.
06:15:49 HBMASTER: job (5, 0, 8) submitted to dispatcher
06:15:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:15:49 DISPATCHER: Trying to submit another job.
06:15:49 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880
06:15:49 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
06:15:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:15:49 WORKER: start processing job (5, 0, 8)
06:15:49 WORKER: args: ()
06:15:49 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 865, 'last_n_outputs': 32, 'leak_rate': 0.8514848520155953, 'lr': 0.006033746192322853, 'optimizer': 'SGD', 'sparsity': 0.890459658703948, 'steps_to_train': 63, 'weight_decay': 0.16758957524770451}, 'budget': 400.0, 'working_directory': '.'}
06:16:26 DISPATCHER: Starting worker discovery
06:16:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:16:26 DISPATCHER: Finished worker discovery
06:17:26 DISPATCHER: Starting worker discovery
06:17:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:17:26 DISPATCHER: Finished worker discovery
06:18:26 DISPATCHER: Starting worker discovery
06:18:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:18:26 DISPATCHER: Finished worker discovery
06:19:26 DISPATCHER: Starting worker discovery
06:19:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:19:26 DISPATCHER: Finished worker discovery
06:20:26 DISPATCHER: Starting worker discovery
06:20:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:20:26 DISPATCHER: Finished worker discovery
06:21:26 DISPATCHER: Starting worker discovery
06:21:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:21:26 DISPATCHER: Finished worker discovery
06:22:26 DISPATCHER: Starting worker discovery
06:22:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:22:26 DISPATCHER: Finished worker discovery
06:22:53 WORKER: done with job (5, 0, 8), trying to register it.
06:22:53 WORKER: registered result for job (5, 0, 8) with dispatcher
06:22:53 DISPATCHER: job (5, 0, 8) finished
06:22:53 DISPATCHER: register_result: lock acquired
06:22:53 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
06:22:53 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 865, 'last_n_outputs': 32, 'leak_rate': 0.8514848520155953, 'lr': 0.006033746192322853, 'optimizer': 'SGD', 'sparsity': 0.890459658703948, 'steps_to_train': 63, 'weight_decay': 0.16758957524770451}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.1770163146952935, 'info': {'data04': 0.1770163146952935, 'config': "{'batch_size': 64, 'hidden_dim': 865, 'last_n_outputs': 32, 'leak_rate': 0.8514848520155953, 'lr': 0.006033746192322853, 'optimizer': 'SGD', 'sparsity': 0.890459658703948, 'steps_to_train': 63, 'weight_decay': 0.16758957524770451}"}}
exception: None

06:22:53 job_callback for (5, 0, 8) started
06:22:53 DISPATCHER: Trying to submit another job.
06:22:53 job_callback for (5, 0, 8) got condition
06:22:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:22:53 HBMASTER: Trying to run another job!
06:22:53 job_callback for (5, 0, 8) finished
06:22:53 ITERATION: Advancing config (5, 0, 8) to next budget 1200.000000
06:22:53 HBMASTER: schedule new run for iteration 5
06:22:53 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
06:22:53 HBMASTER: submitting job (5, 0, 8) to dispatcher
06:22:53 DISPATCHER: trying to submit job (5, 0, 8)
06:22:53 DISPATCHER: trying to notify the job_runner thread.
06:22:53 HBMASTER: job (5, 0, 8) submitted to dispatcher
06:22:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:22:53 DISPATCHER: Trying to submit another job.
06:22:53 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880
06:22:53 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
06:22:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:22:53 WORKER: start processing job (5, 0, 8)
06:22:53 WORKER: args: ()
06:22:53 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 865, 'last_n_outputs': 32, 'leak_rate': 0.8514848520155953, 'lr': 0.006033746192322853, 'optimizer': 'SGD', 'sparsity': 0.890459658703948, 'steps_to_train': 63, 'weight_decay': 0.16758957524770451}, 'budget': 1200.0, 'working_directory': '.'}
06:23:26 DISPATCHER: Starting worker discovery
06:23:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:23:26 DISPATCHER: Finished worker discovery
06:24:26 DISPATCHER: Starting worker discovery
06:24:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:24:26 DISPATCHER: Finished worker discovery
06:25:26 DISPATCHER: Starting worker discovery
06:25:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:25:26 DISPATCHER: Finished worker discovery
06:26:26 DISPATCHER: Starting worker discovery
06:26:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:26:26 DISPATCHER: Finished worker discovery
06:27:26 DISPATCHER: Starting worker discovery
06:27:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:27:26 DISPATCHER: Finished worker discovery
06:28:26 DISPATCHER: Starting worker discovery
06:28:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:28:26 DISPATCHER: Finished worker discovery
06:29:26 DISPATCHER: Starting worker discovery
06:29:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:29:26 DISPATCHER: Finished worker discovery
06:30:26 DISPATCHER: Starting worker discovery
06:30:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:30:26 DISPATCHER: Finished worker discovery
06:31:26 DISPATCHER: Starting worker discovery
06:31:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:31:26 DISPATCHER: Finished worker discovery
06:32:26 DISPATCHER: Starting worker discovery
06:32:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:32:26 DISPATCHER: Finished worker discovery
06:33:26 DISPATCHER: Starting worker discovery
06:33:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:33:26 DISPATCHER: Finished worker discovery
06:34:26 DISPATCHER: Starting worker discovery
06:34:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:34:26 DISPATCHER: Finished worker discovery
06:35:26 DISPATCHER: Starting worker discovery
06:35:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:35:26 DISPATCHER: Finished worker discovery
06:36:26 DISPATCHER: Starting worker discovery
06:36:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:36:26 DISPATCHER: Finished worker discovery
06:37:26 DISPATCHER: Starting worker discovery
06:37:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:37:26 DISPATCHER: Finished worker discovery
06:38:26 DISPATCHER: Starting worker discovery
06:38:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:38:26 DISPATCHER: Finished worker discovery
06:39:26 DISPATCHER: Starting worker discovery
06:39:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:39:26 DISPATCHER: Finished worker discovery
06:40:26 DISPATCHER: Starting worker discovery
06:40:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:40:26 DISPATCHER: Finished worker discovery
06:41:26 DISPATCHER: Starting worker discovery
06:41:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:41:26 DISPATCHER: Finished worker discovery
06:42:26 DISPATCHER: Starting worker discovery
06:42:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:42:26 DISPATCHER: Finished worker discovery
06:43:26 DISPATCHER: Starting worker discovery
06:43:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:43:26 DISPATCHER: Finished worker discovery
06:43:34 WORKER: done with job (5, 0, 8), trying to register it.
06:43:34 WORKER: registered result for job (5, 0, 8) with dispatcher
06:43:34 DISPATCHER: job (5, 0, 8) finished
06:43:34 DISPATCHER: register_result: lock acquired
06:43:34 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
06:43:34 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 865, 'last_n_outputs': 32, 'leak_rate': 0.8514848520155953, 'lr': 0.006033746192322853, 'optimizer': 'SGD', 'sparsity': 0.890459658703948, 'steps_to_train': 63, 'weight_decay': 0.16758957524770451}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.17886268245900933, 'info': {'data04': 0.17886268245900933, 'config': "{'batch_size': 64, 'hidden_dim': 865, 'last_n_outputs': 32, 'leak_rate': 0.8514848520155953, 'lr': 0.006033746192322853, 'optimizer': 'SGD', 'sparsity': 0.890459658703948, 'steps_to_train': 63, 'weight_decay': 0.16758957524770451}"}}
exception: None

06:43:34 job_callback for (5, 0, 8) started
06:43:34 DISPATCHER: Trying to submit another job.
06:43:34 job_callback for (5, 0, 8) got condition
06:43:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:43:34 HBMASTER: Trying to run another job!
06:43:34 job_callback for (5, 0, 8) finished
06:43:34 start sampling a new configuration.
06:43:34 best_vector: [0, 0.7632331737301479, 0.6869755256214695, 0.23086192491094124, 0.03441800908577475, 1, 0.486925122798793, 0.48898348314947415, 0.9856830945287032], 0.013056781558753013, 0.04646134439903375, 0.0006066356247441764
06:43:34 done sampling a new configuration.
06:43:34 HBMASTER: schedule new run for iteration 6
06:43:34 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
06:43:34 HBMASTER: submitting job (6, 0, 0) to dispatcher
06:43:34 DISPATCHER: trying to submit job (6, 0, 0)
06:43:34 DISPATCHER: trying to notify the job_runner thread.
06:43:34 HBMASTER: job (6, 0, 0) submitted to dispatcher
06:43:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:43:34 DISPATCHER: Trying to submit another job.
06:43:34 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
06:43:34 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
06:43:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:43:34 WORKER: start processing job (6, 0, 0)
06:43:34 WORKER: args: ()
06:43:34 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 811, 'last_n_outputs': 38, 'leak_rate': 0.8077154812277353, 'lr': 0.0011717528490927307, 'optimizer': 'SGD', 'sparsity': 0.8668620294717103, 'steps_to_train': 54, 'weight_decay': 0.1916034268413817}, 'budget': 400.0, 'working_directory': '.'}
06:44:26 DISPATCHER: Starting worker discovery
06:44:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:44:26 DISPATCHER: Finished worker discovery
06:45:26 DISPATCHER: Starting worker discovery
06:45:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:45:26 DISPATCHER: Finished worker discovery
06:46:26 DISPATCHER: Starting worker discovery
06:46:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:46:26 DISPATCHER: Finished worker discovery
06:47:26 DISPATCHER: Starting worker discovery
06:47:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:47:26 DISPATCHER: Finished worker discovery
06:48:26 DISPATCHER: Starting worker discovery
06:48:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:48:26 DISPATCHER: Finished worker discovery
06:49:26 DISPATCHER: Starting worker discovery
06:49:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:49:26 DISPATCHER: Finished worker discovery
06:50:26 DISPATCHER: Starting worker discovery
06:50:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:50:26 DISPATCHER: Finished worker discovery
06:50:40 WORKER: done with job (6, 0, 0), trying to register it.
06:50:40 WORKER: registered result for job (6, 0, 0) with dispatcher
06:50:40 DISPATCHER: job (6, 0, 0) finished
06:50:40 DISPATCHER: register_result: lock acquired
06:50:40 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
06:50:40 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 811, 'last_n_outputs': 38, 'leak_rate': 0.8077154812277353, 'lr': 0.0011717528490927307, 'optimizer': 'SGD', 'sparsity': 0.8668620294717103, 'steps_to_train': 54, 'weight_decay': 0.1916034268413817}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.17839842044331922, 'info': {'data04': 0.17839842044331922, 'config': "{'batch_size': 16, 'hidden_dim': 811, 'last_n_outputs': 38, 'leak_rate': 0.8077154812277353, 'lr': 0.0011717528490927307, 'optimizer': 'SGD', 'sparsity': 0.8668620294717103, 'steps_to_train': 54, 'weight_decay': 0.1916034268413817}"}}
exception: None

06:50:40 job_callback for (6, 0, 0) started
06:50:40 DISPATCHER: Trying to submit another job.
06:50:40 job_callback for (6, 0, 0) got condition
06:50:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:50:40 HBMASTER: Trying to run another job!
06:50:40 job_callback for (6, 0, 0) finished
06:50:40 start sampling a new configuration.
06:50:40 best_vector: [1, 0.05252482529719846, 0.7952011960180876, 0.17656923043926165, 0.7815084191886141, 1, 0.45912771419008935, 0.649732002697961, 0.8019441523289792], 0.0025828212146299166, 4.434241344093506, 0.011452852614313783
06:50:40 done sampling a new configuration.
06:50:40 HBMASTER: schedule new run for iteration 6
06:50:40 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
06:50:40 HBMASTER: submitting job (6, 0, 1) to dispatcher
06:50:40 DISPATCHER: trying to submit job (6, 0, 1)
06:50:40 DISPATCHER: trying to notify the job_runner thread.
06:50:40 HBMASTER: job (6, 0, 1) submitted to dispatcher
06:50:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:50:40 DISPATCHER: Trying to submit another job.
06:50:40 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
06:50:40 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
06:50:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:50:40 WORKER: start processing job (6, 0, 1)
06:50:40 WORKER: args: ()
06:50:40 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 242, 'last_n_outputs': 42, 'leak_rate': 0.7941423076098154, 'lr': 0.0365608966654743, 'optimizer': 'SGD', 'sparsity': 0.8601906514056215, 'steps_to_train': 69, 'weight_decay': 0.11049774038164834}, 'budget': 400.0, 'working_directory': '.'}
06:51:26 DISPATCHER: Starting worker discovery
06:51:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:51:26 DISPATCHER: Finished worker discovery
06:52:26 DISPATCHER: Starting worker discovery
06:52:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:52:26 DISPATCHER: Finished worker discovery
06:53:26 DISPATCHER: Starting worker discovery
06:53:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:53:26 DISPATCHER: Finished worker discovery
06:54:26 DISPATCHER: Starting worker discovery
06:54:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:54:26 DISPATCHER: Finished worker discovery
06:55:26 DISPATCHER: Starting worker discovery
06:55:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:55:26 DISPATCHER: Finished worker discovery
06:56:26 DISPATCHER: Starting worker discovery
06:56:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:56:26 DISPATCHER: Finished worker discovery
06:57:26 DISPATCHER: Starting worker discovery
06:57:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:57:26 DISPATCHER: Finished worker discovery
06:57:44 WORKER: done with job (6, 0, 1), trying to register it.
06:57:44 WORKER: registered result for job (6, 0, 1) with dispatcher
06:57:44 DISPATCHER: job (6, 0, 1) finished
06:57:44 DISPATCHER: register_result: lock acquired
06:57:44 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
06:57:44 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 242, 'last_n_outputs': 42, 'leak_rate': 0.7941423076098154, 'lr': 0.0365608966654743, 'optimizer': 'SGD', 'sparsity': 0.8601906514056215, 'steps_to_train': 69, 'weight_decay': 0.11049774038164834}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.150070300362419, 'info': {'data04': 0.150070300362419, 'config': "{'batch_size': 32, 'hidden_dim': 242, 'last_n_outputs': 42, 'leak_rate': 0.7941423076098154, 'lr': 0.0365608966654743, 'optimizer': 'SGD', 'sparsity': 0.8601906514056215, 'steps_to_train': 69, 'weight_decay': 0.11049774038164834}"}}
exception: None

06:57:44 job_callback for (6, 0, 1) started
06:57:44 job_callback for (6, 0, 1) got condition
06:57:44 DISPATCHER: Trying to submit another job.
06:57:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:57:44 done building a new model for budget 400.000000 based on 10/17 split
Best loss for this budget:-0.183173





06:57:44 HBMASTER: Trying to run another job!
06:57:44 job_callback for (6, 0, 1) finished
06:57:44 start sampling a new configuration.
06:57:44 best_vector: [0, 0.9964637602784443, 0.5692184036021877, 0.35683315054277204, 0.19015276387054061, 1, 0.5080416864269426, 0.24448218243560432, 0.9360714376018469], 0.00012057935189003477, 0.09353314492725294, 1.1278165995564853e-05
06:57:44 done sampling a new configuration.
06:57:44 HBMASTER: schedule new run for iteration 6
06:57:44 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
06:57:44 HBMASTER: submitting job (6, 0, 2) to dispatcher
06:57:44 DISPATCHER: trying to submit job (6, 0, 2)
06:57:44 DISPATCHER: trying to notify the job_runner thread.
06:57:44 HBMASTER: job (6, 0, 2) submitted to dispatcher
06:57:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:57:44 DISPATCHER: Trying to submit another job.
06:57:44 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
06:57:44 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
06:57:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:57:44 WORKER: start processing job (6, 0, 2)
06:57:44 WORKER: args: ()
06:57:44 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 998, 'last_n_outputs': 33, 'leak_rate': 0.839208287635693, 'lr': 0.0024005211004180962, 'optimizer': 'SGD', 'sparsity': 0.8719300047424662, 'steps_to_train': 32, 'weight_decay': 0.1651418016840404}, 'budget': 400.0, 'working_directory': '.'}
06:58:26 DISPATCHER: Starting worker discovery
06:58:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:58:26 DISPATCHER: Finished worker discovery
06:59:26 DISPATCHER: Starting worker discovery
06:59:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:59:26 DISPATCHER: Finished worker discovery
07:00:26 DISPATCHER: Starting worker discovery
07:00:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:00:26 DISPATCHER: Finished worker discovery
07:01:26 DISPATCHER: Starting worker discovery
07:01:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:01:26 DISPATCHER: Finished worker discovery
07:02:26 DISPATCHER: Starting worker discovery
07:02:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:02:26 DISPATCHER: Finished worker discovery
07:03:26 DISPATCHER: Starting worker discovery
07:03:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:03:26 DISPATCHER: Finished worker discovery
07:04:26 DISPATCHER: Starting worker discovery
07:04:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:04:26 DISPATCHER: Finished worker discovery
07:04:55 WORKER: done with job (6, 0, 2), trying to register it.
07:04:55 WORKER: registered result for job (6, 0, 2) with dispatcher
07:04:55 DISPATCHER: job (6, 0, 2) finished
07:04:55 DISPATCHER: register_result: lock acquired
07:04:55 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
07:04:55 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 998, 'last_n_outputs': 33, 'leak_rate': 0.839208287635693, 'lr': 0.0024005211004180962, 'optimizer': 'SGD', 'sparsity': 0.8719300047424662, 'steps_to_train': 32, 'weight_decay': 0.1651418016840404}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.16216456077198244, 'info': {'data04': 0.16216456077198244, 'config': "{'batch_size': 16, 'hidden_dim': 998, 'last_n_outputs': 33, 'leak_rate': 0.839208287635693, 'lr': 0.0024005211004180962, 'optimizer': 'SGD', 'sparsity': 0.8719300047424662, 'steps_to_train': 32, 'weight_decay': 0.1651418016840404}"}}
exception: None

07:04:55 job_callback for (6, 0, 2) started
07:04:55 job_callback for (6, 0, 2) got condition
07:04:55 DISPATCHER: Trying to submit another job.
07:04:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:04:55 done building a new model for budget 400.000000 based on 10/17 split
Best loss for this budget:-0.183173





07:04:55 HBMASTER: Trying to run another job!
07:04:55 job_callback for (6, 0, 2) finished
07:04:55 start sampling a new configuration.
07:04:55 best_vector: [3, 0.34541882282221736, 0.669060497467303, 0.5259574238068689, 0.03616452118418789, 1, 0.6164466302257948, 0.8737874955901181, 0.4224970695602356], 1.2268438409160717e-32, 0.8150996619531548, -0.011361614325150237
07:04:55 done sampling a new configuration.
07:04:55 HBMASTER: schedule new run for iteration 6
07:04:55 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
07:04:55 HBMASTER: submitting job (6, 0, 3) to dispatcher
07:04:55 DISPATCHER: trying to submit job (6, 0, 3)
07:04:55 DISPATCHER: trying to notify the job_runner thread.
07:04:55 HBMASTER: job (6, 0, 3) submitted to dispatcher
07:04:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:04:55 DISPATCHER: Trying to submit another job.
07:04:55 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
07:04:55 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
07:04:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:04:55 WORKER: start processing job (6, 0, 3)
07:04:55 WORKER: args: ()
07:04:55 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 476, 'last_n_outputs': 37, 'leak_rate': 0.8814893559517172, 'lr': 0.0011812152421381591, 'optimizer': 'SGD', 'sparsity': 0.8979471912541908, 'steps_to_train': 89, 'weight_decay': 0.035455316011882475}, 'budget': 400.0, 'working_directory': '.'}
07:05:26 DISPATCHER: Starting worker discovery
07:05:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:05:26 DISPATCHER: Finished worker discovery
07:06:26 DISPATCHER: Starting worker discovery
07:06:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:06:26 DISPATCHER: Finished worker discovery
07:07:26 DISPATCHER: Starting worker discovery
07:07:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:07:26 DISPATCHER: Finished worker discovery
07:08:26 DISPATCHER: Starting worker discovery
07:08:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:08:26 DISPATCHER: Finished worker discovery
07:09:26 DISPATCHER: Starting worker discovery
07:09:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:09:26 DISPATCHER: Finished worker discovery
07:10:26 DISPATCHER: Starting worker discovery
07:10:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:10:26 DISPATCHER: Finished worker discovery
07:11:26 DISPATCHER: Starting worker discovery
07:11:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:11:26 DISPATCHER: Finished worker discovery
07:11:56 WORKER: done with job (6, 0, 3), trying to register it.
07:11:56 WORKER: registered result for job (6, 0, 3) with dispatcher
07:11:56 DISPATCHER: job (6, 0, 3) finished
07:11:56 DISPATCHER: register_result: lock acquired
07:11:56 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
07:11:56 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 476, 'last_n_outputs': 37, 'leak_rate': 0.8814893559517172, 'lr': 0.0011812152421381591, 'optimizer': 'SGD', 'sparsity': 0.8979471912541908, 'steps_to_train': 89, 'weight_decay': 0.035455316011882475}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.18535912883986128, 'info': {'data04': 0.18535912883986128, 'config': "{'batch_size': 128, 'hidden_dim': 476, 'last_n_outputs': 37, 'leak_rate': 0.8814893559517172, 'lr': 0.0011812152421381591, 'optimizer': 'SGD', 'sparsity': 0.8979471912541908, 'steps_to_train': 89, 'weight_decay': 0.035455316011882475}"}}
exception: None

07:11:56 job_callback for (6, 0, 3) started
07:11:56 DISPATCHER: Trying to submit another job.
07:11:56 job_callback for (6, 0, 3) got condition
07:11:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:11:56 done building a new model for budget 400.000000 based on 10/18 split
Best loss for this budget:-0.185359





07:11:56 HBMASTER: Trying to run another job!
07:11:56 job_callback for (6, 0, 3) finished
07:11:56 start sampling a new configuration.
07:11:56 best_vector: [3, 0.41529852446619187, 0.5336699383202119, 0.003525101152301091, 0.46768858277020997, 1, 0.7355247036169498, 0.6915234140949911, 0.885584426859182], 9.228997963766739e-33, 1.0835412510935893, -0.029100025990661763
07:11:56 done sampling a new configuration.
07:11:56 HBMASTER: schedule new run for iteration 6
07:11:56 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
07:11:56 HBMASTER: submitting job (6, 0, 4) to dispatcher
07:11:56 DISPATCHER: trying to submit job (6, 0, 4)
07:11:56 DISPATCHER: trying to notify the job_runner thread.
07:11:56 HBMASTER: job (6, 0, 4) submitted to dispatcher
07:11:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:11:56 DISPATCHER: Trying to submit another job.
07:11:56 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
07:11:56 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
07:11:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:11:56 WORKER: start processing job (6, 0, 4)
07:11:56 WORKER: args: ()
07:11:56 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 532, 'last_n_outputs': 31, 'leak_rate': 0.7508812752880752, 'lr': 0.00861741811941611, 'optimizer': 'SGD', 'sparsity': 0.926525928868068, 'steps_to_train': 72, 'weight_decay': 0.14196193261608178}, 'budget': 400.0, 'working_directory': '.'}
07:12:26 DISPATCHER: Starting worker discovery
07:12:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:12:26 DISPATCHER: Finished worker discovery
07:13:26 DISPATCHER: Starting worker discovery
07:13:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:13:26 DISPATCHER: Finished worker discovery
07:14:26 DISPATCHER: Starting worker discovery
07:14:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:14:26 DISPATCHER: Finished worker discovery
07:15:26 DISPATCHER: Starting worker discovery
07:15:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:15:26 DISPATCHER: Finished worker discovery
07:16:26 DISPATCHER: Starting worker discovery
07:16:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:16:26 DISPATCHER: Finished worker discovery
07:17:26 DISPATCHER: Starting worker discovery
07:17:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:17:26 DISPATCHER: Finished worker discovery
07:18:26 DISPATCHER: Starting worker discovery
07:18:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:18:26 DISPATCHER: Finished worker discovery
07:18:59 WORKER: done with job (6, 0, 4), trying to register it.
07:18:59 WORKER: registered result for job (6, 0, 4) with dispatcher
07:18:59 DISPATCHER: job (6, 0, 4) finished
07:18:59 DISPATCHER: register_result: lock acquired
07:18:59 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
07:18:59 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 532, 'last_n_outputs': 31, 'leak_rate': 0.7508812752880752, 'lr': 0.00861741811941611, 'optimizer': 'SGD', 'sparsity': 0.926525928868068, 'steps_to_train': 72, 'weight_decay': 0.14196193261608178}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.16794503352230677, 'info': {'data04': 0.16794503352230677, 'config': "{'batch_size': 128, 'hidden_dim': 532, 'last_n_outputs': 31, 'leak_rate': 0.7508812752880752, 'lr': 0.00861741811941611, 'optimizer': 'SGD', 'sparsity': 0.926525928868068, 'steps_to_train': 72, 'weight_decay': 0.14196193261608178}"}}
exception: None

07:18:59 job_callback for (6, 0, 4) started
07:18:59 job_callback for (6, 0, 4) got condition
07:18:59 DISPATCHER: Trying to submit another job.
07:18:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:18:59 done building a new model for budget 400.000000 based on 10/19 split
Best loss for this budget:-0.185359





07:18:59 HBMASTER: Trying to run another job!
07:18:59 job_callback for (6, 0, 4) finished
07:18:59 start sampling a new configuration.
07:18:59 done sampling a new configuration.
07:18:59 HBMASTER: schedule new run for iteration 6
07:18:59 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
07:18:59 HBMASTER: submitting job (6, 0, 5) to dispatcher
07:18:59 DISPATCHER: trying to submit job (6, 0, 5)
07:18:59 DISPATCHER: trying to notify the job_runner thread.
07:18:59 HBMASTER: job (6, 0, 5) submitted to dispatcher
07:18:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:18:59 DISPATCHER: Trying to submit another job.
07:18:59 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
07:18:59 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
07:18:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:18:59 WORKER: start processing job (6, 0, 5)
07:18:59 WORKER: args: ()
07:18:59 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 586, 'last_n_outputs': 34, 'leak_rate': 0.9165268498409401, 'lr': 0.031051832703745685, 'optimizer': 'SGD', 'sparsity': 0.9022882758080152, 'steps_to_train': 52, 'weight_decay': 0.104785190851072}, 'budget': 400.0, 'working_directory': '.'}
07:19:26 DISPATCHER: Starting worker discovery
07:19:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:19:26 DISPATCHER: Finished worker discovery
07:20:26 DISPATCHER: Starting worker discovery
07:20:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:20:26 DISPATCHER: Finished worker discovery
07:21:26 DISPATCHER: Starting worker discovery
07:21:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:21:26 DISPATCHER: Finished worker discovery
07:22:26 DISPATCHER: Starting worker discovery
07:22:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:22:26 DISPATCHER: Finished worker discovery
07:23:26 DISPATCHER: Starting worker discovery
07:23:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:23:26 DISPATCHER: Finished worker discovery
07:24:26 DISPATCHER: Starting worker discovery
07:24:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:24:26 DISPATCHER: Finished worker discovery
07:25:26 DISPATCHER: Starting worker discovery
07:25:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:25:26 DISPATCHER: Finished worker discovery
07:26:05 WORKER: done with job (6, 0, 5), trying to register it.
07:26:05 WORKER: registered result for job (6, 0, 5) with dispatcher
07:26:05 DISPATCHER: job (6, 0, 5) finished
07:26:05 DISPATCHER: register_result: lock acquired
07:26:05 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
07:26:05 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 586, 'last_n_outputs': 34, 'leak_rate': 0.9165268498409401, 'lr': 0.031051832703745685, 'optimizer': 'SGD', 'sparsity': 0.9022882758080152, 'steps_to_train': 52, 'weight_decay': 0.104785190851072}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.1789421928688683, 'info': {'data04': 0.1789421928688683, 'config': "{'batch_size': 128, 'hidden_dim': 586, 'last_n_outputs': 34, 'leak_rate': 0.9165268498409401, 'lr': 0.031051832703745685, 'optimizer': 'SGD', 'sparsity': 0.9022882758080152, 'steps_to_train': 52, 'weight_decay': 0.104785190851072}"}}
exception: None

07:26:05 job_callback for (6, 0, 5) started
07:26:05 job_callback for (6, 0, 5) got condition
07:26:05 DISPATCHER: Trying to submit another job.
07:26:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:26:05 done building a new model for budget 400.000000 based on 10/20 split
Best loss for this budget:-0.185359





07:26:05 HBMASTER: Trying to run another job!
07:26:05 job_callback for (6, 0, 5) finished
07:26:05 ITERATION: Advancing config (6, 0, 3) to next budget 1200.000000
07:26:05 ITERATION: Advancing config (6, 0, 5) to next budget 1200.000000
07:26:05 HBMASTER: schedule new run for iteration 6
07:26:05 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
07:26:05 HBMASTER: submitting job (6, 0, 3) to dispatcher
07:26:05 DISPATCHER: trying to submit job (6, 0, 3)
07:26:05 DISPATCHER: trying to notify the job_runner thread.
07:26:05 HBMASTER: job (6, 0, 3) submitted to dispatcher
07:26:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:26:05 DISPATCHER: Trying to submit another job.
07:26:05 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
07:26:05 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
07:26:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:26:05 WORKER: start processing job (6, 0, 3)
07:26:05 WORKER: args: ()
07:26:05 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 476, 'last_n_outputs': 37, 'leak_rate': 0.8814893559517172, 'lr': 0.0011812152421381591, 'optimizer': 'SGD', 'sparsity': 0.8979471912541908, 'steps_to_train': 89, 'weight_decay': 0.035455316011882475}, 'budget': 1200.0, 'working_directory': '.'}
07:26:26 DISPATCHER: Starting worker discovery
07:26:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:26:26 DISPATCHER: Finished worker discovery
07:27:26 DISPATCHER: Starting worker discovery
07:27:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:27:26 DISPATCHER: Finished worker discovery
07:28:26 DISPATCHER: Starting worker discovery
07:28:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:28:26 DISPATCHER: Finished worker discovery
07:29:26 DISPATCHER: Starting worker discovery
07:29:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:29:26 DISPATCHER: Finished worker discovery
07:30:26 DISPATCHER: Starting worker discovery
07:30:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:30:26 DISPATCHER: Finished worker discovery
07:31:26 DISPATCHER: Starting worker discovery
07:31:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:31:26 DISPATCHER: Finished worker discovery
07:32:26 DISPATCHER: Starting worker discovery
07:32:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:32:26 DISPATCHER: Finished worker discovery
07:33:26 DISPATCHER: Starting worker discovery
07:33:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:33:26 DISPATCHER: Finished worker discovery
07:34:26 DISPATCHER: Starting worker discovery
07:34:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:34:26 DISPATCHER: Finished worker discovery
07:35:26 DISPATCHER: Starting worker discovery
07:35:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:35:26 DISPATCHER: Finished worker discovery
07:36:26 DISPATCHER: Starting worker discovery
07:36:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:36:26 DISPATCHER: Finished worker discovery
07:37:26 DISPATCHER: Starting worker discovery
07:37:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:37:26 DISPATCHER: Finished worker discovery
07:38:26 DISPATCHER: Starting worker discovery
07:38:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:38:26 DISPATCHER: Finished worker discovery
07:39:26 DISPATCHER: Starting worker discovery
07:39:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:39:26 DISPATCHER: Finished worker discovery
07:40:26 DISPATCHER: Starting worker discovery
07:40:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:40:26 DISPATCHER: Finished worker discovery
07:41:26 DISPATCHER: Starting worker discovery
07:41:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:41:26 DISPATCHER: Finished worker discovery
07:42:26 DISPATCHER: Starting worker discovery
07:42:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:42:26 DISPATCHER: Finished worker discovery
07:43:26 DISPATCHER: Starting worker discovery
07:43:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:43:26 DISPATCHER: Finished worker discovery
07:44:26 DISPATCHER: Starting worker discovery
07:44:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:44:26 DISPATCHER: Finished worker discovery
07:45:26 DISPATCHER: Starting worker discovery
07:45:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:45:26 DISPATCHER: Finished worker discovery
07:46:26 DISPATCHER: Starting worker discovery
07:46:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:46:27 DISPATCHER: Finished worker discovery
07:46:39 WORKER: done with job (6, 0, 3), trying to register it.
07:46:39 WORKER: registered result for job (6, 0, 3) with dispatcher
07:46:39 DISPATCHER: job (6, 0, 3) finished
07:46:39 DISPATCHER: register_result: lock acquired
07:46:39 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
07:46:39 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 476, 'last_n_outputs': 37, 'leak_rate': 0.8814893559517172, 'lr': 0.0011812152421381591, 'optimizer': 'SGD', 'sparsity': 0.8979471912541908, 'steps_to_train': 89, 'weight_decay': 0.035455316011882475}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.16726049339849683, 'info': {'data04': 0.16726049339849683, 'config': "{'batch_size': 128, 'hidden_dim': 476, 'last_n_outputs': 37, 'leak_rate': 0.8814893559517172, 'lr': 0.0011812152421381591, 'optimizer': 'SGD', 'sparsity': 0.8979471912541908, 'steps_to_train': 89, 'weight_decay': 0.035455316011882475}"}}
exception: None

07:46:39 job_callback for (6, 0, 3) started
07:46:39 DISPATCHER: Trying to submit another job.
07:46:39 job_callback for (6, 0, 3) got condition
07:46:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:46:39 HBMASTER: Trying to run another job!
07:46:39 job_callback for (6, 0, 3) finished
07:46:39 HBMASTER: schedule new run for iteration 6
07:46:39 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
07:46:39 HBMASTER: submitting job (6, 0, 5) to dispatcher
07:46:39 DISPATCHER: trying to submit job (6, 0, 5)
07:46:39 DISPATCHER: trying to notify the job_runner thread.
07:46:39 HBMASTER: job (6, 0, 5) submitted to dispatcher
07:46:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:46:39 DISPATCHER: Trying to submit another job.
07:46:39 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
07:46:39 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
07:46:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:46:40 WORKER: start processing job (6, 0, 5)
07:46:40 WORKER: args: ()
07:46:40 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 586, 'last_n_outputs': 34, 'leak_rate': 0.9165268498409401, 'lr': 0.031051832703745685, 'optimizer': 'SGD', 'sparsity': 0.9022882758080152, 'steps_to_train': 52, 'weight_decay': 0.104785190851072}, 'budget': 1200.0, 'working_directory': '.'}
07:47:27 DISPATCHER: Starting worker discovery
07:47:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:47:27 DISPATCHER: Finished worker discovery
07:48:27 DISPATCHER: Starting worker discovery
07:48:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:48:27 DISPATCHER: Finished worker discovery
07:49:27 DISPATCHER: Starting worker discovery
07:49:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:49:27 DISPATCHER: Finished worker discovery
07:50:27 DISPATCHER: Starting worker discovery
07:50:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:50:27 DISPATCHER: Finished worker discovery
07:51:27 DISPATCHER: Starting worker discovery
07:51:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:51:27 DISPATCHER: Finished worker discovery
07:52:27 DISPATCHER: Starting worker discovery
07:52:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:52:27 DISPATCHER: Finished worker discovery
07:53:27 DISPATCHER: Starting worker discovery
07:53:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:53:27 DISPATCHER: Finished worker discovery
07:54:27 DISPATCHER: Starting worker discovery
07:54:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:54:27 DISPATCHER: Finished worker discovery
07:55:27 DISPATCHER: Starting worker discovery
07:55:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:55:27 DISPATCHER: Finished worker discovery
07:56:27 DISPATCHER: Starting worker discovery
07:56:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:56:27 DISPATCHER: Finished worker discovery
07:57:27 DISPATCHER: Starting worker discovery
07:57:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:57:27 DISPATCHER: Finished worker discovery
07:58:27 DISPATCHER: Starting worker discovery
07:58:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:58:27 DISPATCHER: Finished worker discovery
07:59:27 DISPATCHER: Starting worker discovery
07:59:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:59:27 DISPATCHER: Finished worker discovery
08:00:27 DISPATCHER: Starting worker discovery
08:00:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:00:27 DISPATCHER: Finished worker discovery
08:01:27 DISPATCHER: Starting worker discovery
08:01:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:01:27 DISPATCHER: Finished worker discovery
08:02:27 DISPATCHER: Starting worker discovery
08:02:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:02:27 DISPATCHER: Finished worker discovery
08:03:27 DISPATCHER: Starting worker discovery
08:03:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:03:27 DISPATCHER: Finished worker discovery
08:04:27 DISPATCHER: Starting worker discovery
08:04:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:04:27 DISPATCHER: Finished worker discovery
08:05:27 DISPATCHER: Starting worker discovery
08:05:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:05:27 DISPATCHER: Finished worker discovery
08:06:27 DISPATCHER: Starting worker discovery
08:06:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:06:27 DISPATCHER: Finished worker discovery
08:07:25 WORKER: done with job (6, 0, 5), trying to register it.
08:07:25 WORKER: registered result for job (6, 0, 5) with dispatcher
08:07:25 DISPATCHER: job (6, 0, 5) finished
08:07:25 DISPATCHER: register_result: lock acquired
08:07:25 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
08:07:25 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 586, 'last_n_outputs': 34, 'leak_rate': 0.9165268498409401, 'lr': 0.031051832703745685, 'optimizer': 'SGD', 'sparsity': 0.9022882758080152, 'steps_to_train': 52, 'weight_decay': 0.104785190851072}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.1593516249419524, 'info': {'data04': 0.1593516249419524, 'config': "{'batch_size': 128, 'hidden_dim': 586, 'last_n_outputs': 34, 'leak_rate': 0.9165268498409401, 'lr': 0.031051832703745685, 'optimizer': 'SGD', 'sparsity': 0.9022882758080152, 'steps_to_train': 52, 'weight_decay': 0.104785190851072}"}}
exception: None

08:07:25 job_callback for (6, 0, 5) started
08:07:25 DISPATCHER: Trying to submit another job.
08:07:25 job_callback for (6, 0, 5) got condition
08:07:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:07:25 HBMASTER: Trying to run another job!
08:07:25 job_callback for (6, 0, 5) finished
08:07:25 start sampling a new configuration.
08:07:25 best_vector: [0, 0.5374929101003039, 0.7557822691894667, 0.22388071570648443, 0.31412225089172596, 1, 0.008990047099462495, 0.588277854447353, 0.46196783358861315], 0.0031958674276319817, 0.2033452001000337, 0.0006498643015650053
08:07:25 done sampling a new configuration.
08:07:25 HBMASTER: schedule new run for iteration 7
08:07:25 HBMASTER: trying submitting job (7, 0, 0) to dispatcher
08:07:25 HBMASTER: submitting job (7, 0, 0) to dispatcher
08:07:25 DISPATCHER: trying to submit job (7, 0, 0)
08:07:25 DISPATCHER: trying to notify the job_runner thread.
08:07:25 HBMASTER: job (7, 0, 0) submitted to dispatcher
08:07:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:07:25 DISPATCHER: Trying to submit another job.
08:07:25 DISPATCHER: starting job (7, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:07:25 DISPATCHER: job (7, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:07:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:07:25 WORKER: start processing job (7, 0, 0)
08:07:25 WORKER: args: ()
08:07:25 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 630, 'last_n_outputs': 40, 'leak_rate': 0.8059701789266212, 'lr': 0.004248586861897799, 'optimizer': 'SGD', 'sparsity': 0.752157611303871, 'steps_to_train': 63, 'weight_decay': 0.03990561502424279}, 'budget': 1200.0, 'working_directory': '.'}
08:07:27 DISPATCHER: Starting worker discovery
08:07:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:07:27 DISPATCHER: Finished worker discovery
08:08:27 DISPATCHER: Starting worker discovery
08:08:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:08:27 DISPATCHER: Finished worker discovery
08:09:27 DISPATCHER: Starting worker discovery
08:09:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:09:27 DISPATCHER: Finished worker discovery
08:10:27 DISPATCHER: Starting worker discovery
08:10:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:10:27 DISPATCHER: Finished worker discovery
08:11:27 DISPATCHER: Starting worker discovery
08:11:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:11:27 DISPATCHER: Finished worker discovery
08:12:27 DISPATCHER: Starting worker discovery
08:12:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:12:27 DISPATCHER: Finished worker discovery
08:13:27 DISPATCHER: Starting worker discovery
08:13:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:13:27 DISPATCHER: Finished worker discovery
08:14:27 DISPATCHER: Starting worker discovery
08:14:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:14:27 DISPATCHER: Finished worker discovery
08:15:27 DISPATCHER: Starting worker discovery
08:15:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:15:27 DISPATCHER: Finished worker discovery
08:16:27 DISPATCHER: Starting worker discovery
08:16:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:16:27 DISPATCHER: Finished worker discovery
08:17:27 DISPATCHER: Starting worker discovery
08:17:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:17:27 DISPATCHER: Finished worker discovery
08:18:27 DISPATCHER: Starting worker discovery
08:18:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:18:27 DISPATCHER: Finished worker discovery
08:19:27 DISPATCHER: Starting worker discovery
08:19:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:19:27 DISPATCHER: Finished worker discovery
08:20:27 DISPATCHER: Starting worker discovery
08:20:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:20:27 DISPATCHER: Finished worker discovery
08:21:27 DISPATCHER: Starting worker discovery
08:21:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:21:27 DISPATCHER: Finished worker discovery
08:22:27 DISPATCHER: Starting worker discovery
08:22:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:22:27 DISPATCHER: Finished worker discovery
08:23:27 DISPATCHER: Starting worker discovery
08:23:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:23:27 DISPATCHER: Finished worker discovery
08:24:27 DISPATCHER: Starting worker discovery
08:24:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:24:27 DISPATCHER: Finished worker discovery
08:25:27 DISPATCHER: Starting worker discovery
08:25:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:25:27 DISPATCHER: Finished worker discovery
08:26:27 DISPATCHER: Starting worker discovery
08:26:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:26:27 DISPATCHER: Finished worker discovery
08:27:27 DISPATCHER: Starting worker discovery
08:27:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:27:27 DISPATCHER: Finished worker discovery
08:28:07 WORKER: done with job (7, 0, 0), trying to register it.
08:28:07 WORKER: registered result for job (7, 0, 0) with dispatcher
08:28:07 DISPATCHER: job (7, 0, 0) finished
08:28:07 DISPATCHER: register_result: lock acquired
08:28:07 DISPATCHER: job (7, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
08:28:07 job_id: (7, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 630, 'last_n_outputs': 40, 'leak_rate': 0.8059701789266212, 'lr': 0.004248586861897799, 'optimizer': 'SGD', 'sparsity': 0.752157611303871, 'steps_to_train': 63, 'weight_decay': 0.03990561502424279}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.18294823217649486, 'info': {'data04': 0.18294823217649486, 'config': "{'batch_size': 16, 'hidden_dim': 630, 'last_n_outputs': 40, 'leak_rate': 0.8059701789266212, 'lr': 0.004248586861897799, 'optimizer': 'SGD', 'sparsity': 0.752157611303871, 'steps_to_train': 63, 'weight_decay': 0.03990561502424279}"}}
exception: None

08:28:07 job_callback for (7, 0, 0) started
08:28:07 job_callback for (7, 0, 0) got condition
08:28:07 DISPATCHER: Trying to submit another job.
08:28:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:28:07 HBMASTER: Trying to run another job!
08:28:07 job_callback for (7, 0, 0) finished
08:28:07 start sampling a new configuration.
08:28:07 done sampling a new configuration.
08:28:07 HBMASTER: schedule new run for iteration 7
08:28:07 HBMASTER: trying submitting job (7, 0, 1) to dispatcher
08:28:07 HBMASTER: submitting job (7, 0, 1) to dispatcher
08:28:07 DISPATCHER: trying to submit job (7, 0, 1)
08:28:07 DISPATCHER: trying to notify the job_runner thread.
08:28:07 HBMASTER: job (7, 0, 1) submitted to dispatcher
08:28:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:28:07 DISPATCHER: Trying to submit another job.
08:28:07 DISPATCHER: starting job (7, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:28:07 DISPATCHER: job (7, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:28:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:28:07 WORKER: start processing job (7, 0, 1)
08:28:07 WORKER: args: ()
08:28:07 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 210, 'last_n_outputs': 30, 'leak_rate': 0.8809941714062803, 'lr': 0.02813686332842766, 'optimizer': 'Adam', 'sparsity': 0.7625580202562354, 'steps_to_train': 88, 'weight_decay': 0.06301954214872013}, 'budget': 1200.0, 'working_directory': '.'}
08:28:27 DISPATCHER: Starting worker discovery
08:28:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:28:27 DISPATCHER: Finished worker discovery
08:29:27 DISPATCHER: Starting worker discovery
08:29:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:29:27 DISPATCHER: Finished worker discovery
08:30:27 DISPATCHER: Starting worker discovery
08:30:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:30:27 DISPATCHER: Finished worker discovery
08:31:27 DISPATCHER: Starting worker discovery
08:31:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:31:27 DISPATCHER: Finished worker discovery
08:32:27 DISPATCHER: Starting worker discovery
08:32:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:32:27 DISPATCHER: Finished worker discovery
08:33:27 DISPATCHER: Starting worker discovery
08:33:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:33:27 DISPATCHER: Finished worker discovery
08:34:27 DISPATCHER: Starting worker discovery
08:34:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:34:27 DISPATCHER: Finished worker discovery
08:35:27 DISPATCHER: Starting worker discovery
08:35:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:35:27 DISPATCHER: Finished worker discovery
08:36:27 DISPATCHER: Starting worker discovery
08:36:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:36:27 DISPATCHER: Finished worker discovery
08:37:27 DISPATCHER: Starting worker discovery
08:37:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:37:27 DISPATCHER: Finished worker discovery
08:38:27 DISPATCHER: Starting worker discovery
08:38:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:38:27 DISPATCHER: Finished worker discovery
08:39:27 DISPATCHER: Starting worker discovery
08:39:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:39:27 DISPATCHER: Finished worker discovery
08:40:27 DISPATCHER: Starting worker discovery
08:40:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:40:27 DISPATCHER: Finished worker discovery
08:41:27 DISPATCHER: Starting worker discovery
08:41:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:41:27 DISPATCHER: Finished worker discovery
08:42:27 DISPATCHER: Starting worker discovery
08:42:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:42:27 DISPATCHER: Finished worker discovery
08:43:27 DISPATCHER: Starting worker discovery
08:43:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:43:27 DISPATCHER: Finished worker discovery
08:44:27 DISPATCHER: Starting worker discovery
08:44:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:44:27 DISPATCHER: Finished worker discovery
08:45:27 DISPATCHER: Starting worker discovery
08:45:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:45:27 DISPATCHER: Finished worker discovery
08:46:27 DISPATCHER: Starting worker discovery
08:46:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:46:27 DISPATCHER: Finished worker discovery
08:47:27 DISPATCHER: Starting worker discovery
08:47:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:47:27 DISPATCHER: Finished worker discovery
08:48:27 DISPATCHER: Starting worker discovery
08:48:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:48:27 DISPATCHER: Finished worker discovery
08:48:39 WORKER: done with job (7, 0, 1), trying to register it.
08:48:39 WORKER: registered result for job (7, 0, 1) with dispatcher
08:48:39 DISPATCHER: job (7, 0, 1) finished
08:48:39 DISPATCHER: register_result: lock acquired
08:48:39 DISPATCHER: job (7, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
08:48:39 job_id: (7, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 210, 'last_n_outputs': 30, 'leak_rate': 0.8809941714062803, 'lr': 0.02813686332842766, 'optimizer': 'Adam', 'sparsity': 0.7625580202562354, 'steps_to_train': 88, 'weight_decay': 0.06301954214872013}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.022549548896222536, 'info': {'data04': 0.022549548896222536, 'config': "{'batch_size': 32, 'hidden_dim': 210, 'last_n_outputs': 30, 'leak_rate': 0.8809941714062803, 'lr': 0.02813686332842766, 'optimizer': 'Adam', 'sparsity': 0.7625580202562354, 'steps_to_train': 88, 'weight_decay': 0.06301954214872013}"}}
exception: None

08:48:39 job_callback for (7, 0, 1) started
08:48:39 job_callback for (7, 0, 1) got condition
08:48:39 DISPATCHER: Trying to submit another job.
08:48:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:48:39 HBMASTER: Trying to run another job!
08:48:39 job_callback for (7, 0, 1) finished
08:48:39 start sampling a new configuration.
08:48:39 best_vector: [2, 0.7121139454795486, 0.6545286426361535, 0.5812375049635851, 0.005046913339474962, 1, 0.6503153487835386, 0.9766732223369595, 0.5889871637198449], 0.0048076020919080266, 4.773267596124368, 0.02294797128036431
08:48:39 done sampling a new configuration.
08:48:39 HBMASTER: schedule new run for iteration 7
08:48:39 HBMASTER: trying submitting job (7, 0, 2) to dispatcher
08:48:39 HBMASTER: submitting job (7, 0, 2) to dispatcher
08:48:39 DISPATCHER: trying to submit job (7, 0, 2)
08:48:39 DISPATCHER: trying to notify the job_runner thread.
08:48:39 HBMASTER: job (7, 0, 2) submitted to dispatcher
08:48:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:48:39 DISPATCHER: Trying to submit another job.
08:48:39 DISPATCHER: starting job (7, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:48:39 DISPATCHER: job (7, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:48:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:48:39 WORKER: start processing job (7, 0, 2)
08:48:39 WORKER: args: ()
08:48:39 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 770, 'last_n_outputs': 36, 'leak_rate': 0.8953093762408962, 'lr': 0.0010235140923850166, 'optimizer': 'SGD', 'sparsity': 0.9060756837080493, 'steps_to_train': 98, 'weight_decay': 0.05838347853772299}, 'budget': 1200.0, 'working_directory': '.'}
08:49:27 DISPATCHER: Starting worker discovery
08:49:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:49:27 DISPATCHER: Finished worker discovery
08:50:27 DISPATCHER: Starting worker discovery
08:50:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:50:27 DISPATCHER: Finished worker discovery
08:51:27 DISPATCHER: Starting worker discovery
08:51:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:51:27 DISPATCHER: Finished worker discovery
08:52:27 DISPATCHER: Starting worker discovery
08:52:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:52:27 DISPATCHER: Finished worker discovery
08:53:27 DISPATCHER: Starting worker discovery
08:53:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:53:27 DISPATCHER: Finished worker discovery
08:54:27 DISPATCHER: Starting worker discovery
08:54:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:54:27 DISPATCHER: Finished worker discovery
08:55:27 DISPATCHER: Starting worker discovery
08:55:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:55:27 DISPATCHER: Finished worker discovery
08:56:27 DISPATCHER: Starting worker discovery
08:56:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:56:27 DISPATCHER: Finished worker discovery
08:57:27 DISPATCHER: Starting worker discovery
08:57:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:57:27 DISPATCHER: Finished worker discovery
08:58:27 DISPATCHER: Starting worker discovery
08:58:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:58:27 DISPATCHER: Finished worker discovery
08:59:27 DISPATCHER: Starting worker discovery
08:59:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:59:27 DISPATCHER: Finished worker discovery
09:00:27 DISPATCHER: Starting worker discovery
09:00:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:00:27 DISPATCHER: Finished worker discovery
09:01:27 DISPATCHER: Starting worker discovery
09:01:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:01:27 DISPATCHER: Finished worker discovery
09:02:27 DISPATCHER: Starting worker discovery
09:02:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:02:27 DISPATCHER: Finished worker discovery
09:03:27 DISPATCHER: Starting worker discovery
09:03:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:03:27 DISPATCHER: Finished worker discovery
09:04:27 DISPATCHER: Starting worker discovery
09:04:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:04:27 DISPATCHER: Finished worker discovery
09:05:27 DISPATCHER: Starting worker discovery
09:05:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:05:27 DISPATCHER: Finished worker discovery
09:06:27 DISPATCHER: Starting worker discovery
09:06:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:06:27 DISPATCHER: Finished worker discovery
09:07:27 DISPATCHER: Starting worker discovery
09:07:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:07:27 DISPATCHER: Finished worker discovery
09:08:27 DISPATCHER: Starting worker discovery
09:08:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:08:27 DISPATCHER: Finished worker discovery
09:09:12 WORKER: done with job (7, 0, 2), trying to register it.
09:09:12 WORKER: registered result for job (7, 0, 2) with dispatcher
09:09:12 DISPATCHER: job (7, 0, 2) finished
09:09:12 DISPATCHER: register_result: lock acquired
09:09:12 DISPATCHER: job (7, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:09:12 job_id: (7, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 770, 'last_n_outputs': 36, 'leak_rate': 0.8953093762408962, 'lr': 0.0010235140923850166, 'optimizer': 'SGD', 'sparsity': 0.9060756837080493, 'steps_to_train': 98, 'weight_decay': 0.05838347853772299}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.1620112912299801, 'info': {'data04': 0.1620112912299801, 'config': "{'batch_size': 64, 'hidden_dim': 770, 'last_n_outputs': 36, 'leak_rate': 0.8953093762408962, 'lr': 0.0010235140923850166, 'optimizer': 'SGD', 'sparsity': 0.9060756837080493, 'steps_to_train': 98, 'weight_decay': 0.05838347853772299}"}}
exception: None

09:09:12 job_callback for (7, 0, 2) started
09:09:12 DISPATCHER: Trying to submit another job.
09:09:12 job_callback for (7, 0, 2) got condition
09:09:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:09:12 HBMASTER: Trying to run another job!
09:09:12 job_callback for (7, 0, 2) finished
09:09:12 start sampling a new configuration.
09:09:13 best_vector: [1, 0.8819575218664366, 0.6885815687097939, 0.3898933441899903, 0.30561520586299873, 1, 0.9702495303570943, 0.9747504668451051, 0.16024206883420833], 0.0005889102501034792, 0.062013519685032395, 3.652039738750946e-05
09:09:13 done sampling a new configuration.
09:09:13 HBMASTER: schedule new run for iteration 7
09:09:13 HBMASTER: trying submitting job (7, 0, 3) to dispatcher
09:09:13 HBMASTER: submitting job (7, 0, 3) to dispatcher
09:09:13 DISPATCHER: trying to submit job (7, 0, 3)
09:09:13 DISPATCHER: trying to notify the job_runner thread.
09:09:13 HBMASTER: job (7, 0, 3) submitted to dispatcher
09:09:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:09:13 DISPATCHER: Trying to submit another job.
09:09:13 DISPATCHER: starting job (7, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:09:13 DISPATCHER: job (7, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:09:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:09:13 WORKER: start processing job (7, 0, 3)
09:09:13 WORKER: args: ()
09:09:13 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 906, 'last_n_outputs': 38, 'leak_rate': 0.8474733360474975, 'lr': 0.004085360746399135, 'optimizer': 'SGD', 'sparsity': 0.9828598872857026, 'steps_to_train': 98, 'weight_decay': 0.016161428236865706}, 'budget': 1200.0, 'working_directory': '.'}
09:09:27 DISPATCHER: Starting worker discovery
09:09:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:09:27 DISPATCHER: Finished worker discovery
09:10:27 DISPATCHER: Starting worker discovery
09:10:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:10:27 DISPATCHER: Finished worker discovery
09:11:27 DISPATCHER: Starting worker discovery
09:11:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:11:27 DISPATCHER: Finished worker discovery
09:12:27 DISPATCHER: Starting worker discovery
09:12:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:12:27 DISPATCHER: Finished worker discovery
09:13:27 DISPATCHER: Starting worker discovery
09:13:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:13:27 DISPATCHER: Finished worker discovery
09:14:27 DISPATCHER: Starting worker discovery
09:14:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:14:27 DISPATCHER: Finished worker discovery
09:15:27 DISPATCHER: Starting worker discovery
09:15:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:15:27 DISPATCHER: Finished worker discovery
09:16:27 DISPATCHER: Starting worker discovery
09:16:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:16:27 DISPATCHER: Finished worker discovery
09:17:27 DISPATCHER: Starting worker discovery
09:17:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:17:27 DISPATCHER: Finished worker discovery
09:18:27 DISPATCHER: Starting worker discovery
09:18:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:18:27 DISPATCHER: Finished worker discovery
09:19:27 DISPATCHER: Starting worker discovery
09:19:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:19:27 DISPATCHER: Finished worker discovery
09:20:27 DISPATCHER: Starting worker discovery
09:20:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:20:27 DISPATCHER: Finished worker discovery
09:21:27 DISPATCHER: Starting worker discovery
09:21:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:21:27 DISPATCHER: Finished worker discovery
09:22:27 DISPATCHER: Starting worker discovery
09:22:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:22:27 DISPATCHER: Finished worker discovery
09:23:27 DISPATCHER: Starting worker discovery
09:23:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:23:27 DISPATCHER: Finished worker discovery
09:24:27 DISPATCHER: Starting worker discovery
09:24:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:24:27 DISPATCHER: Finished worker discovery
09:25:27 DISPATCHER: Starting worker discovery
09:25:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:25:27 DISPATCHER: Finished worker discovery
09:26:27 DISPATCHER: Starting worker discovery
09:26:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:26:27 DISPATCHER: Finished worker discovery
09:27:27 DISPATCHER: Starting worker discovery
09:27:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:27:27 DISPATCHER: Finished worker discovery
09:28:27 DISPATCHER: Starting worker discovery
09:28:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:28:27 DISPATCHER: Finished worker discovery
09:29:27 DISPATCHER: Starting worker discovery
09:29:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:29:27 DISPATCHER: Finished worker discovery
09:29:45 WORKER: done with job (7, 0, 3), trying to register it.
09:29:45 WORKER: registered result for job (7, 0, 3) with dispatcher
09:29:45 DISPATCHER: job (7, 0, 3) finished
09:29:45 DISPATCHER: register_result: lock acquired
09:29:45 DISPATCHER: job (7, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:29:45 job_id: (7, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 906, 'last_n_outputs': 38, 'leak_rate': 0.8474733360474975, 'lr': 0.004085360746399135, 'optimizer': 'SGD', 'sparsity': 0.9828598872857026, 'steps_to_train': 98, 'weight_decay': 0.016161428236865706}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.17209883694478462, 'info': {'data04': 0.17209883694478462, 'config': "{'batch_size': 32, 'hidden_dim': 906, 'last_n_outputs': 38, 'leak_rate': 0.8474733360474975, 'lr': 0.004085360746399135, 'optimizer': 'SGD', 'sparsity': 0.9828598872857026, 'steps_to_train': 98, 'weight_decay': 0.016161428236865706}"}}
exception: None

09:29:45 job_callback for (7, 0, 3) started
09:29:45 DISPATCHER: Trying to submit another job.
09:29:45 job_callback for (7, 0, 3) got condition
09:29:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:29:45 HBMASTER: Trying to run another job!
09:29:45 job_callback for (7, 0, 3) finished
09:29:45 start sampling a new configuration.
09:29:45 done sampling a new configuration.
09:29:45 HBMASTER: schedule new run for iteration 8
09:29:45 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
09:29:45 HBMASTER: submitting job (8, 0, 0) to dispatcher
09:29:45 DISPATCHER: trying to submit job (8, 0, 0)
09:29:45 DISPATCHER: trying to notify the job_runner thread.
09:29:45 HBMASTER: job (8, 0, 0) submitted to dispatcher
09:29:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:29:45 DISPATCHER: Trying to submit another job.
09:29:45 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:29:45 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:29:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:29:45 WORKER: start processing job (8, 0, 0)
09:29:45 WORKER: args: ()
09:29:45 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 267, 'last_n_outputs': 12, 'leak_rate': 0.9390668817207696, 'lr': 0.008920734322578202, 'optimizer': 'Adam', 'sparsity': 0.8352069707466645, 'steps_to_train': 46, 'weight_decay': 0.03251137475629032}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:30:27 DISPATCHER: Starting worker discovery
09:30:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:30:27 DISPATCHER: Finished worker discovery
09:30:48 WORKER: done with job (8, 0, 0), trying to register it.
09:30:48 WORKER: registered result for job (8, 0, 0) with dispatcher
09:30:48 DISPATCHER: job (8, 0, 0) finished
09:30:48 DISPATCHER: register_result: lock acquired
09:30:48 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:30:48 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 267, 'last_n_outputs': 12, 'leak_rate': 0.9390668817207696, 'lr': 0.008920734322578202, 'optimizer': 'Adam', 'sparsity': 0.8352069707466645, 'steps_to_train': 46, 'weight_decay': 0.03251137475629032}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.028230053736213335, 'info': {'data04': 0.028230053736213335, 'config': "{'batch_size': 32, 'hidden_dim': 267, 'last_n_outputs': 12, 'leak_rate': 0.9390668817207696, 'lr': 0.008920734322578202, 'optimizer': 'Adam', 'sparsity': 0.8352069707466645, 'steps_to_train': 46, 'weight_decay': 0.03251137475629032}"}}
exception: None

09:30:48 job_callback for (8, 0, 0) started
09:30:48 job_callback for (8, 0, 0) got condition
09:30:48 DISPATCHER: Trying to submit another job.
09:30:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:30:48 HBMASTER: Trying to run another job!
09:30:48 job_callback for (8, 0, 0) finished
09:30:48 start sampling a new configuration.
09:30:48 best_vector: [2, 0.6949947104228948, 0.6643081863833503, 0.6079174561279254, 0.23080203681581077, 1, 0.9356397667105318, 0.8423035510361189, 0.09663001810525829], 0.00037245178274912625, 0.224954076353929, 8.378454677470392e-05
09:30:48 done sampling a new configuration.
09:30:48 HBMASTER: schedule new run for iteration 8
09:30:48 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
09:30:48 HBMASTER: submitting job (8, 0, 1) to dispatcher
09:30:48 DISPATCHER: trying to submit job (8, 0, 1)
09:30:48 DISPATCHER: trying to notify the job_runner thread.
09:30:48 HBMASTER: job (8, 0, 1) submitted to dispatcher
09:30:48 DISPATCHER: Trying to submit another job.
09:30:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:30:48 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:30:48 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:30:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:30:48 WORKER: start processing job (8, 0, 1)
09:30:48 WORKER: args: ()
09:30:48 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 756, 'last_n_outputs': 37, 'leak_rate': 0.9019793640319813, 'lr': 0.0028947034160293436, 'optimizer': 'SGD', 'sparsity': 0.9745535440105276, 'steps_to_train': 86, 'weight_decay': 0.013357296058930119}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:31:27 DISPATCHER: Starting worker discovery
09:31:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:31:27 DISPATCHER: Finished worker discovery
09:31:50 WORKER: done with job (8, 0, 1), trying to register it.
09:31:50 WORKER: registered result for job (8, 0, 1) with dispatcher
09:31:50 DISPATCHER: job (8, 0, 1) finished
09:31:50 DISPATCHER: register_result: lock acquired
09:31:50 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:31:50 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 756, 'last_n_outputs': 37, 'leak_rate': 0.9019793640319813, 'lr': 0.0028947034160293436, 'optimizer': 'SGD', 'sparsity': 0.9745535440105276, 'steps_to_train': 86, 'weight_decay': 0.013357296058930119}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.18012925196623103, 'info': {'data04': 0.18012925196623103, 'config': "{'batch_size': 64, 'hidden_dim': 756, 'last_n_outputs': 37, 'leak_rate': 0.9019793640319813, 'lr': 0.0028947034160293436, 'optimizer': 'SGD', 'sparsity': 0.9745535440105276, 'steps_to_train': 86, 'weight_decay': 0.013357296058930119}"}}
exception: None

09:31:50 job_callback for (8, 0, 1) started
09:31:50 job_callback for (8, 0, 1) got condition
09:31:50 DISPATCHER: Trying to submit another job.
09:31:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:31:50 HBMASTER: Trying to run another job!
09:31:50 job_callback for (8, 0, 1) finished
09:31:50 start sampling a new configuration.
09:31:50 best_vector: [1, 0.6808774511329605, 0.7527253384600247, 0.4647019805909141, 0.1925232571930663, 1, 0.9374536790564874, 0.6123661800431859, 0.3820439188297794], 0.012406762660359918, 0.08141983915426965, 0.0010101566202317031
09:31:50 done sampling a new configuration.
09:31:50 HBMASTER: schedule new run for iteration 8
09:31:50 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
09:31:50 HBMASTER: submitting job (8, 0, 2) to dispatcher
09:31:50 DISPATCHER: trying to submit job (8, 0, 2)
09:31:50 DISPATCHER: trying to notify the job_runner thread.
09:31:50 HBMASTER: job (8, 0, 2) submitted to dispatcher
09:31:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:31:50 DISPATCHER: Trying to submit another job.
09:31:50 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:31:50 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:31:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:31:50 WORKER: start processing job (8, 0, 2)
09:31:50 WORKER: args: ()
09:31:50 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 745, 'last_n_outputs': 40, 'leak_rate': 0.8661754951477285, 'lr': 0.0024268700070278213, 'optimizer': 'SGD', 'sparsity': 0.9749888829735569, 'steps_to_train': 65, 'weight_decay': 0.031408746043503716}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:32:27 DISPATCHER: Starting worker discovery
09:32:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:32:27 DISPATCHER: Finished worker discovery
09:32:52 WORKER: done with job (8, 0, 2), trying to register it.
09:32:52 WORKER: registered result for job (8, 0, 2) with dispatcher
09:32:52 DISPATCHER: job (8, 0, 2) finished
09:32:52 DISPATCHER: register_result: lock acquired
09:32:52 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:32:52 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 745, 'last_n_outputs': 40, 'leak_rate': 0.8661754951477285, 'lr': 0.0024268700070278213, 'optimizer': 'SGD', 'sparsity': 0.9749888829735569, 'steps_to_train': 65, 'weight_decay': 0.031408746043503716}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.18235650085057428, 'info': {'data04': 0.18235650085057428, 'config': "{'batch_size': 32, 'hidden_dim': 745, 'last_n_outputs': 40, 'leak_rate': 0.8661754951477285, 'lr': 0.0024268700070278213, 'optimizer': 'SGD', 'sparsity': 0.9749888829735569, 'steps_to_train': 65, 'weight_decay': 0.031408746043503716}"}}
exception: None

09:32:52 job_callback for (8, 0, 2) started
09:32:52 job_callback for (8, 0, 2) got condition
09:32:52 DISPATCHER: Trying to submit another job.
09:32:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:32:52 HBMASTER: Trying to run another job!
09:32:52 job_callback for (8, 0, 2) finished
09:32:52 start sampling a new configuration.
09:32:52 best_vector: [2, 0.07329352710178849, 0.8445487376485956, 0.1671199667574717, 0.18031462922865502, 1, 0.05252351390596449, 0.675479302297568, 0.8407817310145115], 7.999304202001882e-05, 4.0194984959293505, 0.000321531912084279
09:32:52 done sampling a new configuration.
09:32:52 HBMASTER: schedule new run for iteration 8
09:32:52 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
09:32:52 HBMASTER: submitting job (8, 0, 3) to dispatcher
09:32:52 DISPATCHER: trying to submit job (8, 0, 3)
09:32:52 DISPATCHER: trying to notify the job_runner thread.
09:32:52 HBMASTER: job (8, 0, 3) submitted to dispatcher
09:32:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:32:52 DISPATCHER: Trying to submit another job.
09:32:52 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:32:52 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:32:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:32:52 WORKER: start processing job (8, 0, 3)
09:32:52 WORKER: args: ()
09:32:52 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 258, 'last_n_outputs': 44, 'leak_rate': 0.791779991689368, 'lr': 0.0022941893452007736, 'optimizer': 'SGD', 'sparsity': 0.7626056433374315, 'steps_to_train': 71, 'weight_decay': 0.12413157100926996}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:33:27 DISPATCHER: Starting worker discovery
09:33:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:33:27 DISPATCHER: Finished worker discovery
09:33:53 WORKER: done with job (8, 0, 3), trying to register it.
09:33:53 WORKER: registered result for job (8, 0, 3) with dispatcher
09:33:53 DISPATCHER: job (8, 0, 3) finished
09:33:53 DISPATCHER: register_result: lock acquired
09:33:53 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:33:53 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 258, 'last_n_outputs': 44, 'leak_rate': 0.791779991689368, 'lr': 0.0022941893452007736, 'optimizer': 'SGD', 'sparsity': 0.7626056433374315, 'steps_to_train': 71, 'weight_decay': 0.12413157100926996}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.15266074859835882, 'info': {'data04': 0.15266074859835882, 'config': "{'batch_size': 64, 'hidden_dim': 258, 'last_n_outputs': 44, 'leak_rate': 0.791779991689368, 'lr': 0.0022941893452007736, 'optimizer': 'SGD', 'sparsity': 0.7626056433374315, 'steps_to_train': 71, 'weight_decay': 0.12413157100926996}"}}
exception: None

09:33:53 job_callback for (8, 0, 3) started
09:33:53 job_callback for (8, 0, 3) got condition
09:33:53 DISPATCHER: Trying to submit another job.
09:33:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:33:53 HBMASTER: Trying to run another job!
09:33:53 job_callback for (8, 0, 3) finished
09:33:53 start sampling a new configuration.
09:33:53 best_vector: [3, 0.9449422344590244, 0.6923089111140229, 0.9744379456166529, 0.375734907220421, 1, 0.7699040722367867, 0.816620672343056, 0.15353066682179883], 0.0017945357425680857, 0.31940393817677915, 0.0005731817833752373
09:33:53 done sampling a new configuration.
09:33:53 HBMASTER: schedule new run for iteration 8
09:33:53 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
09:33:53 HBMASTER: submitting job (8, 0, 4) to dispatcher
09:33:53 DISPATCHER: trying to submit job (8, 0, 4)
09:33:53 DISPATCHER: trying to notify the job_runner thread.
09:33:53 HBMASTER: job (8, 0, 4) submitted to dispatcher
09:33:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:33:53 DISPATCHER: Trying to submit another job.
09:33:53 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:33:53 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:33:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:33:53 WORKER: start processing job (8, 0, 4)
09:33:53 WORKER: args: ()
09:33:53 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 956, 'last_n_outputs': 38, 'leak_rate': 0.9936094864041632, 'lr': 0.005642477220466217, 'optimizer': 'SGD', 'sparsity': 0.9347769773368289, 'steps_to_train': 84, 'weight_decay': 0.015839738328309115}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:34:27 DISPATCHER: Starting worker discovery
09:34:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:34:27 DISPATCHER: Finished worker discovery
09:34:55 WORKER: done with job (8, 0, 4), trying to register it.
09:34:55 WORKER: registered result for job (8, 0, 4) with dispatcher
09:34:55 DISPATCHER: job (8, 0, 4) finished
09:34:55 DISPATCHER: register_result: lock acquired
09:34:55 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:34:55 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 956, 'last_n_outputs': 38, 'leak_rate': 0.9936094864041632, 'lr': 0.005642477220466217, 'optimizer': 'SGD', 'sparsity': 0.9347769773368289, 'steps_to_train': 84, 'weight_decay': 0.015839738328309115}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.16877080879135617, 'info': {'data04': 0.16877080879135617, 'config': "{'batch_size': 128, 'hidden_dim': 956, 'last_n_outputs': 38, 'leak_rate': 0.9936094864041632, 'lr': 0.005642477220466217, 'optimizer': 'SGD', 'sparsity': 0.9347769773368289, 'steps_to_train': 84, 'weight_decay': 0.015839738328309115}"}}
exception: None

09:34:55 job_callback for (8, 0, 4) started
09:34:55 DISPATCHER: Trying to submit another job.
09:34:55 job_callback for (8, 0, 4) got condition
09:34:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:34:55 HBMASTER: Trying to run another job!
09:34:55 job_callback for (8, 0, 4) finished
09:34:55 start sampling a new configuration.
09:34:55 done sampling a new configuration.
09:34:55 HBMASTER: schedule new run for iteration 8
09:34:55 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
09:34:55 HBMASTER: submitting job (8, 0, 5) to dispatcher
09:34:55 DISPATCHER: trying to submit job (8, 0, 5)
09:34:55 DISPATCHER: trying to notify the job_runner thread.
09:34:55 HBMASTER: job (8, 0, 5) submitted to dispatcher
09:34:55 DISPATCHER: Trying to submit another job.
09:34:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:34:55 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:34:55 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:34:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:34:55 WORKER: start processing job (8, 0, 5)
09:34:55 WORKER: args: ()
09:34:55 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 604, 'last_n_outputs': 40, 'leak_rate': 0.9404572804871348, 'lr': 0.022431917890105554, 'optimizer': 'SGD', 'sparsity': 0.7666816244185286, 'steps_to_train': 27, 'weight_decay': 0.12341204031592448}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:35:27 DISPATCHER: Starting worker discovery
09:35:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:35:27 DISPATCHER: Finished worker discovery
09:35:57 WORKER: done with job (8, 0, 5), trying to register it.
09:35:57 WORKER: registered result for job (8, 0, 5) with dispatcher
09:35:57 DISPATCHER: job (8, 0, 5) finished
09:35:57 DISPATCHER: register_result: lock acquired
09:35:57 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:35:57 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 604, 'last_n_outputs': 40, 'leak_rate': 0.9404572804871348, 'lr': 0.022431917890105554, 'optimizer': 'SGD', 'sparsity': 0.7666816244185286, 'steps_to_train': 27, 'weight_decay': 0.12341204031592448}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1709774307114713, 'info': {'data04': 0.1709774307114713, 'config': "{'batch_size': 64, 'hidden_dim': 604, 'last_n_outputs': 40, 'leak_rate': 0.9404572804871348, 'lr': 0.022431917890105554, 'optimizer': 'SGD', 'sparsity': 0.7666816244185286, 'steps_to_train': 27, 'weight_decay': 0.12341204031592448}"}}
exception: None

09:35:57 job_callback for (8, 0, 5) started
09:35:57 job_callback for (8, 0, 5) got condition
09:35:57 DISPATCHER: Trying to submit another job.
09:35:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:35:57 HBMASTER: Trying to run another job!
09:35:57 job_callback for (8, 0, 5) finished
09:35:57 start sampling a new configuration.
09:35:57 best_vector: [3, 0.9002591938010136, 0.4932170275620268, 0.6820476512728969, 0.5817266080024469, 1, 0.7280570070544743, 0.685638848544566, 0.9712139469716057], 0.001730475942692626, 2.350745743296632, 0.004067908956161917
09:35:57 done sampling a new configuration.
09:35:57 HBMASTER: schedule new run for iteration 8
09:35:57 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
09:35:57 HBMASTER: submitting job (8, 0, 6) to dispatcher
09:35:57 DISPATCHER: trying to submit job (8, 0, 6)
09:35:57 DISPATCHER: trying to notify the job_runner thread.
09:35:57 HBMASTER: job (8, 0, 6) submitted to dispatcher
09:35:57 DISPATCHER: Trying to submit another job.
09:35:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:35:57 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:35:57 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:35:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:35:57 WORKER: start processing job (8, 0, 6)
09:35:57 WORKER: args: ()
09:35:57 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 921, 'last_n_outputs': 30, 'leak_rate': 0.9205119128182242, 'lr': 0.014569787445090954, 'optimizer': 'SGD', 'sparsity': 0.9247336816930738, 'steps_to_train': 72, 'weight_decay': 0.18347566785599728}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:36:27 DISPATCHER: Starting worker discovery
09:36:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:36:27 DISPATCHER: Finished worker discovery
09:36:58 WORKER: done with job (8, 0, 6), trying to register it.
09:36:58 WORKER: registered result for job (8, 0, 6) with dispatcher
09:36:58 DISPATCHER: job (8, 0, 6) finished
09:36:58 DISPATCHER: register_result: lock acquired
09:36:58 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:36:58 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 921, 'last_n_outputs': 30, 'leak_rate': 0.9205119128182242, 'lr': 0.014569787445090954, 'optimizer': 'SGD', 'sparsity': 0.9247336816930738, 'steps_to_train': 72, 'weight_decay': 0.18347566785599728}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1705054876863592, 'info': {'data04': 0.1705054876863592, 'config': "{'batch_size': 128, 'hidden_dim': 921, 'last_n_outputs': 30, 'leak_rate': 0.9205119128182242, 'lr': 0.014569787445090954, 'optimizer': 'SGD', 'sparsity': 0.9247336816930738, 'steps_to_train': 72, 'weight_decay': 0.18347566785599728}"}}
exception: None

09:36:58 job_callback for (8, 0, 6) started
09:36:58 DISPATCHER: Trying to submit another job.
09:36:58 job_callback for (8, 0, 6) got condition
09:36:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:36:58 HBMASTER: Trying to run another job!
09:36:58 job_callback for (8, 0, 6) finished
09:36:58 start sampling a new configuration.
09:36:58 done sampling a new configuration.
09:36:58 HBMASTER: schedule new run for iteration 8
09:36:58 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
09:36:58 HBMASTER: submitting job (8, 0, 7) to dispatcher
09:36:58 DISPATCHER: trying to submit job (8, 0, 7)
09:36:58 DISPATCHER: trying to notify the job_runner thread.
09:36:58 HBMASTER: job (8, 0, 7) submitted to dispatcher
09:36:58 DISPATCHER: Trying to submit another job.
09:36:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:36:58 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:36:58 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:36:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:36:58 WORKER: start processing job (8, 0, 7)
09:36:58 WORKER: args: ()
09:36:58 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 575, 'last_n_outputs': 30, 'leak_rate': 0.8905329149233484, 'lr': 0.041774208519694565, 'optimizer': 'SGD', 'sparsity': 0.8556456170177136, 'steps_to_train': 32, 'weight_decay': 0.04498597115311882}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:37:27 DISPATCHER: Starting worker discovery
09:37:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:37:27 DISPATCHER: Finished worker discovery
09:37:59 WORKER: done with job (8, 0, 7), trying to register it.
09:37:59 WORKER: registered result for job (8, 0, 7) with dispatcher
09:37:59 DISPATCHER: job (8, 0, 7) finished
09:37:59 DISPATCHER: register_result: lock acquired
09:37:59 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:37:59 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 575, 'last_n_outputs': 30, 'leak_rate': 0.8905329149233484, 'lr': 0.041774208519694565, 'optimizer': 'SGD', 'sparsity': 0.8556456170177136, 'steps_to_train': 32, 'weight_decay': 0.04498597115311882}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.14365689832934483, 'info': {'data04': 0.14365689832934483, 'config': "{'batch_size': 16, 'hidden_dim': 575, 'last_n_outputs': 30, 'leak_rate': 0.8905329149233484, 'lr': 0.041774208519694565, 'optimizer': 'SGD', 'sparsity': 0.8556456170177136, 'steps_to_train': 32, 'weight_decay': 0.04498597115311882}"}}
exception: None

09:37:59 job_callback for (8, 0, 7) started
09:37:59 job_callback for (8, 0, 7) got condition
09:37:59 DISPATCHER: Trying to submit another job.
09:37:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:37:59 HBMASTER: Trying to run another job!
09:37:59 job_callback for (8, 0, 7) finished
09:37:59 start sampling a new configuration.
09:37:59 done sampling a new configuration.
09:37:59 HBMASTER: schedule new run for iteration 8
09:37:59 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
09:37:59 HBMASTER: submitting job (8, 0, 8) to dispatcher
09:37:59 DISPATCHER: trying to submit job (8, 0, 8)
09:37:59 DISPATCHER: trying to notify the job_runner thread.
09:37:59 HBMASTER: job (8, 0, 8) submitted to dispatcher
09:37:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:37:59 DISPATCHER: Trying to submit another job.
09:37:59 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:37:59 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:37:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:37:59 WORKER: start processing job (8, 0, 8)
09:37:59 WORKER: args: ()
09:37:59 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 593, 'last_n_outputs': 36, 'leak_rate': 0.8824845822551465, 'lr': 0.0019813224200841187, 'optimizer': 'Adam', 'sparsity': 0.8570153450271987, 'steps_to_train': 33, 'weight_decay': 0.1557271093583489}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:38:27 DISPATCHER: Starting worker discovery
09:38:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:38:27 DISPATCHER: Finished worker discovery
09:39:01 WORKER: done with job (8, 0, 8), trying to register it.
09:39:01 WORKER: registered result for job (8, 0, 8) with dispatcher
09:39:01 DISPATCHER: job (8, 0, 8) finished
09:39:01 DISPATCHER: register_result: lock acquired
09:39:01 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:39:01 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 593, 'last_n_outputs': 36, 'leak_rate': 0.8824845822551465, 'lr': 0.0019813224200841187, 'optimizer': 'Adam', 'sparsity': 0.8570153450271987, 'steps_to_train': 33, 'weight_decay': 0.1557271093583489}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.04324510221433959, 'info': {'data04': 0.04324510221433959, 'config': "{'batch_size': 64, 'hidden_dim': 593, 'last_n_outputs': 36, 'leak_rate': 0.8824845822551465, 'lr': 0.0019813224200841187, 'optimizer': 'Adam', 'sparsity': 0.8570153450271987, 'steps_to_train': 33, 'weight_decay': 0.1557271093583489}"}}
exception: None

09:39:01 job_callback for (8, 0, 8) started
09:39:01 job_callback for (8, 0, 8) got condition
09:39:01 DISPATCHER: Trying to submit another job.
09:39:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:39:01 HBMASTER: Trying to run another job!
09:39:01 job_callback for (8, 0, 8) finished
09:39:01 start sampling a new configuration.
09:39:01 done sampling a new configuration.
09:39:01 HBMASTER: schedule new run for iteration 8
09:39:01 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
09:39:01 HBMASTER: submitting job (8, 0, 9) to dispatcher
09:39:01 DISPATCHER: trying to submit job (8, 0, 9)
09:39:01 DISPATCHER: trying to notify the job_runner thread.
09:39:01 HBMASTER: job (8, 0, 9) submitted to dispatcher
09:39:01 DISPATCHER: Trying to submit another job.
09:39:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:39:01 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:39:01 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:39:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:39:01 WORKER: start processing job (8, 0, 9)
09:39:01 WORKER: args: ()
09:39:01 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 299, 'last_n_outputs': 14, 'leak_rate': 0.7551714747668883, 'lr': 0.036775152217359885, 'optimizer': 'Adam', 'sparsity': 0.7561010267021249, 'steps_to_train': 77, 'weight_decay': 0.029358435327628427}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:39:27 DISPATCHER: Starting worker discovery
09:39:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:39:27 DISPATCHER: Finished worker discovery
09:40:02 WORKER: done with job (8, 0, 9), trying to register it.
09:40:02 WORKER: registered result for job (8, 0, 9) with dispatcher
09:40:02 DISPATCHER: job (8, 0, 9) finished
09:40:02 DISPATCHER: register_result: lock acquired
09:40:02 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:40:02 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 299, 'last_n_outputs': 14, 'leak_rate': 0.7551714747668883, 'lr': 0.036775152217359885, 'optimizer': 'Adam', 'sparsity': 0.7561010267021249, 'steps_to_train': 77, 'weight_decay': 0.029358435327628427}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.02720894842618409, 'info': {'data04': 0.02720894842618409, 'config': "{'batch_size': 64, 'hidden_dim': 299, 'last_n_outputs': 14, 'leak_rate': 0.7551714747668883, 'lr': 0.036775152217359885, 'optimizer': 'Adam', 'sparsity': 0.7561010267021249, 'steps_to_train': 77, 'weight_decay': 0.029358435327628427}"}}
exception: None

09:40:02 job_callback for (8, 0, 9) started
09:40:02 DISPATCHER: Trying to submit another job.
09:40:02 job_callback for (8, 0, 9) got condition
09:40:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:40:02 HBMASTER: Trying to run another job!
09:40:02 job_callback for (8, 0, 9) finished
09:40:02 start sampling a new configuration.
09:40:02 best_vector: [2, 0.5537420696956963, 0.6471455584468417, 0.24987713499187814, 0.023396186853991474, 1, 0.7484590445421757, 0.9250783975518433, 0.06248771048140611], 9.362127093152854e-05, 1.4345038965302768, 0.00013430007794939443
09:40:02 done sampling a new configuration.
09:40:02 HBMASTER: schedule new run for iteration 8
09:40:02 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
09:40:02 HBMASTER: submitting job (8, 0, 10) to dispatcher
09:40:02 DISPATCHER: trying to submit job (8, 0, 10)
09:40:02 DISPATCHER: trying to notify the job_runner thread.
09:40:02 HBMASTER: job (8, 0, 10) submitted to dispatcher
09:40:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:40:02 DISPATCHER: Trying to submit another job.
09:40:02 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:40:02 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:40:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:40:02 WORKER: start processing job (8, 0, 10)
09:40:02 WORKER: args: ()
09:40:02 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 643, 'last_n_outputs': 36, 'leak_rate': 0.8124692837479696, 'lr': 0.001113761942095733, 'optimizer': 'SGD', 'sparsity': 0.9296301706901222, 'steps_to_train': 94, 'weight_decay': 0.012058641549891235}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:40:27 DISPATCHER: Starting worker discovery
09:40:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:40:27 DISPATCHER: Finished worker discovery
09:41:03 WORKER: done with job (8, 0, 10), trying to register it.
09:41:03 WORKER: registered result for job (8, 0, 10) with dispatcher
09:41:03 DISPATCHER: job (8, 0, 10) finished
09:41:03 DISPATCHER: register_result: lock acquired
09:41:03 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:41:03 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 643, 'last_n_outputs': 36, 'leak_rate': 0.8124692837479696, 'lr': 0.001113761942095733, 'optimizer': 'SGD', 'sparsity': 0.9296301706901222, 'steps_to_train': 94, 'weight_decay': 0.012058641549891235}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.15004365105861467, 'info': {'data04': 0.15004365105861467, 'config': "{'batch_size': 64, 'hidden_dim': 643, 'last_n_outputs': 36, 'leak_rate': 0.8124692837479696, 'lr': 0.001113761942095733, 'optimizer': 'SGD', 'sparsity': 0.9296301706901222, 'steps_to_train': 94, 'weight_decay': 0.012058641549891235}"}}
exception: None

09:41:03 job_callback for (8, 0, 10) started
09:41:03 DISPATCHER: Trying to submit another job.
09:41:03 job_callback for (8, 0, 10) got condition
09:41:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:41:03 HBMASTER: Trying to run another job!
09:41:03 job_callback for (8, 0, 10) finished
09:41:03 start sampling a new configuration.
09:41:03 best_vector: [1, 0.5509756876389371, 0.5867248136040377, 0.5493779040373982, 0.10801903990828671, 1, 0.7379016488621082, 0.8305939559543949, 0.21529755118566996], 0.0013613283751107538, 3.435997161612234, 0.004677520432902744
09:41:03 done sampling a new configuration.
09:41:03 HBMASTER: schedule new run for iteration 8
09:41:03 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
09:41:03 HBMASTER: submitting job (8, 0, 11) to dispatcher
09:41:03 DISPATCHER: trying to submit job (8, 0, 11)
09:41:03 DISPATCHER: trying to notify the job_runner thread.
09:41:03 HBMASTER: job (8, 0, 11) submitted to dispatcher
09:41:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:41:03 DISPATCHER: Trying to submit another job.
09:41:03 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:41:03 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:41:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:41:03 WORKER: start processing job (8, 0, 11)
09:41:03 WORKER: args: ()
09:41:03 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 641, 'last_n_outputs': 34, 'leak_rate': 0.8873444760093495, 'lr': 0.0016445159113672046, 'optimizer': 'SGD', 'sparsity': 0.9270963957269059, 'steps_to_train': 85, 'weight_decay': 0.019059371359572346}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:41:27 DISPATCHER: Starting worker discovery
09:41:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:41:27 DISPATCHER: Finished worker discovery
09:42:04 WORKER: done with job (8, 0, 11), trying to register it.
09:42:04 WORKER: registered result for job (8, 0, 11) with dispatcher
09:42:04 DISPATCHER: job (8, 0, 11) finished
09:42:04 DISPATCHER: register_result: lock acquired
09:42:04 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:42:04 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 641, 'last_n_outputs': 34, 'leak_rate': 0.8873444760093495, 'lr': 0.0016445159113672046, 'optimizer': 'SGD', 'sparsity': 0.9270963957269059, 'steps_to_train': 85, 'weight_decay': 0.019059371359572346}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.15517368616558883, 'info': {'data04': 0.15517368616558883, 'config': "{'batch_size': 32, 'hidden_dim': 641, 'last_n_outputs': 34, 'leak_rate': 0.8873444760093495, 'lr': 0.0016445159113672046, 'optimizer': 'SGD', 'sparsity': 0.9270963957269059, 'steps_to_train': 85, 'weight_decay': 0.019059371359572346}"}}
exception: None

09:42:04 job_callback for (8, 0, 11) started
09:42:04 job_callback for (8, 0, 11) got condition
09:42:04 DISPATCHER: Trying to submit another job.
09:42:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:42:04 HBMASTER: Trying to run another job!
09:42:04 job_callback for (8, 0, 11) finished
09:42:04 start sampling a new configuration.
09:42:04 best_vector: [1, 0.2561231761070233, 0.7180083601861749, 0.05453848227497282, 0.011703440660451397, 1, 0.07999012501612657, 0.3133578557706408, 0.23834620259483014], 0.00025224138110117075, 0.021352997133318584, 5.386109487557619e-06
09:42:04 done sampling a new configuration.
09:42:04 HBMASTER: schedule new run for iteration 8
09:42:04 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
09:42:04 HBMASTER: submitting job (8, 0, 12) to dispatcher
09:42:04 DISPATCHER: trying to submit job (8, 0, 12)
09:42:04 DISPATCHER: trying to notify the job_runner thread.
09:42:04 HBMASTER: job (8, 0, 12) submitted to dispatcher
09:42:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:42:04 DISPATCHER: Trying to submit another job.
09:42:04 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:42:04 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:42:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:42:04 WORKER: start processing job (8, 0, 12)
09:42:04 WORKER: args: ()
09:42:04 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 405, 'last_n_outputs': 39, 'leak_rate': 0.7636346205687432, 'lr': 0.0010553751920734811, 'optimizer': 'SGD', 'sparsity': 0.7691976300038704, 'steps_to_train': 38, 'weight_decay': 0.020421872429332657}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:42:27 DISPATCHER: Starting worker discovery
09:42:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:42:27 DISPATCHER: Finished worker discovery
09:43:04 WORKER: done with job (8, 0, 12), trying to register it.
09:43:04 WORKER: registered result for job (8, 0, 12) with dispatcher
09:43:04 DISPATCHER: job (8, 0, 12) finished
09:43:04 DISPATCHER: register_result: lock acquired
09:43:04 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:43:04 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 405, 'last_n_outputs': 39, 'leak_rate': 0.7636346205687432, 'lr': 0.0010553751920734811, 'optimizer': 'SGD', 'sparsity': 0.7691976300038704, 'steps_to_train': 38, 'weight_decay': 0.020421872429332657}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1198151698541126, 'info': {'data04': 0.1198151698541126, 'config': "{'batch_size': 32, 'hidden_dim': 405, 'last_n_outputs': 39, 'leak_rate': 0.7636346205687432, 'lr': 0.0010553751920734811, 'optimizer': 'SGD', 'sparsity': 0.7691976300038704, 'steps_to_train': 38, 'weight_decay': 0.020421872429332657}"}}
exception: None

09:43:04 job_callback for (8, 0, 12) started
09:43:04 DISPATCHER: Trying to submit another job.
09:43:04 job_callback for (8, 0, 12) got condition
09:43:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:43:04 HBMASTER: Trying to run another job!
09:43:04 job_callback for (8, 0, 12) finished
09:43:04 start sampling a new configuration.
09:43:04 best_vector: [3, 0.5671464384519317, 0.7002976157561821, 0.270497318943851, 0.03656906173132879, 1, 0.28822861261322, 0.5023252018270083, 0.8529035788793096], 0.005085062869403506, 5.49347389479955, 0.027934660126482654
09:43:04 done sampling a new configuration.
09:43:04 HBMASTER: schedule new run for iteration 8
09:43:04 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
09:43:04 HBMASTER: submitting job (8, 0, 13) to dispatcher
09:43:04 DISPATCHER: trying to submit job (8, 0, 13)
09:43:04 DISPATCHER: trying to notify the job_runner thread.
09:43:04 HBMASTER: job (8, 0, 13) submitted to dispatcher
09:43:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:43:04 DISPATCHER: Trying to submit another job.
09:43:04 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:43:04 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:43:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:43:04 WORKER: start processing job (8, 0, 13)
09:43:04 WORKER: args: ()
09:43:04 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 654, 'last_n_outputs': 38, 'leak_rate': 0.8176243297359628, 'lr': 0.0011834178713142028, 'optimizer': 'SGD', 'sparsity': 0.8191748670271728, 'steps_to_train': 55, 'weight_decay': 0.12872210687896113}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:43:27 DISPATCHER: Starting worker discovery
09:43:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:43:27 DISPATCHER: Finished worker discovery
09:44:06 WORKER: done with job (8, 0, 13), trying to register it.
09:44:06 WORKER: registered result for job (8, 0, 13) with dispatcher
09:44:06 DISPATCHER: job (8, 0, 13) finished
09:44:06 DISPATCHER: register_result: lock acquired
09:44:06 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:44:06 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 654, 'last_n_outputs': 38, 'leak_rate': 0.8176243297359628, 'lr': 0.0011834178713142028, 'optimizer': 'SGD', 'sparsity': 0.8191748670271728, 'steps_to_train': 55, 'weight_decay': 0.12872210687896113}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1523679650852691, 'info': {'data04': 0.1523679650852691, 'config': "{'batch_size': 128, 'hidden_dim': 654, 'last_n_outputs': 38, 'leak_rate': 0.8176243297359628, 'lr': 0.0011834178713142028, 'optimizer': 'SGD', 'sparsity': 0.8191748670271728, 'steps_to_train': 55, 'weight_decay': 0.12872210687896113}"}}
exception: None

09:44:06 job_callback for (8, 0, 13) started
09:44:06 DISPATCHER: Trying to submit another job.
09:44:06 job_callback for (8, 0, 13) got condition
09:44:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:44:06 HBMASTER: Trying to run another job!
09:44:06 job_callback for (8, 0, 13) finished
09:44:06 start sampling a new configuration.
09:44:06 best_vector: [1, 0.17864497600670004, 0.7371147999526072, 0.2869914725033425, 0.23960163167101362, 1, 0.19567310730036752, 0.4447567595704965, 0.7293668588145088], 0.001866489045157853, 2.8260363798437713, 0.0052747659441959565
09:44:06 done sampling a new configuration.
09:44:06 HBMASTER: schedule new run for iteration 8
09:44:06 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
09:44:06 HBMASTER: submitting job (8, 0, 14) to dispatcher
09:44:06 DISPATCHER: trying to submit job (8, 0, 14)
09:44:06 DISPATCHER: trying to notify the job_runner thread.
09:44:06 HBMASTER: job (8, 0, 14) submitted to dispatcher
09:44:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:44:06 DISPATCHER: Trying to submit another job.
09:44:06 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:44:06 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:44:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:44:06 WORKER: start processing job (8, 0, 14)
09:44:06 WORKER: args: ()
09:44:06 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 343, 'last_n_outputs': 40, 'leak_rate': 0.8217478681258357, 'lr': 0.003014416534890098, 'optimizer': 'SGD', 'sparsity': 0.7969615457520882, 'steps_to_train': 50, 'weight_decay': 0.08890540427839949}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:44:27 DISPATCHER: Starting worker discovery
09:44:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:44:27 DISPATCHER: Finished worker discovery
09:45:07 WORKER: done with job (8, 0, 14), trying to register it.
09:45:07 WORKER: registered result for job (8, 0, 14) with dispatcher
09:45:07 DISPATCHER: job (8, 0, 14) finished
09:45:07 DISPATCHER: register_result: lock acquired
09:45:07 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:45:07 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 343, 'last_n_outputs': 40, 'leak_rate': 0.8217478681258357, 'lr': 0.003014416534890098, 'optimizer': 'SGD', 'sparsity': 0.7969615457520882, 'steps_to_train': 50, 'weight_decay': 0.08890540427839949}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.16637817926035042, 'info': {'data04': 0.16637817926035042, 'config': "{'batch_size': 32, 'hidden_dim': 343, 'last_n_outputs': 40, 'leak_rate': 0.8217478681258357, 'lr': 0.003014416534890098, 'optimizer': 'SGD', 'sparsity': 0.7969615457520882, 'steps_to_train': 50, 'weight_decay': 0.08890540427839949}"}}
exception: None

09:45:07 job_callback for (8, 0, 14) started
09:45:07 DISPATCHER: Trying to submit another job.
09:45:07 job_callback for (8, 0, 14) got condition
09:45:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:45:07 HBMASTER: Trying to run another job!
09:45:07 job_callback for (8, 0, 14) finished
09:45:07 start sampling a new configuration.
09:45:07 best_vector: [1, 0.0018055756250377475, 0.68058313963527, 0.23642990393504787, 0.03583258529740138, 1, 0.6397130157959255, 0.9625722321744583, 0.6986621337246155], 0.004700047886168032, 3.3576359246423904, 0.015781049630137312
09:45:07 done sampling a new configuration.
09:45:07 HBMASTER: schedule new run for iteration 8
09:45:07 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
09:45:07 HBMASTER: submitting job (8, 0, 15) to dispatcher
09:45:07 DISPATCHER: trying to submit job (8, 0, 15)
09:45:07 DISPATCHER: trying to notify the job_runner thread.
09:45:07 HBMASTER: job (8, 0, 15) submitted to dispatcher
09:45:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:45:07 DISPATCHER: Trying to submit another job.
09:45:07 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:45:07 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:45:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:45:07 WORKER: start processing job (8, 0, 15)
09:45:07 WORKER: args: ()
09:45:07 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 201, 'last_n_outputs': 37, 'leak_rate': 0.809107475983762, 'lr': 0.0011794109907786198, 'optimizer': 'SGD', 'sparsity': 0.9035311237910222, 'steps_to_train': 97, 'weight_decay': 0.08109244460408582}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:45:27 DISPATCHER: Starting worker discovery
09:45:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:45:28 DISPATCHER: Finished worker discovery
09:46:10 WORKER: done with job (8, 0, 15), trying to register it.
09:46:10 WORKER: registered result for job (8, 0, 15) with dispatcher
09:46:10 DISPATCHER: job (8, 0, 15) finished
09:46:10 DISPATCHER: register_result: lock acquired
09:46:10 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:46:10 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 201, 'last_n_outputs': 37, 'leak_rate': 0.809107475983762, 'lr': 0.0011794109907786198, 'optimizer': 'SGD', 'sparsity': 0.9035311237910222, 'steps_to_train': 97, 'weight_decay': 0.08109244460408582}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.08715498275163314, 'info': {'data04': 0.08715498275163314, 'config': "{'batch_size': 32, 'hidden_dim': 201, 'last_n_outputs': 37, 'leak_rate': 0.809107475983762, 'lr': 0.0011794109907786198, 'optimizer': 'SGD', 'sparsity': 0.9035311237910222, 'steps_to_train': 97, 'weight_decay': 0.08109244460408582}"}}
exception: None

09:46:10 job_callback for (8, 0, 15) started
09:46:10 DISPATCHER: Trying to submit another job.
09:46:10 job_callback for (8, 0, 15) got condition
09:46:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:46:10 HBMASTER: Trying to run another job!
09:46:10 job_callback for (8, 0, 15) finished
09:46:10 start sampling a new configuration.
09:46:10 best_vector: [2, 0.07422732724564618, 0.6185086905134073, 0.46058072434865094, 0.135306689089218, 1, 0.855134157600473, 0.672591300448702, 0.0838871665249199], 0.0005847203967415304, 0.3174547836814875, 0.0001856222870617361
09:46:10 done sampling a new configuration.
09:46:10 HBMASTER: schedule new run for iteration 8
09:46:10 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
09:46:10 HBMASTER: submitting job (8, 0, 16) to dispatcher
09:46:10 DISPATCHER: trying to submit job (8, 0, 16)
09:46:10 DISPATCHER: trying to notify the job_runner thread.
09:46:10 HBMASTER: job (8, 0, 16) submitted to dispatcher
09:46:10 DISPATCHER: Trying to submit another job.
09:46:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:46:10 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:46:10 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:46:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:46:10 WORKER: start processing job (8, 0, 16)
09:46:10 WORKER: args: ()
09:46:10 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 259, 'last_n_outputs': 35, 'leak_rate': 0.8651451810871628, 'lr': 0.0018647189236506423, 'optimizer': 'SGD', 'sparsity': 0.9552321978241135, 'steps_to_train': 71, 'weight_decay': 0.012857002249816214}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:46:28 DISPATCHER: Starting worker discovery
09:46:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:46:28 DISPATCHER: Finished worker discovery
09:47:09 WORKER: done with job (8, 0, 16), trying to register it.
09:47:09 WORKER: registered result for job (8, 0, 16) with dispatcher
09:47:09 DISPATCHER: job (8, 0, 16) finished
09:47:09 DISPATCHER: register_result: lock acquired
09:47:09 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:47:09 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 259, 'last_n_outputs': 35, 'leak_rate': 0.8651451810871628, 'lr': 0.0018647189236506423, 'optimizer': 'SGD', 'sparsity': 0.9552321978241135, 'steps_to_train': 71, 'weight_decay': 0.012857002249816214}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.13763903339014, 'info': {'data04': 0.13763903339014, 'config': "{'batch_size': 64, 'hidden_dim': 259, 'last_n_outputs': 35, 'leak_rate': 0.8651451810871628, 'lr': 0.0018647189236506423, 'optimizer': 'SGD', 'sparsity': 0.9552321978241135, 'steps_to_train': 71, 'weight_decay': 0.012857002249816214}"}}
exception: None

09:47:09 job_callback for (8, 0, 16) started
09:47:09 DISPATCHER: Trying to submit another job.
09:47:09 job_callback for (8, 0, 16) got condition
09:47:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:47:09 HBMASTER: Trying to run another job!
09:47:09 job_callback for (8, 0, 16) finished
09:47:09 start sampling a new configuration.
09:47:10 best_vector: [1, 0.24232914292105667, 0.7505215669288829, 0.8195683263408071, 0.09254973686939533, 1, 0.9761974704436344, 0.3120384027623637, 0.5060904418046016], 0.007592268874569628, 0.0011474535259825354, 8.711775690332376e-06
09:47:10 done sampling a new configuration.
09:47:10 HBMASTER: schedule new run for iteration 8
09:47:10 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
09:47:10 HBMASTER: submitting job (8, 0, 17) to dispatcher
09:47:10 DISPATCHER: trying to submit job (8, 0, 17)
09:47:10 DISPATCHER: trying to notify the job_runner thread.
09:47:10 HBMASTER: job (8, 0, 17) submitted to dispatcher
09:47:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:47:10 DISPATCHER: Trying to submit another job.
09:47:10 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:47:10 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:47:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:47:10 WORKER: start processing job (8, 0, 17)
09:47:10 WORKER: args: ()
09:47:10 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 394, 'last_n_outputs': 40, 'leak_rate': 0.9548920815852018, 'lr': 0.0015314381924514983, 'optimizer': 'SGD', 'sparsity': 0.9842873929064723, 'steps_to_train': 38, 'weight_decay': 0.04554480482408485}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:47:28 DISPATCHER: Starting worker discovery
09:47:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:47:28 DISPATCHER: Finished worker discovery
09:48:10 WORKER: done with job (8, 0, 17), trying to register it.
09:48:10 WORKER: registered result for job (8, 0, 17) with dispatcher
09:48:10 DISPATCHER: job (8, 0, 17) finished
09:48:10 DISPATCHER: register_result: lock acquired
09:48:10 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:48:10 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 394, 'last_n_outputs': 40, 'leak_rate': 0.9548920815852018, 'lr': 0.0015314381924514983, 'optimizer': 'SGD', 'sparsity': 0.9842873929064723, 'steps_to_train': 38, 'weight_decay': 0.04554480482408485}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.13702053547051865, 'info': {'data04': 0.13702053547051865, 'config': "{'batch_size': 32, 'hidden_dim': 394, 'last_n_outputs': 40, 'leak_rate': 0.9548920815852018, 'lr': 0.0015314381924514983, 'optimizer': 'SGD', 'sparsity': 0.9842873929064723, 'steps_to_train': 38, 'weight_decay': 0.04554480482408485}"}}
exception: None

09:48:10 job_callback for (8, 0, 17) started
09:48:10 job_callback for (8, 0, 17) got condition
09:48:10 DISPATCHER: Trying to submit another job.
09:48:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:48:10 HBMASTER: Trying to run another job!
09:48:10 job_callback for (8, 0, 17) finished
09:48:10 start sampling a new configuration.
09:48:10 best_vector: [0, 0.7040404171401679, 0.7053805644741548, 0.4150991099418107, 0.20289067164700558, 1, 0.8373735549509348, 0.9713085319997664, 0.131194406927859], 0.0007648184427813906, 0.6422699607073714, 0.0004912199111934767
09:48:10 done sampling a new configuration.
09:48:10 HBMASTER: schedule new run for iteration 8
09:48:10 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
09:48:10 HBMASTER: submitting job (8, 0, 18) to dispatcher
09:48:10 DISPATCHER: trying to submit job (8, 0, 18)
09:48:10 DISPATCHER: trying to notify the job_runner thread.
09:48:10 HBMASTER: job (8, 0, 18) submitted to dispatcher
09:48:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:48:10 DISPATCHER: Trying to submit another job.
09:48:10 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:48:10 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:48:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:48:10 WORKER: start processing job (8, 0, 18)
09:48:10 WORKER: args: ()
09:48:10 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 763, 'last_n_outputs': 38, 'leak_rate': 0.8537747774854527, 'lr': 0.002545548308253905, 'optimizer': 'SGD', 'sparsity': 0.9509696531882244, 'steps_to_train': 98, 'weight_decay': 0.014814529348438592}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:48:28 DISPATCHER: Starting worker discovery
09:48:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:48:28 DISPATCHER: Finished worker discovery
09:49:13 WORKER: done with job (8, 0, 18), trying to register it.
09:49:13 WORKER: registered result for job (8, 0, 18) with dispatcher
09:49:13 DISPATCHER: job (8, 0, 18) finished
09:49:13 DISPATCHER: register_result: lock acquired
09:49:13 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:49:13 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 763, 'last_n_outputs': 38, 'leak_rate': 0.8537747774854527, 'lr': 0.002545548308253905, 'optimizer': 'SGD', 'sparsity': 0.9509696531882244, 'steps_to_train': 98, 'weight_decay': 0.014814529348438592}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.16296168977124115, 'info': {'data04': 0.16296168977124115, 'config': "{'batch_size': 16, 'hidden_dim': 763, 'last_n_outputs': 38, 'leak_rate': 0.8537747774854527, 'lr': 0.002545548308253905, 'optimizer': 'SGD', 'sparsity': 0.9509696531882244, 'steps_to_train': 98, 'weight_decay': 0.014814529348438592}"}}
exception: None

09:49:13 job_callback for (8, 0, 18) started
09:49:13 job_callback for (8, 0, 18) got condition
09:49:13 DISPATCHER: Trying to submit another job.
09:49:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:49:13 HBMASTER: Trying to run another job!
09:49:13 job_callback for (8, 0, 18) finished
09:49:13 start sampling a new configuration.
09:49:13 best_vector: [0, 0.3988630576835141, 0.7878429134031958, 0.256088482301671, 0.11161314520025362, 1, 0.12931763011826927, 0.5816128084628853, 0.9481341369375298], 0.0005820838974219145, 2.0140895720051124, 0.0011723691078295716
09:49:13 done sampling a new configuration.
09:49:13 HBMASTER: schedule new run for iteration 8
09:49:13 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
09:49:13 HBMASTER: submitting job (8, 0, 19) to dispatcher
09:49:13 DISPATCHER: trying to submit job (8, 0, 19)
09:49:13 DISPATCHER: trying to notify the job_runner thread.
09:49:13 HBMASTER: job (8, 0, 19) submitted to dispatcher
09:49:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:49:13 DISPATCHER: Trying to submit another job.
09:49:13 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:49:13 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:49:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:49:13 WORKER: start processing job (8, 0, 19)
09:49:13 WORKER: args: ()
09:49:13 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 519, 'last_n_outputs': 42, 'leak_rate': 0.8140221205754178, 'lr': 0.001671961567813016, 'optimizer': 'SGD', 'sparsity': 0.7810362312283846, 'steps_to_train': 62, 'weight_decay': 0.17121860411096435}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:49:28 DISPATCHER: Starting worker discovery
09:49:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:49:28 DISPATCHER: Finished worker discovery
09:50:15 WORKER: done with job (8, 0, 19), trying to register it.
09:50:15 WORKER: registered result for job (8, 0, 19) with dispatcher
09:50:15 DISPATCHER: job (8, 0, 19) finished
09:50:15 DISPATCHER: register_result: lock acquired
09:50:15 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:50:15 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 519, 'last_n_outputs': 42, 'leak_rate': 0.8140221205754178, 'lr': 0.001671961567813016, 'optimizer': 'SGD', 'sparsity': 0.7810362312283846, 'steps_to_train': 62, 'weight_decay': 0.17121860411096435}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1491220870391445, 'info': {'data04': 0.1491220870391445, 'config': "{'batch_size': 16, 'hidden_dim': 519, 'last_n_outputs': 42, 'leak_rate': 0.8140221205754178, 'lr': 0.001671961567813016, 'optimizer': 'SGD', 'sparsity': 0.7810362312283846, 'steps_to_train': 62, 'weight_decay': 0.17121860411096435}"}}
exception: None

09:50:15 job_callback for (8, 0, 19) started
09:50:15 job_callback for (8, 0, 19) got condition
09:50:15 DISPATCHER: Trying to submit another job.
09:50:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:50:15 HBMASTER: Trying to run another job!
09:50:15 job_callback for (8, 0, 19) finished
09:50:15 start sampling a new configuration.
09:50:15 best_vector: [0, 0.1289742627689872, 0.8590734893162207, 0.24104105284144564, 0.01174295574051376, 1, 0.04462867770976445, 0.8288513239838116, 0.7702559597550007], 0.0010966377561123916, 0.645174737732042, 0.0007075229766868674
09:50:15 done sampling a new configuration.
09:50:15 HBMASTER: schedule new run for iteration 8
09:50:15 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
09:50:15 HBMASTER: submitting job (8, 0, 20) to dispatcher
09:50:15 DISPATCHER: trying to submit job (8, 0, 20)
09:50:15 DISPATCHER: trying to notify the job_runner thread.
09:50:15 HBMASTER: job (8, 0, 20) submitted to dispatcher
09:50:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:50:15 DISPATCHER: Trying to submit another job.
09:50:15 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:50:15 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:50:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:50:15 WORKER: start processing job (8, 0, 20)
09:50:15 WORKER: args: ()
09:50:15 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 303, 'last_n_outputs': 45, 'leak_rate': 0.8102602632103614, 'lr': 0.0010555672600440593, 'optimizer': 'SGD', 'sparsity': 0.7607108826503435, 'steps_to_train': 85, 'weight_decay': 0.10049075472981757}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:50:28 DISPATCHER: Starting worker discovery
09:50:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:50:28 DISPATCHER: Finished worker discovery
09:51:17 WORKER: done with job (8, 0, 20), trying to register it.
09:51:17 WORKER: registered result for job (8, 0, 20) with dispatcher
09:51:17 DISPATCHER: job (8, 0, 20) finished
09:51:17 DISPATCHER: register_result: lock acquired
09:51:17 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:51:17 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 303, 'last_n_outputs': 45, 'leak_rate': 0.8102602632103614, 'lr': 0.0010555672600440593, 'optimizer': 'SGD', 'sparsity': 0.7607108826503435, 'steps_to_train': 85, 'weight_decay': 0.10049075472981757}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.11681654119674975, 'info': {'data04': 0.11681654119674975, 'config': "{'batch_size': 16, 'hidden_dim': 303, 'last_n_outputs': 45, 'leak_rate': 0.8102602632103614, 'lr': 0.0010555672600440593, 'optimizer': 'SGD', 'sparsity': 0.7607108826503435, 'steps_to_train': 85, 'weight_decay': 0.10049075472981757}"}}
exception: None

09:51:17 job_callback for (8, 0, 20) started
09:51:17 job_callback for (8, 0, 20) got condition
09:51:17 DISPATCHER: Trying to submit another job.
09:51:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:51:17 HBMASTER: Trying to run another job!
09:51:17 job_callback for (8, 0, 20) finished
09:51:17 start sampling a new configuration.
09:51:17 best_vector: [1, 0.7419000543989159, 0.6750300522133991, 0.4357790921810917, 0.44423848503582747, 1, 0.1446913719838927, 0.6223014391366476, 0.12317203192917392], 0.0019958011995683247, 7.275615971143848, 0.014520683082807354
09:51:17 done sampling a new configuration.
09:51:17 HBMASTER: schedule new run for iteration 8
09:51:17 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
09:51:17 HBMASTER: submitting job (8, 0, 21) to dispatcher
09:51:17 DISPATCHER: trying to submit job (8, 0, 21)
09:51:17 DISPATCHER: trying to notify the job_runner thread.
09:51:17 HBMASTER: job (8, 0, 21) submitted to dispatcher
09:51:17 DISPATCHER: Trying to submit another job.
09:51:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:51:17 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:51:17 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:51:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:51:17 WORKER: start processing job (8, 0, 21)
09:51:17 WORKER: args: ()
09:51:17 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 794, 'last_n_outputs': 37, 'leak_rate': 0.858944773045273, 'lr': 0.0077352965867062045, 'optimizer': 'SGD', 'sparsity': 0.7847259292761343, 'steps_to_train': 66, 'weight_decay': 0.014462737645756469}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:51:28 DISPATCHER: Starting worker discovery
09:51:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:51:28 DISPATCHER: Finished worker discovery
09:52:18 WORKER: done with job (8, 0, 21), trying to register it.
09:52:18 WORKER: registered result for job (8, 0, 21) with dispatcher
09:52:18 DISPATCHER: job (8, 0, 21) finished
09:52:18 DISPATCHER: register_result: lock acquired
09:52:18 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:52:18 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 794, 'last_n_outputs': 37, 'leak_rate': 0.858944773045273, 'lr': 0.0077352965867062045, 'optimizer': 'SGD', 'sparsity': 0.7847259292761343, 'steps_to_train': 66, 'weight_decay': 0.014462737645756469}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.16515280305494937, 'info': {'data04': 0.16515280305494937, 'config': "{'batch_size': 32, 'hidden_dim': 794, 'last_n_outputs': 37, 'leak_rate': 0.858944773045273, 'lr': 0.0077352965867062045, 'optimizer': 'SGD', 'sparsity': 0.7847259292761343, 'steps_to_train': 66, 'weight_decay': 0.014462737645756469}"}}
exception: None

09:52:18 job_callback for (8, 0, 21) started
09:52:18 job_callback for (8, 0, 21) got condition
09:52:18 DISPATCHER: Trying to submit another job.
09:52:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:52:18 HBMASTER: Trying to run another job!
09:52:18 job_callback for (8, 0, 21) finished
09:52:18 start sampling a new configuration.
09:52:18 best_vector: [3, 0.6407310936390642, 0.5628791117357013, 0.1587942010762431, 0.014933505991480911, 1, 0.055201166874568997, 0.49986729388559537, 0.6339432656402114], 0.002650524684849881, 0.014431631542141285, 3.825139564510363e-05
09:52:18 done sampling a new configuration.
09:52:18 HBMASTER: schedule new run for iteration 8
09:52:18 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
09:52:18 HBMASTER: submitting job (8, 0, 22) to dispatcher
09:52:18 DISPATCHER: trying to submit job (8, 0, 22)
09:52:18 DISPATCHER: trying to notify the job_runner thread.
09:52:18 HBMASTER: job (8, 0, 22) submitted to dispatcher
09:52:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:52:18 DISPATCHER: Trying to submit another job.
09:52:18 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:52:18 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:52:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:52:18 WORKER: start processing job (8, 0, 22)
09:52:18 WORKER: args: ()
09:52:18 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 713, 'last_n_outputs': 33, 'leak_rate': 0.7896985502690608, 'lr': 0.001071191238872507, 'optimizer': 'SGD', 'sparsity': 0.7632482800498965, 'steps_to_train': 55, 'weight_decay': 0.06680042170519124}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:52:28 DISPATCHER: Starting worker discovery
09:52:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:52:28 DISPATCHER: Finished worker discovery
09:53:20 WORKER: done with job (8, 0, 22), trying to register it.
09:53:20 WORKER: registered result for job (8, 0, 22) with dispatcher
09:53:20 DISPATCHER: job (8, 0, 22) finished
09:53:20 DISPATCHER: register_result: lock acquired
09:53:20 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:53:20 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 713, 'last_n_outputs': 33, 'leak_rate': 0.7896985502690608, 'lr': 0.001071191238872507, 'optimizer': 'SGD', 'sparsity': 0.7632482800498965, 'steps_to_train': 55, 'weight_decay': 0.06680042170519124}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.12601630969722316, 'info': {'data04': 0.12601630969722316, 'config': "{'batch_size': 128, 'hidden_dim': 713, 'last_n_outputs': 33, 'leak_rate': 0.7896985502690608, 'lr': 0.001071191238872507, 'optimizer': 'SGD', 'sparsity': 0.7632482800498965, 'steps_to_train': 55, 'weight_decay': 0.06680042170519124}"}}
exception: None

09:53:20 job_callback for (8, 0, 22) started
09:53:20 job_callback for (8, 0, 22) got condition
09:53:20 DISPATCHER: Trying to submit another job.
09:53:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:53:20 HBMASTER: Trying to run another job!
09:53:20 job_callback for (8, 0, 22) finished
09:53:20 start sampling a new configuration.
09:53:20 best_vector: [3, 0.9375528828730533, 0.5502862378714972, 0.1398617576505678, 0.05892319787256692, 1, 0.1333825850212884, 0.924458398318858, 0.35167625377014156], 0.0017837513106459956, 0.010221718692798495, 1.823300411533399e-05
09:53:20 done sampling a new configuration.
09:53:20 HBMASTER: schedule new run for iteration 8
09:53:20 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
09:53:20 HBMASTER: submitting job (8, 0, 23) to dispatcher
09:53:20 DISPATCHER: trying to submit job (8, 0, 23)
09:53:20 DISPATCHER: trying to notify the job_runner thread.
09:53:20 HBMASTER: job (8, 0, 23) submitted to dispatcher
09:53:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:53:20 DISPATCHER: Trying to submit another job.
09:53:20 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:53:20 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:53:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:53:20 WORKER: start processing job (8, 0, 23)
09:53:20 WORKER: args: ()
09:53:20 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 950, 'last_n_outputs': 32, 'leak_rate': 0.784965439412642, 'lr': 0.0013117358732121723, 'optimizer': 'SGD', 'sparsity': 0.7820118204051092, 'steps_to_train': 94, 'weight_decay': 0.028677504390024786}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:53:28 DISPATCHER: Starting worker discovery
09:53:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:53:28 DISPATCHER: Finished worker discovery
09:54:21 WORKER: done with job (8, 0, 23), trying to register it.
09:54:21 WORKER: registered result for job (8, 0, 23) with dispatcher
09:54:21 DISPATCHER: job (8, 0, 23) finished
09:54:21 DISPATCHER: register_result: lock acquired
09:54:21 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:54:21 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 950, 'last_n_outputs': 32, 'leak_rate': 0.784965439412642, 'lr': 0.0013117358732121723, 'optimizer': 'SGD', 'sparsity': 0.7820118204051092, 'steps_to_train': 94, 'weight_decay': 0.028677504390024786}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1499733563478613, 'info': {'data04': 0.1499733563478613, 'config': "{'batch_size': 128, 'hidden_dim': 950, 'last_n_outputs': 32, 'leak_rate': 0.784965439412642, 'lr': 0.0013117358732121723, 'optimizer': 'SGD', 'sparsity': 0.7820118204051092, 'steps_to_train': 94, 'weight_decay': 0.028677504390024786}"}}
exception: None

09:54:21 job_callback for (8, 0, 23) started
09:54:21 DISPATCHER: Trying to submit another job.
09:54:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:54:21 job_callback for (8, 0, 23) got condition
09:54:21 HBMASTER: Trying to run another job!
09:54:21 job_callback for (8, 0, 23) finished
09:54:21 start sampling a new configuration.
09:54:21 done sampling a new configuration.
09:54:21 HBMASTER: schedule new run for iteration 8
09:54:21 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
09:54:21 HBMASTER: submitting job (8, 0, 24) to dispatcher
09:54:21 DISPATCHER: trying to submit job (8, 0, 24)
09:54:21 DISPATCHER: trying to notify the job_runner thread.
09:54:21 HBMASTER: job (8, 0, 24) submitted to dispatcher
09:54:21 DISPATCHER: Trying to submit another job.
09:54:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:54:21 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:54:21 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:54:21 WORKER: start processing job (8, 0, 24)
09:54:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:54:21 WORKER: args: ()
09:54:21 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 299, 'last_n_outputs': 25, 'leak_rate': 0.8965212127905627, 'lr': 0.0039366386518377965, 'optimizer': 'SGD', 'sparsity': 0.8190503157058944, 'steps_to_train': 42, 'weight_decay': 0.010783194044235467}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:54:28 DISPATCHER: Starting worker discovery
09:54:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:54:28 DISPATCHER: Finished worker discovery
09:55:23 WORKER: done with job (8, 0, 24), trying to register it.
09:55:23 WORKER: registered result for job (8, 0, 24) with dispatcher
09:55:23 DISPATCHER: job (8, 0, 24) finished
09:55:23 DISPATCHER: register_result: lock acquired
09:55:23 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:55:23 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 299, 'last_n_outputs': 25, 'leak_rate': 0.8965212127905627, 'lr': 0.0039366386518377965, 'optimizer': 'SGD', 'sparsity': 0.8190503157058944, 'steps_to_train': 42, 'weight_decay': 0.010783194044235467}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1515751601916086, 'info': {'data04': 0.1515751601916086, 'config': "{'batch_size': 32, 'hidden_dim': 299, 'last_n_outputs': 25, 'leak_rate': 0.8965212127905627, 'lr': 0.0039366386518377965, 'optimizer': 'SGD', 'sparsity': 0.8190503157058944, 'steps_to_train': 42, 'weight_decay': 0.010783194044235467}"}}
exception: None

09:55:23 job_callback for (8, 0, 24) started
09:55:23 DISPATCHER: Trying to submit another job.
09:55:23 job_callback for (8, 0, 24) got condition
09:55:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:55:23 HBMASTER: Trying to run another job!
09:55:23 job_callback for (8, 0, 24) finished
09:55:23 start sampling a new configuration.
09:55:23 best_vector: [3, 0.03575410512119853, 0.5343021231691532, 0.062205931323980945, 0.26121174029547917, 1, 0.41883464786257785, 0.975175607466831, 0.3682323636784703], 0.0011573372649882835, 1.8579916657336777, 0.0021503229927912395
09:55:23 done sampling a new configuration.
09:55:23 HBMASTER: schedule new run for iteration 8
09:55:23 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
09:55:23 HBMASTER: submitting job (8, 0, 25) to dispatcher
09:55:23 DISPATCHER: trying to submit job (8, 0, 25)
09:55:23 DISPATCHER: trying to notify the job_runner thread.
09:55:23 HBMASTER: job (8, 0, 25) submitted to dispatcher
09:55:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:55:23 DISPATCHER: Trying to submit another job.
09:55:23 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:55:23 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:55:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:55:23 WORKER: start processing job (8, 0, 25)
09:55:23 WORKER: args: ()
09:55:23 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 228, 'last_n_outputs': 31, 'leak_rate': 0.7655514828309953, 'lr': 0.0033298408785745553, 'optimizer': 'SGD', 'sparsity': 0.8505203154870187, 'steps_to_train': 98, 'weight_decay': 0.030135704627752058}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:55:28 DISPATCHER: Starting worker discovery
09:55:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:55:28 DISPATCHER: Finished worker discovery
09:56:23 WORKER: done with job (8, 0, 25), trying to register it.
09:56:23 WORKER: registered result for job (8, 0, 25) with dispatcher
09:56:23 DISPATCHER: job (8, 0, 25) finished
09:56:23 DISPATCHER: register_result: lock acquired
09:56:23 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:56:23 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 228, 'last_n_outputs': 31, 'leak_rate': 0.7655514828309953, 'lr': 0.0033298408785745553, 'optimizer': 'SGD', 'sparsity': 0.8505203154870187, 'steps_to_train': 98, 'weight_decay': 0.030135704627752058}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.15287596041431217, 'info': {'data04': 0.15287596041431217, 'config': "{'batch_size': 128, 'hidden_dim': 228, 'last_n_outputs': 31, 'leak_rate': 0.7655514828309953, 'lr': 0.0033298408785745553, 'optimizer': 'SGD', 'sparsity': 0.8505203154870187, 'steps_to_train': 98, 'weight_decay': 0.030135704627752058}"}}
exception: None

09:56:23 job_callback for (8, 0, 25) started
09:56:23 job_callback for (8, 0, 25) got condition
09:56:23 DISPATCHER: Trying to submit another job.
09:56:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:56:23 HBMASTER: Trying to run another job!
09:56:23 job_callback for (8, 0, 25) finished
09:56:23 start sampling a new configuration.
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/hpbandster/optimizers/config_generators/bohb.py:140: RuntimeWarning: invalid value encountered in true_divide
  minimize_me = lambda x: max(1e-32, g(x))/max(l(x),1e-32)
09:56:23 sampled vector: [1, 0.5107569931668511, 0.8429657558321941, 0.39260751203788397, 0.9779887548983309, 0, 0.8099324931529512, 0.7165594213152191, 0.9308452880842195] has EI value nan
09:56:23 data in the KDEs:
[[3.         0.3451935  0.67073179 0.52595742 0.03616452 1.
  0.61644663 0.87362646 0.42249707]
 [3.         0.42009987 0.62195128 0.34909845 0.4099224  1.
  0.79910264 0.95054955 0.76085155]
 [0.         0.83083646 0.64634153 0.87505936 0.47796791 1.
  0.42843374 0.87362646 0.47701047]
 [3.         0.48252185 0.59756102 0.6661074  0.74604362 1.
  0.63453448 0.46703296 0.78422474]
 [0.         0.76342073 0.69512205 0.23086192 0.03441801 1.
  0.48692512 0.48901099 0.98568309]
 [3.         0.09675405 0.7195123  0.77107369 0.71229011 1.
  0.72745692 0.73076928 0.67702914]
 [2.         0.83083646 0.54878051 0.40593941 0.39029352 1.
  0.58524858 0.58791211 0.94098292]
 [3.         0.10299624 0.81707333 0.05459638 0.23954867 1.
  0.28586372 0.60989013 0.72774311]
 [2.         0.30274656 0.57317077 0.15747595 0.20466643 1.
  0.535807   0.89560448 0.72799666]
 [0.         0.83333334 0.62195128 0.60540606 0.51949976 1.
  0.26169293 0.63186816 0.027787  ]]
[[3.         0.91822723 0.57317077 0.60308056 0.48328355 1.
  0.47648461 0.71978027 0.55770103]
 [2.         0.44382022 0.89024409 0.88395607 0.57972612 1.
  0.35201721 0.85164843 0.3779064 ]
 [3.         0.6485643  0.91463435 0.96539698 0.55031546 1.
  0.58309007 0.9065935  0.62247293]
 [3.         0.41510612 0.52439026 0.0035251  0.46768858 1.
  0.7355247  0.68681323 0.88558443]
 [3.         0.06179774 0.67073179 0.2510512  0.63137598 1.
  0.53495557 0.73076928 0.66356437]
 [3.         0.18789013 0.76829281 0.9696463  0.57686415 1.
  0.48481071 0.56593408 0.27321636]
 [0.         0.99687891 0.57317077 0.35683315 0.19015276 1.
  0.50804169 0.24725269 0.93607144]
 [3.         0.01061172 0.32926821 0.60270941 0.93056119 1.
  0.72494085 0.73076928 0.0104419 ]
 [3.         0.16416978 0.45121949 0.22669614 0.68473781 1.
  0.61598158 0.89560448 0.85077754]
 [3.         0.43258427 0.9390246  0.74358069 0.26746076 1.
  0.36498433 0.9065935  0.50129168]
 [1.         0.05305867 0.79268307 0.17656923 0.78150842 1.
  0.45912771 0.65384619 0.80194415]
 [0.         0.49625468 0.37804872 0.71073514 0.83748835 1.
  0.28519945 0.75274731 0.5722816 ]
 [1.         0.14169787 0.30487795 0.44647455 0.34132059 1.
  0.46167707 0.06043946 0.34155232]
 [3.         0.48252185 0.86585384 0.79204221 0.87761075 1.
  0.65838161 0.73076928 0.72187098]]
09:56:23 bandwidth of the KDEs:
[1.15431979e+00 2.49443071e-01 6.62578086e-02 2.28191622e-01
 2.10592470e-01 1.00000000e-03 1.47589144e-01 1.49949376e-01
 2.36473057e-01]
[0.9907879  0.25937462 0.18709464 0.26035818 0.18801067 0.001
 0.11297894 0.20392485 0.21872518]
09:56:23 l(x) = inf
09:56:23 g(x) = inf
09:56:23 best_vector: [1, 0.9698658667026223, 0.6444296121561349, 0.670464023785934, 0.6912481901773442, 1, 0.12007085714690033, 0.2519711070626412, 0.1205186234364175], 0.001754852757244039, 0.2947039644083185, 0.0005171620645126868
09:56:23 done sampling a new configuration.
09:56:23 HBMASTER: schedule new run for iteration 8
09:56:23 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
09:56:23 HBMASTER: submitting job (8, 0, 26) to dispatcher
09:56:23 DISPATCHER: trying to submit job (8, 0, 26)
09:56:23 DISPATCHER: trying to notify the job_runner thread.
09:56:23 HBMASTER: job (8, 0, 26) submitted to dispatcher
09:56:23 DISPATCHER: Trying to submit another job.
09:56:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:56:23 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:56:23 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:56:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:56:23 WORKER: start processing job (8, 0, 26)
09:56:23 WORKER: args: ()
09:56:23 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 976, 'last_n_outputs': 36, 'leak_rate': 0.9176160059464835, 'lr': 0.02412661424081468, 'optimizer': 'SGD', 'sparsity': 0.778817005715256, 'steps_to_train': 32, 'weight_decay': 0.014348230475450719}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:56:28 DISPATCHER: Starting worker discovery
09:56:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:56:28 DISPATCHER: Finished worker discovery
09:57:25 WORKER: done with job (8, 0, 26), trying to register it.
09:57:25 WORKER: registered result for job (8, 0, 26) with dispatcher
09:57:25 DISPATCHER: job (8, 0, 26) finished
09:57:25 DISPATCHER: register_result: lock acquired
09:57:25 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:57:25 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 976, 'last_n_outputs': 36, 'leak_rate': 0.9176160059464835, 'lr': 0.02412661424081468, 'optimizer': 'SGD', 'sparsity': 0.778817005715256, 'steps_to_train': 32, 'weight_decay': 0.014348230475450719}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.17600132601537014, 'info': {'data04': 0.17600132601537014, 'config': "{'batch_size': 32, 'hidden_dim': 976, 'last_n_outputs': 36, 'leak_rate': 0.9176160059464835, 'lr': 0.02412661424081468, 'optimizer': 'SGD', 'sparsity': 0.778817005715256, 'steps_to_train': 32, 'weight_decay': 0.014348230475450719}"}}
exception: None

09:57:25 job_callback for (8, 0, 26) started
09:57:25 job_callback for (8, 0, 26) got condition
09:57:25 DISPATCHER: Trying to submit another job.
09:57:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:57:25 HBMASTER: Trying to run another job!
09:57:25 job_callback for (8, 0, 26) finished
09:57:25 ITERATION: Advancing config (8, 0, 1) to next budget 133.333333
09:57:25 ITERATION: Advancing config (8, 0, 2) to next budget 133.333333
09:57:25 ITERATION: Advancing config (8, 0, 4) to next budget 133.333333
09:57:25 ITERATION: Advancing config (8, 0, 5) to next budget 133.333333
09:57:25 ITERATION: Advancing config (8, 0, 6) to next budget 133.333333
09:57:25 ITERATION: Advancing config (8, 0, 14) to next budget 133.333333
09:57:25 ITERATION: Advancing config (8, 0, 18) to next budget 133.333333
09:57:25 ITERATION: Advancing config (8, 0, 21) to next budget 133.333333
09:57:25 ITERATION: Advancing config (8, 0, 26) to next budget 133.333333
09:57:25 HBMASTER: schedule new run for iteration 8
09:57:25 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
09:57:25 HBMASTER: submitting job (8, 0, 1) to dispatcher
09:57:25 DISPATCHER: trying to submit job (8, 0, 1)
09:57:25 DISPATCHER: trying to notify the job_runner thread.
09:57:25 HBMASTER: job (8, 0, 1) submitted to dispatcher
09:57:25 DISPATCHER: Trying to submit another job.
09:57:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:57:25 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:57:25 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:57:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:57:25 WORKER: start processing job (8, 0, 1)
09:57:25 WORKER: args: ()
09:57:25 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 756, 'last_n_outputs': 37, 'leak_rate': 0.9019793640319813, 'lr': 0.0028947034160293436, 'optimizer': 'SGD', 'sparsity': 0.9745535440105276, 'steps_to_train': 86, 'weight_decay': 0.013357296058930119}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:57:28 DISPATCHER: Starting worker discovery
09:57:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:57:28 DISPATCHER: Finished worker discovery
09:58:28 DISPATCHER: Starting worker discovery
09:58:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:58:28 DISPATCHER: Finished worker discovery
09:59:28 DISPATCHER: Starting worker discovery
09:59:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:59:28 DISPATCHER: Finished worker discovery
09:59:56 WORKER: done with job (8, 0, 1), trying to register it.
09:59:56 WORKER: registered result for job (8, 0, 1) with dispatcher
09:59:56 DISPATCHER: job (8, 0, 1) finished
09:59:56 DISPATCHER: register_result: lock acquired
09:59:56 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:59:56 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 756, 'last_n_outputs': 37, 'leak_rate': 0.9019793640319813, 'lr': 0.0028947034160293436, 'optimizer': 'SGD', 'sparsity': 0.9745535440105276, 'steps_to_train': 86, 'weight_decay': 0.013357296058930119}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.16923965630557536, 'info': {'data04': 0.16923965630557536, 'config': "{'batch_size': 64, 'hidden_dim': 756, 'last_n_outputs': 37, 'leak_rate': 0.9019793640319813, 'lr': 0.0028947034160293436, 'optimizer': 'SGD', 'sparsity': 0.9745535440105276, 'steps_to_train': 86, 'weight_decay': 0.013357296058930119}"}}
exception: None

09:59:56 job_callback for (8, 0, 1) started
09:59:56 DISPATCHER: Trying to submit another job.
09:59:56 job_callback for (8, 0, 1) got condition
09:59:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:59:56 HBMASTER: Trying to run another job!
09:59:56 job_callback for (8, 0, 1) finished
09:59:56 HBMASTER: schedule new run for iteration 8
09:59:56 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
09:59:56 HBMASTER: submitting job (8, 0, 2) to dispatcher
09:59:56 DISPATCHER: trying to submit job (8, 0, 2)
09:59:56 DISPATCHER: trying to notify the job_runner thread.
09:59:56 HBMASTER: job (8, 0, 2) submitted to dispatcher
09:59:56 DISPATCHER: Trying to submit another job.
09:59:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:59:56 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:59:56 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:59:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:59:56 WORKER: start processing job (8, 0, 2)
09:59:56 WORKER: args: ()
09:59:56 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 745, 'last_n_outputs': 40, 'leak_rate': 0.8661754951477285, 'lr': 0.0024268700070278213, 'optimizer': 'SGD', 'sparsity': 0.9749888829735569, 'steps_to_train': 65, 'weight_decay': 0.031408746043503716}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:00:28 DISPATCHER: Starting worker discovery
10:00:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:00:28 DISPATCHER: Finished worker discovery
10:01:28 DISPATCHER: Starting worker discovery
10:01:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:01:28 DISPATCHER: Finished worker discovery
10:02:28 DISPATCHER: Starting worker discovery
10:02:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:02:28 DISPATCHER: Finished worker discovery
10:02:29 WORKER: done with job (8, 0, 2), trying to register it.
10:02:29 WORKER: registered result for job (8, 0, 2) with dispatcher
10:02:29 DISPATCHER: job (8, 0, 2) finished
10:02:29 DISPATCHER: register_result: lock acquired
10:02:29 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
10:02:29 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 745, 'last_n_outputs': 40, 'leak_rate': 0.8661754951477285, 'lr': 0.0024268700070278213, 'optimizer': 'SGD', 'sparsity': 0.9749888829735569, 'steps_to_train': 65, 'weight_decay': 0.031408746043503716}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.16833610668562965, 'info': {'data04': 0.16833610668562965, 'config': "{'batch_size': 32, 'hidden_dim': 745, 'last_n_outputs': 40, 'leak_rate': 0.8661754951477285, 'lr': 0.0024268700070278213, 'optimizer': 'SGD', 'sparsity': 0.9749888829735569, 'steps_to_train': 65, 'weight_decay': 0.031408746043503716}"}}
exception: None

10:02:29 job_callback for (8, 0, 2) started
10:02:29 DISPATCHER: Trying to submit another job.
10:02:29 job_callback for (8, 0, 2) got condition
10:02:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:02:29 HBMASTER: Trying to run another job!
10:02:29 job_callback for (8, 0, 2) finished
10:02:29 HBMASTER: schedule new run for iteration 8
10:02:29 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
10:02:29 HBMASTER: submitting job (8, 0, 4) to dispatcher
10:02:29 DISPATCHER: trying to submit job (8, 0, 4)
10:02:29 DISPATCHER: trying to notify the job_runner thread.
10:02:29 HBMASTER: job (8, 0, 4) submitted to dispatcher
10:02:29 DISPATCHER: Trying to submit another job.
10:02:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:02:29 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:02:29 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:02:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:02:29 WORKER: start processing job (8, 0, 4)
10:02:29 WORKER: args: ()
10:02:29 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 956, 'last_n_outputs': 38, 'leak_rate': 0.9936094864041632, 'lr': 0.005642477220466217, 'optimizer': 'SGD', 'sparsity': 0.9347769773368289, 'steps_to_train': 84, 'weight_decay': 0.015839738328309115}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:03:28 DISPATCHER: Starting worker discovery
10:03:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:03:28 DISPATCHER: Finished worker discovery
10:04:28 DISPATCHER: Starting worker discovery
10:04:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:04:28 DISPATCHER: Finished worker discovery
10:05:00 WORKER: done with job (8, 0, 4), trying to register it.
10:05:00 WORKER: registered result for job (8, 0, 4) with dispatcher
10:05:00 DISPATCHER: job (8, 0, 4) finished
10:05:00 DISPATCHER: register_result: lock acquired
10:05:00 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
10:05:00 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 956, 'last_n_outputs': 38, 'leak_rate': 0.9936094864041632, 'lr': 0.005642477220466217, 'optimizer': 'SGD', 'sparsity': 0.9347769773368289, 'steps_to_train': 84, 'weight_decay': 0.015839738328309115}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.16810367759132558, 'info': {'data04': 0.16810367759132558, 'config': "{'batch_size': 128, 'hidden_dim': 956, 'last_n_outputs': 38, 'leak_rate': 0.9936094864041632, 'lr': 0.005642477220466217, 'optimizer': 'SGD', 'sparsity': 0.9347769773368289, 'steps_to_train': 84, 'weight_decay': 0.015839738328309115}"}}
exception: None

10:05:00 job_callback for (8, 0, 4) started
10:05:00 DISPATCHER: Trying to submit another job.
10:05:00 job_callback for (8, 0, 4) got condition
10:05:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:05:00 HBMASTER: Trying to run another job!
10:05:00 job_callback for (8, 0, 4) finished
10:05:00 HBMASTER: schedule new run for iteration 8
10:05:00 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
10:05:00 HBMASTER: submitting job (8, 0, 5) to dispatcher
10:05:00 DISPATCHER: trying to submit job (8, 0, 5)
10:05:00 DISPATCHER: trying to notify the job_runner thread.
10:05:00 HBMASTER: job (8, 0, 5) submitted to dispatcher
10:05:00 DISPATCHER: Trying to submit another job.
10:05:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:05:00 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:05:00 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:05:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:05:00 WORKER: start processing job (8, 0, 5)
10:05:00 WORKER: args: ()
10:05:00 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 604, 'last_n_outputs': 40, 'leak_rate': 0.9404572804871348, 'lr': 0.022431917890105554, 'optimizer': 'SGD', 'sparsity': 0.7666816244185286, 'steps_to_train': 27, 'weight_decay': 0.12341204031592448}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:05:28 DISPATCHER: Starting worker discovery
10:05:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:05:28 DISPATCHER: Finished worker discovery
10:06:28 DISPATCHER: Starting worker discovery
10:06:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:06:28 DISPATCHER: Finished worker discovery
10:07:28 DISPATCHER: Starting worker discovery
10:07:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:07:28 DISPATCHER: Finished worker discovery
10:07:35 WORKER: done with job (8, 0, 5), trying to register it.
10:07:35 WORKER: registered result for job (8, 0, 5) with dispatcher
10:07:35 DISPATCHER: job (8, 0, 5) finished
10:07:35 DISPATCHER: register_result: lock acquired
10:07:35 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
10:07:35 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 604, 'last_n_outputs': 40, 'leak_rate': 0.9404572804871348, 'lr': 0.022431917890105554, 'optimizer': 'SGD', 'sparsity': 0.7666816244185286, 'steps_to_train': 27, 'weight_decay': 0.12341204031592448}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.16004784544186504, 'info': {'data04': 0.16004784544186504, 'config': "{'batch_size': 64, 'hidden_dim': 604, 'last_n_outputs': 40, 'leak_rate': 0.9404572804871348, 'lr': 0.022431917890105554, 'optimizer': 'SGD', 'sparsity': 0.7666816244185286, 'steps_to_train': 27, 'weight_decay': 0.12341204031592448}"}}
exception: None

10:07:35 job_callback for (8, 0, 5) started
10:07:35 DISPATCHER: Trying to submit another job.
10:07:35 job_callback for (8, 0, 5) got condition
10:07:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:07:35 HBMASTER: Trying to run another job!
10:07:35 job_callback for (8, 0, 5) finished
10:07:35 HBMASTER: schedule new run for iteration 8
10:07:35 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
10:07:35 HBMASTER: submitting job (8, 0, 6) to dispatcher
10:07:35 DISPATCHER: trying to submit job (8, 0, 6)
10:07:35 DISPATCHER: trying to notify the job_runner thread.
10:07:35 HBMASTER: job (8, 0, 6) submitted to dispatcher
10:07:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:07:35 DISPATCHER: Trying to submit another job.
10:07:35 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:07:35 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:07:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:07:35 WORKER: start processing job (8, 0, 6)
10:07:35 WORKER: args: ()
10:07:35 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 921, 'last_n_outputs': 30, 'leak_rate': 0.9205119128182242, 'lr': 0.014569787445090954, 'optimizer': 'SGD', 'sparsity': 0.9247336816930738, 'steps_to_train': 72, 'weight_decay': 0.18347566785599728}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:08:28 DISPATCHER: Starting worker discovery
10:08:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:08:28 DISPATCHER: Finished worker discovery
10:09:28 DISPATCHER: Starting worker discovery
10:09:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:09:28 DISPATCHER: Finished worker discovery
10:10:07 WORKER: done with job (8, 0, 6), trying to register it.
10:10:07 WORKER: registered result for job (8, 0, 6) with dispatcher
10:10:07 DISPATCHER: job (8, 0, 6) finished
10:10:07 DISPATCHER: register_result: lock acquired
10:10:07 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
10:10:07 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 921, 'last_n_outputs': 30, 'leak_rate': 0.9205119128182242, 'lr': 0.014569787445090954, 'optimizer': 'SGD', 'sparsity': 0.9247336816930738, 'steps_to_train': 72, 'weight_decay': 0.18347566785599728}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.16874363978819085, 'info': {'data04': 0.16874363978819085, 'config': "{'batch_size': 128, 'hidden_dim': 921, 'last_n_outputs': 30, 'leak_rate': 0.9205119128182242, 'lr': 0.014569787445090954, 'optimizer': 'SGD', 'sparsity': 0.9247336816930738, 'steps_to_train': 72, 'weight_decay': 0.18347566785599728}"}}
exception: None

10:10:07 job_callback for (8, 0, 6) started
10:10:07 DISPATCHER: Trying to submit another job.
10:10:07 job_callback for (8, 0, 6) got condition
10:10:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:10:07 HBMASTER: Trying to run another job!
10:10:07 job_callback for (8, 0, 6) finished
10:10:07 HBMASTER: schedule new run for iteration 8
10:10:07 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
10:10:07 HBMASTER: submitting job (8, 0, 14) to dispatcher
10:10:07 DISPATCHER: trying to submit job (8, 0, 14)
10:10:07 DISPATCHER: trying to notify the job_runner thread.
10:10:07 HBMASTER: job (8, 0, 14) submitted to dispatcher
10:10:07 DISPATCHER: Trying to submit another job.
10:10:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:10:07 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:10:07 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:10:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:10:07 WORKER: start processing job (8, 0, 14)
10:10:07 WORKER: args: ()
10:10:07 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 343, 'last_n_outputs': 40, 'leak_rate': 0.8217478681258357, 'lr': 0.003014416534890098, 'optimizer': 'SGD', 'sparsity': 0.7969615457520882, 'steps_to_train': 50, 'weight_decay': 0.08890540427839949}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:10:28 DISPATCHER: Starting worker discovery
10:10:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:10:28 DISPATCHER: Finished worker discovery
10:11:28 DISPATCHER: Starting worker discovery
10:11:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:11:28 DISPATCHER: Finished worker discovery
10:12:28 DISPATCHER: Starting worker discovery
10:12:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:12:28 DISPATCHER: Finished worker discovery
10:12:39 WORKER: done with job (8, 0, 14), trying to register it.
10:12:39 WORKER: registered result for job (8, 0, 14) with dispatcher
10:12:39 DISPATCHER: job (8, 0, 14) finished
10:12:39 DISPATCHER: register_result: lock acquired
10:12:39 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
10:12:39 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 343, 'last_n_outputs': 40, 'leak_rate': 0.8217478681258357, 'lr': 0.003014416534890098, 'optimizer': 'SGD', 'sparsity': 0.7969615457520882, 'steps_to_train': 50, 'weight_decay': 0.08890540427839949}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.17303829714441205, 'info': {'data04': 0.17303829714441205, 'config': "{'batch_size': 32, 'hidden_dim': 343, 'last_n_outputs': 40, 'leak_rate': 0.8217478681258357, 'lr': 0.003014416534890098, 'optimizer': 'SGD', 'sparsity': 0.7969615457520882, 'steps_to_train': 50, 'weight_decay': 0.08890540427839949}"}}
exception: None

10:12:39 job_callback for (8, 0, 14) started
10:12:39 job_callback for (8, 0, 14) got condition
10:12:39 DISPATCHER: Trying to submit another job.
10:12:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:12:39 HBMASTER: Trying to run another job!
10:12:39 job_callback for (8, 0, 14) finished
10:12:39 HBMASTER: schedule new run for iteration 8
10:12:39 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
10:12:39 HBMASTER: submitting job (8, 0, 18) to dispatcher
10:12:39 DISPATCHER: trying to submit job (8, 0, 18)
10:12:39 DISPATCHER: trying to notify the job_runner thread.
10:12:39 HBMASTER: job (8, 0, 18) submitted to dispatcher
10:12:39 DISPATCHER: Trying to submit another job.
10:12:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:12:39 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:12:39 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:12:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:12:39 WORKER: start processing job (8, 0, 18)
10:12:39 WORKER: args: ()
10:12:39 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 763, 'last_n_outputs': 38, 'leak_rate': 0.8537747774854527, 'lr': 0.002545548308253905, 'optimizer': 'SGD', 'sparsity': 0.9509696531882244, 'steps_to_train': 98, 'weight_decay': 0.014814529348438592}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:13:28 DISPATCHER: Starting worker discovery
10:13:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:13:28 DISPATCHER: Finished worker discovery
10:14:28 DISPATCHER: Starting worker discovery
10:14:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:14:28 DISPATCHER: Finished worker discovery
10:15:09 WORKER: done with job (8, 0, 18), trying to register it.
10:15:09 WORKER: registered result for job (8, 0, 18) with dispatcher
10:15:09 DISPATCHER: job (8, 0, 18) finished
10:15:09 DISPATCHER: register_result: lock acquired
10:15:09 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
10:15:09 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 763, 'last_n_outputs': 38, 'leak_rate': 0.8537747774854527, 'lr': 0.002545548308253905, 'optimizer': 'SGD', 'sparsity': 0.9509696531882244, 'steps_to_train': 98, 'weight_decay': 0.014814529348438592}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1740588836913307, 'info': {'data04': 0.1740588836913307, 'config': "{'batch_size': 16, 'hidden_dim': 763, 'last_n_outputs': 38, 'leak_rate': 0.8537747774854527, 'lr': 0.002545548308253905, 'optimizer': 'SGD', 'sparsity': 0.9509696531882244, 'steps_to_train': 98, 'weight_decay': 0.014814529348438592}"}}
exception: None

10:15:09 job_callback for (8, 0, 18) started
10:15:09 job_callback for (8, 0, 18) got condition
10:15:09 DISPATCHER: Trying to submit another job.
10:15:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:15:09 HBMASTER: Trying to run another job!
10:15:09 job_callback for (8, 0, 18) finished
10:15:09 HBMASTER: schedule new run for iteration 8
10:15:09 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
10:15:09 HBMASTER: submitting job (8, 0, 21) to dispatcher
10:15:09 DISPATCHER: trying to submit job (8, 0, 21)
10:15:09 DISPATCHER: trying to notify the job_runner thread.
10:15:09 HBMASTER: job (8, 0, 21) submitted to dispatcher
10:15:09 DISPATCHER: Trying to submit another job.
10:15:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:15:09 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:15:09 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:15:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:15:09 WORKER: start processing job (8, 0, 21)
10:15:09 WORKER: args: ()
10:15:09 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 794, 'last_n_outputs': 37, 'leak_rate': 0.858944773045273, 'lr': 0.0077352965867062045, 'optimizer': 'SGD', 'sparsity': 0.7847259292761343, 'steps_to_train': 66, 'weight_decay': 0.014462737645756469}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:15:28 DISPATCHER: Starting worker discovery
10:15:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:15:28 DISPATCHER: Finished worker discovery
10:16:28 DISPATCHER: Starting worker discovery
10:16:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:16:28 DISPATCHER: Finished worker discovery
10:17:28 DISPATCHER: Starting worker discovery
10:17:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:17:28 DISPATCHER: Finished worker discovery
10:17:42 WORKER: done with job (8, 0, 21), trying to register it.
10:17:42 WORKER: registered result for job (8, 0, 21) with dispatcher
10:17:42 DISPATCHER: job (8, 0, 21) finished
10:17:42 DISPATCHER: register_result: lock acquired
10:17:42 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
10:17:42 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 794, 'last_n_outputs': 37, 'leak_rate': 0.858944773045273, 'lr': 0.0077352965867062045, 'optimizer': 'SGD', 'sparsity': 0.7847259292761343, 'steps_to_train': 66, 'weight_decay': 0.014462737645756469}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1744621893921514, 'info': {'data04': 0.1744621893921514, 'config': "{'batch_size': 32, 'hidden_dim': 794, 'last_n_outputs': 37, 'leak_rate': 0.858944773045273, 'lr': 0.0077352965867062045, 'optimizer': 'SGD', 'sparsity': 0.7847259292761343, 'steps_to_train': 66, 'weight_decay': 0.014462737645756469}"}}
exception: None

10:17:42 job_callback for (8, 0, 21) started
10:17:42 DISPATCHER: Trying to submit another job.
10:17:42 job_callback for (8, 0, 21) got condition
10:17:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:17:42 HBMASTER: Trying to run another job!
10:17:42 job_callback for (8, 0, 21) finished
10:17:42 HBMASTER: schedule new run for iteration 8
10:17:42 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
10:17:42 HBMASTER: submitting job (8, 0, 26) to dispatcher
10:17:42 DISPATCHER: trying to submit job (8, 0, 26)
10:17:42 DISPATCHER: trying to notify the job_runner thread.
10:17:42 HBMASTER: job (8, 0, 26) submitted to dispatcher
10:17:42 DISPATCHER: Trying to submit another job.
10:17:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:17:42 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:17:42 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:17:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:17:42 WORKER: start processing job (8, 0, 26)
10:17:42 WORKER: args: ()
10:17:42 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 976, 'last_n_outputs': 36, 'leak_rate': 0.9176160059464835, 'lr': 0.02412661424081468, 'optimizer': 'SGD', 'sparsity': 0.778817005715256, 'steps_to_train': 32, 'weight_decay': 0.014348230475450719}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:18:28 DISPATCHER: Starting worker discovery
10:18:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:18:28 DISPATCHER: Finished worker discovery
10:19:28 DISPATCHER: Starting worker discovery
10:19:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:19:28 DISPATCHER: Finished worker discovery
10:20:17 WORKER: done with job (8, 0, 26), trying to register it.
10:20:17 WORKER: registered result for job (8, 0, 26) with dispatcher
10:20:17 DISPATCHER: job (8, 0, 26) finished
10:20:17 DISPATCHER: register_result: lock acquired
10:20:17 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
10:20:17 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 976, 'last_n_outputs': 36, 'leak_rate': 0.9176160059464835, 'lr': 0.02412661424081468, 'optimizer': 'SGD', 'sparsity': 0.778817005715256, 'steps_to_train': 32, 'weight_decay': 0.014348230475450719}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.17082886143275033, 'info': {'data04': 0.17082886143275033, 'config': "{'batch_size': 32, 'hidden_dim': 976, 'last_n_outputs': 36, 'leak_rate': 0.9176160059464835, 'lr': 0.02412661424081468, 'optimizer': 'SGD', 'sparsity': 0.778817005715256, 'steps_to_train': 32, 'weight_decay': 0.014348230475450719}"}}
exception: None

10:20:17 job_callback for (8, 0, 26) started
10:20:17 DISPATCHER: Trying to submit another job.
10:20:17 job_callback for (8, 0, 26) got condition
10:20:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:20:17 HBMASTER: Trying to run another job!
10:20:17 job_callback for (8, 0, 26) finished
10:20:17 ITERATION: Advancing config (8, 0, 14) to next budget 400.000000
10:20:17 ITERATION: Advancing config (8, 0, 18) to next budget 400.000000
10:20:17 ITERATION: Advancing config (8, 0, 21) to next budget 400.000000
10:20:17 HBMASTER: schedule new run for iteration 8
10:20:17 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
10:20:17 HBMASTER: submitting job (8, 0, 14) to dispatcher
10:20:17 DISPATCHER: trying to submit job (8, 0, 14)
10:20:17 DISPATCHER: trying to notify the job_runner thread.
10:20:17 HBMASTER: job (8, 0, 14) submitted to dispatcher
10:20:17 DISPATCHER: Trying to submit another job.
10:20:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:20:17 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:20:17 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:20:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:20:17 WORKER: start processing job (8, 0, 14)
10:20:17 WORKER: args: ()
10:20:17 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 343, 'last_n_outputs': 40, 'leak_rate': 0.8217478681258357, 'lr': 0.003014416534890098, 'optimizer': 'SGD', 'sparsity': 0.7969615457520882, 'steps_to_train': 50, 'weight_decay': 0.08890540427839949}, 'budget': 400.0, 'working_directory': '.'}
10:20:28 DISPATCHER: Starting worker discovery
10:20:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:20:28 DISPATCHER: Finished worker discovery
10:21:28 DISPATCHER: Starting worker discovery
10:21:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:21:28 DISPATCHER: Finished worker discovery
10:22:28 DISPATCHER: Starting worker discovery
10:22:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:22:28 DISPATCHER: Finished worker discovery
10:23:28 DISPATCHER: Starting worker discovery
10:23:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:23:28 DISPATCHER: Finished worker discovery
10:24:28 DISPATCHER: Starting worker discovery
10:24:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:24:28 DISPATCHER: Finished worker discovery
10:25:28 DISPATCHER: Starting worker discovery
10:25:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:25:28 DISPATCHER: Finished worker discovery
10:26:28 DISPATCHER: Starting worker discovery
10:26:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:26:28 DISPATCHER: Finished worker discovery
10:27:22 WORKER: done with job (8, 0, 14), trying to register it.
10:27:22 WORKER: registered result for job (8, 0, 14) with dispatcher
10:27:22 DISPATCHER: job (8, 0, 14) finished
10:27:22 DISPATCHER: register_result: lock acquired
10:27:22 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
10:27:22 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 343, 'last_n_outputs': 40, 'leak_rate': 0.8217478681258357, 'lr': 0.003014416534890098, 'optimizer': 'SGD', 'sparsity': 0.7969615457520882, 'steps_to_train': 50, 'weight_decay': 0.08890540427839949}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.1800005848890639, 'info': {'data04': 0.1800005848890639, 'config': "{'batch_size': 32, 'hidden_dim': 343, 'last_n_outputs': 40, 'leak_rate': 0.8217478681258357, 'lr': 0.003014416534890098, 'optimizer': 'SGD', 'sparsity': 0.7969615457520882, 'steps_to_train': 50, 'weight_decay': 0.08890540427839949}"}}
exception: None

10:27:22 job_callback for (8, 0, 14) started
10:27:22 job_callback for (8, 0, 14) got condition
10:27:22 DISPATCHER: Trying to submit another job.
10:27:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:27:22 done building a new model for budget 400.000000 based on 10/21 split
Best loss for this budget:-0.185359





10:27:22 HBMASTER: Trying to run another job!
10:27:22 job_callback for (8, 0, 14) finished
10:27:22 HBMASTER: schedule new run for iteration 8
10:27:22 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
10:27:22 HBMASTER: submitting job (8, 0, 18) to dispatcher
10:27:22 DISPATCHER: trying to submit job (8, 0, 18)
10:27:22 DISPATCHER: trying to notify the job_runner thread.
10:27:22 HBMASTER: job (8, 0, 18) submitted to dispatcher
10:27:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:27:22 DISPATCHER: Trying to submit another job.
10:27:22 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:27:22 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:27:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:27:22 WORKER: start processing job (8, 0, 18)
10:27:22 WORKER: args: ()
10:27:22 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 763, 'last_n_outputs': 38, 'leak_rate': 0.8537747774854527, 'lr': 0.002545548308253905, 'optimizer': 'SGD', 'sparsity': 0.9509696531882244, 'steps_to_train': 98, 'weight_decay': 0.014814529348438592}, 'budget': 400.0, 'working_directory': '.'}
10:27:28 DISPATCHER: Starting worker discovery
10:27:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:27:28 DISPATCHER: Finished worker discovery
10:28:28 DISPATCHER: Starting worker discovery
10:28:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:28:28 DISPATCHER: Finished worker discovery
10:29:28 DISPATCHER: Starting worker discovery
10:29:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:29:28 DISPATCHER: Finished worker discovery
10:30:28 DISPATCHER: Starting worker discovery
10:30:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:30:28 DISPATCHER: Finished worker discovery
10:31:28 DISPATCHER: Starting worker discovery
10:31:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:31:28 DISPATCHER: Finished worker discovery
10:32:28 DISPATCHER: Starting worker discovery
10:32:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:32:28 DISPATCHER: Finished worker discovery
10:33:28 DISPATCHER: Starting worker discovery
10:33:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:33:28 DISPATCHER: Finished worker discovery
10:34:26 WORKER: done with job (8, 0, 18), trying to register it.
10:34:26 WORKER: registered result for job (8, 0, 18) with dispatcher
10:34:26 DISPATCHER: job (8, 0, 18) finished
10:34:26 DISPATCHER: register_result: lock acquired
10:34:26 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
10:34:26 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 763, 'last_n_outputs': 38, 'leak_rate': 0.8537747774854527, 'lr': 0.002545548308253905, 'optimizer': 'SGD', 'sparsity': 0.9509696531882244, 'steps_to_train': 98, 'weight_decay': 0.014814529348438592}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.17878083208456438, 'info': {'data04': 0.17878083208456438, 'config': "{'batch_size': 16, 'hidden_dim': 763, 'last_n_outputs': 38, 'leak_rate': 0.8537747774854527, 'lr': 0.002545548308253905, 'optimizer': 'SGD', 'sparsity': 0.9509696531882244, 'steps_to_train': 98, 'weight_decay': 0.014814529348438592}"}}
exception: None

10:34:26 job_callback for (8, 0, 18) started
10:34:26 DISPATCHER: Trying to submit another job.
10:34:26 job_callback for (8, 0, 18) got condition
10:34:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:34:26 done building a new model for budget 400.000000 based on 10/22 split
Best loss for this budget:-0.185359





10:34:26 HBMASTER: Trying to run another job!
10:34:26 job_callback for (8, 0, 18) finished
10:34:26 HBMASTER: schedule new run for iteration 8
10:34:26 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
10:34:26 HBMASTER: submitting job (8, 0, 21) to dispatcher
10:34:26 DISPATCHER: trying to submit job (8, 0, 21)
10:34:26 DISPATCHER: trying to notify the job_runner thread.
10:34:26 HBMASTER: job (8, 0, 21) submitted to dispatcher
10:34:26 DISPATCHER: Trying to submit another job.
10:34:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:34:26 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:34:26 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:34:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:34:26 WORKER: start processing job (8, 0, 21)
10:34:26 WORKER: args: ()
10:34:26 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 794, 'last_n_outputs': 37, 'leak_rate': 0.858944773045273, 'lr': 0.0077352965867062045, 'optimizer': 'SGD', 'sparsity': 0.7847259292761343, 'steps_to_train': 66, 'weight_decay': 0.014462737645756469}, 'budget': 400.0, 'working_directory': '.'}
10:34:28 DISPATCHER: Starting worker discovery
10:34:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:34:28 DISPATCHER: Finished worker discovery
10:35:28 DISPATCHER: Starting worker discovery
10:35:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:35:28 DISPATCHER: Finished worker discovery
10:36:28 DISPATCHER: Starting worker discovery
10:36:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:36:28 DISPATCHER: Finished worker discovery
10:37:28 DISPATCHER: Starting worker discovery
10:37:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:37:28 DISPATCHER: Finished worker discovery
10:38:28 DISPATCHER: Starting worker discovery
10:38:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:38:28 DISPATCHER: Finished worker discovery
10:39:28 DISPATCHER: Starting worker discovery
10:39:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:39:28 DISPATCHER: Finished worker discovery
10:40:28 DISPATCHER: Starting worker discovery
10:40:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:40:28 DISPATCHER: Finished worker discovery
10:41:28 DISPATCHER: Starting worker discovery
10:41:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:41:28 DISPATCHER: Finished worker discovery
10:41:31 WORKER: done with job (8, 0, 21), trying to register it.
10:41:31 WORKER: registered result for job (8, 0, 21) with dispatcher
10:41:31 DISPATCHER: job (8, 0, 21) finished
10:41:31 DISPATCHER: register_result: lock acquired
10:41:31 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
10:41:31 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 794, 'last_n_outputs': 37, 'leak_rate': 0.858944773045273, 'lr': 0.0077352965867062045, 'optimizer': 'SGD', 'sparsity': 0.7847259292761343, 'steps_to_train': 66, 'weight_decay': 0.014462737645756469}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.18216321958579487, 'info': {'data04': 0.18216321958579487, 'config': "{'batch_size': 32, 'hidden_dim': 794, 'last_n_outputs': 37, 'leak_rate': 0.858944773045273, 'lr': 0.0077352965867062045, 'optimizer': 'SGD', 'sparsity': 0.7847259292761343, 'steps_to_train': 66, 'weight_decay': 0.014462737645756469}"}}
exception: None

10:41:31 job_callback for (8, 0, 21) started
10:41:31 DISPATCHER: Trying to submit another job.
10:41:31 job_callback for (8, 0, 21) got condition
10:41:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:41:31 done building a new model for budget 400.000000 based on 10/22 split
Best loss for this budget:-0.185359





10:41:31 HBMASTER: Trying to run another job!
10:41:31 job_callback for (8, 0, 21) finished
10:41:31 ITERATION: Advancing config (8, 0, 21) to next budget 1200.000000
10:41:31 HBMASTER: schedule new run for iteration 8
10:41:31 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
10:41:31 HBMASTER: submitting job (8, 0, 21) to dispatcher
10:41:31 DISPATCHER: trying to submit job (8, 0, 21)
10:41:31 DISPATCHER: trying to notify the job_runner thread.
10:41:31 HBMASTER: job (8, 0, 21) submitted to dispatcher
10:41:31 DISPATCHER: Trying to submit another job.
10:41:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:41:31 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:41:31 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:41:31 WORKER: start processing job (8, 0, 21)
10:41:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:41:31 WORKER: args: ()
10:41:31 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 794, 'last_n_outputs': 37, 'leak_rate': 0.858944773045273, 'lr': 0.0077352965867062045, 'optimizer': 'SGD', 'sparsity': 0.7847259292761343, 'steps_to_train': 66, 'weight_decay': 0.014462737645756469}, 'budget': 1200.0, 'working_directory': '.'}
10:42:28 DISPATCHER: Starting worker discovery
10:42:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:42:28 DISPATCHER: Finished worker discovery
10:43:28 DISPATCHER: Starting worker discovery
10:43:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:43:28 DISPATCHER: Finished worker discovery
10:44:28 DISPATCHER: Starting worker discovery
10:44:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:44:28 DISPATCHER: Finished worker discovery
10:45:28 DISPATCHER: Starting worker discovery
10:45:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:45:28 DISPATCHER: Finished worker discovery
10:46:28 DISPATCHER: Starting worker discovery
10:46:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:46:28 DISPATCHER: Finished worker discovery
10:47:28 DISPATCHER: Starting worker discovery
10:47:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:47:28 DISPATCHER: Finished worker discovery
10:48:28 DISPATCHER: Starting worker discovery
10:48:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:48:28 DISPATCHER: Finished worker discovery
10:49:28 DISPATCHER: Starting worker discovery
10:49:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:49:28 DISPATCHER: Finished worker discovery
10:50:28 DISPATCHER: Starting worker discovery
10:50:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:50:28 DISPATCHER: Finished worker discovery
10:51:28 DISPATCHER: Starting worker discovery
10:51:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:51:28 DISPATCHER: Finished worker discovery
10:52:28 DISPATCHER: Starting worker discovery
10:52:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:52:28 DISPATCHER: Finished worker discovery
10:53:28 DISPATCHER: Starting worker discovery
10:53:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:53:28 DISPATCHER: Finished worker discovery
10:54:28 DISPATCHER: Starting worker discovery
10:54:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:54:28 DISPATCHER: Finished worker discovery
10:55:28 DISPATCHER: Starting worker discovery
10:55:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:55:28 DISPATCHER: Finished worker discovery
10:56:28 DISPATCHER: Starting worker discovery
10:56:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:56:28 DISPATCHER: Finished worker discovery
10:57:28 DISPATCHER: Starting worker discovery
10:57:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:57:28 DISPATCHER: Finished worker discovery
10:58:28 DISPATCHER: Starting worker discovery
10:58:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:58:28 DISPATCHER: Finished worker discovery
10:59:28 DISPATCHER: Starting worker discovery
10:59:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:59:28 DISPATCHER: Finished worker discovery
11:00:28 DISPATCHER: Starting worker discovery
11:00:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:00:28 DISPATCHER: Finished worker discovery
11:01:28 DISPATCHER: Starting worker discovery
11:01:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:01:28 DISPATCHER: Finished worker discovery
11:02:09 WORKER: done with job (8, 0, 21), trying to register it.
11:02:09 WORKER: registered result for job (8, 0, 21) with dispatcher
11:02:09 DISPATCHER: job (8, 0, 21) finished
11:02:09 DISPATCHER: register_result: lock acquired
11:02:09 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
11:02:09 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 794, 'last_n_outputs': 37, 'leak_rate': 0.858944773045273, 'lr': 0.0077352965867062045, 'optimizer': 'SGD', 'sparsity': 0.7847259292761343, 'steps_to_train': 66, 'weight_decay': 0.014462737645756469}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.1733064147647051, 'info': {'data04': 0.1733064147647051, 'config': "{'batch_size': 32, 'hidden_dim': 794, 'last_n_outputs': 37, 'leak_rate': 0.858944773045273, 'lr': 0.0077352965867062045, 'optimizer': 'SGD', 'sparsity': 0.7847259292761343, 'steps_to_train': 66, 'weight_decay': 0.014462737645756469}"}}
exception: None

11:02:09 job_callback for (8, 0, 21) started
11:02:09 job_callback for (8, 0, 21) got condition
11:02:09 DISPATCHER: Trying to submit another job.
11:02:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:02:09 HBMASTER: Trying to run another job!
11:02:09 job_callback for (8, 0, 21) finished
11:02:09 start sampling a new configuration.
11:02:10 best_vector: [3, 0.20432809772642788, 0.8220074278758808, 0.019178212647001203, 0.24773514426055873, 1, 0.12168792270336856, 0.65930567720216, 0.6812738139052088], 1.5412721253120743e-32, 0.6488146924719875, -0.019657017212089574
11:02:10 done sampling a new configuration.
11:02:10 HBMASTER: schedule new run for iteration 9
11:02:10 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
11:02:10 HBMASTER: submitting job (9, 0, 0) to dispatcher
11:02:10 DISPATCHER: trying to submit job (9, 0, 0)
11:02:10 DISPATCHER: trying to notify the job_runner thread.
11:02:10 HBMASTER: job (9, 0, 0) submitted to dispatcher
11:02:10 DISPATCHER: Trying to submit another job.
11:02:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:02:10 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:02:10 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:02:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:02:10 WORKER: start processing job (9, 0, 0)
11:02:10 WORKER: args: ()
11:02:10 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 363, 'last_n_outputs': 43, 'leak_rate': 0.7547945531617503, 'lr': 0.0031294663674053098, 'optimizer': 'SGD', 'sparsity': 0.7792051014488085, 'steps_to_train': 69, 'weight_decay': 0.07697641255243784}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:02:28 DISPATCHER: Starting worker discovery
11:02:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:02:28 DISPATCHER: Finished worker discovery
11:03:28 DISPATCHER: Starting worker discovery
11:03:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:03:28 DISPATCHER: Finished worker discovery
11:04:28 DISPATCHER: Starting worker discovery
11:04:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:04:28 DISPATCHER: Finished worker discovery
11:04:41 WORKER: done with job (9, 0, 0), trying to register it.
11:04:41 WORKER: registered result for job (9, 0, 0) with dispatcher
11:04:41 DISPATCHER: job (9, 0, 0) finished
11:04:41 DISPATCHER: register_result: lock acquired
11:04:41 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
11:04:41 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 363, 'last_n_outputs': 43, 'leak_rate': 0.7547945531617503, 'lr': 0.0031294663674053098, 'optimizer': 'SGD', 'sparsity': 0.7792051014488085, 'steps_to_train': 69, 'weight_decay': 0.07697641255243784}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.15373993795585666, 'info': {'data04': 0.15373993795585666, 'config': "{'batch_size': 128, 'hidden_dim': 363, 'last_n_outputs': 43, 'leak_rate': 0.7547945531617503, 'lr': 0.0031294663674053098, 'optimizer': 'SGD', 'sparsity': 0.7792051014488085, 'steps_to_train': 69, 'weight_decay': 0.07697641255243784}"}}
exception: None

11:04:41 job_callback for (9, 0, 0) started
11:04:41 job_callback for (9, 0, 0) got condition
11:04:41 DISPATCHER: Trying to submit another job.
11:04:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:04:41 HBMASTER: Trying to run another job!
11:04:41 job_callback for (9, 0, 0) finished
11:04:41 start sampling a new configuration.
11:04:41 best_vector: [1, 0.17844212490768285, 0.7344621722225169, 0.3468836147827874, 0.06548886027526718, 1, 0.9467598376477773, 0.6713409481372701, 0.11209977467902474], 0.0002561034700855676, 0.32545138477328955, 8.334922898459273e-05
11:04:41 done sampling a new configuration.
11:04:41 HBMASTER: schedule new run for iteration 9
11:04:41 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
11:04:41 HBMASTER: submitting job (9, 0, 1) to dispatcher
11:04:41 DISPATCHER: trying to submit job (9, 0, 1)
11:04:41 DISPATCHER: trying to notify the job_runner thread.
11:04:41 HBMASTER: job (9, 0, 1) submitted to dispatcher
11:04:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:04:41 DISPATCHER: Trying to submit another job.
11:04:41 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:04:41 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:04:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:04:41 WORKER: start processing job (9, 0, 1)
11:04:41 WORKER: args: ()
11:04:41 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 342, 'last_n_outputs': 40, 'leak_rate': 0.8367209036956968, 'lr': 0.001352003203207119, 'optimizer': 'SGD', 'sparsity': 0.9772223610354666, 'steps_to_train': 71, 'weight_decay': 0.013990884436314058}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:05:28 DISPATCHER: Starting worker discovery
11:05:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:05:28 DISPATCHER: Finished worker discovery
11:06:28 DISPATCHER: Starting worker discovery
11:06:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:06:28 DISPATCHER: Finished worker discovery
11:07:13 WORKER: done with job (9, 0, 1), trying to register it.
11:07:13 WORKER: registered result for job (9, 0, 1) with dispatcher
11:07:13 DISPATCHER: job (9, 0, 1) finished
11:07:13 DISPATCHER: register_result: lock acquired
11:07:13 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
11:07:13 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 342, 'last_n_outputs': 40, 'leak_rate': 0.8367209036956968, 'lr': 0.001352003203207119, 'optimizer': 'SGD', 'sparsity': 0.9772223610354666, 'steps_to_train': 71, 'weight_decay': 0.013990884436314058}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.15300662090087672, 'info': {'data04': 0.15300662090087672, 'config': "{'batch_size': 32, 'hidden_dim': 342, 'last_n_outputs': 40, 'leak_rate': 0.8367209036956968, 'lr': 0.001352003203207119, 'optimizer': 'SGD', 'sparsity': 0.9772223610354666, 'steps_to_train': 71, 'weight_decay': 0.013990884436314058}"}}
exception: None

11:07:13 job_callback for (9, 0, 1) started
11:07:13 DISPATCHER: Trying to submit another job.
11:07:13 job_callback for (9, 0, 1) got condition
11:07:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:07:13 HBMASTER: Trying to run another job!
11:07:13 job_callback for (9, 0, 1) finished
11:07:13 start sampling a new configuration.
11:07:13 done sampling a new configuration.
11:07:13 HBMASTER: schedule new run for iteration 9
11:07:13 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
11:07:13 HBMASTER: submitting job (9, 0, 2) to dispatcher
11:07:13 DISPATCHER: trying to submit job (9, 0, 2)
11:07:13 DISPATCHER: trying to notify the job_runner thread.
11:07:13 HBMASTER: job (9, 0, 2) submitted to dispatcher
11:07:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:07:13 DISPATCHER: Trying to submit another job.
11:07:13 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:07:13 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:07:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:07:13 WORKER: start processing job (9, 0, 2)
11:07:13 WORKER: args: ()
11:07:13 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 450, 'last_n_outputs': 11, 'leak_rate': 0.7749995179219403, 'lr': 0.02781484549309265, 'optimizer': 'SGD', 'sparsity': 0.8587789352507098, 'steps_to_train': 45, 'weight_decay': 0.11239543116664431}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:07:28 DISPATCHER: Starting worker discovery
11:07:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:07:28 DISPATCHER: Finished worker discovery
11:08:28 DISPATCHER: Starting worker discovery
11:08:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:08:28 DISPATCHER: Finished worker discovery
11:09:28 DISPATCHER: Starting worker discovery
11:09:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:09:28 DISPATCHER: Finished worker discovery
11:09:46 WORKER: done with job (9, 0, 2), trying to register it.
11:09:46 WORKER: registered result for job (9, 0, 2) with dispatcher
11:09:46 DISPATCHER: job (9, 0, 2) finished
11:09:46 DISPATCHER: register_result: lock acquired
11:09:46 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
11:09:46 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 450, 'last_n_outputs': 11, 'leak_rate': 0.7749995179219403, 'lr': 0.02781484549309265, 'optimizer': 'SGD', 'sparsity': 0.8587789352507098, 'steps_to_train': 45, 'weight_decay': 0.11239543116664431}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.13293696744411976, 'info': {'data04': 0.13293696744411976, 'config': "{'batch_size': 128, 'hidden_dim': 450, 'last_n_outputs': 11, 'leak_rate': 0.7749995179219403, 'lr': 0.02781484549309265, 'optimizer': 'SGD', 'sparsity': 0.8587789352507098, 'steps_to_train': 45, 'weight_decay': 0.11239543116664431}"}}
exception: None

11:09:46 job_callback for (9, 0, 2) started
11:09:46 DISPATCHER: Trying to submit another job.
11:09:46 job_callback for (9, 0, 2) got condition
11:09:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:09:46 HBMASTER: Trying to run another job!
11:09:46 job_callback for (9, 0, 2) finished
11:09:46 start sampling a new configuration.
11:09:46 done sampling a new configuration.
11:09:46 HBMASTER: schedule new run for iteration 9
11:09:46 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
11:09:46 HBMASTER: submitting job (9, 0, 3) to dispatcher
11:09:46 DISPATCHER: trying to submit job (9, 0, 3)
11:09:46 DISPATCHER: trying to notify the job_runner thread.
11:09:46 HBMASTER: job (9, 0, 3) submitted to dispatcher
11:09:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:09:46 DISPATCHER: Trying to submit another job.
11:09:46 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:09:46 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:09:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:09:46 WORKER: start processing job (9, 0, 3)
11:09:46 WORKER: args: ()
11:09:46 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 443, 'last_n_outputs': 33, 'leak_rate': 0.9718251782142112, 'lr': 0.006106382158021423, 'optimizer': 'SGD', 'sparsity': 0.7613896330525777, 'steps_to_train': 92, 'weight_decay': 0.1611863011444092}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:10:28 DISPATCHER: Starting worker discovery
11:10:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:10:28 DISPATCHER: Finished worker discovery
11:11:28 DISPATCHER: Starting worker discovery
11:11:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:11:28 DISPATCHER: Finished worker discovery
11:12:17 WORKER: done with job (9, 0, 3), trying to register it.
11:12:17 WORKER: registered result for job (9, 0, 3) with dispatcher
11:12:17 DISPATCHER: job (9, 0, 3) finished
11:12:17 DISPATCHER: register_result: lock acquired
11:12:17 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
11:12:17 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 443, 'last_n_outputs': 33, 'leak_rate': 0.9718251782142112, 'lr': 0.006106382158021423, 'optimizer': 'SGD', 'sparsity': 0.7613896330525777, 'steps_to_train': 92, 'weight_decay': 0.1611863011444092}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1906011304966475, 'info': {'data04': 0.1906011304966475, 'config': "{'batch_size': 64, 'hidden_dim': 443, 'last_n_outputs': 33, 'leak_rate': 0.9718251782142112, 'lr': 0.006106382158021423, 'optimizer': 'SGD', 'sparsity': 0.7613896330525777, 'steps_to_train': 92, 'weight_decay': 0.1611863011444092}"}}
exception: None

11:12:17 job_callback for (9, 0, 3) started
11:12:17 job_callback for (9, 0, 3) got condition
11:12:17 DISPATCHER: Trying to submit another job.
11:12:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:12:17 HBMASTER: Trying to run another job!
11:12:17 job_callback for (9, 0, 3) finished
11:12:17 start sampling a new configuration.
11:12:17 done sampling a new configuration.
11:12:17 HBMASTER: schedule new run for iteration 9
11:12:17 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
11:12:17 HBMASTER: submitting job (9, 0, 4) to dispatcher
11:12:17 DISPATCHER: trying to submit job (9, 0, 4)
11:12:17 DISPATCHER: trying to notify the job_runner thread.
11:12:17 HBMASTER: job (9, 0, 4) submitted to dispatcher
11:12:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:12:17 DISPATCHER: Trying to submit another job.
11:12:17 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:12:17 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:12:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:12:17 WORKER: start processing job (9, 0, 4)
11:12:17 WORKER: args: ()
11:12:17 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 452, 'last_n_outputs': 29, 'leak_rate': 0.8248428980168945, 'lr': 0.03929646418647474, 'optimizer': 'SGD', 'sparsity': 0.8025175778936225, 'steps_to_train': 95, 'weight_decay': 0.12829490720762268}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:12:28 DISPATCHER: Starting worker discovery
11:12:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:12:28 DISPATCHER: Finished worker discovery
11:13:28 DISPATCHER: Starting worker discovery
11:13:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:13:29 DISPATCHER: Finished worker discovery
11:14:29 DISPATCHER: Starting worker discovery
11:14:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:14:29 DISPATCHER: Finished worker discovery
11:14:47 WORKER: done with job (9, 0, 4), trying to register it.
11:14:47 WORKER: registered result for job (9, 0, 4) with dispatcher
11:14:47 DISPATCHER: job (9, 0, 4) finished
11:14:47 DISPATCHER: register_result: lock acquired
11:14:47 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
11:14:47 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 452, 'last_n_outputs': 29, 'leak_rate': 0.8248428980168945, 'lr': 0.03929646418647474, 'optimizer': 'SGD', 'sparsity': 0.8025175778936225, 'steps_to_train': 95, 'weight_decay': 0.12829490720762268}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.102902245855921, 'info': {'data04': 0.102902245855921, 'config': "{'batch_size': 16, 'hidden_dim': 452, 'last_n_outputs': 29, 'leak_rate': 0.8248428980168945, 'lr': 0.03929646418647474, 'optimizer': 'SGD', 'sparsity': 0.8025175778936225, 'steps_to_train': 95, 'weight_decay': 0.12829490720762268}"}}
exception: None

11:14:47 job_callback for (9, 0, 4) started
11:14:47 job_callback for (9, 0, 4) got condition
11:14:47 DISPATCHER: Trying to submit another job.
11:14:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:14:47 HBMASTER: Trying to run another job!
11:14:47 job_callback for (9, 0, 4) finished
11:14:47 start sampling a new configuration.
11:14:47 best_vector: [3, 0.9330933602859854, 0.5459555461633379, 0.7992147322922505, 0.6726345090426635, 1, 0.9117208234201202, 0.6886658059495864, 0.6814212257495678], 2.8262763023612397e-31, 0.03538224479908565, -0.00022307471410841866
11:14:47 done sampling a new configuration.
11:14:47 HBMASTER: schedule new run for iteration 9
11:14:47 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
11:14:47 HBMASTER: submitting job (9, 0, 5) to dispatcher
11:14:47 DISPATCHER: trying to submit job (9, 0, 5)
11:14:47 DISPATCHER: trying to notify the job_runner thread.
11:14:47 HBMASTER: job (9, 0, 5) submitted to dispatcher
11:14:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:14:47 DISPATCHER: Trying to submit another job.
11:14:47 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:14:47 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:14:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:14:47 WORKER: start processing job (9, 0, 5)
11:14:47 WORKER: args: ()
11:14:47 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 947, 'last_n_outputs': 32, 'leak_rate': 0.9498036830730626, 'lr': 0.02214466007098727, 'optimizer': 'SGD', 'sparsity': 0.9688129976208288, 'steps_to_train': 72, 'weight_decay': 0.0770104133373125}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:15:29 DISPATCHER: Starting worker discovery
11:15:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:15:29 DISPATCHER: Finished worker discovery
11:16:29 DISPATCHER: Starting worker discovery
11:16:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:16:29 DISPATCHER: Finished worker discovery
11:17:20 WORKER: done with job (9, 0, 5), trying to register it.
11:17:20 WORKER: registered result for job (9, 0, 5) with dispatcher
11:17:20 DISPATCHER: job (9, 0, 5) finished
11:17:20 DISPATCHER: register_result: lock acquired
11:17:20 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
11:17:20 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 947, 'last_n_outputs': 32, 'leak_rate': 0.9498036830730626, 'lr': 0.02214466007098727, 'optimizer': 'SGD', 'sparsity': 0.9688129976208288, 'steps_to_train': 72, 'weight_decay': 0.0770104133373125}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1652741586801066, 'info': {'data04': 0.1652741586801066, 'config': "{'batch_size': 128, 'hidden_dim': 947, 'last_n_outputs': 32, 'leak_rate': 0.9498036830730626, 'lr': 0.02214466007098727, 'optimizer': 'SGD', 'sparsity': 0.9688129976208288, 'steps_to_train': 72, 'weight_decay': 0.0770104133373125}"}}
exception: None

11:17:20 job_callback for (9, 0, 5) started
11:17:20 DISPATCHER: Trying to submit another job.
11:17:20 job_callback for (9, 0, 5) got condition
11:17:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:17:20 HBMASTER: Trying to run another job!
11:17:20 job_callback for (9, 0, 5) finished
11:17:20 start sampling a new configuration.
11:17:20 best_vector: [3, 0.7572832369461753, 0.6207106969027697, 0.3585563446461777, 0.6677117478896141, 1, 0.8103244948339594, 0.525368590266366, 0.1229146229823731], 4.543713390508584e-31, 0.022008430419245013, -4.7477019441650295e-05
11:17:20 done sampling a new configuration.
11:17:20 HBMASTER: schedule new run for iteration 9
11:17:20 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
11:17:20 HBMASTER: submitting job (9, 0, 6) to dispatcher
11:17:20 DISPATCHER: trying to submit job (9, 0, 6)
11:17:20 DISPATCHER: trying to notify the job_runner thread.
11:17:20 HBMASTER: job (9, 0, 6) submitted to dispatcher
11:17:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:17:20 DISPATCHER: Trying to submit another job.
11:17:20 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:17:20 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:17:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:17:20 WORKER: start processing job (9, 0, 6)
11:17:20 WORKER: args: ()
11:17:20 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 806, 'last_n_outputs': 35, 'leak_rate': 0.8396390861615444, 'lr': 0.02164828494988435, 'optimizer': 'SGD', 'sparsity': 0.9444778787601502, 'steps_to_train': 57, 'weight_decay': 0.01445158931856286}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:17:29 DISPATCHER: Starting worker discovery
11:17:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:17:29 DISPATCHER: Finished worker discovery
11:18:29 DISPATCHER: Starting worker discovery
11:18:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:18:29 DISPATCHER: Finished worker discovery
11:19:29 DISPATCHER: Starting worker discovery
11:19:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:19:29 DISPATCHER: Finished worker discovery
11:19:52 WORKER: done with job (9, 0, 6), trying to register it.
11:19:52 WORKER: registered result for job (9, 0, 6) with dispatcher
11:19:52 DISPATCHER: job (9, 0, 6) finished
11:19:52 DISPATCHER: register_result: lock acquired
11:19:52 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
11:19:52 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 806, 'last_n_outputs': 35, 'leak_rate': 0.8396390861615444, 'lr': 0.02164828494988435, 'optimizer': 'SGD', 'sparsity': 0.9444778787601502, 'steps_to_train': 57, 'weight_decay': 0.01445158931856286}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.17975275288154477, 'info': {'data04': 0.17975275288154477, 'config': "{'batch_size': 128, 'hidden_dim': 806, 'last_n_outputs': 35, 'leak_rate': 0.8396390861615444, 'lr': 0.02164828494988435, 'optimizer': 'SGD', 'sparsity': 0.9444778787601502, 'steps_to_train': 57, 'weight_decay': 0.01445158931856286}"}}
exception: None

11:19:52 job_callback for (9, 0, 6) started
11:19:52 job_callback for (9, 0, 6) got condition
11:19:52 DISPATCHER: Trying to submit another job.
11:19:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:19:52 HBMASTER: Trying to run another job!
11:19:52 job_callback for (9, 0, 6) finished
11:19:52 start sampling a new configuration.
11:19:52 done sampling a new configuration.
11:19:52 HBMASTER: schedule new run for iteration 9
11:19:52 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
11:19:52 HBMASTER: submitting job (9, 0, 7) to dispatcher
11:19:52 DISPATCHER: trying to submit job (9, 0, 7)
11:19:52 DISPATCHER: trying to notify the job_runner thread.
11:19:52 HBMASTER: job (9, 0, 7) submitted to dispatcher
11:19:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:19:52 DISPATCHER: Trying to submit another job.
11:19:52 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:19:52 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:19:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:19:52 WORKER: start processing job (9, 0, 7)
11:19:52 WORKER: args: ()
11:19:52 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 386, 'last_n_outputs': 20, 'leak_rate': 0.8098680074346449, 'lr': 0.0017664371183286481, 'optimizer': 'SGD', 'sparsity': 0.8862648551414796, 'steps_to_train': 14, 'weight_decay': 0.14911295215219797}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:20:29 DISPATCHER: Starting worker discovery
11:20:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:20:29 DISPATCHER: Finished worker discovery
11:21:29 DISPATCHER: Starting worker discovery
11:21:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:21:29 DISPATCHER: Finished worker discovery
11:22:29 DISPATCHER: Starting worker discovery
11:22:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:22:29 DISPATCHER: Finished worker discovery
11:22:32 WORKER: done with job (9, 0, 7), trying to register it.
11:22:32 WORKER: registered result for job (9, 0, 7) with dispatcher
11:22:32 DISPATCHER: job (9, 0, 7) finished
11:22:32 DISPATCHER: register_result: lock acquired
11:22:32 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
11:22:32 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 386, 'last_n_outputs': 20, 'leak_rate': 0.8098680074346449, 'lr': 0.0017664371183286481, 'optimizer': 'SGD', 'sparsity': 0.8862648551414796, 'steps_to_train': 14, 'weight_decay': 0.14911295215219797}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1282087825278581, 'info': {'data04': 0.1282087825278581, 'config': "{'batch_size': 32, 'hidden_dim': 386, 'last_n_outputs': 20, 'leak_rate': 0.8098680074346449, 'lr': 0.0017664371183286481, 'optimizer': 'SGD', 'sparsity': 0.8862648551414796, 'steps_to_train': 14, 'weight_decay': 0.14911295215219797}"}}
exception: None

11:22:32 job_callback for (9, 0, 7) started
11:22:32 job_callback for (9, 0, 7) got condition
11:22:32 DISPATCHER: Trying to submit another job.
11:22:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:22:32 HBMASTER: Trying to run another job!
11:22:32 job_callback for (9, 0, 7) finished
11:22:32 start sampling a new configuration.
11:22:32 best_vector: [3, 0.7470102709415918, 0.808001924401229, 0.11678689667419012, 0.8881481918040195, 1, 0.8102568731548261, 0.7902609561522292, 0.4807157212410894], 3.752304461323487e-29, 0.00026650289450320534, -0.00020345817850298188
11:22:32 done sampling a new configuration.
11:22:32 HBMASTER: schedule new run for iteration 9
11:22:32 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
11:22:32 HBMASTER: submitting job (9, 0, 8) to dispatcher
11:22:32 DISPATCHER: trying to submit job (9, 0, 8)
11:22:32 DISPATCHER: trying to notify the job_runner thread.
11:22:32 HBMASTER: job (9, 0, 8) submitted to dispatcher
11:22:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:22:32 DISPATCHER: Trying to submit another job.
11:22:32 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:22:32 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:22:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:22:32 WORKER: start processing job (9, 0, 8)
11:22:32 WORKER: args: ()
11:22:32 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 798, 'last_n_outputs': 43, 'leak_rate': 0.7791967241685476, 'lr': 0.059744287146830985, 'optimizer': 'SGD', 'sparsity': 0.9444616495571583, 'steps_to_train': 81, 'weight_decay': 0.04221099337027819}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:23:29 DISPATCHER: Starting worker discovery
11:23:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:23:29 DISPATCHER: Finished worker discovery
11:24:29 DISPATCHER: Starting worker discovery
11:24:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:24:29 DISPATCHER: Finished worker discovery
11:25:03 WORKER: done with job (9, 0, 8), trying to register it.
11:25:03 WORKER: registered result for job (9, 0, 8) with dispatcher
11:25:03 DISPATCHER: job (9, 0, 8) finished
11:25:03 DISPATCHER: register_result: lock acquired
11:25:03 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
11:25:03 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 798, 'last_n_outputs': 43, 'leak_rate': 0.7791967241685476, 'lr': 0.059744287146830985, 'optimizer': 'SGD', 'sparsity': 0.9444616495571583, 'steps_to_train': 81, 'weight_decay': 0.04221099337027819}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.15309156113768968, 'info': {'data04': 0.15309156113768968, 'config': "{'batch_size': 128, 'hidden_dim': 798, 'last_n_outputs': 43, 'leak_rate': 0.7791967241685476, 'lr': 0.059744287146830985, 'optimizer': 'SGD', 'sparsity': 0.9444616495571583, 'steps_to_train': 81, 'weight_decay': 0.04221099337027819}"}}
exception: None

11:25:03 DISPATCHER: Trying to submit another job.
11:25:03 job_callback for (9, 0, 8) started
11:25:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:25:03 job_callback for (9, 0, 8) got condition
11:25:03 HBMASTER: Trying to run another job!
11:25:03 job_callback for (9, 0, 8) finished
11:25:03 ITERATION: Advancing config (9, 0, 3) to next budget 400.000000
11:25:03 ITERATION: Advancing config (9, 0, 5) to next budget 400.000000
11:25:03 ITERATION: Advancing config (9, 0, 6) to next budget 400.000000
11:25:03 HBMASTER: schedule new run for iteration 9
11:25:03 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
11:25:03 HBMASTER: submitting job (9, 0, 3) to dispatcher
11:25:03 DISPATCHER: trying to submit job (9, 0, 3)
11:25:03 DISPATCHER: trying to notify the job_runner thread.
11:25:03 HBMASTER: job (9, 0, 3) submitted to dispatcher
11:25:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:25:03 DISPATCHER: Trying to submit another job.
11:25:03 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:25:03 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:25:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:25:03 WORKER: start processing job (9, 0, 3)
11:25:03 WORKER: args: ()
11:25:03 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 443, 'last_n_outputs': 33, 'leak_rate': 0.9718251782142112, 'lr': 0.006106382158021423, 'optimizer': 'SGD', 'sparsity': 0.7613896330525777, 'steps_to_train': 92, 'weight_decay': 0.1611863011444092}, 'budget': 400.0, 'working_directory': '.'}
11:25:29 DISPATCHER: Starting worker discovery
11:25:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:25:29 DISPATCHER: Finished worker discovery
11:26:29 DISPATCHER: Starting worker discovery
11:26:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:26:29 DISPATCHER: Finished worker discovery
11:27:29 DISPATCHER: Starting worker discovery
11:27:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:27:29 DISPATCHER: Finished worker discovery
11:28:29 DISPATCHER: Starting worker discovery
11:28:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:28:29 DISPATCHER: Finished worker discovery
11:29:29 DISPATCHER: Starting worker discovery
11:29:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:29:29 DISPATCHER: Finished worker discovery
11:30:29 DISPATCHER: Starting worker discovery
11:30:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:30:29 DISPATCHER: Finished worker discovery
11:31:29 DISPATCHER: Starting worker discovery
11:31:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:31:29 DISPATCHER: Finished worker discovery
11:32:06 WORKER: done with job (9, 0, 3), trying to register it.
11:32:06 WORKER: registered result for job (9, 0, 3) with dispatcher
11:32:06 DISPATCHER: job (9, 0, 3) finished
11:32:06 DISPATCHER: register_result: lock acquired
11:32:06 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
11:32:06 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 443, 'last_n_outputs': 33, 'leak_rate': 0.9718251782142112, 'lr': 0.006106382158021423, 'optimizer': 'SGD', 'sparsity': 0.7613896330525777, 'steps_to_train': 92, 'weight_decay': 0.1611863011444092}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.16879018651742908, 'info': {'data04': 0.16879018651742908, 'config': "{'batch_size': 64, 'hidden_dim': 443, 'last_n_outputs': 33, 'leak_rate': 0.9718251782142112, 'lr': 0.006106382158021423, 'optimizer': 'SGD', 'sparsity': 0.7613896330525777, 'steps_to_train': 92, 'weight_decay': 0.1611863011444092}"}}
exception: None

11:32:06 job_callback for (9, 0, 3) started
11:32:06 job_callback for (9, 0, 3) got condition
11:32:06 DISPATCHER: Trying to submit another job.
11:32:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:32:07 done building a new model for budget 400.000000 based on 10/23 split
Best loss for this budget:-0.185359





11:32:07 HBMASTER: Trying to run another job!
11:32:07 job_callback for (9, 0, 3) finished
11:32:07 HBMASTER: schedule new run for iteration 9
11:32:07 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
11:32:07 HBMASTER: submitting job (9, 0, 5) to dispatcher
11:32:07 DISPATCHER: trying to submit job (9, 0, 5)
11:32:07 DISPATCHER: trying to notify the job_runner thread.
11:32:07 HBMASTER: job (9, 0, 5) submitted to dispatcher
11:32:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:32:07 DISPATCHER: Trying to submit another job.
11:32:07 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:32:07 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:32:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:32:07 WORKER: start processing job (9, 0, 5)
11:32:07 WORKER: args: ()
11:32:07 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 947, 'last_n_outputs': 32, 'leak_rate': 0.9498036830730626, 'lr': 0.02214466007098727, 'optimizer': 'SGD', 'sparsity': 0.9688129976208288, 'steps_to_train': 72, 'weight_decay': 0.0770104133373125}, 'budget': 400.0, 'working_directory': '.'}
11:32:29 DISPATCHER: Starting worker discovery
11:32:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:32:29 DISPATCHER: Finished worker discovery
11:33:29 DISPATCHER: Starting worker discovery
11:33:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:33:29 DISPATCHER: Finished worker discovery
11:34:29 DISPATCHER: Starting worker discovery
11:34:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:34:29 DISPATCHER: Finished worker discovery
11:35:29 DISPATCHER: Starting worker discovery
11:35:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:35:29 DISPATCHER: Finished worker discovery
11:36:29 DISPATCHER: Starting worker discovery
11:36:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:36:29 DISPATCHER: Finished worker discovery
11:37:29 DISPATCHER: Starting worker discovery
11:37:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:37:29 DISPATCHER: Finished worker discovery
11:38:29 DISPATCHER: Starting worker discovery
11:38:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:38:29 DISPATCHER: Finished worker discovery
11:39:11 WORKER: done with job (9, 0, 5), trying to register it.
11:39:11 WORKER: registered result for job (9, 0, 5) with dispatcher
11:39:11 DISPATCHER: job (9, 0, 5) finished
11:39:11 DISPATCHER: register_result: lock acquired
11:39:11 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
11:39:11 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 947, 'last_n_outputs': 32, 'leak_rate': 0.9498036830730626, 'lr': 0.02214466007098727, 'optimizer': 'SGD', 'sparsity': 0.9688129976208288, 'steps_to_train': 72, 'weight_decay': 0.0770104133373125}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.15979004709698624, 'info': {'data04': 0.15979004709698624, 'config': "{'batch_size': 128, 'hidden_dim': 947, 'last_n_outputs': 32, 'leak_rate': 0.9498036830730626, 'lr': 0.02214466007098727, 'optimizer': 'SGD', 'sparsity': 0.9688129976208288, 'steps_to_train': 72, 'weight_decay': 0.0770104133373125}"}}
exception: None

11:39:11 job_callback for (9, 0, 5) started
11:39:11 DISPATCHER: Trying to submit another job.
11:39:11 job_callback for (9, 0, 5) got condition
11:39:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:39:11 done building a new model for budget 400.000000 based on 10/24 split
Best loss for this budget:-0.185359





11:39:11 HBMASTER: Trying to run another job!
11:39:11 job_callback for (9, 0, 5) finished
11:39:11 HBMASTER: schedule new run for iteration 9
11:39:11 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
11:39:11 HBMASTER: submitting job (9, 0, 6) to dispatcher
11:39:11 DISPATCHER: trying to submit job (9, 0, 6)
11:39:11 DISPATCHER: trying to notify the job_runner thread.
11:39:11 HBMASTER: job (9, 0, 6) submitted to dispatcher
11:39:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:39:11 DISPATCHER: Trying to submit another job.
11:39:11 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:39:11 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:39:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:39:11 WORKER: start processing job (9, 0, 6)
11:39:11 WORKER: args: ()
11:39:11 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 806, 'last_n_outputs': 35, 'leak_rate': 0.8396390861615444, 'lr': 0.02164828494988435, 'optimizer': 'SGD', 'sparsity': 0.9444778787601502, 'steps_to_train': 57, 'weight_decay': 0.01445158931856286}, 'budget': 400.0, 'working_directory': '.'}
11:39:29 DISPATCHER: Starting worker discovery
11:39:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:39:29 DISPATCHER: Finished worker discovery
11:40:29 DISPATCHER: Starting worker discovery
11:40:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:40:29 DISPATCHER: Finished worker discovery
11:41:29 DISPATCHER: Starting worker discovery
11:41:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:41:29 DISPATCHER: Finished worker discovery
11:42:29 DISPATCHER: Starting worker discovery
11:42:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:42:29 DISPATCHER: Finished worker discovery
11:43:29 DISPATCHER: Starting worker discovery
11:43:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:43:29 DISPATCHER: Finished worker discovery
11:44:29 DISPATCHER: Starting worker discovery
11:44:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:44:29 DISPATCHER: Finished worker discovery
11:45:29 DISPATCHER: Starting worker discovery
11:45:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:45:29 DISPATCHER: Finished worker discovery
11:46:16 WORKER: done with job (9, 0, 6), trying to register it.
11:46:16 WORKER: registered result for job (9, 0, 6) with dispatcher
11:46:16 DISPATCHER: job (9, 0, 6) finished
11:46:16 DISPATCHER: register_result: lock acquired
11:46:16 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
11:46:16 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 806, 'last_n_outputs': 35, 'leak_rate': 0.8396390861615444, 'lr': 0.02164828494988435, 'optimizer': 'SGD', 'sparsity': 0.9444778787601502, 'steps_to_train': 57, 'weight_decay': 0.01445158931856286}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.17851083692415243, 'info': {'data04': 0.17851083692415243, 'config': "{'batch_size': 128, 'hidden_dim': 806, 'last_n_outputs': 35, 'leak_rate': 0.8396390861615444, 'lr': 0.02164828494988435, 'optimizer': 'SGD', 'sparsity': 0.9444778787601502, 'steps_to_train': 57, 'weight_decay': 0.01445158931856286}"}}
exception: None

11:46:16 job_callback for (9, 0, 6) started
11:46:16 DISPATCHER: Trying to submit another job.
11:46:16 job_callback for (9, 0, 6) got condition
11:46:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:46:16 done building a new model for budget 400.000000 based on 10/25 split
Best loss for this budget:-0.185359





11:46:16 HBMASTER: Trying to run another job!
11:46:16 job_callback for (9, 0, 6) finished
11:46:16 ITERATION: Advancing config (9, 0, 6) to next budget 1200.000000
11:46:16 HBMASTER: schedule new run for iteration 9
11:46:16 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
11:46:16 HBMASTER: submitting job (9, 0, 6) to dispatcher
11:46:16 DISPATCHER: trying to submit job (9, 0, 6)
11:46:16 DISPATCHER: trying to notify the job_runner thread.
11:46:16 HBMASTER: job (9, 0, 6) submitted to dispatcher
11:46:16 DISPATCHER: Trying to submit another job.
11:46:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:46:16 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:46:16 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:46:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:46:16 WORKER: start processing job (9, 0, 6)
11:46:16 WORKER: args: ()
11:46:16 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 806, 'last_n_outputs': 35, 'leak_rate': 0.8396390861615444, 'lr': 0.02164828494988435, 'optimizer': 'SGD', 'sparsity': 0.9444778787601502, 'steps_to_train': 57, 'weight_decay': 0.01445158931856286}, 'budget': 1200.0, 'working_directory': '.'}
11:46:29 DISPATCHER: Starting worker discovery
11:46:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:46:29 DISPATCHER: Finished worker discovery
11:47:29 DISPATCHER: Starting worker discovery
11:47:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:47:29 DISPATCHER: Finished worker discovery
11:48:29 DISPATCHER: Starting worker discovery
11:48:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:48:29 DISPATCHER: Finished worker discovery
11:49:29 DISPATCHER: Starting worker discovery
11:49:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:49:29 DISPATCHER: Finished worker discovery
11:50:29 DISPATCHER: Starting worker discovery
11:50:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:50:29 DISPATCHER: Finished worker discovery
11:51:29 DISPATCHER: Starting worker discovery
11:51:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:51:29 DISPATCHER: Finished worker discovery
11:52:29 DISPATCHER: Starting worker discovery
11:52:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:52:29 DISPATCHER: Finished worker discovery
11:53:29 DISPATCHER: Starting worker discovery
11:53:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:53:29 DISPATCHER: Finished worker discovery
11:54:29 DISPATCHER: Starting worker discovery
11:54:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:54:29 DISPATCHER: Finished worker discovery
11:55:29 DISPATCHER: Starting worker discovery
11:55:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:55:29 DISPATCHER: Finished worker discovery
11:56:29 DISPATCHER: Starting worker discovery
11:56:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:56:29 DISPATCHER: Finished worker discovery
11:57:29 DISPATCHER: Starting worker discovery
11:57:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:57:29 DISPATCHER: Finished worker discovery
11:58:29 DISPATCHER: Starting worker discovery
11:58:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:58:29 DISPATCHER: Finished worker discovery
11:59:29 DISPATCHER: Starting worker discovery
11:59:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:59:29 DISPATCHER: Finished worker discovery
12:00:29 DISPATCHER: Starting worker discovery
12:00:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:00:29 DISPATCHER: Finished worker discovery
12:01:29 DISPATCHER: Starting worker discovery
12:01:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:01:29 DISPATCHER: Finished worker discovery
12:02:29 DISPATCHER: Starting worker discovery
12:02:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:02:29 DISPATCHER: Finished worker discovery
12:03:29 DISPATCHER: Starting worker discovery
12:03:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:03:29 DISPATCHER: Finished worker discovery
12:04:29 DISPATCHER: Starting worker discovery
12:04:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:04:29 DISPATCHER: Finished worker discovery
12:05:29 DISPATCHER: Starting worker discovery
12:05:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:05:29 DISPATCHER: Finished worker discovery
12:06:29 DISPATCHER: Starting worker discovery
12:06:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:06:29 DISPATCHER: Finished worker discovery
12:06:56 WORKER: done with job (9, 0, 6), trying to register it.
12:06:56 WORKER: registered result for job (9, 0, 6) with dispatcher
12:06:56 DISPATCHER: job (9, 0, 6) finished
12:06:56 DISPATCHER: register_result: lock acquired
12:06:56 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:06:56 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 806, 'last_n_outputs': 35, 'leak_rate': 0.8396390861615444, 'lr': 0.02164828494988435, 'optimizer': 'SGD', 'sparsity': 0.9444778787601502, 'steps_to_train': 57, 'weight_decay': 0.01445158931856286}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.1817928304567869, 'info': {'data04': 0.1817928304567869, 'config': "{'batch_size': 128, 'hidden_dim': 806, 'last_n_outputs': 35, 'leak_rate': 0.8396390861615444, 'lr': 0.02164828494988435, 'optimizer': 'SGD', 'sparsity': 0.9444778787601502, 'steps_to_train': 57, 'weight_decay': 0.01445158931856286}"}}
exception: None

12:06:56 job_callback for (9, 0, 6) started
12:06:56 job_callback for (9, 0, 6) got condition
12:06:56 DISPATCHER: Trying to submit another job.
12:06:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:06:56 HBMASTER: Trying to run another job!
12:06:56 job_callback for (9, 0, 6) finished
12:06:56 HBMASTER: shutdown initiated, shutdown_workers = True
12:06:56 WORKER: shutting down now!
12:06:57 DISPATCHER: Dispatcher shutting down
12:06:57 DISPATCHER: Trying to submit another job.
12:06:57 DISPATCHER: job_runner shutting down
12:06:57 DISPATCHER: discover_workers shutting down
12:06:57 DISPATCHER: 'discover_worker' thread exited
12:06:57 DISPATCHER: 'job_runner' thread exited
12:06:57 DISPATCHER: shut down complete
12:06:57 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7fb914038240; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:34201>
12:06:57 WORKER: No dispatcher found. Waiting for one to initiate contact.
12:06:57 WORKER: start listening for jobs
12:06:57 wait_for_workers trying to get the condition
12:06:57 DISPATCHER: started the 'discover_worker' thread
12:06:57 DISPATCHER: started the 'job_runner' thread
12:06:57 DISPATCHER: Pyro daemon running on localhost:34711
12:06:57 DISPATCHER: Starting worker discovery
12:06:57 DISPATCHER: Found 1 potential workers, 0 currently in the pool.
12:06:57 DISPATCHER: discovered new worker, hpbandster.run_0.worker.metagpuj.13102140436472194880
12:06:57 HBMASTER: number of workers changed to 1
12:06:57 Enough workers to start this run!
12:06:57 adjust_queue_size: lock accquired
12:06:57 HBMASTER: starting run at 1583838417.279733
12:06:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:06:57 HBMASTER: adjusted queue size to (0, 1)
12:06:57 DISPATCHER: Finished worker discovery
12:06:57 DISPATCHER: Trying to submit another job.
12:06:57 start sampling a new configuration.
12:06:57 done sampling a new configuration.
12:06:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:06:57 HBMASTER: schedule new run for iteration 0
12:06:57 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
12:06:57 HBMASTER: submitting job (0, 0, 0) to dispatcher
12:06:57 DISPATCHER: trying to submit job (0, 0, 0)
12:06:57 DISPATCHER: trying to notify the job_runner thread.
12:06:57 HBMASTER: job (0, 0, 0) submitted to dispatcher
12:06:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:06:57 DISPATCHER: Trying to submit another job.
12:06:57 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:06:57 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:06:57 WORKER: start processing job (0, 0, 0)
12:06:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:06:57 WORKER: args: ()
12:06:57 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.008949551207947685, 'num_filters_1': 24, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.013512508778365557, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 48, 'num_filters_3': 92}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:07:57 DISPATCHER: Starting worker discovery
12:07:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:07:57 DISPATCHER: Finished worker discovery
12:07:59 WORKER: done with job (0, 0, 0), trying to register it.
12:07:59 WORKER: registered result for job (0, 0, 0) with dispatcher
12:07:59 DISPATCHER: job (0, 0, 0) finished
12:07:59 DISPATCHER: register_result: lock acquired
12:07:59 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:07:59 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.008949551207947685, 'num_filters_1': 24, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.013512508778365557, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 48, 'num_filters_3': 92}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -6.0753254916711186e-05, 'info': {'data04': 6.0753254916711186e-05, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.008949551207947685, 'num_filters_1': 24, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.013512508778365557, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 48, 'num_filters_3': 92}"}}
exception: None

12:07:59 job_callback for (0, 0, 0) started
12:07:59 job_callback for (0, 0, 0) got condition
12:07:59 DISPATCHER: Trying to submit another job.
12:07:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:07:59 Only 1 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
12:07:59 HBMASTER: Trying to run another job!
12:07:59 job_callback for (0, 0, 0) finished
12:07:59 start sampling a new configuration.
12:07:59 done sampling a new configuration.
12:07:59 HBMASTER: schedule new run for iteration 0
12:07:59 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
12:07:59 HBMASTER: submitting job (0, 0, 1) to dispatcher
12:07:59 DISPATCHER: trying to submit job (0, 0, 1)
12:07:59 DISPATCHER: trying to notify the job_runner thread.
12:07:59 HBMASTER: job (0, 0, 1) submitted to dispatcher
12:07:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:07:59 DISPATCHER: Trying to submit another job.
12:07:59 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:07:59 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:07:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:07:59 WORKER: start processing job (0, 0, 1)
12:07:59 WORKER: args: ()
12:07:59 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.07349964649878199, 'num_filters_1': 43, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.014668290951981524, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 35, 'num_filters_3': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:08:57 DISPATCHER: Starting worker discovery
12:08:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:08:57 DISPATCHER: Finished worker discovery
12:09:01 WORKER: done with job (0, 0, 1), trying to register it.
12:09:01 WORKER: registered result for job (0, 0, 1) with dispatcher
12:09:01 DISPATCHER: job (0, 0, 1) finished
12:09:01 DISPATCHER: register_result: lock acquired
12:09:01 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:09:01 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.07349964649878199, 'num_filters_1': 43, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.014668290951981524, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 35, 'num_filters_3': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.002409823187779045, 'info': {'data04': 0.002409823187779045, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.07349964649878199, 'num_filters_1': 43, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.014668290951981524, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 35, 'num_filters_3': 23}"}}
exception: None

12:09:01 job_callback for (0, 0, 1) started
12:09:01 job_callback for (0, 0, 1) got condition
12:09:01 DISPATCHER: Trying to submit another job.
12:09:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:09:01 Only 2 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
12:09:01 HBMASTER: Trying to run another job!
12:09:01 job_callback for (0, 0, 1) finished
12:09:01 start sampling a new configuration.
12:09:01 done sampling a new configuration.
12:09:01 HBMASTER: schedule new run for iteration 0
12:09:01 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
12:09:01 HBMASTER: submitting job (0, 0, 2) to dispatcher
12:09:01 DISPATCHER: trying to submit job (0, 0, 2)
12:09:01 DISPATCHER: trying to notify the job_runner thread.
12:09:01 HBMASTER: job (0, 0, 2) submitted to dispatcher
12:09:01 DISPATCHER: Trying to submit another job.
12:09:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:09:01 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:09:01 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:09:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:09:01 WORKER: start processing job (0, 0, 2)
12:09:01 WORKER: args: ()
12:09:01 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0018427867735740864, 'num_filters_1': 58, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.018124338555921205, 'kernel_size_2': 5, 'num_filters_2': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:09:57 DISPATCHER: Starting worker discovery
12:09:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:09:57 DISPATCHER: Finished worker discovery
12:10:07 WORKER: done with job (0, 0, 2), trying to register it.
12:10:07 WORKER: registered result for job (0, 0, 2) with dispatcher
12:10:07 DISPATCHER: job (0, 0, 2) finished
12:10:07 DISPATCHER: register_result: lock acquired
12:10:07 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:10:07 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0018427867735740864, 'num_filters_1': 58, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.018124338555921205, 'kernel_size_2': 5, 'num_filters_2': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1402606474041948, 'info': {'data04': 0.1402606474041948, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0018427867735740864, 'num_filters_1': 58, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.018124338555921205, 'kernel_size_2': 5, 'num_filters_2': 19}"}}
exception: None

12:10:07 job_callback for (0, 0, 2) started
12:10:07 DISPATCHER: Trying to submit another job.
12:10:07 job_callback for (0, 0, 2) got condition
12:10:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:10:07 Only 3 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
12:10:07 HBMASTER: Trying to run another job!
12:10:07 job_callback for (0, 0, 2) finished
12:10:07 start sampling a new configuration.
12:10:07 done sampling a new configuration.
12:10:07 HBMASTER: schedule new run for iteration 0
12:10:07 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
12:10:07 HBMASTER: submitting job (0, 0, 3) to dispatcher
12:10:07 DISPATCHER: trying to submit job (0, 0, 3)
12:10:07 DISPATCHER: trying to notify the job_runner thread.
12:10:07 HBMASTER: job (0, 0, 3) submitted to dispatcher
12:10:07 DISPATCHER: Trying to submit another job.
12:10:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:10:07 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:10:07 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:10:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:10:07 WORKER: start processing job (0, 0, 3)
12:10:07 WORKER: args: ()
12:10:07 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0034807991576196523, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.016224155586070457, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 30, 'num_filters_3': 18, 'num_filters_4': 41, 'num_filters_5': 33}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:10:57 DISPATCHER: Starting worker discovery
12:10:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:10:57 DISPATCHER: Finished worker discovery
12:11:10 WORKER: done with job (0, 0, 3), trying to register it.
12:11:10 WORKER: registered result for job (0, 0, 3) with dispatcher
12:11:10 DISPATCHER: job (0, 0, 3) finished
12:11:10 DISPATCHER: register_result: lock acquired
12:11:10 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:11:10 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0034807991576196523, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.016224155586070457, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 30, 'num_filters_3': 18, 'num_filters_4': 41, 'num_filters_5': 33}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.029850590399303333, 'info': {'data04': 0.029850590399303333, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0034807991576196523, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.016224155586070457, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 30, 'num_filters_3': 18, 'num_filters_4': 41, 'num_filters_5': 33}"}}
exception: None

12:11:10 job_callback for (0, 0, 3) started
12:11:10 DISPATCHER: Trying to submit another job.
12:11:10 job_callback for (0, 0, 3) got condition
12:11:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:11:10 Only 4 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
12:11:10 HBMASTER: Trying to run another job!
12:11:10 job_callback for (0, 0, 3) finished
12:11:10 start sampling a new configuration.
12:11:10 done sampling a new configuration.
12:11:10 HBMASTER: schedule new run for iteration 0
12:11:10 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
12:11:10 HBMASTER: submitting job (0, 0, 4) to dispatcher
12:11:10 DISPATCHER: trying to submit job (0, 0, 4)
12:11:10 DISPATCHER: trying to notify the job_runner thread.
12:11:10 HBMASTER: job (0, 0, 4) submitted to dispatcher
12:11:10 DISPATCHER: Trying to submit another job.
12:11:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:11:10 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:11:10 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:11:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:11:10 WORKER: start processing job (0, 0, 4)
12:11:10 WORKER: args: ()
12:11:10 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0144508170791823, 'num_filters_1': 49, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.10200953272695695, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 33, 'num_filters_3': 63}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:11:57 DISPATCHER: Starting worker discovery
12:11:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:11:57 DISPATCHER: Finished worker discovery
12:12:11 WORKER: done with job (0, 0, 4), trying to register it.
12:12:11 WORKER: registered result for job (0, 0, 4) with dispatcher
12:12:11 DISPATCHER: job (0, 0, 4) finished
12:12:11 DISPATCHER: register_result: lock acquired
12:12:11 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:12:11 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0144508170791823, 'num_filters_1': 49, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.10200953272695695, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 33, 'num_filters_3': 63}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 6.820188010714083e-06, 'info': {'data04': -6.820188010714083e-06, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0144508170791823, 'num_filters_1': 49, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.10200953272695695, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 33, 'num_filters_3': 63}"}}
exception: None

12:12:11 job_callback for (0, 0, 4) started
12:12:11 DISPATCHER: Trying to submit another job.
12:12:11 job_callback for (0, 0, 4) got condition
12:12:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:12:11 Only 5 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
12:12:11 HBMASTER: Trying to run another job!
12:12:11 job_callback for (0, 0, 4) finished
12:12:11 start sampling a new configuration.
12:12:11 done sampling a new configuration.
12:12:11 HBMASTER: schedule new run for iteration 0
12:12:11 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
12:12:11 HBMASTER: submitting job (0, 0, 5) to dispatcher
12:12:11 DISPATCHER: trying to submit job (0, 0, 5)
12:12:11 DISPATCHER: trying to notify the job_runner thread.
12:12:11 HBMASTER: job (0, 0, 5) submitted to dispatcher
12:12:11 DISPATCHER: Trying to submit another job.
12:12:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:12:11 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:12:11 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:12:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:12:11 WORKER: start processing job (0, 0, 5)
12:12:11 WORKER: args: ()
12:12:11 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.006985950594569088, 'num_filters_1': 41, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.15302839557303566, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 37, 'num_filters_3': 116, 'num_filters_4': 34, 'num_filters_5': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:12:57 DISPATCHER: Starting worker discovery
12:12:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:12:57 DISPATCHER: Finished worker discovery
12:13:13 WORKER: done with job (0, 0, 5), trying to register it.
12:13:13 WORKER: registered result for job (0, 0, 5) with dispatcher
12:13:13 DISPATCHER: job (0, 0, 5) finished
12:13:13 DISPATCHER: register_result: lock acquired
12:13:13 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:13:13 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.006985950594569088, 'num_filters_1': 41, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.15302839557303566, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 37, 'num_filters_3': 116, 'num_filters_4': 34, 'num_filters_5': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0008374173769899226, 'info': {'data04': 0.0008374173769899226, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.006985950594569088, 'num_filters_1': 41, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.15302839557303566, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 37, 'num_filters_3': 116, 'num_filters_4': 34, 'num_filters_5': 43}"}}
exception: None

12:13:13 job_callback for (0, 0, 5) started
12:13:13 DISPATCHER: Trying to submit another job.
12:13:13 job_callback for (0, 0, 5) got condition
12:13:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:13:13 Only 6 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
12:13:13 HBMASTER: Trying to run another job!
12:13:13 job_callback for (0, 0, 5) finished
12:13:13 start sampling a new configuration.
12:13:13 done sampling a new configuration.
12:13:13 HBMASTER: schedule new run for iteration 0
12:13:13 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
12:13:13 HBMASTER: submitting job (0, 0, 6) to dispatcher
12:13:13 DISPATCHER: trying to submit job (0, 0, 6)
12:13:13 DISPATCHER: trying to notify the job_runner thread.
12:13:13 HBMASTER: job (0, 0, 6) submitted to dispatcher
12:13:13 DISPATCHER: Trying to submit another job.
12:13:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:13:13 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:13:13 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:13:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:13:13 WORKER: start processing job (0, 0, 6)
12:13:13 WORKER: args: ()
12:13:13 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0018446601469640836, 'num_filters_1': 64, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.015996657233553802, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 105, 'num_filters_3': 50}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:13:57 DISPATCHER: Starting worker discovery
12:13:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:13:57 DISPATCHER: Finished worker discovery
12:14:15 WORKER: done with job (0, 0, 6), trying to register it.
12:14:15 WORKER: registered result for job (0, 0, 6) with dispatcher
12:14:15 DISPATCHER: job (0, 0, 6) finished
12:14:15 DISPATCHER: register_result: lock acquired
12:14:15 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:14:15 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0018446601469640836, 'num_filters_1': 64, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.015996657233553802, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 105, 'num_filters_3': 50}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.07928469970124835, 'info': {'data04': 0.07928469970124835, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0018446601469640836, 'num_filters_1': 64, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.015996657233553802, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 105, 'num_filters_3': 50}"}}
exception: None

12:14:15 job_callback for (0, 0, 6) started
12:14:15 DISPATCHER: Trying to submit another job.
12:14:15 job_callback for (0, 0, 6) got condition
12:14:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:14:15 Only 7 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
12:14:15 HBMASTER: Trying to run another job!
12:14:15 job_callback for (0, 0, 6) finished
12:14:15 start sampling a new configuration.
12:14:15 done sampling a new configuration.
12:14:15 HBMASTER: schedule new run for iteration 0
12:14:15 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
12:14:15 HBMASTER: submitting job (0, 0, 7) to dispatcher
12:14:15 DISPATCHER: trying to submit job (0, 0, 7)
12:14:15 DISPATCHER: trying to notify the job_runner thread.
12:14:15 HBMASTER: job (0, 0, 7) submitted to dispatcher
12:14:15 DISPATCHER: Trying to submit another job.
12:14:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:14:15 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:14:15 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:14:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:14:15 WORKER: start processing job (0, 0, 7)
12:14:15 WORKER: args: ()
12:14:15 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.058523616055037746, 'num_filters_1': 120, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.06095002605389649, 'kernel_size_2': 5, 'num_filters_2': 38}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:14:57 DISPATCHER: Starting worker discovery
12:14:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:14:57 DISPATCHER: Finished worker discovery
12:15:16 WORKER: done with job (0, 0, 7), trying to register it.
12:15:16 WORKER: registered result for job (0, 0, 7) with dispatcher
12:15:16 DISPATCHER: job (0, 0, 7) finished
12:15:16 DISPATCHER: register_result: lock acquired
12:15:16 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:15:16 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.058523616055037746, 'num_filters_1': 120, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.06095002605389649, 'kernel_size_2': 5, 'num_filters_2': 38}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.02168502773211514, 'info': {'data04': 0.02168502773211514, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.058523616055037746, 'num_filters_1': 120, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.06095002605389649, 'kernel_size_2': 5, 'num_filters_2': 38}"}}
exception: None

12:15:16 job_callback for (0, 0, 7) started
12:15:16 DISPATCHER: Trying to submit another job.
12:15:16 job_callback for (0, 0, 7) got condition
12:15:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:15:16 Only 8 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
12:15:16 HBMASTER: Trying to run another job!
12:15:16 job_callback for (0, 0, 7) finished
12:15:16 start sampling a new configuration.
12:15:16 done sampling a new configuration.
12:15:16 HBMASTER: schedule new run for iteration 0
12:15:16 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
12:15:16 HBMASTER: submitting job (0, 0, 8) to dispatcher
12:15:16 DISPATCHER: trying to submit job (0, 0, 8)
12:15:16 DISPATCHER: trying to notify the job_runner thread.
12:15:16 HBMASTER: job (0, 0, 8) submitted to dispatcher
12:15:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:15:16 DISPATCHER: Trying to submit another job.
12:15:16 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:15:16 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:15:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:15:16 WORKER: start processing job (0, 0, 8)
12:15:16 WORKER: args: ()
12:15:16 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0015726327386514983, 'num_filters_1': 35, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.06680799769503927, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 42, 'num_filters_3': 109, 'num_filters_4': 17, 'num_filters_5': 85}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:15:57 DISPATCHER: Starting worker discovery
12:15:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:15:57 DISPATCHER: Finished worker discovery
12:16:19 WORKER: done with job (0, 0, 8), trying to register it.
12:16:19 WORKER: registered result for job (0, 0, 8) with dispatcher
12:16:19 DISPATCHER: job (0, 0, 8) finished
12:16:19 DISPATCHER: register_result: lock acquired
12:16:19 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:16:19 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0015726327386514983, 'num_filters_1': 35, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.06680799769503927, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 42, 'num_filters_3': 109, 'num_filters_4': 17, 'num_filters_5': 85}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.06170700992679182, 'info': {'data04': 0.06170700992679182, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0015726327386514983, 'num_filters_1': 35, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.06680799769503927, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 42, 'num_filters_3': 109, 'num_filters_4': 17, 'num_filters_5': 85}"}}
exception: None

12:16:19 job_callback for (0, 0, 8) started
12:16:19 job_callback for (0, 0, 8) got condition
12:16:19 DISPATCHER: Trying to submit another job.
12:16:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:16:19 Only 9 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
12:16:19 HBMASTER: Trying to run another job!
12:16:19 job_callback for (0, 0, 8) finished
12:16:19 start sampling a new configuration.
12:16:19 done sampling a new configuration.
12:16:19 HBMASTER: schedule new run for iteration 0
12:16:19 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
12:16:19 HBMASTER: submitting job (0, 0, 9) to dispatcher
12:16:19 DISPATCHER: trying to submit job (0, 0, 9)
12:16:19 DISPATCHER: trying to notify the job_runner thread.
12:16:19 HBMASTER: job (0, 0, 9) submitted to dispatcher
12:16:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:16:19 DISPATCHER: Trying to submit another job.
12:16:19 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:16:19 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:16:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:16:19 WORKER: start processing job (0, 0, 9)
12:16:19 WORKER: args: ()
12:16:19 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0016391985837059995, 'num_filters_1': 81, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.10619952974996838, 'kernel_size_2': 5, 'num_filters_2': 99}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:16:57 DISPATCHER: Starting worker discovery
12:16:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:16:57 DISPATCHER: Finished worker discovery
12:17:21 WORKER: done with job (0, 0, 9), trying to register it.
12:17:21 WORKER: registered result for job (0, 0, 9) with dispatcher
12:17:21 DISPATCHER: job (0, 0, 9) finished
12:17:21 DISPATCHER: register_result: lock acquired
12:17:21 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:17:21 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0016391985837059995, 'num_filters_1': 81, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.10619952974996838, 'kernel_size_2': 5, 'num_filters_2': 99}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.03519961624626269, 'info': {'data04': 0.03519961624626269, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0016391985837059995, 'num_filters_1': 81, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.10619952974996838, 'kernel_size_2': 5, 'num_filters_2': 99}"}}
exception: None

12:17:21 job_callback for (0, 0, 9) started
12:17:21 job_callback for (0, 0, 9) got condition
12:17:21 DISPATCHER: Trying to submit another job.
12:17:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:17:21 Only 10 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
12:17:21 HBMASTER: Trying to run another job!
12:17:21 job_callback for (0, 0, 9) finished
12:17:21 start sampling a new configuration.
12:17:21 done sampling a new configuration.
12:17:21 HBMASTER: schedule new run for iteration 0
12:17:21 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
12:17:21 HBMASTER: submitting job (0, 0, 10) to dispatcher
12:17:21 DISPATCHER: trying to submit job (0, 0, 10)
12:17:21 DISPATCHER: trying to notify the job_runner thread.
12:17:21 HBMASTER: job (0, 0, 10) submitted to dispatcher
12:17:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:17:21 DISPATCHER: Trying to submit another job.
12:17:21 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:17:21 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:17:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:17:21 WORKER: start processing job (0, 0, 10)
12:17:21 WORKER: args: ()
12:17:21 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.05994929185821558, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.037941464949323524, 'kernel_size_2': 5, 'num_filters_2': 50}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:17:57 DISPATCHER: Starting worker discovery
12:17:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:17:57 DISPATCHER: Finished worker discovery
12:18:22 WORKER: done with job (0, 0, 10), trying to register it.
12:18:22 WORKER: registered result for job (0, 0, 10) with dispatcher
12:18:22 DISPATCHER: job (0, 0, 10) finished
12:18:22 DISPATCHER: register_result: lock acquired
12:18:22 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:18:22 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.05994929185821558, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.037941464949323524, 'kernel_size_2': 5, 'num_filters_2': 50}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.03715267534054534, 'info': {'data04': 0.03715267534054534, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.05994929185821558, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.037941464949323524, 'kernel_size_2': 5, 'num_filters_2': 50}"}}
exception: None

12:18:22 job_callback for (0, 0, 10) started
12:18:22 DISPATCHER: Trying to submit another job.
12:18:22 job_callback for (0, 0, 10) got condition
12:18:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:18:22 Only 11 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
12:18:22 HBMASTER: Trying to run another job!
12:18:22 job_callback for (0, 0, 10) finished
12:18:22 start sampling a new configuration.
12:18:22 done sampling a new configuration.
12:18:22 HBMASTER: schedule new run for iteration 0
12:18:22 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
12:18:22 HBMASTER: submitting job (0, 0, 11) to dispatcher
12:18:22 DISPATCHER: trying to submit job (0, 0, 11)
12:18:22 DISPATCHER: trying to notify the job_runner thread.
12:18:22 HBMASTER: job (0, 0, 11) submitted to dispatcher
12:18:22 DISPATCHER: Trying to submit another job.
12:18:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:18:22 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:18:22 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:18:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:18:22 WORKER: start processing job (0, 0, 11)
12:18:22 WORKER: args: ()
12:18:22 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.022473827077780176, 'num_filters_1': 60, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.017386036742530447}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:18:57 DISPATCHER: Starting worker discovery
12:18:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:18:57 DISPATCHER: Finished worker discovery
12:19:29 WORKER: done with job (0, 0, 11), trying to register it.
12:19:29 WORKER: registered result for job (0, 0, 11) with dispatcher
12:19:29 DISPATCHER: job (0, 0, 11) finished
12:19:29 DISPATCHER: register_result: lock acquired
12:19:29 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:19:29 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.022473827077780176, 'num_filters_1': 60, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.017386036742530447}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.12889118125208426, 'info': {'data04': 0.12889118125208426, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.022473827077780176, 'num_filters_1': 60, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.017386036742530447}"}}
exception: None

12:19:29 job_callback for (0, 0, 11) started
12:19:29 DISPATCHER: Trying to submit another job.
12:19:29 job_callback for (0, 0, 11) got condition
12:19:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:19:29 Only 12 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
12:19:29 HBMASTER: Trying to run another job!
12:19:29 job_callback for (0, 0, 11) finished
12:19:29 start sampling a new configuration.
12:19:29 done sampling a new configuration.
12:19:29 HBMASTER: schedule new run for iteration 0
12:19:29 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
12:19:29 HBMASTER: submitting job (0, 0, 12) to dispatcher
12:19:29 DISPATCHER: trying to submit job (0, 0, 12)
12:19:29 DISPATCHER: trying to notify the job_runner thread.
12:19:29 HBMASTER: job (0, 0, 12) submitted to dispatcher
12:19:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:19:29 DISPATCHER: Trying to submit another job.
12:19:29 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:19:29 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:19:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:19:29 WORKER: start processing job (0, 0, 12)
12:19:29 WORKER: args: ()
12:19:29 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.022018873488499475, 'num_filters_1': 28, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.025408551939621972, 'kernel_size_2': 7, 'num_filters_2': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:19:57 DISPATCHER: Starting worker discovery
12:19:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:19:57 DISPATCHER: Finished worker discovery
12:20:32 WORKER: done with job (0, 0, 12), trying to register it.
12:20:32 WORKER: registered result for job (0, 0, 12) with dispatcher
12:20:32 DISPATCHER: job (0, 0, 12) finished
12:20:32 DISPATCHER: register_result: lock acquired
12:20:32 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:20:32 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.022018873488499475, 'num_filters_1': 28, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.025408551939621972, 'kernel_size_2': 7, 'num_filters_2': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.11536944740353708, 'info': {'data04': 0.11536944740353708, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.022018873488499475, 'num_filters_1': 28, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.025408551939621972, 'kernel_size_2': 7, 'num_filters_2': 27}"}}
exception: None

12:20:32 job_callback for (0, 0, 12) started
12:20:32 job_callback for (0, 0, 12) got condition
12:20:32 DISPATCHER: Trying to submit another job.
12:20:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:20:32 Only 13 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
12:20:32 HBMASTER: Trying to run another job!
12:20:32 job_callback for (0, 0, 12) finished
12:20:32 start sampling a new configuration.
12:20:32 done sampling a new configuration.
12:20:32 HBMASTER: schedule new run for iteration 0
12:20:32 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
12:20:32 HBMASTER: submitting job (0, 0, 13) to dispatcher
12:20:32 DISPATCHER: trying to submit job (0, 0, 13)
12:20:32 DISPATCHER: trying to notify the job_runner thread.
12:20:32 HBMASTER: job (0, 0, 13) submitted to dispatcher
12:20:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:20:32 DISPATCHER: Trying to submit another job.
12:20:32 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:20:32 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:20:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:20:32 WORKER: start processing job (0, 0, 13)
12:20:32 WORKER: args: ()
12:20:32 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.02813635061821548, 'num_filters_1': 30, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.04506451628603371, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 67, 'num_filters_3': 101, 'num_filters_4': 21, 'num_filters_5': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:20:57 DISPATCHER: Starting worker discovery
12:20:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:20:57 DISPATCHER: Finished worker discovery
12:21:34 WORKER: done with job (0, 0, 13), trying to register it.
12:21:34 WORKER: registered result for job (0, 0, 13) with dispatcher
12:21:34 DISPATCHER: job (0, 0, 13) finished
12:21:34 DISPATCHER: register_result: lock acquired
12:21:34 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:21:34 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.02813635061821548, 'num_filters_1': 30, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.04506451628603371, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 67, 'num_filters_3': 101, 'num_filters_4': 21, 'num_filters_5': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0011694614170921784, 'info': {'data04': 0.0011694614170921784, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.02813635061821548, 'num_filters_1': 30, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.04506451628603371, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 67, 'num_filters_3': 101, 'num_filters_4': 21, 'num_filters_5': 26}"}}
exception: None

12:21:34 job_callback for (0, 0, 13) started
12:21:34 DISPATCHER: Trying to submit another job.
12:21:34 job_callback for (0, 0, 13) got condition
12:21:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:21:34 Only 14 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
12:21:34 HBMASTER: Trying to run another job!
12:21:34 job_callback for (0, 0, 13) finished
12:21:34 start sampling a new configuration.
12:21:34 done sampling a new configuration.
12:21:34 HBMASTER: schedule new run for iteration 0
12:21:34 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
12:21:34 HBMASTER: submitting job (0, 0, 14) to dispatcher
12:21:34 DISPATCHER: trying to submit job (0, 0, 14)
12:21:34 DISPATCHER: trying to notify the job_runner thread.
12:21:34 HBMASTER: job (0, 0, 14) submitted to dispatcher
12:21:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:21:34 DISPATCHER: Trying to submit another job.
12:21:34 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:21:34 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:21:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:21:34 WORKER: start processing job (0, 0, 14)
12:21:34 WORKER: args: ()
12:21:34 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.006899124390242902, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.0297462742583842, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 90, 'num_filters_3': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:21:57 DISPATCHER: Starting worker discovery
12:21:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:21:57 DISPATCHER: Finished worker discovery
12:22:36 WORKER: done with job (0, 0, 14), trying to register it.
12:22:36 WORKER: registered result for job (0, 0, 14) with dispatcher
12:22:36 DISPATCHER: job (0, 0, 14) finished
12:22:36 DISPATCHER: register_result: lock acquired
12:22:36 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:22:36 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.006899124390242902, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.0297462742583842, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 90, 'num_filters_3': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.09458257868448351, 'info': {'data04': 0.09458257868448351, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.006899124390242902, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.0297462742583842, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 90, 'num_filters_3': 17}"}}
exception: None

12:22:36 job_callback for (0, 0, 14) started
12:22:36 DISPATCHER: Trying to submit another job.
12:22:36 job_callback for (0, 0, 14) got condition
12:22:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:22:36 Only 15 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
12:22:36 HBMASTER: Trying to run another job!
12:22:36 job_callback for (0, 0, 14) finished
12:22:36 start sampling a new configuration.
12:22:36 done sampling a new configuration.
12:22:36 HBMASTER: schedule new run for iteration 0
12:22:36 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
12:22:36 HBMASTER: submitting job (0, 0, 15) to dispatcher
12:22:36 DISPATCHER: trying to submit job (0, 0, 15)
12:22:36 DISPATCHER: trying to notify the job_runner thread.
12:22:36 HBMASTER: job (0, 0, 15) submitted to dispatcher
12:22:36 DISPATCHER: Trying to submit another job.
12:22:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:22:36 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:22:36 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:22:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:22:36 WORKER: start processing job (0, 0, 15)
12:22:36 WORKER: args: ()
12:22:36 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.038357517030255715, 'num_filters_1': 128, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.1793151563731742, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 99, 'num_filters_3': 25, 'num_filters_4': 68, 'num_filters_5': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:22:57 DISPATCHER: Starting worker discovery
12:22:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:22:57 DISPATCHER: Finished worker discovery
12:23:40 WORKER: done with job (0, 0, 15), trying to register it.
12:23:40 WORKER: registered result for job (0, 0, 15) with dispatcher
12:23:40 DISPATCHER: job (0, 0, 15) finished
12:23:40 DISPATCHER: register_result: lock acquired
12:23:40 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:23:40 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.038357517030255715, 'num_filters_1': 128, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.1793151563731742, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 99, 'num_filters_3': 25, 'num_filters_4': 68, 'num_filters_5': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -1.280817788792761e-05, 'info': {'data04': 1.280817788792761e-05, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.038357517030255715, 'num_filters_1': 128, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.1793151563731742, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 99, 'num_filters_3': 25, 'num_filters_4': 68, 'num_filters_5': 26}"}}
exception: None

12:23:40 job_callback for (0, 0, 15) started
12:23:40 job_callback for (0, 0, 15) got condition
12:23:40 DISPATCHER: Trying to submit another job.
12:23:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:23:40 Only 16 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
12:23:40 HBMASTER: Trying to run another job!
12:23:40 job_callback for (0, 0, 15) finished
12:23:40 start sampling a new configuration.
12:23:40 done sampling a new configuration.
12:23:40 HBMASTER: schedule new run for iteration 0
12:23:40 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
12:23:40 HBMASTER: submitting job (0, 0, 16) to dispatcher
12:23:40 DISPATCHER: trying to submit job (0, 0, 16)
12:23:40 DISPATCHER: trying to notify the job_runner thread.
12:23:40 HBMASTER: job (0, 0, 16) submitted to dispatcher
12:23:40 DISPATCHER: Trying to submit another job.
12:23:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:23:40 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:23:40 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:23:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:23:40 WORKER: start processing job (0, 0, 16)
12:23:40 WORKER: args: ()
12:23:40 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.02253863778339907, 'num_filters_1': 49, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.021983810198382907, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 80, 'num_filters_3': 83, 'num_filters_4': 36, 'num_filters_5': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:23:57 DISPATCHER: Starting worker discovery
12:23:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:23:57 DISPATCHER: Finished worker discovery
12:24:42 WORKER: done with job (0, 0, 16), trying to register it.
12:24:42 WORKER: registered result for job (0, 0, 16) with dispatcher
12:24:42 DISPATCHER: job (0, 0, 16) finished
12:24:42 DISPATCHER: register_result: lock acquired
12:24:42 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:24:42 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.02253863778339907, 'num_filters_1': 49, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.021983810198382907, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 80, 'num_filters_3': 83, 'num_filters_4': 36, 'num_filters_5': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0365564111133161, 'info': {'data04': 0.0365564111133161, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.02253863778339907, 'num_filters_1': 49, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.021983810198382907, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 80, 'num_filters_3': 83, 'num_filters_4': 36, 'num_filters_5': 16}"}}
exception: None

12:24:42 job_callback for (0, 0, 16) started
12:24:42 DISPATCHER: Trying to submit another job.
12:24:42 job_callback for (0, 0, 16) got condition
12:24:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:24:42 HBMASTER: Trying to run another job!
12:24:42 job_callback for (0, 0, 16) finished
12:24:42 start sampling a new configuration.
12:24:42 done sampling a new configuration.
12:24:42 HBMASTER: schedule new run for iteration 0
12:24:42 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
12:24:42 HBMASTER: submitting job (0, 0, 17) to dispatcher
12:24:42 DISPATCHER: trying to submit job (0, 0, 17)
12:24:42 DISPATCHER: trying to notify the job_runner thread.
12:24:42 HBMASTER: job (0, 0, 17) submitted to dispatcher
12:24:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:24:42 DISPATCHER: Trying to submit another job.
12:24:42 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:24:42 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:24:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:24:42 WORKER: start processing job (0, 0, 17)
12:24:42 WORKER: args: ()
12:24:42 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.003146206658147817, 'num_filters_1': 113, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.15470425863989862, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 17, 'num_filters_3': 49}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:24:57 DISPATCHER: Starting worker discovery
12:24:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:24:57 DISPATCHER: Finished worker discovery
12:25:51 WORKER: done with job (0, 0, 17), trying to register it.
12:25:51 WORKER: registered result for job (0, 0, 17) with dispatcher
12:25:51 DISPATCHER: job (0, 0, 17) finished
12:25:51 DISPATCHER: register_result: lock acquired
12:25:51 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:25:51 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.003146206658147817, 'num_filters_1': 113, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.15470425863989862, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 17, 'num_filters_3': 49}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.004617168000075408, 'info': {'data04': 0.004617168000075408, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.003146206658147817, 'num_filters_1': 113, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.15470425863989862, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 17, 'num_filters_3': 49}"}}
exception: None

12:25:51 job_callback for (0, 0, 17) started
12:25:51 DISPATCHER: Trying to submit another job.
12:25:51 job_callback for (0, 0, 17) got condition
12:25:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:25:51 HBMASTER: Trying to run another job!
12:25:51 job_callback for (0, 0, 17) finished
12:25:51 start sampling a new configuration.
12:25:51 done sampling a new configuration.
12:25:51 HBMASTER: schedule new run for iteration 0
12:25:51 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
12:25:51 HBMASTER: submitting job (0, 0, 18) to dispatcher
12:25:51 DISPATCHER: trying to submit job (0, 0, 18)
12:25:51 DISPATCHER: trying to notify the job_runner thread.
12:25:51 HBMASTER: job (0, 0, 18) submitted to dispatcher
12:25:51 DISPATCHER: Trying to submit another job.
12:25:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:25:51 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:25:51 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:25:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:25:51 WORKER: start processing job (0, 0, 18)
12:25:51 WORKER: args: ()
12:25:51 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.024943892676181863, 'num_filters_1': 32, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.07095213147287817, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 23, 'num_filters_3': 19, 'num_filters_4': 39, 'num_filters_5': 35}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:25:57 DISPATCHER: Starting worker discovery
12:25:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:25:57 DISPATCHER: Finished worker discovery
12:26:55 WORKER: done with job (0, 0, 18), trying to register it.
12:26:55 WORKER: registered result for job (0, 0, 18) with dispatcher
12:26:55 DISPATCHER: job (0, 0, 18) finished
12:26:55 DISPATCHER: register_result: lock acquired
12:26:55 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:26:55 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.024943892676181863, 'num_filters_1': 32, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.07095213147287817, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 23, 'num_filters_3': 19, 'num_filters_4': 39, 'num_filters_5': 35}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.024943892676181863, 'num_filters_1': 32, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.07095213147287817, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 23, 'num_filters_3': 19, 'num_filters_4': 39, 'num_filters_5': 35}"}}
exception: None

12:26:55 job_callback for (0, 0, 18) started
12:26:55 DISPATCHER: Trying to submit another job.
12:26:55 job_callback for (0, 0, 18) got condition
12:26:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:26:55 HBMASTER: Trying to run another job!
12:26:55 job_callback for (0, 0, 18) finished
12:26:55 start sampling a new configuration.
12:26:55 done sampling a new configuration.
12:26:55 HBMASTER: schedule new run for iteration 0
12:26:55 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
12:26:55 HBMASTER: submitting job (0, 0, 19) to dispatcher
12:26:55 DISPATCHER: trying to submit job (0, 0, 19)
12:26:55 DISPATCHER: trying to notify the job_runner thread.
12:26:55 HBMASTER: job (0, 0, 19) submitted to dispatcher
12:26:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:26:55 DISPATCHER: Trying to submit another job.
12:26:55 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:26:55 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:26:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:26:55 WORKER: start processing job (0, 0, 19)
12:26:55 WORKER: args: ()
12:26:55 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0017601376825632543, 'num_filters_1': 57, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.03006980780957016, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 122, 'num_filters_3': 98, 'num_filters_4': 87}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:26:57 DISPATCHER: Starting worker discovery
12:26:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:26:57 DISPATCHER: Finished worker discovery
12:27:57 WORKER: done with job (0, 0, 19), trying to register it.
12:27:57 WORKER: registered result for job (0, 0, 19) with dispatcher
12:27:57 DISPATCHER: job (0, 0, 19) finished
12:27:57 DISPATCHER: register_result: lock acquired
12:27:57 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:27:57 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0017601376825632543, 'num_filters_1': 57, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.03006980780957016, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 122, 'num_filters_3': 98, 'num_filters_4': 87}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.16211490569581102, 'info': {'data04': 0.16211490569581102, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0017601376825632543, 'num_filters_1': 57, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.03006980780957016, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 122, 'num_filters_3': 98, 'num_filters_4': 87}"}}
exception: None

12:27:57 job_callback for (0, 0, 19) started
12:27:57 job_callback for (0, 0, 19) got condition
12:27:57 DISPATCHER: Trying to submit another job.
12:27:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:27:57 HBMASTER: Trying to run another job!
12:27:57 job_callback for (0, 0, 19) finished
12:27:57 start sampling a new configuration.
12:27:57 done sampling a new configuration.
12:27:57 HBMASTER: schedule new run for iteration 0
12:27:57 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
12:27:57 HBMASTER: submitting job (0, 0, 20) to dispatcher
12:27:57 DISPATCHER: trying to submit job (0, 0, 20)
12:27:57 DISPATCHER: trying to notify the job_runner thread.
12:27:57 HBMASTER: job (0, 0, 20) submitted to dispatcher
12:27:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:27:57 DISPATCHER: Trying to submit another job.
12:27:57 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:27:57 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:27:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:27:57 WORKER: start processing job (0, 0, 20)
12:27:57 WORKER: args: ()
12:27:57 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.05714585561022027, 'num_filters_1': 31, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.029875244918809586}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:27:57 DISPATCHER: Starting worker discovery
12:27:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:27:57 DISPATCHER: Finished worker discovery
12:28:57 DISPATCHER: Starting worker discovery
12:28:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:28:57 DISPATCHER: Finished worker discovery
12:29:00 WORKER: done with job (0, 0, 20), trying to register it.
12:29:00 WORKER: registered result for job (0, 0, 20) with dispatcher
12:29:00 DISPATCHER: job (0, 0, 20) finished
12:29:00 DISPATCHER: register_result: lock acquired
12:29:00 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:29:00 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.05714585561022027, 'num_filters_1': 31, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.029875244918809586}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.03091194401325328, 'info': {'data04': 0.03091194401325328, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.05714585561022027, 'num_filters_1': 31, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.029875244918809586}"}}
exception: None

12:29:00 job_callback for (0, 0, 20) started
12:29:00 job_callback for (0, 0, 20) got condition
12:29:00 DISPATCHER: Trying to submit another job.
12:29:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:29:00 HBMASTER: Trying to run another job!
12:29:00 job_callback for (0, 0, 20) finished
12:29:00 start sampling a new configuration.
12:29:00 done sampling a new configuration.
12:29:00 HBMASTER: schedule new run for iteration 0
12:29:00 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
12:29:00 HBMASTER: submitting job (0, 0, 21) to dispatcher
12:29:00 DISPATCHER: trying to submit job (0, 0, 21)
12:29:00 DISPATCHER: trying to notify the job_runner thread.
12:29:00 HBMASTER: job (0, 0, 21) submitted to dispatcher
12:29:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:29:00 DISPATCHER: Trying to submit another job.
12:29:00 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:29:00 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:29:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:29:00 WORKER: start processing job (0, 0, 21)
12:29:00 WORKER: args: ()
12:29:00 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.05512630939331712, 'num_filters_1': 55, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.010437367407440206, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 20, 'num_filters_3': 72, 'num_filters_4': 104}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:29:57 DISPATCHER: Starting worker discovery
12:29:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:29:57 DISPATCHER: Finished worker discovery
12:30:02 WORKER: done with job (0, 0, 21), trying to register it.
12:30:02 WORKER: registered result for job (0, 0, 21) with dispatcher
12:30:02 DISPATCHER: job (0, 0, 21) finished
12:30:02 DISPATCHER: register_result: lock acquired
12:30:02 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:30:02 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.05512630939331712, 'num_filters_1': 55, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.010437367407440206, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 20, 'num_filters_3': 72, 'num_filters_4': 104}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.05512630939331712, 'num_filters_1': 55, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.010437367407440206, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 20, 'num_filters_3': 72, 'num_filters_4': 104}"}}
exception: None

12:30:02 job_callback for (0, 0, 21) started
12:30:02 job_callback for (0, 0, 21) got condition
12:30:02 DISPATCHER: Trying to submit another job.
12:30:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:30:02 HBMASTER: Trying to run another job!
12:30:02 job_callback for (0, 0, 21) finished
12:30:02 start sampling a new configuration.
12:30:02 done sampling a new configuration.
12:30:02 HBMASTER: schedule new run for iteration 0
12:30:02 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
12:30:02 HBMASTER: submitting job (0, 0, 22) to dispatcher
12:30:02 DISPATCHER: trying to submit job (0, 0, 22)
12:30:02 DISPATCHER: trying to notify the job_runner thread.
12:30:02 HBMASTER: job (0, 0, 22) submitted to dispatcher
12:30:02 DISPATCHER: Trying to submit another job.
12:30:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:30:02 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:30:02 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:30:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:30:02 WORKER: start processing job (0, 0, 22)
12:30:02 WORKER: args: ()
12:30:02 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.004084616037193211, 'num_filters_1': 28, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.0606438134302822, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 17, 'num_filters_3': 46, 'num_filters_4': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:30:57 DISPATCHER: Starting worker discovery
12:30:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:30:57 DISPATCHER: Finished worker discovery
12:31:03 WORKER: done with job (0, 0, 22), trying to register it.
12:31:03 WORKER: registered result for job (0, 0, 22) with dispatcher
12:31:03 DISPATCHER: job (0, 0, 22) finished
12:31:03 DISPATCHER: register_result: lock acquired
12:31:03 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:31:03 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.004084616037193211, 'num_filters_1': 28, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.0606438134302822, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 17, 'num_filters_3': 46, 'num_filters_4': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.03125940411987382, 'info': {'data04': 0.03125940411987382, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.004084616037193211, 'num_filters_1': 28, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.0606438134302822, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 17, 'num_filters_3': 46, 'num_filters_4': 19}"}}
exception: None

12:31:03 job_callback for (0, 0, 22) started
12:31:03 job_callback for (0, 0, 22) got condition
12:31:03 DISPATCHER: Trying to submit another job.
12:31:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:31:03 HBMASTER: Trying to run another job!
12:31:03 job_callback for (0, 0, 22) finished
12:31:03 start sampling a new configuration.
12:31:03 done sampling a new configuration.
12:31:03 HBMASTER: schedule new run for iteration 0
12:31:03 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
12:31:03 HBMASTER: submitting job (0, 0, 23) to dispatcher
12:31:03 DISPATCHER: trying to submit job (0, 0, 23)
12:31:03 DISPATCHER: trying to notify the job_runner thread.
12:31:03 HBMASTER: job (0, 0, 23) submitted to dispatcher
12:31:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:31:03 DISPATCHER: Trying to submit another job.
12:31:03 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:31:03 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:31:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:31:03 WORKER: start processing job (0, 0, 23)
12:31:03 WORKER: args: ()
12:31:03 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.040304714424628824, 'num_filters_1': 32, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.021112069942900276, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 41, 'num_filters_3': 72}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:31:57 DISPATCHER: Starting worker discovery
12:31:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:31:57 DISPATCHER: Finished worker discovery
12:32:04 WORKER: done with job (0, 0, 23), trying to register it.
12:32:04 WORKER: registered result for job (0, 0, 23) with dispatcher
12:32:04 DISPATCHER: job (0, 0, 23) finished
12:32:04 DISPATCHER: register_result: lock acquired
12:32:04 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:32:04 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.040304714424628824, 'num_filters_1': 32, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.021112069942900276, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 41, 'num_filters_3': 72}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.040304714424628824, 'num_filters_1': 32, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.021112069942900276, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 41, 'num_filters_3': 72}"}}
exception: None

12:32:04 job_callback for (0, 0, 23) started
12:32:04 job_callback for (0, 0, 23) got condition
12:32:04 DISPATCHER: Trying to submit another job.
12:32:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:32:04 HBMASTER: Trying to run another job!
12:32:04 job_callback for (0, 0, 23) finished
12:32:04 start sampling a new configuration.
12:32:04 done sampling a new configuration.
12:32:04 HBMASTER: schedule new run for iteration 0
12:32:04 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
12:32:04 HBMASTER: submitting job (0, 0, 24) to dispatcher
12:32:04 DISPATCHER: trying to submit job (0, 0, 24)
12:32:04 DISPATCHER: trying to notify the job_runner thread.
12:32:04 HBMASTER: job (0, 0, 24) submitted to dispatcher
12:32:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:32:04 DISPATCHER: Trying to submit another job.
12:32:04 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:32:04 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:32:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:32:04 WORKER: start processing job (0, 0, 24)
12:32:04 WORKER: args: ()
12:32:04 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.027029583400342155, 'num_filters_1': 57, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.04485019797965598, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 21, 'num_filters_3': 27, 'num_filters_4': 23, 'num_filters_5': 75}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:32:57 DISPATCHER: Starting worker discovery
12:32:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:32:57 DISPATCHER: Finished worker discovery
12:33:08 WORKER: done with job (0, 0, 24), trying to register it.
12:33:08 WORKER: registered result for job (0, 0, 24) with dispatcher
12:33:08 DISPATCHER: job (0, 0, 24) finished
12:33:08 DISPATCHER: register_result: lock acquired
12:33:08 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:33:08 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.027029583400342155, 'num_filters_1': 57, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.04485019797965598, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 21, 'num_filters_3': 27, 'num_filters_4': 23, 'num_filters_5': 75}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.027029583400342155, 'num_filters_1': 57, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.04485019797965598, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 21, 'num_filters_3': 27, 'num_filters_4': 23, 'num_filters_5': 75}"}}
exception: None

12:33:08 job_callback for (0, 0, 24) started
12:33:08 job_callback for (0, 0, 24) got condition
12:33:08 DISPATCHER: Trying to submit another job.
12:33:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:33:08 HBMASTER: Trying to run another job!
12:33:08 job_callback for (0, 0, 24) finished
12:33:08 start sampling a new configuration.
12:33:08 done sampling a new configuration.
12:33:08 HBMASTER: schedule new run for iteration 0
12:33:08 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
12:33:08 HBMASTER: submitting job (0, 0, 25) to dispatcher
12:33:08 DISPATCHER: trying to submit job (0, 0, 25)
12:33:08 DISPATCHER: trying to notify the job_runner thread.
12:33:08 HBMASTER: job (0, 0, 25) submitted to dispatcher
12:33:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:33:08 DISPATCHER: Trying to submit another job.
12:33:08 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:33:08 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:33:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:33:08 WORKER: start processing job (0, 0, 25)
12:33:08 WORKER: args: ()
12:33:08 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0017845083315240384, 'num_filters_1': 39, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.11021855763078056, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 80, 'num_filters_3': 24, 'num_filters_4': 82, 'num_filters_5': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:33:57 DISPATCHER: Starting worker discovery
12:33:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:33:57 DISPATCHER: Finished worker discovery
12:34:08 WORKER: done with job (0, 0, 25), trying to register it.
12:34:08 WORKER: registered result for job (0, 0, 25) with dispatcher
12:34:08 DISPATCHER: job (0, 0, 25) finished
12:34:08 DISPATCHER: register_result: lock acquired
12:34:08 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:34:08 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0017845083315240384, 'num_filters_1': 39, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.11021855763078056, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 80, 'num_filters_3': 24, 'num_filters_4': 82, 'num_filters_5': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0001593101558118631, 'info': {'data04': 0.0001593101558118631, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0017845083315240384, 'num_filters_1': 39, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.11021855763078056, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 80, 'num_filters_3': 24, 'num_filters_4': 82, 'num_filters_5': 44}"}}
exception: None

12:34:08 job_callback for (0, 0, 25) started
12:34:08 DISPATCHER: Trying to submit another job.
12:34:08 job_callback for (0, 0, 25) got condition
12:34:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:34:08 HBMASTER: Trying to run another job!
12:34:08 job_callback for (0, 0, 25) finished
12:34:08 start sampling a new configuration.
12:34:08 done sampling a new configuration.
12:34:08 HBMASTER: schedule new run for iteration 0
12:34:08 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
12:34:08 HBMASTER: submitting job (0, 0, 26) to dispatcher
12:34:08 DISPATCHER: trying to submit job (0, 0, 26)
12:34:08 DISPATCHER: trying to notify the job_runner thread.
12:34:08 HBMASTER: job (0, 0, 26) submitted to dispatcher
12:34:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:34:08 DISPATCHER: Trying to submit another job.
12:34:08 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:34:08 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:34:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:34:08 WORKER: start processing job (0, 0, 26)
12:34:08 WORKER: args: ()
12:34:08 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.07892124409859967, 'num_filters_1': 105, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.10346181515418525, 'kernel_size_2': 7, 'num_filters_2': 102}, 'budget': 44.44444444444444, 'working_directory': '.'}
12:34:57 DISPATCHER: Starting worker discovery
12:34:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:34:57 DISPATCHER: Finished worker discovery
12:35:10 WORKER: done with job (0, 0, 26), trying to register it.
12:35:10 WORKER: registered result for job (0, 0, 26) with dispatcher
12:35:10 DISPATCHER: job (0, 0, 26) finished
12:35:10 DISPATCHER: register_result: lock acquired
12:35:10 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:35:10 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.07892124409859967, 'num_filters_1': 105, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.10346181515418525, 'kernel_size_2': 7, 'num_filters_2': 102}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0013914819229337886, 'info': {'data04': 0.0013914819229337886, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.07892124409859967, 'num_filters_1': 105, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.10346181515418525, 'kernel_size_2': 7, 'num_filters_2': 102}"}}
exception: None

12:35:10 job_callback for (0, 0, 26) started
12:35:10 job_callback for (0, 0, 26) got condition
12:35:10 DISPATCHER: Trying to submit another job.
12:35:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:35:10 HBMASTER: Trying to run another job!
12:35:10 job_callback for (0, 0, 26) finished
12:35:10 ITERATION: Advancing config (0, 0, 2) to next budget 133.333333
12:35:10 ITERATION: Advancing config (0, 0, 6) to next budget 133.333333
12:35:10 ITERATION: Advancing config (0, 0, 8) to next budget 133.333333
12:35:10 ITERATION: Advancing config (0, 0, 10) to next budget 133.333333
12:35:10 ITERATION: Advancing config (0, 0, 11) to next budget 133.333333
12:35:10 ITERATION: Advancing config (0, 0, 12) to next budget 133.333333
12:35:10 ITERATION: Advancing config (0, 0, 14) to next budget 133.333333
12:35:10 ITERATION: Advancing config (0, 0, 16) to next budget 133.333333
12:35:10 ITERATION: Advancing config (0, 0, 19) to next budget 133.333333
12:35:10 HBMASTER: schedule new run for iteration 0
12:35:10 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
12:35:10 HBMASTER: submitting job (0, 0, 2) to dispatcher
12:35:10 DISPATCHER: trying to submit job (0, 0, 2)
12:35:10 DISPATCHER: trying to notify the job_runner thread.
12:35:10 HBMASTER: job (0, 0, 2) submitted to dispatcher
12:35:10 DISPATCHER: Trying to submit another job.
12:35:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:35:10 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:35:10 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:35:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:35:10 WORKER: start processing job (0, 0, 2)
12:35:10 WORKER: args: ()
12:35:10 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0018427867735740864, 'num_filters_1': 58, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.018124338555921205, 'kernel_size_2': 5, 'num_filters_2': 19}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:35:57 DISPATCHER: Starting worker discovery
12:35:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:35:57 DISPATCHER: Finished worker discovery
12:36:57 DISPATCHER: Starting worker discovery
12:36:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:36:57 DISPATCHER: Finished worker discovery
12:37:57 DISPATCHER: Starting worker discovery
12:37:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:37:58 DISPATCHER: Finished worker discovery
12:38:02 WORKER: done with job (0, 0, 2), trying to register it.
12:38:02 WORKER: registered result for job (0, 0, 2) with dispatcher
12:38:02 DISPATCHER: job (0, 0, 2) finished
12:38:02 DISPATCHER: register_result: lock acquired
12:38:02 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:38:02 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0018427867735740864, 'num_filters_1': 58, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.018124338555921205, 'kernel_size_2': 5, 'num_filters_2': 19}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.13001640993898267, 'info': {'data04': 0.13001640993898267, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0018427867735740864, 'num_filters_1': 58, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.018124338555921205, 'kernel_size_2': 5, 'num_filters_2': 19}"}}
exception: None

12:38:02 job_callback for (0, 0, 2) started
12:38:02 job_callback for (0, 0, 2) got condition
12:38:02 DISPATCHER: Trying to submit another job.
12:38:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:38:02 Only 1 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:38:02 HBMASTER: Trying to run another job!
12:38:02 job_callback for (0, 0, 2) finished
12:38:02 HBMASTER: schedule new run for iteration 0
12:38:02 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
12:38:02 HBMASTER: submitting job (0, 0, 6) to dispatcher
12:38:02 DISPATCHER: trying to submit job (0, 0, 6)
12:38:02 DISPATCHER: trying to notify the job_runner thread.
12:38:02 HBMASTER: job (0, 0, 6) submitted to dispatcher
12:38:02 DISPATCHER: Trying to submit another job.
12:38:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:38:02 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:38:02 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:38:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:38:02 WORKER: start processing job (0, 0, 6)
12:38:02 WORKER: args: ()
12:38:02 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0018446601469640836, 'num_filters_1': 64, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.015996657233553802, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 105, 'num_filters_3': 50}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:38:58 DISPATCHER: Starting worker discovery
12:38:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:38:58 DISPATCHER: Finished worker discovery
12:39:58 DISPATCHER: Starting worker discovery
12:39:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:39:58 DISPATCHER: Finished worker discovery
12:40:38 WORKER: done with job (0, 0, 6), trying to register it.
12:40:38 WORKER: registered result for job (0, 0, 6) with dispatcher
12:40:38 DISPATCHER: job (0, 0, 6) finished
12:40:38 DISPATCHER: register_result: lock acquired
12:40:38 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:40:38 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0018446601469640836, 'num_filters_1': 64, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.015996657233553802, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 105, 'num_filters_3': 50}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0928578279343249, 'info': {'data04': 0.0928578279343249, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0018446601469640836, 'num_filters_1': 64, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.015996657233553802, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 105, 'num_filters_3': 50}"}}
exception: None

12:40:38 job_callback for (0, 0, 6) started
12:40:38 job_callback for (0, 0, 6) got condition
12:40:38 DISPATCHER: Trying to submit another job.
12:40:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:40:38 Only 2 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:40:38 HBMASTER: Trying to run another job!
12:40:38 job_callback for (0, 0, 6) finished
12:40:38 HBMASTER: schedule new run for iteration 0
12:40:38 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
12:40:38 HBMASTER: submitting job (0, 0, 8) to dispatcher
12:40:38 DISPATCHER: trying to submit job (0, 0, 8)
12:40:38 DISPATCHER: trying to notify the job_runner thread.
12:40:38 HBMASTER: job (0, 0, 8) submitted to dispatcher
12:40:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:40:38 DISPATCHER: Trying to submit another job.
12:40:38 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:40:38 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:40:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:40:38 WORKER: start processing job (0, 0, 8)
12:40:38 WORKER: args: ()
12:40:38 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0015726327386514983, 'num_filters_1': 35, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.06680799769503927, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 42, 'num_filters_3': 109, 'num_filters_4': 17, 'num_filters_5': 85}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:40:58 DISPATCHER: Starting worker discovery
12:40:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:40:58 DISPATCHER: Finished worker discovery
12:41:58 DISPATCHER: Starting worker discovery
12:41:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:41:58 DISPATCHER: Finished worker discovery
12:42:58 DISPATCHER: Starting worker discovery
12:42:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:42:58 DISPATCHER: Finished worker discovery
12:43:17 WORKER: done with job (0, 0, 8), trying to register it.
12:43:17 WORKER: registered result for job (0, 0, 8) with dispatcher
12:43:17 DISPATCHER: job (0, 0, 8) finished
12:43:17 DISPATCHER: register_result: lock acquired
12:43:17 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:43:17 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0015726327386514983, 'num_filters_1': 35, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.06680799769503927, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 42, 'num_filters_3': 109, 'num_filters_4': 17, 'num_filters_5': 85}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.007718073378056918, 'info': {'data04': 0.007718073378056918, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0015726327386514983, 'num_filters_1': 35, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.06680799769503927, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 42, 'num_filters_3': 109, 'num_filters_4': 17, 'num_filters_5': 85}"}}
exception: None

12:43:17 job_callback for (0, 0, 8) started
12:43:17 DISPATCHER: Trying to submit another job.
12:43:17 job_callback for (0, 0, 8) got condition
12:43:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:43:17 Only 3 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:43:17 HBMASTER: Trying to run another job!
12:43:17 job_callback for (0, 0, 8) finished
12:43:17 HBMASTER: schedule new run for iteration 0
12:43:17 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
12:43:17 HBMASTER: submitting job (0, 0, 10) to dispatcher
12:43:17 DISPATCHER: trying to submit job (0, 0, 10)
12:43:17 DISPATCHER: trying to notify the job_runner thread.
12:43:17 HBMASTER: job (0, 0, 10) submitted to dispatcher
12:43:17 DISPATCHER: Trying to submit another job.
12:43:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:43:17 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:43:17 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:43:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:43:17 WORKER: start processing job (0, 0, 10)
12:43:17 WORKER: args: ()
12:43:17 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.05994929185821558, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.037941464949323524, 'kernel_size_2': 5, 'num_filters_2': 50}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:43:58 DISPATCHER: Starting worker discovery
12:43:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:43:58 DISPATCHER: Finished worker discovery
12:44:58 DISPATCHER: Starting worker discovery
12:44:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:44:58 DISPATCHER: Finished worker discovery
12:45:51 WORKER: done with job (0, 0, 10), trying to register it.
12:45:51 WORKER: registered result for job (0, 0, 10) with dispatcher
12:45:51 DISPATCHER: job (0, 0, 10) finished
12:45:51 DISPATCHER: register_result: lock acquired
12:45:51 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:45:51 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.05994929185821558, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.037941464949323524, 'kernel_size_2': 5, 'num_filters_2': 50}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.029945010341884837, 'info': {'data04': 0.029945010341884837, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.05994929185821558, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.037941464949323524, 'kernel_size_2': 5, 'num_filters_2': 50}"}}
exception: None

12:45:51 job_callback for (0, 0, 10) started
12:45:51 DISPATCHER: Trying to submit another job.
12:45:51 job_callback for (0, 0, 10) got condition
12:45:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:45:51 Only 4 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:45:51 HBMASTER: Trying to run another job!
12:45:51 job_callback for (0, 0, 10) finished
12:45:51 HBMASTER: schedule new run for iteration 0
12:45:51 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
12:45:51 HBMASTER: submitting job (0, 0, 11) to dispatcher
12:45:51 DISPATCHER: trying to submit job (0, 0, 11)
12:45:51 DISPATCHER: trying to notify the job_runner thread.
12:45:51 HBMASTER: job (0, 0, 11) submitted to dispatcher
12:45:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:45:51 DISPATCHER: Trying to submit another job.
12:45:51 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:45:51 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:45:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:45:51 WORKER: start processing job (0, 0, 11)
12:45:51 WORKER: args: ()
12:45:51 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.022473827077780176, 'num_filters_1': 60, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.017386036742530447}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:45:58 DISPATCHER: Starting worker discovery
12:45:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:45:58 DISPATCHER: Finished worker discovery
12:46:58 DISPATCHER: Starting worker discovery
12:46:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:46:58 DISPATCHER: Finished worker discovery
12:47:58 DISPATCHER: Starting worker discovery
12:47:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:47:58 DISPATCHER: Finished worker discovery
12:48:42 WORKER: done with job (0, 0, 11), trying to register it.
12:48:42 WORKER: registered result for job (0, 0, 11) with dispatcher
12:48:42 DISPATCHER: job (0, 0, 11) finished
12:48:42 DISPATCHER: register_result: lock acquired
12:48:42 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:48:42 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.022473827077780176, 'num_filters_1': 60, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.017386036742530447}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.11739619611012364, 'info': {'data04': 0.11739619611012364, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.022473827077780176, 'num_filters_1': 60, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.017386036742530447}"}}
exception: None

12:48:42 job_callback for (0, 0, 11) started
12:48:42 DISPATCHER: Trying to submit another job.
12:48:42 job_callback for (0, 0, 11) got condition
12:48:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:48:42 Only 5 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:48:42 HBMASTER: Trying to run another job!
12:48:42 job_callback for (0, 0, 11) finished
12:48:42 HBMASTER: schedule new run for iteration 0
12:48:42 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
12:48:42 HBMASTER: submitting job (0, 0, 12) to dispatcher
12:48:42 DISPATCHER: trying to submit job (0, 0, 12)
12:48:42 DISPATCHER: trying to notify the job_runner thread.
12:48:42 HBMASTER: job (0, 0, 12) submitted to dispatcher
12:48:42 DISPATCHER: Trying to submit another job.
12:48:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:48:42 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:48:42 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:48:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:48:42 WORKER: start processing job (0, 0, 12)
12:48:42 WORKER: args: ()
12:48:42 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.022018873488499475, 'num_filters_1': 28, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.025408551939621972, 'kernel_size_2': 7, 'num_filters_2': 27}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:48:58 DISPATCHER: Starting worker discovery
12:48:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:48:58 DISPATCHER: Finished worker discovery
12:49:58 DISPATCHER: Starting worker discovery
12:49:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:49:58 DISPATCHER: Finished worker discovery
12:50:58 DISPATCHER: Starting worker discovery
12:50:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:50:58 DISPATCHER: Finished worker discovery
12:51:19 WORKER: done with job (0, 0, 12), trying to register it.
12:51:19 WORKER: registered result for job (0, 0, 12) with dispatcher
12:51:19 DISPATCHER: job (0, 0, 12) finished
12:51:19 DISPATCHER: register_result: lock acquired
12:51:19 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:51:19 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.022018873488499475, 'num_filters_1': 28, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.025408551939621972, 'kernel_size_2': 7, 'num_filters_2': 27}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.09064731772628708, 'info': {'data04': 0.09064731772628708, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.022018873488499475, 'num_filters_1': 28, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.025408551939621972, 'kernel_size_2': 7, 'num_filters_2': 27}"}}
exception: None

12:51:19 job_callback for (0, 0, 12) started
12:51:19 DISPATCHER: Trying to submit another job.
12:51:19 job_callback for (0, 0, 12) got condition
12:51:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:51:19 Only 6 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:51:19 HBMASTER: Trying to run another job!
12:51:19 job_callback for (0, 0, 12) finished
12:51:19 HBMASTER: schedule new run for iteration 0
12:51:19 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
12:51:19 HBMASTER: submitting job (0, 0, 14) to dispatcher
12:51:19 DISPATCHER: trying to submit job (0, 0, 14)
12:51:19 DISPATCHER: trying to notify the job_runner thread.
12:51:19 HBMASTER: job (0, 0, 14) submitted to dispatcher
12:51:19 DISPATCHER: Trying to submit another job.
12:51:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:51:19 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:51:19 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:51:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:51:19 WORKER: start processing job (0, 0, 14)
12:51:19 WORKER: args: ()
12:51:19 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.006899124390242902, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.0297462742583842, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 90, 'num_filters_3': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:51:58 DISPATCHER: Starting worker discovery
12:51:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:51:58 DISPATCHER: Finished worker discovery
12:52:58 DISPATCHER: Starting worker discovery
12:52:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:52:58 DISPATCHER: Finished worker discovery
12:53:53 WORKER: done with job (0, 0, 14), trying to register it.
12:53:53 WORKER: registered result for job (0, 0, 14) with dispatcher
12:53:53 DISPATCHER: job (0, 0, 14) finished
12:53:53 DISPATCHER: register_result: lock acquired
12:53:53 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:53:53 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.006899124390242902, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.0297462742583842, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 90, 'num_filters_3': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.04788521040326391, 'info': {'data04': 0.04788521040326391, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.006899124390242902, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.0297462742583842, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 90, 'num_filters_3': 17}"}}
exception: None

12:53:53 job_callback for (0, 0, 14) started
12:53:53 DISPATCHER: Trying to submit another job.
12:53:53 job_callback for (0, 0, 14) got condition
12:53:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:53:53 Only 7 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:53:53 HBMASTER: Trying to run another job!
12:53:53 job_callback for (0, 0, 14) finished
12:53:53 HBMASTER: schedule new run for iteration 0
12:53:53 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
12:53:53 HBMASTER: submitting job (0, 0, 16) to dispatcher
12:53:53 DISPATCHER: trying to submit job (0, 0, 16)
12:53:53 DISPATCHER: trying to notify the job_runner thread.
12:53:53 HBMASTER: job (0, 0, 16) submitted to dispatcher
12:53:53 DISPATCHER: Trying to submit another job.
12:53:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:53:53 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:53:53 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:53:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:53:53 WORKER: start processing job (0, 0, 16)
12:53:53 WORKER: args: ()
12:53:53 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.02253863778339907, 'num_filters_1': 49, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.021983810198382907, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 80, 'num_filters_3': 83, 'num_filters_4': 36, 'num_filters_5': 16}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:53:58 DISPATCHER: Starting worker discovery
12:53:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:53:58 DISPATCHER: Finished worker discovery
12:54:58 DISPATCHER: Starting worker discovery
12:54:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:54:58 DISPATCHER: Finished worker discovery
12:55:58 DISPATCHER: Starting worker discovery
12:55:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:55:58 DISPATCHER: Finished worker discovery
12:56:31 WORKER: done with job (0, 0, 16), trying to register it.
12:56:31 WORKER: registered result for job (0, 0, 16) with dispatcher
12:56:31 DISPATCHER: job (0, 0, 16) finished
12:56:31 DISPATCHER: register_result: lock acquired
12:56:31 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:56:31 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.02253863778339907, 'num_filters_1': 49, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.021983810198382907, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 80, 'num_filters_3': 83, 'num_filters_4': 36, 'num_filters_5': 16}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.006554695875839925, 'info': {'data04': 0.006554695875839925, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.02253863778339907, 'num_filters_1': 49, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.021983810198382907, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 80, 'num_filters_3': 83, 'num_filters_4': 36, 'num_filters_5': 16}"}}
exception: None

12:56:31 job_callback for (0, 0, 16) started
12:56:31 DISPATCHER: Trying to submit another job.
12:56:31 job_callback for (0, 0, 16) got condition
12:56:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:56:31 Only 8 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:56:31 HBMASTER: Trying to run another job!
12:56:31 job_callback for (0, 0, 16) finished
12:56:31 HBMASTER: schedule new run for iteration 0
12:56:31 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
12:56:31 HBMASTER: submitting job (0, 0, 19) to dispatcher
12:56:31 DISPATCHER: trying to submit job (0, 0, 19)
12:56:31 DISPATCHER: trying to notify the job_runner thread.
12:56:31 HBMASTER: job (0, 0, 19) submitted to dispatcher
12:56:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:56:31 DISPATCHER: Trying to submit another job.
12:56:31 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:56:31 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:56:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:56:31 WORKER: start processing job (0, 0, 19)
12:56:31 WORKER: args: ()
12:56:31 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0017601376825632543, 'num_filters_1': 57, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.03006980780957016, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 122, 'num_filters_3': 98, 'num_filters_4': 87}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:56:58 DISPATCHER: Starting worker discovery
12:56:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:56:58 DISPATCHER: Finished worker discovery
12:57:58 DISPATCHER: Starting worker discovery
12:57:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:57:58 DISPATCHER: Finished worker discovery
12:58:58 DISPATCHER: Starting worker discovery
12:58:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:58:58 DISPATCHER: Finished worker discovery
12:59:07 WORKER: done with job (0, 0, 19), trying to register it.
12:59:07 WORKER: registered result for job (0, 0, 19) with dispatcher
12:59:07 DISPATCHER: job (0, 0, 19) finished
12:59:07 DISPATCHER: register_result: lock acquired
12:59:07 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:59:07 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0017601376825632543, 'num_filters_1': 57, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.03006980780957016, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 122, 'num_filters_3': 98, 'num_filters_4': 87}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.12657562030054836, 'info': {'data04': 0.12657562030054836, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0017601376825632543, 'num_filters_1': 57, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.03006980780957016, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 122, 'num_filters_3': 98, 'num_filters_4': 87}"}}
exception: None

12:59:07 job_callback for (0, 0, 19) started
12:59:07 DISPATCHER: Trying to submit another job.
12:59:07 job_callback for (0, 0, 19) got condition
12:59:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:59:07 Only 9 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
12:59:07 HBMASTER: Trying to run another job!
12:59:07 job_callback for (0, 0, 19) finished
12:59:07 ITERATION: Advancing config (0, 0, 2) to next budget 400.000000
12:59:07 ITERATION: Advancing config (0, 0, 11) to next budget 400.000000
12:59:07 ITERATION: Advancing config (0, 0, 19) to next budget 400.000000
12:59:07 HBMASTER: schedule new run for iteration 0
12:59:07 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
12:59:07 HBMASTER: submitting job (0, 0, 2) to dispatcher
12:59:07 DISPATCHER: trying to submit job (0, 0, 2)
12:59:07 DISPATCHER: trying to notify the job_runner thread.
12:59:07 HBMASTER: job (0, 0, 2) submitted to dispatcher
12:59:07 DISPATCHER: Trying to submit another job.
12:59:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:59:07 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:59:07 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:59:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:59:07 WORKER: start processing job (0, 0, 2)
12:59:07 WORKER: args: ()
12:59:07 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0018427867735740864, 'num_filters_1': 58, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.018124338555921205, 'kernel_size_2': 5, 'num_filters_2': 19}, 'budget': 400.0, 'working_directory': '.'}
12:59:58 DISPATCHER: Starting worker discovery
12:59:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:59:58 DISPATCHER: Finished worker discovery
13:00:58 DISPATCHER: Starting worker discovery
13:00:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:00:58 DISPATCHER: Finished worker discovery
13:01:58 DISPATCHER: Starting worker discovery
13:01:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:01:58 DISPATCHER: Finished worker discovery
13:02:58 DISPATCHER: Starting worker discovery
13:02:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:02:58 DISPATCHER: Finished worker discovery
13:03:58 DISPATCHER: Starting worker discovery
13:03:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:03:58 DISPATCHER: Finished worker discovery
13:04:58 DISPATCHER: Starting worker discovery
13:04:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:04:58 DISPATCHER: Finished worker discovery
13:05:58 DISPATCHER: Starting worker discovery
13:05:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:05:58 DISPATCHER: Finished worker discovery
13:06:58 DISPATCHER: Starting worker discovery
13:06:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:06:58 DISPATCHER: Finished worker discovery
13:07:12 WORKER: done with job (0, 0, 2), trying to register it.
13:07:12 WORKER: registered result for job (0, 0, 2) with dispatcher
13:07:12 DISPATCHER: job (0, 0, 2) finished
13:07:12 DISPATCHER: register_result: lock acquired
13:07:12 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
13:07:12 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0018427867735740864, 'num_filters_1': 58, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.018124338555921205, 'kernel_size_2': 5, 'num_filters_2': 19}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.1229485525213442, 'info': {'data04': 0.1229485525213442, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0018427867735740864, 'num_filters_1': 58, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.018124338555921205, 'kernel_size_2': 5, 'num_filters_2': 19}"}}
exception: None

13:07:12 job_callback for (0, 0, 2) started
13:07:12 job_callback for (0, 0, 2) got condition
13:07:12 DISPATCHER: Trying to submit another job.
13:07:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:07:12 Only 1 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
13:07:12 HBMASTER: Trying to run another job!
13:07:12 job_callback for (0, 0, 2) finished
13:07:12 HBMASTER: schedule new run for iteration 0
13:07:12 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
13:07:12 HBMASTER: submitting job (0, 0, 11) to dispatcher
13:07:12 DISPATCHER: trying to submit job (0, 0, 11)
13:07:12 DISPATCHER: trying to notify the job_runner thread.
13:07:12 HBMASTER: job (0, 0, 11) submitted to dispatcher
13:07:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:07:12 DISPATCHER: Trying to submit another job.
13:07:12 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:07:12 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:07:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:07:12 WORKER: start processing job (0, 0, 11)
13:07:12 WORKER: args: ()
13:07:12 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.022473827077780176, 'num_filters_1': 60, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.017386036742530447}, 'budget': 400.0, 'working_directory': '.'}
13:07:58 DISPATCHER: Starting worker discovery
13:07:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:07:58 DISPATCHER: Finished worker discovery
13:08:58 DISPATCHER: Starting worker discovery
13:08:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:08:58 DISPATCHER: Finished worker discovery
13:09:58 DISPATCHER: Starting worker discovery
13:09:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:09:58 DISPATCHER: Finished worker discovery
13:10:58 DISPATCHER: Starting worker discovery
13:10:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:10:58 DISPATCHER: Finished worker discovery
13:11:58 DISPATCHER: Starting worker discovery
13:11:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:11:58 DISPATCHER: Finished worker discovery
13:12:58 DISPATCHER: Starting worker discovery
13:12:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:12:58 DISPATCHER: Finished worker discovery
13:13:58 DISPATCHER: Starting worker discovery
13:13:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:13:58 DISPATCHER: Finished worker discovery
13:14:58 DISPATCHER: Starting worker discovery
13:14:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:14:58 DISPATCHER: Finished worker discovery
13:15:18 WORKER: done with job (0, 0, 11), trying to register it.
13:15:18 WORKER: registered result for job (0, 0, 11) with dispatcher
13:15:18 DISPATCHER: job (0, 0, 11) finished
13:15:18 DISPATCHER: register_result: lock acquired
13:15:18 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
13:15:18 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.022473827077780176, 'num_filters_1': 60, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.017386036742530447}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.12472205991652247, 'info': {'data04': 0.12472205991652247, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.022473827077780176, 'num_filters_1': 60, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.017386036742530447}"}}
exception: None

13:15:18 job_callback for (0, 0, 11) started
13:15:18 job_callback for (0, 0, 11) got condition
13:15:18 DISPATCHER: Trying to submit another job.
13:15:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:15:18 Only 2 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
13:15:18 HBMASTER: Trying to run another job!
13:15:18 job_callback for (0, 0, 11) finished
13:15:18 HBMASTER: schedule new run for iteration 0
13:15:18 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
13:15:18 HBMASTER: submitting job (0, 0, 19) to dispatcher
13:15:18 DISPATCHER: trying to submit job (0, 0, 19)
13:15:18 DISPATCHER: trying to notify the job_runner thread.
13:15:18 HBMASTER: job (0, 0, 19) submitted to dispatcher
13:15:18 DISPATCHER: Trying to submit another job.
13:15:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:15:18 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:15:18 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:15:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:15:18 WORKER: start processing job (0, 0, 19)
13:15:18 WORKER: args: ()
13:15:18 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0017601376825632543, 'num_filters_1': 57, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.03006980780957016, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 122, 'num_filters_3': 98, 'num_filters_4': 87}, 'budget': 400.0, 'working_directory': '.'}
13:15:58 DISPATCHER: Starting worker discovery
13:15:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:15:58 DISPATCHER: Finished worker discovery
13:16:58 DISPATCHER: Starting worker discovery
13:16:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:16:58 DISPATCHER: Finished worker discovery
13:17:58 DISPATCHER: Starting worker discovery
13:17:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:17:58 DISPATCHER: Finished worker discovery
13:18:58 DISPATCHER: Starting worker discovery
13:18:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:18:58 DISPATCHER: Finished worker discovery
13:19:58 DISPATCHER: Starting worker discovery
13:19:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:19:58 DISPATCHER: Finished worker discovery
13:20:58 DISPATCHER: Starting worker discovery
13:20:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:20:58 DISPATCHER: Finished worker discovery
13:21:58 DISPATCHER: Starting worker discovery
13:21:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:21:58 DISPATCHER: Finished worker discovery
13:22:37 WORKER: done with job (0, 0, 19), trying to register it.
13:22:37 WORKER: registered result for job (0, 0, 19) with dispatcher
13:22:37 DISPATCHER: job (0, 0, 19) finished
13:22:37 DISPATCHER: register_result: lock acquired
13:22:37 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
13:22:37 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0017601376825632543, 'num_filters_1': 57, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.03006980780957016, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 122, 'num_filters_3': 98, 'num_filters_4': 87}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.04341924124506819, 'info': {'data04': 0.04341924124506819, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0017601376825632543, 'num_filters_1': 57, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.03006980780957016, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 122, 'num_filters_3': 98, 'num_filters_4': 87}"}}
exception: None

13:22:37 job_callback for (0, 0, 19) started
13:22:37 DISPATCHER: Trying to submit another job.
13:22:37 job_callback for (0, 0, 19) got condition
13:22:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:22:37 Only 3 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
13:22:37 HBMASTER: Trying to run another job!
13:22:37 job_callback for (0, 0, 19) finished
13:22:37 ITERATION: Advancing config (0, 0, 11) to next budget 1200.000000
13:22:37 HBMASTER: schedule new run for iteration 0
13:22:37 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
13:22:37 HBMASTER: submitting job (0, 0, 11) to dispatcher
13:22:37 DISPATCHER: trying to submit job (0, 0, 11)
13:22:37 DISPATCHER: trying to notify the job_runner thread.
13:22:37 HBMASTER: job (0, 0, 11) submitted to dispatcher
13:22:37 DISPATCHER: Trying to submit another job.
13:22:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:22:37 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:22:37 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:22:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:22:37 WORKER: start processing job (0, 0, 11)
13:22:37 WORKER: args: ()
13:22:37 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.022473827077780176, 'num_filters_1': 60, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.017386036742530447}, 'budget': 1200.0, 'working_directory': '.'}
13:22:58 DISPATCHER: Starting worker discovery
13:22:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:22:58 DISPATCHER: Finished worker discovery
13:23:58 DISPATCHER: Starting worker discovery
13:23:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:23:58 DISPATCHER: Finished worker discovery
13:24:58 DISPATCHER: Starting worker discovery
13:24:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:24:58 DISPATCHER: Finished worker discovery
13:25:58 DISPATCHER: Starting worker discovery
13:25:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:25:58 DISPATCHER: Finished worker discovery
13:26:58 DISPATCHER: Starting worker discovery
13:26:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:26:58 DISPATCHER: Finished worker discovery
13:27:58 DISPATCHER: Starting worker discovery
13:27:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:27:58 DISPATCHER: Finished worker discovery
13:28:58 DISPATCHER: Starting worker discovery
13:28:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:28:58 DISPATCHER: Finished worker discovery
13:29:58 DISPATCHER: Starting worker discovery
13:29:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:29:58 DISPATCHER: Finished worker discovery
13:30:58 DISPATCHER: Starting worker discovery
13:30:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:30:58 DISPATCHER: Finished worker discovery
13:31:58 DISPATCHER: Starting worker discovery
13:31:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:31:58 DISPATCHER: Finished worker discovery
13:32:58 DISPATCHER: Starting worker discovery
13:32:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:32:58 DISPATCHER: Finished worker discovery
13:33:58 DISPATCHER: Starting worker discovery
13:33:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:33:58 DISPATCHER: Finished worker discovery
13:34:58 DISPATCHER: Starting worker discovery
13:34:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:34:58 DISPATCHER: Finished worker discovery
13:35:58 DISPATCHER: Starting worker discovery
13:35:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:35:58 DISPATCHER: Finished worker discovery
13:36:58 DISPATCHER: Starting worker discovery
13:36:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:36:58 DISPATCHER: Finished worker discovery
13:37:58 DISPATCHER: Starting worker discovery
13:37:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:37:58 DISPATCHER: Finished worker discovery
13:38:58 DISPATCHER: Starting worker discovery
13:38:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:38:59 DISPATCHER: Finished worker discovery
13:39:59 DISPATCHER: Starting worker discovery
13:39:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:39:59 DISPATCHER: Finished worker discovery
13:40:59 DISPATCHER: Starting worker discovery
13:40:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:40:59 DISPATCHER: Finished worker discovery
13:41:59 DISPATCHER: Starting worker discovery
13:41:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:41:59 DISPATCHER: Finished worker discovery
13:42:59 DISPATCHER: Starting worker discovery
13:42:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:42:59 DISPATCHER: Finished worker discovery
13:43:59 DISPATCHER: Starting worker discovery
13:43:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:43:59 DISPATCHER: Finished worker discovery
13:44:59 DISPATCHER: Starting worker discovery
13:44:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:44:59 DISPATCHER: Finished worker discovery
13:45:59 DISPATCHER: Starting worker discovery
13:45:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:45:59 DISPATCHER: Finished worker discovery
13:46:27 WORKER: done with job (0, 0, 11), trying to register it.
13:46:27 WORKER: registered result for job (0, 0, 11) with dispatcher
13:46:27 DISPATCHER: job (0, 0, 11) finished
13:46:27 DISPATCHER: register_result: lock acquired
13:46:27 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
13:46:27 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.022473827077780176, 'num_filters_1': 60, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.017386036742530447}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.11606855774079568, 'info': {'data04': 0.11606855774079568, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.022473827077780176, 'num_filters_1': 60, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.017386036742530447}"}}
exception: None

13:46:27 job_callback for (0, 0, 11) started
13:46:27 job_callback for (0, 0, 11) got condition
13:46:27 DISPATCHER: Trying to submit another job.
13:46:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:46:27 Only 1 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
13:46:27 HBMASTER: Trying to run another job!
13:46:27 job_callback for (0, 0, 11) finished
13:46:27 start sampling a new configuration.
13:46:27 done sampling a new configuration.
13:46:27 HBMASTER: schedule new run for iteration 1
13:46:27 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
13:46:27 HBMASTER: submitting job (1, 0, 0) to dispatcher
13:46:27 DISPATCHER: trying to submit job (1, 0, 0)
13:46:27 DISPATCHER: trying to notify the job_runner thread.
13:46:27 HBMASTER: job (1, 0, 0) submitted to dispatcher
13:46:27 DISPATCHER: Trying to submit another job.
13:46:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:46:27 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:46:27 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:46:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:46:27 WORKER: start processing job (1, 0, 0)
13:46:27 WORKER: args: ()
13:46:27 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004130788241532912, 'num_filters_1': 31, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.018897818296464506}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:46:59 DISPATCHER: Starting worker discovery
13:46:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:46:59 DISPATCHER: Finished worker discovery
13:47:59 DISPATCHER: Starting worker discovery
13:47:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:47:59 DISPATCHER: Finished worker discovery
13:48:59 DISPATCHER: Starting worker discovery
13:48:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:48:59 DISPATCHER: Finished worker discovery
13:49:03 WORKER: done with job (1, 0, 0), trying to register it.
13:49:03 WORKER: registered result for job (1, 0, 0) with dispatcher
13:49:03 DISPATCHER: job (1, 0, 0) finished
13:49:03 DISPATCHER: register_result: lock acquired
13:49:03 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
13:49:03 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004130788241532912, 'num_filters_1': 31, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.018897818296464506}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.14444234115676385, 'info': {'data04': 0.14444234115676385, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004130788241532912, 'num_filters_1': 31, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.018897818296464506}"}}
exception: None

13:49:03 job_callback for (1, 0, 0) started
13:49:03 DISPATCHER: Trying to submit another job.
13:49:03 job_callback for (1, 0, 0) got condition
13:49:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:49:03 Only 10 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
13:49:03 HBMASTER: Trying to run another job!
13:49:03 job_callback for (1, 0, 0) finished
13:49:03 start sampling a new configuration.
13:49:03 done sampling a new configuration.
13:49:03 HBMASTER: schedule new run for iteration 1
13:49:03 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
13:49:03 HBMASTER: submitting job (1, 0, 1) to dispatcher
13:49:03 DISPATCHER: trying to submit job (1, 0, 1)
13:49:03 DISPATCHER: trying to notify the job_runner thread.
13:49:03 HBMASTER: job (1, 0, 1) submitted to dispatcher
13:49:03 DISPATCHER: Trying to submit another job.
13:49:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:49:03 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:49:03 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:49:03 WORKER: start processing job (1, 0, 1)
13:49:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:49:03 WORKER: args: ()
13:49:03 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0038797197427687335, 'num_filters_1': 92, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.012786805768242081, 'kernel_size_2': 3, 'num_filters_2': 21}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:49:59 DISPATCHER: Starting worker discovery
13:49:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:49:59 DISPATCHER: Finished worker discovery
13:50:59 DISPATCHER: Starting worker discovery
13:50:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:50:59 DISPATCHER: Finished worker discovery
13:51:42 WORKER: done with job (1, 0, 1), trying to register it.
13:51:42 WORKER: registered result for job (1, 0, 1) with dispatcher
13:51:42 DISPATCHER: job (1, 0, 1) finished
13:51:42 DISPATCHER: register_result: lock acquired
13:51:42 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
13:51:42 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0038797197427687335, 'num_filters_1': 92, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.012786805768242081, 'kernel_size_2': 3, 'num_filters_2': 21}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.04747824609543231, 'info': {'data04': 0.04747824609543231, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0038797197427687335, 'num_filters_1': 92, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.012786805768242081, 'kernel_size_2': 3, 'num_filters_2': 21}"}}
exception: None

13:51:42 job_callback for (1, 0, 1) started
13:51:42 DISPATCHER: Trying to submit another job.
13:51:42 job_callback for (1, 0, 1) got condition
13:51:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:51:42 Only 11 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
13:51:42 HBMASTER: Trying to run another job!
13:51:42 job_callback for (1, 0, 1) finished
13:51:42 start sampling a new configuration.
13:51:42 done sampling a new configuration.
13:51:42 HBMASTER: schedule new run for iteration 1
13:51:42 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
13:51:42 HBMASTER: submitting job (1, 0, 2) to dispatcher
13:51:42 DISPATCHER: trying to submit job (1, 0, 2)
13:51:42 DISPATCHER: trying to notify the job_runner thread.
13:51:42 HBMASTER: job (1, 0, 2) submitted to dispatcher
13:51:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:51:42 DISPATCHER: Trying to submit another job.
13:51:42 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:51:42 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:51:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:51:42 WORKER: start processing job (1, 0, 2)
13:51:42 WORKER: args: ()
13:51:42 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.023618251443218073, 'num_filters_1': 44, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.07633261844540856, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 55, 'num_filters_3': 37, 'num_filters_4': 19, 'num_filters_5': 68}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:51:59 DISPATCHER: Starting worker discovery
13:51:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:51:59 DISPATCHER: Finished worker discovery
13:52:59 DISPATCHER: Starting worker discovery
13:52:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:52:59 DISPATCHER: Finished worker discovery
13:53:59 DISPATCHER: Starting worker discovery
13:54:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:54:00 DISPATCHER: Finished worker discovery
13:54:58 WORKER: done with job (1, 0, 2), trying to register it.
13:54:58 WORKER: registered result for job (1, 0, 2) with dispatcher
13:54:58 DISPATCHER: job (1, 0, 2) finished
13:54:58 DISPATCHER: register_result: lock acquired
13:54:58 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
13:54:58 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.023618251443218073, 'num_filters_1': 44, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.07633261844540856, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 55, 'num_filters_3': 37, 'num_filters_4': 19, 'num_filters_5': 68}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -1.6529099578620093e-05, 'info': {'data04': 1.6529099578620093e-05, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.023618251443218073, 'num_filters_1': 44, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.07633261844540856, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 55, 'num_filters_3': 37, 'num_filters_4': 19, 'num_filters_5': 68}"}}
exception: None

13:54:58 job_callback for (1, 0, 2) started
13:54:58 job_callback for (1, 0, 2) got condition
13:54:58 DISPATCHER: Trying to submit another job.
13:54:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:54:58 Only 12 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
13:54:58 HBMASTER: Trying to run another job!
13:54:58 job_callback for (1, 0, 2) finished
13:54:58 start sampling a new configuration.
13:54:58 done sampling a new configuration.
13:54:58 HBMASTER: schedule new run for iteration 1
13:54:58 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
13:54:58 HBMASTER: submitting job (1, 0, 3) to dispatcher
13:54:58 DISPATCHER: trying to submit job (1, 0, 3)
13:54:58 DISPATCHER: trying to notify the job_runner thread.
13:54:58 HBMASTER: job (1, 0, 3) submitted to dispatcher
13:54:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:54:58 DISPATCHER: Trying to submit another job.
13:54:58 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:54:58 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:54:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:54:58 WORKER: start processing job (1, 0, 3)
13:54:58 WORKER: args: ()
13:54:58 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.023605907070225057, 'num_filters_1': 125, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.013101422350810733, 'kernel_size_2': 7, 'num_filters_2': 100}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:55:00 DISPATCHER: Starting worker discovery
13:55:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:55:00 DISPATCHER: Finished worker discovery
13:56:00 DISPATCHER: Starting worker discovery
13:56:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:56:00 DISPATCHER: Finished worker discovery
13:57:00 DISPATCHER: Starting worker discovery
13:57:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:57:00 DISPATCHER: Finished worker discovery
13:58:00 DISPATCHER: Starting worker discovery
13:58:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:58:00 DISPATCHER: Finished worker discovery
13:58:14 WORKER: done with job (1, 0, 3), trying to register it.
13:58:14 WORKER: registered result for job (1, 0, 3) with dispatcher
13:58:14 DISPATCHER: job (1, 0, 3) finished
13:58:14 DISPATCHER: register_result: lock acquired
13:58:14 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
13:58:14 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.023605907070225057, 'num_filters_1': 125, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.013101422350810733, 'kernel_size_2': 7, 'num_filters_2': 100}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.11763224106469458, 'info': {'data04': 0.11763224106469458, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.023605907070225057, 'num_filters_1': 125, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.013101422350810733, 'kernel_size_2': 7, 'num_filters_2': 100}"}}
exception: None

13:58:14 job_callback for (1, 0, 3) started
13:58:14 job_callback for (1, 0, 3) got condition
13:58:14 DISPATCHER: Trying to submit another job.
13:58:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:58:14 Only 13 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
13:58:14 HBMASTER: Trying to run another job!
13:58:14 job_callback for (1, 0, 3) finished
13:58:14 start sampling a new configuration.
13:58:14 done sampling a new configuration.
13:58:14 HBMASTER: schedule new run for iteration 1
13:58:14 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
13:58:14 HBMASTER: submitting job (1, 0, 4) to dispatcher
13:58:14 DISPATCHER: trying to submit job (1, 0, 4)
13:58:14 DISPATCHER: trying to notify the job_runner thread.
13:58:14 HBMASTER: job (1, 0, 4) submitted to dispatcher
13:58:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:58:14 DISPATCHER: Trying to submit another job.
13:58:14 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:58:14 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:58:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:58:14 WORKER: start processing job (1, 0, 4)
13:58:14 WORKER: args: ()
13:58:14 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0029134895342308237, 'num_filters_1': 106, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.16710768392132622, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 54, 'num_filters_3': 25, 'num_filters_4': 32, 'num_filters_5': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:59:00 DISPATCHER: Starting worker discovery
13:59:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:59:00 DISPATCHER: Finished worker discovery
14:00:00 DISPATCHER: Starting worker discovery
14:00:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:00:00 DISPATCHER: Finished worker discovery
14:00:47 WORKER: done with job (1, 0, 4), trying to register it.
14:00:47 WORKER: registered result for job (1, 0, 4) with dispatcher
14:00:47 DISPATCHER: job (1, 0, 4) finished
14:00:47 DISPATCHER: register_result: lock acquired
14:00:47 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
14:00:47 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0029134895342308237, 'num_filters_1': 106, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.16710768392132622, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 54, 'num_filters_3': 25, 'num_filters_4': 32, 'num_filters_5': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.000297357456603158, 'info': {'data04': 0.000297357456603158, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0029134895342308237, 'num_filters_1': 106, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.16710768392132622, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 54, 'num_filters_3': 25, 'num_filters_4': 32, 'num_filters_5': 26}"}}
exception: None

14:00:47 job_callback for (1, 0, 4) started
14:00:47 DISPATCHER: Trying to submit another job.
14:00:47 job_callback for (1, 0, 4) got condition
14:00:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:00:47 Only 14 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
14:00:47 HBMASTER: Trying to run another job!
14:00:47 job_callback for (1, 0, 4) finished
14:00:47 start sampling a new configuration.
14:00:47 done sampling a new configuration.
14:00:47 HBMASTER: schedule new run for iteration 1
14:00:47 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
14:00:47 HBMASTER: submitting job (1, 0, 5) to dispatcher
14:00:47 DISPATCHER: trying to submit job (1, 0, 5)
14:00:47 DISPATCHER: trying to notify the job_runner thread.
14:00:47 HBMASTER: job (1, 0, 5) submitted to dispatcher
14:00:47 DISPATCHER: Trying to submit another job.
14:00:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:00:47 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:00:47 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:00:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:00:47 WORKER: start processing job (1, 0, 5)
14:00:47 WORKER: args: ()
14:00:47 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.06649425979078509, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.0429353852274808, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 18, 'num_filters_3': 120, 'num_filters_4': 32, 'num_filters_5': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:01:00 DISPATCHER: Starting worker discovery
14:01:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:01:00 DISPATCHER: Finished worker discovery
14:02:00 DISPATCHER: Starting worker discovery
14:02:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:02:00 DISPATCHER: Finished worker discovery
14:03:00 DISPATCHER: Starting worker discovery
14:03:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:03:00 DISPATCHER: Finished worker discovery
14:03:25 WORKER: done with job (1, 0, 5), trying to register it.
14:03:25 WORKER: registered result for job (1, 0, 5) with dispatcher
14:03:25 DISPATCHER: job (1, 0, 5) finished
14:03:25 DISPATCHER: register_result: lock acquired
14:03:25 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
14:03:25 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.06649425979078509, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.0429353852274808, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 18, 'num_filters_3': 120, 'num_filters_4': 32, 'num_filters_5': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.00038630677996648994, 'info': {'data04': 0.00038630677996648994, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.06649425979078509, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.0429353852274808, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 18, 'num_filters_3': 120, 'num_filters_4': 32, 'num_filters_5': 17}"}}
exception: None

14:03:25 job_callback for (1, 0, 5) started
14:03:25 DISPATCHER: Trying to submit another job.
14:03:25 job_callback for (1, 0, 5) got condition
14:03:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:03:25 Only 15 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
14:03:25 HBMASTER: Trying to run another job!
14:03:25 job_callback for (1, 0, 5) finished
14:03:25 start sampling a new configuration.
14:03:25 done sampling a new configuration.
14:03:25 HBMASTER: schedule new run for iteration 1
14:03:25 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
14:03:25 HBMASTER: submitting job (1, 0, 6) to dispatcher
14:03:25 DISPATCHER: trying to submit job (1, 0, 6)
14:03:25 DISPATCHER: trying to notify the job_runner thread.
14:03:25 HBMASTER: job (1, 0, 6) submitted to dispatcher
14:03:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:03:25 DISPATCHER: Trying to submit another job.
14:03:25 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:03:25 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:03:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:03:25 WORKER: start processing job (1, 0, 6)
14:03:25 WORKER: args: ()
14:03:25 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.04236351369204513, 'num_filters_1': 77, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.011633337593400642, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 54, 'num_filters_3': 63, 'num_filters_4': 101}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:04:00 DISPATCHER: Starting worker discovery
14:04:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:04:00 DISPATCHER: Finished worker discovery
14:05:00 DISPATCHER: Starting worker discovery
14:05:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:05:00 DISPATCHER: Finished worker discovery
14:05:58 WORKER: done with job (1, 0, 6), trying to register it.
14:05:58 WORKER: registered result for job (1, 0, 6) with dispatcher
14:05:58 DISPATCHER: job (1, 0, 6) finished
14:05:58 DISPATCHER: register_result: lock acquired
14:05:58 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
14:05:58 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.04236351369204513, 'num_filters_1': 77, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.011633337593400642, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 54, 'num_filters_3': 63, 'num_filters_4': 101}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': 0.00024916562617398466, 'info': {'data04': -0.00024916562617398466, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.04236351369204513, 'num_filters_1': 77, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.011633337593400642, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 54, 'num_filters_3': 63, 'num_filters_4': 101}"}}
exception: None

14:05:58 job_callback for (1, 0, 6) started
14:05:58 job_callback for (1, 0, 6) got condition
14:05:58 DISPATCHER: Trying to submit another job.
14:05:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:05:58 Only 16 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
14:05:58 HBMASTER: Trying to run another job!
14:05:58 job_callback for (1, 0, 6) finished
14:05:58 start sampling a new configuration.
14:05:58 done sampling a new configuration.
14:05:58 HBMASTER: schedule new run for iteration 1
14:05:58 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
14:05:58 HBMASTER: submitting job (1, 0, 7) to dispatcher
14:05:58 DISPATCHER: trying to submit job (1, 0, 7)
14:05:58 DISPATCHER: trying to notify the job_runner thread.
14:05:58 HBMASTER: job (1, 0, 7) submitted to dispatcher
14:05:58 DISPATCHER: Trying to submit another job.
14:05:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:05:58 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:05:58 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:05:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:05:58 WORKER: start processing job (1, 0, 7)
14:05:58 WORKER: args: ()
14:05:58 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.005216911173257216, 'num_filters_1': 111, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.051628755769803955, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 34, 'num_filters_3': 122, 'num_filters_4': 45}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:06:00 DISPATCHER: Starting worker discovery
14:06:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:06:00 DISPATCHER: Finished worker discovery
14:07:00 DISPATCHER: Starting worker discovery
14:07:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:07:00 DISPATCHER: Finished worker discovery
14:08:00 DISPATCHER: Starting worker discovery
14:08:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:08:00 DISPATCHER: Finished worker discovery
14:08:51 WORKER: done with job (1, 0, 7), trying to register it.
14:08:51 WORKER: registered result for job (1, 0, 7) with dispatcher
14:08:51 DISPATCHER: job (1, 0, 7) finished
14:08:51 DISPATCHER: register_result: lock acquired
14:08:51 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
14:08:51 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.005216911173257216, 'num_filters_1': 111, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.051628755769803955, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 34, 'num_filters_3': 122, 'num_filters_4': 45}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.003569279255079693, 'info': {'data04': 0.003569279255079693, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.005216911173257216, 'num_filters_1': 111, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.051628755769803955, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 34, 'num_filters_3': 122, 'num_filters_4': 45}"}}
exception: None

14:08:51 job_callback for (1, 0, 7) started
14:08:51 DISPATCHER: Trying to submit another job.
14:08:51 job_callback for (1, 0, 7) got condition
14:08:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:08:51 HBMASTER: Trying to run another job!
14:08:51 job_callback for (1, 0, 7) finished
14:08:51 start sampling a new configuration.
14:08:51 done sampling a new configuration.
14:08:51 HBMASTER: schedule new run for iteration 1
14:08:51 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
14:08:51 HBMASTER: submitting job (1, 0, 8) to dispatcher
14:08:51 DISPATCHER: trying to submit job (1, 0, 8)
14:08:51 DISPATCHER: trying to notify the job_runner thread.
14:08:51 HBMASTER: job (1, 0, 8) submitted to dispatcher
14:08:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:08:51 DISPATCHER: Trying to submit another job.
14:08:51 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:08:51 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:08:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:08:51 WORKER: start processing job (1, 0, 8)
14:08:51 WORKER: args: ()
14:08:51 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.003560754961132499, 'num_filters_1': 42, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.19456416306263938, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 63, 'num_filters_3': 20, 'num_filters_4': 101, 'num_filters_5': 27}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:09:00 DISPATCHER: Starting worker discovery
14:09:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:09:00 DISPATCHER: Finished worker discovery
14:10:00 DISPATCHER: Starting worker discovery
14:10:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:10:00 DISPATCHER: Finished worker discovery
14:11:00 DISPATCHER: Starting worker discovery
14:11:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:11:00 DISPATCHER: Finished worker discovery
14:11:22 WORKER: done with job (1, 0, 8), trying to register it.
14:11:22 WORKER: registered result for job (1, 0, 8) with dispatcher
14:11:22 DISPATCHER: job (1, 0, 8) finished
14:11:22 DISPATCHER: register_result: lock acquired
14:11:22 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
14:11:22 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.003560754961132499, 'num_filters_1': 42, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.19456416306263938, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 63, 'num_filters_3': 20, 'num_filters_4': 101, 'num_filters_5': 27}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': 2.6193785175381193e-05, 'info': {'data04': -2.6193785175381193e-05, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.003560754961132499, 'num_filters_1': 42, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.19456416306263938, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 63, 'num_filters_3': 20, 'num_filters_4': 101, 'num_filters_5': 27}"}}
exception: None

14:11:22 job_callback for (1, 0, 8) started
14:11:22 job_callback for (1, 0, 8) got condition
14:11:22 DISPATCHER: Trying to submit another job.
14:11:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:11:22 HBMASTER: Trying to run another job!
14:11:22 job_callback for (1, 0, 8) finished
14:11:22 ITERATION: Advancing config (1, 0, 0) to next budget 400.000000
14:11:22 ITERATION: Advancing config (1, 0, 1) to next budget 400.000000
14:11:22 ITERATION: Advancing config (1, 0, 3) to next budget 400.000000
14:11:22 HBMASTER: schedule new run for iteration 1
14:11:22 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
14:11:22 HBMASTER: submitting job (1, 0, 0) to dispatcher
14:11:22 DISPATCHER: trying to submit job (1, 0, 0)
14:11:22 DISPATCHER: trying to notify the job_runner thread.
14:11:22 HBMASTER: job (1, 0, 0) submitted to dispatcher
14:11:22 DISPATCHER: Trying to submit another job.
14:11:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:11:22 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:11:23 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:11:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:11:23 WORKER: start processing job (1, 0, 0)
14:11:23 WORKER: args: ()
14:11:23 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004130788241532912, 'num_filters_1': 31, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.018897818296464506}, 'budget': 400.0, 'working_directory': '.'}
14:12:00 DISPATCHER: Starting worker discovery
14:12:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:12:00 DISPATCHER: Finished worker discovery
14:13:00 DISPATCHER: Starting worker discovery
14:13:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:13:00 DISPATCHER: Finished worker discovery
14:14:00 DISPATCHER: Starting worker discovery
14:14:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:14:00 DISPATCHER: Finished worker discovery
14:15:00 DISPATCHER: Starting worker discovery
14:15:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:15:00 DISPATCHER: Finished worker discovery
14:16:00 DISPATCHER: Starting worker discovery
14:16:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:16:00 DISPATCHER: Finished worker discovery
14:17:00 DISPATCHER: Starting worker discovery
14:17:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:17:00 DISPATCHER: Finished worker discovery
14:18:00 DISPATCHER: Starting worker discovery
14:18:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:18:00 DISPATCHER: Finished worker discovery
14:18:43 WORKER: done with job (1, 0, 0), trying to register it.
14:18:43 WORKER: registered result for job (1, 0, 0) with dispatcher
14:18:43 DISPATCHER: job (1, 0, 0) finished
14:18:43 DISPATCHER: register_result: lock acquired
14:18:43 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
14:18:43 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004130788241532912, 'num_filters_1': 31, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.018897818296464506}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.12925433449026702, 'info': {'data04': 0.12925433449026702, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004130788241532912, 'num_filters_1': 31, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.018897818296464506}"}}
exception: None

14:18:43 job_callback for (1, 0, 0) started
14:18:43 job_callback for (1, 0, 0) got condition
14:18:43 DISPATCHER: Trying to submit another job.
14:18:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:18:43 Only 4 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
14:18:43 HBMASTER: Trying to run another job!
14:18:43 job_callback for (1, 0, 0) finished
14:18:43 HBMASTER: schedule new run for iteration 1
14:18:43 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
14:18:43 HBMASTER: submitting job (1, 0, 1) to dispatcher
14:18:43 DISPATCHER: trying to submit job (1, 0, 1)
14:18:43 DISPATCHER: trying to notify the job_runner thread.
14:18:43 HBMASTER: job (1, 0, 1) submitted to dispatcher
14:18:43 DISPATCHER: Trying to submit another job.
14:18:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:18:43 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:18:43 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:18:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:18:43 WORKER: start processing job (1, 0, 1)
14:18:43 WORKER: args: ()
14:18:43 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0038797197427687335, 'num_filters_1': 92, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.012786805768242081, 'kernel_size_2': 3, 'num_filters_2': 21}, 'budget': 400.0, 'working_directory': '.'}
14:19:00 DISPATCHER: Starting worker discovery
14:19:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:19:00 DISPATCHER: Finished worker discovery
14:20:00 DISPATCHER: Starting worker discovery
14:20:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:20:00 DISPATCHER: Finished worker discovery
14:21:00 DISPATCHER: Starting worker discovery
14:21:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:21:00 DISPATCHER: Finished worker discovery
14:22:00 DISPATCHER: Starting worker discovery
14:22:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:22:00 DISPATCHER: Finished worker discovery
14:23:00 DISPATCHER: Starting worker discovery
14:23:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:23:00 DISPATCHER: Finished worker discovery
14:24:00 DISPATCHER: Starting worker discovery
14:24:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:24:00 DISPATCHER: Finished worker discovery
14:25:00 DISPATCHER: Starting worker discovery
14:25:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:25:00 DISPATCHER: Finished worker discovery
14:26:00 DISPATCHER: Starting worker discovery
14:26:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:26:00 DISPATCHER: Finished worker discovery
14:26:12 WORKER: done with job (1, 0, 1), trying to register it.
14:26:12 WORKER: registered result for job (1, 0, 1) with dispatcher
14:26:12 DISPATCHER: job (1, 0, 1) finished
14:26:12 DISPATCHER: register_result: lock acquired
14:26:12 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
14:26:12 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0038797197427687335, 'num_filters_1': 92, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.012786805768242081, 'kernel_size_2': 3, 'num_filters_2': 21}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.08244547655914149, 'info': {'data04': 0.08244547655914149, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0038797197427687335, 'num_filters_1': 92, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.012786805768242081, 'kernel_size_2': 3, 'num_filters_2': 21}"}}
exception: None

14:26:12 job_callback for (1, 0, 1) started
14:26:12 job_callback for (1, 0, 1) got condition
14:26:12 DISPATCHER: Trying to submit another job.
14:26:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:26:12 Only 5 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
14:26:12 HBMASTER: Trying to run another job!
14:26:12 job_callback for (1, 0, 1) finished
14:26:12 HBMASTER: schedule new run for iteration 1
14:26:12 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
14:26:12 HBMASTER: submitting job (1, 0, 3) to dispatcher
14:26:12 DISPATCHER: trying to submit job (1, 0, 3)
14:26:12 DISPATCHER: trying to notify the job_runner thread.
14:26:12 HBMASTER: job (1, 0, 3) submitted to dispatcher
14:26:12 DISPATCHER: Trying to submit another job.
14:26:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:26:12 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:26:12 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:26:12 WORKER: start processing job (1, 0, 3)
14:26:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:26:12 WORKER: args: ()
14:26:12 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.023605907070225057, 'num_filters_1': 125, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.013101422350810733, 'kernel_size_2': 7, 'num_filters_2': 100}, 'budget': 400.0, 'working_directory': '.'}
14:27:00 DISPATCHER: Starting worker discovery
14:27:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:27:00 DISPATCHER: Finished worker discovery
14:28:00 DISPATCHER: Starting worker discovery
14:28:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:28:00 DISPATCHER: Finished worker discovery
14:29:00 DISPATCHER: Starting worker discovery
14:29:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:29:00 DISPATCHER: Finished worker discovery
14:30:00 DISPATCHER: Starting worker discovery
14:30:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:30:00 DISPATCHER: Finished worker discovery
14:31:00 DISPATCHER: Starting worker discovery
14:31:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:31:00 DISPATCHER: Finished worker discovery
14:32:00 DISPATCHER: Starting worker discovery
14:32:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:32:00 DISPATCHER: Finished worker discovery
14:33:00 DISPATCHER: Starting worker discovery
14:33:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:33:00 DISPATCHER: Finished worker discovery
14:34:00 DISPATCHER: Starting worker discovery
14:34:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:34:00 DISPATCHER: Finished worker discovery
14:35:00 DISPATCHER: Starting worker discovery
14:35:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:35:01 DISPATCHER: Finished worker discovery
14:35:31 WORKER: done with job (1, 0, 3), trying to register it.
14:35:31 WORKER: registered result for job (1, 0, 3) with dispatcher
14:35:31 DISPATCHER: job (1, 0, 3) finished
14:35:31 DISPATCHER: register_result: lock acquired
14:35:31 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
14:35:31 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.023605907070225057, 'num_filters_1': 125, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.013101422350810733, 'kernel_size_2': 7, 'num_filters_2': 100}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.09994936036087179, 'info': {'data04': 0.09994936036087179, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.023605907070225057, 'num_filters_1': 125, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.013101422350810733, 'kernel_size_2': 7, 'num_filters_2': 100}"}}
exception: None

14:35:31 job_callback for (1, 0, 3) started
14:35:31 DISPATCHER: Trying to submit another job.
14:35:31 job_callback for (1, 0, 3) got condition
14:35:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:35:31 Only 6 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
14:35:31 HBMASTER: Trying to run another job!
14:35:31 job_callback for (1, 0, 3) finished
14:35:31 ITERATION: Advancing config (1, 0, 0) to next budget 1200.000000
14:35:31 HBMASTER: schedule new run for iteration 1
14:35:31 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
14:35:31 HBMASTER: submitting job (1, 0, 0) to dispatcher
14:35:31 DISPATCHER: trying to submit job (1, 0, 0)
14:35:31 DISPATCHER: trying to notify the job_runner thread.
14:35:31 HBMASTER: job (1, 0, 0) submitted to dispatcher
14:35:31 DISPATCHER: Trying to submit another job.
14:35:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:35:31 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:35:31 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:35:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:35:31 WORKER: start processing job (1, 0, 0)
14:35:31 WORKER: args: ()
14:35:31 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004130788241532912, 'num_filters_1': 31, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.018897818296464506}, 'budget': 1200.0, 'working_directory': '.'}
14:36:01 DISPATCHER: Starting worker discovery
14:36:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:36:01 DISPATCHER: Finished worker discovery
14:37:01 DISPATCHER: Starting worker discovery
14:37:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:37:01 DISPATCHER: Finished worker discovery
14:38:01 DISPATCHER: Starting worker discovery
14:38:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:38:01 DISPATCHER: Finished worker discovery
14:39:01 DISPATCHER: Starting worker discovery
14:39:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:39:01 DISPATCHER: Finished worker discovery
14:40:01 DISPATCHER: Starting worker discovery
14:40:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:40:01 DISPATCHER: Finished worker discovery
14:41:01 DISPATCHER: Starting worker discovery
14:41:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:41:01 DISPATCHER: Finished worker discovery
14:42:01 DISPATCHER: Starting worker discovery
14:42:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:42:01 DISPATCHER: Finished worker discovery
14:43:01 DISPATCHER: Starting worker discovery
14:43:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:43:01 DISPATCHER: Finished worker discovery
14:44:01 DISPATCHER: Starting worker discovery
14:44:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:44:01 DISPATCHER: Finished worker discovery
14:45:01 DISPATCHER: Starting worker discovery
14:45:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:45:01 DISPATCHER: Finished worker discovery
14:46:01 DISPATCHER: Starting worker discovery
14:46:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:46:01 DISPATCHER: Finished worker discovery
14:47:01 DISPATCHER: Starting worker discovery
14:47:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:47:01 DISPATCHER: Finished worker discovery
14:48:01 DISPATCHER: Starting worker discovery
14:48:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:48:01 DISPATCHER: Finished worker discovery
14:49:01 DISPATCHER: Starting worker discovery
14:49:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:49:01 DISPATCHER: Finished worker discovery
14:50:01 DISPATCHER: Starting worker discovery
14:50:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:50:01 DISPATCHER: Finished worker discovery
14:51:01 DISPATCHER: Starting worker discovery
14:51:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:51:01 DISPATCHER: Finished worker discovery
14:52:01 DISPATCHER: Starting worker discovery
14:52:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:52:01 DISPATCHER: Finished worker discovery
14:53:01 DISPATCHER: Starting worker discovery
14:53:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:53:01 DISPATCHER: Finished worker discovery
14:54:01 DISPATCHER: Starting worker discovery
14:54:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:54:01 DISPATCHER: Finished worker discovery
14:55:01 DISPATCHER: Starting worker discovery
14:55:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:55:01 DISPATCHER: Finished worker discovery
14:56:01 DISPATCHER: Starting worker discovery
14:56:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:56:01 DISPATCHER: Finished worker discovery
14:57:01 DISPATCHER: Starting worker discovery
14:57:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:57:01 DISPATCHER: Finished worker discovery
14:57:08 WORKER: done with job (1, 0, 0), trying to register it.
14:57:08 WORKER: registered result for job (1, 0, 0) with dispatcher
14:57:08 DISPATCHER: job (1, 0, 0) finished
14:57:08 DISPATCHER: register_result: lock acquired
14:57:08 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
14:57:08 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004130788241532912, 'num_filters_1': 31, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.018897818296464506}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.13831190546984626, 'info': {'data04': 0.13831190546984626, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004130788241532912, 'num_filters_1': 31, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.018897818296464506}"}}
exception: None

14:57:08 job_callback for (1, 0, 0) started
14:57:08 job_callback for (1, 0, 0) got condition
14:57:08 DISPATCHER: Trying to submit another job.
14:57:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:57:08 Only 2 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
14:57:08 HBMASTER: Trying to run another job!
14:57:08 job_callback for (1, 0, 0) finished
14:57:08 start sampling a new configuration.
14:57:08 done sampling a new configuration.
14:57:08 HBMASTER: schedule new run for iteration 2
14:57:08 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
14:57:08 HBMASTER: submitting job (2, 0, 0) to dispatcher
14:57:08 DISPATCHER: trying to submit job (2, 0, 0)
14:57:08 DISPATCHER: trying to notify the job_runner thread.
14:57:08 HBMASTER: job (2, 0, 0) submitted to dispatcher
14:57:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:57:08 DISPATCHER: Trying to submit another job.
14:57:08 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:57:08 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:57:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:57:08 WORKER: start processing job (2, 0, 0)
14:57:08 WORKER: args: ()
14:57:08 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.005246826760221017, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.022011406836927615}, 'budget': 400.0, 'working_directory': '.'}
14:58:01 DISPATCHER: Starting worker discovery
14:58:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:58:01 DISPATCHER: Finished worker discovery
14:59:01 DISPATCHER: Starting worker discovery
14:59:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:59:01 DISPATCHER: Finished worker discovery
15:00:01 DISPATCHER: Starting worker discovery
15:00:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:00:01 DISPATCHER: Finished worker discovery
15:01:01 DISPATCHER: Starting worker discovery
15:01:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:01:01 DISPATCHER: Finished worker discovery
15:02:01 DISPATCHER: Starting worker discovery
15:02:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:02:01 DISPATCHER: Finished worker discovery
15:03:01 DISPATCHER: Starting worker discovery
15:03:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:03:01 DISPATCHER: Finished worker discovery
15:04:01 DISPATCHER: Starting worker discovery
15:04:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:04:01 DISPATCHER: Finished worker discovery
15:04:46 WORKER: done with job (2, 0, 0), trying to register it.
15:04:46 WORKER: registered result for job (2, 0, 0) with dispatcher
15:04:46 DISPATCHER: job (2, 0, 0) finished
15:04:46 DISPATCHER: register_result: lock acquired
15:04:46 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
15:04:46 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.005246826760221017, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.022011406836927615}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.09029732221652008, 'info': {'data04': 0.09029732221652008, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.005246826760221017, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.022011406836927615}"}}
exception: None

15:04:46 job_callback for (2, 0, 0) started
15:04:46 DISPATCHER: Trying to submit another job.
15:04:46 job_callback for (2, 0, 0) got condition
15:04:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:04:46 Only 7 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
15:04:46 HBMASTER: Trying to run another job!
15:04:46 job_callback for (2, 0, 0) finished
15:04:46 start sampling a new configuration.
15:04:46 done sampling a new configuration.
15:04:46 HBMASTER: schedule new run for iteration 2
15:04:46 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
15:04:46 HBMASTER: submitting job (2, 0, 1) to dispatcher
15:04:46 DISPATCHER: trying to submit job (2, 0, 1)
15:04:46 DISPATCHER: trying to notify the job_runner thread.
15:04:46 HBMASTER: job (2, 0, 1) submitted to dispatcher
15:04:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:04:46 DISPATCHER: Trying to submit another job.
15:04:46 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:04:46 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:04:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:04:46 WORKER: start processing job (2, 0, 1)
15:04:46 WORKER: args: ()
15:04:46 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.038247726815015516, 'num_filters_1': 55, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.01173250338956397}, 'budget': 400.0, 'working_directory': '.'}
15:05:01 DISPATCHER: Starting worker discovery
15:05:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:05:01 DISPATCHER: Finished worker discovery
15:06:01 DISPATCHER: Starting worker discovery
15:06:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:06:01 DISPATCHER: Finished worker discovery
15:07:01 DISPATCHER: Starting worker discovery
15:07:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:07:01 DISPATCHER: Finished worker discovery
15:08:01 DISPATCHER: Starting worker discovery
15:08:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:08:01 DISPATCHER: Finished worker discovery
15:09:01 DISPATCHER: Starting worker discovery
15:09:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:09:01 DISPATCHER: Finished worker discovery
15:10:01 DISPATCHER: Starting worker discovery
15:10:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:10:01 DISPATCHER: Finished worker discovery
15:11:01 DISPATCHER: Starting worker discovery
15:11:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:11:01 DISPATCHER: Finished worker discovery
15:12:01 DISPATCHER: Starting worker discovery
15:12:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:12:01 DISPATCHER: Finished worker discovery
15:12:15 WORKER: done with job (2, 0, 1), trying to register it.
15:12:15 WORKER: registered result for job (2, 0, 1) with dispatcher
15:12:15 DISPATCHER: job (2, 0, 1) finished
15:12:15 DISPATCHER: register_result: lock acquired
15:12:15 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
15:12:15 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.038247726815015516, 'num_filters_1': 55, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.01173250338956397}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.002501240776404261, 'info': {'data04': 0.002501240776404261, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.038247726815015516, 'num_filters_1': 55, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.01173250338956397}"}}
exception: None

15:12:15 job_callback for (2, 0, 1) started
15:12:15 job_callback for (2, 0, 1) got condition
15:12:15 DISPATCHER: Trying to submit another job.
15:12:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:12:15 Only 8 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
15:12:15 HBMASTER: Trying to run another job!
15:12:15 job_callback for (2, 0, 1) finished
15:12:15 start sampling a new configuration.
15:12:15 done sampling a new configuration.
15:12:15 HBMASTER: schedule new run for iteration 2
15:12:15 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
15:12:15 HBMASTER: submitting job (2, 0, 2) to dispatcher
15:12:15 DISPATCHER: trying to submit job (2, 0, 2)
15:12:15 DISPATCHER: trying to notify the job_runner thread.
15:12:15 HBMASTER: job (2, 0, 2) submitted to dispatcher
15:12:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:12:15 DISPATCHER: Trying to submit another job.
15:12:15 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:12:15 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:12:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:12:15 WORKER: start processing job (2, 0, 2)
15:12:15 WORKER: args: ()
15:12:15 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005209495774728084, 'num_filters_1': 37, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.014498270635115709, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 31, 'num_filters_3': 69}, 'budget': 400.0, 'working_directory': '.'}
15:13:01 DISPATCHER: Starting worker discovery
15:13:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:13:01 DISPATCHER: Finished worker discovery
15:14:01 DISPATCHER: Starting worker discovery
15:14:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:14:01 DISPATCHER: Finished worker discovery
15:15:01 DISPATCHER: Starting worker discovery
15:15:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:15:01 DISPATCHER: Finished worker discovery
15:16:01 DISPATCHER: Starting worker discovery
15:16:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:16:01 DISPATCHER: Finished worker discovery
15:17:01 DISPATCHER: Starting worker discovery
15:17:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:17:01 DISPATCHER: Finished worker discovery
15:18:01 DISPATCHER: Starting worker discovery
15:18:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:18:01 DISPATCHER: Finished worker discovery
15:19:01 DISPATCHER: Starting worker discovery
15:19:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:19:01 DISPATCHER: Finished worker discovery
15:19:48 WORKER: done with job (2, 0, 2), trying to register it.
15:19:48 WORKER: registered result for job (2, 0, 2) with dispatcher
15:19:48 DISPATCHER: job (2, 0, 2) finished
15:19:48 DISPATCHER: register_result: lock acquired
15:19:48 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
15:19:48 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005209495774728084, 'num_filters_1': 37, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.014498270635115709, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 31, 'num_filters_3': 69}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.029211806204820487, 'info': {'data04': 0.029211806204820487, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005209495774728084, 'num_filters_1': 37, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.014498270635115709, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 31, 'num_filters_3': 69}"}}
exception: None

15:19:48 job_callback for (2, 0, 2) started
15:19:48 DISPATCHER: Trying to submit another job.
15:19:48 job_callback for (2, 0, 2) got condition
15:19:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:19:48 Only 9 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
15:19:48 HBMASTER: Trying to run another job!
15:19:48 job_callback for (2, 0, 2) finished
15:19:48 start sampling a new configuration.
15:19:48 done sampling a new configuration.
15:19:48 HBMASTER: schedule new run for iteration 2
15:19:48 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
15:19:48 HBMASTER: submitting job (2, 0, 3) to dispatcher
15:19:48 DISPATCHER: trying to submit job (2, 0, 3)
15:19:48 DISPATCHER: trying to notify the job_runner thread.
15:19:48 HBMASTER: job (2, 0, 3) submitted to dispatcher
15:19:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:19:48 DISPATCHER: Trying to submit another job.
15:19:48 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:19:48 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:19:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:19:48 WORKER: start processing job (2, 0, 3)
15:19:48 WORKER: args: ()
15:19:48 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0019106882301353097, 'num_filters_1': 69, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.04933927719661313, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 39, 'num_filters_3': 57}, 'budget': 400.0, 'working_directory': '.'}
15:20:01 DISPATCHER: Starting worker discovery
15:20:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:20:01 DISPATCHER: Finished worker discovery
15:21:01 DISPATCHER: Starting worker discovery
15:21:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:21:01 DISPATCHER: Finished worker discovery
15:22:01 DISPATCHER: Starting worker discovery
15:22:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:22:01 DISPATCHER: Finished worker discovery
15:23:01 DISPATCHER: Starting worker discovery
15:23:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:23:01 DISPATCHER: Finished worker discovery
15:24:01 DISPATCHER: Starting worker discovery
15:24:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:24:02 DISPATCHER: Finished worker discovery
15:25:02 DISPATCHER: Starting worker discovery
15:25:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:25:02 DISPATCHER: Finished worker discovery
15:26:02 DISPATCHER: Starting worker discovery
15:26:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:26:02 DISPATCHER: Finished worker discovery
15:27:02 DISPATCHER: Starting worker discovery
15:27:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:27:02 DISPATCHER: Finished worker discovery
15:27:04 WORKER: done with job (2, 0, 3), trying to register it.
15:27:04 WORKER: registered result for job (2, 0, 3) with dispatcher
15:27:04 DISPATCHER: job (2, 0, 3) finished
15:27:04 DISPATCHER: register_result: lock acquired
15:27:04 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
15:27:04 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0019106882301353097, 'num_filters_1': 69, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.04933927719661313, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 39, 'num_filters_3': 57}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.03283325743931784, 'info': {'data04': 0.03283325743931784, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0019106882301353097, 'num_filters_1': 69, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.04933927719661313, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 39, 'num_filters_3': 57}"}}
exception: None

15:27:04 job_callback for (2, 0, 3) started
15:27:04 job_callback for (2, 0, 3) got condition
15:27:04 DISPATCHER: Trying to submit another job.
15:27:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:27:04 Only 10 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
15:27:04 HBMASTER: Trying to run another job!
15:27:04 job_callback for (2, 0, 3) finished
15:27:04 start sampling a new configuration.
15:27:04 done sampling a new configuration.
15:27:04 HBMASTER: schedule new run for iteration 2
15:27:04 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
15:27:04 HBMASTER: submitting job (2, 0, 4) to dispatcher
15:27:04 DISPATCHER: trying to submit job (2, 0, 4)
15:27:04 DISPATCHER: trying to notify the job_runner thread.
15:27:04 HBMASTER: job (2, 0, 4) submitted to dispatcher
15:27:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:27:04 DISPATCHER: Trying to submit another job.
15:27:04 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:27:04 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:27:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:27:04 WORKER: start processing job (2, 0, 4)
15:27:04 WORKER: args: ()
15:27:04 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.03813759510152996, 'num_filters_1': 61, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.07063568941383155, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 49, 'num_filters_3': 25, 'num_filters_4': 126}, 'budget': 400.0, 'working_directory': '.'}
15:28:02 DISPATCHER: Starting worker discovery
15:28:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:28:02 DISPATCHER: Finished worker discovery
15:29:02 DISPATCHER: Starting worker discovery
15:29:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:29:02 DISPATCHER: Finished worker discovery
15:30:02 DISPATCHER: Starting worker discovery
15:30:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:30:02 DISPATCHER: Finished worker discovery
15:31:02 DISPATCHER: Starting worker discovery
15:31:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:31:02 DISPATCHER: Finished worker discovery
15:32:02 DISPATCHER: Starting worker discovery
15:32:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:32:02 DISPATCHER: Finished worker discovery
15:33:02 DISPATCHER: Starting worker discovery
15:33:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:33:02 DISPATCHER: Finished worker discovery
15:34:02 DISPATCHER: Starting worker discovery
15:34:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:34:02 DISPATCHER: Finished worker discovery
15:35:02 DISPATCHER: Starting worker discovery
15:35:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:35:02 DISPATCHER: Finished worker discovery
15:35:34 WORKER: done with job (2, 0, 4), trying to register it.
15:35:35 WORKER: registered result for job (2, 0, 4) with dispatcher
15:35:35 DISPATCHER: job (2, 0, 4) finished
15:35:35 DISPATCHER: register_result: lock acquired
15:35:35 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
15:35:35 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.03813759510152996, 'num_filters_1': 61, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.07063568941383155, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 49, 'num_filters_3': 25, 'num_filters_4': 126}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0002973791285829409, 'info': {'data04': 0.0002973791285829409, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.03813759510152996, 'num_filters_1': 61, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.07063568941383155, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 49, 'num_filters_3': 25, 'num_filters_4': 126}"}}
exception: None

15:35:35 job_callback for (2, 0, 4) started
15:35:35 DISPATCHER: Trying to submit another job.
15:35:35 job_callback for (2, 0, 4) got condition
15:35:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:35:35 Only 11 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
15:35:35 HBMASTER: Trying to run another job!
15:35:35 job_callback for (2, 0, 4) finished
15:35:35 start sampling a new configuration.
15:35:35 done sampling a new configuration.
15:35:35 HBMASTER: schedule new run for iteration 2
15:35:35 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
15:35:35 HBMASTER: submitting job (2, 0, 5) to dispatcher
15:35:35 DISPATCHER: trying to submit job (2, 0, 5)
15:35:35 DISPATCHER: trying to notify the job_runner thread.
15:35:35 HBMASTER: job (2, 0, 5) submitted to dispatcher
15:35:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:35:35 DISPATCHER: Trying to submit another job.
15:35:35 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:35:35 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:35:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:35:35 WORKER: start processing job (2, 0, 5)
15:35:35 WORKER: args: ()
15:35:35 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005870663243811123, 'num_filters_1': 51, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.010988911532090258, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 29, 'num_filters_3': 22, 'num_filters_4': 16}, 'budget': 400.0, 'working_directory': '.'}
15:36:02 DISPATCHER: Starting worker discovery
15:36:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:36:02 DISPATCHER: Finished worker discovery
15:37:02 DISPATCHER: Starting worker discovery
15:37:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:37:02 DISPATCHER: Finished worker discovery
15:38:02 DISPATCHER: Starting worker discovery
15:38:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:38:02 DISPATCHER: Finished worker discovery
15:39:02 DISPATCHER: Starting worker discovery
15:39:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:39:02 DISPATCHER: Finished worker discovery
15:40:02 DISPATCHER: Starting worker discovery
15:40:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:40:02 DISPATCHER: Finished worker discovery
15:41:02 DISPATCHER: Starting worker discovery
15:41:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:41:02 DISPATCHER: Finished worker discovery
15:42:02 DISPATCHER: Starting worker discovery
15:42:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:42:02 DISPATCHER: Finished worker discovery
15:42:55 WORKER: done with job (2, 0, 5), trying to register it.
15:42:55 WORKER: registered result for job (2, 0, 5) with dispatcher
15:42:55 DISPATCHER: job (2, 0, 5) finished
15:42:55 DISPATCHER: register_result: lock acquired
15:42:55 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
15:42:55 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005870663243811123, 'num_filters_1': 51, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.010988911532090258, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 29, 'num_filters_3': 22, 'num_filters_4': 16}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -7.582135792255615e-05, 'info': {'data04': 7.582135792255615e-05, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005870663243811123, 'num_filters_1': 51, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.010988911532090258, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 29, 'num_filters_3': 22, 'num_filters_4': 16}"}}
exception: None

15:42:55 job_callback for (2, 0, 5) started
15:42:55 DISPATCHER: Trying to submit another job.
15:42:55 job_callback for (2, 0, 5) got condition
15:42:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:42:55 Only 12 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
15:42:55 HBMASTER: Trying to run another job!
15:42:55 job_callback for (2, 0, 5) finished
15:42:55 ITERATION: Advancing config (2, 0, 0) to next budget 1200.000000
15:42:55 ITERATION: Advancing config (2, 0, 3) to next budget 1200.000000
15:42:55 HBMASTER: schedule new run for iteration 2
15:42:55 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
15:42:55 HBMASTER: submitting job (2, 0, 0) to dispatcher
15:42:55 DISPATCHER: trying to submit job (2, 0, 0)
15:42:55 DISPATCHER: trying to notify the job_runner thread.
15:42:55 HBMASTER: job (2, 0, 0) submitted to dispatcher
15:42:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:42:55 DISPATCHER: Trying to submit another job.
15:42:55 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:42:55 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:42:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:42:55 WORKER: start processing job (2, 0, 0)
15:42:55 WORKER: args: ()
15:42:55 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.005246826760221017, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.022011406836927615}, 'budget': 1200.0, 'working_directory': '.'}
15:43:02 DISPATCHER: Starting worker discovery
15:43:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:43:02 DISPATCHER: Finished worker discovery
15:44:02 DISPATCHER: Starting worker discovery
15:44:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:44:02 DISPATCHER: Finished worker discovery
15:45:02 DISPATCHER: Starting worker discovery
15:45:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:45:02 DISPATCHER: Finished worker discovery
15:46:02 DISPATCHER: Starting worker discovery
15:46:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:46:02 DISPATCHER: Finished worker discovery
15:47:02 DISPATCHER: Starting worker discovery
15:47:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:47:02 DISPATCHER: Finished worker discovery
15:48:02 DISPATCHER: Starting worker discovery
15:48:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:48:02 DISPATCHER: Finished worker discovery
15:49:02 DISPATCHER: Starting worker discovery
15:49:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:49:02 DISPATCHER: Finished worker discovery
15:50:02 DISPATCHER: Starting worker discovery
15:50:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:50:02 DISPATCHER: Finished worker discovery
15:51:02 DISPATCHER: Starting worker discovery
15:51:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:51:02 DISPATCHER: Finished worker discovery
15:52:02 DISPATCHER: Starting worker discovery
15:52:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:52:02 DISPATCHER: Finished worker discovery
15:53:02 DISPATCHER: Starting worker discovery
15:53:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:53:02 DISPATCHER: Finished worker discovery
15:54:02 DISPATCHER: Starting worker discovery
15:54:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:54:02 DISPATCHER: Finished worker discovery
15:55:02 DISPATCHER: Starting worker discovery
15:55:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:55:02 DISPATCHER: Finished worker discovery
15:56:02 DISPATCHER: Starting worker discovery
15:56:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:56:02 DISPATCHER: Finished worker discovery
15:57:02 DISPATCHER: Starting worker discovery
15:57:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:57:02 DISPATCHER: Finished worker discovery
15:58:02 DISPATCHER: Starting worker discovery
15:58:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:58:02 DISPATCHER: Finished worker discovery
15:59:02 DISPATCHER: Starting worker discovery
15:59:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:59:02 DISPATCHER: Finished worker discovery
16:00:02 DISPATCHER: Starting worker discovery
16:00:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:00:02 DISPATCHER: Finished worker discovery
16:01:02 DISPATCHER: Starting worker discovery
16:01:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:01:02 DISPATCHER: Finished worker discovery
16:02:02 DISPATCHER: Starting worker discovery
16:02:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:02:02 DISPATCHER: Finished worker discovery
16:03:02 DISPATCHER: Starting worker discovery
16:03:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:03:02 DISPATCHER: Finished worker discovery
16:04:02 DISPATCHER: Starting worker discovery
16:04:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:04:03 DISPATCHER: Finished worker discovery
16:05:03 DISPATCHER: Starting worker discovery
16:05:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:05:03 DISPATCHER: Finished worker discovery
16:05:15 WORKER: done with job (2, 0, 0), trying to register it.
16:05:15 WORKER: registered result for job (2, 0, 0) with dispatcher
16:05:15 DISPATCHER: job (2, 0, 0) finished
16:05:15 DISPATCHER: register_result: lock acquired
16:05:15 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:05:15 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.005246826760221017, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.022011406836927615}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.08410734532597566, 'info': {'data04': 0.08410734532597566, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.005246826760221017, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.022011406836927615}"}}
exception: None

16:05:15 job_callback for (2, 0, 0) started
16:05:15 DISPATCHER: Trying to submit another job.
16:05:15 job_callback for (2, 0, 0) got condition
16:05:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:05:15 Only 3 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
16:05:15 HBMASTER: Trying to run another job!
16:05:15 job_callback for (2, 0, 0) finished
16:05:15 HBMASTER: schedule new run for iteration 2
16:05:15 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
16:05:15 HBMASTER: submitting job (2, 0, 3) to dispatcher
16:05:15 DISPATCHER: trying to submit job (2, 0, 3)
16:05:15 DISPATCHER: trying to notify the job_runner thread.
16:05:15 HBMASTER: job (2, 0, 3) submitted to dispatcher
16:05:15 DISPATCHER: Trying to submit another job.
16:05:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:05:15 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:05:15 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:05:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:05:15 WORKER: start processing job (2, 0, 3)
16:05:15 WORKER: args: ()
16:05:15 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0019106882301353097, 'num_filters_1': 69, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.04933927719661313, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 39, 'num_filters_3': 57}, 'budget': 1200.0, 'working_directory': '.'}
16:06:03 DISPATCHER: Starting worker discovery
16:06:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:06:03 DISPATCHER: Finished worker discovery
16:07:03 DISPATCHER: Starting worker discovery
16:07:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:07:03 DISPATCHER: Finished worker discovery
16:08:03 DISPATCHER: Starting worker discovery
16:08:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:08:03 DISPATCHER: Finished worker discovery
16:09:03 DISPATCHER: Starting worker discovery
16:09:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:09:03 DISPATCHER: Finished worker discovery
16:10:03 DISPATCHER: Starting worker discovery
16:10:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:10:03 DISPATCHER: Finished worker discovery
16:11:03 DISPATCHER: Starting worker discovery
16:11:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:11:03 DISPATCHER: Finished worker discovery
16:12:03 DISPATCHER: Starting worker discovery
16:12:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:12:03 DISPATCHER: Finished worker discovery
16:13:03 DISPATCHER: Starting worker discovery
16:13:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:13:03 DISPATCHER: Finished worker discovery
16:14:03 DISPATCHER: Starting worker discovery
16:14:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:14:03 DISPATCHER: Finished worker discovery
16:15:03 DISPATCHER: Starting worker discovery
16:15:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:15:03 DISPATCHER: Finished worker discovery
16:16:03 DISPATCHER: Starting worker discovery
16:16:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:16:03 DISPATCHER: Finished worker discovery
16:17:03 DISPATCHER: Starting worker discovery
16:17:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:17:03 DISPATCHER: Finished worker discovery
16:18:03 DISPATCHER: Starting worker discovery
16:18:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:18:03 DISPATCHER: Finished worker discovery
16:19:03 DISPATCHER: Starting worker discovery
16:19:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:19:03 DISPATCHER: Finished worker discovery
16:20:03 DISPATCHER: Starting worker discovery
16:20:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:20:03 DISPATCHER: Finished worker discovery
16:21:03 DISPATCHER: Starting worker discovery
16:21:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:21:03 DISPATCHER: Finished worker discovery
16:22:03 DISPATCHER: Starting worker discovery
16:22:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:22:03 DISPATCHER: Finished worker discovery
16:23:03 DISPATCHER: Starting worker discovery
16:23:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:23:03 DISPATCHER: Finished worker discovery
16:24:03 DISPATCHER: Starting worker discovery
16:24:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:24:03 DISPATCHER: Finished worker discovery
16:25:03 DISPATCHER: Starting worker discovery
16:25:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:25:03 DISPATCHER: Finished worker discovery
16:26:03 DISPATCHER: Starting worker discovery
16:26:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:26:03 DISPATCHER: Finished worker discovery
16:26:38 WORKER: done with job (2, 0, 3), trying to register it.
16:26:38 WORKER: registered result for job (2, 0, 3) with dispatcher
16:26:38 DISPATCHER: job (2, 0, 3) finished
16:26:38 DISPATCHER: register_result: lock acquired
16:26:38 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:26:38 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0019106882301353097, 'num_filters_1': 69, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.04933927719661313, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 39, 'num_filters_3': 57}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.034982495600699916, 'info': {'data04': 0.034982495600699916, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0019106882301353097, 'num_filters_1': 69, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.04933927719661313, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 39, 'num_filters_3': 57}"}}
exception: None

16:26:38 job_callback for (2, 0, 3) started
16:26:38 DISPATCHER: Trying to submit another job.
16:26:38 job_callback for (2, 0, 3) got condition
16:26:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:26:38 Only 4 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
16:26:38 HBMASTER: Trying to run another job!
16:26:38 job_callback for (2, 0, 3) finished
16:26:38 start sampling a new configuration.
16:26:38 done sampling a new configuration.
16:26:38 HBMASTER: schedule new run for iteration 3
16:26:38 HBMASTER: trying submitting job (3, 0, 0) to dispatcher
16:26:38 HBMASTER: submitting job (3, 0, 0) to dispatcher
16:26:38 DISPATCHER: trying to submit job (3, 0, 0)
16:26:38 DISPATCHER: trying to notify the job_runner thread.
16:26:38 HBMASTER: job (3, 0, 0) submitted to dispatcher
16:26:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:26:38 DISPATCHER: Trying to submit another job.
16:26:38 DISPATCHER: starting job (3, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:26:38 DISPATCHER: job (3, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:26:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:26:38 WORKER: start processing job (3, 0, 0)
16:26:38 WORKER: args: ()
16:26:38 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.06101314855510367, 'num_filters_1': 18, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.01138081606327087, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 16, 'num_filters_3': 37}, 'budget': 1200.0, 'working_directory': '.'}
16:27:03 DISPATCHER: Starting worker discovery
16:27:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:27:03 DISPATCHER: Finished worker discovery
16:28:03 DISPATCHER: Starting worker discovery
16:28:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:28:03 DISPATCHER: Finished worker discovery
16:29:03 DISPATCHER: Starting worker discovery
16:29:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:29:03 DISPATCHER: Finished worker discovery
16:30:03 DISPATCHER: Starting worker discovery
16:30:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:30:03 DISPATCHER: Finished worker discovery
16:31:03 DISPATCHER: Starting worker discovery
16:31:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:31:03 DISPATCHER: Finished worker discovery
16:32:03 DISPATCHER: Starting worker discovery
16:32:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:32:03 DISPATCHER: Finished worker discovery
16:33:03 DISPATCHER: Starting worker discovery
16:33:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:33:03 DISPATCHER: Finished worker discovery
16:34:03 DISPATCHER: Starting worker discovery
16:34:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:34:03 DISPATCHER: Finished worker discovery
16:35:03 DISPATCHER: Starting worker discovery
16:35:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:35:03 DISPATCHER: Finished worker discovery
16:36:03 DISPATCHER: Starting worker discovery
16:36:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:36:03 DISPATCHER: Finished worker discovery
16:37:03 DISPATCHER: Starting worker discovery
16:37:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:37:03 DISPATCHER: Finished worker discovery
16:38:03 DISPATCHER: Starting worker discovery
16:38:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:38:03 DISPATCHER: Finished worker discovery
16:39:03 DISPATCHER: Starting worker discovery
16:39:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:39:03 DISPATCHER: Finished worker discovery
16:40:03 DISPATCHER: Starting worker discovery
16:40:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:40:03 DISPATCHER: Finished worker discovery
16:41:03 DISPATCHER: Starting worker discovery
16:41:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:41:03 DISPATCHER: Finished worker discovery
16:42:03 DISPATCHER: Starting worker discovery
16:42:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:42:03 DISPATCHER: Finished worker discovery
16:43:03 DISPATCHER: Starting worker discovery
16:43:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:43:03 DISPATCHER: Finished worker discovery
16:44:03 DISPATCHER: Starting worker discovery
16:44:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:44:03 DISPATCHER: Finished worker discovery
16:45:03 DISPATCHER: Starting worker discovery
16:45:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:45:03 DISPATCHER: Finished worker discovery
16:46:03 DISPATCHER: Starting worker discovery
16:46:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:46:03 DISPATCHER: Finished worker discovery
16:47:03 DISPATCHER: Starting worker discovery
16:47:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:47:04 DISPATCHER: Finished worker discovery
16:48:04 DISPATCHER: Starting worker discovery
16:48:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:48:04 DISPATCHER: Finished worker discovery
16:49:04 DISPATCHER: Starting worker discovery
16:49:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:49:04 DISPATCHER: Finished worker discovery
16:50:04 DISPATCHER: Starting worker discovery
16:50:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:50:04 DISPATCHER: Finished worker discovery
16:51:04 DISPATCHER: Starting worker discovery
16:51:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:51:04 DISPATCHER: Finished worker discovery
16:52:04 DISPATCHER: Starting worker discovery
16:52:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:52:05 DISPATCHER: Finished worker discovery
16:53:05 DISPATCHER: Starting worker discovery
16:53:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:53:05 DISPATCHER: Finished worker discovery
16:53:49 WORKER: done with job (3, 0, 0), trying to register it.
16:53:49 WORKER: registered result for job (3, 0, 0) with dispatcher
16:53:49 DISPATCHER: job (3, 0, 0) finished
16:53:49 DISPATCHER: register_result: lock acquired
16:53:49 DISPATCHER: job (3, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:53:49 job_id: (3, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.06101314855510367, 'num_filters_1': 18, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.01138081606327087, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 16, 'num_filters_3': 37}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.09454783217480861, 'info': {'data04': 0.09454783217480861, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.06101314855510367, 'num_filters_1': 18, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.01138081606327087, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 16, 'num_filters_3': 37}"}}
exception: None

16:53:49 job_callback for (3, 0, 0) started
16:53:49 DISPATCHER: Trying to submit another job.
16:53:49 job_callback for (3, 0, 0) got condition
16:53:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:53:49 Only 5 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
16:53:49 HBMASTER: Trying to run another job!
16:53:49 job_callback for (3, 0, 0) finished
16:53:49 start sampling a new configuration.
16:53:49 done sampling a new configuration.
16:53:49 HBMASTER: schedule new run for iteration 3
16:53:49 HBMASTER: trying submitting job (3, 0, 1) to dispatcher
16:53:49 HBMASTER: submitting job (3, 0, 1) to dispatcher
16:53:49 DISPATCHER: trying to submit job (3, 0, 1)
16:53:49 DISPATCHER: trying to notify the job_runner thread.
16:53:49 HBMASTER: job (3, 0, 1) submitted to dispatcher
16:53:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:53:49 DISPATCHER: Trying to submit another job.
16:53:49 DISPATCHER: starting job (3, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:53:49 DISPATCHER: job (3, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:53:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:53:49 WORKER: start processing job (3, 0, 1)
16:53:49 WORKER: args: ()
16:53:49 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00140890354775646, 'num_filters_1': 112, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.06746662840872039, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 21, 'num_filters_3': 16}, 'budget': 1200.0, 'working_directory': '.'}
16:54:05 DISPATCHER: Starting worker discovery
16:54:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:54:05 DISPATCHER: Finished worker discovery
16:55:05 DISPATCHER: Starting worker discovery
16:55:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:55:05 DISPATCHER: Finished worker discovery
16:56:05 DISPATCHER: Starting worker discovery
16:56:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:56:05 DISPATCHER: Finished worker discovery
16:57:05 DISPATCHER: Starting worker discovery
16:57:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:57:05 DISPATCHER: Finished worker discovery
16:58:05 DISPATCHER: Starting worker discovery
16:58:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:58:05 DISPATCHER: Finished worker discovery
16:59:05 DISPATCHER: Starting worker discovery
16:59:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:59:05 DISPATCHER: Finished worker discovery
17:00:05 DISPATCHER: Starting worker discovery
17:00:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:00:05 DISPATCHER: Finished worker discovery
17:01:05 DISPATCHER: Starting worker discovery
17:01:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:01:05 DISPATCHER: Finished worker discovery
17:02:05 DISPATCHER: Starting worker discovery
17:02:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:02:05 DISPATCHER: Finished worker discovery
17:03:05 DISPATCHER: Starting worker discovery
17:03:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:03:05 DISPATCHER: Finished worker discovery
17:04:05 DISPATCHER: Starting worker discovery
17:04:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:04:05 DISPATCHER: Finished worker discovery
17:05:05 DISPATCHER: Starting worker discovery
17:05:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:05:05 DISPATCHER: Finished worker discovery
17:06:05 DISPATCHER: Starting worker discovery
17:06:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:06:05 DISPATCHER: Finished worker discovery
17:07:05 DISPATCHER: Starting worker discovery
17:07:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:07:05 DISPATCHER: Finished worker discovery
17:08:05 DISPATCHER: Starting worker discovery
17:08:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:08:05 DISPATCHER: Finished worker discovery
17:09:05 DISPATCHER: Starting worker discovery
17:09:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:09:05 DISPATCHER: Finished worker discovery
17:10:05 DISPATCHER: Starting worker discovery
17:10:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:10:05 DISPATCHER: Finished worker discovery
17:11:05 DISPATCHER: Starting worker discovery
17:11:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:11:05 DISPATCHER: Finished worker discovery
17:12:05 DISPATCHER: Starting worker discovery
17:12:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:12:05 DISPATCHER: Finished worker discovery
17:13:05 DISPATCHER: Starting worker discovery
17:13:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:13:05 DISPATCHER: Finished worker discovery
17:14:05 DISPATCHER: Starting worker discovery
17:14:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:14:05 DISPATCHER: Finished worker discovery
17:15:05 DISPATCHER: Starting worker discovery
17:15:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:15:05 DISPATCHER: Finished worker discovery
17:15:17 WORKER: done with job (3, 0, 1), trying to register it.
17:15:17 WORKER: registered result for job (3, 0, 1) with dispatcher
17:15:17 DISPATCHER: job (3, 0, 1) finished
17:15:17 DISPATCHER: register_result: lock acquired
17:15:17 DISPATCHER: job (3, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
17:15:17 job_id: (3, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00140890354775646, 'num_filters_1': 112, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.06746662840872039, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 21, 'num_filters_3': 16}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.013336117877092287, 'info': {'data04': 0.013336117877092287, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.00140890354775646, 'num_filters_1': 112, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.06746662840872039, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 21, 'num_filters_3': 16}"}}
exception: None

17:15:17 job_callback for (3, 0, 1) started
17:15:17 job_callback for (3, 0, 1) got condition
17:15:17 DISPATCHER: Trying to submit another job.
17:15:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:15:17 Only 6 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
17:15:17 HBMASTER: Trying to run another job!
17:15:17 job_callback for (3, 0, 1) finished
17:15:17 start sampling a new configuration.
17:15:17 done sampling a new configuration.
17:15:17 HBMASTER: schedule new run for iteration 3
17:15:17 HBMASTER: trying submitting job (3, 0, 2) to dispatcher
17:15:17 HBMASTER: submitting job (3, 0, 2) to dispatcher
17:15:17 DISPATCHER: trying to submit job (3, 0, 2)
17:15:17 DISPATCHER: trying to notify the job_runner thread.
17:15:17 HBMASTER: job (3, 0, 2) submitted to dispatcher
17:15:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:15:17 DISPATCHER: Trying to submit another job.
17:15:17 DISPATCHER: starting job (3, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
17:15:17 DISPATCHER: job (3, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
17:15:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:15:17 WORKER: start processing job (3, 0, 2)
17:15:17 WORKER: args: ()
17:15:17 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001888352206323106, 'num_filters_1': 48, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.051746945113896346, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 128, 'num_filters_3': 63}, 'budget': 1200.0, 'working_directory': '.'}
17:16:05 DISPATCHER: Starting worker discovery
17:16:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:16:05 DISPATCHER: Finished worker discovery
17:17:05 DISPATCHER: Starting worker discovery
17:17:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:17:05 DISPATCHER: Finished worker discovery
17:18:05 DISPATCHER: Starting worker discovery
17:18:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:18:05 DISPATCHER: Finished worker discovery
17:19:05 DISPATCHER: Starting worker discovery
17:19:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:19:05 DISPATCHER: Finished worker discovery
17:20:05 DISPATCHER: Starting worker discovery
17:20:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:20:05 DISPATCHER: Finished worker discovery
17:21:05 DISPATCHER: Starting worker discovery
17:21:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:21:05 DISPATCHER: Finished worker discovery
17:22:05 DISPATCHER: Starting worker discovery
17:22:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:22:05 DISPATCHER: Finished worker discovery
17:23:05 DISPATCHER: Starting worker discovery
17:23:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:23:05 DISPATCHER: Finished worker discovery
17:24:05 DISPATCHER: Starting worker discovery
17:24:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:24:05 DISPATCHER: Finished worker discovery
17:25:05 DISPATCHER: Starting worker discovery
17:25:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:25:05 DISPATCHER: Finished worker discovery
17:26:05 DISPATCHER: Starting worker discovery
17:26:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:26:05 DISPATCHER: Finished worker discovery
17:27:05 DISPATCHER: Starting worker discovery
17:27:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:27:05 DISPATCHER: Finished worker discovery
17:28:05 DISPATCHER: Starting worker discovery
17:28:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:28:05 DISPATCHER: Finished worker discovery
17:29:05 DISPATCHER: Starting worker discovery
17:29:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:29:05 DISPATCHER: Finished worker discovery
17:30:05 DISPATCHER: Starting worker discovery
17:30:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:30:05 DISPATCHER: Finished worker discovery
17:31:05 DISPATCHER: Starting worker discovery
17:31:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:31:05 DISPATCHER: Finished worker discovery
17:32:05 DISPATCHER: Starting worker discovery
17:32:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:32:05 DISPATCHER: Finished worker discovery
17:33:05 DISPATCHER: Starting worker discovery
17:33:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:33:05 DISPATCHER: Finished worker discovery
17:34:05 DISPATCHER: Starting worker discovery
17:34:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:34:05 DISPATCHER: Finished worker discovery
17:35:05 DISPATCHER: Starting worker discovery
17:35:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:35:05 DISPATCHER: Finished worker discovery
17:36:05 DISPATCHER: Starting worker discovery
17:36:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:36:06 DISPATCHER: Finished worker discovery
17:36:14 WORKER: done with job (3, 0, 2), trying to register it.
17:36:14 WORKER: registered result for job (3, 0, 2) with dispatcher
17:36:14 DISPATCHER: job (3, 0, 2) finished
17:36:14 DISPATCHER: register_result: lock acquired
17:36:14 DISPATCHER: job (3, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
17:36:14 job_id: (3, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001888352206323106, 'num_filters_1': 48, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.051746945113896346, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 128, 'num_filters_3': 63}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.03938373074786075, 'info': {'data04': 0.03938373074786075, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001888352206323106, 'num_filters_1': 48, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.051746945113896346, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 128, 'num_filters_3': 63}"}}
exception: None

17:36:14 job_callback for (3, 0, 2) started
17:36:14 DISPATCHER: Trying to submit another job.
17:36:14 job_callback for (3, 0, 2) got condition
17:36:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:36:14 Only 7 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
17:36:14 HBMASTER: Trying to run another job!
17:36:14 job_callback for (3, 0, 2) finished
17:36:14 start sampling a new configuration.
17:36:14 done sampling a new configuration.
17:36:14 HBMASTER: schedule new run for iteration 3
17:36:14 HBMASTER: trying submitting job (3, 0, 3) to dispatcher
17:36:14 HBMASTER: submitting job (3, 0, 3) to dispatcher
17:36:14 DISPATCHER: trying to submit job (3, 0, 3)
17:36:14 DISPATCHER: trying to notify the job_runner thread.
17:36:14 HBMASTER: job (3, 0, 3) submitted to dispatcher
17:36:14 DISPATCHER: Trying to submit another job.
17:36:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:36:14 DISPATCHER: starting job (3, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
17:36:14 DISPATCHER: job (3, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
17:36:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:36:14 WORKER: start processing job (3, 0, 3)
17:36:14 WORKER: args: ()
17:36:14 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.06455548131484677, 'num_filters_1': 100, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.02216852146089654}, 'budget': 1200.0, 'working_directory': '.'}
17:37:06 DISPATCHER: Starting worker discovery
17:37:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:37:06 DISPATCHER: Finished worker discovery
17:38:06 DISPATCHER: Starting worker discovery
17:38:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:38:06 DISPATCHER: Finished worker discovery
17:39:06 DISPATCHER: Starting worker discovery
17:39:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:39:06 DISPATCHER: Finished worker discovery
17:40:06 DISPATCHER: Starting worker discovery
17:40:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:40:06 DISPATCHER: Finished worker discovery
17:41:06 DISPATCHER: Starting worker discovery
17:41:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:41:06 DISPATCHER: Finished worker discovery
17:42:06 DISPATCHER: Starting worker discovery
17:42:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:42:06 DISPATCHER: Finished worker discovery
17:43:06 DISPATCHER: Starting worker discovery
17:43:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:43:06 DISPATCHER: Finished worker discovery
17:44:06 DISPATCHER: Starting worker discovery
17:44:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:44:06 DISPATCHER: Finished worker discovery
17:45:06 DISPATCHER: Starting worker discovery
17:45:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:45:06 DISPATCHER: Finished worker discovery
17:46:06 DISPATCHER: Starting worker discovery
17:46:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:46:06 DISPATCHER: Finished worker discovery
17:47:06 DISPATCHER: Starting worker discovery
17:47:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:47:06 DISPATCHER: Finished worker discovery
17:48:06 DISPATCHER: Starting worker discovery
17:48:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:48:06 DISPATCHER: Finished worker discovery
17:49:06 DISPATCHER: Starting worker discovery
17:49:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:49:06 DISPATCHER: Finished worker discovery
17:50:06 DISPATCHER: Starting worker discovery
17:50:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:50:06 DISPATCHER: Finished worker discovery
17:51:06 DISPATCHER: Starting worker discovery
17:51:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:51:06 DISPATCHER: Finished worker discovery
17:52:06 DISPATCHER: Starting worker discovery
17:52:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:52:06 DISPATCHER: Finished worker discovery
17:53:06 DISPATCHER: Starting worker discovery
17:53:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:53:06 DISPATCHER: Finished worker discovery
17:54:06 DISPATCHER: Starting worker discovery
17:54:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:54:06 DISPATCHER: Finished worker discovery
17:55:06 DISPATCHER: Starting worker discovery
17:55:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:55:06 DISPATCHER: Finished worker discovery
17:56:06 DISPATCHER: Starting worker discovery
17:56:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:56:06 DISPATCHER: Finished worker discovery
17:57:06 DISPATCHER: Starting worker discovery
17:57:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:57:06 DISPATCHER: Finished worker discovery
17:58:06 DISPATCHER: Starting worker discovery
17:58:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:58:06 DISPATCHER: Finished worker discovery
17:59:06 DISPATCHER: Starting worker discovery
17:59:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:59:06 DISPATCHER: Finished worker discovery
18:00:06 DISPATCHER: Starting worker discovery
18:00:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:00:07 DISPATCHER: Finished worker discovery
18:01:07 DISPATCHER: Starting worker discovery
18:01:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:01:07 DISPATCHER: Finished worker discovery
18:01:42 WORKER: done with job (3, 0, 3), trying to register it.
18:01:42 WORKER: registered result for job (3, 0, 3) with dispatcher
18:01:42 DISPATCHER: job (3, 0, 3) finished
18:01:42 DISPATCHER: register_result: lock acquired
18:01:42 DISPATCHER: job (3, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:01:42 job_id: (3, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.06455548131484677, 'num_filters_1': 100, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.02216852146089654}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0077065880992543455, 'info': {'data04': 0.0077065880992543455, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.06455548131484677, 'num_filters_1': 100, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.02216852146089654}"}}
exception: None

18:01:42 job_callback for (3, 0, 3) started
18:01:42 job_callback for (3, 0, 3) got condition
18:01:42 DISPATCHER: Trying to submit another job.
18:01:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:01:42 Only 8 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
18:01:42 HBMASTER: Trying to run another job!
18:01:42 job_callback for (3, 0, 3) finished
18:01:42 start sampling a new configuration.
18:01:42 done sampling a new configuration.
18:01:42 HBMASTER: schedule new run for iteration 4
18:01:42 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
18:01:42 HBMASTER: submitting job (4, 0, 0) to dispatcher
18:01:42 DISPATCHER: trying to submit job (4, 0, 0)
18:01:42 DISPATCHER: trying to notify the job_runner thread.
18:01:42 HBMASTER: job (4, 0, 0) submitted to dispatcher
18:01:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:01:42 DISPATCHER: Trying to submit another job.
18:01:42 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:01:42 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:01:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:01:42 WORKER: start processing job (4, 0, 0)
18:01:42 WORKER: args: ()
18:01:42 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.004466813345855306, 'num_filters_1': 25, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.07896643825473183}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:02:07 DISPATCHER: Starting worker discovery
18:02:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:02:07 DISPATCHER: Finished worker discovery
18:02:43 WORKER: done with job (4, 0, 0), trying to register it.
18:02:43 WORKER: registered result for job (4, 0, 0) with dispatcher
18:02:43 DISPATCHER: job (4, 0, 0) finished
18:02:43 DISPATCHER: register_result: lock acquired
18:02:43 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:02:43 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.004466813345855306, 'num_filters_1': 25, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.07896643825473183}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.06369330311000575, 'info': {'data04': 0.06369330311000575, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.004466813345855306, 'num_filters_1': 25, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.07896643825473183}"}}
exception: None

18:02:43 job_callback for (4, 0, 0) started
18:02:43 DISPATCHER: Trying to submit another job.
18:02:43 job_callback for (4, 0, 0) got condition
18:02:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:02:43 HBMASTER: Trying to run another job!
18:02:43 job_callback for (4, 0, 0) finished
18:02:43 start sampling a new configuration.
18:02:43 done sampling a new configuration.
18:02:43 HBMASTER: schedule new run for iteration 4
18:02:43 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
18:02:43 HBMASTER: submitting job (4, 0, 1) to dispatcher
18:02:43 DISPATCHER: trying to submit job (4, 0, 1)
18:02:43 DISPATCHER: trying to notify the job_runner thread.
18:02:43 HBMASTER: job (4, 0, 1) submitted to dispatcher
18:02:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:02:43 DISPATCHER: Trying to submit another job.
18:02:43 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:02:43 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:02:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:02:43 WORKER: start processing job (4, 0, 1)
18:02:43 WORKER: args: ()
18:02:43 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.02499520036810352, 'num_filters_1': 18, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.014734997154929406, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 64, 'num_filters_3': 67}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:03:07 DISPATCHER: Starting worker discovery
18:03:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:03:07 DISPATCHER: Finished worker discovery
18:03:50 WORKER: done with job (4, 0, 1), trying to register it.
18:03:50 WORKER: registered result for job (4, 0, 1) with dispatcher
18:03:50 DISPATCHER: job (4, 0, 1) finished
18:03:50 DISPATCHER: register_result: lock acquired
18:03:50 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:03:50 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.02499520036810352, 'num_filters_1': 18, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.014734997154929406, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 64, 'num_filters_3': 67}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -1.2155650231459532e-08, 'info': {'data04': 1.2155650231459532e-08, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.02499520036810352, 'num_filters_1': 18, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.014734997154929406, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 64, 'num_filters_3': 67}"}}
exception: None

18:03:50 job_callback for (4, 0, 1) started
18:03:50 job_callback for (4, 0, 1) got condition
18:03:50 DISPATCHER: Trying to submit another job.
18:03:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:03:50 HBMASTER: Trying to run another job!
18:03:50 job_callback for (4, 0, 1) finished
18:03:50 start sampling a new configuration.
18:03:50 done sampling a new configuration.
18:03:50 HBMASTER: schedule new run for iteration 4
18:03:50 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
18:03:50 HBMASTER: submitting job (4, 0, 2) to dispatcher
18:03:50 DISPATCHER: trying to submit job (4, 0, 2)
18:03:50 DISPATCHER: trying to notify the job_runner thread.
18:03:50 HBMASTER: job (4, 0, 2) submitted to dispatcher
18:03:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:03:50 DISPATCHER: Trying to submit another job.
18:03:50 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:03:50 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:03:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:03:50 WORKER: start processing job (4, 0, 2)
18:03:50 WORKER: args: ()
18:03:50 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.022226185903432567, 'num_filters_1': 40, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.02546878068691622}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:04:07 DISPATCHER: Starting worker discovery
18:04:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:04:07 DISPATCHER: Finished worker discovery
18:04:52 WORKER: done with job (4, 0, 2), trying to register it.
18:04:52 WORKER: registered result for job (4, 0, 2) with dispatcher
18:04:52 DISPATCHER: job (4, 0, 2) finished
18:04:52 DISPATCHER: register_result: lock acquired
18:04:52 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:04:52 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.022226185903432567, 'num_filters_1': 40, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.02546878068691622}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.10757841368610047, 'info': {'data04': 0.10757841368610047, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.022226185903432567, 'num_filters_1': 40, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.02546878068691622}"}}
exception: None

18:04:52 job_callback for (4, 0, 2) started
18:04:52 DISPATCHER: Trying to submit another job.
18:04:52 job_callback for (4, 0, 2) got condition
18:04:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:04:52 HBMASTER: Trying to run another job!
18:04:52 job_callback for (4, 0, 2) finished
18:04:52 start sampling a new configuration.
18:04:52 done sampling a new configuration.
18:04:52 HBMASTER: schedule new run for iteration 4
18:04:52 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
18:04:52 HBMASTER: submitting job (4, 0, 3) to dispatcher
18:04:52 DISPATCHER: trying to submit job (4, 0, 3)
18:04:52 DISPATCHER: trying to notify the job_runner thread.
18:04:52 HBMASTER: job (4, 0, 3) submitted to dispatcher
18:04:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:04:52 DISPATCHER: Trying to submit another job.
18:04:52 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:04:52 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:04:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:04:52 WORKER: start processing job (4, 0, 3)
18:04:52 WORKER: args: ()
18:04:52 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.006154098934501963, 'num_filters_1': 111, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.14459221705351635, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 32, 'num_filters_3': 17, 'num_filters_4': 21, 'num_filters_5': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:05:07 DISPATCHER: Starting worker discovery
18:05:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:05:07 DISPATCHER: Finished worker discovery
18:05:53 WORKER: done with job (4, 0, 3), trying to register it.
18:05:53 WORKER: registered result for job (4, 0, 3) with dispatcher
18:05:53 DISPATCHER: job (4, 0, 3) finished
18:05:53 DISPATCHER: register_result: lock acquired
18:05:53 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:05:53 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.006154098934501963, 'num_filters_1': 111, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.14459221705351635, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 32, 'num_filters_3': 17, 'num_filters_4': 21, 'num_filters_5': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 1.698766266944186e-05, 'info': {'data04': -1.698766266944186e-05, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.006154098934501963, 'num_filters_1': 111, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.14459221705351635, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 32, 'num_filters_3': 17, 'num_filters_4': 21, 'num_filters_5': 27}"}}
exception: None

18:05:53 job_callback for (4, 0, 3) started
18:05:53 job_callback for (4, 0, 3) got condition
18:05:53 DISPATCHER: Trying to submit another job.
18:05:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:05:53 HBMASTER: Trying to run another job!
18:05:53 job_callback for (4, 0, 3) finished
18:05:53 start sampling a new configuration.
18:05:53 done sampling a new configuration.
18:05:53 HBMASTER: schedule new run for iteration 4
18:05:53 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
18:05:53 HBMASTER: submitting job (4, 0, 4) to dispatcher
18:05:53 DISPATCHER: trying to submit job (4, 0, 4)
18:05:53 DISPATCHER: trying to notify the job_runner thread.
18:05:53 HBMASTER: job (4, 0, 4) submitted to dispatcher
18:05:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:05:53 DISPATCHER: Trying to submit another job.
18:05:53 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:05:53 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:05:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:05:53 WORKER: start processing job (4, 0, 4)
18:05:53 WORKER: args: ()
18:05:53 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.002935579733199639, 'num_filters_1': 79, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.026141212278630227, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 16, 'num_filters_3': 29, 'num_filters_4': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:06:07 DISPATCHER: Starting worker discovery
18:06:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:06:07 DISPATCHER: Finished worker discovery
18:06:53 WORKER: done with job (4, 0, 4), trying to register it.
18:06:53 WORKER: registered result for job (4, 0, 4) with dispatcher
18:06:53 DISPATCHER: job (4, 0, 4) finished
18:06:53 DISPATCHER: register_result: lock acquired
18:06:53 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:06:53 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.002935579733199639, 'num_filters_1': 79, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.026141212278630227, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 16, 'num_filters_3': 29, 'num_filters_4': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.06223870437373927, 'info': {'data04': 0.06223870437373927, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.002935579733199639, 'num_filters_1': 79, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.026141212278630227, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 16, 'num_filters_3': 29, 'num_filters_4': 20}"}}
exception: None

18:06:53 job_callback for (4, 0, 4) started
18:06:53 DISPATCHER: Trying to submit another job.
18:06:53 job_callback for (4, 0, 4) got condition
18:06:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:06:53 HBMASTER: Trying to run another job!
18:06:53 job_callback for (4, 0, 4) finished
18:06:53 start sampling a new configuration.
18:06:53 done sampling a new configuration.
18:06:53 HBMASTER: schedule new run for iteration 4
18:06:53 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
18:06:53 HBMASTER: submitting job (4, 0, 5) to dispatcher
18:06:53 DISPATCHER: trying to submit job (4, 0, 5)
18:06:53 DISPATCHER: trying to notify the job_runner thread.
18:06:53 HBMASTER: job (4, 0, 5) submitted to dispatcher
18:06:53 DISPATCHER: Trying to submit another job.
18:06:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:06:53 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:06:53 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:06:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:06:53 WORKER: start processing job (4, 0, 5)
18:06:53 WORKER: args: ()
18:06:53 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006024649274698134, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.026107263219437758, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 32, 'num_filters_3': 37, 'num_filters_4': 24, 'num_filters_5': 56}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:07:07 DISPATCHER: Starting worker discovery
18:07:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:07:07 DISPATCHER: Finished worker discovery
18:07:53 WORKER: done with job (4, 0, 5), trying to register it.
18:07:53 WORKER: registered result for job (4, 0, 5) with dispatcher
18:07:53 DISPATCHER: job (4, 0, 5) finished
18:07:53 DISPATCHER: register_result: lock acquired
18:07:53 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:07:53 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006024649274698134, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.026107263219437758, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 32, 'num_filters_3': 37, 'num_filters_4': 24, 'num_filters_5': 56}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006024649274698134, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.026107263219437758, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 32, 'num_filters_3': 37, 'num_filters_4': 24, 'num_filters_5': 56}"}}
exception: None

18:07:53 job_callback for (4, 0, 5) started
18:07:53 job_callback for (4, 0, 5) got condition
18:07:53 DISPATCHER: Trying to submit another job.
18:07:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:07:53 HBMASTER: Trying to run another job!
18:07:53 job_callback for (4, 0, 5) finished
18:07:53 start sampling a new configuration.
18:07:53 done sampling a new configuration.
18:07:53 HBMASTER: schedule new run for iteration 4
18:07:53 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
18:07:53 HBMASTER: submitting job (4, 0, 6) to dispatcher
18:07:53 DISPATCHER: trying to submit job (4, 0, 6)
18:07:53 DISPATCHER: trying to notify the job_runner thread.
18:07:53 HBMASTER: job (4, 0, 6) submitted to dispatcher
18:07:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:07:53 DISPATCHER: Trying to submit another job.
18:07:53 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:07:53 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:07:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:07:53 WORKER: start processing job (4, 0, 6)
18:07:53 WORKER: args: ()
18:07:53 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0630190795537271, 'num_filters_1': 112, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.03215276769081809}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:08:07 DISPATCHER: Starting worker discovery
18:08:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:08:07 DISPATCHER: Finished worker discovery
18:09:05 WORKER: done with job (4, 0, 6), trying to register it.
18:09:05 WORKER: registered result for job (4, 0, 6) with dispatcher
18:09:05 DISPATCHER: job (4, 0, 6) finished
18:09:05 DISPATCHER: register_result: lock acquired
18:09:05 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:09:05 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0630190795537271, 'num_filters_1': 112, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.03215276769081809}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.06370498141760712, 'info': {'data04': 0.06370498141760712, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0630190795537271, 'num_filters_1': 112, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.03215276769081809}"}}
exception: None

18:09:05 job_callback for (4, 0, 6) started
18:09:05 DISPATCHER: Trying to submit another job.
18:09:05 job_callback for (4, 0, 6) got condition
18:09:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:09:05 done building a new model for budget 44.444444 based on 17/28 split
Best loss for this budget:-0.162115





18:09:05 HBMASTER: Trying to run another job!
18:09:05 job_callback for (4, 0, 6) finished
18:09:05 start sampling a new configuration.
18:09:05 done sampling a new configuration.
18:09:05 HBMASTER: schedule new run for iteration 4
18:09:05 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
18:09:05 HBMASTER: submitting job (4, 0, 7) to dispatcher
18:09:05 DISPATCHER: trying to submit job (4, 0, 7)
18:09:05 DISPATCHER: trying to notify the job_runner thread.
18:09:05 HBMASTER: job (4, 0, 7) submitted to dispatcher
18:09:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:09:05 DISPATCHER: Trying to submit another job.
18:09:05 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:09:05 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:09:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:09:05 WORKER: start processing job (4, 0, 7)
18:09:05 WORKER: args: ()
18:09:05 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0012306283829648303, 'num_filters_1': 48, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.026166648095047873, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 81, 'num_filters_3': 30, 'num_filters_4': 26, 'num_filters_5': 30}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:09:07 DISPATCHER: Starting worker discovery
18:09:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:09:07 DISPATCHER: Finished worker discovery
18:10:06 WORKER: done with job (4, 0, 7), trying to register it.
18:10:06 WORKER: registered result for job (4, 0, 7) with dispatcher
18:10:06 DISPATCHER: job (4, 0, 7) finished
18:10:06 DISPATCHER: register_result: lock acquired
18:10:06 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:10:06 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0012306283829648303, 'num_filters_1': 48, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.026166648095047873, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 81, 'num_filters_3': 30, 'num_filters_4': 26, 'num_filters_5': 30}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.07587256375538508, 'info': {'data04': 0.07587256375538508, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0012306283829648303, 'num_filters_1': 48, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.026166648095047873, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 81, 'num_filters_3': 30, 'num_filters_4': 26, 'num_filters_5': 30}"}}
exception: None

18:10:06 job_callback for (4, 0, 7) started
18:10:06 DISPATCHER: Trying to submit another job.
18:10:06 job_callback for (4, 0, 7) got condition
18:10:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:10:06 done building a new model for budget 44.444444 based on 17/29 split
Best loss for this budget:-0.162115





18:10:06 HBMASTER: Trying to run another job!
18:10:06 job_callback for (4, 0, 7) finished
18:10:06 start sampling a new configuration.
18:10:06 best_vector: [0, 0, 0.5591213408748843, 0.4472408441902565, 0.8864062869470407, 0, 0.002015980762686276, 0.4874582346962282, 1, 1, 2, 0, 0.4605100355666141, 0.29186446414365674, 0.17626207217835785, 0.8280296302928339], 2.6553477942269533e-28, 3.7659850139937254e-05, -4.342259808664241e-05
18:10:06 done sampling a new configuration.
18:10:06 HBMASTER: schedule new run for iteration 4
18:10:06 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
18:10:06 HBMASTER: submitting job (4, 0, 8) to dispatcher
18:10:06 DISPATCHER: trying to submit job (4, 0, 8)
18:10:06 DISPATCHER: trying to notify the job_runner thread.
18:10:06 HBMASTER: job (4, 0, 8) submitted to dispatcher
18:10:06 DISPATCHER: Trying to submit another job.
18:10:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:10:06 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:10:06 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:10:06 WORKER: start processing job (4, 0, 8)
18:10:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:10:06 WORKER: args: ()
18:10:06 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.013129333551664384, 'num_filters_1': 40, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 10, 'weight_decay': 0.04307227241665704, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 41, 'num_filters_3': 29, 'num_filters_4': 23, 'num_filters_5': 89}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:10:07 DISPATCHER: Starting worker discovery
18:10:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:10:07 DISPATCHER: Finished worker discovery
18:11:07 DISPATCHER: Starting worker discovery
18:11:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:11:07 DISPATCHER: Finished worker discovery
18:11:16 WORKER: done with job (4, 0, 8), trying to register it.
18:11:16 WORKER: registered result for job (4, 0, 8) with dispatcher
18:11:16 DISPATCHER: job (4, 0, 8) finished
18:11:16 DISPATCHER: register_result: lock acquired
18:11:16 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:11:16 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.013129333551664384, 'num_filters_1': 40, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 10, 'weight_decay': 0.04307227241665704, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 41, 'num_filters_3': 29, 'num_filters_4': 23, 'num_filters_5': 89}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -4.1058513004929045e-06, 'info': {'data04': 4.1058513004929045e-06, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.013129333551664384, 'num_filters_1': 40, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 10, 'weight_decay': 0.04307227241665704, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 41, 'num_filters_3': 29, 'num_filters_4': 23, 'num_filters_5': 89}"}}
exception: None

18:11:16 job_callback for (4, 0, 8) started
18:11:16 job_callback for (4, 0, 8) got condition
18:11:16 DISPATCHER: Trying to submit another job.
18:11:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:11:16 done building a new model for budget 44.444444 based on 17/30 split
Best loss for this budget:-0.162115





18:11:16 HBMASTER: Trying to run another job!
18:11:16 job_callback for (4, 0, 8) finished
18:11:16 start sampling a new configuration.
18:11:16 done sampling a new configuration.
18:11:16 HBMASTER: schedule new run for iteration 4
18:11:16 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
18:11:16 HBMASTER: submitting job (4, 0, 9) to dispatcher
18:11:16 DISPATCHER: trying to submit job (4, 0, 9)
18:11:16 DISPATCHER: trying to notify the job_runner thread.
18:11:16 HBMASTER: job (4, 0, 9) submitted to dispatcher
18:11:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:11:16 DISPATCHER: Trying to submit another job.
18:11:16 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:11:16 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:11:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:11:16 WORKER: start processing job (4, 0, 9)
18:11:16 WORKER: args: ()
18:11:16 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.007037190063653176, 'num_filters_1': 40, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.051667431647910954, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 20, 'num_filters_3': 52, 'num_filters_4': 117, 'num_filters_5': 125}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:12:07 DISPATCHER: Starting worker discovery
18:12:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:12:07 DISPATCHER: Finished worker discovery
18:12:17 WORKER: done with job (4, 0, 9), trying to register it.
18:12:17 WORKER: registered result for job (4, 0, 9) with dispatcher
18:12:17 DISPATCHER: job (4, 0, 9) finished
18:12:17 DISPATCHER: register_result: lock acquired
18:12:17 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:12:17 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.007037190063653176, 'num_filters_1': 40, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.051667431647910954, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 20, 'num_filters_3': 52, 'num_filters_4': 117, 'num_filters_5': 125}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.007037190063653176, 'num_filters_1': 40, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.051667431647910954, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 20, 'num_filters_3': 52, 'num_filters_4': 117, 'num_filters_5': 125}"}}
exception: None

18:12:17 job_callback for (4, 0, 9) started
18:12:17 job_callback for (4, 0, 9) got condition
18:12:17 DISPATCHER: Trying to submit another job.
18:12:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:12:17 done building a new model for budget 44.444444 based on 17/31 split
Best loss for this budget:-0.162115





18:12:17 HBMASTER: Trying to run another job!
18:12:17 job_callback for (4, 0, 9) finished
18:12:17 start sampling a new configuration.
18:12:17 done sampling a new configuration.
18:12:17 HBMASTER: schedule new run for iteration 4
18:12:17 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
18:12:17 HBMASTER: submitting job (4, 0, 10) to dispatcher
18:12:17 DISPATCHER: trying to submit job (4, 0, 10)
18:12:17 DISPATCHER: trying to notify the job_runner thread.
18:12:17 HBMASTER: job (4, 0, 10) submitted to dispatcher
18:12:17 DISPATCHER: Trying to submit another job.
18:12:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:12:17 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:12:17 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:12:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:12:17 WORKER: start processing job (4, 0, 10)
18:12:17 WORKER: args: ()
18:12:17 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0030331375884015215, 'num_filters_1': 89, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.04527238391083688}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:13:07 DISPATCHER: Starting worker discovery
18:13:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:13:07 DISPATCHER: Finished worker discovery
18:13:26 WORKER: done with job (4, 0, 10), trying to register it.
18:13:26 WORKER: registered result for job (4, 0, 10) with dispatcher
18:13:26 DISPATCHER: job (4, 0, 10) finished
18:13:26 DISPATCHER: register_result: lock acquired
18:13:26 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:13:26 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0030331375884015215, 'num_filters_1': 89, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.04527238391083688}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.039484199621656585, 'info': {'data04': 0.039484199621656585, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0030331375884015215, 'num_filters_1': 89, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.04527238391083688}"}}
exception: None

18:13:26 job_callback for (4, 0, 10) started
18:13:26 job_callback for (4, 0, 10) got condition
18:13:26 DISPATCHER: Trying to submit another job.
18:13:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:13:26 done building a new model for budget 44.444444 based on 17/32 split
Best loss for this budget:-0.162115





18:13:26 HBMASTER: Trying to run another job!
18:13:26 job_callback for (4, 0, 10) finished
18:13:26 start sampling a new configuration.
18:13:26 best_vector: [0, 0, 0.13122724115602935, 0.5044525021131219, 0.004729906062243397, 0, 0.0577920117683737, 0.8688393020877426, 1, 1, 1, 0, 0.9607469621218777, 0.9154608786147866, 0.4735411315831105, 0.9974257115123419], 0.0004828703423840155, 1.1819519549272717e-05, 5.7072954515718815e-09
18:13:26 done sampling a new configuration.
18:13:26 HBMASTER: schedule new run for iteration 4
18:13:26 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
18:13:26 HBMASTER: submitting job (4, 0, 11) to dispatcher
18:13:26 DISPATCHER: trying to submit job (4, 0, 11)
18:13:26 DISPATCHER: trying to notify the job_runner thread.
18:13:26 HBMASTER: job (4, 0, 11) submitted to dispatcher
18:13:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:13:26 DISPATCHER: Trying to submit another job.
18:13:26 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:13:26 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:13:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:13:26 WORKER: start processing job (4, 0, 11)
18:13:26 WORKER: args: ()
18:13:26 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0018300142954812693, 'num_filters_1': 45, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.13501623504365046}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:14:07 DISPATCHER: Starting worker discovery
18:14:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:14:07 DISPATCHER: Finished worker discovery
18:14:41 WORKER: done with job (4, 0, 11), trying to register it.
18:14:41 WORKER: registered result for job (4, 0, 11) with dispatcher
18:14:41 DISPATCHER: job (4, 0, 11) finished
18:14:41 DISPATCHER: register_result: lock acquired
18:14:41 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:14:41 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0018300142954812693, 'num_filters_1': 45, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.13501623504365046}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0004010899473983822, 'info': {'data04': 0.0004010899473983822, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0018300142954812693, 'num_filters_1': 45, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.13501623504365046}"}}
exception: None

18:14:41 job_callback for (4, 0, 11) started
18:14:41 DISPATCHER: Trying to submit another job.
18:14:41 job_callback for (4, 0, 11) got condition
18:14:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:14:41 done building a new model for budget 44.444444 based on 17/33 split
Best loss for this budget:-0.162115





18:14:41 HBMASTER: Trying to run another job!
18:14:41 job_callback for (4, 0, 11) finished
18:14:41 start sampling a new configuration.
18:14:41 done sampling a new configuration.
18:14:41 HBMASTER: schedule new run for iteration 4
18:14:41 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
18:14:41 HBMASTER: submitting job (4, 0, 12) to dispatcher
18:14:41 DISPATCHER: trying to submit job (4, 0, 12)
18:14:41 DISPATCHER: trying to notify the job_runner thread.
18:14:41 HBMASTER: job (4, 0, 12) submitted to dispatcher
18:14:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:14:41 DISPATCHER: Trying to submit another job.
18:14:41 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:14:41 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:14:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:14:41 WORKER: start processing job (4, 0, 12)
18:14:41 WORKER: args: ()
18:14:41 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.001991717358562793, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.042432584618417805, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 26, 'num_filters_3': 79, 'num_filters_4': 48, 'num_filters_5': 111}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:15:07 DISPATCHER: Starting worker discovery
18:15:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:15:07 DISPATCHER: Finished worker discovery
18:15:41 WORKER: done with job (4, 0, 12), trying to register it.
18:15:41 WORKER: registered result for job (4, 0, 12) with dispatcher
18:15:41 DISPATCHER: job (4, 0, 12) finished
18:15:41 DISPATCHER: register_result: lock acquired
18:15:41 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:15:41 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.001991717358562793, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.042432584618417805, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 26, 'num_filters_3': 79, 'num_filters_4': 48, 'num_filters_5': 111}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.001991717358562793, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.042432584618417805, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 26, 'num_filters_3': 79, 'num_filters_4': 48, 'num_filters_5': 111}"}}
exception: None

18:15:41 job_callback for (4, 0, 12) started
18:15:41 job_callback for (4, 0, 12) got condition
18:15:41 DISPATCHER: Trying to submit another job.
18:15:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:15:41 done building a new model for budget 44.444444 based on 17/34 split
Best loss for this budget:-0.162115





18:15:41 HBMASTER: Trying to run another job!
18:15:41 job_callback for (4, 0, 12) finished
18:15:41 start sampling a new configuration.
18:15:42 best_vector: [0, 1, 0.18143406898001457, 0.4951254264487134, 0.44374878793733663, 1, 0.5857347767109016, 0.9732165229210374, 0, 0, 0, 1, 0.7419903543958354, 0.08384194208513338, 0.7035723736926718, 0.2917798927927698], 7.563392797425376e-29, 0.00013221579610943993, -1.929459679092319e-06
18:15:42 done sampling a new configuration.
18:15:42 HBMASTER: schedule new run for iteration 4
18:15:42 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
18:15:42 HBMASTER: submitting job (4, 0, 13) to dispatcher
18:15:42 DISPATCHER: trying to submit job (4, 0, 13)
18:15:42 DISPATCHER: trying to notify the job_runner thread.
18:15:42 HBMASTER: job (4, 0, 13) submitted to dispatcher
18:15:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:15:42 DISPATCHER: Trying to submit another job.
18:15:42 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:15:42 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:15:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:15:42 WORKER: start processing job (4, 0, 13)
18:15:42 WORKER: args: ()
18:15:42 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0023060469122247558, 'num_filters_1': 44, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.18457967994357144, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 74, 'num_filters_3': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:16:07 DISPATCHER: Starting worker discovery
18:16:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:16:07 DISPATCHER: Finished worker discovery
18:16:44 WORKER: done with job (4, 0, 13), trying to register it.
18:16:44 WORKER: registered result for job (4, 0, 13) with dispatcher
18:16:44 DISPATCHER: job (4, 0, 13) finished
18:16:44 DISPATCHER: register_result: lock acquired
18:16:44 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:16:44 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0023060469122247558, 'num_filters_1': 44, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.18457967994357144, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 74, 'num_filters_3': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.009783651130476127, 'info': {'data04': -0.009783651130476127, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0023060469122247558, 'num_filters_1': 44, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.18457967994357144, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 74, 'num_filters_3': 19}"}}
exception: None

18:16:44 job_callback for (4, 0, 13) started
18:16:44 job_callback for (4, 0, 13) got condition
18:16:44 DISPATCHER: Trying to submit another job.
18:16:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:16:44 done building a new model for budget 44.444444 based on 17/34 split
Best loss for this budget:-0.162115





18:16:44 HBMASTER: Trying to run another job!
18:16:44 job_callback for (4, 0, 13) finished
18:16:44 start sampling a new configuration.
18:16:44 best_vector: [0, 0, 0.9580610207020255, 0.5527960724213323, 0.020686628902274726, 0, 0.2705118265565826, 0.3684323426147231, 1, 1, 2, 2, 0.06647079972082738, 0.8907214341989373, 0.022565011513904665, 0.07060035231554099], 0.0035410191065803295, 0.000964514894570395, 3.4153656702550807e-06
18:16:44 done sampling a new configuration.
18:16:44 HBMASTER: schedule new run for iteration 4
18:16:44 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
18:16:44 HBMASTER: submitting job (4, 0, 14) to dispatcher
18:16:44 DISPATCHER: trying to submit job (4, 0, 14)
18:16:44 DISPATCHER: trying to notify the job_runner thread.
18:16:44 HBMASTER: job (4, 0, 14) submitted to dispatcher
18:16:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:16:44 DISPATCHER: Trying to submit another job.
18:16:44 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:16:44 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:16:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:16:44 WORKER: start processing job (4, 0, 14)
18:16:44 WORKER: args: ()
18:16:44 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.08243697391990984, 'num_filters_1': 50, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.030153763835681725}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:17:07 DISPATCHER: Starting worker discovery
18:17:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:17:07 DISPATCHER: Finished worker discovery
18:17:50 WORKER: done with job (4, 0, 14), trying to register it.
18:17:50 WORKER: registered result for job (4, 0, 14) with dispatcher
18:17:50 DISPATCHER: job (4, 0, 14) finished
18:17:50 DISPATCHER: register_result: lock acquired
18:17:50 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:17:50 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.08243697391990984, 'num_filters_1': 50, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.030153763835681725}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.00019060123983405516, 'info': {'data04': -0.00019060123983405516, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.08243697391990984, 'num_filters_1': 50, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.030153763835681725}"}}
exception: None

18:17:50 job_callback for (4, 0, 14) started
18:17:50 DISPATCHER: Trying to submit another job.
18:17:50 job_callback for (4, 0, 14) got condition
18:17:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:17:50 done building a new model for budget 44.444444 based on 17/35 split
Best loss for this budget:-0.162115





18:17:50 HBMASTER: Trying to run another job!
18:17:50 job_callback for (4, 0, 14) finished
18:17:50 start sampling a new configuration.
18:17:50 best_vector: [0, 0, 0.6884815539330829, 0.8206981202940385, 0.7558276366256721, 1, 0.9371215276319848, 0.14067613723127387, 1, 1, 1, 2, 0.13166367463963716, 0.3689483888819073, 0.19358046551164, 0.1341279784676357], 0.0004488019269049628, 0.005294584295738318, 2.3762196340881127e-06
18:17:50 done sampling a new configuration.
18:17:50 HBMASTER: schedule new run for iteration 4
18:17:50 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
18:17:50 HBMASTER: submitting job (4, 0, 15) to dispatcher
18:17:50 DISPATCHER: trying to submit job (4, 0, 15)
18:17:50 DISPATCHER: trying to notify the job_runner thread.
18:17:50 HBMASTER: job (4, 0, 15) submitted to dispatcher
18:17:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:17:50 DISPATCHER: Trying to submit another job.
18:17:50 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:17:50 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:17:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:17:50 WORKER: start processing job (4, 0, 15)
18:17:50 WORKER: args: ()
18:17:50 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.023821171064010487, 'num_filters_1': 88, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.015241365369449577, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 20, 'num_filters_3': 34, 'num_filters_4': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:18:07 DISPATCHER: Starting worker discovery
18:18:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:18:07 DISPATCHER: Finished worker discovery
18:18:51 WORKER: done with job (4, 0, 15), trying to register it.
18:18:51 WORKER: registered result for job (4, 0, 15) with dispatcher
18:18:51 DISPATCHER: job (4, 0, 15) finished
18:18:51 DISPATCHER: register_result: lock acquired
18:18:51 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:18:51 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.023821171064010487, 'num_filters_1': 88, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.015241365369449577, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 20, 'num_filters_3': 34, 'num_filters_4': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.10099622980100424, 'info': {'data04': 0.10099622980100424, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.023821171064010487, 'num_filters_1': 88, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.015241365369449577, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 20, 'num_filters_3': 34, 'num_filters_4': 23}"}}
exception: None

18:18:51 job_callback for (4, 0, 15) started
18:18:51 DISPATCHER: Trying to submit another job.
18:18:51 job_callback for (4, 0, 15) got condition
18:18:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:18:51 done building a new model for budget 44.444444 based on 17/36 split
Best loss for this budget:-0.162115





18:18:51 HBMASTER: Trying to run another job!
18:18:51 job_callback for (4, 0, 15) finished
18:18:51 start sampling a new configuration.
18:18:51 done sampling a new configuration.
18:18:51 HBMASTER: schedule new run for iteration 4
18:18:51 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
18:18:51 HBMASTER: submitting job (4, 0, 16) to dispatcher
18:18:51 DISPATCHER: trying to submit job (4, 0, 16)
18:18:51 DISPATCHER: trying to notify the job_runner thread.
18:18:51 HBMASTER: job (4, 0, 16) submitted to dispatcher
18:18:51 DISPATCHER: Trying to submit another job.
18:18:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:18:51 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:18:51 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:18:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:18:51 WORKER: start processing job (4, 0, 16)
18:18:51 WORKER: args: ()
18:18:51 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.010190019601777693, 'num_filters_1': 28, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.011061536143196065, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 20, 'num_filters_3': 23, 'num_filters_4': 29}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:19:07 DISPATCHER: Starting worker discovery
18:19:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:19:07 DISPATCHER: Finished worker discovery
18:19:53 WORKER: done with job (4, 0, 16), trying to register it.
18:19:53 WORKER: registered result for job (4, 0, 16) with dispatcher
18:19:53 DISPATCHER: job (4, 0, 16) finished
18:19:53 DISPATCHER: register_result: lock acquired
18:19:53 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:19:53 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.010190019601777693, 'num_filters_1': 28, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.011061536143196065, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 20, 'num_filters_3': 23, 'num_filters_4': 29}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.16772113352437915, 'info': {'data04': 0.16772113352437915, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.010190019601777693, 'num_filters_1': 28, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.011061536143196065, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 20, 'num_filters_3': 23, 'num_filters_4': 29}"}}
exception: None

18:19:53 job_callback for (4, 0, 16) started
18:19:53 DISPATCHER: Trying to submit another job.
18:19:53 job_callback for (4, 0, 16) got condition
18:19:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:19:53 done building a new model for budget 44.444444 based on 17/37 split
Best loss for this budget:-0.167721





18:19:53 HBMASTER: Trying to run another job!
18:19:53 job_callback for (4, 0, 16) finished
18:19:53 start sampling a new configuration.
18:19:53 best_vector: [2, 0, 0.8166029347057977, 0.2494614669963943, 0.1597725284863285, 1, 0.1838108286218093, 0.057566711917275235, 0, 1, 1, 2, 0.25428788204088554, 0.1937510141898139, 0.6028246121076759, 0.8661710341580304], 7.786333664963932e-29, 0.0001284301499304721, -3.3654870811364026e-06
18:19:53 done sampling a new configuration.
18:19:53 HBMASTER: schedule new run for iteration 4
18:19:53 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
18:19:53 HBMASTER: submitting job (4, 0, 17) to dispatcher
18:19:53 DISPATCHER: trying to submit job (4, 0, 17)
18:19:53 DISPATCHER: trying to notify the job_runner thread.
18:19:53 HBMASTER: job (4, 0, 17) submitted to dispatcher
18:19:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:19:53 DISPATCHER: Trying to submit another job.
18:19:53 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:19:53 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:19:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:19:53 WORKER: start processing job (4, 0, 17)
18:19:53 WORKER: args: ()
18:19:53 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.04297400889742314, 'num_filters_1': 26, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.011882177041140142}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:20:07 DISPATCHER: Starting worker discovery
18:20:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:20:07 DISPATCHER: Finished worker discovery
18:21:03 WORKER: done with job (4, 0, 17), trying to register it.
18:21:03 WORKER: registered result for job (4, 0, 17) with dispatcher
18:21:03 DISPATCHER: job (4, 0, 17) finished
18:21:03 DISPATCHER: register_result: lock acquired
18:21:03 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:21:03 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.04297400889742314, 'num_filters_1': 26, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.011882177041140142}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.14003313508503984, 'info': {'data04': 0.14003313508503984, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.04297400889742314, 'num_filters_1': 26, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.011882177041140142}"}}
exception: None

18:21:03 job_callback for (4, 0, 17) started
18:21:03 DISPATCHER: Trying to submit another job.
18:21:03 job_callback for (4, 0, 17) got condition
18:21:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:21:03 done building a new model for budget 44.444444 based on 17/38 split
Best loss for this budget:-0.167721





18:21:03 HBMASTER: Trying to run another job!
18:21:03 job_callback for (4, 0, 17) finished
18:21:03 start sampling a new configuration.
18:21:03 best_vector: [1, 0, 0.0802861345636508, 0.5233359009632031, 0.3810882802294241, 1, 0.09328661157464435, 0.16654482419301395, 2, 1, 0, 1, 0.9464765021830461, 0.08711908095026794, 0.2086969439581954, 0.3520777129339392], 0.0017514108448919627, 0.00048639588186385, 8.518790224071368e-07
18:21:03 done sampling a new configuration.
18:21:03 HBMASTER: schedule new run for iteration 4
18:21:03 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
18:21:03 HBMASTER: submitting job (4, 0, 18) to dispatcher
18:21:03 DISPATCHER: trying to submit job (4, 0, 18)
18:21:03 DISPATCHER: trying to notify the job_runner thread.
18:21:03 HBMASTER: job (4, 0, 18) submitted to dispatcher
18:21:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:21:03 DISPATCHER: Trying to submit another job.
18:21:03 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:21:03 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:21:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:21:03 WORKER: start processing job (4, 0, 18)
18:21:03 WORKER: args: ()
18:21:03 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0014473456797946247, 'num_filters_1': 47, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.016469477145633012, 'kernel_size_2': 7, 'num_filters_2': 115}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:21:07 DISPATCHER: Starting worker discovery
18:21:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:21:07 DISPATCHER: Finished worker discovery
18:22:07 DISPATCHER: Starting worker discovery
18:22:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:22:07 DISPATCHER: Finished worker discovery
18:22:09 WORKER: done with job (4, 0, 18), trying to register it.
18:22:09 WORKER: registered result for job (4, 0, 18) with dispatcher
18:22:09 DISPATCHER: job (4, 0, 18) finished
18:22:09 DISPATCHER: register_result: lock acquired
18:22:09 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:22:09 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0014473456797946247, 'num_filters_1': 47, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.016469477145633012, 'kernel_size_2': 7, 'num_filters_2': 115}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.11340215334665996, 'info': {'data04': 0.11340215334665996, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0014473456797946247, 'num_filters_1': 47, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.016469477145633012, 'kernel_size_2': 7, 'num_filters_2': 115}"}}
exception: None

18:22:09 job_callback for (4, 0, 18) started
18:22:09 job_callback for (4, 0, 18) got condition
18:22:09 DISPATCHER: Trying to submit another job.
18:22:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:22:12 done building a new model for budget 44.444444 based on 17/39 split
Best loss for this budget:-0.167721





18:22:12 HBMASTER: Trying to run another job!
18:22:12 job_callback for (4, 0, 18) finished
18:22:12 start sampling a new configuration.
18:22:12 best_vector: [2, 1, 0.03642880308058727, 0.6013087908542482, 0.37033697252756764, 1, 0.11142988169785117, 0.028631997105792784, 1, 0, 2, 1, 0.8063634414539737, 0.3149492919385345, 0.33345471119329173, 0.6384477474989545], 0.0004251027563593207, 0.0035549841117398866, 1.5112335447142173e-06
18:22:12 done sampling a new configuration.
18:22:12 HBMASTER: schedule new run for iteration 4
18:22:12 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
18:22:12 HBMASTER: submitting job (4, 0, 19) to dispatcher
18:22:12 DISPATCHER: trying to submit job (4, 0, 19)
18:22:12 DISPATCHER: trying to notify the job_runner thread.
18:22:12 HBMASTER: job (4, 0, 19) submitted to dispatcher
18:22:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:22:12 DISPATCHER: Trying to submit another job.
18:22:12 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:22:12 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:22:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:22:12 WORKER: start processing job (4, 0, 19)
18:22:12 WORKER: args: ()
18:22:12 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0011826537308225217, 'num_filters_1': 55, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.01089559839580173, 'kernel_size_2': 5, 'num_filters_2': 85}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:23:07 DISPATCHER: Starting worker discovery
18:23:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:23:07 DISPATCHER: Finished worker discovery
18:23:23 WORKER: done with job (4, 0, 19), trying to register it.
18:23:23 WORKER: registered result for job (4, 0, 19) with dispatcher
18:23:23 DISPATCHER: job (4, 0, 19) finished
18:23:23 DISPATCHER: register_result: lock acquired
18:23:23 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:23:23 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0011826537308225217, 'num_filters_1': 55, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.01089559839580173, 'kernel_size_2': 5, 'num_filters_2': 85}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.15989116376511747, 'info': {'data04': 0.15989116376511747, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0011826537308225217, 'num_filters_1': 55, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.01089559839580173, 'kernel_size_2': 5, 'num_filters_2': 85}"}}
exception: None

18:23:23 job_callback for (4, 0, 19) started
18:23:23 job_callback for (4, 0, 19) got condition
18:23:23 DISPATCHER: Trying to submit another job.
18:23:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:23:23 done building a new model for budget 44.444444 based on 17/39 split
Best loss for this budget:-0.167721





18:23:23 HBMASTER: Trying to run another job!
18:23:23 job_callback for (4, 0, 19) finished
18:23:23 start sampling a new configuration.
18:23:23 done sampling a new configuration.
18:23:23 HBMASTER: schedule new run for iteration 4
18:23:23 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
18:23:23 HBMASTER: submitting job (4, 0, 20) to dispatcher
18:23:23 DISPATCHER: trying to submit job (4, 0, 20)
18:23:23 DISPATCHER: trying to notify the job_runner thread.
18:23:23 HBMASTER: job (4, 0, 20) submitted to dispatcher
18:23:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:23:23 DISPATCHER: Trying to submit another job.
18:23:23 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:23:23 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:23:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:23:23 WORKER: start processing job (4, 0, 20)
18:23:23 WORKER: args: ()
18:23:23 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006064198117371106, 'num_filters_1': 35, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.062026904385621175, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 128, 'num_filters_3': 40, 'num_filters_4': 108}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:24:07 DISPATCHER: Starting worker discovery
18:24:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:24:07 DISPATCHER: Finished worker discovery
18:24:25 WORKER: done with job (4, 0, 20), trying to register it.
18:24:25 WORKER: registered result for job (4, 0, 20) with dispatcher
18:24:25 DISPATCHER: job (4, 0, 20) finished
18:24:25 DISPATCHER: register_result: lock acquired
18:24:25 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:24:25 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006064198117371106, 'num_filters_1': 35, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.062026904385621175, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 128, 'num_filters_3': 40, 'num_filters_4': 108}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -2.873532923100832e-05, 'info': {'data04': 2.873532923100832e-05, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006064198117371106, 'num_filters_1': 35, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.062026904385621175, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 128, 'num_filters_3': 40, 'num_filters_4': 108}"}}
exception: None

18:24:25 job_callback for (4, 0, 20) started
18:24:25 DISPATCHER: Trying to submit another job.
18:24:25 job_callback for (4, 0, 20) got condition
18:24:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:24:25 done building a new model for budget 44.444444 based on 17/40 split
Best loss for this budget:-0.167721





18:24:25 HBMASTER: Trying to run another job!
18:24:25 job_callback for (4, 0, 20) finished
18:24:25 start sampling a new configuration.
18:24:25 done sampling a new configuration.
18:24:25 HBMASTER: schedule new run for iteration 4
18:24:25 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
18:24:25 HBMASTER: submitting job (4, 0, 21) to dispatcher
18:24:25 DISPATCHER: trying to submit job (4, 0, 21)
18:24:25 DISPATCHER: trying to notify the job_runner thread.
18:24:25 HBMASTER: job (4, 0, 21) submitted to dispatcher
18:24:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:24:25 DISPATCHER: Trying to submit another job.
18:24:25 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:24:25 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:24:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:24:25 WORKER: start processing job (4, 0, 21)
18:24:25 WORKER: args: ()
18:24:25 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.01893702257465736, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.08043089276951988, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 65, 'num_filters_3': 92, 'num_filters_4': 22}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:25:07 DISPATCHER: Starting worker discovery
18:25:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:25:07 DISPATCHER: Finished worker discovery
18:25:26 WORKER: done with job (4, 0, 21), trying to register it.
18:25:26 WORKER: registered result for job (4, 0, 21) with dispatcher
18:25:26 DISPATCHER: job (4, 0, 21) finished
18:25:26 DISPATCHER: register_result: lock acquired
18:25:26 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:25:26 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.01893702257465736, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.08043089276951988, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 65, 'num_filters_3': 92, 'num_filters_4': 22}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0007318271281982391, 'info': {'data04': 0.0007318271281982391, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.01893702257465736, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.08043089276951988, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 65, 'num_filters_3': 92, 'num_filters_4': 22}"}}
exception: None

18:25:26 job_callback for (4, 0, 21) started
18:25:26 DISPATCHER: Trying to submit another job.
18:25:26 job_callback for (4, 0, 21) got condition
18:25:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:25:26 done building a new model for budget 44.444444 based on 17/41 split
Best loss for this budget:-0.167721





18:25:26 HBMASTER: Trying to run another job!
18:25:26 job_callback for (4, 0, 21) finished
18:25:26 start sampling a new configuration.
18:25:26 done sampling a new configuration.
18:25:26 HBMASTER: schedule new run for iteration 4
18:25:26 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
18:25:26 HBMASTER: submitting job (4, 0, 22) to dispatcher
18:25:26 DISPATCHER: trying to submit job (4, 0, 22)
18:25:26 DISPATCHER: trying to notify the job_runner thread.
18:25:26 HBMASTER: job (4, 0, 22) submitted to dispatcher
18:25:26 DISPATCHER: Trying to submit another job.
18:25:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:25:26 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:25:26 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:25:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:25:26 WORKER: start processing job (4, 0, 22)
18:25:26 WORKER: args: ()
18:25:26 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.003958641728927311, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.09446332162720326, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 20, 'num_filters_3': 19, 'num_filters_4': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:26:07 DISPATCHER: Starting worker discovery
18:26:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:26:07 DISPATCHER: Finished worker discovery
18:26:28 WORKER: done with job (4, 0, 22), trying to register it.
18:26:28 WORKER: registered result for job (4, 0, 22) with dispatcher
18:26:28 DISPATCHER: job (4, 0, 22) finished
18:26:28 DISPATCHER: register_result: lock acquired
18:26:28 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:26:28 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.003958641728927311, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.09446332162720326, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 20, 'num_filters_3': 19, 'num_filters_4': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -8.58069786596522e-06, 'info': {'data04': 8.58069786596522e-06, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.003958641728927311, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.09446332162720326, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 20, 'num_filters_3': 19, 'num_filters_4': 16}"}}
exception: None

18:26:28 job_callback for (4, 0, 22) started
18:26:28 DISPATCHER: Trying to submit another job.
18:26:28 job_callback for (4, 0, 22) got condition
18:26:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:26:28 done building a new model for budget 44.444444 based on 17/42 split
Best loss for this budget:-0.167721





18:26:28 HBMASTER: Trying to run another job!
18:26:28 job_callback for (4, 0, 22) finished
18:26:28 start sampling a new configuration.
18:26:28 best_vector: [0, 1, 0.05538438636825771, 0.5921045838526886, 0.8561185475060338, 1, 0.4060138321239666, 0.7378172916854371, 2, 1, 2, 1, 0.7509452183392292, 0.6791570490927742, 0.004530753242214081, 0.775483384196145], 0.002625899521470494, 0.008508312647034198, 2.2341974108368453e-05
18:26:28 done sampling a new configuration.
18:26:28 HBMASTER: schedule new run for iteration 4
18:26:28 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
18:26:28 HBMASTER: submitting job (4, 0, 23) to dispatcher
18:26:28 DISPATCHER: trying to submit job (4, 0, 23)
18:26:28 DISPATCHER: trying to notify the job_runner thread.
18:26:28 HBMASTER: job (4, 0, 23) submitted to dispatcher
18:26:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:26:28 DISPATCHER: Trying to submit another job.
18:26:28 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:26:28 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:26:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:26:28 WORKER: start processing job (4, 0, 23)
18:26:28 WORKER: args: ()
18:26:28 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001290531985046317, 'num_filters_1': 54, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.09118479536408479, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 76, 'num_filters_3': 65, 'num_filters_4': 16, 'num_filters_5': 80}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:27:07 DISPATCHER: Starting worker discovery
18:27:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:27:07 DISPATCHER: Finished worker discovery
18:27:31 WORKER: done with job (4, 0, 23), trying to register it.
18:27:31 WORKER: registered result for job (4, 0, 23) with dispatcher
18:27:31 DISPATCHER: job (4, 0, 23) finished
18:27:31 DISPATCHER: register_result: lock acquired
18:27:31 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:27:31 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001290531985046317, 'num_filters_1': 54, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.09118479536408479, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 76, 'num_filters_3': 65, 'num_filters_4': 16, 'num_filters_5': 80}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.035209630280307644, 'info': {'data04': 0.035209630280307644, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001290531985046317, 'num_filters_1': 54, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.09118479536408479, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 76, 'num_filters_3': 65, 'num_filters_4': 16, 'num_filters_5': 80}"}}
exception: None

18:27:31 job_callback for (4, 0, 23) started
18:27:31 job_callback for (4, 0, 23) got condition
18:27:31 DISPATCHER: Trying to submit another job.
18:27:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:27:31 done building a new model for budget 44.444444 based on 17/43 split
Best loss for this budget:-0.167721





18:27:31 HBMASTER: Trying to run another job!
18:27:31 job_callback for (4, 0, 23) finished
18:27:31 start sampling a new configuration.
18:27:31 best_vector: [1, 1, 0.7425213422857952, 0.989072928956049, 0.7443812241848674, 0, 0.0775482331648748, 0.43610927273360456, 2, 1, 0, 0, 0.970865480229915, 0.8532382174531298, 0.8734200509174079, 0.8655911001030153], 0.0015411523890255516, 0.00022938450046837235, 3.535164709022648e-07
18:27:31 done sampling a new configuration.
18:27:31 HBMASTER: schedule new run for iteration 4
18:27:31 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
18:27:31 HBMASTER: submitting job (4, 0, 24) to dispatcher
18:27:31 DISPATCHER: trying to submit job (4, 0, 24)
18:27:31 DISPATCHER: trying to notify the job_runner thread.
18:27:31 HBMASTER: job (4, 0, 24) submitted to dispatcher
18:27:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:27:31 DISPATCHER: Trying to submit another job.
18:27:31 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:27:31 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:27:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:27:31 WORKER: start processing job (4, 0, 24)
18:27:31 WORKER: args: ()
18:27:31 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.03055221380459697, 'num_filters_1': 126, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.036931015118233906, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 121, 'num_filters_3': 94, 'num_filters_4': 98}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:28:07 DISPATCHER: Starting worker discovery
18:28:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:28:07 DISPATCHER: Finished worker discovery
18:28:38 WORKER: done with job (4, 0, 24), trying to register it.
18:28:38 WORKER: registered result for job (4, 0, 24) with dispatcher
18:28:38 DISPATCHER: job (4, 0, 24) finished
18:28:38 DISPATCHER: register_result: lock acquired
18:28:38 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:28:38 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.03055221380459697, 'num_filters_1': 126, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.036931015118233906, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 121, 'num_filters_3': 94, 'num_filters_4': 98}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.03055221380459697, 'num_filters_1': 126, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.036931015118233906, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 121, 'num_filters_3': 94, 'num_filters_4': 98}"}}
exception: None

18:28:38 job_callback for (4, 0, 24) started
18:28:38 DISPATCHER: Trying to submit another job.
18:28:38 job_callback for (4, 0, 24) got condition
18:28:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:28:38 done building a new model for budget 44.444444 based on 17/44 split
Best loss for this budget:-0.167721





18:28:38 HBMASTER: Trying to run another job!
18:28:38 job_callback for (4, 0, 24) finished
18:28:38 start sampling a new configuration.
18:28:38 best_vector: [2, 2, 0.3775443248736803, 0.5891120743639578, 0.4512379534265316, 1, 0.08405344920144638, 0.3516358213041713, 1, 1, 0, 0, 0.277128624820544, 0.8914109016982722, 0.5823792598844069, 0.9598676601327587], 0.0029325802979643175, 0.0040954383321786594, 1.201020176447498e-05
18:28:38 done sampling a new configuration.
18:28:38 HBMASTER: schedule new run for iteration 4
18:28:38 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
18:28:38 HBMASTER: submitting job (4, 0, 25) to dispatcher
18:28:38 DISPATCHER: trying to submit job (4, 0, 25)
18:28:38 DISPATCHER: trying to notify the job_runner thread.
18:28:38 HBMASTER: job (4, 0, 25) submitted to dispatcher
18:28:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:28:38 DISPATCHER: Trying to submit another job.
18:28:38 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:28:38 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:28:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:28:38 WORKER: start processing job (4, 0, 25)
18:28:38 WORKER: args: ()
18:28:38 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005689690589962744, 'num_filters_1': 54, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.028674031042160594, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 28, 'num_filters_3': 102}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:29:07 DISPATCHER: Starting worker discovery
18:29:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:29:07 DISPATCHER: Finished worker discovery
18:29:50 WORKER: done with job (4, 0, 25), trying to register it.
18:29:50 WORKER: registered result for job (4, 0, 25) with dispatcher
18:29:50 DISPATCHER: job (4, 0, 25) finished
18:29:50 DISPATCHER: register_result: lock acquired
18:29:50 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:29:50 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005689690589962744, 'num_filters_1': 54, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.028674031042160594, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 28, 'num_filters_3': 102}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.057412695181374596, 'info': {'data04': 0.057412695181374596, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005689690589962744, 'num_filters_1': 54, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.028674031042160594, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 28, 'num_filters_3': 102}"}}
exception: None

18:29:50 job_callback for (4, 0, 25) started
18:29:50 DISPATCHER: Trying to submit another job.
18:29:50 job_callback for (4, 0, 25) got condition
18:29:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:29:50 done building a new model for budget 44.444444 based on 17/45 split
Best loss for this budget:-0.167721





18:29:50 HBMASTER: Trying to run another job!
18:29:50 job_callback for (4, 0, 25) finished
18:29:50 start sampling a new configuration.
18:29:50 best_vector: [0, 1, 0.09340448338447113, 0.742435013419821, 0.05100066208219753, 1, 0.03283788668029668, 0.05890574805502588, 1, 2, 2, 1, 0.7570470428874629, 0.7086862133997611, 0.07637167122956379, 0.9041991720113117], 0.001471220983142082, 0.004547146139002624, 6.689856813114162e-06
18:29:50 done sampling a new configuration.
18:29:50 HBMASTER: schedule new run for iteration 4
18:29:50 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
18:29:50 HBMASTER: submitting job (4, 0, 26) to dispatcher
18:29:50 DISPATCHER: trying to submit job (4, 0, 26)
18:29:50 DISPATCHER: trying to notify the job_runner thread.
18:29:50 HBMASTER: job (4, 0, 26) submitted to dispatcher
18:29:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:29:50 DISPATCHER: Trying to submit another job.
18:29:50 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:29:50 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:29:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:29:50 WORKER: start processing job (4, 0, 26)
18:29:50 WORKER: args: ()
18:29:50 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001537478200589716, 'num_filters_1': 75, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.011929936859812978}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:30:07 DISPATCHER: Starting worker discovery
18:30:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:30:07 DISPATCHER: Finished worker discovery
18:31:07 DISPATCHER: Starting worker discovery
18:31:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:31:08 DISPATCHER: Finished worker discovery
18:31:09 WORKER: done with job (4, 0, 26), trying to register it.
18:31:09 WORKER: registered result for job (4, 0, 26) with dispatcher
18:31:09 DISPATCHER: job (4, 0, 26) finished
18:31:09 DISPATCHER: register_result: lock acquired
18:31:09 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:31:09 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001537478200589716, 'num_filters_1': 75, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.011929936859812978}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.18849417843725533, 'info': {'data04': 0.18849417843725533, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001537478200589716, 'num_filters_1': 75, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.011929936859812978}"}}
exception: None

18:31:09 job_callback for (4, 0, 26) started
18:31:09 DISPATCHER: Trying to submit another job.
18:31:09 job_callback for (4, 0, 26) got condition
18:31:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:31:09 done building a new model for budget 44.444444 based on 17/45 split
Best loss for this budget:-0.188494





18:31:09 HBMASTER: Trying to run another job!
18:31:09 job_callback for (4, 0, 26) finished
18:31:09 ITERATION: Advancing config (4, 0, 2) to next budget 133.333333
18:31:09 ITERATION: Advancing config (4, 0, 6) to next budget 133.333333
18:31:09 ITERATION: Advancing config (4, 0, 7) to next budget 133.333333
18:31:09 ITERATION: Advancing config (4, 0, 15) to next budget 133.333333
18:31:09 ITERATION: Advancing config (4, 0, 16) to next budget 133.333333
18:31:09 ITERATION: Advancing config (4, 0, 17) to next budget 133.333333
18:31:09 ITERATION: Advancing config (4, 0, 18) to next budget 133.333333
18:31:09 ITERATION: Advancing config (4, 0, 19) to next budget 133.333333
18:31:09 ITERATION: Advancing config (4, 0, 26) to next budget 133.333333
18:31:09 HBMASTER: schedule new run for iteration 4
18:31:09 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
18:31:09 HBMASTER: submitting job (4, 0, 2) to dispatcher
18:31:09 DISPATCHER: trying to submit job (4, 0, 2)
18:31:09 DISPATCHER: trying to notify the job_runner thread.
18:31:09 HBMASTER: job (4, 0, 2) submitted to dispatcher
18:31:09 DISPATCHER: Trying to submit another job.
18:31:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:31:09 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:31:09 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:31:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:31:09 WORKER: start processing job (4, 0, 2)
18:31:09 WORKER: args: ()
18:31:09 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.022226185903432567, 'num_filters_1': 40, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.02546878068691622}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:32:08 DISPATCHER: Starting worker discovery
18:32:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:32:08 DISPATCHER: Finished worker discovery
18:33:08 DISPATCHER: Starting worker discovery
18:33:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:33:08 DISPATCHER: Finished worker discovery
18:33:49 WORKER: done with job (4, 0, 2), trying to register it.
18:33:49 WORKER: registered result for job (4, 0, 2) with dispatcher
18:33:49 DISPATCHER: job (4, 0, 2) finished
18:33:49 DISPATCHER: register_result: lock acquired
18:33:49 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:33:49 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.022226185903432567, 'num_filters_1': 40, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.02546878068691622}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.11414589136995647, 'info': {'data04': 0.11414589136995647, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.022226185903432567, 'num_filters_1': 40, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.02546878068691622}"}}
exception: None

18:33:49 job_callback for (4, 0, 2) started
18:33:49 DISPATCHER: Trying to submit another job.
18:33:49 job_callback for (4, 0, 2) got condition
18:33:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:33:49 HBMASTER: Trying to run another job!
18:33:49 job_callback for (4, 0, 2) finished
18:33:49 HBMASTER: schedule new run for iteration 4
18:33:49 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
18:33:49 HBMASTER: submitting job (4, 0, 6) to dispatcher
18:33:49 DISPATCHER: trying to submit job (4, 0, 6)
18:33:49 DISPATCHER: trying to notify the job_runner thread.
18:33:49 HBMASTER: job (4, 0, 6) submitted to dispatcher
18:33:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:33:49 DISPATCHER: Trying to submit another job.
18:33:49 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:33:49 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:33:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:33:49 WORKER: start processing job (4, 0, 6)
18:33:49 WORKER: args: ()
18:33:49 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0630190795537271, 'num_filters_1': 112, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.03215276769081809}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:34:08 DISPATCHER: Starting worker discovery
18:34:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:34:08 DISPATCHER: Finished worker discovery
18:35:08 DISPATCHER: Starting worker discovery
18:35:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:35:08 DISPATCHER: Finished worker discovery
18:36:08 DISPATCHER: Starting worker discovery
18:36:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:36:08 DISPATCHER: Finished worker discovery
18:37:03 WORKER: done with job (4, 0, 6), trying to register it.
18:37:03 WORKER: registered result for job (4, 0, 6) with dispatcher
18:37:03 DISPATCHER: job (4, 0, 6) finished
18:37:03 DISPATCHER: register_result: lock acquired
18:37:03 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:37:03 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0630190795537271, 'num_filters_1': 112, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.03215276769081809}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.09945183568454166, 'info': {'data04': 0.09945183568454166, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0630190795537271, 'num_filters_1': 112, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.03215276769081809}"}}
exception: None

18:37:03 job_callback for (4, 0, 6) started
18:37:03 job_callback for (4, 0, 6) got condition
18:37:03 DISPATCHER: Trying to submit another job.
18:37:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:37:03 HBMASTER: Trying to run another job!
18:37:03 job_callback for (4, 0, 6) finished
18:37:03 HBMASTER: schedule new run for iteration 4
18:37:03 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
18:37:03 HBMASTER: submitting job (4, 0, 7) to dispatcher
18:37:03 DISPATCHER: trying to submit job (4, 0, 7)
18:37:03 DISPATCHER: trying to notify the job_runner thread.
18:37:03 HBMASTER: job (4, 0, 7) submitted to dispatcher
18:37:03 DISPATCHER: Trying to submit another job.
18:37:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:37:03 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:37:03 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:37:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:37:03 WORKER: start processing job (4, 0, 7)
18:37:03 WORKER: args: ()
18:37:03 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0012306283829648303, 'num_filters_1': 48, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.026166648095047873, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 81, 'num_filters_3': 30, 'num_filters_4': 26, 'num_filters_5': 30}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:37:08 DISPATCHER: Starting worker discovery
18:37:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:37:08 DISPATCHER: Finished worker discovery
18:38:08 DISPATCHER: Starting worker discovery
18:38:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:38:08 DISPATCHER: Finished worker discovery
18:39:08 DISPATCHER: Starting worker discovery
18:39:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:39:08 DISPATCHER: Finished worker discovery
18:39:38 WORKER: done with job (4, 0, 7), trying to register it.
18:39:38 WORKER: registered result for job (4, 0, 7) with dispatcher
18:39:38 DISPATCHER: job (4, 0, 7) finished
18:39:38 DISPATCHER: register_result: lock acquired
18:39:38 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:39:38 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0012306283829648303, 'num_filters_1': 48, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.026166648095047873, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 81, 'num_filters_3': 30, 'num_filters_4': 26, 'num_filters_5': 30}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0845387843620538, 'info': {'data04': 0.0845387843620538, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0012306283829648303, 'num_filters_1': 48, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.026166648095047873, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 81, 'num_filters_3': 30, 'num_filters_4': 26, 'num_filters_5': 30}"}}
exception: None

18:39:38 job_callback for (4, 0, 7) started
18:39:38 job_callback for (4, 0, 7) got condition
18:39:38 DISPATCHER: Trying to submit another job.
18:39:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:39:38 HBMASTER: Trying to run another job!
18:39:38 job_callback for (4, 0, 7) finished
18:39:38 HBMASTER: schedule new run for iteration 4
18:39:38 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
18:39:38 HBMASTER: submitting job (4, 0, 15) to dispatcher
18:39:38 DISPATCHER: trying to submit job (4, 0, 15)
18:39:38 DISPATCHER: trying to notify the job_runner thread.
18:39:38 HBMASTER: job (4, 0, 15) submitted to dispatcher
18:39:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:39:38 DISPATCHER: Trying to submit another job.
18:39:38 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:39:38 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:39:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:39:38 WORKER: start processing job (4, 0, 15)
18:39:38 WORKER: args: ()
18:39:38 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.023821171064010487, 'num_filters_1': 88, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.015241365369449577, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 20, 'num_filters_3': 34, 'num_filters_4': 23}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:40:08 DISPATCHER: Starting worker discovery
18:40:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:40:08 DISPATCHER: Finished worker discovery
18:41:08 DISPATCHER: Starting worker discovery
18:41:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:41:08 DISPATCHER: Finished worker discovery
18:42:08 DISPATCHER: Starting worker discovery
18:42:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:42:08 DISPATCHER: Finished worker discovery
18:42:13 WORKER: done with job (4, 0, 15), trying to register it.
18:42:13 WORKER: registered result for job (4, 0, 15) with dispatcher
18:42:13 DISPATCHER: job (4, 0, 15) finished
18:42:13 DISPATCHER: register_result: lock acquired
18:42:13 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:42:13 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.023821171064010487, 'num_filters_1': 88, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.015241365369449577, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 20, 'num_filters_3': 34, 'num_filters_4': 23}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.09866062327037703, 'info': {'data04': 0.09866062327037703, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.023821171064010487, 'num_filters_1': 88, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.015241365369449577, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 20, 'num_filters_3': 34, 'num_filters_4': 23}"}}
exception: None

18:42:13 job_callback for (4, 0, 15) started
18:42:13 DISPATCHER: Trying to submit another job.
18:42:13 job_callback for (4, 0, 15) got condition
18:42:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:42:13 HBMASTER: Trying to run another job!
18:42:13 job_callback for (4, 0, 15) finished
18:42:13 HBMASTER: schedule new run for iteration 4
18:42:13 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
18:42:13 HBMASTER: submitting job (4, 0, 16) to dispatcher
18:42:13 DISPATCHER: trying to submit job (4, 0, 16)
18:42:13 DISPATCHER: trying to notify the job_runner thread.
18:42:13 HBMASTER: job (4, 0, 16) submitted to dispatcher
18:42:13 DISPATCHER: Trying to submit another job.
18:42:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:42:13 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:42:13 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:42:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:42:13 WORKER: start processing job (4, 0, 16)
18:42:13 WORKER: args: ()
18:42:13 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.010190019601777693, 'num_filters_1': 28, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.011061536143196065, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 20, 'num_filters_3': 23, 'num_filters_4': 29}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:43:08 DISPATCHER: Starting worker discovery
18:43:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:43:08 DISPATCHER: Finished worker discovery
18:44:08 DISPATCHER: Starting worker discovery
18:44:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:44:08 DISPATCHER: Finished worker discovery
18:44:49 WORKER: done with job (4, 0, 16), trying to register it.
18:44:49 WORKER: registered result for job (4, 0, 16) with dispatcher
18:44:49 DISPATCHER: job (4, 0, 16) finished
18:44:49 DISPATCHER: register_result: lock acquired
18:44:49 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:44:49 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.010190019601777693, 'num_filters_1': 28, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.011061536143196065, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 20, 'num_filters_3': 23, 'num_filters_4': 29}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1089787700991387, 'info': {'data04': 0.1089787700991387, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.010190019601777693, 'num_filters_1': 28, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.011061536143196065, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 20, 'num_filters_3': 23, 'num_filters_4': 29}"}}
exception: None

18:44:49 job_callback for (4, 0, 16) started
18:44:49 job_callback for (4, 0, 16) got condition
18:44:49 DISPATCHER: Trying to submit another job.
18:44:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:44:49 HBMASTER: Trying to run another job!
18:44:49 job_callback for (4, 0, 16) finished
18:44:49 HBMASTER: schedule new run for iteration 4
18:44:49 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
18:44:49 HBMASTER: submitting job (4, 0, 17) to dispatcher
18:44:49 DISPATCHER: trying to submit job (4, 0, 17)
18:44:49 DISPATCHER: trying to notify the job_runner thread.
18:44:49 HBMASTER: job (4, 0, 17) submitted to dispatcher
18:44:49 DISPATCHER: Trying to submit another job.
18:44:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:44:49 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:44:49 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:44:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:44:49 WORKER: start processing job (4, 0, 17)
18:44:49 WORKER: args: ()
18:44:49 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.04297400889742314, 'num_filters_1': 26, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.011882177041140142}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:45:08 DISPATCHER: Starting worker discovery
18:45:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:45:08 DISPATCHER: Finished worker discovery
18:46:08 DISPATCHER: Starting worker discovery
18:46:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:46:08 DISPATCHER: Finished worker discovery
18:47:08 DISPATCHER: Starting worker discovery
18:47:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:47:08 DISPATCHER: Finished worker discovery
18:47:52 WORKER: done with job (4, 0, 17), trying to register it.
18:47:52 WORKER: registered result for job (4, 0, 17) with dispatcher
18:47:52 DISPATCHER: job (4, 0, 17) finished
18:47:52 DISPATCHER: register_result: lock acquired
18:47:52 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:47:52 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.04297400889742314, 'num_filters_1': 26, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.011882177041140142}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.14240369402210354, 'info': {'data04': 0.14240369402210354, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.04297400889742314, 'num_filters_1': 26, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.011882177041140142}"}}
exception: None

18:47:52 job_callback for (4, 0, 17) started
18:47:52 DISPATCHER: Trying to submit another job.
18:47:52 job_callback for (4, 0, 17) got condition
18:47:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:47:52 HBMASTER: Trying to run another job!
18:47:52 job_callback for (4, 0, 17) finished
18:47:52 HBMASTER: schedule new run for iteration 4
18:47:52 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
18:47:52 HBMASTER: submitting job (4, 0, 18) to dispatcher
18:47:52 DISPATCHER: trying to submit job (4, 0, 18)
18:47:52 DISPATCHER: trying to notify the job_runner thread.
18:47:52 HBMASTER: job (4, 0, 18) submitted to dispatcher
18:47:52 DISPATCHER: Trying to submit another job.
18:47:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:47:52 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:47:52 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:47:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:47:52 WORKER: start processing job (4, 0, 18)
18:47:52 WORKER: args: ()
18:47:52 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0014473456797946247, 'num_filters_1': 47, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.016469477145633012, 'kernel_size_2': 7, 'num_filters_2': 115}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:48:08 DISPATCHER: Starting worker discovery
18:48:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:48:08 DISPATCHER: Finished worker discovery
18:49:08 DISPATCHER: Starting worker discovery
18:49:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:49:08 DISPATCHER: Finished worker discovery
18:50:08 DISPATCHER: Starting worker discovery
18:50:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:50:08 DISPATCHER: Finished worker discovery
18:50:48 WORKER: done with job (4, 0, 18), trying to register it.
18:50:48 WORKER: registered result for job (4, 0, 18) with dispatcher
18:50:48 DISPATCHER: job (4, 0, 18) finished
18:50:48 DISPATCHER: register_result: lock acquired
18:50:48 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:50:48 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0014473456797946247, 'num_filters_1': 47, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.016469477145633012, 'kernel_size_2': 7, 'num_filters_2': 115}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.17026410435666622, 'info': {'data04': 0.17026410435666622, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0014473456797946247, 'num_filters_1': 47, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.016469477145633012, 'kernel_size_2': 7, 'num_filters_2': 115}"}}
exception: None

18:50:48 job_callback for (4, 0, 18) started
18:50:48 DISPATCHER: Trying to submit another job.
18:50:48 job_callback for (4, 0, 18) got condition
18:50:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:50:48 HBMASTER: Trying to run another job!
18:50:48 job_callback for (4, 0, 18) finished
18:50:48 HBMASTER: schedule new run for iteration 4
18:50:48 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
18:50:48 HBMASTER: submitting job (4, 0, 19) to dispatcher
18:50:48 DISPATCHER: trying to submit job (4, 0, 19)
18:50:48 DISPATCHER: trying to notify the job_runner thread.
18:50:48 HBMASTER: job (4, 0, 19) submitted to dispatcher
18:50:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:50:48 DISPATCHER: Trying to submit another job.
18:50:48 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:50:48 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:50:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:50:48 WORKER: start processing job (4, 0, 19)
18:50:48 WORKER: args: ()
18:50:48 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0011826537308225217, 'num_filters_1': 55, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.01089559839580173, 'kernel_size_2': 5, 'num_filters_2': 85}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:51:08 DISPATCHER: Starting worker discovery
18:51:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:51:08 DISPATCHER: Finished worker discovery
18:52:08 DISPATCHER: Starting worker discovery
18:52:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:52:08 DISPATCHER: Finished worker discovery
18:53:08 DISPATCHER: Starting worker discovery
18:53:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:53:08 DISPATCHER: Finished worker discovery
18:53:57 WORKER: done with job (4, 0, 19), trying to register it.
18:53:57 WORKER: registered result for job (4, 0, 19) with dispatcher
18:53:57 DISPATCHER: job (4, 0, 19) finished
18:53:57 DISPATCHER: register_result: lock acquired
18:53:57 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:53:57 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0011826537308225217, 'num_filters_1': 55, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.01089559839580173, 'kernel_size_2': 5, 'num_filters_2': 85}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.17927797959366482, 'info': {'data04': 0.17927797959366482, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0011826537308225217, 'num_filters_1': 55, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.01089559839580173, 'kernel_size_2': 5, 'num_filters_2': 85}"}}
exception: None

18:53:57 job_callback for (4, 0, 19) started
18:53:57 job_callback for (4, 0, 19) got condition
18:53:57 DISPATCHER: Trying to submit another job.
18:53:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:53:57 HBMASTER: Trying to run another job!
18:53:57 job_callback for (4, 0, 19) finished
18:53:57 HBMASTER: schedule new run for iteration 4
18:53:57 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
18:53:57 HBMASTER: submitting job (4, 0, 26) to dispatcher
18:53:57 DISPATCHER: trying to submit job (4, 0, 26)
18:53:57 DISPATCHER: trying to notify the job_runner thread.
18:53:57 HBMASTER: job (4, 0, 26) submitted to dispatcher
18:53:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:53:57 DISPATCHER: Trying to submit another job.
18:53:57 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:53:57 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:53:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:53:57 WORKER: start processing job (4, 0, 26)
18:53:57 WORKER: args: ()
18:53:57 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001537478200589716, 'num_filters_1': 75, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.011929936859812978}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:54:08 DISPATCHER: Starting worker discovery
18:54:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:54:08 DISPATCHER: Finished worker discovery
18:55:08 DISPATCHER: Starting worker discovery
18:55:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:55:08 DISPATCHER: Finished worker discovery
18:56:08 DISPATCHER: Starting worker discovery
18:56:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:56:08 DISPATCHER: Finished worker discovery
18:57:08 DISPATCHER: Starting worker discovery
18:57:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:57:08 DISPATCHER: Finished worker discovery
18:57:39 WORKER: done with job (4, 0, 26), trying to register it.
18:57:39 WORKER: registered result for job (4, 0, 26) with dispatcher
18:57:39 DISPATCHER: job (4, 0, 26) finished
18:57:39 DISPATCHER: register_result: lock acquired
18:57:39 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:57:39 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001537478200589716, 'num_filters_1': 75, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.011929936859812978}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1928556671385178, 'info': {'data04': 0.1928556671385178, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001537478200589716, 'num_filters_1': 75, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.011929936859812978}"}}
exception: None

18:57:39 job_callback for (4, 0, 26) started
18:57:39 DISPATCHER: Trying to submit another job.
18:57:39 job_callback for (4, 0, 26) got condition
18:57:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:57:39 HBMASTER: Trying to run another job!
18:57:39 job_callback for (4, 0, 26) finished
18:57:39 ITERATION: Advancing config (4, 0, 18) to next budget 400.000000
18:57:39 ITERATION: Advancing config (4, 0, 19) to next budget 400.000000
18:57:39 ITERATION: Advancing config (4, 0, 26) to next budget 400.000000
18:57:39 HBMASTER: schedule new run for iteration 4
18:57:39 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
18:57:39 HBMASTER: submitting job (4, 0, 18) to dispatcher
18:57:39 DISPATCHER: trying to submit job (4, 0, 18)
18:57:39 DISPATCHER: trying to notify the job_runner thread.
18:57:39 HBMASTER: job (4, 0, 18) submitted to dispatcher
18:57:39 DISPATCHER: Trying to submit another job.
18:57:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:57:39 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:57:39 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:57:39 WORKER: start processing job (4, 0, 18)
18:57:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:57:39 WORKER: args: ()
18:57:39 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0014473456797946247, 'num_filters_1': 47, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.016469477145633012, 'kernel_size_2': 7, 'num_filters_2': 115}, 'budget': 400.0, 'working_directory': '.'}
18:58:08 DISPATCHER: Starting worker discovery
18:58:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:58:08 DISPATCHER: Finished worker discovery
18:59:08 DISPATCHER: Starting worker discovery
18:59:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:59:08 DISPATCHER: Finished worker discovery
19:00:08 DISPATCHER: Starting worker discovery
19:00:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:00:08 DISPATCHER: Finished worker discovery
19:01:08 DISPATCHER: Starting worker discovery
19:01:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:01:08 DISPATCHER: Finished worker discovery
19:02:08 DISPATCHER: Starting worker discovery
19:02:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:02:08 DISPATCHER: Finished worker discovery
19:03:08 DISPATCHER: Starting worker discovery
19:03:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:03:08 DISPATCHER: Finished worker discovery
19:04:08 DISPATCHER: Starting worker discovery
19:04:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:04:08 DISPATCHER: Finished worker discovery
19:05:08 DISPATCHER: Starting worker discovery
19:05:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:05:09 DISPATCHER: Finished worker discovery
19:06:06 WORKER: done with job (4, 0, 18), trying to register it.
19:06:06 WORKER: registered result for job (4, 0, 18) with dispatcher
19:06:06 DISPATCHER: job (4, 0, 18) finished
19:06:06 DISPATCHER: register_result: lock acquired
19:06:06 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
19:06:06 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0014473456797946247, 'num_filters_1': 47, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.016469477145633012, 'kernel_size_2': 7, 'num_filters_2': 115}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.1774749988330093, 'info': {'data04': 0.1774749988330093, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0014473456797946247, 'num_filters_1': 47, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.016469477145633012, 'kernel_size_2': 7, 'num_filters_2': 115}"}}
exception: None

19:06:06 job_callback for (4, 0, 18) started
19:06:06 DISPATCHER: Trying to submit another job.
19:06:06 job_callback for (4, 0, 18) got condition
19:06:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:06:06 Only 13 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
19:06:06 HBMASTER: Trying to run another job!
19:06:06 job_callback for (4, 0, 18) finished
19:06:06 HBMASTER: schedule new run for iteration 4
19:06:06 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
19:06:06 HBMASTER: submitting job (4, 0, 19) to dispatcher
19:06:06 DISPATCHER: trying to submit job (4, 0, 19)
19:06:06 DISPATCHER: trying to notify the job_runner thread.
19:06:06 HBMASTER: job (4, 0, 19) submitted to dispatcher
19:06:06 DISPATCHER: Trying to submit another job.
19:06:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:06:06 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880
19:06:06 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
19:06:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:06:06 WORKER: start processing job (4, 0, 19)
19:06:06 WORKER: args: ()
19:06:06 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0011826537308225217, 'num_filters_1': 55, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.01089559839580173, 'kernel_size_2': 5, 'num_filters_2': 85}, 'budget': 400.0, 'working_directory': '.'}
19:06:09 DISPATCHER: Starting worker discovery
19:06:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:06:09 DISPATCHER: Finished worker discovery
19:07:09 DISPATCHER: Starting worker discovery
19:07:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:07:09 DISPATCHER: Finished worker discovery
19:08:09 DISPATCHER: Starting worker discovery
19:08:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:08:09 DISPATCHER: Finished worker discovery
19:09:09 DISPATCHER: Starting worker discovery
19:09:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:09:09 DISPATCHER: Finished worker discovery
19:10:09 DISPATCHER: Starting worker discovery
19:10:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:10:09 DISPATCHER: Finished worker discovery
19:11:09 DISPATCHER: Starting worker discovery
19:11:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:11:09 DISPATCHER: Finished worker discovery
19:12:09 DISPATCHER: Starting worker discovery
19:12:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:12:09 DISPATCHER: Finished worker discovery
19:13:09 DISPATCHER: Starting worker discovery
19:13:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:13:09 DISPATCHER: Finished worker discovery
19:14:09 DISPATCHER: Starting worker discovery
19:14:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:14:09 DISPATCHER: Finished worker discovery
19:14:57 WORKER: done with job (4, 0, 19), trying to register it.
19:14:57 WORKER: registered result for job (4, 0, 19) with dispatcher
19:14:57 DISPATCHER: job (4, 0, 19) finished
19:14:57 DISPATCHER: register_result: lock acquired
19:14:57 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
19:14:57 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0011826537308225217, 'num_filters_1': 55, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.01089559839580173, 'kernel_size_2': 5, 'num_filters_2': 85}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.1950975875716413, 'info': {'data04': 0.1950975875716413, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0011826537308225217, 'num_filters_1': 55, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.01089559839580173, 'kernel_size_2': 5, 'num_filters_2': 85}"}}
exception: None

19:14:57 job_callback for (4, 0, 19) started
19:14:57 DISPATCHER: Trying to submit another job.
19:14:57 job_callback for (4, 0, 19) got condition
19:14:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:14:57 Only 14 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
19:14:57 HBMASTER: Trying to run another job!
19:14:57 job_callback for (4, 0, 19) finished
19:14:57 HBMASTER: schedule new run for iteration 4
19:14:57 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
19:14:57 HBMASTER: submitting job (4, 0, 26) to dispatcher
19:14:57 DISPATCHER: trying to submit job (4, 0, 26)
19:14:57 DISPATCHER: trying to notify the job_runner thread.
19:14:57 HBMASTER: job (4, 0, 26) submitted to dispatcher
19:14:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:14:57 DISPATCHER: Trying to submit another job.
19:14:57 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880
19:14:57 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
19:14:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:14:57 WORKER: start processing job (4, 0, 26)
19:14:57 WORKER: args: ()
19:14:57 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001537478200589716, 'num_filters_1': 75, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.011929936859812978}, 'budget': 400.0, 'working_directory': '.'}
19:15:09 DISPATCHER: Starting worker discovery
19:15:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:15:09 DISPATCHER: Finished worker discovery
19:16:09 DISPATCHER: Starting worker discovery
19:16:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:16:09 DISPATCHER: Finished worker discovery
19:17:09 DISPATCHER: Starting worker discovery
19:17:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:17:09 DISPATCHER: Finished worker discovery
19:18:09 DISPATCHER: Starting worker discovery
19:18:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:18:09 DISPATCHER: Finished worker discovery
19:19:09 DISPATCHER: Starting worker discovery
19:19:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:19:09 DISPATCHER: Finished worker discovery
19:20:09 DISPATCHER: Starting worker discovery
19:20:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:20:09 DISPATCHER: Finished worker discovery
19:21:09 DISPATCHER: Starting worker discovery
19:21:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:21:09 DISPATCHER: Finished worker discovery
19:22:09 DISPATCHER: Starting worker discovery
19:22:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:22:09 DISPATCHER: Finished worker discovery
19:23:09 DISPATCHER: Starting worker discovery
19:23:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:23:09 DISPATCHER: Finished worker discovery
19:24:09 DISPATCHER: Starting worker discovery
19:24:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:24:10 DISPATCHER: Finished worker discovery
19:25:10 DISPATCHER: Starting worker discovery
19:25:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:25:10 DISPATCHER: Finished worker discovery
19:25:16 WORKER: done with job (4, 0, 26), trying to register it.
19:25:16 WORKER: registered result for job (4, 0, 26) with dispatcher
19:25:16 DISPATCHER: job (4, 0, 26) finished
19:25:16 DISPATCHER: register_result: lock acquired
19:25:16 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
19:25:16 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001537478200589716, 'num_filters_1': 75, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.011929936859812978}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.17130946853162637, 'info': {'data04': 0.17130946853162637, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001537478200589716, 'num_filters_1': 75, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.011929936859812978}"}}
exception: None

19:25:16 job_callback for (4, 0, 26) started
19:25:16 job_callback for (4, 0, 26) got condition
19:25:16 DISPATCHER: Trying to submit another job.
19:25:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:25:16 Only 15 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
19:25:16 HBMASTER: Trying to run another job!
19:25:16 job_callback for (4, 0, 26) finished
19:25:16 ITERATION: Advancing config (4, 0, 19) to next budget 1200.000000
19:25:16 HBMASTER: schedule new run for iteration 4
19:25:16 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
19:25:16 HBMASTER: submitting job (4, 0, 19) to dispatcher
19:25:16 DISPATCHER: trying to submit job (4, 0, 19)
19:25:16 DISPATCHER: trying to notify the job_runner thread.
19:25:16 HBMASTER: job (4, 0, 19) submitted to dispatcher
19:25:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:25:16 DISPATCHER: Trying to submit another job.
19:25:16 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880
19:25:16 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
19:25:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:25:16 WORKER: start processing job (4, 0, 19)
19:25:16 WORKER: args: ()
19:25:16 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0011826537308225217, 'num_filters_1': 55, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.01089559839580173, 'kernel_size_2': 5, 'num_filters_2': 85}, 'budget': 1200.0, 'working_directory': '.'}
19:26:10 DISPATCHER: Starting worker discovery
19:26:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:26:10 DISPATCHER: Finished worker discovery
19:27:10 DISPATCHER: Starting worker discovery
19:27:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:27:10 DISPATCHER: Finished worker discovery
19:28:10 DISPATCHER: Starting worker discovery
19:28:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:28:10 DISPATCHER: Finished worker discovery
19:29:10 DISPATCHER: Starting worker discovery
19:29:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:29:10 DISPATCHER: Finished worker discovery
19:30:10 DISPATCHER: Starting worker discovery
19:30:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:30:10 DISPATCHER: Finished worker discovery
19:31:10 DISPATCHER: Starting worker discovery
19:31:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:31:10 DISPATCHER: Finished worker discovery
19:32:10 DISPATCHER: Starting worker discovery
19:32:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:32:10 DISPATCHER: Finished worker discovery
19:33:10 DISPATCHER: Starting worker discovery
19:33:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:33:10 DISPATCHER: Finished worker discovery
19:34:10 DISPATCHER: Starting worker discovery
19:34:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:34:10 DISPATCHER: Finished worker discovery
19:35:10 DISPATCHER: Starting worker discovery
19:35:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:35:10 DISPATCHER: Finished worker discovery
19:36:10 DISPATCHER: Starting worker discovery
19:36:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:36:10 DISPATCHER: Finished worker discovery
19:37:10 DISPATCHER: Starting worker discovery
19:37:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:37:10 DISPATCHER: Finished worker discovery
19:38:10 DISPATCHER: Starting worker discovery
19:38:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:38:10 DISPATCHER: Finished worker discovery
19:39:10 DISPATCHER: Starting worker discovery
19:39:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:39:10 DISPATCHER: Finished worker discovery
19:40:10 DISPATCHER: Starting worker discovery
19:40:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:40:10 DISPATCHER: Finished worker discovery
19:41:10 DISPATCHER: Starting worker discovery
19:41:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:41:10 DISPATCHER: Finished worker discovery
19:42:10 DISPATCHER: Starting worker discovery
19:42:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:42:10 DISPATCHER: Finished worker discovery
19:43:10 DISPATCHER: Starting worker discovery
19:43:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:43:10 DISPATCHER: Finished worker discovery
19:44:10 DISPATCHER: Starting worker discovery
19:44:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:44:10 DISPATCHER: Finished worker discovery
19:45:10 DISPATCHER: Starting worker discovery
19:45:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:45:10 DISPATCHER: Finished worker discovery
19:46:10 DISPATCHER: Starting worker discovery
19:46:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:46:10 DISPATCHER: Finished worker discovery
19:47:10 DISPATCHER: Starting worker discovery
19:47:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:47:10 DISPATCHER: Finished worker discovery
19:48:10 DISPATCHER: Starting worker discovery
19:48:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:48:10 DISPATCHER: Finished worker discovery
19:49:10 DISPATCHER: Starting worker discovery
19:49:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:49:11 DISPATCHER: Finished worker discovery
19:50:11 DISPATCHER: Starting worker discovery
19:50:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:50:11 DISPATCHER: Finished worker discovery
19:51:11 DISPATCHER: Starting worker discovery
19:51:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:51:11 DISPATCHER: Finished worker discovery
19:51:23 WORKER: done with job (4, 0, 19), trying to register it.
19:51:23 WORKER: registered result for job (4, 0, 19) with dispatcher
19:51:23 DISPATCHER: job (4, 0, 19) finished
19:51:23 DISPATCHER: register_result: lock acquired
19:51:23 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
19:51:23 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0011826537308225217, 'num_filters_1': 55, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.01089559839580173, 'kernel_size_2': 5, 'num_filters_2': 85}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.18031094097003486, 'info': {'data04': 0.18031094097003486, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0011826537308225217, 'num_filters_1': 55, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.01089559839580173, 'kernel_size_2': 5, 'num_filters_2': 85}"}}
exception: None

19:51:23 job_callback for (4, 0, 19) started
19:51:23 DISPATCHER: Trying to submit another job.
19:51:23 job_callback for (4, 0, 19) got condition
19:51:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:51:23 Only 9 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
19:51:23 HBMASTER: Trying to run another job!
19:51:23 job_callback for (4, 0, 19) finished
19:51:23 start sampling a new configuration.
19:51:23 best_vector: [3, 2, 0.14365381331755833, 0.8203261587743951, 0.4191130174502341, 1, 0.2943810754235267, 0.08962833492550161, 0, 1, 0, 1, 0.8326521680470259, 0.9200737415519697, 0.818022795756916, 0.3109864808037542], 1.913073100715668e-05, 0.27305497877017215, 5.223741349017042e-06
19:51:23 done sampling a new configuration.
19:51:23 HBMASTER: schedule new run for iteration 5
19:51:23 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
19:51:23 HBMASTER: submitting job (5, 0, 0) to dispatcher
19:51:23 DISPATCHER: trying to submit job (5, 0, 0)
19:51:23 DISPATCHER: trying to notify the job_runner thread.
19:51:23 HBMASTER: job (5, 0, 0) submitted to dispatcher
19:51:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:51:23 DISPATCHER: Trying to submit another job.
19:51:23 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
19:51:23 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
19:51:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:51:23 WORKER: start processing job (5, 0, 0)
19:51:23 WORKER: args: ()
19:51:23 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0019377940882167434, 'num_filters_1': 88, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.013080042412311789, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 90, 'num_filters_3': 109}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:52:11 DISPATCHER: Starting worker discovery
19:52:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:52:11 DISPATCHER: Finished worker discovery
19:53:11 DISPATCHER: Starting worker discovery
19:53:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:53:11 DISPATCHER: Finished worker discovery
19:54:06 WORKER: done with job (5, 0, 0), trying to register it.
19:54:06 WORKER: registered result for job (5, 0, 0) with dispatcher
19:54:06 DISPATCHER: job (5, 0, 0) finished
19:54:06 DISPATCHER: register_result: lock acquired
19:54:06 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
19:54:06 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0019377940882167434, 'num_filters_1': 88, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.013080042412311789, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 90, 'num_filters_3': 109}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.21692582511535655, 'info': {'data04': 0.21692582511535655, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0019377940882167434, 'num_filters_1': 88, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.013080042412311789, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 90, 'num_filters_3': 109}"}}
exception: None

19:54:06 job_callback for (5, 0, 0) started
19:54:06 DISPATCHER: Trying to submit another job.
19:54:06 job_callback for (5, 0, 0) got condition
19:54:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:54:06 HBMASTER: Trying to run another job!
19:54:06 job_callback for (5, 0, 0) finished
19:54:06 start sampling a new configuration.
19:54:06 best_vector: [3, 1, 0.17092921731718858, 0.3967541099607136, 0.06921383688667332, 1, 0.11830452476282734, 0.11961990365750763, 1, 1, 0, 1, 0.5859239996469998, 0.25706760983031485, 0.14097557320244553, 0.31193138617381533], 1.216434259086282e-06, 4.320423143581915, 5.255510725602292e-06
19:54:06 done sampling a new configuration.
19:54:06 HBMASTER: schedule new run for iteration 5
19:54:06 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
19:54:06 HBMASTER: submitting job (5, 0, 1) to dispatcher
19:54:06 DISPATCHER: trying to submit job (5, 0, 1)
19:54:06 DISPATCHER: trying to notify the job_runner thread.
19:54:06 HBMASTER: job (5, 0, 1) submitted to dispatcher
19:54:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:54:06 DISPATCHER: Trying to submit another job.
19:54:06 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
19:54:06 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
19:54:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:54:06 WORKER: start processing job (5, 0, 1)
19:54:06 WORKER: args: ()
19:54:06 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0021971435612859764, 'num_filters_1': 36, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.014309652348094956}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:54:11 DISPATCHER: Starting worker discovery
19:54:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:54:11 DISPATCHER: Finished worker discovery
19:55:11 DISPATCHER: Starting worker discovery
19:55:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:55:11 DISPATCHER: Finished worker discovery
19:56:11 DISPATCHER: Starting worker discovery
19:56:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:56:11 DISPATCHER: Finished worker discovery
19:57:11 DISPATCHER: Starting worker discovery
19:57:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:57:11 DISPATCHER: Finished worker discovery
19:57:16 WORKER: done with job (5, 0, 1), trying to register it.
19:57:16 WORKER: registered result for job (5, 0, 1) with dispatcher
19:57:16 DISPATCHER: job (5, 0, 1) finished
19:57:16 DISPATCHER: register_result: lock acquired
19:57:16 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
19:57:16 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0021971435612859764, 'num_filters_1': 36, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.014309652348094956}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.17230027394333644, 'info': {'data04': 0.17230027394333644, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0021971435612859764, 'num_filters_1': 36, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.014309652348094956}"}}
exception: None

19:57:16 job_callback for (5, 0, 1) started
19:57:16 job_callback for (5, 0, 1) got condition
19:57:16 DISPATCHER: Trying to submit another job.
19:57:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:57:16 HBMASTER: Trying to run another job!
19:57:16 job_callback for (5, 0, 1) finished
19:57:16 start sampling a new configuration.
19:57:16 best_vector: [1, 1, 0.3655294121295741, 0.38385821268143583, 0.328574891571056, 1, 0.9200347491957783, 0.5053742333039702, 1, 1, 0, 1, 0.9282498062064811, 0.8667106436104722, 0.960323418435361, 0.3111656935438859], 1.3033810717285732e-05, 0.20118768443174886, 2.622242197532428e-06
19:57:16 done sampling a new configuration.
19:57:16 HBMASTER: schedule new run for iteration 5
19:57:16 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
19:57:16 HBMASTER: submitting job (5, 0, 2) to dispatcher
19:57:16 DISPATCHER: trying to submit job (5, 0, 2)
19:57:16 DISPATCHER: trying to notify the job_runner thread.
19:57:16 HBMASTER: job (5, 0, 2) submitted to dispatcher
19:57:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:57:16 DISPATCHER: Trying to submit another job.
19:57:16 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
19:57:16 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
19:57:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:57:16 WORKER: start processing job (5, 0, 2)
19:57:16 WORKER: args: ()
19:57:16 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.005383426949454334, 'num_filters_1': 35, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.04544719006343525, 'kernel_size_2': 5, 'num_filters_2': 110}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:58:11 DISPATCHER: Starting worker discovery
19:58:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:58:11 DISPATCHER: Finished worker discovery
19:59:11 DISPATCHER: Starting worker discovery
19:59:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:59:11 DISPATCHER: Finished worker discovery
19:59:51 WORKER: done with job (5, 0, 2), trying to register it.
19:59:51 WORKER: registered result for job (5, 0, 2) with dispatcher
19:59:51 DISPATCHER: job (5, 0, 2) finished
19:59:51 DISPATCHER: register_result: lock acquired
19:59:51 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
19:59:51 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.005383426949454334, 'num_filters_1': 35, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.04544719006343525, 'kernel_size_2': 5, 'num_filters_2': 110}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.026594426583391076, 'info': {'data04': 0.026594426583391076, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.005383426949454334, 'num_filters_1': 35, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.04544719006343525, 'kernel_size_2': 5, 'num_filters_2': 110}"}}
exception: None

19:59:51 job_callback for (5, 0, 2) started
19:59:51 job_callback for (5, 0, 2) got condition
19:59:51 DISPATCHER: Trying to submit another job.
19:59:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:59:51 HBMASTER: Trying to run another job!
19:59:51 job_callback for (5, 0, 2) finished
19:59:51 start sampling a new configuration.
19:59:51 best_vector: [3, 0, 0.21577409464426156, 0.5846157179257101, 0.12455654971880549, 1, 0.3224760227362986, 0.052734420646241204, 1, 1, 1, 1, 0.5853492596023346, 0.14519646961172264, 0.3421699132909417, 0.3138950738734212], 4.513693141988785e-06, 1.0891979210572356, 4.916305186544486e-06
19:59:51 done sampling a new configuration.
19:59:51 HBMASTER: schedule new run for iteration 5
19:59:51 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
19:59:51 HBMASTER: submitting job (5, 0, 3) to dispatcher
19:59:51 DISPATCHER: trying to submit job (5, 0, 3)
19:59:51 DISPATCHER: trying to notify the job_runner thread.
19:59:51 HBMASTER: job (5, 0, 3) submitted to dispatcher
19:59:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:59:51 DISPATCHER: Trying to submit another job.
19:59:51 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
19:59:51 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
19:59:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:59:51 WORKER: start processing job (5, 0, 3)
19:59:51 WORKER: args: ()
19:59:51 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0027011468107778916, 'num_filters_1': 53, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.011711406704224239}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:00:11 DISPATCHER: Starting worker discovery
20:00:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:00:11 DISPATCHER: Finished worker discovery
20:01:11 DISPATCHER: Starting worker discovery
20:01:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:01:11 DISPATCHER: Finished worker discovery
20:02:11 DISPATCHER: Starting worker discovery
20:02:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:02:11 DISPATCHER: Finished worker discovery
20:02:39 WORKER: done with job (5, 0, 3), trying to register it.
20:02:39 WORKER: registered result for job (5, 0, 3) with dispatcher
20:02:39 DISPATCHER: job (5, 0, 3) finished
20:02:39 DISPATCHER: register_result: lock acquired
20:02:39 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
20:02:39 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0027011468107778916, 'num_filters_1': 53, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.011711406704224239}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1764021999842827, 'info': {'data04': 0.1764021999842827, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0027011468107778916, 'num_filters_1': 53, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.011711406704224239}"}}
exception: None

20:02:39 job_callback for (5, 0, 3) started
20:02:39 DISPATCHER: Trying to submit another job.
20:02:39 job_callback for (5, 0, 3) got condition
20:02:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:02:39 HBMASTER: Trying to run another job!
20:02:39 job_callback for (5, 0, 3) finished
20:02:39 start sampling a new configuration.
20:02:40 best_vector: [2, 0, 0.2874794797095442, 0.9688897673204842, 0.15180166805844791, 1, 0.5500789830154337, 0.20351802575064437, 1, 1, 1, 1, 0.3271104606700691, 0.15891376961347772, 0.3871282252335373, 0.3113557015369042], 7.478964741355977e-06, 0.7622850194008999, 5.701102782963187e-06
20:02:40 done sampling a new configuration.
20:02:40 HBMASTER: schedule new run for iteration 5
20:02:40 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
20:02:40 HBMASTER: submitting job (5, 0, 4) to dispatcher
20:02:40 DISPATCHER: trying to submit job (5, 0, 4)
20:02:40 DISPATCHER: trying to notify the job_runner thread.
20:02:40 HBMASTER: job (5, 0, 4) submitted to dispatcher
20:02:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:02:40 DISPATCHER: Trying to submit another job.
20:02:40 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
20:02:40 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
20:02:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:02:40 WORKER: start processing job (5, 0, 4)
20:02:40 WORKER: args: ()
20:02:40 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003758018895461238, 'num_filters_1': 120, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.01839852707217098}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:03:11 DISPATCHER: Starting worker discovery
20:03:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:03:11 DISPATCHER: Finished worker discovery
20:04:11 DISPATCHER: Starting worker discovery
20:04:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:04:11 DISPATCHER: Finished worker discovery
20:05:11 DISPATCHER: Starting worker discovery
20:05:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:05:12 DISPATCHER: Finished worker discovery
20:05:22 WORKER: done with job (5, 0, 4), trying to register it.
20:05:22 WORKER: registered result for job (5, 0, 4) with dispatcher
20:05:22 DISPATCHER: job (5, 0, 4) finished
20:05:22 DISPATCHER: register_result: lock acquired
20:05:22 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
20:05:22 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003758018895461238, 'num_filters_1': 120, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.01839852707217098}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.15453835640430802, 'info': {'data04': 0.15453835640430802, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003758018895461238, 'num_filters_1': 120, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.01839852707217098}"}}
exception: None

20:05:22 job_callback for (5, 0, 4) started
20:05:22 DISPATCHER: Trying to submit another job.
20:05:22 job_callback for (5, 0, 4) got condition
20:05:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:05:22 HBMASTER: Trying to run another job!
20:05:22 job_callback for (5, 0, 4) finished
20:05:22 start sampling a new configuration.
20:05:22 best_vector: [2, 0, 0.1972430404134915, 0.5344745737159815, 0.05782831695845425, 1, 0.8568685319576068, 0.06780245495152057, 0, 2, 2, 1, 0.27351009496338163, 0.06341729662722141, 0.8070212665151816, 0.3120802151654697], 7.000398416609992e-06, 0.01673972253756149, 1.1718472714643605e-07
20:05:22 done sampling a new configuration.
20:05:22 HBMASTER: schedule new run for iteration 5
20:05:22 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
20:05:22 HBMASTER: submitting job (5, 0, 5) to dispatcher
20:05:22 DISPATCHER: trying to submit job (5, 0, 5)
20:05:22 DISPATCHER: trying to notify the job_runner thread.
20:05:22 HBMASTER: job (5, 0, 5) submitted to dispatcher
20:05:22 DISPATCHER: Trying to submit another job.
20:05:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:05:22 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
20:05:22 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
20:05:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:05:22 WORKER: start processing job (5, 0, 5)
20:05:22 WORKER: args: ()
20:05:22 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.002480196445923867, 'num_filters_1': 48, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.01225217038421055}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:06:12 DISPATCHER: Starting worker discovery
20:06:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:06:12 DISPATCHER: Finished worker discovery
20:07:12 DISPATCHER: Starting worker discovery
20:07:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:07:12 DISPATCHER: Finished worker discovery
20:08:01 WORKER: done with job (5, 0, 5), trying to register it.
20:08:01 WORKER: registered result for job (5, 0, 5) with dispatcher
20:08:01 DISPATCHER: job (5, 0, 5) finished
20:08:01 DISPATCHER: register_result: lock acquired
20:08:01 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
20:08:01 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.002480196445923867, 'num_filters_1': 48, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.01225217038421055}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1739422238456989, 'info': {'data04': 0.1739422238456989, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.002480196445923867, 'num_filters_1': 48, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.01225217038421055}"}}
exception: None

20:08:01 job_callback for (5, 0, 5) started
20:08:01 DISPATCHER: Trying to submit another job.
20:08:01 job_callback for (5, 0, 5) got condition
20:08:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:08:01 HBMASTER: Trying to run another job!
20:08:01 job_callback for (5, 0, 5) finished
20:08:01 start sampling a new configuration.
20:08:01 best_vector: [2, 1, 0.01751006670966103, 0.838502621483628, 0.6011193938667287, 1, 0.7184012960402554, 0.22372881455858573, 2, 1, 1, 1, 0.5624109623340635, 0.42292477214329793, 0.2641760920989982, 0.3126014031717399], 3.6781543360455138e-06, 1.4500777788349113, 5.3336098698248764e-06
20:08:01 done sampling a new configuration.
20:08:01 HBMASTER: schedule new run for iteration 5
20:08:01 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
20:08:01 HBMASTER: submitting job (5, 0, 6) to dispatcher
20:08:01 DISPATCHER: trying to submit job (5, 0, 6)
20:08:01 DISPATCHER: trying to notify the job_runner thread.
20:08:01 HBMASTER: job (5, 0, 6) submitted to dispatcher
20:08:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:08:01 DISPATCHER: Trying to submit another job.
20:08:01 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880
20:08:01 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
20:08:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:08:01 WORKER: start processing job (5, 0, 6)
20:08:01 WORKER: args: ()
20:08:01 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0010839771648575383, 'num_filters_1': 91, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.019546900336361833, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 51, 'num_filters_3': 38, 'num_filters_4': 27}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:08:12 DISPATCHER: Starting worker discovery
20:08:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:08:12 DISPATCHER: Finished worker discovery
20:09:12 DISPATCHER: Starting worker discovery
20:09:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:09:12 DISPATCHER: Finished worker discovery
20:10:12 DISPATCHER: Starting worker discovery
20:10:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:10:12 DISPATCHER: Finished worker discovery
20:10:37 WORKER: done with job (5, 0, 6), trying to register it.
20:10:37 WORKER: registered result for job (5, 0, 6) with dispatcher
20:10:37 DISPATCHER: job (5, 0, 6) finished
20:10:37 DISPATCHER: register_result: lock acquired
20:10:37 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
20:10:37 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0010839771648575383, 'num_filters_1': 91, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.019546900336361833, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 51, 'num_filters_3': 38, 'num_filters_4': 27}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.14339397393899758, 'info': {'data04': 0.14339397393899758, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0010839771648575383, 'num_filters_1': 91, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.019546900336361833, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 51, 'num_filters_3': 38, 'num_filters_4': 27}"}}
exception: None

20:10:37 job_callback for (5, 0, 6) started
20:10:37 job_callback for (5, 0, 6) got condition
20:10:37 DISPATCHER: Trying to submit another job.
20:10:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:10:37 done building a new model for budget 133.333333 based on 17/28 split
Best loss for this budget:-0.216926





20:10:37 HBMASTER: Trying to run another job!
20:10:37 job_callback for (5, 0, 6) finished
20:10:37 start sampling a new configuration.
20:10:37 done sampling a new configuration.
20:10:37 HBMASTER: schedule new run for iteration 5
20:10:37 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
20:10:37 HBMASTER: submitting job (5, 0, 7) to dispatcher
20:10:37 DISPATCHER: trying to submit job (5, 0, 7)
20:10:37 DISPATCHER: trying to notify the job_runner thread.
20:10:37 HBMASTER: job (5, 0, 7) submitted to dispatcher
20:10:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:10:37 DISPATCHER: Trying to submit another job.
20:10:37 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880
20:10:37 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
20:10:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:10:37 WORKER: start processing job (5, 0, 7)
20:10:37 WORKER: args: ()
20:10:37 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003119582515242903, 'num_filters_1': 21, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.09798457656050752, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 63, 'num_filters_3': 101}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:11:12 DISPATCHER: Starting worker discovery
20:11:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:11:12 DISPATCHER: Finished worker discovery
20:12:12 DISPATCHER: Starting worker discovery
20:12:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:12:12 DISPATCHER: Finished worker discovery
20:13:12 DISPATCHER: Starting worker discovery
20:13:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:13:12 DISPATCHER: Finished worker discovery
20:13:13 WORKER: done with job (5, 0, 7), trying to register it.
20:13:13 WORKER: registered result for job (5, 0, 7) with dispatcher
20:13:13 DISPATCHER: job (5, 0, 7) finished
20:13:13 DISPATCHER: register_result: lock acquired
20:13:13 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
20:13:13 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003119582515242903, 'num_filters_1': 21, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.09798457656050752, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 63, 'num_filters_3': 101}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.022048893154867282, 'info': {'data04': 0.022048893154867282, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003119582515242903, 'num_filters_1': 21, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.09798457656050752, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 63, 'num_filters_3': 101}"}}
exception: None

20:13:13 job_callback for (5, 0, 7) started
20:13:13 job_callback for (5, 0, 7) got condition
20:13:13 DISPATCHER: Trying to submit another job.
20:13:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:13:13 done building a new model for budget 133.333333 based on 17/29 split
Best loss for this budget:-0.216926





20:13:13 HBMASTER: Trying to run another job!
20:13:13 job_callback for (5, 0, 7) finished
20:13:13 start sampling a new configuration.
20:13:13 best_vector: [3, 1, 0.014519626444608219, 0.7258949260347777, 0.09614542535167607, 1, 0.30657951612156653, 0.04159402180155716, 1, 1, 2, 0, 0.7816281261732593, 0.8174177997519363, 0.0557559889333854, 0.574833353580306], 0.0003674897980314267, 0.0046175846816295845, 1.6969152620450659e-06
20:13:13 done sampling a new configuration.
20:13:13 HBMASTER: schedule new run for iteration 5
20:13:13 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
20:13:13 HBMASTER: submitting job (5, 0, 8) to dispatcher
20:13:13 DISPATCHER: trying to submit job (5, 0, 8)
20:13:13 DISPATCHER: trying to notify the job_runner thread.
20:13:13 HBMASTER: job (5, 0, 8) submitted to dispatcher
20:13:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:13:13 DISPATCHER: Trying to submit another job.
20:13:13 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880
20:13:13 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
20:13:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:13:13 WORKER: start processing job (5, 0, 8)
20:13:13 WORKER: args: ()
20:13:13 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0010691515081022365, 'num_filters_1': 72, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.011327004420626561}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:14:12 DISPATCHER: Starting worker discovery
20:14:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:14:12 DISPATCHER: Finished worker discovery
20:15:12 DISPATCHER: Starting worker discovery
20:15:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:15:12 DISPATCHER: Finished worker discovery
20:16:02 WORKER: done with job (5, 0, 8), trying to register it.
20:16:02 WORKER: registered result for job (5, 0, 8) with dispatcher
20:16:02 DISPATCHER: job (5, 0, 8) finished
20:16:02 DISPATCHER: register_result: lock acquired
20:16:02 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
20:16:02 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0010691515081022365, 'num_filters_1': 72, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.011327004420626561}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.21137448035740666, 'info': {'data04': 0.21137448035740666, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0010691515081022365, 'num_filters_1': 72, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.011327004420626561}"}}
exception: None

20:16:02 job_callback for (5, 0, 8) started
20:16:02 DISPATCHER: Trying to submit another job.
20:16:02 job_callback for (5, 0, 8) got condition
20:16:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:16:02 done building a new model for budget 133.333333 based on 17/30 split
Best loss for this budget:-0.216926





20:16:02 HBMASTER: Trying to run another job!
20:16:02 job_callback for (5, 0, 8) finished
20:16:02 ITERATION: Advancing config (5, 0, 0) to next budget 400.000000
20:16:02 ITERATION: Advancing config (5, 0, 3) to next budget 400.000000
20:16:02 ITERATION: Advancing config (5, 0, 8) to next budget 400.000000
20:16:02 HBMASTER: schedule new run for iteration 5
20:16:02 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
20:16:02 HBMASTER: submitting job (5, 0, 0) to dispatcher
20:16:02 DISPATCHER: trying to submit job (5, 0, 0)
20:16:02 DISPATCHER: trying to notify the job_runner thread.
20:16:02 HBMASTER: job (5, 0, 0) submitted to dispatcher
20:16:02 DISPATCHER: Trying to submit another job.
20:16:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:16:02 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
20:16:02 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
20:16:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:16:02 WORKER: start processing job (5, 0, 0)
20:16:02 WORKER: args: ()
20:16:02 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0019377940882167434, 'num_filters_1': 88, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.013080042412311789, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 90, 'num_filters_3': 109}, 'budget': 400.0, 'working_directory': '.'}
20:16:12 DISPATCHER: Starting worker discovery
20:16:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:16:12 DISPATCHER: Finished worker discovery
20:17:12 DISPATCHER: Starting worker discovery
20:17:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:17:12 DISPATCHER: Finished worker discovery
20:18:12 DISPATCHER: Starting worker discovery
20:18:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:18:12 DISPATCHER: Finished worker discovery
20:19:12 DISPATCHER: Starting worker discovery
20:19:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:19:12 DISPATCHER: Finished worker discovery
20:20:12 DISPATCHER: Starting worker discovery
20:20:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:20:12 DISPATCHER: Finished worker discovery
20:21:12 DISPATCHER: Starting worker discovery
20:21:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:21:12 DISPATCHER: Finished worker discovery
20:22:12 DISPATCHER: Starting worker discovery
20:22:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:22:12 DISPATCHER: Finished worker discovery
20:23:12 DISPATCHER: Starting worker discovery
20:23:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:23:12 DISPATCHER: Finished worker discovery
20:23:40 WORKER: done with job (5, 0, 0), trying to register it.
20:23:40 WORKER: registered result for job (5, 0, 0) with dispatcher
20:23:40 DISPATCHER: job (5, 0, 0) finished
20:23:40 DISPATCHER: register_result: lock acquired
20:23:40 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
20:23:40 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0019377940882167434, 'num_filters_1': 88, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.013080042412311789, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 90, 'num_filters_3': 109}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.19971037641143538, 'info': {'data04': 0.19971037641143538, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0019377940882167434, 'num_filters_1': 88, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.013080042412311789, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 90, 'num_filters_3': 109}"}}
exception: None

20:23:40 job_callback for (5, 0, 0) started
20:23:40 DISPATCHER: Trying to submit another job.
20:23:40 job_callback for (5, 0, 0) got condition
20:23:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:23:40 Only 16 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
20:23:40 HBMASTER: Trying to run another job!
20:23:40 job_callback for (5, 0, 0) finished
20:23:40 HBMASTER: schedule new run for iteration 5
20:23:40 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
20:23:40 HBMASTER: submitting job (5, 0, 3) to dispatcher
20:23:40 DISPATCHER: trying to submit job (5, 0, 3)
20:23:40 DISPATCHER: trying to notify the job_runner thread.
20:23:40 HBMASTER: job (5, 0, 3) submitted to dispatcher
20:23:40 DISPATCHER: Trying to submit another job.
20:23:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:23:40 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
20:23:40 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
20:23:40 WORKER: start processing job (5, 0, 3)
20:23:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:23:40 WORKER: args: ()
20:23:40 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0027011468107778916, 'num_filters_1': 53, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.011711406704224239}, 'budget': 400.0, 'working_directory': '.'}
20:24:12 DISPATCHER: Starting worker discovery
20:24:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:24:12 DISPATCHER: Finished worker discovery
20:25:12 DISPATCHER: Starting worker discovery
20:25:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:25:12 DISPATCHER: Finished worker discovery
20:26:12 DISPATCHER: Starting worker discovery
20:26:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:26:12 DISPATCHER: Finished worker discovery
20:27:12 DISPATCHER: Starting worker discovery
20:27:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:27:12 DISPATCHER: Finished worker discovery
20:28:12 DISPATCHER: Starting worker discovery
20:28:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:28:12 DISPATCHER: Finished worker discovery
20:29:12 DISPATCHER: Starting worker discovery
20:29:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:29:12 DISPATCHER: Finished worker discovery
20:30:12 DISPATCHER: Starting worker discovery
20:30:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:30:12 DISPATCHER: Finished worker discovery
20:31:12 DISPATCHER: Starting worker discovery
20:31:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:31:12 DISPATCHER: Finished worker discovery
20:31:38 WORKER: done with job (5, 0, 3), trying to register it.
20:31:38 WORKER: registered result for job (5, 0, 3) with dispatcher
20:31:38 DISPATCHER: job (5, 0, 3) finished
20:31:38 DISPATCHER: register_result: lock acquired
20:31:38 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
20:31:38 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0027011468107778916, 'num_filters_1': 53, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.011711406704224239}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.1587451382889783, 'info': {'data04': 0.1587451382889783, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0027011468107778916, 'num_filters_1': 53, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.011711406704224239}"}}
exception: None

20:31:38 job_callback for (5, 0, 3) started
20:31:38 DISPATCHER: Trying to submit another job.
20:31:38 job_callback for (5, 0, 3) got condition
20:31:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:31:38 HBMASTER: Trying to run another job!
20:31:38 job_callback for (5, 0, 3) finished
20:31:38 HBMASTER: schedule new run for iteration 5
20:31:38 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
20:31:38 HBMASTER: submitting job (5, 0, 8) to dispatcher
20:31:38 DISPATCHER: trying to submit job (5, 0, 8)
20:31:38 DISPATCHER: trying to notify the job_runner thread.
20:31:38 HBMASTER: job (5, 0, 8) submitted to dispatcher
20:31:38 DISPATCHER: Trying to submit another job.
20:31:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:31:38 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880
20:31:38 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
20:31:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:31:38 WORKER: start processing job (5, 0, 8)
20:31:38 WORKER: args: ()
20:31:38 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0010691515081022365, 'num_filters_1': 72, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.011327004420626561}, 'budget': 400.0, 'working_directory': '.'}
20:32:12 DISPATCHER: Starting worker discovery
20:32:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:32:12 DISPATCHER: Finished worker discovery
20:33:12 DISPATCHER: Starting worker discovery
20:33:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:33:12 DISPATCHER: Finished worker discovery
20:34:12 DISPATCHER: Starting worker discovery
20:34:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:34:12 DISPATCHER: Finished worker discovery
20:35:12 DISPATCHER: Starting worker discovery
20:35:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:35:12 DISPATCHER: Finished worker discovery
20:36:12 DISPATCHER: Starting worker discovery
20:36:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:36:12 DISPATCHER: Finished worker discovery
20:37:12 DISPATCHER: Starting worker discovery
20:37:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:37:12 DISPATCHER: Finished worker discovery
20:38:12 DISPATCHER: Starting worker discovery
20:38:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:38:12 DISPATCHER: Finished worker discovery
20:39:12 DISPATCHER: Starting worker discovery
20:39:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:39:13 DISPATCHER: Finished worker discovery
20:39:38 WORKER: done with job (5, 0, 8), trying to register it.
20:39:38 WORKER: registered result for job (5, 0, 8) with dispatcher
20:39:38 DISPATCHER: job (5, 0, 8) finished
20:39:38 DISPATCHER: register_result: lock acquired
20:39:38 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
20:39:38 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0010691515081022365, 'num_filters_1': 72, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.011327004420626561}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.17980117938691065, 'info': {'data04': 0.17980117938691065, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0010691515081022365, 'num_filters_1': 72, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.011327004420626561}"}}
exception: None

20:39:38 job_callback for (5, 0, 8) started
20:39:38 DISPATCHER: Trying to submit another job.
20:39:38 job_callback for (5, 0, 8) got condition
20:39:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:39:38 HBMASTER: Trying to run another job!
20:39:38 job_callback for (5, 0, 8) finished
20:39:38 ITERATION: Advancing config (5, 0, 0) to next budget 1200.000000
20:39:38 HBMASTER: schedule new run for iteration 5
20:39:38 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
20:39:38 HBMASTER: submitting job (5, 0, 0) to dispatcher
20:39:38 DISPATCHER: trying to submit job (5, 0, 0)
20:39:38 DISPATCHER: trying to notify the job_runner thread.
20:39:38 HBMASTER: job (5, 0, 0) submitted to dispatcher
20:39:38 DISPATCHER: Trying to submit another job.
20:39:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:39:38 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
20:39:38 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
20:39:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:39:38 WORKER: start processing job (5, 0, 0)
20:39:38 WORKER: args: ()
20:39:38 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0019377940882167434, 'num_filters_1': 88, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.013080042412311789, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 90, 'num_filters_3': 109}, 'budget': 1200.0, 'working_directory': '.'}
20:40:13 DISPATCHER: Starting worker discovery
20:40:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:40:13 DISPATCHER: Finished worker discovery
20:41:13 DISPATCHER: Starting worker discovery
20:41:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:41:13 DISPATCHER: Finished worker discovery
20:42:13 DISPATCHER: Starting worker discovery
20:42:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:42:13 DISPATCHER: Finished worker discovery
20:43:13 DISPATCHER: Starting worker discovery
20:43:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:43:13 DISPATCHER: Finished worker discovery
20:44:13 DISPATCHER: Starting worker discovery
20:44:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:44:13 DISPATCHER: Finished worker discovery
20:45:13 DISPATCHER: Starting worker discovery
20:45:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:45:13 DISPATCHER: Finished worker discovery
20:46:13 DISPATCHER: Starting worker discovery
20:46:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:46:13 DISPATCHER: Finished worker discovery
20:47:13 DISPATCHER: Starting worker discovery
20:47:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:47:13 DISPATCHER: Finished worker discovery
20:48:13 DISPATCHER: Starting worker discovery
20:48:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:48:13 DISPATCHER: Finished worker discovery
20:49:13 DISPATCHER: Starting worker discovery
20:49:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:49:13 DISPATCHER: Finished worker discovery
20:50:13 DISPATCHER: Starting worker discovery
20:50:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:50:13 DISPATCHER: Finished worker discovery
20:51:13 DISPATCHER: Starting worker discovery
20:51:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:51:13 DISPATCHER: Finished worker discovery
20:52:13 DISPATCHER: Starting worker discovery
20:52:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:52:13 DISPATCHER: Finished worker discovery
20:53:13 DISPATCHER: Starting worker discovery
20:53:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:53:13 DISPATCHER: Finished worker discovery
20:54:13 DISPATCHER: Starting worker discovery
20:54:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:54:13 DISPATCHER: Finished worker discovery
20:55:13 DISPATCHER: Starting worker discovery
20:55:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:55:13 DISPATCHER: Finished worker discovery
20:56:13 DISPATCHER: Starting worker discovery
20:56:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:56:13 DISPATCHER: Finished worker discovery
20:57:13 DISPATCHER: Starting worker discovery
20:57:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:57:13 DISPATCHER: Finished worker discovery
20:58:13 DISPATCHER: Starting worker discovery
20:58:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:58:13 DISPATCHER: Finished worker discovery
20:59:13 DISPATCHER: Starting worker discovery
20:59:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:59:13 DISPATCHER: Finished worker discovery
21:00:13 DISPATCHER: Starting worker discovery
21:00:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:00:13 DISPATCHER: Finished worker discovery
21:01:13 DISPATCHER: Starting worker discovery
21:01:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:01:13 DISPATCHER: Finished worker discovery
21:02:03 WORKER: done with job (5, 0, 0), trying to register it.
21:02:03 WORKER: registered result for job (5, 0, 0) with dispatcher
21:02:03 DISPATCHER: job (5, 0, 0) finished
21:02:03 DISPATCHER: register_result: lock acquired
21:02:03 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
21:02:03 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0019377940882167434, 'num_filters_1': 88, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.013080042412311789, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 90, 'num_filters_3': 109}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.1367586496483239, 'info': {'data04': 0.1367586496483239, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0019377940882167434, 'num_filters_1': 88, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.013080042412311789, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 90, 'num_filters_3': 109}"}}
exception: None

21:02:03 job_callback for (5, 0, 0) started
21:02:03 DISPATCHER: Trying to submit another job.
21:02:03 job_callback for (5, 0, 0) got condition
21:02:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:02:03 Only 10 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
21:02:03 HBMASTER: Trying to run another job!
21:02:03 job_callback for (5, 0, 0) finished
21:02:03 start sampling a new configuration.
21:02:03 best_vector: [3, 2, 0.4810771360168717, 0.9798803751034818, 0.2513930750201373, 1, 0.04110598975562219, 0.18011619426641023, 1, 1, 1, 0, 0.6836919118674627, 0.9271180646037671, 0.6023310696001697, 0.5236705385802756], 0.0011623635621392917, 0.03312442227810412, 3.8502621472983215e-05
21:02:03 done sampling a new configuration.
21:02:03 HBMASTER: schedule new run for iteration 6
21:02:03 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
21:02:03 HBMASTER: submitting job (6, 0, 0) to dispatcher
21:02:03 DISPATCHER: trying to submit job (6, 0, 0)
21:02:03 DISPATCHER: trying to notify the job_runner thread.
21:02:03 HBMASTER: job (6, 0, 0) submitted to dispatcher
21:02:03 DISPATCHER: Trying to submit another job.
21:02:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:02:03 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:02:03 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:02:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:02:03 WORKER: start processing job (6, 0, 0)
21:02:03 WORKER: args: ()
21:02:03 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.00916546011887127, 'num_filters_1': 123, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.01715286112507072, 'kernel_size_2': 5, 'num_filters_2': 66}, 'budget': 400.0, 'working_directory': '.'}
21:02:13 DISPATCHER: Starting worker discovery
21:02:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:02:13 DISPATCHER: Finished worker discovery
21:03:13 DISPATCHER: Starting worker discovery
21:03:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:03:13 DISPATCHER: Finished worker discovery
21:04:13 DISPATCHER: Starting worker discovery
21:04:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:04:13 DISPATCHER: Finished worker discovery
21:05:13 DISPATCHER: Starting worker discovery
21:05:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:05:13 DISPATCHER: Finished worker discovery
21:06:13 DISPATCHER: Starting worker discovery
21:06:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:06:13 DISPATCHER: Finished worker discovery
21:07:13 DISPATCHER: Starting worker discovery
21:07:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:07:13 DISPATCHER: Finished worker discovery
21:08:13 DISPATCHER: Starting worker discovery
21:08:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:08:13 DISPATCHER: Finished worker discovery
21:09:13 DISPATCHER: Starting worker discovery
21:09:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:09:13 DISPATCHER: Finished worker discovery
21:10:13 DISPATCHER: Starting worker discovery
21:10:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:10:14 DISPATCHER: Finished worker discovery
21:11:08 WORKER: done with job (6, 0, 0), trying to register it.
21:11:08 WORKER: registered result for job (6, 0, 0) with dispatcher
21:11:08 DISPATCHER: job (6, 0, 0) finished
21:11:08 DISPATCHER: register_result: lock acquired
21:11:08 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
21:11:08 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.00916546011887127, 'num_filters_1': 123, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.01715286112507072, 'kernel_size_2': 5, 'num_filters_2': 66}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.05027665321901964, 'info': {'data04': 0.05027665321901964, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.00916546011887127, 'num_filters_1': 123, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.01715286112507072, 'kernel_size_2': 5, 'num_filters_2': 66}"}}
exception: None

21:11:08 job_callback for (6, 0, 0) started
21:11:08 DISPATCHER: Trying to submit another job.
21:11:08 job_callback for (6, 0, 0) got condition
21:11:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:11:08 HBMASTER: Trying to run another job!
21:11:08 job_callback for (6, 0, 0) finished
21:11:08 start sampling a new configuration.
21:11:09 best_vector: [0, 1, 0.7040051031844318, 0.5509744166890718, 0.163140083225865, 1, 0.0664758218641898, 0.09348675912523637, 1, 1, 2, 1, 0.9454278020361345, 0.6889782685947701, 0.698152728905104, 0.5217255318956022], 0.00014491100777438786, 0.011126185763818323, 1.6123067917199606e-06
21:11:09 done sampling a new configuration.
21:11:09 HBMASTER: schedule new run for iteration 6
21:11:09 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
21:11:09 HBMASTER: submitting job (6, 0, 1) to dispatcher
21:11:09 DISPATCHER: trying to submit job (6, 0, 1)
21:11:09 DISPATCHER: trying to notify the job_runner thread.
21:11:09 HBMASTER: job (6, 0, 1) submitted to dispatcher
21:11:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:11:09 DISPATCHER: Trying to submit another job.
21:11:09 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:11:09 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:11:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:11:09 WORKER: start processing job (6, 0, 1)
21:11:09 WORKER: args: ()
21:11:09 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.025586460170230512, 'num_filters_1': 50, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.013232109246147322}, 'budget': 400.0, 'working_directory': '.'}
21:11:14 DISPATCHER: Starting worker discovery
21:11:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:11:14 DISPATCHER: Finished worker discovery
21:12:14 DISPATCHER: Starting worker discovery
21:12:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:12:14 DISPATCHER: Finished worker discovery
21:13:14 DISPATCHER: Starting worker discovery
21:13:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:13:14 DISPATCHER: Finished worker discovery
21:14:14 DISPATCHER: Starting worker discovery
21:14:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:14:14 DISPATCHER: Finished worker discovery
21:15:14 DISPATCHER: Starting worker discovery
21:15:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:15:14 DISPATCHER: Finished worker discovery
21:16:14 DISPATCHER: Starting worker discovery
21:16:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:16:14 DISPATCHER: Finished worker discovery
21:17:14 DISPATCHER: Starting worker discovery
21:17:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:17:14 DISPATCHER: Finished worker discovery
21:18:14 DISPATCHER: Starting worker discovery
21:18:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:18:14 DISPATCHER: Finished worker discovery
21:19:14 DISPATCHER: Starting worker discovery
21:19:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:19:14 DISPATCHER: Finished worker discovery
21:20:14 DISPATCHER: Starting worker discovery
21:20:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:20:14 DISPATCHER: Finished worker discovery
21:20:40 WORKER: done with job (6, 0, 1), trying to register it.
21:20:40 WORKER: registered result for job (6, 0, 1) with dispatcher
21:20:40 DISPATCHER: job (6, 0, 1) finished
21:20:40 DISPATCHER: register_result: lock acquired
21:20:40 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
21:20:40 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.025586460170230512, 'num_filters_1': 50, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.013232109246147322}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.125453610395374, 'info': {'data04': 0.125453610395374, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.025586460170230512, 'num_filters_1': 50, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.013232109246147322}"}}
exception: None

21:20:40 job_callback for (6, 0, 1) started
21:20:40 DISPATCHER: Trying to submit another job.
21:20:40 job_callback for (6, 0, 1) got condition
21:20:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:20:40 HBMASTER: Trying to run another job!
21:20:40 job_callback for (6, 0, 1) finished
21:20:40 start sampling a new configuration.
21:20:40 best_vector: [3, 1, 0.454625229112559, 0.8313366650992554, 0.3118051368193019, 1, 0.009330819023178345, 0.12549152158841062, 1, 1, 2, 1, 0.9957066167658056, 0.8468352175760958, 0.9653462788328389, 0.8445622942368416], 2.4726338151318328e-05, 0.06003711198206744, 1.4844979324971648e-06
21:20:40 done sampling a new configuration.
21:20:40 HBMASTER: schedule new run for iteration 6
21:20:40 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
21:20:40 HBMASTER: submitting job (6, 0, 2) to dispatcher
21:20:40 DISPATCHER: trying to submit job (6, 0, 2)
21:20:40 DISPATCHER: trying to notify the job_runner thread.
21:20:40 HBMASTER: job (6, 0, 2) submitted to dispatcher
21:20:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:20:40 DISPATCHER: Trying to submit another job.
21:20:40 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:20:40 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:20:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:20:40 WORKER: start processing job (6, 0, 2)
21:20:40 WORKER: args: ()
21:20:40 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.008114288750939, 'num_filters_1': 90, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.014563582950694376, 'kernel_size_2': 5, 'num_filters_2': 127}, 'budget': 400.0, 'working_directory': '.'}
21:21:14 DISPATCHER: Starting worker discovery
21:21:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:21:14 DISPATCHER: Finished worker discovery
21:22:14 DISPATCHER: Starting worker discovery
21:22:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:22:14 DISPATCHER: Finished worker discovery
21:23:14 DISPATCHER: Starting worker discovery
21:23:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:23:14 DISPATCHER: Finished worker discovery
21:24:14 DISPATCHER: Starting worker discovery
21:24:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:24:14 DISPATCHER: Finished worker discovery
21:25:14 DISPATCHER: Starting worker discovery
21:25:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:25:14 DISPATCHER: Finished worker discovery
21:26:14 DISPATCHER: Starting worker discovery
21:26:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:26:14 DISPATCHER: Finished worker discovery
21:27:14 DISPATCHER: Starting worker discovery
21:27:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:27:14 DISPATCHER: Finished worker discovery
21:28:14 DISPATCHER: Starting worker discovery
21:28:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:28:14 DISPATCHER: Finished worker discovery
21:29:14 DISPATCHER: Starting worker discovery
21:29:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:29:15 DISPATCHER: Finished worker discovery
21:30:15 DISPATCHER: Starting worker discovery
21:30:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:30:15 DISPATCHER: Finished worker discovery
21:30:25 WORKER: done with job (6, 0, 2), trying to register it.
21:30:25 WORKER: registered result for job (6, 0, 2) with dispatcher
21:30:25 DISPATCHER: job (6, 0, 2) finished
21:30:25 DISPATCHER: register_result: lock acquired
21:30:25 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
21:30:25 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.008114288750939, 'num_filters_1': 90, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.014563582950694376, 'kernel_size_2': 5, 'num_filters_2': 127}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.12272851553045167, 'info': {'data04': 0.12272851553045167, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.008114288750939, 'num_filters_1': 90, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.014563582950694376, 'kernel_size_2': 5, 'num_filters_2': 127}"}}
exception: None

21:30:25 job_callback for (6, 0, 2) started
21:30:25 DISPATCHER: Trying to submit another job.
21:30:25 job_callback for (6, 0, 2) got condition
21:30:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:30:25 HBMASTER: Trying to run another job!
21:30:25 job_callback for (6, 0, 2) finished
21:30:25 start sampling a new configuration.
21:30:25 best_vector: [0, 1, 0.7145698150220601, 0.39701764333957607, 0.07648924382994063, 1, 0.07963354243789907, 0.058661816330931385, 0, 1, 1, 0, 0.6942410197773821, 0.4337811658943871, 0.4426774786780691, 0.765714970831552], 3.969296746032864e-05, 0.028191374260173273, 1.118999301171004e-06
21:30:25 done sampling a new configuration.
21:30:25 HBMASTER: schedule new run for iteration 6
21:30:25 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
21:30:25 HBMASTER: submitting job (6, 0, 3) to dispatcher
21:30:25 DISPATCHER: trying to submit job (6, 0, 3)
21:30:25 DISPATCHER: trying to notify the job_runner thread.
21:30:25 HBMASTER: job (6, 0, 3) submitted to dispatcher
21:30:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:30:25 DISPATCHER: Trying to submit another job.
21:30:25 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:30:25 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:30:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:30:25 WORKER: start processing job (6, 0, 3)
21:30:25 WORKER: args: ()
21:30:25 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.026862079497124994, 'num_filters_1': 36, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.011921222193608666}, 'budget': 400.0, 'working_directory': '.'}
21:31:15 DISPATCHER: Starting worker discovery
21:31:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:31:15 DISPATCHER: Finished worker discovery
21:32:15 DISPATCHER: Starting worker discovery
21:32:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:32:15 DISPATCHER: Finished worker discovery
21:33:15 DISPATCHER: Starting worker discovery
21:33:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:33:15 DISPATCHER: Finished worker discovery
21:34:15 DISPATCHER: Starting worker discovery
21:34:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:34:15 DISPATCHER: Finished worker discovery
21:35:15 DISPATCHER: Starting worker discovery
21:35:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:35:15 DISPATCHER: Finished worker discovery
21:36:15 DISPATCHER: Starting worker discovery
21:36:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:36:15 DISPATCHER: Finished worker discovery
21:37:15 DISPATCHER: Starting worker discovery
21:37:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:37:15 DISPATCHER: Finished worker discovery
21:38:15 DISPATCHER: Starting worker discovery
21:38:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:38:15 DISPATCHER: Finished worker discovery
21:39:15 DISPATCHER: Starting worker discovery
21:39:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:39:15 DISPATCHER: Finished worker discovery
21:39:44 WORKER: done with job (6, 0, 3), trying to register it.
21:39:44 WORKER: registered result for job (6, 0, 3) with dispatcher
21:39:44 DISPATCHER: job (6, 0, 3) finished
21:39:44 DISPATCHER: register_result: lock acquired
21:39:44 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
21:39:44 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.026862079497124994, 'num_filters_1': 36, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.011921222193608666}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.12175447234251072, 'info': {'data04': 0.12175447234251072, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.026862079497124994, 'num_filters_1': 36, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.011921222193608666}"}}
exception: None

21:39:44 job_callback for (6, 0, 3) started
21:39:44 DISPATCHER: Trying to submit another job.
21:39:44 job_callback for (6, 0, 3) got condition
21:39:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:39:44 HBMASTER: Trying to run another job!
21:39:44 job_callback for (6, 0, 3) finished
21:39:44 start sampling a new configuration.
21:39:45 best_vector: [0, 1, 0.005436860112061176, 0.6820902426505704, 0.1199395030872972, 1, 0.7545365822357395, 0.1294407352133573, 1, 1, 2, 0, 0.3200759794953571, 0.12164293598709291, 0.06572587795265283, 0.7707766866322917], 0.0009353289924105426, 0.0013268684086946974, 1.2410584917657912e-06
21:39:45 done sampling a new configuration.
21:39:45 HBMASTER: schedule new run for iteration 6
21:39:45 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
21:39:45 HBMASTER: submitting job (6, 0, 4) to dispatcher
21:39:45 DISPATCHER: trying to submit job (6, 0, 4)
21:39:45 DISPATCHER: trying to notify the job_runner thread.
21:39:45 HBMASTER: job (6, 0, 4) submitted to dispatcher
21:39:45 DISPATCHER: Trying to submit another job.
21:39:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:39:45 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:39:45 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:39:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:39:45 WORKER: start processing job (6, 0, 4)
21:39:45 WORKER: args: ()
21:39:45 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0010253537408669103, 'num_filters_1': 66, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.014736904839874863}, 'budget': 400.0, 'working_directory': '.'}
21:40:15 DISPATCHER: Starting worker discovery
21:40:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:40:15 DISPATCHER: Finished worker discovery
21:41:15 DISPATCHER: Starting worker discovery
21:41:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:41:15 DISPATCHER: Finished worker discovery
21:42:15 DISPATCHER: Starting worker discovery
21:42:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:42:15 DISPATCHER: Finished worker discovery
21:43:15 DISPATCHER: Starting worker discovery
21:43:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:43:15 DISPATCHER: Finished worker discovery
21:44:15 DISPATCHER: Starting worker discovery
21:44:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:44:15 DISPATCHER: Finished worker discovery
21:45:15 DISPATCHER: Starting worker discovery
21:45:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:45:15 DISPATCHER: Finished worker discovery
21:46:15 DISPATCHER: Starting worker discovery
21:46:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:46:15 DISPATCHER: Finished worker discovery
21:47:11 WORKER: done with job (6, 0, 4), trying to register it.
21:47:11 WORKER: registered result for job (6, 0, 4) with dispatcher
21:47:11 DISPATCHER: job (6, 0, 4) finished
21:47:11 DISPATCHER: register_result: lock acquired
21:47:11 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
21:47:11 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0010253537408669103, 'num_filters_1': 66, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.014736904839874863}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.17590897909215247, 'info': {'data04': 0.17590897909215247, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0010253537408669103, 'num_filters_1': 66, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.014736904839874863}"}}
exception: None

21:47:11 job_callback for (6, 0, 4) started
21:47:11 DISPATCHER: Trying to submit another job.
21:47:11 job_callback for (6, 0, 4) got condition
21:47:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:47:11 HBMASTER: Trying to run another job!
21:47:11 job_callback for (6, 0, 4) finished
21:47:11 start sampling a new configuration.
21:47:11 best_vector: [0, 2, 0.42806728000424565, 0.4214242057487951, 0.003980125899884723, 1, 0.43089891435535166, 0.14542839748868877, 0, 1, 1, 1, 0.9888480813337596, 0.9868807695395062, 0.7195905700833586, 0.038934973346565704], 0.0002781398736991288, 0.02870963327644699, 7.98529377345927e-06
21:47:11 done sampling a new configuration.
21:47:11 HBMASTER: schedule new run for iteration 6
21:47:11 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
21:47:11 HBMASTER: submitting job (6, 0, 5) to dispatcher
21:47:11 DISPATCHER: trying to submit job (6, 0, 5)
21:47:11 DISPATCHER: trying to notify the job_runner thread.
21:47:11 HBMASTER: job (6, 0, 5) submitted to dispatcher
21:47:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:47:11 DISPATCHER: Trying to submit another job.
21:47:11 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:47:11 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:47:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:47:11 WORKER: start processing job (6, 0, 5)
21:47:11 WORKER: args: ()
21:47:11 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00718016724146901, 'num_filters_1': 38, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.01545990095865446}, 'budget': 400.0, 'working_directory': '.'}
21:47:15 DISPATCHER: Starting worker discovery
21:47:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:47:15 DISPATCHER: Finished worker discovery
21:48:15 DISPATCHER: Starting worker discovery
21:48:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:48:15 DISPATCHER: Finished worker discovery
21:49:15 DISPATCHER: Starting worker discovery
21:49:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:49:15 DISPATCHER: Finished worker discovery
21:50:15 DISPATCHER: Starting worker discovery
21:50:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:50:15 DISPATCHER: Finished worker discovery
21:51:15 DISPATCHER: Starting worker discovery
21:51:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:51:15 DISPATCHER: Finished worker discovery
21:52:15 DISPATCHER: Starting worker discovery
21:52:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:52:15 DISPATCHER: Finished worker discovery
21:53:15 DISPATCHER: Starting worker discovery
21:53:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:53:15 DISPATCHER: Finished worker discovery
21:54:15 DISPATCHER: Starting worker discovery
21:54:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:54:16 DISPATCHER: Finished worker discovery
21:54:58 WORKER: done with job (6, 0, 5), trying to register it.
21:54:58 WORKER: registered result for job (6, 0, 5) with dispatcher
21:54:58 DISPATCHER: job (6, 0, 5) finished
21:54:58 DISPATCHER: register_result: lock acquired
21:54:58 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
21:54:58 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00718016724146901, 'num_filters_1': 38, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.01545990095865446}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.1450121722271597, 'info': {'data04': 0.1450121722271597, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00718016724146901, 'num_filters_1': 38, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.01545990095865446}"}}
exception: None

21:54:58 job_callback for (6, 0, 5) started
21:54:58 job_callback for (6, 0, 5) got condition
21:54:58 DISPATCHER: Trying to submit another job.
21:54:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:54:58 HBMASTER: Trying to run another job!
21:54:58 job_callback for (6, 0, 5) finished
21:54:58 ITERATION: Advancing config (6, 0, 4) to next budget 1200.000000
21:54:58 ITERATION: Advancing config (6, 0, 5) to next budget 1200.000000
21:54:58 HBMASTER: schedule new run for iteration 6
21:54:58 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
21:54:58 HBMASTER: submitting job (6, 0, 4) to dispatcher
21:54:58 DISPATCHER: trying to submit job (6, 0, 4)
21:54:58 DISPATCHER: trying to notify the job_runner thread.
21:54:58 HBMASTER: job (6, 0, 4) submitted to dispatcher
21:54:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:54:58 DISPATCHER: Trying to submit another job.
21:54:58 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:54:58 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:54:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:54:58 WORKER: start processing job (6, 0, 4)
21:54:58 WORKER: args: ()
21:54:58 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0010253537408669103, 'num_filters_1': 66, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.014736904839874863}, 'budget': 1200.0, 'working_directory': '.'}
21:55:16 DISPATCHER: Starting worker discovery
21:55:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:55:16 DISPATCHER: Finished worker discovery
21:56:16 DISPATCHER: Starting worker discovery
21:56:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:56:16 DISPATCHER: Finished worker discovery
21:57:16 DISPATCHER: Starting worker discovery
21:57:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:57:16 DISPATCHER: Finished worker discovery
21:58:16 DISPATCHER: Starting worker discovery
21:58:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:58:16 DISPATCHER: Finished worker discovery
21:59:16 DISPATCHER: Starting worker discovery
21:59:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:59:16 DISPATCHER: Finished worker discovery
22:00:16 DISPATCHER: Starting worker discovery
22:00:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:00:16 DISPATCHER: Finished worker discovery
22:01:16 DISPATCHER: Starting worker discovery
22:01:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:01:16 DISPATCHER: Finished worker discovery
22:02:16 DISPATCHER: Starting worker discovery
22:02:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:02:16 DISPATCHER: Finished worker discovery
22:03:16 DISPATCHER: Starting worker discovery
22:03:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:03:16 DISPATCHER: Finished worker discovery
22:04:16 DISPATCHER: Starting worker discovery
22:04:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:04:16 DISPATCHER: Finished worker discovery
22:05:16 DISPATCHER: Starting worker discovery
22:05:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:05:16 DISPATCHER: Finished worker discovery
22:06:16 DISPATCHER: Starting worker discovery
22:06:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:06:16 DISPATCHER: Finished worker discovery
22:07:16 DISPATCHER: Starting worker discovery
22:07:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:07:16 DISPATCHER: Finished worker discovery
22:08:16 DISPATCHER: Starting worker discovery
22:08:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:08:16 DISPATCHER: Finished worker discovery
22:09:16 DISPATCHER: Starting worker discovery
22:09:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:09:16 DISPATCHER: Finished worker discovery
22:10:16 DISPATCHER: Starting worker discovery
22:10:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:10:16 DISPATCHER: Finished worker discovery
22:11:16 DISPATCHER: Starting worker discovery
22:11:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:11:16 DISPATCHER: Finished worker discovery
22:12:16 DISPATCHER: Starting worker discovery
22:12:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:12:16 DISPATCHER: Finished worker discovery
22:13:16 DISPATCHER: Starting worker discovery
22:13:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:13:16 DISPATCHER: Finished worker discovery
22:14:16 DISPATCHER: Starting worker discovery
22:14:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:14:16 DISPATCHER: Finished worker discovery
22:15:16 DISPATCHER: Starting worker discovery
22:15:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:15:16 DISPATCHER: Finished worker discovery
22:16:16 DISPATCHER: Starting worker discovery
22:16:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:16:16 DISPATCHER: Finished worker discovery
22:16:46 WORKER: done with job (6, 0, 4), trying to register it.
22:16:46 WORKER: registered result for job (6, 0, 4) with dispatcher
22:16:46 DISPATCHER: job (6, 0, 4) finished
22:16:46 DISPATCHER: register_result: lock acquired
22:16:46 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:16:46 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0010253537408669103, 'num_filters_1': 66, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.014736904839874863}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.16625991282670374, 'info': {'data04': 0.16625991282670374, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0010253537408669103, 'num_filters_1': 66, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.014736904839874863}"}}
exception: None

22:16:46 job_callback for (6, 0, 4) started
22:16:46 job_callback for (6, 0, 4) got condition
22:16:46 DISPATCHER: Trying to submit another job.
22:16:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:16:46 Only 11 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
22:16:46 HBMASTER: Trying to run another job!
22:16:46 job_callback for (6, 0, 4) finished
22:16:46 HBMASTER: schedule new run for iteration 6
22:16:46 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
22:16:46 HBMASTER: submitting job (6, 0, 5) to dispatcher
22:16:46 DISPATCHER: trying to submit job (6, 0, 5)
22:16:46 DISPATCHER: trying to notify the job_runner thread.
22:16:46 HBMASTER: job (6, 0, 5) submitted to dispatcher
22:16:46 DISPATCHER: Trying to submit another job.
22:16:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:16:46 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:16:46 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:16:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:16:46 WORKER: start processing job (6, 0, 5)
22:16:46 WORKER: args: ()
22:16:46 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00718016724146901, 'num_filters_1': 38, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.01545990095865446}, 'budget': 1200.0, 'working_directory': '.'}
22:17:16 DISPATCHER: Starting worker discovery
22:17:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:17:16 DISPATCHER: Finished worker discovery
22:18:16 DISPATCHER: Starting worker discovery
22:18:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:18:16 DISPATCHER: Finished worker discovery
22:19:16 DISPATCHER: Starting worker discovery
22:19:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:19:16 DISPATCHER: Finished worker discovery
22:20:16 DISPATCHER: Starting worker discovery
22:20:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:20:16 DISPATCHER: Finished worker discovery
22:21:16 DISPATCHER: Starting worker discovery
22:21:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:21:16 DISPATCHER: Finished worker discovery
22:22:16 DISPATCHER: Starting worker discovery
22:22:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:22:16 DISPATCHER: Finished worker discovery
22:23:16 DISPATCHER: Starting worker discovery
22:23:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:23:16 DISPATCHER: Finished worker discovery
22:24:16 DISPATCHER: Starting worker discovery
22:24:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:24:16 DISPATCHER: Finished worker discovery
22:25:16 DISPATCHER: Starting worker discovery
22:25:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:25:16 DISPATCHER: Finished worker discovery
22:26:16 DISPATCHER: Starting worker discovery
22:26:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:26:16 DISPATCHER: Finished worker discovery
22:27:16 DISPATCHER: Starting worker discovery
22:27:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:27:16 DISPATCHER: Finished worker discovery
22:28:16 DISPATCHER: Starting worker discovery
22:28:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:28:16 DISPATCHER: Finished worker discovery
22:29:16 DISPATCHER: Starting worker discovery
22:29:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:29:16 DISPATCHER: Finished worker discovery
22:30:16 DISPATCHER: Starting worker discovery
22:30:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:30:16 DISPATCHER: Finished worker discovery
22:31:16 DISPATCHER: Starting worker discovery
22:31:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:31:16 DISPATCHER: Finished worker discovery
22:32:16 DISPATCHER: Starting worker discovery
22:32:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:32:16 DISPATCHER: Finished worker discovery
22:33:16 DISPATCHER: Starting worker discovery
22:33:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:33:16 DISPATCHER: Finished worker discovery
22:34:16 DISPATCHER: Starting worker discovery
22:34:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:34:16 DISPATCHER: Finished worker discovery
22:35:16 DISPATCHER: Starting worker discovery
22:35:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:35:16 DISPATCHER: Finished worker discovery
22:36:16 DISPATCHER: Starting worker discovery
22:36:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:36:16 DISPATCHER: Finished worker discovery
22:37:16 DISPATCHER: Starting worker discovery
22:37:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:37:16 DISPATCHER: Finished worker discovery
22:38:16 DISPATCHER: Starting worker discovery
22:38:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:38:17 DISPATCHER: Finished worker discovery
22:39:17 DISPATCHER: Starting worker discovery
22:39:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:39:17 DISPATCHER: Finished worker discovery
22:39:41 WORKER: done with job (6, 0, 5), trying to register it.
22:39:41 WORKER: registered result for job (6, 0, 5) with dispatcher
22:39:41 DISPATCHER: job (6, 0, 5) finished
22:39:41 DISPATCHER: register_result: lock acquired
22:39:41 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:39:41 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00718016724146901, 'num_filters_1': 38, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.01545990095865446}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.13041405633842013, 'info': {'data04': 0.13041405633842013, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00718016724146901, 'num_filters_1': 38, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.01545990095865446}"}}
exception: None

22:39:41 job_callback for (6, 0, 5) started
22:39:41 job_callback for (6, 0, 5) got condition
22:39:41 DISPATCHER: Trying to submit another job.
22:39:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:39:41 Only 12 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
22:39:41 HBMASTER: Trying to run another job!
22:39:41 job_callback for (6, 0, 5) finished
22:39:41 start sampling a new configuration.
22:39:41 done sampling a new configuration.
22:39:41 HBMASTER: schedule new run for iteration 7
22:39:41 HBMASTER: trying submitting job (7, 0, 0) to dispatcher
22:39:41 HBMASTER: submitting job (7, 0, 0) to dispatcher
22:39:41 DISPATCHER: trying to submit job (7, 0, 0)
22:39:41 DISPATCHER: trying to notify the job_runner thread.
22:39:41 HBMASTER: job (7, 0, 0) submitted to dispatcher
22:39:41 DISPATCHER: Trying to submit another job.
22:39:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:39:41 DISPATCHER: starting job (7, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:39:41 DISPATCHER: job (7, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:39:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:39:41 WORKER: start processing job (7, 0, 0)
22:39:41 WORKER: args: ()
22:39:41 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004884443622714857, 'num_filters_1': 114, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.029130759696489834, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 21, 'num_filters_3': 83}, 'budget': 1200.0, 'working_directory': '.'}
22:40:17 DISPATCHER: Starting worker discovery
22:40:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:40:17 DISPATCHER: Finished worker discovery
22:41:17 DISPATCHER: Starting worker discovery
22:41:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:41:17 DISPATCHER: Finished worker discovery
22:42:17 DISPATCHER: Starting worker discovery
22:42:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:42:17 DISPATCHER: Finished worker discovery
22:43:17 DISPATCHER: Starting worker discovery
22:43:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:43:17 DISPATCHER: Finished worker discovery
22:44:17 DISPATCHER: Starting worker discovery
22:44:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:44:17 DISPATCHER: Finished worker discovery
22:45:17 DISPATCHER: Starting worker discovery
22:45:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:45:17 DISPATCHER: Finished worker discovery
22:46:17 DISPATCHER: Starting worker discovery
22:46:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:46:17 DISPATCHER: Finished worker discovery
22:47:17 DISPATCHER: Starting worker discovery
22:47:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:47:17 DISPATCHER: Finished worker discovery
22:48:17 DISPATCHER: Starting worker discovery
22:48:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:48:17 DISPATCHER: Finished worker discovery
22:49:17 DISPATCHER: Starting worker discovery
22:49:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:49:17 DISPATCHER: Finished worker discovery
22:50:17 DISPATCHER: Starting worker discovery
22:50:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:50:17 DISPATCHER: Finished worker discovery
22:51:17 DISPATCHER: Starting worker discovery
22:51:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:51:17 DISPATCHER: Finished worker discovery
22:52:17 DISPATCHER: Starting worker discovery
22:52:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:52:17 DISPATCHER: Finished worker discovery
22:53:17 DISPATCHER: Starting worker discovery
22:53:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:53:17 DISPATCHER: Finished worker discovery
22:54:17 DISPATCHER: Starting worker discovery
22:54:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:54:17 DISPATCHER: Finished worker discovery
22:55:17 DISPATCHER: Starting worker discovery
22:55:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:55:17 DISPATCHER: Finished worker discovery
22:56:17 DISPATCHER: Starting worker discovery
22:56:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:56:17 DISPATCHER: Finished worker discovery
22:57:17 DISPATCHER: Starting worker discovery
22:57:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:57:17 DISPATCHER: Finished worker discovery
22:58:17 DISPATCHER: Starting worker discovery
22:58:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:58:17 DISPATCHER: Finished worker discovery
22:59:17 DISPATCHER: Starting worker discovery
22:59:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:59:17 DISPATCHER: Finished worker discovery
23:00:17 DISPATCHER: Starting worker discovery
23:00:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:00:17 DISPATCHER: Finished worker discovery
23:01:17 DISPATCHER: Starting worker discovery
23:01:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:01:17 DISPATCHER: Finished worker discovery
23:01:37 WORKER: done with job (7, 0, 0), trying to register it.
23:01:37 WORKER: registered result for job (7, 0, 0) with dispatcher
23:01:37 DISPATCHER: job (7, 0, 0) finished
23:01:37 DISPATCHER: register_result: lock acquired
23:01:37 DISPATCHER: job (7, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
23:01:37 job_id: (7, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004884443622714857, 'num_filters_1': 114, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.029130759696489834, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 21, 'num_filters_3': 83}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.049008565849580216, 'info': {'data04': 0.049008565849580216, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004884443622714857, 'num_filters_1': 114, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.029130759696489834, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 21, 'num_filters_3': 83}"}}
exception: None

23:01:37 job_callback for (7, 0, 0) started
23:01:37 job_callback for (7, 0, 0) got condition
23:01:37 DISPATCHER: Trying to submit another job.
23:01:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:01:37 Only 13 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
23:01:37 HBMASTER: Trying to run another job!
23:01:37 job_callback for (7, 0, 0) finished
23:01:37 start sampling a new configuration.
23:01:37 done sampling a new configuration.
23:01:38 HBMASTER: schedule new run for iteration 7
23:01:38 HBMASTER: trying submitting job (7, 0, 1) to dispatcher
23:01:38 HBMASTER: submitting job (7, 0, 1) to dispatcher
23:01:38 DISPATCHER: trying to submit job (7, 0, 1)
23:01:38 DISPATCHER: trying to notify the job_runner thread.
23:01:38 HBMASTER: job (7, 0, 1) submitted to dispatcher
23:01:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:01:38 DISPATCHER: Trying to submit another job.
23:01:38 DISPATCHER: starting job (7, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:01:38 DISPATCHER: job (7, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:01:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:01:38 WORKER: start processing job (7, 0, 1)
23:01:38 WORKER: args: ()
23:01:38 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.04553375821685805, 'num_filters_1': 69, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.16873845034028123, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 18, 'num_filters_3': 21}, 'budget': 1200.0, 'working_directory': '.'}
23:02:17 DISPATCHER: Starting worker discovery
23:02:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:02:17 DISPATCHER: Finished worker discovery
23:03:17 DISPATCHER: Starting worker discovery
23:03:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:03:17 DISPATCHER: Finished worker discovery
23:04:17 DISPATCHER: Starting worker discovery
23:04:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:04:17 DISPATCHER: Finished worker discovery
23:05:17 DISPATCHER: Starting worker discovery
23:05:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:05:18 DISPATCHER: Finished worker discovery
23:06:18 DISPATCHER: Starting worker discovery
23:06:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:06:18 DISPATCHER: Finished worker discovery
23:07:18 DISPATCHER: Starting worker discovery
23:07:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:07:18 DISPATCHER: Finished worker discovery
23:08:18 DISPATCHER: Starting worker discovery
23:08:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:08:18 DISPATCHER: Finished worker discovery
23:09:18 DISPATCHER: Starting worker discovery
23:09:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:09:18 DISPATCHER: Finished worker discovery
23:10:18 DISPATCHER: Starting worker discovery
23:10:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:10:18 DISPATCHER: Finished worker discovery
23:11:18 DISPATCHER: Starting worker discovery
23:11:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:11:18 DISPATCHER: Finished worker discovery
23:12:18 DISPATCHER: Starting worker discovery
23:12:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:12:18 DISPATCHER: Finished worker discovery
23:13:18 DISPATCHER: Starting worker discovery
23:13:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:13:18 DISPATCHER: Finished worker discovery
23:14:18 DISPATCHER: Starting worker discovery
23:14:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:14:18 DISPATCHER: Finished worker discovery
23:15:18 DISPATCHER: Starting worker discovery
23:15:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:15:18 DISPATCHER: Finished worker discovery
23:16:18 DISPATCHER: Starting worker discovery
23:16:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:16:18 DISPATCHER: Finished worker discovery
23:17:18 DISPATCHER: Starting worker discovery
23:17:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:17:18 DISPATCHER: Finished worker discovery
23:18:18 DISPATCHER: Starting worker discovery
23:18:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:18:18 DISPATCHER: Finished worker discovery
23:19:18 DISPATCHER: Starting worker discovery
23:19:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:19:18 DISPATCHER: Finished worker discovery
23:20:18 DISPATCHER: Starting worker discovery
23:20:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:20:18 DISPATCHER: Finished worker discovery
23:21:18 DISPATCHER: Starting worker discovery
23:21:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:21:18 DISPATCHER: Finished worker discovery
23:22:18 DISPATCHER: Starting worker discovery
23:22:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:22:18 DISPATCHER: Finished worker discovery
23:23:18 DISPATCHER: Starting worker discovery
23:23:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:23:18 DISPATCHER: Finished worker discovery
23:23:58 WORKER: done with job (7, 0, 1), trying to register it.
23:23:58 WORKER: registered result for job (7, 0, 1) with dispatcher
23:23:58 DISPATCHER: job (7, 0, 1) finished
23:23:58 DISPATCHER: register_result: lock acquired
23:23:58 DISPATCHER: job (7, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
23:23:58 job_id: (7, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.04553375821685805, 'num_filters_1': 69, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.16873845034028123, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 18, 'num_filters_3': 21}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': 0.0016944235260691772, 'info': {'data04': -0.0016944235260691772, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.04553375821685805, 'num_filters_1': 69, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.16873845034028123, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 18, 'num_filters_3': 21}"}}
exception: None

23:23:58 job_callback for (7, 0, 1) started
23:23:58 job_callback for (7, 0, 1) got condition
23:23:58 DISPATCHER: Trying to submit another job.
23:23:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:23:58 Only 14 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
23:23:58 HBMASTER: Trying to run another job!
23:23:58 job_callback for (7, 0, 1) finished
23:23:58 start sampling a new configuration.
23:23:58 best_vector: [1, 0, 0.19988450889346482, 0.29030089225324346, 0.024440315745980018, 1, 0.3621190146119495, 0.16267929850442084, 2, 1, 2, 1, 0.12747431723317104, 0.8570963850146089, 0.812509926878972, 0.42039835657084484], 0.00017539256731114784, 0.021980240344777014, 3.85517078418651e-06
23:23:58 done sampling a new configuration.
23:23:58 HBMASTER: schedule new run for iteration 7
23:23:58 HBMASTER: trying submitting job (7, 0, 2) to dispatcher
23:23:58 HBMASTER: submitting job (7, 0, 2) to dispatcher
23:23:58 DISPATCHER: trying to submit job (7, 0, 2)
23:23:58 DISPATCHER: trying to notify the job_runner thread.
23:23:58 HBMASTER: job (7, 0, 2) submitted to dispatcher
23:23:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:23:58 DISPATCHER: Trying to submit another job.
23:23:58 DISPATCHER: starting job (7, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:23:58 DISPATCHER: job (7, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:23:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:23:58 WORKER: start processing job (7, 0, 2)
23:23:58 WORKER: args: ()
23:23:58 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.002510550824342833, 'num_filters_1': 29, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.016279859295636318}, 'budget': 1200.0, 'working_directory': '.'}
23:24:18 DISPATCHER: Starting worker discovery
23:24:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:24:18 DISPATCHER: Finished worker discovery
23:25:18 DISPATCHER: Starting worker discovery
23:25:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:25:18 DISPATCHER: Finished worker discovery
23:26:18 DISPATCHER: Starting worker discovery
23:26:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:26:18 DISPATCHER: Finished worker discovery
23:27:18 DISPATCHER: Starting worker discovery
23:27:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:27:18 DISPATCHER: Finished worker discovery
23:28:18 DISPATCHER: Starting worker discovery
23:28:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:28:18 DISPATCHER: Finished worker discovery
23:29:18 DISPATCHER: Starting worker discovery
23:29:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:29:18 DISPATCHER: Finished worker discovery
23:30:18 DISPATCHER: Starting worker discovery
23:30:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:30:18 DISPATCHER: Finished worker discovery
23:31:18 DISPATCHER: Starting worker discovery
23:31:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:31:18 DISPATCHER: Finished worker discovery
23:32:18 DISPATCHER: Starting worker discovery
23:32:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:32:18 DISPATCHER: Finished worker discovery
23:33:18 DISPATCHER: Starting worker discovery
23:33:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:33:18 DISPATCHER: Finished worker discovery
23:34:18 DISPATCHER: Starting worker discovery
23:34:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:34:18 DISPATCHER: Finished worker discovery
23:35:18 DISPATCHER: Starting worker discovery
23:35:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:35:18 DISPATCHER: Finished worker discovery
23:36:18 DISPATCHER: Starting worker discovery
23:36:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:36:18 DISPATCHER: Finished worker discovery
23:37:18 DISPATCHER: Starting worker discovery
23:37:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:37:18 DISPATCHER: Finished worker discovery
23:38:18 DISPATCHER: Starting worker discovery
23:38:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:38:18 DISPATCHER: Finished worker discovery
23:39:18 DISPATCHER: Starting worker discovery
23:39:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:39:18 DISPATCHER: Finished worker discovery
23:40:18 DISPATCHER: Starting worker discovery
23:40:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:40:18 DISPATCHER: Finished worker discovery
23:41:18 DISPATCHER: Starting worker discovery
23:41:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:41:18 DISPATCHER: Finished worker discovery
23:42:18 DISPATCHER: Starting worker discovery
23:42:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:42:18 DISPATCHER: Finished worker discovery
23:43:18 DISPATCHER: Starting worker discovery
23:43:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:43:18 DISPATCHER: Finished worker discovery
23:44:18 DISPATCHER: Starting worker discovery
23:44:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:44:18 DISPATCHER: Finished worker discovery
23:45:18 DISPATCHER: Starting worker discovery
23:45:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:45:19 DISPATCHER: Finished worker discovery
23:46:19 DISPATCHER: Starting worker discovery
23:46:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:46:19 DISPATCHER: Finished worker discovery
23:46:23 WORKER: done with job (7, 0, 2), trying to register it.
23:46:23 WORKER: registered result for job (7, 0, 2) with dispatcher
23:46:23 DISPATCHER: job (7, 0, 2) finished
23:46:23 DISPATCHER: register_result: lock acquired
23:46:23 DISPATCHER: job (7, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
23:46:23 job_id: (7, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.002510550824342833, 'num_filters_1': 29, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.016279859295636318}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.15825480917382656, 'info': {'data04': 0.15825480917382656, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.002510550824342833, 'num_filters_1': 29, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.016279859295636318}"}}
exception: None

23:46:23 job_callback for (7, 0, 2) started
23:46:23 job_callback for (7, 0, 2) got condition
23:46:23 DISPATCHER: Trying to submit another job.
23:46:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:46:23 Only 15 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
23:46:23 HBMASTER: Trying to run another job!
23:46:23 job_callback for (7, 0, 2) finished
23:46:23 start sampling a new configuration.
23:46:23 best_vector: [0, 1, 0.74880170684962, 0.06977929640153435, 0.047090019484957946, 1, 0.03954396621753464, 0.12985685462877983, 1, 1, 1, 2, 0.6690832904832362, 0.9225978139899931, 0.9899936225399049, 0.11878675649473669], 0.00028909383255774256, 0.0005059921908059742, 1.4627922168438763e-07
23:46:23 done sampling a new configuration.
23:46:23 HBMASTER: schedule new run for iteration 7
23:46:23 HBMASTER: trying submitting job (7, 0, 3) to dispatcher
23:46:23 HBMASTER: submitting job (7, 0, 3) to dispatcher
23:46:23 DISPATCHER: trying to submit job (7, 0, 3)
23:46:23 DISPATCHER: trying to notify the job_runner thread.
23:46:23 HBMASTER: job (7, 0, 3) submitted to dispatcher
23:46:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:46:23 DISPATCHER: Trying to submit another job.
23:46:23 DISPATCHER: starting job (7, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:46:23 DISPATCHER: job (7, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:46:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:46:23 WORKER: start processing job (7, 0, 3)
23:46:23 WORKER: args: ()
23:46:23 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.03144875185145952, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.01475528706062075}, 'budget': 1200.0, 'working_directory': '.'}
23:47:19 DISPATCHER: Starting worker discovery
23:47:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:47:19 DISPATCHER: Finished worker discovery
23:48:19 DISPATCHER: Starting worker discovery
23:48:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:48:19 DISPATCHER: Finished worker discovery
23:49:19 DISPATCHER: Starting worker discovery
23:49:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:49:19 DISPATCHER: Finished worker discovery
23:50:19 DISPATCHER: Starting worker discovery
23:50:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:50:19 DISPATCHER: Finished worker discovery
23:51:19 DISPATCHER: Starting worker discovery
23:51:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:51:19 DISPATCHER: Finished worker discovery
23:52:19 DISPATCHER: Starting worker discovery
23:52:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:52:19 DISPATCHER: Finished worker discovery
23:53:19 DISPATCHER: Starting worker discovery
23:53:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:53:19 DISPATCHER: Finished worker discovery
23:54:19 DISPATCHER: Starting worker discovery
23:54:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:54:19 DISPATCHER: Finished worker discovery
23:55:19 DISPATCHER: Starting worker discovery
23:55:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:55:19 DISPATCHER: Finished worker discovery
23:56:19 DISPATCHER: Starting worker discovery
23:56:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:56:19 DISPATCHER: Finished worker discovery
23:57:19 DISPATCHER: Starting worker discovery
23:57:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:57:19 DISPATCHER: Finished worker discovery
23:58:19 DISPATCHER: Starting worker discovery
23:58:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:58:19 DISPATCHER: Finished worker discovery
23:59:19 DISPATCHER: Starting worker discovery
23:59:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:59:19 DISPATCHER: Finished worker discovery
00:00:19 DISPATCHER: Starting worker discovery
00:00:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:00:19 DISPATCHER: Finished worker discovery
00:01:19 DISPATCHER: Starting worker discovery
00:01:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:01:19 DISPATCHER: Finished worker discovery
00:02:19 DISPATCHER: Starting worker discovery
00:02:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:02:19 DISPATCHER: Finished worker discovery
00:03:19 DISPATCHER: Starting worker discovery
00:03:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:03:19 DISPATCHER: Finished worker discovery
00:04:19 DISPATCHER: Starting worker discovery
00:04:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:04:19 DISPATCHER: Finished worker discovery
00:05:19 DISPATCHER: Starting worker discovery
00:05:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:05:19 DISPATCHER: Finished worker discovery
00:06:19 DISPATCHER: Starting worker discovery
00:06:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:06:19 DISPATCHER: Finished worker discovery
00:07:19 DISPATCHER: Starting worker discovery
00:07:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:07:19 DISPATCHER: Finished worker discovery
00:08:19 DISPATCHER: Starting worker discovery
00:08:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:08:19 DISPATCHER: Finished worker discovery
00:09:19 DISPATCHER: Starting worker discovery
00:09:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:09:20 DISPATCHER: Finished worker discovery
00:10:20 DISPATCHER: Starting worker discovery
00:10:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:10:20 DISPATCHER: Finished worker discovery
00:11:20 DISPATCHER: Starting worker discovery
00:11:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:11:20 DISPATCHER: Finished worker discovery
00:12:20 DISPATCHER: Starting worker discovery
00:12:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:12:20 DISPATCHER: Finished worker discovery
00:13:20 DISPATCHER: Starting worker discovery
00:13:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:13:20 DISPATCHER: Finished worker discovery
00:14:20 DISPATCHER: Starting worker discovery
00:14:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:14:20 DISPATCHER: Finished worker discovery
00:15:20 DISPATCHER: Starting worker discovery
00:15:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:15:21 DISPATCHER: Finished worker discovery
00:16:01 WORKER: done with job (7, 0, 3), trying to register it.
00:16:01 WORKER: registered result for job (7, 0, 3) with dispatcher
00:16:01 DISPATCHER: job (7, 0, 3) finished
00:16:01 DISPATCHER: register_result: lock acquired
00:16:01 DISPATCHER: job (7, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:16:01 job_id: (7, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.03144875185145952, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.01475528706062075}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.10506792057941738, 'info': {'data04': 0.10506792057941738, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.03144875185145952, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.01475528706062075}"}}
exception: None

00:16:01 job_callback for (7, 0, 3) started
00:16:01 job_callback for (7, 0, 3) got condition
00:16:01 DISPATCHER: Trying to submit another job.
00:16:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:16:01 Only 16 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
00:16:01 HBMASTER: Trying to run another job!
00:16:01 job_callback for (7, 0, 3) finished
00:16:01 start sampling a new configuration.
00:16:01 best_vector: [0, 2, 0.21639722375004483, 0.6810636186751124, 0.4837845512973173, 1, 0.42639428242825905, 0.12500892407286737, 0, 1, 1, 1, 0.8546933550883602, 0.8034182639027091, 0.43705006165042287, 0.5741010927345811], 0.000490735741003925, 0.09324191654547291, 4.5757141008568777e-05
00:16:01 done sampling a new configuration.
00:16:01 HBMASTER: schedule new run for iteration 8
00:16:01 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
00:16:01 HBMASTER: submitting job (8, 0, 0) to dispatcher
00:16:01 DISPATCHER: trying to submit job (8, 0, 0)
00:16:01 DISPATCHER: trying to notify the job_runner thread.
00:16:01 HBMASTER: job (8, 0, 0) submitted to dispatcher
00:16:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:16:01 DISPATCHER: Trying to submit another job.
00:16:01 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:16:01 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:16:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:16:01 WORKER: start processing job (8, 0, 0)
00:16:01 WORKER: args: ()
00:16:01 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.002708909195953881, 'num_filters_1': 65, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.01454254311157587, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 94, 'num_filters_3': 85}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:16:21 DISPATCHER: Starting worker discovery
00:16:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:16:21 DISPATCHER: Finished worker discovery
00:17:04 WORKER: done with job (8, 0, 0), trying to register it.
00:17:04 WORKER: registered result for job (8, 0, 0) with dispatcher
00:17:04 DISPATCHER: job (8, 0, 0) finished
00:17:04 DISPATCHER: register_result: lock acquired
00:17:04 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:17:04 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.002708909195953881, 'num_filters_1': 65, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.01454254311157587, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 94, 'num_filters_3': 85}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1884349788505379, 'info': {'data04': 0.1884349788505379, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.002708909195953881, 'num_filters_1': 65, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.01454254311157587, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 94, 'num_filters_3': 85}"}}
exception: None

00:17:04 job_callback for (8, 0, 0) started
00:17:04 job_callback for (8, 0, 0) got condition
00:17:04 DISPATCHER: Trying to submit another job.
00:17:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:17:04 HBMASTER: Trying to run another job!
00:17:04 job_callback for (8, 0, 0) finished
00:17:04 start sampling a new configuration.
00:17:04 best_vector: [3, 1, 0.4155372633365064, 0.840495468603726, 0.364836905751466, 1, 0.906387518855189, 0.1057044610583309, 0, 1, 1, 0, 0.9213513552763116, 0.8902970727555093, 0.2549709439504266, 0.9156078486177406], 0.002825651648189116, 0.000926201947852069, 2.6171240605041683e-06
00:17:04 done sampling a new configuration.
00:17:04 HBMASTER: schedule new run for iteration 8
00:17:04 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
00:17:04 HBMASTER: submitting job (8, 0, 1) to dispatcher
00:17:04 DISPATCHER: trying to submit job (8, 0, 1)
00:17:04 DISPATCHER: trying to notify the job_runner thread.
00:17:04 HBMASTER: job (8, 0, 1) submitted to dispatcher
00:17:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:17:04 DISPATCHER: Trying to submit another job.
00:17:04 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:17:04 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:17:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:17:04 WORKER: start processing job (8, 0, 1)
00:17:04 WORKER: args: ()
00:17:04 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006777578035863653, 'num_filters_1': 92, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.013725389398178515, 'kernel_size_2': 3, 'num_filters_2': 109}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:17:21 DISPATCHER: Starting worker discovery
00:17:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:17:21 DISPATCHER: Finished worker discovery
00:18:05 WORKER: done with job (8, 0, 1), trying to register it.
00:18:05 WORKER: registered result for job (8, 0, 1) with dispatcher
00:18:05 DISPATCHER: job (8, 0, 1) finished
00:18:05 DISPATCHER: register_result: lock acquired
00:18:05 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:18:05 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006777578035863653, 'num_filters_1': 92, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.013725389398178515, 'kernel_size_2': 3, 'num_filters_2': 109}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.206604432108604, 'info': {'data04': 0.206604432108604, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006777578035863653, 'num_filters_1': 92, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.013725389398178515, 'kernel_size_2': 3, 'num_filters_2': 109}"}}
exception: None

00:18:05 job_callback for (8, 0, 1) started
00:18:05 job_callback for (8, 0, 1) got condition
00:18:05 DISPATCHER: Trying to submit another job.
00:18:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:18:05 HBMASTER: Trying to run another job!
00:18:05 job_callback for (8, 0, 1) finished
00:18:05 start sampling a new configuration.
00:18:05 done sampling a new configuration.
00:18:05 HBMASTER: schedule new run for iteration 8
00:18:05 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
00:18:05 HBMASTER: submitting job (8, 0, 2) to dispatcher
00:18:05 DISPATCHER: trying to submit job (8, 0, 2)
00:18:05 DISPATCHER: trying to notify the job_runner thread.
00:18:05 HBMASTER: job (8, 0, 2) submitted to dispatcher
00:18:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:18:05 DISPATCHER: Trying to submit another job.
00:18:05 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:18:05 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:18:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:18:05 WORKER: start processing job (8, 0, 2)
00:18:05 WORKER: args: ()
00:18:05 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.010681326537247272, 'num_filters_1': 91, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.17926563298710274}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:18:21 DISPATCHER: Starting worker discovery
00:18:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:18:21 DISPATCHER: Finished worker discovery
00:19:06 WORKER: done with job (8, 0, 2), trying to register it.
00:19:06 WORKER: registered result for job (8, 0, 2) with dispatcher
00:19:06 DISPATCHER: job (8, 0, 2) finished
00:19:06 DISPATCHER: register_result: lock acquired
00:19:06 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:19:06 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.010681326537247272, 'num_filters_1': 91, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.17926563298710274}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0029089301285463, 'info': {'data04': 0.0029089301285463, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.010681326537247272, 'num_filters_1': 91, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.17926563298710274}"}}
exception: None

00:19:06 job_callback for (8, 0, 2) started
00:19:06 job_callback for (8, 0, 2) got condition
00:19:06 DISPATCHER: Trying to submit another job.
00:19:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:19:06 HBMASTER: Trying to run another job!
00:19:06 job_callback for (8, 0, 2) finished
00:19:06 start sampling a new configuration.
00:19:06 done sampling a new configuration.
00:19:06 HBMASTER: schedule new run for iteration 8
00:19:06 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
00:19:06 HBMASTER: submitting job (8, 0, 3) to dispatcher
00:19:06 DISPATCHER: trying to submit job (8, 0, 3)
00:19:06 DISPATCHER: trying to notify the job_runner thread.
00:19:06 HBMASTER: job (8, 0, 3) submitted to dispatcher
00:19:06 DISPATCHER: Trying to submit another job.
00:19:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:19:06 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:19:06 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:19:06 WORKER: start processing job (8, 0, 3)
00:19:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:19:06 WORKER: args: ()
00:19:06 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.03268543911937743, 'num_filters_1': 46, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.12127352285110911, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 72, 'num_filters_3': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:19:21 DISPATCHER: Starting worker discovery
00:19:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:19:21 DISPATCHER: Finished worker discovery
00:20:14 WORKER: done with job (8, 0, 3), trying to register it.
00:20:14 WORKER: registered result for job (8, 0, 3) with dispatcher
00:20:14 DISPATCHER: job (8, 0, 3) finished
00:20:14 DISPATCHER: register_result: lock acquired
00:20:14 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:20:14 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.03268543911937743, 'num_filters_1': 46, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.12127352285110911, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 72, 'num_filters_3': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.00018086115858397333, 'info': {'data04': 0.00018086115858397333, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.03268543911937743, 'num_filters_1': 46, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.12127352285110911, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 72, 'num_filters_3': 17}"}}
exception: None

00:20:14 job_callback for (8, 0, 3) started
00:20:14 job_callback for (8, 0, 3) got condition
00:20:14 DISPATCHER: Trying to submit another job.
00:20:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:20:14 HBMASTER: Trying to run another job!
00:20:14 job_callback for (8, 0, 3) finished
00:20:14 start sampling a new configuration.
00:20:15 best_vector: [3, 0, 0.3258332957114282, 0.18454072892558204, 0.2199049454318862, 1, 0.17802644573459492, 0.07407247994506864, 2, 1, 1, 2, 0.8394212848393166, 0.7118789037500718, 0.8049014247940789, 0.896686915884596], 0.00038562635238185625, 0.002474938454163061, 9.544014884484913e-07
00:20:15 done sampling a new configuration.
00:20:15 HBMASTER: schedule new run for iteration 8
00:20:15 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
00:20:15 HBMASTER: submitting job (8, 0, 4) to dispatcher
00:20:15 DISPATCHER: trying to submit job (8, 0, 4)
00:20:15 DISPATCHER: trying to notify the job_runner thread.
00:20:15 HBMASTER: job (8, 0, 4) submitted to dispatcher
00:20:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:20:15 DISPATCHER: Trying to submit another job.
00:20:15 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:20:15 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:20:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:20:15 WORKER: start processing job (8, 0, 4)
00:20:15 WORKER: args: ()
00:20:15 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.004484010195742439, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.01248448173363612, 'kernel_size_2': 7, 'num_filters_2': 91}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:20:21 DISPATCHER: Starting worker discovery
00:20:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:20:21 DISPATCHER: Finished worker discovery
00:21:21 DISPATCHER: Starting worker discovery
00:21:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:21:21 DISPATCHER: Finished worker discovery
00:21:22 WORKER: done with job (8, 0, 4), trying to register it.
00:21:22 WORKER: registered result for job (8, 0, 4) with dispatcher
00:21:22 DISPATCHER: job (8, 0, 4) finished
00:21:22 DISPATCHER: register_result: lock acquired
00:21:22 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:21:22 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.004484010195742439, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.01248448173363612, 'kernel_size_2': 7, 'num_filters_2': 91}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1796271476525857, 'info': {'data04': 0.1796271476525857, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.004484010195742439, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.01248448173363612, 'kernel_size_2': 7, 'num_filters_2': 91}"}}
exception: None

00:21:22 job_callback for (8, 0, 4) started
00:21:22 job_callback for (8, 0, 4) got condition
00:21:22 DISPATCHER: Trying to submit another job.
00:21:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:21:22 HBMASTER: Trying to run another job!
00:21:22 job_callback for (8, 0, 4) finished
00:21:22 start sampling a new configuration.
00:21:22 best_vector: [1, 1, 0.7488229443701103, 0.6382017201532308, 0.16280433567326874, 1, 0.15559813877039474, 0.10058863268693591, 1, 1, 0, 0, 0.46817967829995066, 0.7797537424771329, 0.7376674210219543, 0.8306504889771346], 0.00021808058700579532, 0.017847654741837353, 3.892227022776656e-06
00:21:22 done sampling a new configuration.
00:21:22 HBMASTER: schedule new run for iteration 8
00:21:22 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
00:21:22 HBMASTER: submitting job (8, 0, 5) to dispatcher
00:21:22 DISPATCHER: trying to submit job (8, 0, 5)
00:21:22 DISPATCHER: trying to notify the job_runner thread.
00:21:22 HBMASTER: job (8, 0, 5) submitted to dispatcher
00:21:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:21:22 DISPATCHER: Trying to submit another job.
00:21:22 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:21:22 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:21:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:21:22 WORKER: start processing job (8, 0, 5)
00:21:22 WORKER: args: ()
00:21:22 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.03145182776516108, 'num_filters_1': 60, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.013516642531242455}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:22:21 DISPATCHER: Starting worker discovery
00:22:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:22:21 DISPATCHER: Finished worker discovery
00:22:29 WORKER: done with job (8, 0, 5), trying to register it.
00:22:29 WORKER: registered result for job (8, 0, 5) with dispatcher
00:22:29 DISPATCHER: job (8, 0, 5) finished
00:22:29 DISPATCHER: register_result: lock acquired
00:22:29 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:22:29 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.03145182776516108, 'num_filters_1': 60, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.013516642531242455}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.14685003718157902, 'info': {'data04': 0.14685003718157902, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.03145182776516108, 'num_filters_1': 60, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.013516642531242455}"}}
exception: None

00:22:29 job_callback for (8, 0, 5) started
00:22:29 job_callback for (8, 0, 5) got condition
00:22:29 DISPATCHER: Trying to submit another job.
00:22:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:22:29 HBMASTER: Trying to run another job!
00:22:29 job_callback for (8, 0, 5) finished
00:22:29 start sampling a new configuration.
00:22:29 best_vector: [0, 1, 0.5661304888341232, 0.2533490701683586, 0.1712005370789493, 1, 0.8489116651474654, 0.24827139482102534, 2, 1, 1, 0, 0.12484767561965153, 0.9334688015408982, 0.7084426473425398, 0.2295792617657836], 0.00028093544978057, 0.03923542641951094, 1.1022622168497764e-05
00:22:29 done sampling a new configuration.
00:22:29 HBMASTER: schedule new run for iteration 8
00:22:29 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
00:22:29 HBMASTER: submitting job (8, 0, 6) to dispatcher
00:22:29 DISPATCHER: trying to submit job (8, 0, 6)
00:22:29 DISPATCHER: trying to notify the job_runner thread.
00:22:29 HBMASTER: job (8, 0, 6) submitted to dispatcher
00:22:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:22:29 DISPATCHER: Trying to submit another job.
00:22:29 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:22:29 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:22:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:22:29 WORKER: start processing job (8, 0, 6)
00:22:29 WORKER: args: ()
00:22:29 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.013560040219636886, 'num_filters_1': 26, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.02103819768959909}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:23:21 DISPATCHER: Starting worker discovery
00:23:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:23:21 DISPATCHER: Finished worker discovery
00:23:31 WORKER: done with job (8, 0, 6), trying to register it.
00:23:31 WORKER: registered result for job (8, 0, 6) with dispatcher
00:23:31 DISPATCHER: job (8, 0, 6) finished
00:23:31 DISPATCHER: register_result: lock acquired
00:23:31 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:23:31 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.013560040219636886, 'num_filters_1': 26, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.02103819768959909}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.15315231536491958, 'info': {'data04': 0.15315231536491958, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.013560040219636886, 'num_filters_1': 26, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.02103819768959909}"}}
exception: None

00:23:31 job_callback for (8, 0, 6) started
00:23:31 job_callback for (8, 0, 6) got condition
00:23:31 DISPATCHER: Trying to submit another job.
00:23:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:23:31 HBMASTER: Trying to run another job!
00:23:31 job_callback for (8, 0, 6) finished
00:23:31 start sampling a new configuration.
00:23:31 best_vector: [2, 0, 0.8558847026761597, 0.49972834601576716, 0.07526915385226145, 1, 0.2167654148223187, 0.11316266922790393, 1, 1, 2, 2, 0.8477608604669051, 0.6663994907955278, 0.9966539414739466, 0.5335383368957094], 0.00011007336804388228, 0.01312617316510799, 1.4448420898106629e-06
00:23:31 done sampling a new configuration.
00:23:31 HBMASTER: schedule new run for iteration 8
00:23:31 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
00:23:31 HBMASTER: submitting job (8, 0, 7) to dispatcher
00:23:31 DISPATCHER: trying to submit job (8, 0, 7)
00:23:31 DISPATCHER: trying to notify the job_runner thread.
00:23:31 HBMASTER: job (8, 0, 7) submitted to dispatcher
00:23:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:23:31 DISPATCHER: Trying to submit another job.
00:23:31 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:23:31 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:23:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:23:31 WORKER: start processing job (8, 0, 7)
00:23:31 WORKER: args: ()
00:23:31 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.05149551494380857, 'num_filters_1': 45, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.014035504476758918}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:24:21 DISPATCHER: Starting worker discovery
00:24:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:24:21 DISPATCHER: Finished worker discovery
00:24:40 WORKER: done with job (8, 0, 7), trying to register it.
00:24:40 WORKER: registered result for job (8, 0, 7) with dispatcher
00:24:40 DISPATCHER: job (8, 0, 7) finished
00:24:40 DISPATCHER: register_result: lock acquired
00:24:40 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:24:40 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.05149551494380857, 'num_filters_1': 45, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.014035504476758918}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.11015964366233516, 'info': {'data04': 0.11015964366233516, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.05149551494380857, 'num_filters_1': 45, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.014035504476758918}"}}
exception: None

00:24:40 job_callback for (8, 0, 7) started
00:24:40 job_callback for (8, 0, 7) got condition
00:24:40 DISPATCHER: Trying to submit another job.
00:24:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:24:40 HBMASTER: Trying to run another job!
00:24:40 job_callback for (8, 0, 7) finished
00:24:40 start sampling a new configuration.
00:24:40 best_vector: [3, 0, 0.05586121866748069, 0.2623815626149401, 0.017368005488709926, 1, 0.29385664669163497, 0.17287711641669437, 2, 1, 2, 0, 0.3243929535872777, 0.9463671326612737, 0.9376626556006178, 0.9348186677535095], 0.00029261352437798694, 0.0008864661523735716, 2.593919850878244e-07
00:24:40 done sampling a new configuration.
00:24:40 HBMASTER: schedule new run for iteration 8
00:24:40 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
00:24:40 HBMASTER: submitting job (8, 0, 8) to dispatcher
00:24:40 DISPATCHER: trying to submit job (8, 0, 8)
00:24:40 DISPATCHER: trying to notify the job_runner thread.
00:24:40 HBMASTER: job (8, 0, 8) submitted to dispatcher
00:24:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:24:40 DISPATCHER: Trying to submit another job.
00:24:40 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:24:40 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:24:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:24:40 WORKER: start processing job (8, 0, 8)
00:24:40 WORKER: args: ()
00:24:40 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0012933689700637212, 'num_filters_1': 27, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.016784882833899607}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:25:21 DISPATCHER: Starting worker discovery
00:25:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:25:21 DISPATCHER: Finished worker discovery
00:25:46 WORKER: done with job (8, 0, 8), trying to register it.
00:25:46 WORKER: registered result for job (8, 0, 8) with dispatcher
00:25:46 DISPATCHER: job (8, 0, 8) finished
00:25:46 DISPATCHER: register_result: lock acquired
00:25:46 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:25:46 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0012933689700637212, 'num_filters_1': 27, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.016784882833899607}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.12952789909469906, 'info': {'data04': 0.12952789909469906, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0012933689700637212, 'num_filters_1': 27, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.016784882833899607}"}}
exception: None

00:25:46 job_callback for (8, 0, 8) started
00:25:46 job_callback for (8, 0, 8) got condition
00:25:46 DISPATCHER: Trying to submit another job.
00:25:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:25:46 HBMASTER: Trying to run another job!
00:25:46 job_callback for (8, 0, 8) finished
00:25:46 start sampling a new configuration.
00:25:46 done sampling a new configuration.
00:25:46 HBMASTER: schedule new run for iteration 8
00:25:46 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
00:25:46 HBMASTER: submitting job (8, 0, 9) to dispatcher
00:25:46 DISPATCHER: trying to submit job (8, 0, 9)
00:25:46 DISPATCHER: trying to notify the job_runner thread.
00:25:46 HBMASTER: job (8, 0, 9) submitted to dispatcher
00:25:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:25:46 DISPATCHER: Trying to submit another job.
00:25:46 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:25:46 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:25:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:25:46 WORKER: start processing job (8, 0, 9)
00:25:46 WORKER: args: ()
00:25:46 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.016289400009231094, 'num_filters_1': 96, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.07564072909593957, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 20, 'num_filters_3': 78, 'num_filters_4': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:26:21 DISPATCHER: Starting worker discovery
00:26:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:26:21 DISPATCHER: Finished worker discovery
00:26:47 WORKER: done with job (8, 0, 9), trying to register it.
00:26:47 WORKER: registered result for job (8, 0, 9) with dispatcher
00:26:47 DISPATCHER: job (8, 0, 9) finished
00:26:47 DISPATCHER: register_result: lock acquired
00:26:47 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:26:47 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.016289400009231094, 'num_filters_1': 96, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.07564072909593957, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 20, 'num_filters_3': 78, 'num_filters_4': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0015880156900397917, 'info': {'data04': 0.0015880156900397917, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.016289400009231094, 'num_filters_1': 96, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.07564072909593957, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 20, 'num_filters_3': 78, 'num_filters_4': 19}"}}
exception: None

00:26:47 job_callback for (8, 0, 9) started
00:26:47 job_callback for (8, 0, 9) got condition
00:26:47 DISPATCHER: Trying to submit another job.
00:26:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:26:47 HBMASTER: Trying to run another job!
00:26:47 job_callback for (8, 0, 9) finished
00:26:47 start sampling a new configuration.
00:26:47 best_vector: [1, 1, 0.9347987626941263, 0.7975495650772162, 0.14578742151861607, 1, 0.08639016199748684, 0.0464943369480286, 2, 1, 1, 1, 0.9306055903673262, 0.649604974523151, 0.5151319655348124, 0.7673964367337363], 2.8114482403659698e-05, 0.006801615203666574, 1.9122389095994815e-07
00:26:47 done sampling a new configuration.
00:26:47 HBMASTER: schedule new run for iteration 8
00:26:47 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
00:26:47 HBMASTER: submitting job (8, 0, 10) to dispatcher
00:26:47 DISPATCHER: trying to submit job (8, 0, 10)
00:26:47 DISPATCHER: trying to notify the job_runner thread.
00:26:47 HBMASTER: job (8, 0, 10) submitted to dispatcher
00:26:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:26:47 DISPATCHER: Trying to submit another job.
00:26:47 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:26:47 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:26:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:26:47 WORKER: start processing job (8, 0, 10)
00:26:47 WORKER: args: ()
00:26:47 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.07406235635800157, 'num_filters_1': 84, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.01149451170865215}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:27:21 DISPATCHER: Starting worker discovery
00:27:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:27:21 DISPATCHER: Finished worker discovery
00:27:57 WORKER: done with job (8, 0, 10), trying to register it.
00:27:57 WORKER: registered result for job (8, 0, 10) with dispatcher
00:27:57 DISPATCHER: job (8, 0, 10) finished
00:27:57 DISPATCHER: register_result: lock acquired
00:27:57 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:27:57 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.07406235635800157, 'num_filters_1': 84, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.01149451170865215}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.15096096949524712, 'info': {'data04': 0.15096096949524712, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.07406235635800157, 'num_filters_1': 84, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.01149451170865215}"}}
exception: None

00:27:57 job_callback for (8, 0, 10) started
00:27:57 job_callback for (8, 0, 10) got condition
00:27:57 DISPATCHER: Trying to submit another job.
00:27:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:27:57 HBMASTER: Trying to run another job!
00:27:57 job_callback for (8, 0, 10) finished
00:27:57 start sampling a new configuration.
00:27:57 best_vector: [0, 1, 0.9746928412601409, 0.9545605594095796, 0.08470895580039378, 1, 0.10649114005476695, 0.20061204707797947, 2, 1, 0, 2, 0.8796326741910668, 0.615590897320479, 0.5911879044703068, 0.38892852386438553], 0.00039263904357505786, 0.004296510901681316, 1.6869779311459616e-06
00:27:57 done sampling a new configuration.
00:27:57 HBMASTER: schedule new run for iteration 8
00:27:57 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
00:27:57 HBMASTER: submitting job (8, 0, 11) to dispatcher
00:27:57 DISPATCHER: trying to submit job (8, 0, 11)
00:27:57 DISPATCHER: trying to notify the job_runner thread.
00:27:57 HBMASTER: job (8, 0, 11) submitted to dispatcher
00:27:57 DISPATCHER: Trying to submit another job.
00:27:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:27:57 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:27:57 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:27:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:27:57 WORKER: start processing job (8, 0, 11)
00:27:57 WORKER: args: ()
00:27:57 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.08899911386123409, 'num_filters_1': 117, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.018239053227086712}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:28:21 DISPATCHER: Starting worker discovery
00:28:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:28:21 DISPATCHER: Finished worker discovery
00:29:10 WORKER: done with job (8, 0, 11), trying to register it.
00:29:10 WORKER: registered result for job (8, 0, 11) with dispatcher
00:29:10 DISPATCHER: job (8, 0, 11) finished
00:29:10 DISPATCHER: register_result: lock acquired
00:29:10 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:29:10 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.08899911386123409, 'num_filters_1': 117, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.018239053227086712}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0808948146684898, 'info': {'data04': 0.0808948146684898, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.08899911386123409, 'num_filters_1': 117, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.018239053227086712}"}}
exception: None

00:29:10 job_callback for (8, 0, 11) started
00:29:10 DISPATCHER: Trying to submit another job.
00:29:10 job_callback for (8, 0, 11) got condition
00:29:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:29:10 HBMASTER: Trying to run another job!
00:29:10 job_callback for (8, 0, 11) finished
00:29:10 start sampling a new configuration.
00:29:10 done sampling a new configuration.
00:29:10 HBMASTER: schedule new run for iteration 8
00:29:10 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
00:29:10 HBMASTER: submitting job (8, 0, 12) to dispatcher
00:29:10 DISPATCHER: trying to submit job (8, 0, 12)
00:29:10 DISPATCHER: trying to notify the job_runner thread.
00:29:10 HBMASTER: job (8, 0, 12) submitted to dispatcher
00:29:10 DISPATCHER: Trying to submit another job.
00:29:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:29:10 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:29:10 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:29:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:29:10 WORKER: start processing job (8, 0, 12)
00:29:10 WORKER: args: ()
00:29:10 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.007644185395190524, 'num_filters_1': 38, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.03501389204956257}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:29:21 DISPATCHER: Starting worker discovery
00:29:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:29:21 DISPATCHER: Finished worker discovery
00:30:21 DISPATCHER: Starting worker discovery
00:30:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:30:21 DISPATCHER: Finished worker discovery
00:30:28 WORKER: done with job (8, 0, 12), trying to register it.
00:30:28 WORKER: registered result for job (8, 0, 12) with dispatcher
00:30:28 DISPATCHER: job (8, 0, 12) finished
00:30:28 DISPATCHER: register_result: lock acquired
00:30:28 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:30:28 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.007644185395190524, 'num_filters_1': 38, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.03501389204956257}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.09954704775830603, 'info': {'data04': 0.09954704775830603, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.007644185395190524, 'num_filters_1': 38, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.03501389204956257}"}}
exception: None

00:30:28 job_callback for (8, 0, 12) started
00:30:28 job_callback for (8, 0, 12) got condition
00:30:28 DISPATCHER: Trying to submit another job.
00:30:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:30:28 HBMASTER: Trying to run another job!
00:30:28 job_callback for (8, 0, 12) finished
00:30:28 start sampling a new configuration.
00:30:28 done sampling a new configuration.
00:30:28 HBMASTER: schedule new run for iteration 8
00:30:28 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
00:30:28 HBMASTER: submitting job (8, 0, 13) to dispatcher
00:30:28 DISPATCHER: trying to submit job (8, 0, 13)
00:30:28 DISPATCHER: trying to notify the job_runner thread.
00:30:28 HBMASTER: job (8, 0, 13) submitted to dispatcher
00:30:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:30:28 DISPATCHER: Trying to submit another job.
00:30:28 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:30:28 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:30:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:30:28 WORKER: start processing job (8, 0, 13)
00:30:28 WORKER: args: ()
00:30:28 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.020035934584957, 'num_filters_1': 99, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.1172750318588675, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 21, 'num_filters_3': 89, 'num_filters_4': 44, 'num_filters_5': 77}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:31:21 DISPATCHER: Starting worker discovery
00:31:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:31:21 DISPATCHER: Finished worker discovery
00:31:36 WORKER: done with job (8, 0, 13), trying to register it.
00:31:36 WORKER: registered result for job (8, 0, 13) with dispatcher
00:31:36 DISPATCHER: job (8, 0, 13) finished
00:31:36 DISPATCHER: register_result: lock acquired
00:31:36 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:31:36 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.020035934584957, 'num_filters_1': 99, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.1172750318588675, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 21, 'num_filters_3': 89, 'num_filters_4': 44, 'num_filters_5': 77}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.00016121471716104097, 'info': {'data04': 0.00016121471716104097, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.020035934584957, 'num_filters_1': 99, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.1172750318588675, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 21, 'num_filters_3': 89, 'num_filters_4': 44, 'num_filters_5': 77}"}}
exception: None

00:31:36 job_callback for (8, 0, 13) started
00:31:36 DISPATCHER: Trying to submit another job.
00:31:36 job_callback for (8, 0, 13) got condition
00:31:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:31:36 HBMASTER: Trying to run another job!
00:31:36 job_callback for (8, 0, 13) finished
00:31:36 start sampling a new configuration.
00:31:36 best_vector: [0, 1, 0.0467838886778336, 0.8511161817045781, 0.086338667842504, 1, 0.5226139429835754, 0.09740665721576984, 1, 1, 2, 1, 0.9567058973468077, 0.9916356164125161, 0.007788031383034855, 0.9866561274742711], 0.00010167972201417551, 0.000661113981586136, 6.722188586736306e-08
00:31:36 done sampling a new configuration.
00:31:36 HBMASTER: schedule new run for iteration 8
00:31:36 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
00:31:36 HBMASTER: submitting job (8, 0, 14) to dispatcher
00:31:36 DISPATCHER: trying to submit job (8, 0, 14)
00:31:36 DISPATCHER: trying to notify the job_runner thread.
00:31:36 HBMASTER: job (8, 0, 14) submitted to dispatcher
00:31:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:31:36 DISPATCHER: Trying to submit another job.
00:31:36 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:31:36 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:31:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:31:36 WORKER: start processing job (8, 0, 14)
00:31:36 WORKER: args: ()
00:31:36 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0012404171934022811, 'num_filters_1': 94, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.013388409362100916}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:32:21 DISPATCHER: Starting worker discovery
00:32:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:32:21 DISPATCHER: Finished worker discovery
00:32:40 WORKER: done with job (8, 0, 14), trying to register it.
00:32:40 WORKER: registered result for job (8, 0, 14) with dispatcher
00:32:40 DISPATCHER: job (8, 0, 14) finished
00:32:40 DISPATCHER: register_result: lock acquired
00:32:40 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:32:40 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0012404171934022811, 'num_filters_1': 94, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.013388409362100916}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1812659444900932, 'info': {'data04': 0.1812659444900932, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0012404171934022811, 'num_filters_1': 94, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.013388409362100916}"}}
exception: None

00:32:40 job_callback for (8, 0, 14) started
00:32:40 job_callback for (8, 0, 14) got condition
00:32:40 DISPATCHER: Trying to submit another job.
00:32:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:32:40 HBMASTER: Trying to run another job!
00:32:40 job_callback for (8, 0, 14) finished
00:32:40 start sampling a new configuration.
00:32:40 best_vector: [1, 1, 0.08024083418536666, 0.7023724108181812, 0.20543717478177936, 1, 0.0039950985632576826, 0.30024917807270823, 2, 0, 1, 1, 0.8154554210046574, 0.09592642961305076, 0.6523307162163317, 0.33867832764245354], 0.0, inf, 7.832923555056469e-06
00:32:40 done sampling a new configuration.
00:32:40 HBMASTER: schedule new run for iteration 8
00:32:40 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
00:32:40 HBMASTER: submitting job (8, 0, 15) to dispatcher
00:32:40 DISPATCHER: trying to submit job (8, 0, 15)
00:32:40 DISPATCHER: trying to notify the job_runner thread.
00:32:40 HBMASTER: job (8, 0, 15) submitted to dispatcher
00:32:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:32:40 DISPATCHER: Trying to submit another job.
00:32:40 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:32:40 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:32:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:32:40 WORKER: start processing job (8, 0, 15)
00:32:40 WORKER: args: ()
00:32:40 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0014470437718909998, 'num_filters_1': 68, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.024582904094938737, 'kernel_size_2': 7, 'num_filters_2': 87}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:33:21 DISPATCHER: Starting worker discovery
00:33:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:33:21 DISPATCHER: Finished worker discovery
00:33:56 WORKER: done with job (8, 0, 15), trying to register it.
00:33:56 WORKER: registered result for job (8, 0, 15) with dispatcher
00:33:56 DISPATCHER: job (8, 0, 15) finished
00:33:56 DISPATCHER: register_result: lock acquired
00:33:56 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:33:56 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0014470437718909998, 'num_filters_1': 68, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.024582904094938737, 'kernel_size_2': 7, 'num_filters_2': 87}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0861819737077275, 'info': {'data04': 0.0861819737077275, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0014470437718909998, 'num_filters_1': 68, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.024582904094938737, 'kernel_size_2': 7, 'num_filters_2': 87}"}}
exception: None

00:33:56 job_callback for (8, 0, 15) started
00:33:56 DISPATCHER: Trying to submit another job.
00:33:56 job_callback for (8, 0, 15) got condition
00:33:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:33:56 HBMASTER: Trying to run another job!
00:33:56 job_callback for (8, 0, 15) finished
00:33:56 start sampling a new configuration.
00:33:56 best_vector: [1, 1, 0.5834593644627931, 0.7450284710285588, 0.21773639844176085, 1, 0.5241319951414919, 0.22067343724016253, 1, 1, 2, 1, 0.8904280554451468, 0.9920833644063173, 0.5891394523417883, 0.7453946047396341], 0.00013758708614259083, 0.054260917860534726, 7.4656015798534366e-06
00:33:56 done sampling a new configuration.
00:33:56 HBMASTER: schedule new run for iteration 8
00:33:56 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
00:33:56 HBMASTER: submitting job (8, 0, 16) to dispatcher
00:33:56 DISPATCHER: trying to submit job (8, 0, 16)
00:33:56 DISPATCHER: trying to notify the job_runner thread.
00:33:56 HBMASTER: job (8, 0, 16) submitted to dispatcher
00:33:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:33:56 DISPATCHER: Trying to submit another job.
00:33:56 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:33:56 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:33:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:33:56 WORKER: start processing job (8, 0, 16)
00:33:56 WORKER: args: ()
00:33:56 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.014686514179521765, 'num_filters_1': 75, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.01936880206901419, 'kernel_size_2': 5, 'num_filters_2': 102}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:34:21 DISPATCHER: Starting worker discovery
00:34:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:34:21 DISPATCHER: Finished worker discovery
00:34:58 WORKER: done with job (8, 0, 16), trying to register it.
00:34:58 WORKER: registered result for job (8, 0, 16) with dispatcher
00:34:58 DISPATCHER: job (8, 0, 16) finished
00:34:58 DISPATCHER: register_result: lock acquired
00:34:58 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:34:58 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.014686514179521765, 'num_filters_1': 75, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.01936880206901419, 'kernel_size_2': 5, 'num_filters_2': 102}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1709187989258318, 'info': {'data04': 0.1709187989258318, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.014686514179521765, 'num_filters_1': 75, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.01936880206901419, 'kernel_size_2': 5, 'num_filters_2': 102}"}}
exception: None

00:34:58 job_callback for (8, 0, 16) started
00:34:58 job_callback for (8, 0, 16) got condition
00:34:58 DISPATCHER: Trying to submit another job.
00:34:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:34:58 HBMASTER: Trying to run another job!
00:34:58 job_callback for (8, 0, 16) finished
00:34:58 start sampling a new configuration.
00:34:58 best_vector: [0, 2, 0.6546413399197906, 0.3356837464190294, 0.027771260210963156, 1, 0.02392905213169927, 0.09041630704054052, 2, 1, 1, 1, 0.5685800598831705, 0.08786382373728052, 0.09980213534630009, 0.9033923387301275], 0.0001228787165460239, 0.010447713592448437, 1.2838016370805124e-06
00:34:58 done sampling a new configuration.
00:34:58 HBMASTER: schedule new run for iteration 8
00:34:58 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
00:34:58 HBMASTER: submitting job (8, 0, 17) to dispatcher
00:34:58 DISPATCHER: trying to submit job (8, 0, 17)
00:34:58 DISPATCHER: trying to notify the job_runner thread.
00:34:58 HBMASTER: job (8, 0, 17) submitted to dispatcher
00:34:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:34:58 DISPATCHER: Trying to submit another job.
00:34:58 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:34:58 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:34:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:34:58 WORKER: start processing job (8, 0, 17)
00:34:58 WORKER: args: ()
00:34:58 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.02038368408559341, 'num_filters_1': 32, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.013110955023233431}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:35:21 DISPATCHER: Starting worker discovery
00:35:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:35:21 DISPATCHER: Finished worker discovery
00:36:20 WORKER: done with job (8, 0, 17), trying to register it.
00:36:20 WORKER: registered result for job (8, 0, 17) with dispatcher
00:36:20 DISPATCHER: job (8, 0, 17) finished
00:36:20 DISPATCHER: register_result: lock acquired
00:36:20 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:36:20 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.02038368408559341, 'num_filters_1': 32, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.013110955023233431}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.15736448928852398, 'info': {'data04': 0.15736448928852398, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.02038368408559341, 'num_filters_1': 32, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.013110955023233431}"}}
exception: None

00:36:20 job_callback for (8, 0, 17) started
00:36:20 job_callback for (8, 0, 17) got condition
00:36:20 DISPATCHER: Trying to submit another job.
00:36:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:36:20 HBMASTER: Trying to run another job!
00:36:20 job_callback for (8, 0, 17) finished
00:36:20 start sampling a new configuration.
00:36:20 done sampling a new configuration.
00:36:20 HBMASTER: schedule new run for iteration 8
00:36:20 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
00:36:20 HBMASTER: submitting job (8, 0, 18) to dispatcher
00:36:20 DISPATCHER: trying to submit job (8, 0, 18)
00:36:20 DISPATCHER: trying to notify the job_runner thread.
00:36:20 HBMASTER: job (8, 0, 18) submitted to dispatcher
00:36:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:36:20 DISPATCHER: Trying to submit another job.
00:36:20 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:36:20 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:36:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:36:20 WORKER: start processing job (8, 0, 18)
00:36:20 WORKER: args: ()
00:36:20 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0029235155097463864, 'num_filters_1': 48, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.01784728849288031, 'kernel_size_2': 7, 'num_filters_2': 28}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:36:21 DISPATCHER: Starting worker discovery
00:36:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:36:21 DISPATCHER: Finished worker discovery
00:37:21 WORKER: done with job (8, 0, 18), trying to register it.
00:37:21 WORKER: registered result for job (8, 0, 18) with dispatcher
00:37:21 DISPATCHER: job (8, 0, 18) finished
00:37:21 DISPATCHER: register_result: lock acquired
00:37:21 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:37:21 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0029235155097463864, 'num_filters_1': 48, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.01784728849288031, 'kernel_size_2': 7, 'num_filters_2': 28}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1601977571189169, 'info': {'data04': 0.1601977571189169, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0029235155097463864, 'num_filters_1': 48, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.01784728849288031, 'kernel_size_2': 7, 'num_filters_2': 28}"}}
exception: None

00:37:21 job_callback for (8, 0, 18) started
00:37:21 DISPATCHER: Trying to submit another job.
00:37:21 job_callback for (8, 0, 18) got condition
00:37:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:37:21 HBMASTER: Trying to run another job!
00:37:21 job_callback for (8, 0, 18) finished
00:37:21 start sampling a new configuration.
00:37:21 best_vector: [1, 0, 0.26354596325072016, 0.8834723274769025, 0.9870159139131521, 0, 0.6910709285247367, 0.381933726364449, 2, 1, 2, 2, 0.9003384217173948, 0.13510863129171857, 0.5666990349326493, 0.7114202349558276], 0.0, inf, 3.902838260251999e-05
00:37:21 done sampling a new configuration.
00:37:21 HBMASTER: schedule new run for iteration 8
00:37:21 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
00:37:21 HBMASTER: submitting job (8, 0, 19) to dispatcher
00:37:21 DISPATCHER: trying to submit job (8, 0, 19)
00:37:21 DISPATCHER: trying to notify the job_runner thread.
00:37:21 HBMASTER: job (8, 0, 19) submitted to dispatcher
00:37:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:37:21 DISPATCHER: Trying to submit another job.
00:37:21 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:37:21 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:37:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:37:21 WORKER: start processing job (8, 0, 19)
00:37:21 WORKER: args: ()
00:37:21 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0033658280584452343, 'num_filters_1': 100, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.03139837950378553, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 104, 'num_filters_3': 21, 'num_filters_4': 51, 'num_filters_5': 70}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:37:21 DISPATCHER: Starting worker discovery
00:37:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:37:21 DISPATCHER: Finished worker discovery
00:38:21 DISPATCHER: Starting worker discovery
00:38:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:38:22 DISPATCHER: Finished worker discovery
00:38:22 WORKER: done with job (8, 0, 19), trying to register it.
00:38:22 WORKER: registered result for job (8, 0, 19) with dispatcher
00:38:22 DISPATCHER: job (8, 0, 19) finished
00:38:22 DISPATCHER: register_result: lock acquired
00:38:22 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:38:22 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0033658280584452343, 'num_filters_1': 100, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.03139837950378553, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 104, 'num_filters_3': 21, 'num_filters_4': 51, 'num_filters_5': 70}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.03033471504197105, 'info': {'data04': 0.03033471504197105, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0033658280584452343, 'num_filters_1': 100, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.03139837950378553, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 104, 'num_filters_3': 21, 'num_filters_4': 51, 'num_filters_5': 70}"}}
exception: None

00:38:22 job_callback for (8, 0, 19) started
00:38:22 job_callback for (8, 0, 19) got condition
00:38:22 DISPATCHER: Trying to submit another job.
00:38:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:38:22 HBMASTER: Trying to run another job!
00:38:22 job_callback for (8, 0, 19) finished
00:38:22 start sampling a new configuration.
00:38:22 best_vector: [1, 0, 0.33966718440059374, 0.2512041867434773, 0.2941125576738832, 1, 0.3995760844793241, 0.07166148301896305, 2, 1, 2, 1, 0.7799598941412718, 0.9230377888734725, 0.8938778356720096, 0.47257672138352347], 0.0009395498929321636, 0.03752766894006625, 3.5259117334632925e-05
00:38:22 done sampling a new configuration.
00:38:22 HBMASTER: schedule new run for iteration 8
00:38:22 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
00:38:22 HBMASTER: submitting job (8, 0, 20) to dispatcher
00:38:22 DISPATCHER: trying to submit job (8, 0, 20)
00:38:22 DISPATCHER: trying to notify the job_runner thread.
00:38:22 HBMASTER: job (8, 0, 20) submitted to dispatcher
00:38:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:38:22 DISPATCHER: Trying to submit another job.
00:38:22 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:38:22 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:38:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:38:22 WORKER: start processing job (8, 0, 20)
00:38:22 WORKER: args: ()
00:38:22 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.00477897071038305, 'num_filters_1': 26, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.012394634910125619, 'kernel_size_2': 7, 'num_filters_2': 81}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:39:22 DISPATCHER: Starting worker discovery
00:39:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:39:22 DISPATCHER: Finished worker discovery
00:39:25 WORKER: done with job (8, 0, 20), trying to register it.
00:39:25 WORKER: registered result for job (8, 0, 20) with dispatcher
00:39:25 DISPATCHER: job (8, 0, 20) finished
00:39:25 DISPATCHER: register_result: lock acquired
00:39:25 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:39:25 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.00477897071038305, 'num_filters_1': 26, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.012394634910125619, 'kernel_size_2': 7, 'num_filters_2': 81}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.14851080070535333, 'info': {'data04': 0.14851080070535333, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.00477897071038305, 'num_filters_1': 26, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.012394634910125619, 'kernel_size_2': 7, 'num_filters_2': 81}"}}
exception: None

00:39:25 job_callback for (8, 0, 20) started
00:39:25 DISPATCHER: Trying to submit another job.
00:39:25 job_callback for (8, 0, 20) got condition
00:39:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:39:25 HBMASTER: Trying to run another job!
00:39:25 job_callback for (8, 0, 20) finished
00:39:25 start sampling a new configuration.
00:39:25 best_vector: [0, 1, 0.1366161548533918, 0.5965935048028499, 0.04841492868744642, 1, 0.3142867768030275, 0.03558506362124879, 0, 1, 1, 1, 0.8401266580502998, 0.4041106228893987, 0.09541100849858086, 0.2646693812156378], 0.0001277639093546349, 0.04382248793130324, 5.598932375749609e-06
00:39:25 done sampling a new configuration.
00:39:25 HBMASTER: schedule new run for iteration 8
00:39:25 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
00:39:25 HBMASTER: submitting job (8, 0, 21) to dispatcher
00:39:25 DISPATCHER: trying to submit job (8, 0, 21)
00:39:25 DISPATCHER: trying to notify the job_runner thread.
00:39:25 HBMASTER: job (8, 0, 21) submitted to dispatcher
00:39:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:39:25 DISPATCHER: Trying to submit another job.
00:39:25 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:39:25 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:39:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:39:25 WORKER: start processing job (8, 0, 21)
00:39:25 WORKER: args: ()
00:39:25 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001875997735052425, 'num_filters_1': 55, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.01112492867216199}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:40:22 DISPATCHER: Starting worker discovery
00:40:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:40:22 DISPATCHER: Finished worker discovery
00:40:31 WORKER: done with job (8, 0, 21), trying to register it.
00:40:31 WORKER: registered result for job (8, 0, 21) with dispatcher
00:40:31 DISPATCHER: job (8, 0, 21) finished
00:40:31 DISPATCHER: register_result: lock acquired
00:40:31 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:40:31 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001875997735052425, 'num_filters_1': 55, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.01112492867216199}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1799348893680822, 'info': {'data04': 0.1799348893680822, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001875997735052425, 'num_filters_1': 55, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.01112492867216199}"}}
exception: None

00:40:31 job_callback for (8, 0, 21) started
00:40:31 DISPATCHER: Trying to submit another job.
00:40:31 job_callback for (8, 0, 21) got condition
00:40:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:40:31 HBMASTER: Trying to run another job!
00:40:31 job_callback for (8, 0, 21) finished
00:40:31 start sampling a new configuration.
00:40:31 done sampling a new configuration.
00:40:31 HBMASTER: schedule new run for iteration 8
00:40:31 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
00:40:31 HBMASTER: submitting job (8, 0, 22) to dispatcher
00:40:31 DISPATCHER: trying to submit job (8, 0, 22)
00:40:31 DISPATCHER: trying to notify the job_runner thread.
00:40:31 HBMASTER: job (8, 0, 22) submitted to dispatcher
00:40:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:40:31 DISPATCHER: Trying to submit another job.
00:40:31 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:40:31 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:40:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:40:31 WORKER: start processing job (8, 0, 22)
00:40:31 WORKER: args: ()
00:40:31 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.03933058112670273, 'num_filters_1': 29, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.01698926673299179, 'kernel_size_2': 7, 'num_filters_2': 38}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:41:22 DISPATCHER: Starting worker discovery
00:41:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:41:22 DISPATCHER: Finished worker discovery
00:41:39 WORKER: done with job (8, 0, 22), trying to register it.
00:41:39 WORKER: registered result for job (8, 0, 22) with dispatcher
00:41:39 DISPATCHER: job (8, 0, 22) finished
00:41:39 DISPATCHER: register_result: lock acquired
00:41:39 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:41:39 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.03933058112670273, 'num_filters_1': 29, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.01698926673299179, 'kernel_size_2': 7, 'num_filters_2': 38}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.11374547987989256, 'info': {'data04': 0.11374547987989256, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.03933058112670273, 'num_filters_1': 29, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.01698926673299179, 'kernel_size_2': 7, 'num_filters_2': 38}"}}
exception: None

00:41:39 job_callback for (8, 0, 22) started
00:41:39 DISPATCHER: Trying to submit another job.
00:41:39 job_callback for (8, 0, 22) got condition
00:41:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:41:39 HBMASTER: Trying to run another job!
00:41:39 job_callback for (8, 0, 22) finished
00:41:39 start sampling a new configuration.
00:41:40 best_vector: [1, 0, 0.62234757872961, 0.637126009019116, 0.013493399219317248, 1, 0.7658079776169375, 0.31697824700029126, 1, 1, 1, 2, 0.9884354825629171, 0.9111674308357487, 0.8150986660030508, 0.5723403478317373], 0.00014010163988438306, 0.04818608854829294, 6.750950025229933e-06
00:41:40 done sampling a new configuration.
00:41:40 HBMASTER: schedule new run for iteration 8
00:41:40 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
00:41:40 HBMASTER: submitting job (8, 0, 23) to dispatcher
00:41:40 DISPATCHER: trying to submit job (8, 0, 23)
00:41:40 DISPATCHER: trying to notify the job_runner thread.
00:41:40 HBMASTER: job (8, 0, 23) submitted to dispatcher
00:41:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:41:40 DISPATCHER: Trying to submit another job.
00:41:40 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:41:40 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:41:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:41:40 WORKER: start processing job (8, 0, 23)
00:41:40 WORKER: args: ()
00:41:40 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.01756690114824354, 'num_filters_1': 60, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.025846289669230863}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:42:22 DISPATCHER: Starting worker discovery
00:42:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:42:22 DISPATCHER: Finished worker discovery
00:42:42 WORKER: done with job (8, 0, 23), trying to register it.
00:42:42 WORKER: registered result for job (8, 0, 23) with dispatcher
00:42:42 DISPATCHER: job (8, 0, 23) finished
00:42:42 DISPATCHER: register_result: lock acquired
00:42:42 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:42:42 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.01756690114824354, 'num_filters_1': 60, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.025846289669230863}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.14056236804950636, 'info': {'data04': 0.14056236804950636, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.01756690114824354, 'num_filters_1': 60, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.025846289669230863}"}}
exception: None

00:42:42 job_callback for (8, 0, 23) started
00:42:42 DISPATCHER: Trying to submit another job.
00:42:42 job_callback for (8, 0, 23) got condition
00:42:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:42:42 HBMASTER: Trying to run another job!
00:42:42 job_callback for (8, 0, 23) finished
00:42:42 start sampling a new configuration.
00:42:42 best_vector: [0, 2, 0.08060924900165412, 0.6897537600062705, 0.1610368514239619, 1, 0.21538662992428015, 0.015610084937448282, 1, 1, 2, 2, 0.870557965676913, 0.5477676561334848, 0.16336757456600925, 0.9126011210693051], 3.6747165202894075e-05, 0.009624446333825415, 3.5367111941547077e-07
00:42:42 done sampling a new configuration.
00:42:42 HBMASTER: schedule new run for iteration 8
00:42:42 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
00:42:42 HBMASTER: submitting job (8, 0, 24) to dispatcher
00:42:42 DISPATCHER: trying to submit job (8, 0, 24)
00:42:42 DISPATCHER: trying to notify the job_runner thread.
00:42:42 HBMASTER: job (8, 0, 24) submitted to dispatcher
00:42:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:42:42 DISPATCHER: Trying to submit another job.
00:42:42 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:42:42 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:42:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:42:42 WORKER: start processing job (8, 0, 24)
00:42:42 WORKER: args: ()
00:42:42 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0014495009288945943, 'num_filters_1': 67, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.01047874299248654}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:43:22 DISPATCHER: Starting worker discovery
00:43:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:43:22 DISPATCHER: Finished worker discovery
00:43:50 WORKER: done with job (8, 0, 24), trying to register it.
00:43:50 WORKER: registered result for job (8, 0, 24) with dispatcher
00:43:50 DISPATCHER: job (8, 0, 24) finished
00:43:50 DISPATCHER: register_result: lock acquired
00:43:50 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:43:50 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0014495009288945943, 'num_filters_1': 67, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.01047874299248654}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.18639016796652164, 'info': {'data04': 0.18639016796652164, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0014495009288945943, 'num_filters_1': 67, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.01047874299248654}"}}
exception: None

00:43:50 job_callback for (8, 0, 24) started
00:43:50 job_callback for (8, 0, 24) got condition
00:43:50 DISPATCHER: Trying to submit another job.
00:43:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:43:50 HBMASTER: Trying to run another job!
00:43:50 job_callback for (8, 0, 24) finished
00:43:50 start sampling a new configuration.
00:43:50 best_vector: [1, 1, 0.7061498811176459, 0.8754027004894569, 0.04998370458451788, 1, 0.7106098403454919, 0.12713351206801948, 0, 1, 2, 1, 0.9410682709600716, 0.8778668711340835, 0.5004044038448494, 0.8999500237438314], 2.420538440484004e-05, 0.014136376229119748, 3.421764207172866e-07
00:43:50 done sampling a new configuration.
00:43:50 HBMASTER: schedule new run for iteration 8
00:43:50 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
00:43:50 HBMASTER: submitting job (8, 0, 25) to dispatcher
00:43:50 DISPATCHER: trying to submit job (8, 0, 25)
00:43:50 DISPATCHER: trying to notify the job_runner thread.
00:43:50 HBMASTER: job (8, 0, 25) submitted to dispatcher
00:43:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:43:50 DISPATCHER: Trying to submit another job.
00:43:50 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:43:50 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:43:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:43:50 WORKER: start processing job (8, 0, 25)
00:43:50 WORKER: args: ()
00:43:50 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.025840431543169902, 'num_filters_1': 99, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.014635397170057645}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:44:22 DISPATCHER: Starting worker discovery
00:44:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:44:22 DISPATCHER: Finished worker discovery
00:44:52 WORKER: done with job (8, 0, 25), trying to register it.
00:44:52 WORKER: registered result for job (8, 0, 25) with dispatcher
00:44:52 DISPATCHER: job (8, 0, 25) finished
00:44:52 DISPATCHER: register_result: lock acquired
00:44:52 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:44:52 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.025840431543169902, 'num_filters_1': 99, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.014635397170057645}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1804017653904346, 'info': {'data04': 0.1804017653904346, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.025840431543169902, 'num_filters_1': 99, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.014635397170057645}"}}
exception: None

00:44:52 job_callback for (8, 0, 25) started
00:44:52 job_callback for (8, 0, 25) got condition
00:44:52 DISPATCHER: Trying to submit another job.
00:44:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:44:52 HBMASTER: Trying to run another job!
00:44:52 job_callback for (8, 0, 25) finished
00:44:52 start sampling a new configuration.
00:44:52 best_vector: [1, 0, 0.08624395136974072, 0.3594216102106408, 0.20035021879830933, 1, 0.5372195112089908, 0.014879745402252509, 1, 1, 1, 2, 0.9574546542101798, 0.6642167555080389, 0.40338035339768524, 0.7818455515816394], 0.0004698010797550704, 0.015152340291216104, 7.118585829629583e-06
00:44:52 done sampling a new configuration.
00:44:52 HBMASTER: schedule new run for iteration 8
00:44:52 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
00:44:52 HBMASTER: submitting job (8, 0, 26) to dispatcher
00:44:52 DISPATCHER: trying to submit job (8, 0, 26)
00:44:52 DISPATCHER: trying to notify the job_runner thread.
00:44:52 HBMASTER: job (8, 0, 26) submitted to dispatcher
00:44:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:44:52 DISPATCHER: Trying to submit another job.
00:44:52 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:44:52 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:44:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:44:52 WORKER: start processing job (8, 0, 26)
00:44:52 WORKER: args: ()
00:44:52 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001487605936281071, 'num_filters_1': 33, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.010455841594848445, 'kernel_size_2': 5, 'num_filters_2': 117}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:45:22 DISPATCHER: Starting worker discovery
00:45:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:45:22 DISPATCHER: Finished worker discovery
00:45:55 WORKER: done with job (8, 0, 26), trying to register it.
00:45:55 WORKER: registered result for job (8, 0, 26) with dispatcher
00:45:55 DISPATCHER: job (8, 0, 26) finished
00:45:55 DISPATCHER: register_result: lock acquired
00:45:55 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:45:55 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001487605936281071, 'num_filters_1': 33, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.010455841594848445, 'kernel_size_2': 5, 'num_filters_2': 117}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.17092536294896254, 'info': {'data04': 0.17092536294896254, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001487605936281071, 'num_filters_1': 33, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.010455841594848445, 'kernel_size_2': 5, 'num_filters_2': 117}"}}
exception: None

00:45:55 job_callback for (8, 0, 26) started
00:45:55 job_callback for (8, 0, 26) got condition
00:45:55 DISPATCHER: Trying to submit another job.
00:45:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:45:55 HBMASTER: Trying to run another job!
00:45:55 job_callback for (8, 0, 26) finished
00:45:55 ITERATION: Advancing config (8, 0, 0) to next budget 133.333333
00:45:55 ITERATION: Advancing config (8, 0, 1) to next budget 133.333333
00:45:55 ITERATION: Advancing config (8, 0, 4) to next budget 133.333333
00:45:55 ITERATION: Advancing config (8, 0, 14) to next budget 133.333333
00:45:55 ITERATION: Advancing config (8, 0, 16) to next budget 133.333333
00:45:55 ITERATION: Advancing config (8, 0, 21) to next budget 133.333333
00:45:55 ITERATION: Advancing config (8, 0, 24) to next budget 133.333333
00:45:55 ITERATION: Advancing config (8, 0, 25) to next budget 133.333333
00:45:55 ITERATION: Advancing config (8, 0, 26) to next budget 133.333333
00:45:55 HBMASTER: schedule new run for iteration 8
00:45:55 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
00:45:55 HBMASTER: submitting job (8, 0, 0) to dispatcher
00:45:55 DISPATCHER: trying to submit job (8, 0, 0)
00:45:55 DISPATCHER: trying to notify the job_runner thread.
00:45:55 HBMASTER: job (8, 0, 0) submitted to dispatcher
00:45:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:45:55 DISPATCHER: Trying to submit another job.
00:45:55 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:45:55 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:45:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:45:55 WORKER: start processing job (8, 0, 0)
00:45:55 WORKER: args: ()
00:45:55 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.002708909195953881, 'num_filters_1': 65, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.01454254311157587, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 94, 'num_filters_3': 85}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:46:22 DISPATCHER: Starting worker discovery
00:46:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:46:22 DISPATCHER: Finished worker discovery
00:47:22 DISPATCHER: Starting worker discovery
00:47:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:47:22 DISPATCHER: Finished worker discovery
00:48:22 DISPATCHER: Starting worker discovery
00:48:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:48:22 DISPATCHER: Finished worker discovery
00:48:35 WORKER: done with job (8, 0, 0), trying to register it.
00:48:35 WORKER: registered result for job (8, 0, 0) with dispatcher
00:48:35 DISPATCHER: job (8, 0, 0) finished
00:48:35 DISPATCHER: register_result: lock acquired
00:48:35 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:48:35 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.002708909195953881, 'num_filters_1': 65, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.01454254311157587, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 94, 'num_filters_3': 85}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2154848429861766, 'info': {'data04': 0.2154848429861766, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.002708909195953881, 'num_filters_1': 65, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.01454254311157587, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 94, 'num_filters_3': 85}"}}
exception: None

00:48:35 job_callback for (8, 0, 0) started
00:48:35 job_callback for (8, 0, 0) got condition
00:48:35 DISPATCHER: Trying to submit another job.
00:48:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:48:35 done building a new model for budget 133.333333 based on 17/31 split
Best loss for this budget:-0.216926





00:48:35 HBMASTER: Trying to run another job!
00:48:35 job_callback for (8, 0, 0) finished
00:48:35 HBMASTER: schedule new run for iteration 8
00:48:35 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
00:48:35 HBMASTER: submitting job (8, 0, 1) to dispatcher
00:48:35 DISPATCHER: trying to submit job (8, 0, 1)
00:48:35 DISPATCHER: trying to notify the job_runner thread.
00:48:35 HBMASTER: job (8, 0, 1) submitted to dispatcher
00:48:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:48:35 DISPATCHER: Trying to submit another job.
00:48:35 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:48:35 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:48:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:48:35 WORKER: start processing job (8, 0, 1)
00:48:35 WORKER: args: ()
00:48:35 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006777578035863653, 'num_filters_1': 92, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.013725389398178515, 'kernel_size_2': 3, 'num_filters_2': 109}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:49:22 DISPATCHER: Starting worker discovery
00:49:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:49:22 DISPATCHER: Finished worker discovery
00:50:22 DISPATCHER: Starting worker discovery
00:50:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:50:22 DISPATCHER: Finished worker discovery
00:51:10 WORKER: done with job (8, 0, 1), trying to register it.
00:51:10 WORKER: registered result for job (8, 0, 1) with dispatcher
00:51:10 DISPATCHER: job (8, 0, 1) finished
00:51:10 DISPATCHER: register_result: lock acquired
00:51:10 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:51:10 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006777578035863653, 'num_filters_1': 92, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.013725389398178515, 'kernel_size_2': 3, 'num_filters_2': 109}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.19954861754455955, 'info': {'data04': 0.19954861754455955, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006777578035863653, 'num_filters_1': 92, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.013725389398178515, 'kernel_size_2': 3, 'num_filters_2': 109}"}}
exception: None

00:51:10 job_callback for (8, 0, 1) started
00:51:10 DISPATCHER: Trying to submit another job.
00:51:10 job_callback for (8, 0, 1) got condition
00:51:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:51:10 done building a new model for budget 133.333333 based on 17/32 split
Best loss for this budget:-0.216926





00:51:10 HBMASTER: Trying to run another job!
00:51:10 job_callback for (8, 0, 1) finished
00:51:10 HBMASTER: schedule new run for iteration 8
00:51:10 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
00:51:10 HBMASTER: submitting job (8, 0, 4) to dispatcher
00:51:10 DISPATCHER: trying to submit job (8, 0, 4)
00:51:10 DISPATCHER: trying to notify the job_runner thread.
00:51:10 HBMASTER: job (8, 0, 4) submitted to dispatcher
00:51:10 DISPATCHER: Trying to submit another job.
00:51:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:51:10 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:51:10 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:51:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:51:10 WORKER: start processing job (8, 0, 4)
00:51:10 WORKER: args: ()
00:51:10 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.004484010195742439, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.01248448173363612, 'kernel_size_2': 7, 'num_filters_2': 91}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:51:22 DISPATCHER: Starting worker discovery
00:51:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:51:22 DISPATCHER: Finished worker discovery
00:52:22 DISPATCHER: Starting worker discovery
00:52:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:52:22 DISPATCHER: Finished worker discovery
00:53:22 DISPATCHER: Starting worker discovery
00:53:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:53:22 DISPATCHER: Finished worker discovery
00:54:08 WORKER: done with job (8, 0, 4), trying to register it.
00:54:08 WORKER: registered result for job (8, 0, 4) with dispatcher
00:54:08 DISPATCHER: job (8, 0, 4) finished
00:54:08 DISPATCHER: register_result: lock acquired
00:54:08 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:54:08 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.004484010195742439, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.01248448173363612, 'kernel_size_2': 7, 'num_filters_2': 91}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.15567395802267858, 'info': {'data04': 0.15567395802267858, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.004484010195742439, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.01248448173363612, 'kernel_size_2': 7, 'num_filters_2': 91}"}}
exception: None

00:54:08 job_callback for (8, 0, 4) started
00:54:08 job_callback for (8, 0, 4) got condition
00:54:08 DISPATCHER: Trying to submit another job.
00:54:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:54:08 done building a new model for budget 133.333333 based on 17/33 split
Best loss for this budget:-0.216926





00:54:08 HBMASTER: Trying to run another job!
00:54:08 job_callback for (8, 0, 4) finished
00:54:08 HBMASTER: schedule new run for iteration 8
00:54:08 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
00:54:08 HBMASTER: submitting job (8, 0, 14) to dispatcher
00:54:08 DISPATCHER: trying to submit job (8, 0, 14)
00:54:08 DISPATCHER: trying to notify the job_runner thread.
00:54:08 HBMASTER: job (8, 0, 14) submitted to dispatcher
00:54:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:54:08 DISPATCHER: Trying to submit another job.
00:54:08 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:54:08 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:54:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:54:08 WORKER: start processing job (8, 0, 14)
00:54:08 WORKER: args: ()
00:54:08 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0012404171934022811, 'num_filters_1': 94, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.013388409362100916}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:54:22 DISPATCHER: Starting worker discovery
00:54:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:54:22 DISPATCHER: Finished worker discovery
00:55:22 DISPATCHER: Starting worker discovery
00:55:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:55:22 DISPATCHER: Finished worker discovery
00:56:22 DISPATCHER: Starting worker discovery
00:56:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:56:22 DISPATCHER: Finished worker discovery
00:56:50 WORKER: done with job (8, 0, 14), trying to register it.
00:56:50 WORKER: registered result for job (8, 0, 14) with dispatcher
00:56:50 DISPATCHER: job (8, 0, 14) finished
00:56:50 DISPATCHER: register_result: lock acquired
00:56:50 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:56:50 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0012404171934022811, 'num_filters_1': 94, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.013388409362100916}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.18280469728851556, 'info': {'data04': 0.18280469728851556, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0012404171934022811, 'num_filters_1': 94, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.013388409362100916}"}}
exception: None

00:56:50 job_callback for (8, 0, 14) started
00:56:50 job_callback for (8, 0, 14) got condition
00:56:50 DISPATCHER: Trying to submit another job.
00:56:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:56:50 done building a new model for budget 133.333333 based on 17/34 split
Best loss for this budget:-0.216926





00:56:50 HBMASTER: Trying to run another job!
00:56:50 job_callback for (8, 0, 14) finished
00:56:50 HBMASTER: schedule new run for iteration 8
00:56:50 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
00:56:50 HBMASTER: submitting job (8, 0, 16) to dispatcher
00:56:50 DISPATCHER: trying to submit job (8, 0, 16)
00:56:50 DISPATCHER: trying to notify the job_runner thread.
00:56:50 HBMASTER: job (8, 0, 16) submitted to dispatcher
00:56:50 DISPATCHER: Trying to submit another job.
00:56:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:56:50 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:56:50 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:56:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:56:50 WORKER: start processing job (8, 0, 16)
00:56:50 WORKER: args: ()
00:56:50 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.014686514179521765, 'num_filters_1': 75, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.01936880206901419, 'kernel_size_2': 5, 'num_filters_2': 102}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:57:22 DISPATCHER: Starting worker discovery
00:57:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:57:22 DISPATCHER: Finished worker discovery
00:58:22 DISPATCHER: Starting worker discovery
00:58:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:58:22 DISPATCHER: Finished worker discovery
00:59:22 DISPATCHER: Starting worker discovery
00:59:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:59:22 DISPATCHER: Finished worker discovery
00:59:28 WORKER: done with job (8, 0, 16), trying to register it.
00:59:28 WORKER: registered result for job (8, 0, 16) with dispatcher
00:59:28 DISPATCHER: job (8, 0, 16) finished
00:59:28 DISPATCHER: register_result: lock acquired
00:59:28 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:59:28 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.014686514179521765, 'num_filters_1': 75, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.01936880206901419, 'kernel_size_2': 5, 'num_filters_2': 102}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.11218334359832403, 'info': {'data04': 0.11218334359832403, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.014686514179521765, 'num_filters_1': 75, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.01936880206901419, 'kernel_size_2': 5, 'num_filters_2': 102}"}}
exception: None

00:59:28 job_callback for (8, 0, 16) started
00:59:28 job_callback for (8, 0, 16) got condition
00:59:28 DISPATCHER: Trying to submit another job.
00:59:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:59:28 done building a new model for budget 133.333333 based on 17/34 split
Best loss for this budget:-0.216926





00:59:28 HBMASTER: Trying to run another job!
00:59:28 job_callback for (8, 0, 16) finished
00:59:28 HBMASTER: schedule new run for iteration 8
00:59:28 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
00:59:28 HBMASTER: submitting job (8, 0, 21) to dispatcher
00:59:28 DISPATCHER: trying to submit job (8, 0, 21)
00:59:28 DISPATCHER: trying to notify the job_runner thread.
00:59:28 HBMASTER: job (8, 0, 21) submitted to dispatcher
00:59:28 DISPATCHER: Trying to submit another job.
00:59:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:59:28 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:59:28 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:59:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:59:28 WORKER: start processing job (8, 0, 21)
00:59:28 WORKER: args: ()
00:59:28 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001875997735052425, 'num_filters_1': 55, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.01112492867216199}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:00:22 DISPATCHER: Starting worker discovery
01:00:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:00:22 DISPATCHER: Finished worker discovery
01:01:22 DISPATCHER: Starting worker discovery
01:01:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:01:22 DISPATCHER: Finished worker discovery
01:02:20 WORKER: done with job (8, 0, 21), trying to register it.
01:02:20 WORKER: registered result for job (8, 0, 21) with dispatcher
01:02:20 DISPATCHER: job (8, 0, 21) finished
01:02:20 DISPATCHER: register_result: lock acquired
01:02:20 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
01:02:20 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001875997735052425, 'num_filters_1': 55, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.01112492867216199}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.18067459743125971, 'info': {'data04': 0.18067459743125971, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001875997735052425, 'num_filters_1': 55, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.01112492867216199}"}}
exception: None

01:02:20 job_callback for (8, 0, 21) started
01:02:20 DISPATCHER: Trying to submit another job.
01:02:20 job_callback for (8, 0, 21) got condition
01:02:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:02:20 done building a new model for budget 133.333333 based on 17/35 split
Best loss for this budget:-0.216926





01:02:20 HBMASTER: Trying to run another job!
01:02:20 job_callback for (8, 0, 21) finished
01:02:20 HBMASTER: schedule new run for iteration 8
01:02:20 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
01:02:20 HBMASTER: submitting job (8, 0, 24) to dispatcher
01:02:20 DISPATCHER: trying to submit job (8, 0, 24)
01:02:20 DISPATCHER: trying to notify the job_runner thread.
01:02:20 HBMASTER: job (8, 0, 24) submitted to dispatcher
01:02:20 DISPATCHER: Trying to submit another job.
01:02:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:02:20 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:02:20 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:02:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:02:20 WORKER: start processing job (8, 0, 24)
01:02:20 WORKER: args: ()
01:02:20 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0014495009288945943, 'num_filters_1': 67, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.01047874299248654}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:02:22 DISPATCHER: Starting worker discovery
01:02:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:02:22 DISPATCHER: Finished worker discovery
01:03:22 DISPATCHER: Starting worker discovery
01:03:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:03:22 DISPATCHER: Finished worker discovery
01:04:22 DISPATCHER: Starting worker discovery
01:04:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:04:22 DISPATCHER: Finished worker discovery
01:05:16 WORKER: done with job (8, 0, 24), trying to register it.
01:05:16 WORKER: registered result for job (8, 0, 24) with dispatcher
01:05:16 DISPATCHER: job (8, 0, 24) finished
01:05:16 DISPATCHER: register_result: lock acquired
01:05:16 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
01:05:16 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0014495009288945943, 'num_filters_1': 67, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.01047874299248654}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.20029625607030493, 'info': {'data04': 0.20029625607030493, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0014495009288945943, 'num_filters_1': 67, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.01047874299248654}"}}
exception: None

01:05:16 job_callback for (8, 0, 24) started
01:05:16 DISPATCHER: Trying to submit another job.
01:05:16 job_callback for (8, 0, 24) got condition
01:05:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:05:16 done building a new model for budget 133.333333 based on 17/36 split
Best loss for this budget:-0.216926





01:05:16 HBMASTER: Trying to run another job!
01:05:16 job_callback for (8, 0, 24) finished
01:05:16 HBMASTER: schedule new run for iteration 8
01:05:16 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
01:05:16 HBMASTER: submitting job (8, 0, 25) to dispatcher
01:05:16 DISPATCHER: trying to submit job (8, 0, 25)
01:05:16 DISPATCHER: trying to notify the job_runner thread.
01:05:16 HBMASTER: job (8, 0, 25) submitted to dispatcher
01:05:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:05:16 DISPATCHER: Trying to submit another job.
01:05:16 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:05:16 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:05:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:05:16 WORKER: start processing job (8, 0, 25)
01:05:16 WORKER: args: ()
01:05:16 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.025840431543169902, 'num_filters_1': 99, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.014635397170057645}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:05:22 DISPATCHER: Starting worker discovery
01:05:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:05:22 DISPATCHER: Finished worker discovery
01:06:22 DISPATCHER: Starting worker discovery
01:06:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:06:22 DISPATCHER: Finished worker discovery
01:07:22 DISPATCHER: Starting worker discovery
01:07:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:07:22 DISPATCHER: Finished worker discovery
01:07:52 WORKER: done with job (8, 0, 25), trying to register it.
01:07:52 WORKER: registered result for job (8, 0, 25) with dispatcher
01:07:52 DISPATCHER: job (8, 0, 25) finished
01:07:52 DISPATCHER: register_result: lock acquired
01:07:52 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
01:07:52 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.025840431543169902, 'num_filters_1': 99, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.014635397170057645}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.12977826525166108, 'info': {'data04': 0.12977826525166108, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.025840431543169902, 'num_filters_1': 99, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.014635397170057645}"}}
exception: None

01:07:52 job_callback for (8, 0, 25) started
01:07:52 job_callback for (8, 0, 25) got condition
01:07:52 DISPATCHER: Trying to submit another job.
01:07:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:07:52 done building a new model for budget 133.333333 based on 17/37 split
Best loss for this budget:-0.216926





01:07:52 HBMASTER: Trying to run another job!
01:07:52 job_callback for (8, 0, 25) finished
01:07:52 HBMASTER: schedule new run for iteration 8
01:07:52 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
01:07:52 HBMASTER: submitting job (8, 0, 26) to dispatcher
01:07:52 DISPATCHER: trying to submit job (8, 0, 26)
01:07:52 DISPATCHER: trying to notify the job_runner thread.
01:07:52 HBMASTER: job (8, 0, 26) submitted to dispatcher
01:07:52 DISPATCHER: Trying to submit another job.
01:07:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:07:52 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:07:52 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:07:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:07:52 WORKER: start processing job (8, 0, 26)
01:07:52 WORKER: args: ()
01:07:52 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001487605936281071, 'num_filters_1': 33, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.010455841594848445, 'kernel_size_2': 5, 'num_filters_2': 117}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:08:22 DISPATCHER: Starting worker discovery
01:08:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:08:22 DISPATCHER: Finished worker discovery
01:09:22 DISPATCHER: Starting worker discovery
01:09:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:09:22 DISPATCHER: Finished worker discovery
01:10:22 DISPATCHER: Starting worker discovery
01:10:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:10:22 DISPATCHER: Finished worker discovery
01:10:28 WORKER: done with job (8, 0, 26), trying to register it.
01:10:28 WORKER: registered result for job (8, 0, 26) with dispatcher
01:10:28 DISPATCHER: job (8, 0, 26) finished
01:10:28 DISPATCHER: register_result: lock acquired
01:10:28 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
01:10:28 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001487605936281071, 'num_filters_1': 33, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.010455841594848445, 'kernel_size_2': 5, 'num_filters_2': 117}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.21393786559291392, 'info': {'data04': 0.21393786559291392, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001487605936281071, 'num_filters_1': 33, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.010455841594848445, 'kernel_size_2': 5, 'num_filters_2': 117}"}}
exception: None

01:10:28 job_callback for (8, 0, 26) started
01:10:28 job_callback for (8, 0, 26) got condition
01:10:28 DISPATCHER: Trying to submit another job.
01:10:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:10:28 done building a new model for budget 133.333333 based on 17/38 split
Best loss for this budget:-0.216926





01:10:28 HBMASTER: Trying to run another job!
01:10:28 job_callback for (8, 0, 26) finished
01:10:28 ITERATION: Advancing config (8, 0, 0) to next budget 400.000000
01:10:28 ITERATION: Advancing config (8, 0, 24) to next budget 400.000000
01:10:28 ITERATION: Advancing config (8, 0, 26) to next budget 400.000000
01:10:28 HBMASTER: schedule new run for iteration 8
01:10:28 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
01:10:28 HBMASTER: submitting job (8, 0, 0) to dispatcher
01:10:28 DISPATCHER: trying to submit job (8, 0, 0)
01:10:28 DISPATCHER: trying to notify the job_runner thread.
01:10:28 HBMASTER: job (8, 0, 0) submitted to dispatcher
01:10:28 DISPATCHER: Trying to submit another job.
01:10:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:10:28 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:10:28 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:10:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:10:28 WORKER: start processing job (8, 0, 0)
01:10:28 WORKER: args: ()
01:10:28 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.002708909195953881, 'num_filters_1': 65, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.01454254311157587, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 94, 'num_filters_3': 85}, 'budget': 400.0, 'working_directory': '.'}
01:11:22 DISPATCHER: Starting worker discovery
01:11:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:11:22 DISPATCHER: Finished worker discovery
01:12:22 DISPATCHER: Starting worker discovery
01:12:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:12:22 DISPATCHER: Finished worker discovery
01:13:22 DISPATCHER: Starting worker discovery
01:13:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:13:22 DISPATCHER: Finished worker discovery
01:14:22 DISPATCHER: Starting worker discovery
01:14:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:14:22 DISPATCHER: Finished worker discovery
01:15:22 DISPATCHER: Starting worker discovery
01:15:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:15:22 DISPATCHER: Finished worker discovery
01:16:22 DISPATCHER: Starting worker discovery
01:16:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:16:22 DISPATCHER: Finished worker discovery
01:17:22 DISPATCHER: Starting worker discovery
01:17:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:17:23 DISPATCHER: Finished worker discovery
01:18:03 WORKER: done with job (8, 0, 0), trying to register it.
01:18:03 WORKER: registered result for job (8, 0, 0) with dispatcher
01:18:03 DISPATCHER: job (8, 0, 0) finished
01:18:03 DISPATCHER: register_result: lock acquired
01:18:03 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
01:18:03 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.002708909195953881, 'num_filters_1': 65, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.01454254311157587, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 94, 'num_filters_3': 85}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.17751862698224205, 'info': {'data04': 0.17751862698224205, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.002708909195953881, 'num_filters_1': 65, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.01454254311157587, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 94, 'num_filters_3': 85}"}}
exception: None

01:18:03 job_callback for (8, 0, 0) started
01:18:03 job_callback for (8, 0, 0) got condition
01:18:03 DISPATCHER: Trying to submit another job.
01:18:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:18:03 HBMASTER: Trying to run another job!
01:18:03 job_callback for (8, 0, 0) finished
01:18:03 HBMASTER: schedule new run for iteration 8
01:18:03 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
01:18:03 HBMASTER: submitting job (8, 0, 24) to dispatcher
01:18:03 DISPATCHER: trying to submit job (8, 0, 24)
01:18:03 DISPATCHER: trying to notify the job_runner thread.
01:18:03 HBMASTER: job (8, 0, 24) submitted to dispatcher
01:18:03 DISPATCHER: Trying to submit another job.
01:18:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:18:03 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:18:03 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:18:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:18:03 WORKER: start processing job (8, 0, 24)
01:18:03 WORKER: args: ()
01:18:03 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0014495009288945943, 'num_filters_1': 67, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.01047874299248654}, 'budget': 400.0, 'working_directory': '.'}
01:18:23 DISPATCHER: Starting worker discovery
01:18:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:18:23 DISPATCHER: Finished worker discovery
01:19:23 DISPATCHER: Starting worker discovery
01:19:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:19:23 DISPATCHER: Finished worker discovery
01:20:23 DISPATCHER: Starting worker discovery
01:20:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:20:23 DISPATCHER: Finished worker discovery
01:21:23 DISPATCHER: Starting worker discovery
01:21:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:21:23 DISPATCHER: Finished worker discovery
01:22:23 DISPATCHER: Starting worker discovery
01:22:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:22:23 DISPATCHER: Finished worker discovery
01:23:23 DISPATCHER: Starting worker discovery
01:23:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:23:23 DISPATCHER: Finished worker discovery
01:24:23 DISPATCHER: Starting worker discovery
01:24:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:24:23 DISPATCHER: Finished worker discovery
01:25:23 DISPATCHER: Starting worker discovery
01:25:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:25:23 DISPATCHER: Finished worker discovery
01:26:22 WORKER: done with job (8, 0, 24), trying to register it.
01:26:22 WORKER: registered result for job (8, 0, 24) with dispatcher
01:26:22 DISPATCHER: job (8, 0, 24) finished
01:26:22 DISPATCHER: register_result: lock acquired
01:26:22 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
01:26:22 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0014495009288945943, 'num_filters_1': 67, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.01047874299248654}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.18116266403181305, 'info': {'data04': 0.18116266403181305, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0014495009288945943, 'num_filters_1': 67, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.01047874299248654}"}}
exception: None

01:26:22 job_callback for (8, 0, 24) started
01:26:22 job_callback for (8, 0, 24) got condition
01:26:22 DISPATCHER: Trying to submit another job.
01:26:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:26:22 HBMASTER: Trying to run another job!
01:26:22 job_callback for (8, 0, 24) finished
01:26:22 HBMASTER: schedule new run for iteration 8
01:26:22 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
01:26:22 HBMASTER: submitting job (8, 0, 26) to dispatcher
01:26:22 DISPATCHER: trying to submit job (8, 0, 26)
01:26:22 DISPATCHER: trying to notify the job_runner thread.
01:26:22 HBMASTER: job (8, 0, 26) submitted to dispatcher
01:26:22 DISPATCHER: Trying to submit another job.
01:26:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:26:22 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:26:22 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:26:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:26:22 WORKER: start processing job (8, 0, 26)
01:26:22 WORKER: args: ()
01:26:22 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001487605936281071, 'num_filters_1': 33, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.010455841594848445, 'kernel_size_2': 5, 'num_filters_2': 117}, 'budget': 400.0, 'working_directory': '.'}
01:26:23 DISPATCHER: Starting worker discovery
01:26:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:26:23 DISPATCHER: Finished worker discovery
01:27:23 DISPATCHER: Starting worker discovery
01:27:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:27:23 DISPATCHER: Finished worker discovery
01:28:23 DISPATCHER: Starting worker discovery
01:28:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:28:23 DISPATCHER: Finished worker discovery
01:29:23 DISPATCHER: Starting worker discovery
01:29:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:29:23 DISPATCHER: Finished worker discovery
01:30:23 DISPATCHER: Starting worker discovery
01:30:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:30:23 DISPATCHER: Finished worker discovery
01:31:23 DISPATCHER: Starting worker discovery
01:31:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:31:23 DISPATCHER: Finished worker discovery
01:32:23 DISPATCHER: Starting worker discovery
01:32:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:32:23 DISPATCHER: Finished worker discovery
01:33:23 DISPATCHER: Starting worker discovery
01:33:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:33:23 DISPATCHER: Finished worker discovery
01:33:45 WORKER: done with job (8, 0, 26), trying to register it.
01:33:45 WORKER: registered result for job (8, 0, 26) with dispatcher
01:33:45 DISPATCHER: job (8, 0, 26) finished
01:33:45 DISPATCHER: register_result: lock acquired
01:33:45 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
01:33:45 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001487605936281071, 'num_filters_1': 33, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.010455841594848445, 'kernel_size_2': 5, 'num_filters_2': 117}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.19125792741556646, 'info': {'data04': 0.19125792741556646, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001487605936281071, 'num_filters_1': 33, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.010455841594848445, 'kernel_size_2': 5, 'num_filters_2': 117}"}}
exception: None

01:33:45 job_callback for (8, 0, 26) started
01:33:45 DISPATCHER: Trying to submit another job.
01:33:45 job_callback for (8, 0, 26) got condition
01:33:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:33:45 HBMASTER: Trying to run another job!
01:33:45 job_callback for (8, 0, 26) finished
01:33:45 ITERATION: Advancing config (8, 0, 26) to next budget 1200.000000
01:33:45 HBMASTER: schedule new run for iteration 8
01:33:45 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
01:33:45 HBMASTER: submitting job (8, 0, 26) to dispatcher
01:33:45 DISPATCHER: trying to submit job (8, 0, 26)
01:33:45 DISPATCHER: trying to notify the job_runner thread.
01:33:45 HBMASTER: job (8, 0, 26) submitted to dispatcher
01:33:45 DISPATCHER: Trying to submit another job.
01:33:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:33:45 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:33:45 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:33:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:33:45 WORKER: start processing job (8, 0, 26)
01:33:45 WORKER: args: ()
01:33:45 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001487605936281071, 'num_filters_1': 33, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.010455841594848445, 'kernel_size_2': 5, 'num_filters_2': 117}, 'budget': 1200.0, 'working_directory': '.'}
01:34:23 DISPATCHER: Starting worker discovery
01:34:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:34:23 DISPATCHER: Finished worker discovery
01:35:23 DISPATCHER: Starting worker discovery
01:35:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:35:23 DISPATCHER: Finished worker discovery
01:36:23 DISPATCHER: Starting worker discovery
01:36:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:36:23 DISPATCHER: Finished worker discovery
01:37:23 DISPATCHER: Starting worker discovery
01:37:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:37:23 DISPATCHER: Finished worker discovery
01:38:23 DISPATCHER: Starting worker discovery
01:38:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:38:23 DISPATCHER: Finished worker discovery
01:39:23 DISPATCHER: Starting worker discovery
01:39:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:39:23 DISPATCHER: Finished worker discovery
01:40:23 DISPATCHER: Starting worker discovery
01:40:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:40:23 DISPATCHER: Finished worker discovery
01:41:23 DISPATCHER: Starting worker discovery
01:41:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:41:23 DISPATCHER: Finished worker discovery
01:42:23 DISPATCHER: Starting worker discovery
01:42:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:42:23 DISPATCHER: Finished worker discovery
01:43:23 DISPATCHER: Starting worker discovery
01:43:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:43:23 DISPATCHER: Finished worker discovery
01:44:23 DISPATCHER: Starting worker discovery
01:44:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:44:23 DISPATCHER: Finished worker discovery
01:45:23 DISPATCHER: Starting worker discovery
01:45:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:45:23 DISPATCHER: Finished worker discovery
01:46:23 DISPATCHER: Starting worker discovery
01:46:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:46:23 DISPATCHER: Finished worker discovery
01:47:23 DISPATCHER: Starting worker discovery
01:47:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:47:23 DISPATCHER: Finished worker discovery
01:48:23 DISPATCHER: Starting worker discovery
01:48:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:48:23 DISPATCHER: Finished worker discovery
01:49:23 DISPATCHER: Starting worker discovery
01:49:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:49:23 DISPATCHER: Finished worker discovery
01:50:23 DISPATCHER: Starting worker discovery
01:50:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:50:23 DISPATCHER: Finished worker discovery
01:51:23 DISPATCHER: Starting worker discovery
01:51:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:51:23 DISPATCHER: Finished worker discovery
01:52:23 DISPATCHER: Starting worker discovery
01:52:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:52:23 DISPATCHER: Finished worker discovery
01:53:23 DISPATCHER: Starting worker discovery
01:53:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:53:23 DISPATCHER: Finished worker discovery
01:54:23 DISPATCHER: Starting worker discovery
01:54:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:54:24 DISPATCHER: Finished worker discovery
01:55:24 DISPATCHER: Starting worker discovery
01:55:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:55:24 DISPATCHER: Finished worker discovery
01:55:24 WORKER: done with job (8, 0, 26), trying to register it.
01:55:24 WORKER: registered result for job (8, 0, 26) with dispatcher
01:55:24 DISPATCHER: job (8, 0, 26) finished
01:55:24 DISPATCHER: register_result: lock acquired
01:55:24 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
01:55:24 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001487605936281071, 'num_filters_1': 33, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.010455841594848445, 'kernel_size_2': 5, 'num_filters_2': 117}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.14938140502616915, 'info': {'data04': 0.14938140502616915, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001487605936281071, 'num_filters_1': 33, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.010455841594848445, 'kernel_size_2': 5, 'num_filters_2': 117}"}}
exception: None

01:55:24 job_callback for (8, 0, 26) started
01:55:24 job_callback for (8, 0, 26) got condition
01:55:24 DISPATCHER: Trying to submit another job.
01:55:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:55:24 HBMASTER: Trying to run another job!
01:55:24 job_callback for (8, 0, 26) finished
01:55:24 start sampling a new configuration.
01:55:25 best_vector: [2, 2, 0.10410795800403219, 0.2705403446115672, 0.20767933044003145, 1, 0.4190443812901251, 0.15501173897888118, 0, 1, 2, 1, 0.782930821813679, 0.9532774772866354, 0.3289438360764558, 0.07296936353268846], 1.185112386516133e-05, 1.5556404719493495, 1.843608792272977e-05
01:55:25 done sampling a new configuration.
01:55:25 HBMASTER: schedule new run for iteration 9
01:55:25 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
01:55:25 HBMASTER: submitting job (9, 0, 0) to dispatcher
01:55:25 DISPATCHER: trying to submit job (9, 0, 0)
01:55:25 DISPATCHER: trying to notify the job_runner thread.
01:55:25 HBMASTER: job (9, 0, 0) submitted to dispatcher
01:55:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:55:25 DISPATCHER: Trying to submit another job.
01:55:25 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:55:25 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:55:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:55:25 WORKER: start processing job (9, 0, 0)
01:55:25 WORKER: args: ()
01:55:25 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0016151613589145452, 'num_filters_1': 27, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.0159101737362889, 'kernel_size_2': 3, 'num_filters_2': 81}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:56:24 DISPATCHER: Starting worker discovery
01:56:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:56:24 DISPATCHER: Finished worker discovery
01:57:24 DISPATCHER: Starting worker discovery
01:57:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:57:24 DISPATCHER: Finished worker discovery
01:58:08 WORKER: done with job (9, 0, 0), trying to register it.
01:58:08 WORKER: registered result for job (9, 0, 0) with dispatcher
01:58:08 DISPATCHER: job (9, 0, 0) finished
01:58:08 DISPATCHER: register_result: lock acquired
01:58:08 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
01:58:08 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0016151613589145452, 'num_filters_1': 27, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.0159101737362889, 'kernel_size_2': 3, 'num_filters_2': 81}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.17212794005605792, 'info': {'data04': 0.17212794005605792, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0016151613589145452, 'num_filters_1': 27, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.0159101737362889, 'kernel_size_2': 3, 'num_filters_2': 81}"}}
exception: None

01:58:08 job_callback for (9, 0, 0) started
01:58:08 job_callback for (9, 0, 0) got condition
01:58:08 DISPATCHER: Trying to submit another job.
01:58:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:58:08 done building a new model for budget 133.333333 based on 17/39 split
Best loss for this budget:-0.216926





01:58:08 HBMASTER: Trying to run another job!
01:58:08 job_callback for (9, 0, 0) finished
01:58:08 start sampling a new configuration.
01:58:08 best_vector: [2, 2, 0.06021466921178005, 0.5667511599679352, 0.20495890528434096, 1, 0.5535263756790454, 0.030766605114659642, 0, 1, 1, 0, 0.8408120533653344, 0.7311939195860859, 0.7316401385907862, 0.8367977092034543], 6.005903694126576e-06, 2.5490401823519973, 1.530928984766494e-05
01:58:08 done sampling a new configuration.
01:58:08 HBMASTER: schedule new run for iteration 9
01:58:08 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
01:58:08 HBMASTER: submitting job (9, 0, 1) to dispatcher
01:58:08 DISPATCHER: trying to submit job (9, 0, 1)
01:58:08 DISPATCHER: trying to notify the job_runner thread.
01:58:08 HBMASTER: job (9, 0, 1) submitted to dispatcher
01:58:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:58:08 DISPATCHER: Trying to submit another job.
01:58:08 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:58:08 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:58:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:58:08 WORKER: start processing job (9, 0, 1)
01:58:08 WORKER: args: ()
01:58:08 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001319560596066741, 'num_filters_1': 51, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.01096549588155965, 'kernel_size_2': 3, 'num_filters_2': 92}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:58:24 DISPATCHER: Starting worker discovery
01:58:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:58:24 DISPATCHER: Finished worker discovery
01:59:24 DISPATCHER: Starting worker discovery
01:59:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:59:24 DISPATCHER: Finished worker discovery
02:00:24 DISPATCHER: Starting worker discovery
02:00:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:00:24 DISPATCHER: Finished worker discovery
02:00:49 WORKER: done with job (9, 0, 1), trying to register it.
02:00:49 WORKER: registered result for job (9, 0, 1) with dispatcher
02:00:49 DISPATCHER: job (9, 0, 1) finished
02:00:49 DISPATCHER: register_result: lock acquired
02:00:49 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
02:00:49 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001319560596066741, 'num_filters_1': 51, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.01096549588155965, 'kernel_size_2': 3, 'num_filters_2': 92}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1950766261906906, 'info': {'data04': 0.1950766261906906, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001319560596066741, 'num_filters_1': 51, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.01096549588155965, 'kernel_size_2': 3, 'num_filters_2': 92}"}}
exception: None

02:00:49 job_callback for (9, 0, 1) started
02:00:49 DISPATCHER: Trying to submit another job.
02:00:49 job_callback for (9, 0, 1) got condition
02:00:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:00:49 done building a new model for budget 133.333333 based on 17/39 split
Best loss for this budget:-0.216926





02:00:49 HBMASTER: Trying to run another job!
02:00:49 job_callback for (9, 0, 1) finished
02:00:49 start sampling a new configuration.
02:00:49 best_vector: [2, 0, 0.3373632219824836, 0.5673902567062794, 0.0027601794964925153, 1, 0.2819131596187328, 0.08346687403558879, 2, 1, 2, 2, 0.7770612933501015, 0.9776428725602102, 0.9478431622886564, 0.7003052110897194], 1.368715462571248e-06, 1.0294131293075512, 1.408973667457101e-06
02:00:49 done sampling a new configuration.
02:00:49 HBMASTER: schedule new run for iteration 9
02:00:49 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
02:00:49 HBMASTER: submitting job (9, 0, 2) to dispatcher
02:00:49 DISPATCHER: trying to submit job (9, 0, 2)
02:00:49 DISPATCHER: trying to notify the job_runner thread.
02:00:49 HBMASTER: job (9, 0, 2) submitted to dispatcher
02:00:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:00:49 DISPATCHER: Trying to submit another job.
02:00:49 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
02:00:49 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
02:00:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:00:49 WORKER: start processing job (9, 0, 2)
02:00:49 WORKER: args: ()
02:00:49 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0047285332142789314, 'num_filters_1': 51, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.012840824393668513}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:01:24 DISPATCHER: Starting worker discovery
02:01:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:01:24 DISPATCHER: Finished worker discovery
02:02:24 DISPATCHER: Starting worker discovery
02:02:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:02:24 DISPATCHER: Finished worker discovery
02:03:24 DISPATCHER: Starting worker discovery
02:03:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:03:24 DISPATCHER: Finished worker discovery
02:03:41 WORKER: done with job (9, 0, 2), trying to register it.
02:03:41 WORKER: registered result for job (9, 0, 2) with dispatcher
02:03:41 DISPATCHER: job (9, 0, 2) finished
02:03:41 DISPATCHER: register_result: lock acquired
02:03:41 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
02:03:41 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0047285332142789314, 'num_filters_1': 51, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.012840824393668513}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.16484370126930448, 'info': {'data04': 0.16484370126930448, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0047285332142789314, 'num_filters_1': 51, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.012840824393668513}"}}
exception: None

02:03:41 job_callback for (9, 0, 2) started
02:03:41 job_callback for (9, 0, 2) got condition
02:03:41 DISPATCHER: Trying to submit another job.
02:03:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:03:41 done building a new model for budget 133.333333 based on 17/40 split
Best loss for this budget:-0.216926





02:03:41 HBMASTER: Trying to run another job!
02:03:41 job_callback for (9, 0, 2) finished
02:03:41 start sampling a new configuration.
02:03:41 done sampling a new configuration.
02:03:41 HBMASTER: schedule new run for iteration 9
02:03:41 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
02:03:41 HBMASTER: submitting job (9, 0, 3) to dispatcher
02:03:41 DISPATCHER: trying to submit job (9, 0, 3)
02:03:41 DISPATCHER: trying to notify the job_runner thread.
02:03:41 HBMASTER: job (9, 0, 3) submitted to dispatcher
02:03:41 DISPATCHER: Trying to submit another job.
02:03:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:03:41 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
02:03:41 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
02:03:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:03:41 WORKER: start processing job (9, 0, 3)
02:03:41 WORKER: args: ()
02:03:41 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.03199485729575467, 'num_filters_1': 95, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.15100443131231991}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:04:24 DISPATCHER: Starting worker discovery
02:04:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:04:24 DISPATCHER: Finished worker discovery
02:05:24 DISPATCHER: Starting worker discovery
02:05:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:05:24 DISPATCHER: Finished worker discovery
02:06:24 DISPATCHER: Starting worker discovery
02:06:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:06:24 DISPATCHER: Finished worker discovery
02:06:27 WORKER: done with job (9, 0, 3), trying to register it.
02:06:27 WORKER: registered result for job (9, 0, 3) with dispatcher
02:06:27 DISPATCHER: job (9, 0, 3) finished
02:06:27 DISPATCHER: register_result: lock acquired
02:06:27 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
02:06:27 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.03199485729575467, 'num_filters_1': 95, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.15100443131231991}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': 0.004169912070495619, 'info': {'data04': -0.004169912070495619, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.03199485729575467, 'num_filters_1': 95, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.15100443131231991}"}}
exception: None

02:06:27 job_callback for (9, 0, 3) started
02:06:27 job_callback for (9, 0, 3) got condition
02:06:27 DISPATCHER: Trying to submit another job.
02:06:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:06:27 done building a new model for budget 133.333333 based on 17/41 split
Best loss for this budget:-0.216926





02:06:27 HBMASTER: Trying to run another job!
02:06:27 job_callback for (9, 0, 3) finished
02:06:27 start sampling a new configuration.
02:06:27 best_vector: [2, 0, 0.14002161823690928, 0.633563757999629, 0.21618535739220593, 1, 0.11616733829935694, 0.08264764882297726, 0, 1, 0, 0, 0.9305125638094183, 0.6855768669572556, 0.9862252502662986, 0.8704782941397234], 5.116040375886547e-06, 0.10387420000244119, 5.314246012254036e-07
02:06:27 done sampling a new configuration.
02:06:27 HBMASTER: schedule new run for iteration 9
02:06:27 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
02:06:27 HBMASTER: submitting job (9, 0, 4) to dispatcher
02:06:27 DISPATCHER: trying to submit job (9, 0, 4)
02:06:27 DISPATCHER: trying to notify the job_runner thread.
02:06:27 HBMASTER: job (9, 0, 4) submitted to dispatcher
02:06:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:06:27 DISPATCHER: Trying to submit another job.
02:06:27 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
02:06:27 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
02:06:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:06:27 WORKER: start processing job (9, 0, 4)
02:06:27 WORKER: args: ()
02:06:27 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0019056504268059344, 'num_filters_1': 59, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.012809349345356026, 'kernel_size_2': 3, 'num_filters_2': 111}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:07:24 DISPATCHER: Starting worker discovery
02:07:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:07:24 DISPATCHER: Finished worker discovery
02:08:24 DISPATCHER: Starting worker discovery
02:08:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:08:24 DISPATCHER: Finished worker discovery
02:09:24 DISPATCHER: Starting worker discovery
02:09:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:09:25 DISPATCHER: Finished worker discovery
02:09:35 WORKER: done with job (9, 0, 4), trying to register it.
02:09:35 WORKER: registered result for job (9, 0, 4) with dispatcher
02:09:35 DISPATCHER: job (9, 0, 4) finished
02:09:35 DISPATCHER: register_result: lock acquired
02:09:35 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
02:09:35 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0019056504268059344, 'num_filters_1': 59, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.012809349345356026, 'kernel_size_2': 3, 'num_filters_2': 111}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1983335912803824, 'info': {'data04': 0.1983335912803824, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0019056504268059344, 'num_filters_1': 59, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.012809349345356026, 'kernel_size_2': 3, 'num_filters_2': 111}"}}
exception: None

02:09:35 job_callback for (9, 0, 4) started
02:09:35 DISPATCHER: Trying to submit another job.
02:09:35 job_callback for (9, 0, 4) got condition
02:09:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:09:35 done building a new model for budget 133.333333 based on 17/42 split
Best loss for this budget:-0.216926





02:09:35 HBMASTER: Trying to run another job!
02:09:35 job_callback for (9, 0, 4) finished
02:09:35 start sampling a new configuration.
02:09:35 best_vector: [1, 0, 0.1295459206661862, 0.6298698852016456, 0.14780062782956824, 1, 0.17313739558486996, 0.06138002132227581, 0, 1, 1, 2, 0.9331540911320639, 0.8752612286340298, 0.9012312295831871, 0.38364788664832045], 7.815645789565463e-06, 9.420714874410152, 7.362897054288043e-05
02:09:35 done sampling a new configuration.
02:09:35 HBMASTER: schedule new run for iteration 9
02:09:35 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
02:09:35 HBMASTER: submitting job (9, 0, 5) to dispatcher
02:09:35 DISPATCHER: trying to submit job (9, 0, 5)
02:09:35 DISPATCHER: trying to notify the job_runner thread.
02:09:35 HBMASTER: job (9, 0, 5) submitted to dispatcher
02:09:35 DISPATCHER: Trying to submit another job.
02:09:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:09:35 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
02:09:35 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
02:09:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:09:35 WORKER: start processing job (9, 0, 5)
02:09:35 WORKER: args: ()
02:09:35 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0018158996349763258, 'num_filters_1': 59, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.012018693193099735}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:10:25 DISPATCHER: Starting worker discovery
02:10:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:10:25 DISPATCHER: Finished worker discovery
02:11:25 DISPATCHER: Starting worker discovery
02:11:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:11:25 DISPATCHER: Finished worker discovery
02:12:25 DISPATCHER: Starting worker discovery
02:12:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:12:25 DISPATCHER: Finished worker discovery
02:12:28 WORKER: done with job (9, 0, 5), trying to register it.
02:12:28 WORKER: registered result for job (9, 0, 5) with dispatcher
02:12:28 DISPATCHER: job (9, 0, 5) finished
02:12:28 DISPATCHER: register_result: lock acquired
02:12:28 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
02:12:28 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0018158996349763258, 'num_filters_1': 59, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.012018693193099735}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.19722351965801255, 'info': {'data04': 0.19722351965801255, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0018158996349763258, 'num_filters_1': 59, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.012018693193099735}"}}
exception: None

02:12:28 job_callback for (9, 0, 5) started
02:12:28 job_callback for (9, 0, 5) got condition
02:12:28 DISPATCHER: Trying to submit another job.
02:12:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:12:28 done building a new model for budget 133.333333 based on 17/43 split
Best loss for this budget:-0.216926





02:12:28 HBMASTER: Trying to run another job!
02:12:28 job_callback for (9, 0, 5) finished
02:12:28 start sampling a new configuration.
02:12:28 best_vector: [3, 1, 0.2300856493676961, 0.39290804140298, 0.046229309016404506, 1, 0.9822855095858977, 0.05247402796713921, 0, 1, 0, 0, 0.9051650524617116, 0.8283039493953916, 0.017918251897372034, 0.5764704008146581], 3.625952589202601e-05, 0.4376598371647644, 1.5869338197575664e-05
02:12:28 done sampling a new configuration.
02:12:28 HBMASTER: schedule new run for iteration 9
02:12:28 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
02:12:28 HBMASTER: submitting job (9, 0, 6) to dispatcher
02:12:28 DISPATCHER: trying to submit job (9, 0, 6)
02:12:28 DISPATCHER: trying to notify the job_runner thread.
02:12:28 HBMASTER: job (9, 0, 6) submitted to dispatcher
02:12:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:12:28 DISPATCHER: Trying to submit another job.
02:12:28 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880
02:12:28 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
02:12:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:12:28 WORKER: start processing job (9, 0, 6)
02:12:28 WORKER: args: ()
02:12:28 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002885169275797019, 'num_filters_1': 36, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.011702274587521676}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:13:25 DISPATCHER: Starting worker discovery
02:13:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:13:25 DISPATCHER: Finished worker discovery
02:14:25 DISPATCHER: Starting worker discovery
02:14:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:14:25 DISPATCHER: Finished worker discovery
02:15:03 WORKER: done with job (9, 0, 6), trying to register it.
02:15:03 WORKER: registered result for job (9, 0, 6) with dispatcher
02:15:03 DISPATCHER: job (9, 0, 6) finished
02:15:03 DISPATCHER: register_result: lock acquired
02:15:03 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
02:15:03 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002885169275797019, 'num_filters_1': 36, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.011702274587521676}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1760534728302804, 'info': {'data04': 0.1760534728302804, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002885169275797019, 'num_filters_1': 36, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.011702274587521676}"}}
exception: None

02:15:03 job_callback for (9, 0, 6) started
02:15:03 job_callback for (9, 0, 6) got condition
02:15:03 DISPATCHER: Trying to submit another job.
02:15:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:15:03 done building a new model for budget 133.333333 based on 17/44 split
Best loss for this budget:-0.216926





02:15:03 HBMASTER: Trying to run another job!
02:15:03 job_callback for (9, 0, 6) finished
02:15:03 start sampling a new configuration.
02:15:04 best_vector: [0, 0, 0.18325898617447614, 0.3296787668417143, 0.09679088606083144, 1, 0.41103314698252574, 0.06461188976692693, 2, 1, 1, 1, 0.8331699736943821, 0.7419012841615196, 0.7479926993631015, 0.26482086165101604], 8.61102989247487e-06, 5.975523333627437, 5.145541004904694e-05
02:15:04 done sampling a new configuration.
02:15:04 HBMASTER: schedule new run for iteration 9
02:15:04 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
02:15:04 HBMASTER: submitting job (9, 0, 7) to dispatcher
02:15:04 DISPATCHER: trying to submit job (9, 0, 7)
02:15:04 DISPATCHER: trying to notify the job_runner thread.
02:15:04 HBMASTER: job (9, 0, 7) submitted to dispatcher
02:15:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:15:04 DISPATCHER: Trying to submit another job.
02:15:04 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880
02:15:04 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
02:15:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:15:04 WORKER: start processing job (9, 0, 7)
02:15:04 WORKER: args: ()
02:15:04 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0023255087200904083, 'num_filters_1': 31, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.0121356210517668}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:15:25 DISPATCHER: Starting worker discovery
02:15:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:15:25 DISPATCHER: Finished worker discovery
02:16:25 DISPATCHER: Starting worker discovery
02:16:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:16:25 DISPATCHER: Finished worker discovery
02:17:25 DISPATCHER: Starting worker discovery
02:17:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:17:25 DISPATCHER: Finished worker discovery
02:17:49 WORKER: done with job (9, 0, 7), trying to register it.
02:17:49 WORKER: registered result for job (9, 0, 7) with dispatcher
02:17:49 DISPATCHER: job (9, 0, 7) finished
02:17:49 DISPATCHER: register_result: lock acquired
02:17:49 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
02:17:49 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0023255087200904083, 'num_filters_1': 31, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.0121356210517668}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.17598746722767133, 'info': {'data04': 0.17598746722767133, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0023255087200904083, 'num_filters_1': 31, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.0121356210517668}"}}
exception: None

02:17:49 job_callback for (9, 0, 7) started
02:17:49 DISPATCHER: Trying to submit another job.
02:17:49 job_callback for (9, 0, 7) got condition
02:17:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:17:49 done building a new model for budget 133.333333 based on 17/45 split
Best loss for this budget:-0.216926





02:17:49 HBMASTER: Trying to run another job!
02:17:49 job_callback for (9, 0, 7) finished
02:17:49 start sampling a new configuration.
02:17:49 best_vector: [3, 2, 0.06815425644486098, 0.9568545864448574, 0.3444258614984645, 1, 0.13722554098392067, 0.07998950952254476, 0, 1, 0, 0, 0.9363106715065744, 0.9737927091211079, 0.8912485812479932, 0.6721851656348553], 9.043337532475834e-06, 0.895379826628587, 8.097221991972006e-06
02:17:49 done sampling a new configuration.
02:17:49 HBMASTER: schedule new run for iteration 9
02:17:49 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
02:17:49 HBMASTER: submitting job (9, 0, 8) to dispatcher
02:17:49 DISPATCHER: trying to submit job (9, 0, 8)
02:17:49 DISPATCHER: trying to notify the job_runner thread.
02:17:49 HBMASTER: job (9, 0, 8) submitted to dispatcher
02:17:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:17:49 DISPATCHER: Trying to submit another job.
02:17:49 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880
02:17:49 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
02:17:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:17:49 WORKER: start processing job (9, 0, 8)
02:17:49 WORKER: args: ()
02:17:49 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0013687007741273272, 'num_filters_1': 117, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.01270775260063976, 'kernel_size_2': 3, 'num_filters_2': 112}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:18:25 DISPATCHER: Starting worker discovery
02:18:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:18:25 DISPATCHER: Finished worker discovery
02:19:25 DISPATCHER: Starting worker discovery
02:19:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:19:25 DISPATCHER: Finished worker discovery
02:20:25 DISPATCHER: Starting worker discovery
02:20:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:20:25 DISPATCHER: Finished worker discovery
02:20:44 WORKER: done with job (9, 0, 8), trying to register it.
02:20:44 WORKER: registered result for job (9, 0, 8) with dispatcher
02:20:44 DISPATCHER: job (9, 0, 8) finished
02:20:44 DISPATCHER: register_result: lock acquired
02:20:44 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
02:20:44 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0013687007741273272, 'num_filters_1': 117, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.01270775260063976, 'kernel_size_2': 3, 'num_filters_2': 112}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.19393939268406754, 'info': {'data04': 0.19393939268406754, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0013687007741273272, 'num_filters_1': 117, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.01270775260063976, 'kernel_size_2': 3, 'num_filters_2': 112}"}}
exception: None

02:20:44 job_callback for (9, 0, 8) started
02:20:44 job_callback for (9, 0, 8) got condition
02:20:44 DISPATCHER: Trying to submit another job.
02:20:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:20:44 done building a new model for budget 133.333333 based on 17/45 split
Best loss for this budget:-0.216926





02:20:44 HBMASTER: Trying to run another job!
02:20:44 job_callback for (9, 0, 8) finished
02:20:44 ITERATION: Advancing config (9, 0, 1) to next budget 400.000000
02:20:44 ITERATION: Advancing config (9, 0, 4) to next budget 400.000000
02:20:44 ITERATION: Advancing config (9, 0, 5) to next budget 400.000000
02:20:44 HBMASTER: schedule new run for iteration 9
02:20:44 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
02:20:44 HBMASTER: submitting job (9, 0, 1) to dispatcher
02:20:44 DISPATCHER: trying to submit job (9, 0, 1)
02:20:44 DISPATCHER: trying to notify the job_runner thread.
02:20:44 HBMASTER: job (9, 0, 1) submitted to dispatcher
02:20:44 DISPATCHER: Trying to submit another job.
02:20:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:20:44 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
02:20:44 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
02:20:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:20:44 WORKER: start processing job (9, 0, 1)
02:20:44 WORKER: args: ()
02:20:44 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001319560596066741, 'num_filters_1': 51, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.01096549588155965, 'kernel_size_2': 3, 'num_filters_2': 92}, 'budget': 400.0, 'working_directory': '.'}
02:21:25 DISPATCHER: Starting worker discovery
02:21:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:21:25 DISPATCHER: Finished worker discovery
02:22:25 DISPATCHER: Starting worker discovery
02:22:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:22:25 DISPATCHER: Finished worker discovery
02:23:25 DISPATCHER: Starting worker discovery
02:23:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:23:25 DISPATCHER: Finished worker discovery
02:24:25 DISPATCHER: Starting worker discovery
02:24:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:24:25 DISPATCHER: Finished worker discovery
02:25:25 DISPATCHER: Starting worker discovery
02:25:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:25:25 DISPATCHER: Finished worker discovery
02:26:25 DISPATCHER: Starting worker discovery
02:26:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:26:25 DISPATCHER: Finished worker discovery
02:27:25 DISPATCHER: Starting worker discovery
02:27:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:27:25 DISPATCHER: Finished worker discovery
02:28:15 WORKER: done with job (9, 0, 1), trying to register it.
02:28:15 WORKER: registered result for job (9, 0, 1) with dispatcher
02:28:15 DISPATCHER: job (9, 0, 1) finished
02:28:15 DISPATCHER: register_result: lock acquired
02:28:15 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
02:28:15 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001319560596066741, 'num_filters_1': 51, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.01096549588155965, 'kernel_size_2': 3, 'num_filters_2': 92}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.1944046402880441, 'info': {'data04': 0.1944046402880441, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001319560596066741, 'num_filters_1': 51, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.01096549588155965, 'kernel_size_2': 3, 'num_filters_2': 92}"}}
exception: None

02:28:15 job_callback for (9, 0, 1) started
02:28:15 DISPATCHER: Trying to submit another job.
02:28:15 job_callback for (9, 0, 1) got condition
02:28:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:28:15 HBMASTER: Trying to run another job!
02:28:15 job_callback for (9, 0, 1) finished
02:28:15 HBMASTER: schedule new run for iteration 9
02:28:15 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
02:28:15 HBMASTER: submitting job (9, 0, 4) to dispatcher
02:28:15 DISPATCHER: trying to submit job (9, 0, 4)
02:28:15 DISPATCHER: trying to notify the job_runner thread.
02:28:15 HBMASTER: job (9, 0, 4) submitted to dispatcher
02:28:15 DISPATCHER: Trying to submit another job.
02:28:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:28:15 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
02:28:15 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
02:28:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:28:15 WORKER: start processing job (9, 0, 4)
02:28:15 WORKER: args: ()
02:28:15 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0019056504268059344, 'num_filters_1': 59, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.012809349345356026, 'kernel_size_2': 3, 'num_filters_2': 111}, 'budget': 400.0, 'working_directory': '.'}
02:28:25 DISPATCHER: Starting worker discovery
02:28:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:28:25 DISPATCHER: Finished worker discovery
02:29:25 DISPATCHER: Starting worker discovery
02:29:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:29:25 DISPATCHER: Finished worker discovery
02:30:25 DISPATCHER: Starting worker discovery
02:30:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:30:25 DISPATCHER: Finished worker discovery
02:31:25 DISPATCHER: Starting worker discovery
02:31:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:31:25 DISPATCHER: Finished worker discovery
02:32:25 DISPATCHER: Starting worker discovery
02:32:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:32:25 DISPATCHER: Finished worker discovery
02:33:25 DISPATCHER: Starting worker discovery
02:33:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:33:25 DISPATCHER: Finished worker discovery
02:34:25 DISPATCHER: Starting worker discovery
02:34:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:34:25 DISPATCHER: Finished worker discovery
02:35:25 DISPATCHER: Starting worker discovery
02:35:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:35:25 DISPATCHER: Finished worker discovery
02:36:25 DISPATCHER: Starting worker discovery
02:36:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:36:26 DISPATCHER: Finished worker discovery
02:36:56 WORKER: done with job (9, 0, 4), trying to register it.
02:36:56 WORKER: registered result for job (9, 0, 4) with dispatcher
02:36:56 DISPATCHER: job (9, 0, 4) finished
02:36:56 DISPATCHER: register_result: lock acquired
02:36:56 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
02:36:56 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0019056504268059344, 'num_filters_1': 59, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.012809349345356026, 'kernel_size_2': 3, 'num_filters_2': 111}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.13428948567158855, 'info': {'data04': 0.13428948567158855, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0019056504268059344, 'num_filters_1': 59, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.012809349345356026, 'kernel_size_2': 3, 'num_filters_2': 111}"}}
exception: None

02:36:56 job_callback for (9, 0, 4) started
02:36:56 DISPATCHER: Trying to submit another job.
02:36:56 job_callback for (9, 0, 4) got condition
02:36:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:36:56 HBMASTER: Trying to run another job!
02:36:56 job_callback for (9, 0, 4) finished
02:36:56 HBMASTER: schedule new run for iteration 9
02:36:56 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
02:36:56 HBMASTER: submitting job (9, 0, 5) to dispatcher
02:36:56 DISPATCHER: trying to submit job (9, 0, 5)
02:36:56 DISPATCHER: trying to notify the job_runner thread.
02:36:56 HBMASTER: job (9, 0, 5) submitted to dispatcher
02:36:56 DISPATCHER: Trying to submit another job.
02:36:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:36:56 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
02:36:56 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
02:36:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:36:56 WORKER: start processing job (9, 0, 5)
02:36:56 WORKER: args: ()
02:36:56 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0018158996349763258, 'num_filters_1': 59, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.012018693193099735}, 'budget': 400.0, 'working_directory': '.'}
02:37:26 DISPATCHER: Starting worker discovery
02:37:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:37:26 DISPATCHER: Finished worker discovery
02:38:26 DISPATCHER: Starting worker discovery
02:38:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:38:26 DISPATCHER: Finished worker discovery
02:39:26 DISPATCHER: Starting worker discovery
02:39:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:39:26 DISPATCHER: Finished worker discovery
02:40:26 DISPATCHER: Starting worker discovery
02:40:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:40:26 DISPATCHER: Finished worker discovery
02:41:26 DISPATCHER: Starting worker discovery
02:41:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:41:26 DISPATCHER: Finished worker discovery
02:42:26 DISPATCHER: Starting worker discovery
02:42:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:42:26 DISPATCHER: Finished worker discovery
02:43:26 DISPATCHER: Starting worker discovery
02:43:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:43:26 DISPATCHER: Finished worker discovery
02:44:26 DISPATCHER: Starting worker discovery
02:44:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:44:26 DISPATCHER: Finished worker discovery
02:45:05 WORKER: done with job (9, 0, 5), trying to register it.
02:45:05 WORKER: registered result for job (9, 0, 5) with dispatcher
02:45:05 DISPATCHER: job (9, 0, 5) finished
02:45:05 DISPATCHER: register_result: lock acquired
02:45:05 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
02:45:05 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0018158996349763258, 'num_filters_1': 59, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.012018693193099735}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.1753487825342609, 'info': {'data04': 0.1753487825342609, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0018158996349763258, 'num_filters_1': 59, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.012018693193099735}"}}
exception: None

02:45:05 job_callback for (9, 0, 5) started
02:45:05 job_callback for (9, 0, 5) got condition
02:45:05 DISPATCHER: Trying to submit another job.
02:45:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:45:05 HBMASTER: Trying to run another job!
02:45:05 job_callback for (9, 0, 5) finished
02:45:05 ITERATION: Advancing config (9, 0, 1) to next budget 1200.000000
02:45:05 HBMASTER: schedule new run for iteration 9
02:45:05 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
02:45:05 HBMASTER: submitting job (9, 0, 1) to dispatcher
02:45:05 DISPATCHER: trying to submit job (9, 0, 1)
02:45:05 DISPATCHER: trying to notify the job_runner thread.
02:45:05 HBMASTER: job (9, 0, 1) submitted to dispatcher
02:45:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:45:05 DISPATCHER: Trying to submit another job.
02:45:05 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
02:45:05 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
02:45:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:45:05 WORKER: start processing job (9, 0, 1)
02:45:05 WORKER: args: ()
02:45:05 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001319560596066741, 'num_filters_1': 51, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.01096549588155965, 'kernel_size_2': 3, 'num_filters_2': 92}, 'budget': 1200.0, 'working_directory': '.'}
02:45:26 DISPATCHER: Starting worker discovery
02:45:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:45:26 DISPATCHER: Finished worker discovery
02:46:26 DISPATCHER: Starting worker discovery
02:46:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:46:26 DISPATCHER: Finished worker discovery
02:47:26 DISPATCHER: Starting worker discovery
02:47:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:47:26 DISPATCHER: Finished worker discovery
02:48:26 DISPATCHER: Starting worker discovery
02:48:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:48:26 DISPATCHER: Finished worker discovery
02:49:26 DISPATCHER: Starting worker discovery
02:49:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:49:26 DISPATCHER: Finished worker discovery
02:50:26 DISPATCHER: Starting worker discovery
02:50:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:50:26 DISPATCHER: Finished worker discovery
02:51:26 DISPATCHER: Starting worker discovery
02:51:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:51:26 DISPATCHER: Finished worker discovery
02:52:26 DISPATCHER: Starting worker discovery
02:52:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:52:26 DISPATCHER: Finished worker discovery
02:53:26 DISPATCHER: Starting worker discovery
02:53:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:53:26 DISPATCHER: Finished worker discovery
02:54:26 DISPATCHER: Starting worker discovery
02:54:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:54:26 DISPATCHER: Finished worker discovery
02:55:26 DISPATCHER: Starting worker discovery
02:55:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:55:26 DISPATCHER: Finished worker discovery
02:56:26 DISPATCHER: Starting worker discovery
02:56:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:56:26 DISPATCHER: Finished worker discovery
02:57:26 DISPATCHER: Starting worker discovery
02:57:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:57:26 DISPATCHER: Finished worker discovery
02:58:26 DISPATCHER: Starting worker discovery
02:58:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:58:26 DISPATCHER: Finished worker discovery
02:59:26 DISPATCHER: Starting worker discovery
02:59:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:59:26 DISPATCHER: Finished worker discovery
03:00:26 DISPATCHER: Starting worker discovery
03:00:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:00:26 DISPATCHER: Finished worker discovery
03:01:26 DISPATCHER: Starting worker discovery
03:01:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:01:26 DISPATCHER: Finished worker discovery
03:02:26 DISPATCHER: Starting worker discovery
03:02:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:02:26 DISPATCHER: Finished worker discovery
03:03:26 DISPATCHER: Starting worker discovery
03:03:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:03:26 DISPATCHER: Finished worker discovery
03:04:26 DISPATCHER: Starting worker discovery
03:04:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:04:26 DISPATCHER: Finished worker discovery
03:05:26 DISPATCHER: Starting worker discovery
03:05:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:05:26 DISPATCHER: Finished worker discovery
03:06:26 DISPATCHER: Starting worker discovery
03:06:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:06:27 DISPATCHER: Finished worker discovery
03:07:14 WORKER: done with job (9, 0, 1), trying to register it.
03:07:14 WORKER: registered result for job (9, 0, 1) with dispatcher
03:07:14 DISPATCHER: job (9, 0, 1) finished
03:07:14 DISPATCHER: register_result: lock acquired
03:07:14 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:07:14 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001319560596066741, 'num_filters_1': 51, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.01096549588155965, 'kernel_size_2': 3, 'num_filters_2': 92}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.166442997841957, 'info': {'data04': 0.166442997841957, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001319560596066741, 'num_filters_1': 51, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.01096549588155965, 'kernel_size_2': 3, 'num_filters_2': 92}"}}
exception: None

03:07:14 job_callback for (9, 0, 1) started
03:07:14 DISPATCHER: Trying to submit another job.
03:07:14 job_callback for (9, 0, 1) got condition
03:07:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:07:14 HBMASTER: Trying to run another job!
03:07:14 job_callback for (9, 0, 1) finished
03:07:14 HBMASTER: shutdown initiated, shutdown_workers = True
03:07:14 WORKER: shutting down now!
03:07:14 DISPATCHER: Dispatcher shutting down
03:07:14 DISPATCHER: discover_workers shutting down
03:07:14 DISPATCHER: Trying to submit another job.
03:07:14 DISPATCHER: 'discover_worker' thread exited
03:07:14 DISPATCHER: job_runner shutting down
03:07:14 DISPATCHER: 'job_runner' thread exited
03:07:14 DISPATCHER: shut down complete
03:07:14 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7fb8e86a75f8; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:31243>
03:07:14 WORKER: No dispatcher found. Waiting for one to initiate contact.
03:07:14 WORKER: start listening for jobs
03:07:14 wait_for_workers trying to get the condition
03:07:14 DISPATCHER: started the 'discover_worker' thread
03:07:14 DISPATCHER: started the 'job_runner' thread
03:07:14 DISPATCHER: Pyro daemon running on localhost:37447
03:07:14 DISPATCHER: Starting worker discovery
03:07:14 DISPATCHER: Found 1 potential workers, 0 currently in the pool.
03:07:14 DISPATCHER: discovered new worker, hpbandster.run_0.worker.metagpuj.13102140436472194880
03:07:14 HBMASTER: number of workers changed to 1
03:07:14 Enough workers to start this run!
03:07:14 adjust_queue_size: lock accquired
03:07:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:07:14 HBMASTER: starting run at 1583892434.8023932
03:07:14 HBMASTER: adjusted queue size to (0, 1)
03:07:14 DISPATCHER: Finished worker discovery
03:07:14 start sampling a new configuration.
03:07:14 DISPATCHER: Trying to submit another job.
03:07:14 done sampling a new configuration.
03:07:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:07:14 HBMASTER: schedule new run for iteration 0
03:07:14 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
03:07:14 HBMASTER: submitting job (0, 0, 0) to dispatcher
03:07:14 DISPATCHER: trying to submit job (0, 0, 0)
03:07:14 DISPATCHER: trying to notify the job_runner thread.
03:07:14 HBMASTER: job (0, 0, 0) submitted to dispatcher
03:07:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:07:14 DISPATCHER: Trying to submit another job.
03:07:14 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:07:14 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:07:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:07:14 WORKER: start processing job (0, 0, 0)
03:07:14 WORKER: args: ()
03:07:14 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 49, 'last_n_outputs': 46, 'lr': 0.021502265204905394, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.05213590289670609}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-406:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:08:12 WORKER: done with job (0, 0, 0), trying to register it.
03:08:12 WORKER: registered result for job (0, 0, 0) with dispatcher
03:08:12 DISPATCHER: job (0, 0, 0) finished
03:08:12 DISPATCHER: register_result: lock acquired
03:08:12 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:08:12 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 49, 'last_n_outputs': 46, 'lr': 0.021502265204905394, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.05213590289670609}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.022000884767048114, 'info': {'data04': 0.022000884767048114, 'config': "{'batch_size': 32, 'hidden_dim': 49, 'last_n_outputs': 46, 'lr': 0.021502265204905394, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.05213590289670609}"}}
exception: None

03:08:12 job_callback for (0, 0, 0) started
03:08:12 job_callback for (0, 0, 0) got condition
03:08:12 DISPATCHER: Trying to submit another job.
03:08:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:08:12 Only 1 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
03:08:12 HBMASTER: Trying to run another job!
03:08:12 job_callback for (0, 0, 0) finished
03:08:12 start sampling a new configuration.
03:08:12 done sampling a new configuration.
03:08:12 HBMASTER: schedule new run for iteration 0
03:08:12 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
03:08:12 HBMASTER: submitting job (0, 0, 1) to dispatcher
03:08:12 DISPATCHER: trying to submit job (0, 0, 1)
03:08:12 DISPATCHER: trying to notify the job_runner thread.
03:08:12 HBMASTER: job (0, 0, 1) submitted to dispatcher
03:08:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:08:12 DISPATCHER: Trying to submit another job.
03:08:12 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:08:12 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:08:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:08:12 WORKER: start processing job (0, 0, 1)
03:08:12 WORKER: args: ()
03:08:12 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 78, 'last_n_outputs': 9, 'lr': 0.07634703789597547, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.09310918210622306}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:08:14 DISPATCHER: Starting worker discovery
03:08:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:08:14 DISPATCHER: Finished worker discovery
Exception in thread Thread-407:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:09:09 WORKER: done with job (0, 0, 1), trying to register it.
03:09:09 WORKER: registered result for job (0, 0, 1) with dispatcher
03:09:09 DISPATCHER: job (0, 0, 1) finished
03:09:09 DISPATCHER: register_result: lock acquired
03:09:09 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:09:09 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 78, 'last_n_outputs': 9, 'lr': 0.07634703789597547, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.09310918210622306}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.004996478533204455, 'info': {'data04': 0.004996478533204455, 'config': "{'batch_size': 64, 'hidden_dim': 78, 'last_n_outputs': 9, 'lr': 0.07634703789597547, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.09310918210622306}"}}
exception: None

03:09:09 job_callback for (0, 0, 1) started
03:09:09 job_callback for (0, 0, 1) got condition
03:09:09 DISPATCHER: Trying to submit another job.
03:09:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:09:09 Only 2 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
03:09:09 HBMASTER: Trying to run another job!
03:09:09 job_callback for (0, 0, 1) finished
03:09:09 start sampling a new configuration.
03:09:09 done sampling a new configuration.
03:09:09 HBMASTER: schedule new run for iteration 0
03:09:09 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
03:09:09 HBMASTER: submitting job (0, 0, 2) to dispatcher
03:09:09 DISPATCHER: trying to submit job (0, 0, 2)
03:09:09 DISPATCHER: trying to notify the job_runner thread.
03:09:09 HBMASTER: job (0, 0, 2) submitted to dispatcher
03:09:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:09:09 DISPATCHER: Trying to submit another job.
03:09:09 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:09:09 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:09:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:09:09 WORKER: start processing job (0, 0, 2)
03:09:09 WORKER: args: ()
03:09:09 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 31, 'last_n_outputs': 3, 'lr': 0.06548850836122232, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.03601147243859823}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:09:14 DISPATCHER: Starting worker discovery
03:09:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:09:14 DISPATCHER: Finished worker discovery
Exception in thread Thread-408:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:10:07 WORKER: done with job (0, 0, 2), trying to register it.
03:10:07 WORKER: registered result for job (0, 0, 2) with dispatcher
03:10:07 DISPATCHER: job (0, 0, 2) finished
03:10:07 DISPATCHER: register_result: lock acquired
03:10:07 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:10:07 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 31, 'last_n_outputs': 3, 'lr': 0.06548850836122232, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.03601147243859823}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.0028095926544030206, 'info': {'data04': -0.0028095926544030206, 'config': "{'batch_size': 128, 'hidden_dim': 31, 'last_n_outputs': 3, 'lr': 0.06548850836122232, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.03601147243859823}"}}
exception: None

03:10:07 job_callback for (0, 0, 2) started
03:10:07 DISPATCHER: Trying to submit another job.
03:10:07 job_callback for (0, 0, 2) got condition
03:10:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:10:07 Only 3 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
03:10:07 HBMASTER: Trying to run another job!
03:10:07 job_callback for (0, 0, 2) finished
03:10:07 start sampling a new configuration.
03:10:07 done sampling a new configuration.
03:10:07 HBMASTER: schedule new run for iteration 0
03:10:07 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
03:10:07 HBMASTER: submitting job (0, 0, 3) to dispatcher
03:10:07 DISPATCHER: trying to submit job (0, 0, 3)
03:10:07 DISPATCHER: trying to notify the job_runner thread.
03:10:07 HBMASTER: job (0, 0, 3) submitted to dispatcher
03:10:07 DISPATCHER: Trying to submit another job.
03:10:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:10:07 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:10:07 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:10:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:10:07 WORKER: start processing job (0, 0, 3)
03:10:07 WORKER: args: ()
03:10:07 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 69, 'last_n_outputs': 45, 'lr': 0.04271838800489833, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.06839987021472328}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:10:14 DISPATCHER: Starting worker discovery
03:10:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:10:14 DISPATCHER: Finished worker discovery
Exception in thread Thread-409:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:11:05 WORKER: done with job (0, 0, 3), trying to register it.
03:11:05 WORKER: registered result for job (0, 0, 3) with dispatcher
03:11:05 DISPATCHER: job (0, 0, 3) finished
03:11:05 DISPATCHER: register_result: lock acquired
03:11:05 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:11:05 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 69, 'last_n_outputs': 45, 'lr': 0.04271838800489833, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.06839987021472328}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 69, 'last_n_outputs': 45, 'lr': 0.04271838800489833, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.06839987021472328}"}}
exception: None

03:11:05 job_callback for (0, 0, 3) started
03:11:05 DISPATCHER: Trying to submit another job.
03:11:05 job_callback for (0, 0, 3) got condition
03:11:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:11:05 Only 4 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
03:11:05 HBMASTER: Trying to run another job!
03:11:05 job_callback for (0, 0, 3) finished
03:11:05 start sampling a new configuration.
03:11:05 done sampling a new configuration.
03:11:05 HBMASTER: schedule new run for iteration 0
03:11:05 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
03:11:05 HBMASTER: submitting job (0, 0, 4) to dispatcher
03:11:05 DISPATCHER: trying to submit job (0, 0, 4)
03:11:05 DISPATCHER: trying to notify the job_runner thread.
03:11:05 HBMASTER: job (0, 0, 4) submitted to dispatcher
03:11:05 DISPATCHER: Trying to submit another job.
03:11:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:11:05 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:11:05 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:11:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:11:05 WORKER: start processing job (0, 0, 4)
03:11:05 WORKER: args: ()
03:11:05 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 23, 'last_n_outputs': 22, 'lr': 0.044096441159888804, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.01725590571365359}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:11:14 DISPATCHER: Starting worker discovery
03:11:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:11:14 DISPATCHER: Finished worker discovery
Exception in thread Thread-410:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:12:02 WORKER: done with job (0, 0, 4), trying to register it.
03:12:02 WORKER: registered result for job (0, 0, 4) with dispatcher
03:12:02 DISPATCHER: job (0, 0, 4) finished
03:12:02 DISPATCHER: register_result: lock acquired
03:12:02 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:12:02 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 23, 'last_n_outputs': 22, 'lr': 0.044096441159888804, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.01725590571365359}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.003622556060562731, 'info': {'data04': -0.003622556060562731, 'config': "{'batch_size': 32, 'hidden_dim': 23, 'last_n_outputs': 22, 'lr': 0.044096441159888804, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.01725590571365359}"}}
exception: None

03:12:02 job_callback for (0, 0, 4) started
03:12:02 DISPATCHER: Trying to submit another job.
03:12:02 job_callback for (0, 0, 4) got condition
03:12:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:12:02 Only 5 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
03:12:02 HBMASTER: Trying to run another job!
03:12:02 job_callback for (0, 0, 4) finished
03:12:02 start sampling a new configuration.
03:12:02 done sampling a new configuration.
03:12:02 HBMASTER: schedule new run for iteration 0
03:12:02 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
03:12:02 HBMASTER: submitting job (0, 0, 5) to dispatcher
03:12:02 DISPATCHER: trying to submit job (0, 0, 5)
03:12:02 DISPATCHER: trying to notify the job_runner thread.
03:12:02 HBMASTER: job (0, 0, 5) submitted to dispatcher
03:12:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:12:02 DISPATCHER: Trying to submit another job.
03:12:02 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:12:02 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:12:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:12:02 WORKER: start processing job (0, 0, 5)
03:12:02 WORKER: args: ()
03:12:02 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 87, 'last_n_outputs': 18, 'lr': 0.008249611195936982, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.1078514492623631}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:12:14 DISPATCHER: Starting worker discovery
03:12:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:12:14 DISPATCHER: Finished worker discovery
Exception in thread Thread-411:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:13:00 WORKER: done with job (0, 0, 5), trying to register it.
03:13:00 WORKER: registered result for job (0, 0, 5) with dispatcher
03:13:00 DISPATCHER: job (0, 0, 5) finished
03:13:00 DISPATCHER: register_result: lock acquired
03:13:00 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:13:00 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 87, 'last_n_outputs': 18, 'lr': 0.008249611195936982, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.1078514492623631}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 87, 'last_n_outputs': 18, 'lr': 0.008249611195936982, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.1078514492623631}"}}
exception: None

03:13:00 job_callback for (0, 0, 5) started
03:13:00 job_callback for (0, 0, 5) got condition
03:13:00 DISPATCHER: Trying to submit another job.
03:13:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:13:00 Only 6 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
03:13:00 HBMASTER: Trying to run another job!
03:13:00 job_callback for (0, 0, 5) finished
03:13:00 start sampling a new configuration.
03:13:00 done sampling a new configuration.
03:13:00 HBMASTER: schedule new run for iteration 0
03:13:00 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
03:13:00 HBMASTER: submitting job (0, 0, 6) to dispatcher
03:13:00 DISPATCHER: trying to submit job (0, 0, 6)
03:13:00 DISPATCHER: trying to notify the job_runner thread.
03:13:00 HBMASTER: job (0, 0, 6) submitted to dispatcher
03:13:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:13:00 DISPATCHER: Trying to submit another job.
03:13:00 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:13:00 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:13:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:13:00 WORKER: start processing job (0, 0, 6)
03:13:00 WORKER: args: ()
03:13:00 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 65, 'last_n_outputs': 49, 'lr': 0.032822322185056284, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.17785821041451394}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:13:14 DISPATCHER: Starting worker discovery
03:13:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:13:14 DISPATCHER: Finished worker discovery
Exception in thread Thread-412:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:13:58 WORKER: done with job (0, 0, 6), trying to register it.
03:13:58 WORKER: registered result for job (0, 0, 6) with dispatcher
03:13:58 DISPATCHER: job (0, 0, 6) finished
03:13:58 DISPATCHER: register_result: lock acquired
03:13:58 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:13:58 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 65, 'last_n_outputs': 49, 'lr': 0.032822322185056284, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.17785821041451394}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.005089191670888493, 'info': {'data04': 0.005089191670888493, 'config': "{'batch_size': 16, 'hidden_dim': 65, 'last_n_outputs': 49, 'lr': 0.032822322185056284, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.17785821041451394}"}}
exception: None

03:13:58 job_callback for (0, 0, 6) started
03:13:58 DISPATCHER: Trying to submit another job.
03:13:58 job_callback for (0, 0, 6) got condition
03:13:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:13:58 Only 7 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
03:13:58 HBMASTER: Trying to run another job!
03:13:58 job_callback for (0, 0, 6) finished
03:13:58 start sampling a new configuration.
03:13:58 done sampling a new configuration.
03:13:58 HBMASTER: schedule new run for iteration 0
03:13:58 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
03:13:58 HBMASTER: submitting job (0, 0, 7) to dispatcher
03:13:58 DISPATCHER: trying to submit job (0, 0, 7)
03:13:58 DISPATCHER: trying to notify the job_runner thread.
03:13:58 HBMASTER: job (0, 0, 7) submitted to dispatcher
03:13:58 DISPATCHER: Trying to submit another job.
03:13:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:13:58 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:13:58 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:13:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:13:58 WORKER: start processing job (0, 0, 7)
03:13:58 WORKER: args: ()
03:13:58 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 47, 'last_n_outputs': 19, 'lr': 0.03974063331847549, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.058939623528897964}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-413:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:14:14 DISPATCHER: Starting worker discovery
03:14:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:14:14 DISPATCHER: Finished worker discovery
03:14:56 WORKER: done with job (0, 0, 7), trying to register it.
03:14:56 WORKER: registered result for job (0, 0, 7) with dispatcher
03:14:56 DISPATCHER: job (0, 0, 7) finished
03:14:56 DISPATCHER: register_result: lock acquired
03:14:56 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:14:56 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 47, 'last_n_outputs': 19, 'lr': 0.03974063331847549, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.058939623528897964}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 47, 'last_n_outputs': 19, 'lr': 0.03974063331847549, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.058939623528897964}"}}
exception: None

03:14:56 job_callback for (0, 0, 7) started
03:14:56 job_callback for (0, 0, 7) got condition
03:14:56 DISPATCHER: Trying to submit another job.
03:14:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:14:56 Only 8 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
03:14:56 HBMASTER: Trying to run another job!
03:14:56 job_callback for (0, 0, 7) finished
03:14:56 start sampling a new configuration.
03:14:56 done sampling a new configuration.
03:14:56 HBMASTER: schedule new run for iteration 0
03:14:56 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
03:14:56 HBMASTER: submitting job (0, 0, 8) to dispatcher
03:14:56 DISPATCHER: trying to submit job (0, 0, 8)
03:14:56 DISPATCHER: trying to notify the job_runner thread.
03:14:56 HBMASTER: job (0, 0, 8) submitted to dispatcher
03:14:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:14:56 DISPATCHER: Trying to submit another job.
03:14:56 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:14:56 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:14:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:14:56 WORKER: start processing job (0, 0, 8)
03:14:56 WORKER: args: ()
03:14:56 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 29, 'last_n_outputs': 14, 'lr': 0.005484206496202758, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.035947212655711755}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-414:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:15:14 DISPATCHER: Starting worker discovery
03:15:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:15:14 DISPATCHER: Finished worker discovery
03:15:53 WORKER: done with job (0, 0, 8), trying to register it.
03:15:53 WORKER: registered result for job (0, 0, 8) with dispatcher
03:15:53 DISPATCHER: job (0, 0, 8) finished
03:15:53 DISPATCHER: register_result: lock acquired
03:15:53 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:15:53 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 29, 'last_n_outputs': 14, 'lr': 0.005484206496202758, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.035947212655711755}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 29, 'last_n_outputs': 14, 'lr': 0.005484206496202758, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.035947212655711755}"}}
exception: None

03:15:53 job_callback for (0, 0, 8) started
03:15:53 job_callback for (0, 0, 8) got condition
03:15:53 DISPATCHER: Trying to submit another job.
03:15:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:15:53 HBMASTER: Trying to run another job!
03:15:53 job_callback for (0, 0, 8) finished
03:15:53 start sampling a new configuration.
03:15:53 done sampling a new configuration.
03:15:53 HBMASTER: schedule new run for iteration 0
03:15:53 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
03:15:53 HBMASTER: submitting job (0, 0, 9) to dispatcher
03:15:53 DISPATCHER: trying to submit job (0, 0, 9)
03:15:53 DISPATCHER: trying to notify the job_runner thread.
03:15:53 HBMASTER: job (0, 0, 9) submitted to dispatcher
03:15:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:15:53 DISPATCHER: Trying to submit another job.
03:15:53 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:15:53 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:15:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:15:53 WORKER: start processing job (0, 0, 9)
03:15:53 WORKER: args: ()
03:15:53 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 91, 'last_n_outputs': 20, 'lr': 0.0414558499345411, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.07109968633894358}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-415:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:16:14 DISPATCHER: Starting worker discovery
03:16:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:16:14 DISPATCHER: Finished worker discovery
03:16:51 WORKER: done with job (0, 0, 9), trying to register it.
03:16:51 WORKER: registered result for job (0, 0, 9) with dispatcher
03:16:51 DISPATCHER: job (0, 0, 9) finished
03:16:51 DISPATCHER: register_result: lock acquired
03:16:51 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:16:51 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 91, 'last_n_outputs': 20, 'lr': 0.0414558499345411, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.07109968633894358}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.00497118151461346, 'info': {'data04': 0.00497118151461346, 'config': "{'batch_size': 64, 'hidden_dim': 91, 'last_n_outputs': 20, 'lr': 0.0414558499345411, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.07109968633894358}"}}
exception: None

03:16:51 job_callback for (0, 0, 9) started
03:16:51 job_callback for (0, 0, 9) got condition
03:16:51 DISPATCHER: Trying to submit another job.
03:16:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:16:51 HBMASTER: Trying to run another job!
03:16:51 job_callback for (0, 0, 9) finished
03:16:51 start sampling a new configuration.
03:16:51 done sampling a new configuration.
03:16:51 HBMASTER: schedule new run for iteration 0
03:16:51 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
03:16:51 HBMASTER: submitting job (0, 0, 10) to dispatcher
03:16:51 DISPATCHER: trying to submit job (0, 0, 10)
03:16:51 DISPATCHER: trying to notify the job_runner thread.
03:16:51 HBMASTER: job (0, 0, 10) submitted to dispatcher
03:16:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:16:51 DISPATCHER: Trying to submit another job.
03:16:51 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:16:51 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:16:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:16:51 WORKER: start processing job (0, 0, 10)
03:16:51 WORKER: args: ()
03:16:51 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 41, 'last_n_outputs': 10, 'lr': 0.09947076111702233, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.11156926842084111}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-416:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:17:14 DISPATCHER: Starting worker discovery
03:17:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:17:14 DISPATCHER: Finished worker discovery
03:17:48 WORKER: done with job (0, 0, 10), trying to register it.
03:17:48 WORKER: registered result for job (0, 0, 10) with dispatcher
03:17:48 DISPATCHER: job (0, 0, 10) finished
03:17:48 DISPATCHER: register_result: lock acquired
03:17:48 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:17:48 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 41, 'last_n_outputs': 10, 'lr': 0.09947076111702233, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.11156926842084111}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 41, 'last_n_outputs': 10, 'lr': 0.09947076111702233, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.11156926842084111}"}}
exception: None

03:17:48 job_callback for (0, 0, 10) started
03:17:48 job_callback for (0, 0, 10) got condition
03:17:48 DISPATCHER: Trying to submit another job.
03:17:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:17:48 HBMASTER: Trying to run another job!
03:17:48 job_callback for (0, 0, 10) finished
03:17:48 start sampling a new configuration.
03:17:48 done sampling a new configuration.
03:17:48 HBMASTER: schedule new run for iteration 0
03:17:48 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
03:17:48 HBMASTER: submitting job (0, 0, 11) to dispatcher
03:17:48 DISPATCHER: trying to submit job (0, 0, 11)
03:17:48 DISPATCHER: trying to notify the job_runner thread.
03:17:48 HBMASTER: job (0, 0, 11) submitted to dispatcher
03:17:48 DISPATCHER: Trying to submit another job.
03:17:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:17:48 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:17:48 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:17:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:17:48 WORKER: start processing job (0, 0, 11)
03:17:48 WORKER: args: ()
03:17:48 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 36, 'last_n_outputs': 35, 'lr': 0.08263527894382779, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.10380612866384464}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-417:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:18:14 DISPATCHER: Starting worker discovery
03:18:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:18:14 DISPATCHER: Finished worker discovery
03:18:46 WORKER: done with job (0, 0, 11), trying to register it.
03:18:46 WORKER: registered result for job (0, 0, 11) with dispatcher
03:18:46 DISPATCHER: job (0, 0, 11) finished
03:18:46 DISPATCHER: register_result: lock acquired
03:18:46 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:18:46 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 36, 'last_n_outputs': 35, 'lr': 0.08263527894382779, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.10380612866384464}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 36, 'last_n_outputs': 35, 'lr': 0.08263527894382779, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.10380612866384464}"}}
exception: None

03:18:46 job_callback for (0, 0, 11) started
03:18:46 DISPATCHER: Trying to submit another job.
03:18:46 job_callback for (0, 0, 11) got condition
03:18:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:18:46 HBMASTER: Trying to run another job!
03:18:46 job_callback for (0, 0, 11) finished
03:18:46 start sampling a new configuration.
03:18:46 done sampling a new configuration.
03:18:46 HBMASTER: schedule new run for iteration 0
03:18:46 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
03:18:46 HBMASTER: submitting job (0, 0, 12) to dispatcher
03:18:46 DISPATCHER: trying to submit job (0, 0, 12)
03:18:46 DISPATCHER: trying to notify the job_runner thread.
03:18:46 HBMASTER: job (0, 0, 12) submitted to dispatcher
03:18:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:18:46 DISPATCHER: Trying to submit another job.
03:18:46 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:18:46 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:18:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:18:46 WORKER: start processing job (0, 0, 12)
03:18:46 WORKER: args: ()
03:18:46 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 73, 'last_n_outputs': 19, 'lr': 0.01338959635400126, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.0347981128153918}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-418:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:19:14 DISPATCHER: Starting worker discovery
03:19:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:19:14 DISPATCHER: Finished worker discovery
03:19:43 WORKER: done with job (0, 0, 12), trying to register it.
03:19:43 WORKER: registered result for job (0, 0, 12) with dispatcher
03:19:43 DISPATCHER: job (0, 0, 12) finished
03:19:43 DISPATCHER: register_result: lock acquired
03:19:43 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:19:43 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 73, 'last_n_outputs': 19, 'lr': 0.01338959635400126, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.0347981128153918}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.015992970757259774, 'info': {'data04': 0.015992970757259774, 'config': "{'batch_size': 128, 'hidden_dim': 73, 'last_n_outputs': 19, 'lr': 0.01338959635400126, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.0347981128153918}"}}
exception: None

03:19:43 job_callback for (0, 0, 12) started
03:19:43 DISPATCHER: Trying to submit another job.
03:19:43 job_callback for (0, 0, 12) got condition
03:19:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:19:43 HBMASTER: Trying to run another job!
03:19:43 job_callback for (0, 0, 12) finished
03:19:43 start sampling a new configuration.
03:19:43 done sampling a new configuration.
03:19:43 HBMASTER: schedule new run for iteration 0
03:19:43 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
03:19:43 HBMASTER: submitting job (0, 0, 13) to dispatcher
03:19:43 DISPATCHER: trying to submit job (0, 0, 13)
03:19:43 DISPATCHER: trying to notify the job_runner thread.
03:19:43 HBMASTER: job (0, 0, 13) submitted to dispatcher
03:19:43 DISPATCHER: Trying to submit another job.
03:19:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:19:43 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:19:43 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:19:43 WORKER: start processing job (0, 0, 13)
03:19:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:19:43 WORKER: args: ()
03:19:43 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 56, 'last_n_outputs': 25, 'lr': 0.032696725030361105, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.011551729131070457}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-419:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:20:14 DISPATCHER: Starting worker discovery
03:20:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:20:14 DISPATCHER: Finished worker discovery
03:20:40 WORKER: done with job (0, 0, 13), trying to register it.
03:20:40 WORKER: registered result for job (0, 0, 13) with dispatcher
03:20:40 DISPATCHER: job (0, 0, 13) finished
03:20:40 DISPATCHER: register_result: lock acquired
03:20:40 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:20:40 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 56, 'last_n_outputs': 25, 'lr': 0.032696725030361105, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.011551729131070457}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.029800978450953128, 'info': {'data04': 0.029800978450953128, 'config': "{'batch_size': 16, 'hidden_dim': 56, 'last_n_outputs': 25, 'lr': 0.032696725030361105, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.011551729131070457}"}}
exception: None

03:20:40 job_callback for (0, 0, 13) started
03:20:40 job_callback for (0, 0, 13) got condition
03:20:40 DISPATCHER: Trying to submit another job.
03:20:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:20:40 HBMASTER: Trying to run another job!
03:20:40 job_callback for (0, 0, 13) finished
03:20:40 start sampling a new configuration.
03:20:40 done sampling a new configuration.
03:20:40 HBMASTER: schedule new run for iteration 0
03:20:40 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
03:20:40 HBMASTER: submitting job (0, 0, 14) to dispatcher
03:20:40 DISPATCHER: trying to submit job (0, 0, 14)
03:20:40 DISPATCHER: trying to notify the job_runner thread.
03:20:40 HBMASTER: job (0, 0, 14) submitted to dispatcher
03:20:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:20:40 DISPATCHER: Trying to submit another job.
03:20:40 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:20:40 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:20:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:20:40 WORKER: start processing job (0, 0, 14)
03:20:40 WORKER: args: ()
03:20:40 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 68, 'last_n_outputs': 9, 'lr': 0.018086357057871743, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.012955334585108693}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-420:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:21:14 DISPATCHER: Starting worker discovery
03:21:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:21:14 DISPATCHER: Finished worker discovery
03:21:38 WORKER: done with job (0, 0, 14), trying to register it.
03:21:38 WORKER: registered result for job (0, 0, 14) with dispatcher
03:21:38 DISPATCHER: job (0, 0, 14) finished
03:21:38 DISPATCHER: register_result: lock acquired
03:21:38 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:21:38 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 68, 'last_n_outputs': 9, 'lr': 0.018086357057871743, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.012955334585108693}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 68, 'last_n_outputs': 9, 'lr': 0.018086357057871743, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.012955334585108693}"}}
exception: None

03:21:38 job_callback for (0, 0, 14) started
03:21:38 job_callback for (0, 0, 14) got condition
03:21:38 DISPATCHER: Trying to submit another job.
03:21:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:21:38 HBMASTER: Trying to run another job!
03:21:38 job_callback for (0, 0, 14) finished
03:21:38 start sampling a new configuration.
03:21:38 done sampling a new configuration.
03:21:38 HBMASTER: schedule new run for iteration 0
03:21:38 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
03:21:38 HBMASTER: submitting job (0, 0, 15) to dispatcher
03:21:38 DISPATCHER: trying to submit job (0, 0, 15)
03:21:38 DISPATCHER: trying to notify the job_runner thread.
03:21:38 HBMASTER: job (0, 0, 15) submitted to dispatcher
03:21:38 DISPATCHER: Trying to submit another job.
03:21:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:21:38 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:21:38 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:21:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:21:38 WORKER: start processing job (0, 0, 15)
03:21:38 WORKER: args: ()
03:21:38 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 54, 'last_n_outputs': 44, 'lr': 0.07638796899071958, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.0693905067074038}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-421:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:22:14 DISPATCHER: Starting worker discovery
03:22:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:22:14 DISPATCHER: Finished worker discovery
03:22:35 WORKER: done with job (0, 0, 15), trying to register it.
03:22:35 WORKER: registered result for job (0, 0, 15) with dispatcher
03:22:35 DISPATCHER: job (0, 0, 15) finished
03:22:35 DISPATCHER: register_result: lock acquired
03:22:35 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:22:35 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 54, 'last_n_outputs': 44, 'lr': 0.07638796899071958, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.0693905067074038}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 54, 'last_n_outputs': 44, 'lr': 0.07638796899071958, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.0693905067074038}"}}
exception: None

03:22:35 job_callback for (0, 0, 15) started
03:22:35 DISPATCHER: Trying to submit another job.
03:22:35 job_callback for (0, 0, 15) got condition
03:22:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:22:35 HBMASTER: Trying to run another job!
03:22:35 job_callback for (0, 0, 15) finished
03:22:35 start sampling a new configuration.
03:22:35 done sampling a new configuration.
03:22:35 HBMASTER: schedule new run for iteration 0
03:22:35 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
03:22:35 HBMASTER: submitting job (0, 0, 16) to dispatcher
03:22:35 DISPATCHER: trying to submit job (0, 0, 16)
03:22:35 DISPATCHER: trying to notify the job_runner thread.
03:22:35 HBMASTER: job (0, 0, 16) submitted to dispatcher
03:22:35 DISPATCHER: Trying to submit another job.
03:22:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:22:35 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:22:35 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:22:35 WORKER: start processing job (0, 0, 16)
03:22:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:22:35 WORKER: args: ()
03:22:35 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 39, 'lr': 0.0013142038407045625, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.0110432992365297}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-422:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:23:14 DISPATCHER: Starting worker discovery
03:23:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:23:14 DISPATCHER: Finished worker discovery
03:23:33 WORKER: done with job (0, 0, 16), trying to register it.
03:23:33 WORKER: registered result for job (0, 0, 16) with dispatcher
03:23:33 DISPATCHER: job (0, 0, 16) finished
03:23:33 DISPATCHER: register_result: lock acquired
03:23:33 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:23:33 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 39, 'lr': 0.0013142038407045625, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.0110432992365297}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.028970284409605116, 'info': {'data04': 0.028970284409605116, 'config': "{'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 39, 'lr': 0.0013142038407045625, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.0110432992365297}"}}
exception: None

03:23:33 job_callback for (0, 0, 16) started
03:23:33 job_callback for (0, 0, 16) got condition
03:23:33 DISPATCHER: Trying to submit another job.
03:23:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:23:33 HBMASTER: Trying to run another job!
03:23:33 job_callback for (0, 0, 16) finished
03:23:33 start sampling a new configuration.
03:23:33 done sampling a new configuration.
03:23:33 HBMASTER: schedule new run for iteration 0
03:23:33 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
03:23:33 HBMASTER: submitting job (0, 0, 17) to dispatcher
03:23:33 DISPATCHER: trying to submit job (0, 0, 17)
03:23:33 DISPATCHER: trying to notify the job_runner thread.
03:23:33 HBMASTER: job (0, 0, 17) submitted to dispatcher
03:23:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:23:33 DISPATCHER: Trying to submit another job.
03:23:33 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:23:33 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:23:33 WORKER: start processing job (0, 0, 17)
03:23:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:23:33 WORKER: args: ()
03:23:33 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 30, 'last_n_outputs': 32, 'lr': 0.01789942178361944, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.019116651470093254}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-423:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:24:14 DISPATCHER: Starting worker discovery
03:24:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:24:14 DISPATCHER: Finished worker discovery
03:24:30 WORKER: done with job (0, 0, 17), trying to register it.
03:24:30 WORKER: registered result for job (0, 0, 17) with dispatcher
03:24:30 DISPATCHER: job (0, 0, 17) finished
03:24:30 DISPATCHER: register_result: lock acquired
03:24:30 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:24:30 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 30, 'last_n_outputs': 32, 'lr': 0.01789942178361944, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.019116651470093254}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 30, 'last_n_outputs': 32, 'lr': 0.01789942178361944, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.019116651470093254}"}}
exception: None

03:24:30 job_callback for (0, 0, 17) started
03:24:30 job_callback for (0, 0, 17) got condition
03:24:30 DISPATCHER: Trying to submit another job.
03:24:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:24:30 done building a new model for budget 44.444444 based on 9/15 split
Best loss for this budget:-0.029801





03:24:30 HBMASTER: Trying to run another job!
03:24:30 job_callback for (0, 0, 17) finished
03:24:30 start sampling a new configuration.
03:24:30 done sampling a new configuration.
03:24:30 HBMASTER: schedule new run for iteration 0
03:24:30 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
03:24:30 HBMASTER: submitting job (0, 0, 18) to dispatcher
03:24:30 DISPATCHER: trying to submit job (0, 0, 18)
03:24:30 DISPATCHER: trying to notify the job_runner thread.
03:24:30 HBMASTER: job (0, 0, 18) submitted to dispatcher
03:24:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:24:30 DISPATCHER: Trying to submit another job.
03:24:30 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:24:30 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:24:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:24:30 WORKER: start processing job (0, 0, 18)
03:24:30 WORKER: args: ()
03:24:30 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 25, 'last_n_outputs': 40, 'lr': 0.06280814314595812, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.14577906736877014}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-424:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:25:14 DISPATCHER: Starting worker discovery
03:25:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:25:14 DISPATCHER: Finished worker discovery
03:25:27 WORKER: done with job (0, 0, 18), trying to register it.
03:25:27 WORKER: registered result for job (0, 0, 18) with dispatcher
03:25:27 DISPATCHER: job (0, 0, 18) finished
03:25:27 DISPATCHER: register_result: lock acquired
03:25:27 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:25:27 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 25, 'last_n_outputs': 40, 'lr': 0.06280814314595812, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.14577906736877014}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 25, 'last_n_outputs': 40, 'lr': 0.06280814314595812, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.14577906736877014}"}}
exception: None

03:25:27 job_callback for (0, 0, 18) started
03:25:27 job_callback for (0, 0, 18) got condition
03:25:27 DISPATCHER: Trying to submit another job.
03:25:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:25:27 done building a new model for budget 44.444444 based on 9/16 split
Best loss for this budget:-0.029801





03:25:27 HBMASTER: Trying to run another job!
03:25:27 job_callback for (0, 0, 18) finished
03:25:27 start sampling a new configuration.
03:25:28 best_vector: [3, 0.5542683662292196, 0.8393635908863992, 0.2750824106670718, 0.6396865923175532, 1, 0.47397209893560094, 0.7797005005769694], 1.487393841435009e-31, 0.06723168888713558, -0.00045768846837711166
03:25:28 done sampling a new configuration.
03:25:28 HBMASTER: schedule new run for iteration 0
03:25:28 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
03:25:28 HBMASTER: submitting job (0, 0, 19) to dispatcher
03:25:28 DISPATCHER: trying to submit job (0, 0, 19)
03:25:28 DISPATCHER: trying to notify the job_runner thread.
03:25:28 HBMASTER: job (0, 0, 19) submitted to dispatcher
03:25:28 DISPATCHER: Trying to submit another job.
03:25:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:25:28 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:25:28 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:25:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:25:28 WORKER: start processing job (0, 0, 19)
03:25:28 WORKER: args: ()
03:25:28 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 64, 'last_n_outputs': 42, 'lr': 0.0035494807184457936, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.10337457543300886}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-425:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:26:14 DISPATCHER: Starting worker discovery
03:26:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:26:14 DISPATCHER: Finished worker discovery
03:26:25 WORKER: done with job (0, 0, 19), trying to register it.
03:26:25 WORKER: registered result for job (0, 0, 19) with dispatcher
03:26:25 DISPATCHER: job (0, 0, 19) finished
03:26:25 DISPATCHER: register_result: lock acquired
03:26:25 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:26:25 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 64, 'last_n_outputs': 42, 'lr': 0.0035494807184457936, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.10337457543300886}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0015365521229065717, 'info': {'data04': 0.0015365521229065717, 'config': "{'batch_size': 128, 'hidden_dim': 64, 'last_n_outputs': 42, 'lr': 0.0035494807184457936, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.10337457543300886}"}}
exception: None

03:26:25 job_callback for (0, 0, 19) started
03:26:25 DISPATCHER: Trying to submit another job.
03:26:25 job_callback for (0, 0, 19) got condition
03:26:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:26:25 done building a new model for budget 44.444444 based on 9/17 split
Best loss for this budget:-0.029801





03:26:25 HBMASTER: Trying to run another job!
03:26:25 job_callback for (0, 0, 19) finished
03:26:25 start sampling a new configuration.
03:26:25 best_vector: [3, 0.4521916782443129, 0.5373172297260693, 0.42015468293976554, 0.26189863500809724, 1, 0.5685381281796521, 0.5578747658609313], 1.0042846642350029e-31, 0.09957336157888395, -0.0002636924863269632
03:26:25 done sampling a new configuration.
03:26:25 HBMASTER: schedule new run for iteration 0
03:26:25 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
03:26:25 HBMASTER: submitting job (0, 0, 20) to dispatcher
03:26:25 DISPATCHER: trying to submit job (0, 0, 20)
03:26:25 DISPATCHER: trying to notify the job_runner thread.
03:26:25 HBMASTER: job (0, 0, 20) submitted to dispatcher
03:26:25 DISPATCHER: Trying to submit another job.
03:26:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:26:25 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:26:25 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:26:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:26:25 WORKER: start processing job (0, 0, 20)
03:26:25 WORKER: args: ()
03:26:25 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 56, 'last_n_outputs': 27, 'lr': 0.006923239662357968, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.05318777271170285}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-426:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:27:14 DISPATCHER: Starting worker discovery
03:27:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:27:14 DISPATCHER: Finished worker discovery
03:27:23 WORKER: done with job (0, 0, 20), trying to register it.
03:27:23 WORKER: registered result for job (0, 0, 20) with dispatcher
03:27:23 DISPATCHER: job (0, 0, 20) finished
03:27:23 DISPATCHER: register_result: lock acquired
03:27:23 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:27:23 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 56, 'last_n_outputs': 27, 'lr': 0.006923239662357968, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.05318777271170285}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.013294931753868882, 'info': {'data04': -0.013294931753868882, 'config': "{'batch_size': 128, 'hidden_dim': 56, 'last_n_outputs': 27, 'lr': 0.006923239662357968, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.05318777271170285}"}}
exception: None

03:27:23 job_callback for (0, 0, 20) started
03:27:23 DISPATCHER: Trying to submit another job.
03:27:23 job_callback for (0, 0, 20) got condition
03:27:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:27:23 done building a new model for budget 44.444444 based on 9/17 split
Best loss for this budget:-0.029801





03:27:23 HBMASTER: Trying to run another job!
03:27:23 job_callback for (0, 0, 20) finished
03:27:23 start sampling a new configuration.
03:27:23 done sampling a new configuration.
03:27:23 HBMASTER: schedule new run for iteration 0
03:27:23 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
03:27:23 HBMASTER: submitting job (0, 0, 21) to dispatcher
03:27:23 DISPATCHER: trying to submit job (0, 0, 21)
03:27:23 DISPATCHER: trying to notify the job_runner thread.
03:27:23 HBMASTER: job (0, 0, 21) submitted to dispatcher
03:27:23 DISPATCHER: Trying to submit another job.
03:27:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:27:23 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:27:23 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:27:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:27:23 WORKER: start processing job (0, 0, 21)
03:27:23 WORKER: args: ()
03:27:23 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 27, 'last_n_outputs': 36, 'lr': 0.019605938627097176, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.05997918370493422}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-427:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:28:14 DISPATCHER: Starting worker discovery
03:28:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:28:14 DISPATCHER: Finished worker discovery
03:28:20 WORKER: done with job (0, 0, 21), trying to register it.
03:28:20 WORKER: registered result for job (0, 0, 21) with dispatcher
03:28:20 DISPATCHER: job (0, 0, 21) finished
03:28:20 DISPATCHER: register_result: lock acquired
03:28:20 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:28:20 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 27, 'last_n_outputs': 36, 'lr': 0.019605938627097176, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.05997918370493422}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 27, 'last_n_outputs': 36, 'lr': 0.019605938627097176, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.05997918370493422}"}}
exception: None

03:28:20 job_callback for (0, 0, 21) started
03:28:20 job_callback for (0, 0, 21) got condition
03:28:20 DISPATCHER: Trying to submit another job.
03:28:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:28:20 done building a new model for budget 44.444444 based on 9/18 split
Best loss for this budget:-0.029801





03:28:20 HBMASTER: Trying to run another job!
03:28:20 job_callback for (0, 0, 21) finished
03:28:20 start sampling a new configuration.
03:28:20 best_vector: [3, 0.4769961558963735, 0.8683378856795505, 0.46452890511879413, 0.48686445877737833, 1, 0.5345282280101248, 0.10068432158674834], 6.846952872219121e-32, 0.14605036994739773, -0.00021707889549766335
03:28:20 done sampling a new configuration.
03:28:20 HBMASTER: schedule new run for iteration 0
03:28:20 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
03:28:20 HBMASTER: submitting job (0, 0, 22) to dispatcher
03:28:20 DISPATCHER: trying to submit job (0, 0, 22)
03:28:20 DISPATCHER: trying to notify the job_runner thread.
03:28:20 HBMASTER: job (0, 0, 22) submitted to dispatcher
03:28:20 DISPATCHER: Trying to submit another job.
03:28:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:28:20 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:28:20 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:28:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:28:20 WORKER: start processing job (0, 0, 22)
03:28:20 WORKER: args: ()
03:28:20 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 58, 'last_n_outputs': 44, 'lr': 0.008492935195131716, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.013520517744759914}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-428:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:29:14 DISPATCHER: Starting worker discovery
03:29:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:29:14 DISPATCHER: Finished worker discovery
03:29:18 WORKER: done with job (0, 0, 22), trying to register it.
03:29:18 WORKER: registered result for job (0, 0, 22) with dispatcher
03:29:18 DISPATCHER: job (0, 0, 22) finished
03:29:18 DISPATCHER: register_result: lock acquired
03:29:18 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:29:18 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 58, 'last_n_outputs': 44, 'lr': 0.008492935195131716, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.013520517744759914}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.006356623723255511, 'info': {'data04': -0.006356623723255511, 'config': "{'batch_size': 128, 'hidden_dim': 58, 'last_n_outputs': 44, 'lr': 0.008492935195131716, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.013520517744759914}"}}
exception: None

03:29:18 job_callback for (0, 0, 22) started
03:29:18 DISPATCHER: Trying to submit another job.
03:29:18 job_callback for (0, 0, 22) got condition
03:29:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:29:18 done building a new model for budget 44.444444 based on 9/19 split
Best loss for this budget:-0.029801





03:29:18 HBMASTER: Trying to run another job!
03:29:18 job_callback for (0, 0, 22) finished
03:29:18 start sampling a new configuration.
03:29:18 done sampling a new configuration.
03:29:18 HBMASTER: schedule new run for iteration 0
03:29:18 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
03:29:18 HBMASTER: submitting job (0, 0, 23) to dispatcher
03:29:18 DISPATCHER: trying to submit job (0, 0, 23)
03:29:18 DISPATCHER: trying to notify the job_runner thread.
03:29:18 HBMASTER: job (0, 0, 23) submitted to dispatcher
03:29:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:29:18 DISPATCHER: Trying to submit another job.
03:29:18 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:29:18 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:29:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:29:18 WORKER: start processing job (0, 0, 23)
03:29:18 WORKER: args: ()
03:29:18 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 100, 'last_n_outputs': 3, 'lr': 0.029993286030346778, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.01306479141042787}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-429:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:30:14 DISPATCHER: Starting worker discovery
03:30:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:30:14 DISPATCHER: Finished worker discovery
03:30:15 WORKER: done with job (0, 0, 23), trying to register it.
03:30:15 WORKER: registered result for job (0, 0, 23) with dispatcher
03:30:15 DISPATCHER: job (0, 0, 23) finished
03:30:15 DISPATCHER: register_result: lock acquired
03:30:15 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:30:15 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 100, 'last_n_outputs': 3, 'lr': 0.029993286030346778, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.01306479141042787}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.012853442081668675, 'info': {'data04': 0.012853442081668675, 'config': "{'batch_size': 32, 'hidden_dim': 100, 'last_n_outputs': 3, 'lr': 0.029993286030346778, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.01306479141042787}"}}
exception: None

03:30:15 job_callback for (0, 0, 23) started
03:30:15 job_callback for (0, 0, 23) got condition
03:30:15 DISPATCHER: Trying to submit another job.
03:30:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:30:15 done building a new model for budget 44.444444 based on 9/20 split
Best loss for this budget:-0.029801





03:30:15 HBMASTER: Trying to run another job!
03:30:15 job_callback for (0, 0, 23) finished
03:30:15 start sampling a new configuration.
03:30:15 done sampling a new configuration.
03:30:15 HBMASTER: schedule new run for iteration 0
03:30:15 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
03:30:15 HBMASTER: submitting job (0, 0, 24) to dispatcher
03:30:15 DISPATCHER: trying to submit job (0, 0, 24)
03:30:15 DISPATCHER: trying to notify the job_runner thread.
03:30:15 HBMASTER: job (0, 0, 24) submitted to dispatcher
03:30:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:30:15 DISPATCHER: Trying to submit another job.
03:30:15 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:30:15 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:30:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:30:15 WORKER: start processing job (0, 0, 24)
03:30:15 WORKER: args: ()
03:30:15 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 42, 'last_n_outputs': 1, 'lr': 0.025115982738663382, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.03828169909844727}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-430:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:31:13 WORKER: done with job (0, 0, 24), trying to register it.
03:31:13 WORKER: registered result for job (0, 0, 24) with dispatcher
03:31:13 DISPATCHER: job (0, 0, 24) finished
03:31:13 DISPATCHER: register_result: lock acquired
03:31:13 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:31:13 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 42, 'last_n_outputs': 1, 'lr': 0.025115982738663382, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.03828169909844727}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 42, 'last_n_outputs': 1, 'lr': 0.025115982738663382, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.03828169909844727}"}}
exception: None

03:31:13 job_callback for (0, 0, 24) started
03:31:13 DISPATCHER: Trying to submit another job.
03:31:13 job_callback for (0, 0, 24) got condition
03:31:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:31:13 done building a new model for budget 44.444444 based on 9/21 split
Best loss for this budget:-0.029801





03:31:13 HBMASTER: Trying to run another job!
03:31:13 job_callback for (0, 0, 24) finished
03:31:13 start sampling a new configuration.
03:31:13 best_vector: [2, 0.915672627783551, 0.07905030170340056, 0.4913491487952202, 0.01924586275641714, 0, 0.3453054236159193, 0.22203689964113038], 0.0016663930940764473, 0.19717756203490105, 0.0003285753276817894
03:31:13 done sampling a new configuration.
03:31:13 HBMASTER: schedule new run for iteration 0
03:31:13 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
03:31:13 HBMASTER: submitting job (0, 0, 25) to dispatcher
03:31:13 DISPATCHER: trying to submit job (0, 0, 25)
03:31:13 DISPATCHER: trying to notify the job_runner thread.
03:31:13 HBMASTER: job (0, 0, 25) submitted to dispatcher
03:31:13 DISPATCHER: Trying to submit another job.
03:31:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:31:13 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:31:13 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:31:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:31:13 WORKER: start processing job (0, 0, 25)
03:31:13 WORKER: args: ()
03:31:13 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 4, 'lr': 0.009609444826734172, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.019448077056143615}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:31:14 DISPATCHER: Starting worker discovery
03:31:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:31:14 DISPATCHER: Finished worker discovery
Exception in thread Thread-431:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:32:10 WORKER: done with job (0, 0, 25), trying to register it.
03:32:10 WORKER: registered result for job (0, 0, 25) with dispatcher
03:32:10 DISPATCHER: job (0, 0, 25) finished
03:32:10 DISPATCHER: register_result: lock acquired
03:32:10 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:32:10 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 4, 'lr': 0.009609444826734172, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.019448077056143615}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.06117407811338175, 'info': {'data04': 0.06117407811338175, 'config': "{'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 4, 'lr': 0.009609444826734172, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.019448077056143615}"}}
exception: None

03:32:10 job_callback for (0, 0, 25) started
03:32:10 job_callback for (0, 0, 25) got condition
03:32:10 DISPATCHER: Trying to submit another job.
03:32:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:32:10 done building a new model for budget 44.444444 based on 9/22 split
Best loss for this budget:-0.061174





03:32:10 HBMASTER: Trying to run another job!
03:32:10 job_callback for (0, 0, 25) finished
03:32:10 start sampling a new configuration.
03:32:10 done sampling a new configuration.
03:32:10 HBMASTER: schedule new run for iteration 0
03:32:10 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
03:32:10 HBMASTER: submitting job (0, 0, 26) to dispatcher
03:32:10 DISPATCHER: trying to submit job (0, 0, 26)
03:32:10 DISPATCHER: trying to notify the job_runner thread.
03:32:10 HBMASTER: job (0, 0, 26) submitted to dispatcher
03:32:10 DISPATCHER: Trying to submit another job.
03:32:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:32:10 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:32:10 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:32:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:32:10 WORKER: start processing job (0, 0, 26)
03:32:10 WORKER: args: ()
03:32:10 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 40, 'last_n_outputs': 7, 'lr': 0.01671934973665884, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.10989877728804885}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:32:14 DISPATCHER: Starting worker discovery
03:32:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:32:14 DISPATCHER: Finished worker discovery
Exception in thread Thread-432:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:33:08 WORKER: done with job (0, 0, 26), trying to register it.
03:33:08 WORKER: registered result for job (0, 0, 26) with dispatcher
03:33:08 DISPATCHER: job (0, 0, 26) finished
03:33:08 DISPATCHER: register_result: lock acquired
03:33:08 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:33:08 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 40, 'last_n_outputs': 7, 'lr': 0.01671934973665884, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.10989877728804885}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 40, 'last_n_outputs': 7, 'lr': 0.01671934973665884, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.10989877728804885}"}}
exception: None

03:33:08 job_callback for (0, 0, 26) started
03:33:08 job_callback for (0, 0, 26) got condition
03:33:08 DISPATCHER: Trying to submit another job.
03:33:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:33:08 done building a new model for budget 44.444444 based on 9/22 split
Best loss for this budget:-0.061174





03:33:08 HBMASTER: Trying to run another job!
03:33:08 job_callback for (0, 0, 26) finished
03:33:08 ITERATION: Advancing config (0, 0, 0) to next budget 133.333333
03:33:08 ITERATION: Advancing config (0, 0, 1) to next budget 133.333333
03:33:08 ITERATION: Advancing config (0, 0, 6) to next budget 133.333333
03:33:08 ITERATION: Advancing config (0, 0, 9) to next budget 133.333333
03:33:08 ITERATION: Advancing config (0, 0, 12) to next budget 133.333333
03:33:08 ITERATION: Advancing config (0, 0, 13) to next budget 133.333333
03:33:08 ITERATION: Advancing config (0, 0, 16) to next budget 133.333333
03:33:08 ITERATION: Advancing config (0, 0, 23) to next budget 133.333333
03:33:08 ITERATION: Advancing config (0, 0, 25) to next budget 133.333333
03:33:08 HBMASTER: schedule new run for iteration 0
03:33:08 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
03:33:08 HBMASTER: submitting job (0, 0, 0) to dispatcher
03:33:08 DISPATCHER: trying to submit job (0, 0, 0)
03:33:08 DISPATCHER: trying to notify the job_runner thread.
03:33:08 HBMASTER: job (0, 0, 0) submitted to dispatcher
03:33:08 DISPATCHER: Trying to submit another job.
03:33:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:33:08 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:33:08 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:33:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:33:08 WORKER: start processing job (0, 0, 0)
03:33:08 WORKER: args: ()
03:33:08 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 49, 'last_n_outputs': 46, 'lr': 0.021502265204905394, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.05213590289670609}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:33:14 DISPATCHER: Starting worker discovery
03:33:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:33:14 DISPATCHER: Finished worker discovery
Exception in thread Thread-433:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:34:14 DISPATCHER: Starting worker discovery
03:34:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:34:14 DISPATCHER: Finished worker discovery
03:35:14 DISPATCHER: Starting worker discovery
03:35:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:35:15 DISPATCHER: Finished worker discovery
03:35:34 WORKER: done with job (0, 0, 0), trying to register it.
03:35:34 WORKER: registered result for job (0, 0, 0) with dispatcher
03:35:34 DISPATCHER: job (0, 0, 0) finished
03:35:34 DISPATCHER: register_result: lock acquired
03:35:34 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:35:34 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 49, 'last_n_outputs': 46, 'lr': 0.021502265204905394, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.05213590289670609}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.008288853761107138, 'info': {'data04': 0.008288853761107138, 'config': "{'batch_size': 32, 'hidden_dim': 49, 'last_n_outputs': 46, 'lr': 0.021502265204905394, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.05213590289670609}"}}
exception: None

03:35:34 job_callback for (0, 0, 0) started
03:35:34 DISPATCHER: Trying to submit another job.
03:35:34 job_callback for (0, 0, 0) got condition
03:35:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:35:34 Only 1 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
03:35:34 HBMASTER: Trying to run another job!
03:35:34 job_callback for (0, 0, 0) finished
03:35:34 HBMASTER: schedule new run for iteration 0
03:35:34 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
03:35:34 HBMASTER: submitting job (0, 0, 1) to dispatcher
03:35:34 DISPATCHER: trying to submit job (0, 0, 1)
03:35:34 DISPATCHER: trying to notify the job_runner thread.
03:35:34 HBMASTER: job (0, 0, 1) submitted to dispatcher
03:35:34 DISPATCHER: Trying to submit another job.
03:35:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:35:34 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:35:34 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:35:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:35:34 WORKER: start processing job (0, 0, 1)
03:35:34 WORKER: args: ()
03:35:34 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 78, 'last_n_outputs': 9, 'lr': 0.07634703789597547, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.09310918210622306}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-434:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:36:15 DISPATCHER: Starting worker discovery
03:36:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:36:15 DISPATCHER: Finished worker discovery
03:37:15 DISPATCHER: Starting worker discovery
03:37:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:37:15 DISPATCHER: Finished worker discovery
03:38:00 WORKER: done with job (0, 0, 1), trying to register it.
03:38:00 WORKER: registered result for job (0, 0, 1) with dispatcher
03:38:00 DISPATCHER: job (0, 0, 1) finished
03:38:00 DISPATCHER: register_result: lock acquired
03:38:00 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:38:00 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 78, 'last_n_outputs': 9, 'lr': 0.07634703789597547, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.09310918210622306}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.005442287795082961, 'info': {'data04': 0.005442287795082961, 'config': "{'batch_size': 64, 'hidden_dim': 78, 'last_n_outputs': 9, 'lr': 0.07634703789597547, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.09310918210622306}"}}
exception: None

03:38:00 job_callback for (0, 0, 1) started
03:38:00 DISPATCHER: Trying to submit another job.
03:38:00 job_callback for (0, 0, 1) got condition
03:38:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:38:00 Only 2 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
03:38:00 HBMASTER: Trying to run another job!
03:38:00 job_callback for (0, 0, 1) finished
03:38:00 HBMASTER: schedule new run for iteration 0
03:38:00 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
03:38:00 HBMASTER: submitting job (0, 0, 6) to dispatcher
03:38:00 DISPATCHER: trying to submit job (0, 0, 6)
03:38:00 DISPATCHER: trying to notify the job_runner thread.
03:38:00 HBMASTER: job (0, 0, 6) submitted to dispatcher
03:38:00 DISPATCHER: Trying to submit another job.
03:38:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:38:00 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:38:00 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:38:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:38:00 WORKER: start processing job (0, 0, 6)
03:38:00 WORKER: args: ()
03:38:00 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 65, 'last_n_outputs': 49, 'lr': 0.032822322185056284, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.17785821041451394}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-435:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:38:15 DISPATCHER: Starting worker discovery
03:38:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:38:15 DISPATCHER: Finished worker discovery
03:39:15 DISPATCHER: Starting worker discovery
03:39:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:39:15 DISPATCHER: Finished worker discovery
03:40:15 DISPATCHER: Starting worker discovery
03:40:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:40:15 DISPATCHER: Finished worker discovery
03:40:27 WORKER: done with job (0, 0, 6), trying to register it.
03:40:27 WORKER: registered result for job (0, 0, 6) with dispatcher
03:40:27 DISPATCHER: job (0, 0, 6) finished
03:40:27 DISPATCHER: register_result: lock acquired
03:40:27 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:40:27 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 65, 'last_n_outputs': 49, 'lr': 0.032822322185056284, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.17785821041451394}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.011389444507430567, 'info': {'data04': 0.011389444507430567, 'config': "{'batch_size': 16, 'hidden_dim': 65, 'last_n_outputs': 49, 'lr': 0.032822322185056284, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.17785821041451394}"}}
exception: None

03:40:27 job_callback for (0, 0, 6) started
03:40:27 DISPATCHER: Trying to submit another job.
03:40:27 job_callback for (0, 0, 6) got condition
03:40:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:40:27 Only 3 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
03:40:27 HBMASTER: Trying to run another job!
03:40:27 job_callback for (0, 0, 6) finished
03:40:27 HBMASTER: schedule new run for iteration 0
03:40:27 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
03:40:27 HBMASTER: submitting job (0, 0, 9) to dispatcher
03:40:27 DISPATCHER: trying to submit job (0, 0, 9)
03:40:27 DISPATCHER: trying to notify the job_runner thread.
03:40:27 HBMASTER: job (0, 0, 9) submitted to dispatcher
03:40:27 DISPATCHER: Trying to submit another job.
03:40:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:40:27 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:40:27 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:40:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:40:27 WORKER: start processing job (0, 0, 9)
03:40:27 WORKER: args: ()
03:40:27 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 91, 'last_n_outputs': 20, 'lr': 0.0414558499345411, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.07109968633894358}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-436:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:41:15 DISPATCHER: Starting worker discovery
03:41:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:41:15 DISPATCHER: Finished worker discovery
03:42:15 DISPATCHER: Starting worker discovery
03:42:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:42:15 DISPATCHER: Finished worker discovery
03:42:55 WORKER: done with job (0, 0, 9), trying to register it.
03:42:55 WORKER: registered result for job (0, 0, 9) with dispatcher
03:42:55 DISPATCHER: job (0, 0, 9) finished
03:42:55 DISPATCHER: register_result: lock acquired
03:42:55 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:42:55 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 91, 'last_n_outputs': 20, 'lr': 0.0414558499345411, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.07109968633894358}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.011108086923954288, 'info': {'data04': 0.011108086923954288, 'config': "{'batch_size': 64, 'hidden_dim': 91, 'last_n_outputs': 20, 'lr': 0.0414558499345411, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.07109968633894358}"}}
exception: None

03:42:55 job_callback for (0, 0, 9) started
03:42:55 DISPATCHER: Trying to submit another job.
03:42:55 job_callback for (0, 0, 9) got condition
03:42:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:42:55 Only 4 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
03:42:55 HBMASTER: Trying to run another job!
03:42:55 job_callback for (0, 0, 9) finished
03:42:55 HBMASTER: schedule new run for iteration 0
03:42:55 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
03:42:55 HBMASTER: submitting job (0, 0, 12) to dispatcher
03:42:55 DISPATCHER: trying to submit job (0, 0, 12)
03:42:55 DISPATCHER: trying to notify the job_runner thread.
03:42:55 HBMASTER: job (0, 0, 12) submitted to dispatcher
03:42:55 DISPATCHER: Trying to submit another job.
03:42:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:42:55 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:42:55 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:42:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:42:55 WORKER: start processing job (0, 0, 12)
03:42:55 WORKER: args: ()
03:42:55 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 73, 'last_n_outputs': 19, 'lr': 0.01338959635400126, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.0347981128153918}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-437:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:43:15 DISPATCHER: Starting worker discovery
03:43:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:43:15 DISPATCHER: Finished worker discovery
03:44:15 DISPATCHER: Starting worker discovery
03:44:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:44:15 DISPATCHER: Finished worker discovery
03:45:15 DISPATCHER: Starting worker discovery
03:45:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:45:15 DISPATCHER: Finished worker discovery
03:45:22 WORKER: done with job (0, 0, 12), trying to register it.
03:45:22 WORKER: registered result for job (0, 0, 12) with dispatcher
03:45:22 DISPATCHER: job (0, 0, 12) finished
03:45:22 DISPATCHER: register_result: lock acquired
03:45:22 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:45:22 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 73, 'last_n_outputs': 19, 'lr': 0.01338959635400126, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.0347981128153918}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': 0.007172900938308709, 'info': {'data04': -0.007172900938308709, 'config': "{'batch_size': 128, 'hidden_dim': 73, 'last_n_outputs': 19, 'lr': 0.01338959635400126, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.0347981128153918}"}}
exception: None

03:45:22 job_callback for (0, 0, 12) started
03:45:22 DISPATCHER: Trying to submit another job.
03:45:22 job_callback for (0, 0, 12) got condition
03:45:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:45:22 Only 5 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
03:45:22 HBMASTER: Trying to run another job!
03:45:22 job_callback for (0, 0, 12) finished
03:45:22 HBMASTER: schedule new run for iteration 0
03:45:22 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
03:45:22 HBMASTER: submitting job (0, 0, 13) to dispatcher
03:45:22 DISPATCHER: trying to submit job (0, 0, 13)
03:45:22 DISPATCHER: trying to notify the job_runner thread.
03:45:22 HBMASTER: job (0, 0, 13) submitted to dispatcher
03:45:22 DISPATCHER: Trying to submit another job.
03:45:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:45:22 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:45:22 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:45:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:45:22 WORKER: start processing job (0, 0, 13)
03:45:22 WORKER: args: ()
03:45:22 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 56, 'last_n_outputs': 25, 'lr': 0.032696725030361105, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.011551729131070457}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-438:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:46:15 DISPATCHER: Starting worker discovery
03:46:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:46:15 DISPATCHER: Finished worker discovery
03:47:15 DISPATCHER: Starting worker discovery
03:47:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:47:15 DISPATCHER: Finished worker discovery
03:47:48 WORKER: done with job (0, 0, 13), trying to register it.
03:47:48 WORKER: registered result for job (0, 0, 13) with dispatcher
03:47:48 DISPATCHER: job (0, 0, 13) finished
03:47:48 DISPATCHER: register_result: lock acquired
03:47:48 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:47:48 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 56, 'last_n_outputs': 25, 'lr': 0.032696725030361105, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.011551729131070457}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.04849468546553499, 'info': {'data04': 0.04849468546553499, 'config': "{'batch_size': 16, 'hidden_dim': 56, 'last_n_outputs': 25, 'lr': 0.032696725030361105, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.011551729131070457}"}}
exception: None

03:47:48 job_callback for (0, 0, 13) started
03:47:48 job_callback for (0, 0, 13) got condition
03:47:48 DISPATCHER: Trying to submit another job.
03:47:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:47:48 Only 6 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
03:47:48 HBMASTER: Trying to run another job!
03:47:48 job_callback for (0, 0, 13) finished
03:47:48 HBMASTER: schedule new run for iteration 0
03:47:48 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
03:47:48 HBMASTER: submitting job (0, 0, 16) to dispatcher
03:47:48 DISPATCHER: trying to submit job (0, 0, 16)
03:47:48 DISPATCHER: trying to notify the job_runner thread.
03:47:48 HBMASTER: job (0, 0, 16) submitted to dispatcher
03:47:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:47:48 DISPATCHER: Trying to submit another job.
03:47:48 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:47:48 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:47:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:47:48 WORKER: start processing job (0, 0, 16)
03:47:48 WORKER: args: ()
03:47:48 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 39, 'lr': 0.0013142038407045625, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.0110432992365297}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-439:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:48:15 DISPATCHER: Starting worker discovery
03:48:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:48:15 DISPATCHER: Finished worker discovery
03:49:15 DISPATCHER: Starting worker discovery
03:49:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:49:15 DISPATCHER: Finished worker discovery
03:50:15 DISPATCHER: Starting worker discovery
03:50:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:50:15 DISPATCHER: Finished worker discovery
03:50:15 WORKER: done with job (0, 0, 16), trying to register it.
03:50:15 WORKER: registered result for job (0, 0, 16) with dispatcher
03:50:15 DISPATCHER: job (0, 0, 16) finished
03:50:15 DISPATCHER: register_result: lock acquired
03:50:15 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:50:15 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 39, 'lr': 0.0013142038407045625, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.0110432992365297}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.021381175100549776, 'info': {'data04': 0.021381175100549776, 'config': "{'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 39, 'lr': 0.0013142038407045625, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.0110432992365297}"}}
exception: None

03:50:15 job_callback for (0, 0, 16) started
03:50:15 DISPATCHER: Trying to submit another job.
03:50:15 job_callback for (0, 0, 16) got condition
03:50:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:50:15 Only 7 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
03:50:15 HBMASTER: Trying to run another job!
03:50:15 job_callback for (0, 0, 16) finished
03:50:15 HBMASTER: schedule new run for iteration 0
03:50:15 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
03:50:15 HBMASTER: submitting job (0, 0, 23) to dispatcher
03:50:15 DISPATCHER: trying to submit job (0, 0, 23)
03:50:15 DISPATCHER: trying to notify the job_runner thread.
03:50:15 HBMASTER: job (0, 0, 23) submitted to dispatcher
03:50:15 DISPATCHER: Trying to submit another job.
03:50:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:50:15 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:50:15 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:50:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:50:15 WORKER: start processing job (0, 0, 23)
03:50:15 WORKER: args: ()
03:50:15 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 100, 'last_n_outputs': 3, 'lr': 0.029993286030346778, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.01306479141042787}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-440:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:51:15 DISPATCHER: Starting worker discovery
03:51:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:51:15 DISPATCHER: Finished worker discovery
03:52:15 DISPATCHER: Starting worker discovery
03:52:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:52:15 DISPATCHER: Finished worker discovery
03:52:41 WORKER: done with job (0, 0, 23), trying to register it.
03:52:41 WORKER: registered result for job (0, 0, 23) with dispatcher
03:52:41 DISPATCHER: job (0, 0, 23) finished
03:52:41 DISPATCHER: register_result: lock acquired
03:52:41 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:52:41 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 100, 'last_n_outputs': 3, 'lr': 0.029993286030346778, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.01306479141042787}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.015630954789496162, 'info': {'data04': 0.015630954789496162, 'config': "{'batch_size': 32, 'hidden_dim': 100, 'last_n_outputs': 3, 'lr': 0.029993286030346778, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.01306479141042787}"}}
exception: None

03:52:41 job_callback for (0, 0, 23) started
03:52:41 job_callback for (0, 0, 23) got condition
03:52:41 DISPATCHER: Trying to submit another job.
03:52:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:52:41 Only 8 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
03:52:41 HBMASTER: Trying to run another job!
03:52:41 job_callback for (0, 0, 23) finished
03:52:41 HBMASTER: schedule new run for iteration 0
03:52:41 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
03:52:41 HBMASTER: submitting job (0, 0, 25) to dispatcher
03:52:41 DISPATCHER: trying to submit job (0, 0, 25)
03:52:41 DISPATCHER: trying to notify the job_runner thread.
03:52:41 HBMASTER: job (0, 0, 25) submitted to dispatcher
03:52:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:52:41 DISPATCHER: Trying to submit another job.
03:52:41 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:52:41 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:52:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:52:41 WORKER: start processing job (0, 0, 25)
03:52:41 WORKER: args: ()
03:52:41 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 4, 'lr': 0.009609444826734172, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.019448077056143615}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-441:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:53:15 DISPATCHER: Starting worker discovery
03:53:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:53:15 DISPATCHER: Finished worker discovery
03:54:15 DISPATCHER: Starting worker discovery
03:54:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:54:15 DISPATCHER: Finished worker discovery
03:55:09 WORKER: done with job (0, 0, 25), trying to register it.
03:55:09 WORKER: registered result for job (0, 0, 25) with dispatcher
03:55:09 DISPATCHER: job (0, 0, 25) finished
03:55:09 DISPATCHER: register_result: lock acquired
03:55:09 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:55:09 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 4, 'lr': 0.009609444826734172, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.019448077056143615}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.07827829152090925, 'info': {'data04': 0.07827829152090925, 'config': "{'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 4, 'lr': 0.009609444826734172, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.019448077056143615}"}}
exception: None

03:55:09 job_callback for (0, 0, 25) started
03:55:09 job_callback for (0, 0, 25) got condition
03:55:09 DISPATCHER: Trying to submit another job.
03:55:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:55:09 HBMASTER: Trying to run another job!
03:55:09 job_callback for (0, 0, 25) finished
03:55:09 ITERATION: Advancing config (0, 0, 13) to next budget 400.000000
03:55:09 ITERATION: Advancing config (0, 0, 16) to next budget 400.000000
03:55:09 ITERATION: Advancing config (0, 0, 25) to next budget 400.000000
03:55:09 HBMASTER: schedule new run for iteration 0
03:55:09 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
03:55:09 HBMASTER: submitting job (0, 0, 13) to dispatcher
03:55:09 DISPATCHER: trying to submit job (0, 0, 13)
03:55:09 DISPATCHER: trying to notify the job_runner thread.
03:55:09 HBMASTER: job (0, 0, 13) submitted to dispatcher
03:55:09 DISPATCHER: Trying to submit another job.
03:55:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:55:09 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:55:09 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:55:09 WORKER: start processing job (0, 0, 13)
03:55:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:55:09 WORKER: args: ()
03:55:10 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 56, 'last_n_outputs': 25, 'lr': 0.032696725030361105, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.011551729131070457}, 'budget': 400.0, 'working_directory': '.'}
03:55:15 DISPATCHER: Starting worker discovery
03:55:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:55:15 DISPATCHER: Finished worker discovery
Exception in thread Thread-442:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:56:15 DISPATCHER: Starting worker discovery
03:56:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:56:15 DISPATCHER: Finished worker discovery
03:57:15 DISPATCHER: Starting worker discovery
03:57:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:57:15 DISPATCHER: Finished worker discovery
03:58:15 DISPATCHER: Starting worker discovery
03:58:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:58:15 DISPATCHER: Finished worker discovery
03:59:15 DISPATCHER: Starting worker discovery
03:59:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:59:15 DISPATCHER: Finished worker discovery
04:00:15 DISPATCHER: Starting worker discovery
04:00:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:00:15 DISPATCHER: Finished worker discovery
04:01:15 DISPATCHER: Starting worker discovery
04:01:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:01:15 DISPATCHER: Finished worker discovery
04:02:02 WORKER: done with job (0, 0, 13), trying to register it.
04:02:02 WORKER: registered result for job (0, 0, 13) with dispatcher
04:02:02 DISPATCHER: job (0, 0, 13) finished
04:02:02 DISPATCHER: register_result: lock acquired
04:02:02 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:02:02 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 56, 'last_n_outputs': 25, 'lr': 0.032696725030361105, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.011551729131070457}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.031191302126462473, 'info': {'data04': 0.031191302126462473, 'config': "{'batch_size': 16, 'hidden_dim': 56, 'last_n_outputs': 25, 'lr': 0.032696725030361105, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.011551729131070457}"}}
exception: None

04:02:02 job_callback for (0, 0, 13) started
04:02:02 DISPATCHER: Trying to submit another job.
04:02:02 job_callback for (0, 0, 13) got condition
04:02:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:02:02 Only 1 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
04:02:02 HBMASTER: Trying to run another job!
04:02:02 job_callback for (0, 0, 13) finished
04:02:02 HBMASTER: schedule new run for iteration 0
04:02:02 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
04:02:02 HBMASTER: submitting job (0, 0, 16) to dispatcher
04:02:02 DISPATCHER: trying to submit job (0, 0, 16)
04:02:02 DISPATCHER: trying to notify the job_runner thread.
04:02:02 HBMASTER: job (0, 0, 16) submitted to dispatcher
04:02:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:02:02 DISPATCHER: Trying to submit another job.
04:02:02 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:02:02 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:02:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:02:02 WORKER: start processing job (0, 0, 16)
04:02:02 WORKER: args: ()
04:02:02 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 39, 'lr': 0.0013142038407045625, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.0110432992365297}, 'budget': 400.0, 'working_directory': '.'}
04:02:15 DISPATCHER: Starting worker discovery
04:02:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:02:15 DISPATCHER: Finished worker discovery
Exception in thread Thread-443:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:03:15 DISPATCHER: Starting worker discovery
04:03:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:03:15 DISPATCHER: Finished worker discovery
04:04:15 DISPATCHER: Starting worker discovery
04:04:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:04:15 DISPATCHER: Finished worker discovery
04:05:15 DISPATCHER: Starting worker discovery
04:05:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:05:15 DISPATCHER: Finished worker discovery
04:06:15 DISPATCHER: Starting worker discovery
04:06:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:06:15 DISPATCHER: Finished worker discovery
04:07:15 DISPATCHER: Starting worker discovery
04:07:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:07:15 DISPATCHER: Finished worker discovery
04:08:15 DISPATCHER: Starting worker discovery
04:08:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:08:15 DISPATCHER: Finished worker discovery
04:08:57 WORKER: done with job (0, 0, 16), trying to register it.
04:08:57 WORKER: registered result for job (0, 0, 16) with dispatcher
04:08:57 DISPATCHER: job (0, 0, 16) finished
04:08:57 DISPATCHER: register_result: lock acquired
04:08:57 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:08:57 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 39, 'lr': 0.0013142038407045625, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.0110432992365297}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.018158521241021984, 'info': {'data04': 0.018158521241021984, 'config': "{'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 39, 'lr': 0.0013142038407045625, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.0110432992365297}"}}
exception: None

04:08:57 job_callback for (0, 0, 16) started
04:08:57 job_callback for (0, 0, 16) got condition
04:08:57 DISPATCHER: Trying to submit another job.
04:08:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:08:57 Only 2 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
04:08:57 HBMASTER: Trying to run another job!
04:08:57 job_callback for (0, 0, 16) finished
04:08:57 HBMASTER: schedule new run for iteration 0
04:08:57 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
04:08:57 HBMASTER: submitting job (0, 0, 25) to dispatcher
04:08:57 DISPATCHER: trying to submit job (0, 0, 25)
04:08:57 DISPATCHER: trying to notify the job_runner thread.
04:08:57 HBMASTER: job (0, 0, 25) submitted to dispatcher
04:08:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:08:57 DISPATCHER: Trying to submit another job.
04:08:57 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:08:57 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:08:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:08:57 WORKER: start processing job (0, 0, 25)
04:08:57 WORKER: args: ()
04:08:57 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 4, 'lr': 0.009609444826734172, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.019448077056143615}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-444:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:09:15 DISPATCHER: Starting worker discovery
04:09:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:09:15 DISPATCHER: Finished worker discovery
04:10:15 DISPATCHER: Starting worker discovery
04:10:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:10:15 DISPATCHER: Finished worker discovery
04:11:15 DISPATCHER: Starting worker discovery
04:11:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:11:15 DISPATCHER: Finished worker discovery
04:12:15 DISPATCHER: Starting worker discovery
04:12:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:12:15 DISPATCHER: Finished worker discovery
04:13:15 DISPATCHER: Starting worker discovery
04:13:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:13:15 DISPATCHER: Finished worker discovery
04:14:15 DISPATCHER: Starting worker discovery
04:14:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:14:15 DISPATCHER: Finished worker discovery
04:15:15 DISPATCHER: Starting worker discovery
04:15:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:15:15 DISPATCHER: Finished worker discovery
04:15:51 WORKER: done with job (0, 0, 25), trying to register it.
04:15:51 WORKER: registered result for job (0, 0, 25) with dispatcher
04:15:51 DISPATCHER: job (0, 0, 25) finished
04:15:51 DISPATCHER: register_result: lock acquired
04:15:51 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:15:51 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 4, 'lr': 0.009609444826734172, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.019448077056143615}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.05244877619395632, 'info': {'data04': 0.05244877619395632, 'config': "{'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 4, 'lr': 0.009609444826734172, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.019448077056143615}"}}
exception: None

04:15:51 job_callback for (0, 0, 25) started
04:15:51 job_callback for (0, 0, 25) got condition
04:15:51 DISPATCHER: Trying to submit another job.
04:15:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:15:51 Only 3 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
04:15:51 HBMASTER: Trying to run another job!
04:15:51 job_callback for (0, 0, 25) finished
04:15:51 ITERATION: Advancing config (0, 0, 25) to next budget 1200.000000
04:15:51 HBMASTER: schedule new run for iteration 0
04:15:51 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
04:15:51 HBMASTER: submitting job (0, 0, 25) to dispatcher
04:15:51 DISPATCHER: trying to submit job (0, 0, 25)
04:15:51 DISPATCHER: trying to notify the job_runner thread.
04:15:51 HBMASTER: job (0, 0, 25) submitted to dispatcher
04:15:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:15:51 DISPATCHER: Trying to submit another job.
04:15:51 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:15:51 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:15:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:15:51 WORKER: start processing job (0, 0, 25)
04:15:51 WORKER: args: ()
04:15:51 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 4, 'lr': 0.009609444826734172, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.019448077056143615}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-445:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:16:15 DISPATCHER: Starting worker discovery
04:16:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:16:15 DISPATCHER: Finished worker discovery
04:17:15 DISPATCHER: Starting worker discovery
04:17:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:17:15 DISPATCHER: Finished worker discovery
04:18:15 DISPATCHER: Starting worker discovery
04:18:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:18:15 DISPATCHER: Finished worker discovery
04:19:15 DISPATCHER: Starting worker discovery
04:19:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:19:15 DISPATCHER: Finished worker discovery
04:20:15 DISPATCHER: Starting worker discovery
04:20:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:20:15 DISPATCHER: Finished worker discovery
04:21:15 DISPATCHER: Starting worker discovery
04:21:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:21:15 DISPATCHER: Finished worker discovery
04:22:15 DISPATCHER: Starting worker discovery
04:22:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:22:15 DISPATCHER: Finished worker discovery
04:23:15 DISPATCHER: Starting worker discovery
04:23:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:23:15 DISPATCHER: Finished worker discovery
04:24:15 DISPATCHER: Starting worker discovery
04:24:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:24:15 DISPATCHER: Finished worker discovery
04:25:15 DISPATCHER: Starting worker discovery
04:25:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:25:15 DISPATCHER: Finished worker discovery
04:26:15 DISPATCHER: Starting worker discovery
04:26:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:26:15 DISPATCHER: Finished worker discovery
04:27:15 DISPATCHER: Starting worker discovery
04:27:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:27:15 DISPATCHER: Finished worker discovery
04:28:15 DISPATCHER: Starting worker discovery
04:28:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:28:15 DISPATCHER: Finished worker discovery
04:29:15 DISPATCHER: Starting worker discovery
04:29:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:29:15 DISPATCHER: Finished worker discovery
04:30:15 DISPATCHER: Starting worker discovery
04:30:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:30:15 DISPATCHER: Finished worker discovery
04:31:15 DISPATCHER: Starting worker discovery
04:31:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:31:15 DISPATCHER: Finished worker discovery
04:32:15 DISPATCHER: Starting worker discovery
04:32:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:32:15 DISPATCHER: Finished worker discovery
04:33:15 DISPATCHER: Starting worker discovery
04:33:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:33:15 DISPATCHER: Finished worker discovery
04:34:15 DISPATCHER: Starting worker discovery
04:34:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:34:15 DISPATCHER: Finished worker discovery
04:35:15 DISPATCHER: Starting worker discovery
04:35:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:35:15 DISPATCHER: Finished worker discovery
04:36:04 WORKER: done with job (0, 0, 25), trying to register it.
04:36:04 WORKER: registered result for job (0, 0, 25) with dispatcher
04:36:04 DISPATCHER: job (0, 0, 25) finished
04:36:04 DISPATCHER: register_result: lock acquired
04:36:04 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:36:04 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 4, 'lr': 0.009609444826734172, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.019448077056143615}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.02469525106785287, 'info': {'data04': 0.02469525106785287, 'config': "{'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 4, 'lr': 0.009609444826734172, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.019448077056143615}"}}
exception: None

04:36:04 job_callback for (0, 0, 25) started
04:36:04 job_callback for (0, 0, 25) got condition
04:36:04 DISPATCHER: Trying to submit another job.
04:36:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:36:04 Only 1 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
04:36:04 HBMASTER: Trying to run another job!
04:36:04 job_callback for (0, 0, 25) finished
04:36:04 start sampling a new configuration.
04:36:04 done sampling a new configuration.
04:36:04 HBMASTER: schedule new run for iteration 1
04:36:04 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
04:36:04 HBMASTER: submitting job (1, 0, 0) to dispatcher
04:36:04 DISPATCHER: trying to submit job (1, 0, 0)
04:36:04 DISPATCHER: trying to notify the job_runner thread.
04:36:04 HBMASTER: job (1, 0, 0) submitted to dispatcher
04:36:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:36:04 DISPATCHER: Trying to submit another job.
04:36:04 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:36:04 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:36:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:36:04 WORKER: start processing job (1, 0, 0)
04:36:04 WORKER: args: ()
04:36:04 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 55, 'last_n_outputs': 14, 'lr': 0.01326421037522204, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.048275779386594615}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:36:15 DISPATCHER: Starting worker discovery
04:36:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:36:15 DISPATCHER: Finished worker discovery
Exception in thread Thread-446:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:37:15 DISPATCHER: Starting worker discovery
04:37:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:37:15 DISPATCHER: Finished worker discovery
04:38:15 DISPATCHER: Starting worker discovery
04:38:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:38:15 DISPATCHER: Finished worker discovery
04:38:31 WORKER: done with job (1, 0, 0), trying to register it.
04:38:31 WORKER: registered result for job (1, 0, 0) with dispatcher
04:38:31 DISPATCHER: job (1, 0, 0) finished
04:38:31 DISPATCHER: register_result: lock acquired
04:38:31 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:38:31 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 55, 'last_n_outputs': 14, 'lr': 0.01326421037522204, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.048275779386594615}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.010930319574413691, 'info': {'data04': 0.010930319574413691, 'config': "{'batch_size': 32, 'hidden_dim': 55, 'last_n_outputs': 14, 'lr': 0.01326421037522204, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.048275779386594615}"}}
exception: None

04:38:31 job_callback for (1, 0, 0) started
04:38:31 DISPATCHER: Trying to submit another job.
04:38:31 job_callback for (1, 0, 0) got condition
04:38:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:38:31 HBMASTER: Trying to run another job!
04:38:31 job_callback for (1, 0, 0) finished
04:38:31 start sampling a new configuration.
04:38:31 best_vector: [3, 0.6694520419064862, 0.661262085332941, 0.025560370724583836, 0.16252223982052794, 0, 0.9888863240628373, 0.015012667584169526], 4.915893822970375e-05, 0.3168032258672111, 1.5573710211377116e-05
04:38:31 done sampling a new configuration.
04:38:31 HBMASTER: schedule new run for iteration 1
04:38:31 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
04:38:31 HBMASTER: submitting job (1, 0, 1) to dispatcher
04:38:31 DISPATCHER: trying to submit job (1, 0, 1)
04:38:31 DISPATCHER: trying to notify the job_runner thread.
04:38:31 HBMASTER: job (1, 0, 1) submitted to dispatcher
04:38:31 DISPATCHER: Trying to submit another job.
04:38:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:38:31 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:38:31 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:38:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:38:31 WORKER: start processing job (1, 0, 1)
04:38:31 WORKER: args: ()
04:38:31 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 74, 'last_n_outputs': 34, 'lr': 0.0011249176772528443, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.010460005932404322}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-447:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:39:15 DISPATCHER: Starting worker discovery
04:39:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:39:15 DISPATCHER: Finished worker discovery
04:40:15 DISPATCHER: Starting worker discovery
04:40:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:40:15 DISPATCHER: Finished worker discovery
04:40:58 WORKER: done with job (1, 0, 1), trying to register it.
04:40:58 WORKER: registered result for job (1, 0, 1) with dispatcher
04:40:58 DISPATCHER: job (1, 0, 1) finished
04:40:58 DISPATCHER: register_result: lock acquired
04:40:58 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:40:58 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 74, 'last_n_outputs': 34, 'lr': 0.0011249176772528443, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.010460005932404322}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.19064481292129914, 'info': {'data04': 0.19064481292129914, 'config': "{'batch_size': 128, 'hidden_dim': 74, 'last_n_outputs': 34, 'lr': 0.0011249176772528443, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.010460005932404322}"}}
exception: None

04:40:58 job_callback for (1, 0, 1) started
04:40:58 DISPATCHER: Trying to submit another job.
04:40:58 job_callback for (1, 0, 1) got condition
04:40:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:40:58 HBMASTER: Trying to run another job!
04:40:58 job_callback for (1, 0, 1) finished
04:40:58 start sampling a new configuration.
04:40:58 best_vector: [3, 0.8639394875073165, 0.04221737117248969, 0.9036932917719667, 0.1765587870768649, 1, 0.15185619887276314, 0.41206948705682833], 0.00016733871661940117, 0.3912252574279022, 6.546713248708e-05
04:40:58 done sampling a new configuration.
04:40:58 HBMASTER: schedule new run for iteration 1
04:40:58 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
04:40:58 HBMASTER: submitting job (1, 0, 2) to dispatcher
04:40:58 DISPATCHER: trying to submit job (1, 0, 2)
04:40:58 DISPATCHER: trying to notify the job_runner thread.
04:40:58 HBMASTER: job (1, 0, 2) submitted to dispatcher
04:40:58 DISPATCHER: Trying to submit another job.
04:40:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:40:58 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:40:58 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:40:58 WORKER: start processing job (1, 0, 2)
04:40:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:40:58 WORKER: args: ()
04:40:58 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 89, 'last_n_outputs': 3, 'lr': 0.06417805979501821, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.034364874559162824}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-448:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:41:15 DISPATCHER: Starting worker discovery
04:41:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:41:15 DISPATCHER: Finished worker discovery
04:42:15 DISPATCHER: Starting worker discovery
04:42:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:42:15 DISPATCHER: Finished worker discovery
04:43:15 DISPATCHER: Starting worker discovery
04:43:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:43:15 DISPATCHER: Finished worker discovery
04:43:25 WORKER: done with job (1, 0, 2), trying to register it.
04:43:25 WORKER: registered result for job (1, 0, 2) with dispatcher
04:43:25 DISPATCHER: job (1, 0, 2) finished
04:43:25 DISPATCHER: register_result: lock acquired
04:43:25 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:43:25 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 89, 'last_n_outputs': 3, 'lr': 0.06417805979501821, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.034364874559162824}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.003248557049323732, 'info': {'data04': 0.003248557049323732, 'config': "{'batch_size': 128, 'hidden_dim': 89, 'last_n_outputs': 3, 'lr': 0.06417805979501821, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.034364874559162824}"}}
exception: None

04:43:25 job_callback for (1, 0, 2) started
04:43:25 job_callback for (1, 0, 2) got condition
04:43:25 DISPATCHER: Trying to submit another job.
04:43:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:43:25 HBMASTER: Trying to run another job!
04:43:25 job_callback for (1, 0, 2) finished
04:43:25 start sampling a new configuration.
04:43:25 best_vector: [1, 0.9886358735868434, 0.17021595842818077, 0.06463217907303465, 0.034087366360121094, 0, 0.04643814189438518, 0.09498723485332365], 1.8950610295575357e-05, 0.03164077343527315, 5.996119668224545e-07
04:43:25 done sampling a new configuration.
04:43:25 HBMASTER: schedule new run for iteration 1
04:43:25 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
04:43:25 HBMASTER: submitting job (1, 0, 3) to dispatcher
04:43:25 DISPATCHER: trying to submit job (1, 0, 3)
04:43:25 DISPATCHER: trying to notify the job_runner thread.
04:43:25 HBMASTER: job (1, 0, 3) submitted to dispatcher
04:43:25 DISPATCHER: Trying to submit another job.
04:43:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:43:25 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:43:25 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:43:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:43:25 WORKER: start processing job (1, 0, 3)
04:43:25 WORKER: args: ()
04:43:25 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 100, 'last_n_outputs': 9, 'lr': 0.0013466798382321613, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.013291721768486944}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-449:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:44:15 DISPATCHER: Starting worker discovery
04:44:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:44:15 DISPATCHER: Finished worker discovery
04:45:15 DISPATCHER: Starting worker discovery
04:45:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:45:15 DISPATCHER: Finished worker discovery
04:45:51 WORKER: done with job (1, 0, 3), trying to register it.
04:45:51 WORKER: registered result for job (1, 0, 3) with dispatcher
04:45:51 DISPATCHER: job (1, 0, 3) finished
04:45:51 DISPATCHER: register_result: lock acquired
04:45:51 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:45:51 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 100, 'last_n_outputs': 9, 'lr': 0.0013466798382321613, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.013291721768486944}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.05548750174932704, 'info': {'data04': 0.05548750174932704, 'config': "{'batch_size': 32, 'hidden_dim': 100, 'last_n_outputs': 9, 'lr': 0.0013466798382321613, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.013291721768486944}"}}
exception: None

04:45:51 job_callback for (1, 0, 3) started
04:45:51 job_callback for (1, 0, 3) got condition
04:45:51 DISPATCHER: Trying to submit another job.
04:45:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:45:51 HBMASTER: Trying to run another job!
04:45:51 job_callback for (1, 0, 3) finished
04:45:51 start sampling a new configuration.
04:45:51 best_vector: [3, 0.8237672689772481, 0.2756113228146514, 0.8465349974137105, 0.0024311642438417658, 1, 0.2964772964556858, 0.6757250633639701], 0.00022750251081369387, 0.3411278193077948, 7.76074354009234e-05
04:45:51 done sampling a new configuration.
04:45:51 HBMASTER: schedule new run for iteration 1
04:45:51 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
04:45:51 HBMASTER: submitting job (1, 0, 4) to dispatcher
04:45:51 DISPATCHER: trying to submit job (1, 0, 4)
04:45:51 DISPATCHER: trying to notify the job_runner thread.
04:45:51 HBMASTER: job (1, 0, 4) submitted to dispatcher
04:45:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:45:51 DISPATCHER: Trying to submit another job.
04:45:51 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:45:51 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:45:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:45:51 WORKER: start processing job (1, 0, 4)
04:45:51 WORKER: args: ()
04:45:51 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 86, 'last_n_outputs': 14, 'lr': 0.04932532947120863, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.07570744265384735}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-450:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:46:15 DISPATCHER: Starting worker discovery
04:46:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:46:15 DISPATCHER: Finished worker discovery
04:47:15 DISPATCHER: Starting worker discovery
04:47:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:47:15 DISPATCHER: Finished worker discovery
04:48:15 DISPATCHER: Starting worker discovery
04:48:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:48:15 DISPATCHER: Finished worker discovery
04:48:18 WORKER: done with job (1, 0, 4), trying to register it.
04:48:18 WORKER: registered result for job (1, 0, 4) with dispatcher
04:48:18 DISPATCHER: job (1, 0, 4) finished
04:48:18 DISPATCHER: register_result: lock acquired
04:48:18 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:48:18 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 86, 'last_n_outputs': 14, 'lr': 0.04932532947120863, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.07570744265384735}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.02995398267951349, 'info': {'data04': 0.02995398267951349, 'config': "{'batch_size': 128, 'hidden_dim': 86, 'last_n_outputs': 14, 'lr': 0.04932532947120863, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.07570744265384735}"}}
exception: None

04:48:18 job_callback for (1, 0, 4) started
04:48:18 DISPATCHER: Trying to submit another job.
04:48:18 job_callback for (1, 0, 4) got condition
04:48:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:48:18 HBMASTER: Trying to run another job!
04:48:18 job_callback for (1, 0, 4) finished
04:48:18 start sampling a new configuration.
04:48:18 best_vector: [3, 0.9471818445638053, 0.5539216957954755, 0.691690862412669, 0.16678570551808358, 1, 0.6958992687583676, 0.5709356416495633], 0.003146415608792972, 0.1635534495898906, 0.0005146071266615663
04:48:18 done sampling a new configuration.
04:48:18 HBMASTER: schedule new run for iteration 1
04:48:18 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
04:48:18 HBMASTER: submitting job (1, 0, 5) to dispatcher
04:48:18 DISPATCHER: trying to submit job (1, 0, 5)
04:48:18 DISPATCHER: trying to notify the job_runner thread.
04:48:18 HBMASTER: job (1, 0, 5) submitted to dispatcher
04:48:18 DISPATCHER: Trying to submit another job.
04:48:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:48:18 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:48:18 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:48:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:48:18 WORKER: start processing job (1, 0, 5)
04:48:18 WORKER: args: ()
04:48:18 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 96, 'last_n_outputs': 28, 'lr': 0.024175848464650075, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.05531009385004957}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-451:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:49:15 DISPATCHER: Starting worker discovery
04:49:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:49:15 DISPATCHER: Finished worker discovery
04:50:15 DISPATCHER: Starting worker discovery
04:50:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:50:15 DISPATCHER: Finished worker discovery
04:50:45 WORKER: done with job (1, 0, 5), trying to register it.
04:50:45 WORKER: registered result for job (1, 0, 5) with dispatcher
04:50:45 DISPATCHER: job (1, 0, 5) finished
04:50:45 DISPATCHER: register_result: lock acquired
04:50:45 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:50:45 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 96, 'last_n_outputs': 28, 'lr': 0.024175848464650075, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.05531009385004957}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.053411397230211155, 'info': {'data04': 0.053411397230211155, 'config': "{'batch_size': 128, 'hidden_dim': 96, 'last_n_outputs': 28, 'lr': 0.024175848464650075, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.05531009385004957}"}}
exception: None

04:50:45 job_callback for (1, 0, 5) started
04:50:45 DISPATCHER: Trying to submit another job.
04:50:45 job_callback for (1, 0, 5) got condition
04:50:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:50:45 HBMASTER: Trying to run another job!
04:50:45 job_callback for (1, 0, 5) finished
04:50:45 start sampling a new configuration.
04:50:45 best_vector: [2, 0.8865316943615322, 0.017659221614551857, 0.8079736646952663, 0.061795520730835524, 1, 0.03821954749243034, 0.5632125255386838], 0.0006268477143992039, 0.23417586102522003, 0.00014679260325112478
04:50:45 done sampling a new configuration.
04:50:45 HBMASTER: schedule new run for iteration 1
04:50:45 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
04:50:45 HBMASTER: submitting job (1, 0, 6) to dispatcher
04:50:45 DISPATCHER: trying to submit job (1, 0, 6)
04:50:45 DISPATCHER: trying to notify the job_runner thread.
04:50:45 HBMASTER: job (1, 0, 6) submitted to dispatcher
04:50:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:50:45 DISPATCHER: Trying to submit another job.
04:50:45 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:50:45 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:50:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:50:45 WORKER: start processing job (1, 0, 6)
04:50:45 WORKER: args: ()
04:50:45 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 91, 'last_n_outputs': 1, 'lr': 0.04129974112213562, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.054045108076703076}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-452:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:51:15 DISPATCHER: Starting worker discovery
04:51:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:51:15 DISPATCHER: Finished worker discovery
04:52:15 DISPATCHER: Starting worker discovery
04:52:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:52:15 DISPATCHER: Finished worker discovery
04:53:11 WORKER: done with job (1, 0, 6), trying to register it.
04:53:11 WORKER: registered result for job (1, 0, 6) with dispatcher
04:53:11 DISPATCHER: job (1, 0, 6) finished
04:53:11 DISPATCHER: register_result: lock acquired
04:53:11 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:53:11 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 91, 'last_n_outputs': 1, 'lr': 0.04129974112213562, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.054045108076703076}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': 0.0020617534475891857, 'info': {'data04': -0.0020617534475891857, 'config': "{'batch_size': 64, 'hidden_dim': 91, 'last_n_outputs': 1, 'lr': 0.04129974112213562, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.054045108076703076}"}}
exception: None

04:53:11 job_callback for (1, 0, 6) started
04:53:11 DISPATCHER: Trying to submit another job.
04:53:11 job_callback for (1, 0, 6) got condition
04:53:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:53:11 HBMASTER: Trying to run another job!
04:53:11 job_callback for (1, 0, 6) finished
04:53:11 start sampling a new configuration.
04:53:11 best_vector: [0, 0.9582009414537022, 0.2637607780854614, 0.4414154829358621, 0.015430759581696901, 1, 0.6660991162232326, 0.055883271093588684], 0.0018920743740161966, 0.10302940760096892, 0.00019493930189186284
04:53:11 done sampling a new configuration.
04:53:11 HBMASTER: schedule new run for iteration 1
04:53:11 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
04:53:11 HBMASTER: submitting job (1, 0, 7) to dispatcher
04:53:11 DISPATCHER: trying to submit job (1, 0, 7)
04:53:11 DISPATCHER: trying to notify the job_runner thread.
04:53:11 HBMASTER: job (1, 0, 7) submitted to dispatcher
04:53:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:53:11 DISPATCHER: Trying to submit another job.
04:53:11 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:53:11 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:53:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:53:11 WORKER: start processing job (1, 0, 7)
04:53:11 WORKER: args: ()
04:53:11 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 97, 'last_n_outputs': 14, 'lr': 0.0076353854472751585, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.01182240442995614}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:53:15 DISPATCHER: Starting worker discovery
04:53:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:53:15 DISPATCHER: Finished worker discovery
Exception in thread Thread-453:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:54:15 DISPATCHER: Starting worker discovery
04:54:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:54:15 DISPATCHER: Finished worker discovery
04:55:15 DISPATCHER: Starting worker discovery
04:55:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:55:15 DISPATCHER: Finished worker discovery
04:55:39 WORKER: done with job (1, 0, 7), trying to register it.
04:55:39 WORKER: registered result for job (1, 0, 7) with dispatcher
04:55:39 DISPATCHER: job (1, 0, 7) finished
04:55:39 DISPATCHER: register_result: lock acquired
04:55:39 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:55:39 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 97, 'last_n_outputs': 14, 'lr': 0.0076353854472751585, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.01182240442995614}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.001642755634129396, 'info': {'data04': 0.001642755634129396, 'config': "{'batch_size': 16, 'hidden_dim': 97, 'last_n_outputs': 14, 'lr': 0.0076353854472751585, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.01182240442995614}"}}
exception: None

04:55:39 job_callback for (1, 0, 7) started
04:55:39 job_callback for (1, 0, 7) got condition
04:55:39 DISPATCHER: Trying to submit another job.
04:55:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:55:39 HBMASTER: Trying to run another job!
04:55:39 job_callback for (1, 0, 7) finished
04:55:39 start sampling a new configuration.
04:55:39 best_vector: [3, 0.9128837783892221, 0.33240988355278944, 0.7419629709866277, 0.2041224419571185, 1, 0.982926169818155, 0.25068710834529256], 0.00511652509822862, 0.022343498412412774, 0.00011432107040934127
04:55:39 done sampling a new configuration.
04:55:39 HBMASTER: schedule new run for iteration 1
04:55:39 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
04:55:39 HBMASTER: submitting job (1, 0, 8) to dispatcher
04:55:39 DISPATCHER: trying to submit job (1, 0, 8)
04:55:39 DISPATCHER: trying to notify the job_runner thread.
04:55:39 HBMASTER: job (1, 0, 8) submitted to dispatcher
04:55:39 DISPATCHER: Trying to submit another job.
04:55:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:55:39 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:55:39 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:55:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:55:39 WORKER: start processing job (1, 0, 8)
04:55:39 WORKER: args: ()
04:55:39 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 17, 'lr': 0.0304737529192603, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.021190999804821056}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-454:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:56:15 DISPATCHER: Starting worker discovery
04:56:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:56:15 DISPATCHER: Finished worker discovery
04:57:15 DISPATCHER: Starting worker discovery
04:57:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:57:15 DISPATCHER: Finished worker discovery
04:58:05 WORKER: done with job (1, 0, 8), trying to register it.
04:58:05 WORKER: registered result for job (1, 0, 8) with dispatcher
04:58:05 DISPATCHER: job (1, 0, 8) finished
04:58:05 DISPATCHER: register_result: lock acquired
04:58:05 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:58:05 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 17, 'lr': 0.0304737529192603, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.021190999804821056}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.02401368326700665, 'info': {'data04': 0.02401368326700665, 'config': "{'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 17, 'lr': 0.0304737529192603, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.021190999804821056}"}}
exception: None

04:58:05 job_callback for (1, 0, 8) started
04:58:05 DISPATCHER: Trying to submit another job.
04:58:05 job_callback for (1, 0, 8) got condition
04:58:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:58:05 done building a new model for budget 133.333333 based on 9/15 split
Best loss for this budget:-0.190645





04:58:05 HBMASTER: Trying to run another job!
04:58:05 job_callback for (1, 0, 8) finished
04:58:05 ITERATION: Advancing config (1, 0, 1) to next budget 400.000000
04:58:05 ITERATION: Advancing config (1, 0, 3) to next budget 400.000000
04:58:05 ITERATION: Advancing config (1, 0, 5) to next budget 400.000000
04:58:05 HBMASTER: schedule new run for iteration 1
04:58:05 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
04:58:05 HBMASTER: submitting job (1, 0, 1) to dispatcher
04:58:05 DISPATCHER: trying to submit job (1, 0, 1)
04:58:05 DISPATCHER: trying to notify the job_runner thread.
04:58:05 HBMASTER: job (1, 0, 1) submitted to dispatcher
04:58:05 DISPATCHER: Trying to submit another job.
04:58:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:58:05 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:58:05 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:58:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:58:05 WORKER: start processing job (1, 0, 1)
04:58:05 WORKER: args: ()
04:58:05 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 74, 'last_n_outputs': 34, 'lr': 0.0011249176772528443, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.010460005932404322}, 'budget': 400.0, 'working_directory': '.'}
04:58:15 DISPATCHER: Starting worker discovery
04:58:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:58:15 DISPATCHER: Finished worker discovery
Exception in thread Thread-455:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:59:15 DISPATCHER: Starting worker discovery
04:59:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:59:15 DISPATCHER: Finished worker discovery
05:00:15 DISPATCHER: Starting worker discovery
05:00:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:00:15 DISPATCHER: Finished worker discovery
05:01:15 DISPATCHER: Starting worker discovery
05:01:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:01:15 DISPATCHER: Finished worker discovery
05:02:15 DISPATCHER: Starting worker discovery
05:02:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:02:15 DISPATCHER: Finished worker discovery
05:03:15 DISPATCHER: Starting worker discovery
05:03:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:03:15 DISPATCHER: Finished worker discovery
05:04:15 DISPATCHER: Starting worker discovery
05:04:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:04:15 DISPATCHER: Finished worker discovery
05:04:58 WORKER: done with job (1, 0, 1), trying to register it.
05:04:58 WORKER: registered result for job (1, 0, 1) with dispatcher
05:04:58 DISPATCHER: job (1, 0, 1) finished
05:04:58 DISPATCHER: register_result: lock acquired
05:04:58 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
05:04:58 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 74, 'last_n_outputs': 34, 'lr': 0.0011249176772528443, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.010460005932404322}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.18318109584176764, 'info': {'data04': 0.18318109584176764, 'config': "{'batch_size': 128, 'hidden_dim': 74, 'last_n_outputs': 34, 'lr': 0.0011249176772528443, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.010460005932404322}"}}
exception: None

05:04:58 job_callback for (1, 0, 1) started
05:04:58 DISPATCHER: Trying to submit another job.
05:04:58 job_callback for (1, 0, 1) got condition
05:04:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:04:58 Only 4 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
05:04:58 HBMASTER: Trying to run another job!
05:04:58 job_callback for (1, 0, 1) finished
05:04:58 HBMASTER: schedule new run for iteration 1
05:04:58 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
05:04:58 HBMASTER: submitting job (1, 0, 3) to dispatcher
05:04:58 DISPATCHER: trying to submit job (1, 0, 3)
05:04:58 DISPATCHER: trying to notify the job_runner thread.
05:04:58 HBMASTER: job (1, 0, 3) submitted to dispatcher
05:04:58 DISPATCHER: Trying to submit another job.
05:04:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:04:58 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:04:58 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:04:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:04:58 WORKER: start processing job (1, 0, 3)
05:04:58 WORKER: args: ()
05:04:58 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 100, 'last_n_outputs': 9, 'lr': 0.0013466798382321613, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.013291721768486944}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-456:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:05:15 DISPATCHER: Starting worker discovery
05:05:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:05:15 DISPATCHER: Finished worker discovery
05:06:15 DISPATCHER: Starting worker discovery
05:06:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:06:15 DISPATCHER: Finished worker discovery
05:07:15 DISPATCHER: Starting worker discovery
05:07:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:07:15 DISPATCHER: Finished worker discovery
05:08:15 DISPATCHER: Starting worker discovery
05:08:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:08:15 DISPATCHER: Finished worker discovery
05:09:15 DISPATCHER: Starting worker discovery
05:09:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:09:15 DISPATCHER: Finished worker discovery
05:10:15 DISPATCHER: Starting worker discovery
05:10:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:10:15 DISPATCHER: Finished worker discovery
05:11:15 DISPATCHER: Starting worker discovery
05:11:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:11:15 DISPATCHER: Finished worker discovery
05:11:52 WORKER: done with job (1, 0, 3), trying to register it.
05:11:52 WORKER: registered result for job (1, 0, 3) with dispatcher
05:11:52 DISPATCHER: job (1, 0, 3) finished
05:11:52 DISPATCHER: register_result: lock acquired
05:11:52 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
05:11:52 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 100, 'last_n_outputs': 9, 'lr': 0.0013466798382321613, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.013291721768486944}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.06405846234676399, 'info': {'data04': 0.06405846234676399, 'config': "{'batch_size': 32, 'hidden_dim': 100, 'last_n_outputs': 9, 'lr': 0.0013466798382321613, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.013291721768486944}"}}
exception: None

05:11:52 job_callback for (1, 0, 3) started
05:11:52 DISPATCHER: Trying to submit another job.
05:11:52 job_callback for (1, 0, 3) got condition
05:11:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:11:52 Only 5 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
05:11:52 HBMASTER: Trying to run another job!
05:11:52 job_callback for (1, 0, 3) finished
05:11:52 HBMASTER: schedule new run for iteration 1
05:11:52 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
05:11:52 HBMASTER: submitting job (1, 0, 5) to dispatcher
05:11:52 DISPATCHER: trying to submit job (1, 0, 5)
05:11:52 DISPATCHER: trying to notify the job_runner thread.
05:11:52 HBMASTER: job (1, 0, 5) submitted to dispatcher
05:11:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:11:52 DISPATCHER: Trying to submit another job.
05:11:52 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:11:52 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:11:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:11:52 WORKER: start processing job (1, 0, 5)
05:11:52 WORKER: args: ()
05:11:52 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 96, 'last_n_outputs': 28, 'lr': 0.024175848464650075, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.05531009385004957}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-457:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:12:15 DISPATCHER: Starting worker discovery
05:12:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:12:15 DISPATCHER: Finished worker discovery
05:13:15 DISPATCHER: Starting worker discovery
05:13:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:13:15 DISPATCHER: Finished worker discovery
05:14:15 DISPATCHER: Starting worker discovery
05:14:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:14:15 DISPATCHER: Finished worker discovery
05:15:15 DISPATCHER: Starting worker discovery
05:15:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:15:15 DISPATCHER: Finished worker discovery
05:16:15 DISPATCHER: Starting worker discovery
05:16:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:16:15 DISPATCHER: Finished worker discovery
05:17:15 DISPATCHER: Starting worker discovery
05:17:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:17:15 DISPATCHER: Finished worker discovery
05:18:15 DISPATCHER: Starting worker discovery
05:18:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:18:15 DISPATCHER: Finished worker discovery
05:18:45 WORKER: done with job (1, 0, 5), trying to register it.
05:18:45 WORKER: registered result for job (1, 0, 5) with dispatcher
05:18:45 DISPATCHER: job (1, 0, 5) finished
05:18:45 DISPATCHER: register_result: lock acquired
05:18:45 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
05:18:45 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 96, 'last_n_outputs': 28, 'lr': 0.024175848464650075, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.05531009385004957}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.055345550405802954, 'info': {'data04': 0.055345550405802954, 'config': "{'batch_size': 128, 'hidden_dim': 96, 'last_n_outputs': 28, 'lr': 0.024175848464650075, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.05531009385004957}"}}
exception: None

05:18:45 job_callback for (1, 0, 5) started
05:18:45 job_callback for (1, 0, 5) got condition
05:18:45 DISPATCHER: Trying to submit another job.
05:18:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:18:45 Only 6 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
05:18:45 HBMASTER: Trying to run another job!
05:18:45 job_callback for (1, 0, 5) finished
05:18:45 ITERATION: Advancing config (1, 0, 1) to next budget 1200.000000
05:18:45 HBMASTER: schedule new run for iteration 1
05:18:45 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
05:18:45 HBMASTER: submitting job (1, 0, 1) to dispatcher
05:18:45 DISPATCHER: trying to submit job (1, 0, 1)
05:18:45 DISPATCHER: trying to notify the job_runner thread.
05:18:45 HBMASTER: job (1, 0, 1) submitted to dispatcher
05:18:45 DISPATCHER: Trying to submit another job.
05:18:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:18:45 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:18:45 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:18:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:18:45 WORKER: start processing job (1, 0, 1)
05:18:45 WORKER: args: ()
05:18:45 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 74, 'last_n_outputs': 34, 'lr': 0.0011249176772528443, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.010460005932404322}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-458:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:19:15 DISPATCHER: Starting worker discovery
05:19:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:19:15 DISPATCHER: Finished worker discovery
05:20:15 DISPATCHER: Starting worker discovery
05:20:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:20:15 DISPATCHER: Finished worker discovery
05:21:15 DISPATCHER: Starting worker discovery
05:21:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:21:15 DISPATCHER: Finished worker discovery
05:22:15 DISPATCHER: Starting worker discovery
05:22:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:22:15 DISPATCHER: Finished worker discovery
05:23:15 DISPATCHER: Starting worker discovery
05:23:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:23:15 DISPATCHER: Finished worker discovery
05:24:15 DISPATCHER: Starting worker discovery
05:24:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:24:15 DISPATCHER: Finished worker discovery
05:25:15 DISPATCHER: Starting worker discovery
05:25:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:25:15 DISPATCHER: Finished worker discovery
05:26:15 DISPATCHER: Starting worker discovery
05:26:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:26:15 DISPATCHER: Finished worker discovery
05:27:15 DISPATCHER: Starting worker discovery
05:27:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:27:15 DISPATCHER: Finished worker discovery
05:28:15 DISPATCHER: Starting worker discovery
05:28:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:28:15 DISPATCHER: Finished worker discovery
05:29:15 DISPATCHER: Starting worker discovery
05:29:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:29:15 DISPATCHER: Finished worker discovery
05:30:15 DISPATCHER: Starting worker discovery
05:30:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:30:15 DISPATCHER: Finished worker discovery
05:31:15 DISPATCHER: Starting worker discovery
05:31:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:31:15 DISPATCHER: Finished worker discovery
05:32:15 DISPATCHER: Starting worker discovery
05:32:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:32:15 DISPATCHER: Finished worker discovery
05:33:15 DISPATCHER: Starting worker discovery
05:33:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:33:15 DISPATCHER: Finished worker discovery
05:34:15 DISPATCHER: Starting worker discovery
05:34:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:34:15 DISPATCHER: Finished worker discovery
05:35:15 DISPATCHER: Starting worker discovery
05:35:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:35:15 DISPATCHER: Finished worker discovery
05:36:15 DISPATCHER: Starting worker discovery
05:36:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:36:15 DISPATCHER: Finished worker discovery
05:37:15 DISPATCHER: Starting worker discovery
05:37:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:37:15 DISPATCHER: Finished worker discovery
05:38:15 DISPATCHER: Starting worker discovery
05:38:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:38:15 DISPATCHER: Finished worker discovery
05:38:58 WORKER: done with job (1, 0, 1), trying to register it.
05:38:58 WORKER: registered result for job (1, 0, 1) with dispatcher
05:38:58 DISPATCHER: job (1, 0, 1) finished
05:38:58 DISPATCHER: register_result: lock acquired
05:38:58 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
05:38:58 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 74, 'last_n_outputs': 34, 'lr': 0.0011249176772528443, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.010460005932404322}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.1906230882204417, 'info': {'data04': 0.1906230882204417, 'config': "{'batch_size': 128, 'hidden_dim': 74, 'last_n_outputs': 34, 'lr': 0.0011249176772528443, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.010460005932404322}"}}
exception: None

05:38:58 job_callback for (1, 0, 1) started
05:38:58 DISPATCHER: Trying to submit another job.
05:38:58 job_callback for (1, 0, 1) got condition
05:38:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:38:58 Only 2 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
05:38:58 HBMASTER: Trying to run another job!
05:38:58 job_callback for (1, 0, 1) finished
05:38:58 start sampling a new configuration.
05:38:58 done sampling a new configuration.
05:38:58 HBMASTER: schedule new run for iteration 2
05:38:58 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
05:38:58 HBMASTER: submitting job (2, 0, 0) to dispatcher
05:38:58 DISPATCHER: trying to submit job (2, 0, 0)
05:38:58 DISPATCHER: trying to notify the job_runner thread.
05:38:58 HBMASTER: job (2, 0, 0) submitted to dispatcher
05:38:58 DISPATCHER: Trying to submit another job.
05:38:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:38:58 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:38:58 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:38:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:38:58 WORKER: start processing job (2, 0, 0)
05:38:58 WORKER: args: ()
05:38:58 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 28, 'last_n_outputs': 47, 'lr': 0.0022566582324490274, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.08371362873788088}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-459:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:39:15 DISPATCHER: Starting worker discovery
05:39:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:39:15 DISPATCHER: Finished worker discovery
05:40:15 DISPATCHER: Starting worker discovery
05:40:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:40:15 DISPATCHER: Finished worker discovery
05:41:15 DISPATCHER: Starting worker discovery
05:41:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:41:15 DISPATCHER: Finished worker discovery
05:42:15 DISPATCHER: Starting worker discovery
05:42:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:42:15 DISPATCHER: Finished worker discovery
05:43:15 DISPATCHER: Starting worker discovery
05:43:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:43:15 DISPATCHER: Finished worker discovery
05:44:15 DISPATCHER: Starting worker discovery
05:44:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:44:15 DISPATCHER: Finished worker discovery
05:45:15 DISPATCHER: Starting worker discovery
05:45:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:45:15 DISPATCHER: Finished worker discovery
05:45:51 WORKER: done with job (2, 0, 0), trying to register it.
05:45:51 WORKER: registered result for job (2, 0, 0) with dispatcher
05:45:51 DISPATCHER: job (2, 0, 0) finished
05:45:51 DISPATCHER: register_result: lock acquired
05:45:51 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
05:45:51 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 28, 'last_n_outputs': 47, 'lr': 0.0022566582324490274, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.08371362873788088}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': 0.0003541754577158149, 'info': {'data04': -0.0003541754577158149, 'config': "{'batch_size': 64, 'hidden_dim': 28, 'last_n_outputs': 47, 'lr': 0.0022566582324490274, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.08371362873788088}"}}
exception: None

05:45:51 job_callback for (2, 0, 0) started
05:45:51 job_callback for (2, 0, 0) got condition
05:45:51 DISPATCHER: Trying to submit another job.
05:45:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:45:51 Only 7 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
05:45:51 HBMASTER: Trying to run another job!
05:45:51 job_callback for (2, 0, 0) finished
05:45:51 start sampling a new configuration.
05:45:51 sampled vector: [2, 0.28778258213762004, 0.5047612837677169, 0.03713135506436068, 0.4251180288753811, 0, 0.3905432391930962, 0.056043441786629025] has EI value inf
05:45:51 data in the KDEs:
[[3.         0.67283955 0.67000007 0.02556037 0.0999984  0.
  0.98351659 0.01501267]
 [2.         0.91975319 0.06999983 0.49134915 0.0999984  0.
  0.34615381 0.2220369 ]
 [1.         0.99382728 0.16999987 0.06463218 0.0999984  0.
  0.04945045 0.09498723]
 [3.         0.94444455 0.55000002 0.69169086 0.0999984  1.
  0.69780224 0.57093564]
 [0.         0.45061727 0.49       0.75725213 0.0999984  1.
  0.77472534 0.04815185]
 [3.         0.82098773 0.26999991 0.846535   0.0999984  1.
  0.29120875 0.67572506]
 [3.         0.90740751 0.32999993 0.74196297 0.2999992  1.
  0.98351659 0.25068711]
 [2.         0.67283955 0.77000011 0.05933137 0.0999984  1.
  0.91758251 0.03312671]
 [1.         0.99382728 0.04999982 0.73851202 0.0999984  0.
  0.12637354 0.0892389 ]]
[[0.         0.56172841 0.97000019 0.75808465 0.5        1.
  0.20329664 0.96083405]
 [2.         0.88271614 0.38999996 0.80879291 0.2999992  1.
  0.40109888 0.65476406]
 [1.         0.43827159 0.26999991 0.5613407  0.2999992  1.
  0.75274731 0.52552923]
 [1.         0.3641975  0.91000016 0.66624211 0.5        1.
  0.48901099 0.55120704]
 [2.         0.72222228 0.16999987 0.9413961  0.0999984  1.
  0.03846144 0.74478876]
 [3.         0.85802478 0.04999982 0.90369329 0.0999984  1.
  0.14835157 0.41206949]
 [0.         0.95679024 0.26999991 0.44141548 0.0999984  1.
  0.6648352  0.05588327]
 [2.         0.88271614 0.0099998  0.80797366 0.0999984  1.
  0.03846144 0.56321253]
 [3.         0.66049387 0.36999995 0.56338374 0.5        1.
  0.41208789 0.4162515 ]]
05:45:51 bandwidth of the KDEs:
[0.93038865 0.15379994 0.2163274  0.28624806 0.05547788 0.43858941
 0.31087773 0.20190567]
[0.94066949 0.17653868 0.28575046 0.14108478 0.15444389 0.001
 0.21688492 0.2078469 ]
05:45:51 l(x) = 1.5433067490342572e-07
05:45:51 g(x) = inf
05:45:51 best_vector: [2, 0.28778258213762004, 0.5047612837677169, 0.03713135506436068, 0.4251180288753811, 0, 0.3905432391930962, 0.056043441786629025], inf, 1.5433067490342572e-07, inf
05:45:51 done sampling a new configuration.
05:45:51 HBMASTER: schedule new run for iteration 2
05:45:51 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
05:45:51 HBMASTER: submitting job (2, 0, 1) to dispatcher
05:45:51 DISPATCHER: trying to submit job (2, 0, 1)
05:45:51 DISPATCHER: trying to notify the job_runner thread.
05:45:51 HBMASTER: job (2, 0, 1) submitted to dispatcher
05:45:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:45:51 DISPATCHER: Trying to submit another job.
05:45:51 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:45:51 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:45:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:45:51 WORKER: start processing job (2, 0, 1)
05:45:51 WORKER: args: ()
05:45:51 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 43, 'last_n_outputs': 26, 'lr': 0.0011864862514089278, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.011828078517896348}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-460:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:46:15 DISPATCHER: Starting worker discovery
05:46:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:46:15 DISPATCHER: Finished worker discovery
05:47:15 DISPATCHER: Starting worker discovery
05:47:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:47:15 DISPATCHER: Finished worker discovery
05:48:15 DISPATCHER: Starting worker discovery
05:48:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:48:15 DISPATCHER: Finished worker discovery
05:49:15 DISPATCHER: Starting worker discovery
05:49:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:49:15 DISPATCHER: Finished worker discovery
05:50:15 DISPATCHER: Starting worker discovery
05:50:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:50:15 DISPATCHER: Finished worker discovery
05:51:15 DISPATCHER: Starting worker discovery
05:51:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:51:15 DISPATCHER: Finished worker discovery
05:52:15 DISPATCHER: Starting worker discovery
05:52:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:52:15 DISPATCHER: Finished worker discovery
05:52:44 WORKER: done with job (2, 0, 1), trying to register it.
05:52:44 WORKER: registered result for job (2, 0, 1) with dispatcher
05:52:44 DISPATCHER: job (2, 0, 1) finished
05:52:44 DISPATCHER: register_result: lock acquired
05:52:44 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
05:52:44 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 43, 'last_n_outputs': 26, 'lr': 0.0011864862514089278, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.011828078517896348}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 43, 'last_n_outputs': 26, 'lr': 0.0011864862514089278, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.011828078517896348}"}}
exception: None

05:52:44 job_callback for (2, 0, 1) started
05:52:44 DISPATCHER: Trying to submit another job.
05:52:44 job_callback for (2, 0, 1) got condition
05:52:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:52:44 Only 8 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
05:52:44 HBMASTER: Trying to run another job!
05:52:44 job_callback for (2, 0, 1) finished
05:52:44 start sampling a new configuration.
05:52:44 done sampling a new configuration.
05:52:44 HBMASTER: schedule new run for iteration 2
05:52:44 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
05:52:44 HBMASTER: submitting job (2, 0, 2) to dispatcher
05:52:44 DISPATCHER: trying to submit job (2, 0, 2)
05:52:44 DISPATCHER: trying to notify the job_runner thread.
05:52:44 HBMASTER: job (2, 0, 2) submitted to dispatcher
05:52:44 DISPATCHER: Trying to submit another job.
05:52:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:52:44 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:52:44 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:52:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:52:44 WORKER: start processing job (2, 0, 2)
05:52:44 WORKER: args: ()
05:52:44 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 60, 'last_n_outputs': 25, 'lr': 0.020608625355599063, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.03813710858413206}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-461:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:53:15 DISPATCHER: Starting worker discovery
05:53:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:53:15 DISPATCHER: Finished worker discovery
05:54:15 DISPATCHER: Starting worker discovery
05:54:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:54:15 DISPATCHER: Finished worker discovery
05:55:15 DISPATCHER: Starting worker discovery
05:55:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:55:15 DISPATCHER: Finished worker discovery
05:56:15 DISPATCHER: Starting worker discovery
05:56:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:56:15 DISPATCHER: Finished worker discovery
05:57:15 DISPATCHER: Starting worker discovery
05:57:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:57:15 DISPATCHER: Finished worker discovery
05:58:15 DISPATCHER: Starting worker discovery
05:58:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:58:15 DISPATCHER: Finished worker discovery
05:59:15 DISPATCHER: Starting worker discovery
05:59:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:59:15 DISPATCHER: Finished worker discovery
05:59:38 WORKER: done with job (2, 0, 2), trying to register it.
05:59:38 WORKER: registered result for job (2, 0, 2) with dispatcher
05:59:38 DISPATCHER: job (2, 0, 2) finished
05:59:38 DISPATCHER: register_result: lock acquired
05:59:38 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
05:59:38 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 60, 'last_n_outputs': 25, 'lr': 0.020608625355599063, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.03813710858413206}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.037533710718810065, 'info': {'data04': 0.037533710718810065, 'config': "{'batch_size': 32, 'hidden_dim': 60, 'last_n_outputs': 25, 'lr': 0.020608625355599063, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.03813710858413206}"}}
exception: None

05:59:38 job_callback for (2, 0, 2) started
05:59:38 job_callback for (2, 0, 2) got condition
05:59:38 DISPATCHER: Trying to submit another job.
05:59:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:59:38 HBMASTER: Trying to run another job!
05:59:38 job_callback for (2, 0, 2) finished
05:59:38 start sampling a new configuration.
05:59:38 done sampling a new configuration.
05:59:38 HBMASTER: schedule new run for iteration 2
05:59:38 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
05:59:38 HBMASTER: submitting job (2, 0, 3) to dispatcher
05:59:38 DISPATCHER: trying to submit job (2, 0, 3)
05:59:38 DISPATCHER: trying to notify the job_runner thread.
05:59:38 HBMASTER: job (2, 0, 3) submitted to dispatcher
05:59:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:59:38 DISPATCHER: Trying to submit another job.
05:59:38 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:59:38 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:59:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:59:38 WORKER: start processing job (2, 0, 3)
05:59:38 WORKER: args: ()
05:59:38 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 87, 'last_n_outputs': 7, 'lr': 0.00500023153892796, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.10528104857796522}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-462:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:00:15 DISPATCHER: Starting worker discovery
06:00:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:00:15 DISPATCHER: Finished worker discovery
06:01:15 DISPATCHER: Starting worker discovery
06:01:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:01:15 DISPATCHER: Finished worker discovery
06:02:15 DISPATCHER: Starting worker discovery
06:02:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:02:15 DISPATCHER: Finished worker discovery
06:03:16 DISPATCHER: Starting worker discovery
06:03:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:03:16 DISPATCHER: Finished worker discovery
06:04:16 DISPATCHER: Starting worker discovery
06:04:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:04:16 DISPATCHER: Finished worker discovery
06:05:16 DISPATCHER: Starting worker discovery
06:05:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:05:16 DISPATCHER: Finished worker discovery
06:06:16 DISPATCHER: Starting worker discovery
06:06:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:06:16 DISPATCHER: Finished worker discovery
06:06:30 WORKER: done with job (2, 0, 3), trying to register it.
06:06:30 WORKER: registered result for job (2, 0, 3) with dispatcher
06:06:30 DISPATCHER: job (2, 0, 3) finished
06:06:30 DISPATCHER: register_result: lock acquired
06:06:30 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
06:06:30 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 87, 'last_n_outputs': 7, 'lr': 0.00500023153892796, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.10528104857796522}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 87, 'last_n_outputs': 7, 'lr': 0.00500023153892796, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.10528104857796522}"}}
exception: None

06:06:30 job_callback for (2, 0, 3) started
06:06:30 job_callback for (2, 0, 3) got condition
06:06:30 DISPATCHER: Trying to submit another job.
06:06:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:06:30 HBMASTER: Trying to run another job!
06:06:30 job_callback for (2, 0, 3) finished
06:06:30 start sampling a new configuration.
06:06:30 sampled vector: [1, 0.5833612750569015, 0.12908472208337857, 0.46669579348797924, 0.26423293390193503, 0, 0.39294116085664044, 0.011831326844538081] has EI value inf
06:06:30 data in the KDEs:
[[3.         0.67283955 0.67000007 0.02556037 0.0999984  0.
  0.98351659 0.01501267]
 [2.         0.91975319 0.06999983 0.49134915 0.0999984  0.
  0.34615381 0.2220369 ]
 [1.         0.99382728 0.16999987 0.06463218 0.0999984  0.
  0.04945045 0.09498723]
 [3.         0.94444455 0.55000002 0.69169086 0.0999984  1.
  0.69780224 0.57093564]
 [0.         0.45061727 0.49       0.75725213 0.0999984  1.
  0.77472534 0.04815185]
 [3.         0.82098773 0.26999991 0.846535   0.0999984  1.
  0.29120875 0.67572506]
 [3.         0.90740751 0.32999993 0.74196297 0.2999992  1.
  0.98351659 0.25068711]
 [2.         0.67283955 0.77000011 0.05933137 0.0999984  1.
  0.91758251 0.03312671]
 [1.         0.99382728 0.04999982 0.73851202 0.0999984  0.
  0.12637354 0.0892389 ]]
[[0.         0.56172841 0.97000019 0.75808465 0.5        1.
  0.20329664 0.96083405]
 [2.         0.88271614 0.38999996 0.80879291 0.2999992  1.
  0.40109888 0.65476406]
 [1.         0.43827159 0.26999991 0.5613407  0.2999992  1.
  0.75274731 0.52552923]
 [1.         0.3641975  0.91000016 0.66624211 0.5        1.
  0.48901099 0.55120704]
 [2.         0.72222228 0.16999987 0.9413961  0.0999984  1.
  0.03846144 0.74478876]
 [3.         0.85802478 0.04999982 0.90369329 0.0999984  1.
  0.14835157 0.41206949]
 [0.         0.95679024 0.26999991 0.44141548 0.0999984  1.
  0.6648352  0.05588327]
 [2.         0.88271614 0.0099998  0.80797366 0.0999984  1.
  0.03846144 0.56321253]
 [3.         0.66049387 0.36999995 0.56338374 0.5        1.
  0.41208789 0.4162515 ]]
06:06:30 bandwidth of the KDEs:
[0.93038865 0.15379994 0.2163274  0.28624806 0.05547788 0.43858941
 0.31087773 0.20190567]
[0.94066949 0.17653868 0.28575046 0.14108478 0.15444389 0.001
 0.21688492 0.2078469 ]
06:06:30 l(x) = 0.008189461319949897
06:06:30 g(x) = inf
06:06:30 best_vector: [1, 0.5833612750569015, 0.12908472208337857, 0.46669579348797924, 0.26423293390193503, 0, 0.39294116085664044, 0.011831326844538081], inf, 0.008189461319949897, inf
06:06:30 done sampling a new configuration.
06:06:30 HBMASTER: schedule new run for iteration 2
06:06:30 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
06:06:30 HBMASTER: submitting job (2, 0, 4) to dispatcher
06:06:30 DISPATCHER: trying to submit job (2, 0, 4)
06:06:30 DISPATCHER: trying to notify the job_runner thread.
06:06:30 HBMASTER: job (2, 0, 4) submitted to dispatcher
06:06:30 DISPATCHER: Trying to submit another job.
06:06:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:06:30 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
06:06:30 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
06:06:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:06:30 WORKER: start processing job (2, 0, 4)
06:06:30 WORKER: args: ()
06:06:30 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 67, 'last_n_outputs': 7, 'lr': 0.008578109524622155, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.010360790952269102}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-463:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:07:16 DISPATCHER: Starting worker discovery
06:07:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:07:16 DISPATCHER: Finished worker discovery
06:08:16 DISPATCHER: Starting worker discovery
06:08:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:08:16 DISPATCHER: Finished worker discovery
06:09:16 DISPATCHER: Starting worker discovery
06:09:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:09:16 DISPATCHER: Finished worker discovery
06:10:16 DISPATCHER: Starting worker discovery
06:10:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:10:16 DISPATCHER: Finished worker discovery
06:11:16 DISPATCHER: Starting worker discovery
06:11:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:11:16 DISPATCHER: Finished worker discovery
06:12:16 DISPATCHER: Starting worker discovery
06:12:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:12:16 DISPATCHER: Finished worker discovery
06:13:16 DISPATCHER: Starting worker discovery
06:13:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:13:16 DISPATCHER: Finished worker discovery
06:13:23 WORKER: done with job (2, 0, 4), trying to register it.
06:13:23 WORKER: registered result for job (2, 0, 4) with dispatcher
06:13:23 DISPATCHER: job (2, 0, 4) finished
06:13:23 DISPATCHER: register_result: lock acquired
06:13:23 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
06:13:23 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 67, 'last_n_outputs': 7, 'lr': 0.008578109524622155, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.010360790952269102}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.02796295403793802, 'info': {'data04': 0.02796295403793802, 'config': "{'batch_size': 32, 'hidden_dim': 67, 'last_n_outputs': 7, 'lr': 0.008578109524622155, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.010360790952269102}"}}
exception: None

06:13:23 job_callback for (2, 0, 4) started
06:13:23 DISPATCHER: Trying to submit another job.
06:13:23 job_callback for (2, 0, 4) got condition
06:13:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:13:23 HBMASTER: Trying to run another job!
06:13:23 job_callback for (2, 0, 4) finished
06:13:23 start sampling a new configuration.
06:13:23 sampled vector: [2, 0.7241685958105146, 0.28322514153094575, 0.7293479946973318, 0.0016148394795576365, 0, 0.5232692118601717, 0.09820979554141403] has EI value inf
06:13:23 data in the KDEs:
[[3.         0.67283955 0.67000007 0.02556037 0.0999984  0.
  0.98351659 0.01501267]
 [2.         0.91975319 0.06999983 0.49134915 0.0999984  0.
  0.34615381 0.2220369 ]
 [1.         0.99382728 0.16999987 0.06463218 0.0999984  0.
  0.04945045 0.09498723]
 [3.         0.94444455 0.55000002 0.69169086 0.0999984  1.
  0.69780224 0.57093564]
 [0.         0.45061727 0.49       0.75725213 0.0999984  1.
  0.77472534 0.04815185]
 [3.         0.82098773 0.26999991 0.846535   0.0999984  1.
  0.29120875 0.67572506]
 [3.         0.90740751 0.32999993 0.74196297 0.2999992  1.
  0.98351659 0.25068711]
 [2.         0.67283955 0.77000011 0.05933137 0.0999984  1.
  0.91758251 0.03312671]
 [1.         0.99382728 0.04999982 0.73851202 0.0999984  0.
  0.12637354 0.0892389 ]]
[[0.         0.56172841 0.97000019 0.75808465 0.5        1.
  0.20329664 0.96083405]
 [2.         0.88271614 0.38999996 0.80879291 0.2999992  1.
  0.40109888 0.65476406]
 [1.         0.43827159 0.26999991 0.5613407  0.2999992  1.
  0.75274731 0.52552923]
 [1.         0.3641975  0.91000016 0.66624211 0.5        1.
  0.48901099 0.55120704]
 [2.         0.72222228 0.16999987 0.9413961  0.0999984  1.
  0.03846144 0.74478876]
 [3.         0.85802478 0.04999982 0.90369329 0.0999984  1.
  0.14835157 0.41206949]
 [0.         0.95679024 0.26999991 0.44141548 0.0999984  1.
  0.6648352  0.05588327]
 [2.         0.88271614 0.0099998  0.80797366 0.0999984  1.
  0.03846144 0.56321253]
 [3.         0.66049387 0.36999995 0.56338374 0.5        1.
  0.41208789 0.4162515 ]]
06:13:23 bandwidth of the KDEs:
[0.93038865 0.15379994 0.2163274  0.28624806 0.05547788 0.43858941
 0.31087773 0.20190567]
[0.94066949 0.17653868 0.28575046 0.14108478 0.15444389 0.001
 0.21688492 0.2078469 ]
06:13:23 l(x) = 0.0860871732859695
06:13:23 g(x) = inf
06:13:23 best_vector: [2, 0.7241685958105146, 0.28322514153094575, 0.7293479946973318, 0.0016148394795576365, 0, 0.5232692118601717, 0.09820979554141403], inf, 0.0860871732859695, inf
06:13:23 done sampling a new configuration.
06:13:23 HBMASTER: schedule new run for iteration 2
06:13:23 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
06:13:23 HBMASTER: submitting job (2, 0, 5) to dispatcher
06:13:23 DISPATCHER: trying to submit job (2, 0, 5)
06:13:23 DISPATCHER: trying to notify the job_runner thread.
06:13:23 HBMASTER: job (2, 0, 5) submitted to dispatcher
06:13:23 DISPATCHER: Trying to submit another job.
06:13:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:13:23 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
06:13:23 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
06:13:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:13:23 WORKER: start processing job (2, 0, 5)
06:13:23 WORKER: args: ()
06:13:23 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 78, 'last_n_outputs': 15, 'lr': 0.028753849110616604, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.013420660488706727}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-464:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:14:16 DISPATCHER: Starting worker discovery
06:14:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:14:16 DISPATCHER: Finished worker discovery
06:15:16 DISPATCHER: Starting worker discovery
06:15:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:15:16 DISPATCHER: Finished worker discovery
06:16:16 DISPATCHER: Starting worker discovery
06:16:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:16:16 DISPATCHER: Finished worker discovery
06:17:16 DISPATCHER: Starting worker discovery
06:17:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:17:16 DISPATCHER: Finished worker discovery
06:18:16 DISPATCHER: Starting worker discovery
06:18:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:18:16 DISPATCHER: Finished worker discovery
06:19:16 DISPATCHER: Starting worker discovery
06:19:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:19:16 DISPATCHER: Finished worker discovery
06:20:16 DISPATCHER: Starting worker discovery
06:20:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:20:16 DISPATCHER: Finished worker discovery
06:20:16 WORKER: done with job (2, 0, 5), trying to register it.
06:20:16 WORKER: registered result for job (2, 0, 5) with dispatcher
06:20:16 DISPATCHER: job (2, 0, 5) finished
06:20:16 DISPATCHER: register_result: lock acquired
06:20:16 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
06:20:16 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 78, 'last_n_outputs': 15, 'lr': 0.028753849110616604, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.013420660488706727}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.041893194863456794, 'info': {'data04': 0.041893194863456794, 'config': "{'batch_size': 64, 'hidden_dim': 78, 'last_n_outputs': 15, 'lr': 0.028753849110616604, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.013420660488706727}"}}
exception: None

06:20:16 job_callback for (2, 0, 5) started
06:20:16 job_callback for (2, 0, 5) got condition
06:20:16 DISPATCHER: Trying to submit another job.
06:20:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:20:16 HBMASTER: Trying to run another job!
06:20:16 job_callback for (2, 0, 5) finished
06:20:16 ITERATION: Advancing config (2, 0, 2) to next budget 1200.000000
06:20:16 ITERATION: Advancing config (2, 0, 5) to next budget 1200.000000
06:20:16 HBMASTER: schedule new run for iteration 2
06:20:16 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
06:20:16 HBMASTER: submitting job (2, 0, 2) to dispatcher
06:20:16 DISPATCHER: trying to submit job (2, 0, 2)
06:20:16 DISPATCHER: trying to notify the job_runner thread.
06:20:16 HBMASTER: job (2, 0, 2) submitted to dispatcher
06:20:16 DISPATCHER: Trying to submit another job.
06:20:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:20:16 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
06:20:16 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
06:20:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:20:16 WORKER: start processing job (2, 0, 2)
06:20:16 WORKER: args: ()
06:20:16 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 60, 'last_n_outputs': 25, 'lr': 0.020608625355599063, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.03813710858413206}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-465:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:21:16 DISPATCHER: Starting worker discovery
06:21:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:21:16 DISPATCHER: Finished worker discovery
06:22:16 DISPATCHER: Starting worker discovery
06:22:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:22:16 DISPATCHER: Finished worker discovery
06:23:16 DISPATCHER: Starting worker discovery
06:23:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:23:16 DISPATCHER: Finished worker discovery
06:24:16 DISPATCHER: Starting worker discovery
06:24:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:24:16 DISPATCHER: Finished worker discovery
06:25:16 DISPATCHER: Starting worker discovery
06:25:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:25:16 DISPATCHER: Finished worker discovery
06:26:16 DISPATCHER: Starting worker discovery
06:26:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:26:16 DISPATCHER: Finished worker discovery
06:27:16 DISPATCHER: Starting worker discovery
06:27:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:27:16 DISPATCHER: Finished worker discovery
06:28:16 DISPATCHER: Starting worker discovery
06:28:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:28:16 DISPATCHER: Finished worker discovery
06:29:16 DISPATCHER: Starting worker discovery
06:29:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:29:16 DISPATCHER: Finished worker discovery
06:30:16 DISPATCHER: Starting worker discovery
06:30:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:30:16 DISPATCHER: Finished worker discovery
06:31:16 DISPATCHER: Starting worker discovery
06:31:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:31:16 DISPATCHER: Finished worker discovery
06:32:16 DISPATCHER: Starting worker discovery
06:32:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:32:16 DISPATCHER: Finished worker discovery
06:33:16 DISPATCHER: Starting worker discovery
06:33:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:33:16 DISPATCHER: Finished worker discovery
06:34:16 DISPATCHER: Starting worker discovery
06:34:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:34:16 DISPATCHER: Finished worker discovery
06:35:16 DISPATCHER: Starting worker discovery
06:35:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:35:16 DISPATCHER: Finished worker discovery
06:36:16 DISPATCHER: Starting worker discovery
06:36:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:36:16 DISPATCHER: Finished worker discovery
06:37:16 DISPATCHER: Starting worker discovery
06:37:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:37:16 DISPATCHER: Finished worker discovery
06:38:16 DISPATCHER: Starting worker discovery
06:38:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:38:16 DISPATCHER: Finished worker discovery
06:39:16 DISPATCHER: Starting worker discovery
06:39:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:39:16 DISPATCHER: Finished worker discovery
06:40:16 DISPATCHER: Starting worker discovery
06:40:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:40:16 DISPATCHER: Finished worker discovery
06:40:29 WORKER: done with job (2, 0, 2), trying to register it.
06:40:29 WORKER: registered result for job (2, 0, 2) with dispatcher
06:40:29 DISPATCHER: job (2, 0, 2) finished
06:40:29 DISPATCHER: register_result: lock acquired
06:40:29 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
06:40:29 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 60, 'last_n_outputs': 25, 'lr': 0.020608625355599063, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.03813710858413206}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.04610670360980869, 'info': {'data04': 0.04610670360980869, 'config': "{'batch_size': 32, 'hidden_dim': 60, 'last_n_outputs': 25, 'lr': 0.020608625355599063, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.03813710858413206}"}}
exception: None

06:40:29 job_callback for (2, 0, 2) started
06:40:29 DISPATCHER: Trying to submit another job.
06:40:29 job_callback for (2, 0, 2) got condition
06:40:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:40:29 Only 3 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
06:40:29 HBMASTER: Trying to run another job!
06:40:29 job_callback for (2, 0, 2) finished
06:40:29 HBMASTER: schedule new run for iteration 2
06:40:29 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
06:40:29 HBMASTER: submitting job (2, 0, 5) to dispatcher
06:40:29 DISPATCHER: trying to submit job (2, 0, 5)
06:40:29 DISPATCHER: trying to notify the job_runner thread.
06:40:29 HBMASTER: job (2, 0, 5) submitted to dispatcher
06:40:29 DISPATCHER: Trying to submit another job.
06:40:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:40:29 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
06:40:29 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
06:40:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:40:29 WORKER: start processing job (2, 0, 5)
06:40:29 WORKER: args: ()
06:40:29 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 78, 'last_n_outputs': 15, 'lr': 0.028753849110616604, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.013420660488706727}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-466:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:41:16 DISPATCHER: Starting worker discovery
06:41:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:41:16 DISPATCHER: Finished worker discovery
06:42:16 DISPATCHER: Starting worker discovery
06:42:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:42:16 DISPATCHER: Finished worker discovery
06:43:16 DISPATCHER: Starting worker discovery
06:43:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:43:16 DISPATCHER: Finished worker discovery
06:44:16 DISPATCHER: Starting worker discovery
06:44:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:44:16 DISPATCHER: Finished worker discovery
06:45:16 DISPATCHER: Starting worker discovery
06:45:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:45:16 DISPATCHER: Finished worker discovery
06:46:16 DISPATCHER: Starting worker discovery
06:46:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:46:16 DISPATCHER: Finished worker discovery
06:47:16 DISPATCHER: Starting worker discovery
06:47:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:47:16 DISPATCHER: Finished worker discovery
06:48:16 DISPATCHER: Starting worker discovery
06:48:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:48:16 DISPATCHER: Finished worker discovery
06:49:16 DISPATCHER: Starting worker discovery
06:49:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:49:16 DISPATCHER: Finished worker discovery
06:50:16 DISPATCHER: Starting worker discovery
06:50:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:50:16 DISPATCHER: Finished worker discovery
06:51:16 DISPATCHER: Starting worker discovery
06:51:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:51:16 DISPATCHER: Finished worker discovery
06:52:16 DISPATCHER: Starting worker discovery
06:52:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:52:16 DISPATCHER: Finished worker discovery
06:53:16 DISPATCHER: Starting worker discovery
06:53:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:53:16 DISPATCHER: Finished worker discovery
06:54:16 DISPATCHER: Starting worker discovery
06:54:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:54:16 DISPATCHER: Finished worker discovery
06:55:16 DISPATCHER: Starting worker discovery
06:55:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:55:16 DISPATCHER: Finished worker discovery
06:56:16 DISPATCHER: Starting worker discovery
06:56:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:56:16 DISPATCHER: Finished worker discovery
06:57:16 DISPATCHER: Starting worker discovery
06:57:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:57:16 DISPATCHER: Finished worker discovery
06:58:16 DISPATCHER: Starting worker discovery
06:58:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:58:16 DISPATCHER: Finished worker discovery
06:59:16 DISPATCHER: Starting worker discovery
06:59:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:59:16 DISPATCHER: Finished worker discovery
07:00:16 DISPATCHER: Starting worker discovery
07:00:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:00:16 DISPATCHER: Finished worker discovery
07:00:42 WORKER: done with job (2, 0, 5), trying to register it.
07:00:42 WORKER: registered result for job (2, 0, 5) with dispatcher
07:00:42 DISPATCHER: job (2, 0, 5) finished
07:00:42 DISPATCHER: register_result: lock acquired
07:00:42 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
07:00:42 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 78, 'last_n_outputs': 15, 'lr': 0.028753849110616604, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.013420660488706727}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.05408461503318149, 'info': {'data04': 0.05408461503318149, 'config': "{'batch_size': 64, 'hidden_dim': 78, 'last_n_outputs': 15, 'lr': 0.028753849110616604, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.013420660488706727}"}}
exception: None

07:00:42 job_callback for (2, 0, 5) started
07:00:42 DISPATCHER: Trying to submit another job.
07:00:42 job_callback for (2, 0, 5) got condition
07:00:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:00:42 Only 4 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
07:00:42 HBMASTER: Trying to run another job!
07:00:42 job_callback for (2, 0, 5) finished
07:00:42 start sampling a new configuration.
07:00:42 sampled vector: [0, 0.7233612022430869, 0.0077869721404866254, 0.8660062141844779, 0.32665888522638153, 0, 0.6384316736326946, 0.22384800837230073] has EI value inf
07:00:42 data in the KDEs:
[[3.         0.67283955 0.67000007 0.02556037 0.0999984  0.
  0.98351659 0.01501267]
 [2.         0.91975319 0.06999983 0.49134915 0.0999984  0.
  0.34615381 0.2220369 ]
 [1.         0.99382728 0.16999987 0.06463218 0.0999984  0.
  0.04945045 0.09498723]
 [3.         0.94444455 0.55000002 0.69169086 0.0999984  1.
  0.69780224 0.57093564]
 [0.         0.45061727 0.49       0.75725213 0.0999984  1.
  0.77472534 0.04815185]
 [3.         0.82098773 0.26999991 0.846535   0.0999984  1.
  0.29120875 0.67572506]
 [3.         0.90740751 0.32999993 0.74196297 0.2999992  1.
  0.98351659 0.25068711]
 [2.         0.67283955 0.77000011 0.05933137 0.0999984  1.
  0.91758251 0.03312671]
 [1.         0.99382728 0.04999982 0.73851202 0.0999984  0.
  0.12637354 0.0892389 ]]
[[0.         0.56172841 0.97000019 0.75808465 0.5        1.
  0.20329664 0.96083405]
 [2.         0.88271614 0.38999996 0.80879291 0.2999992  1.
  0.40109888 0.65476406]
 [1.         0.43827159 0.26999991 0.5613407  0.2999992  1.
  0.75274731 0.52552923]
 [1.         0.3641975  0.91000016 0.66624211 0.5        1.
  0.48901099 0.55120704]
 [2.         0.72222228 0.16999987 0.9413961  0.0999984  1.
  0.03846144 0.74478876]
 [3.         0.85802478 0.04999982 0.90369329 0.0999984  1.
  0.14835157 0.41206949]
 [0.         0.95679024 0.26999991 0.44141548 0.0999984  1.
  0.6648352  0.05588327]
 [2.         0.88271614 0.0099998  0.80797366 0.0999984  1.
  0.03846144 0.56321253]
 [3.         0.66049387 0.36999995 0.56338374 0.5        1.
  0.41208789 0.4162515 ]]
07:00:42 bandwidth of the KDEs:
[0.93038865 0.15379994 0.2163274  0.28624806 0.05547788 0.43858941
 0.31087773 0.20190567]
[0.94066949 0.17653868 0.28575046 0.14108478 0.15444389 0.001
 0.21688492 0.2078469 ]
07:00:42 l(x) = 0.12866344489614545
07:00:42 g(x) = inf
07:00:42 best_vector: [0, 0.7233612022430869, 0.0077869721404866254, 0.8660062141844779, 0.32665888522638153, 0, 0.6384316736326946, 0.22384800837230073], 12.268283368388545, 0.12866344489614545, inf
07:00:42 done sampling a new configuration.
07:00:42 HBMASTER: schedule new run for iteration 3
07:00:42 HBMASTER: trying submitting job (3, 0, 0) to dispatcher
07:00:42 HBMASTER: submitting job (3, 0, 0) to dispatcher
07:00:42 DISPATCHER: trying to submit job (3, 0, 0)
07:00:42 DISPATCHER: trying to notify the job_runner thread.
07:00:42 HBMASTER: job (3, 0, 0) submitted to dispatcher
07:00:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:00:42 DISPATCHER: Trying to submit another job.
07:00:42 DISPATCHER: starting job (3, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
07:00:42 DISPATCHER: job (3, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
07:00:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:00:42 WORKER: start processing job (3, 0, 0)
07:00:42 WORKER: args: ()
07:00:42 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 78, 'last_n_outputs': 1, 'lr': 0.053952606211497466, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.019553881248180468}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-467:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:01:16 DISPATCHER: Starting worker discovery
07:01:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:01:16 DISPATCHER: Finished worker discovery
07:02:16 DISPATCHER: Starting worker discovery
07:02:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:02:16 DISPATCHER: Finished worker discovery
07:03:16 DISPATCHER: Starting worker discovery
07:03:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:03:16 DISPATCHER: Finished worker discovery
07:04:16 DISPATCHER: Starting worker discovery
07:04:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:04:16 DISPATCHER: Finished worker discovery
07:05:16 DISPATCHER: Starting worker discovery
07:05:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:05:16 DISPATCHER: Finished worker discovery
07:06:16 DISPATCHER: Starting worker discovery
07:06:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:06:16 DISPATCHER: Finished worker discovery
07:07:16 DISPATCHER: Starting worker discovery
07:07:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:07:16 DISPATCHER: Finished worker discovery
07:08:16 DISPATCHER: Starting worker discovery
07:08:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:08:16 DISPATCHER: Finished worker discovery
07:09:16 DISPATCHER: Starting worker discovery
07:09:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:09:16 DISPATCHER: Finished worker discovery
07:10:16 DISPATCHER: Starting worker discovery
07:10:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:10:16 DISPATCHER: Finished worker discovery
07:11:16 DISPATCHER: Starting worker discovery
07:11:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:11:16 DISPATCHER: Finished worker discovery
07:12:16 DISPATCHER: Starting worker discovery
07:12:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:12:16 DISPATCHER: Finished worker discovery
07:13:16 DISPATCHER: Starting worker discovery
07:13:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:13:16 DISPATCHER: Finished worker discovery
07:14:16 DISPATCHER: Starting worker discovery
07:14:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:14:16 DISPATCHER: Finished worker discovery
07:15:16 DISPATCHER: Starting worker discovery
07:15:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:15:16 DISPATCHER: Finished worker discovery
07:16:16 DISPATCHER: Starting worker discovery
07:16:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:16:16 DISPATCHER: Finished worker discovery
07:17:16 DISPATCHER: Starting worker discovery
07:17:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:17:16 DISPATCHER: Finished worker discovery
07:18:16 DISPATCHER: Starting worker discovery
07:18:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:18:16 DISPATCHER: Finished worker discovery
07:19:16 DISPATCHER: Starting worker discovery
07:19:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:19:16 DISPATCHER: Finished worker discovery
07:20:16 DISPATCHER: Starting worker discovery
07:20:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:20:16 DISPATCHER: Finished worker discovery
07:20:55 WORKER: done with job (3, 0, 0), trying to register it.
07:20:55 WORKER: registered result for job (3, 0, 0) with dispatcher
07:20:55 DISPATCHER: job (3, 0, 0) finished
07:20:55 DISPATCHER: register_result: lock acquired
07:20:55 DISPATCHER: job (3, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
07:20:55 job_id: (3, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 78, 'last_n_outputs': 1, 'lr': 0.053952606211497466, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.019553881248180468}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 78, 'last_n_outputs': 1, 'lr': 0.053952606211497466, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.019553881248180468}"}}
exception: None

07:20:55 job_callback for (3, 0, 0) started
07:20:55 job_callback for (3, 0, 0) got condition
07:20:55 DISPATCHER: Trying to submit another job.
07:20:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:20:55 Only 5 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
07:20:55 HBMASTER: Trying to run another job!
07:20:55 job_callback for (3, 0, 0) finished
07:20:55 start sampling a new configuration.
07:20:55 sampled vector: [1, 0.6283806372271665, 0.8138848096048734, 0.09839128215399494, 0.1755696742342849, 0, 0.651220395607801, 0.19061192186804177] has EI value inf
07:20:55 data in the KDEs:
[[3.         0.67283955 0.67000007 0.02556037 0.0999984  0.
  0.98351659 0.01501267]
 [2.         0.91975319 0.06999983 0.49134915 0.0999984  0.
  0.34615381 0.2220369 ]
 [1.         0.99382728 0.16999987 0.06463218 0.0999984  0.
  0.04945045 0.09498723]
 [3.         0.94444455 0.55000002 0.69169086 0.0999984  1.
  0.69780224 0.57093564]
 [0.         0.45061727 0.49       0.75725213 0.0999984  1.
  0.77472534 0.04815185]
 [3.         0.82098773 0.26999991 0.846535   0.0999984  1.
  0.29120875 0.67572506]
 [3.         0.90740751 0.32999993 0.74196297 0.2999992  1.
  0.98351659 0.25068711]
 [2.         0.67283955 0.77000011 0.05933137 0.0999984  1.
  0.91758251 0.03312671]
 [1.         0.99382728 0.04999982 0.73851202 0.0999984  0.
  0.12637354 0.0892389 ]]
[[0.         0.56172841 0.97000019 0.75808465 0.5        1.
  0.20329664 0.96083405]
 [2.         0.88271614 0.38999996 0.80879291 0.2999992  1.
  0.40109888 0.65476406]
 [1.         0.43827159 0.26999991 0.5613407  0.2999992  1.
  0.75274731 0.52552923]
 [1.         0.3641975  0.91000016 0.66624211 0.5        1.
  0.48901099 0.55120704]
 [2.         0.72222228 0.16999987 0.9413961  0.0999984  1.
  0.03846144 0.74478876]
 [3.         0.85802478 0.04999982 0.90369329 0.0999984  1.
  0.14835157 0.41206949]
 [0.         0.95679024 0.26999991 0.44141548 0.0999984  1.
  0.6648352  0.05588327]
 [2.         0.88271614 0.0099998  0.80797366 0.0999984  1.
  0.03846144 0.56321253]
 [3.         0.66049387 0.36999995 0.56338374 0.5        1.
  0.41208789 0.4162515 ]]
07:20:55 bandwidth of the KDEs:
[0.93038865 0.15379994 0.2163274  0.28624806 0.05547788 0.43858941
 0.31087773 0.20190567]
[0.94066949 0.17653868 0.28575046 0.14108478 0.15444389 0.001
 0.21688492 0.2078469 ]
07:20:55 l(x) = 0.6206547323945396
07:20:55 g(x) = inf
07:20:55 best_vector: [1, 0.6283806372271665, 0.8138848096048734, 0.09839128215399494, 0.1755696742342849, 0, 0.651220395607801, 0.19061192186804177], 0.15597687920492276, 0.6206547323945396, inf
07:20:55 done sampling a new configuration.
07:20:55 HBMASTER: schedule new run for iteration 3
07:20:55 HBMASTER: trying submitting job (3, 0, 1) to dispatcher
07:20:55 HBMASTER: submitting job (3, 0, 1) to dispatcher
07:20:55 DISPATCHER: trying to submit job (3, 0, 1)
07:20:55 DISPATCHER: trying to notify the job_runner thread.
07:20:55 HBMASTER: job (3, 0, 1) submitted to dispatcher
07:20:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:20:55 DISPATCHER: Trying to submit another job.
07:20:55 DISPATCHER: starting job (3, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
07:20:55 DISPATCHER: job (3, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
07:20:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:20:55 WORKER: start processing job (3, 0, 1)
07:20:55 WORKER: args: ()
07:20:55 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 70, 'last_n_outputs': 41, 'lr': 0.0015731950248591513, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.017700756504935775}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-468:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:21:16 DISPATCHER: Starting worker discovery
07:21:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:21:16 DISPATCHER: Finished worker discovery
07:22:16 DISPATCHER: Starting worker discovery
07:22:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:22:16 DISPATCHER: Finished worker discovery
07:23:16 DISPATCHER: Starting worker discovery
07:23:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:23:16 DISPATCHER: Finished worker discovery
07:24:16 DISPATCHER: Starting worker discovery
07:24:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:24:16 DISPATCHER: Finished worker discovery
07:25:16 DISPATCHER: Starting worker discovery
07:25:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:25:16 DISPATCHER: Finished worker discovery
07:26:16 DISPATCHER: Starting worker discovery
07:26:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:26:16 DISPATCHER: Finished worker discovery
07:27:16 DISPATCHER: Starting worker discovery
07:27:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:27:16 DISPATCHER: Finished worker discovery
07:28:16 DISPATCHER: Starting worker discovery
07:28:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:28:16 DISPATCHER: Finished worker discovery
07:29:16 DISPATCHER: Starting worker discovery
07:29:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:29:16 DISPATCHER: Finished worker discovery
07:30:16 DISPATCHER: Starting worker discovery
07:30:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:30:16 DISPATCHER: Finished worker discovery
07:31:16 DISPATCHER: Starting worker discovery
07:31:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:31:16 DISPATCHER: Finished worker discovery
07:32:16 DISPATCHER: Starting worker discovery
07:32:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:32:16 DISPATCHER: Finished worker discovery
07:33:16 DISPATCHER: Starting worker discovery
07:33:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:33:16 DISPATCHER: Finished worker discovery
07:34:16 DISPATCHER: Starting worker discovery
07:34:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:34:16 DISPATCHER: Finished worker discovery
07:35:16 DISPATCHER: Starting worker discovery
07:35:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:35:16 DISPATCHER: Finished worker discovery
07:36:16 DISPATCHER: Starting worker discovery
07:36:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:36:16 DISPATCHER: Finished worker discovery
07:37:16 DISPATCHER: Starting worker discovery
07:37:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:37:16 DISPATCHER: Finished worker discovery
07:38:16 DISPATCHER: Starting worker discovery
07:38:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:38:16 DISPATCHER: Finished worker discovery
07:39:16 DISPATCHER: Starting worker discovery
07:39:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:39:16 DISPATCHER: Finished worker discovery
07:40:16 DISPATCHER: Starting worker discovery
07:40:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:40:16 DISPATCHER: Finished worker discovery
07:41:08 WORKER: done with job (3, 0, 1), trying to register it.
07:41:08 WORKER: registered result for job (3, 0, 1) with dispatcher
07:41:08 DISPATCHER: job (3, 0, 1) finished
07:41:08 DISPATCHER: register_result: lock acquired
07:41:08 DISPATCHER: job (3, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
07:41:08 job_id: (3, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 70, 'last_n_outputs': 41, 'lr': 0.0015731950248591513, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.017700756504935775}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.10710922152410662, 'info': {'data04': 0.10710922152410662, 'config': "{'batch_size': 32, 'hidden_dim': 70, 'last_n_outputs': 41, 'lr': 0.0015731950248591513, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.017700756504935775}"}}
exception: None

07:41:08 job_callback for (3, 0, 1) started
07:41:08 DISPATCHER: Trying to submit another job.
07:41:08 job_callback for (3, 0, 1) got condition
07:41:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:41:08 Only 6 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
07:41:08 HBMASTER: Trying to run another job!
07:41:08 job_callback for (3, 0, 1) finished
07:41:08 start sampling a new configuration.
07:41:08 done sampling a new configuration.
07:41:08 HBMASTER: schedule new run for iteration 3
07:41:08 HBMASTER: trying submitting job (3, 0, 2) to dispatcher
07:41:08 HBMASTER: submitting job (3, 0, 2) to dispatcher
07:41:08 DISPATCHER: trying to submit job (3, 0, 2)
07:41:08 DISPATCHER: trying to notify the job_runner thread.
07:41:08 HBMASTER: job (3, 0, 2) submitted to dispatcher
07:41:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:41:08 DISPATCHER: Trying to submit another job.
07:41:08 DISPATCHER: starting job (3, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
07:41:08 DISPATCHER: job (3, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
07:41:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:41:08 WORKER: start processing job (3, 0, 2)
07:41:08 WORKER: args: ()
07:41:08 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 43, 'last_n_outputs': 19, 'lr': 0.0012951674496326344, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.09329087724870608}, 'budget': 1200.0, 'working_directory': '.'}
07:41:16 DISPATCHER: Starting worker discovery
07:41:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:41:16 DISPATCHER: Finished worker discovery
Exception in thread Thread-469:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:42:16 DISPATCHER: Starting worker discovery
07:42:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:42:16 DISPATCHER: Finished worker discovery
07:43:16 DISPATCHER: Starting worker discovery
07:43:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:43:16 DISPATCHER: Finished worker discovery
07:44:16 DISPATCHER: Starting worker discovery
07:44:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:44:16 DISPATCHER: Finished worker discovery
07:45:16 DISPATCHER: Starting worker discovery
07:45:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:45:16 DISPATCHER: Finished worker discovery
07:46:16 DISPATCHER: Starting worker discovery
07:46:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:46:16 DISPATCHER: Finished worker discovery
07:47:16 DISPATCHER: Starting worker discovery
07:47:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:47:16 DISPATCHER: Finished worker discovery
07:48:16 DISPATCHER: Starting worker discovery
07:48:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:48:16 DISPATCHER: Finished worker discovery
07:49:16 DISPATCHER: Starting worker discovery
07:49:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:49:16 DISPATCHER: Finished worker discovery
07:50:16 DISPATCHER: Starting worker discovery
07:50:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:50:16 DISPATCHER: Finished worker discovery
07:51:16 DISPATCHER: Starting worker discovery
07:51:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:51:16 DISPATCHER: Finished worker discovery
07:52:16 DISPATCHER: Starting worker discovery
07:52:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:52:16 DISPATCHER: Finished worker discovery
07:53:16 DISPATCHER: Starting worker discovery
07:53:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:53:16 DISPATCHER: Finished worker discovery
07:54:16 DISPATCHER: Starting worker discovery
07:54:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:54:16 DISPATCHER: Finished worker discovery
07:55:16 DISPATCHER: Starting worker discovery
07:55:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:55:16 DISPATCHER: Finished worker discovery
07:56:16 DISPATCHER: Starting worker discovery
07:56:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:56:16 DISPATCHER: Finished worker discovery
07:57:16 DISPATCHER: Starting worker discovery
07:57:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:57:16 DISPATCHER: Finished worker discovery
07:58:16 DISPATCHER: Starting worker discovery
07:58:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:58:16 DISPATCHER: Finished worker discovery
07:59:16 DISPATCHER: Starting worker discovery
07:59:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:59:16 DISPATCHER: Finished worker discovery
08:00:16 DISPATCHER: Starting worker discovery
08:00:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:00:16 DISPATCHER: Finished worker discovery
08:01:16 DISPATCHER: Starting worker discovery
08:01:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:01:16 DISPATCHER: Finished worker discovery
08:01:21 WORKER: done with job (3, 0, 2), trying to register it.
08:01:21 WORKER: registered result for job (3, 0, 2) with dispatcher
08:01:21 DISPATCHER: job (3, 0, 2) finished
08:01:21 DISPATCHER: register_result: lock acquired
08:01:21 DISPATCHER: job (3, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
08:01:21 job_id: (3, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 43, 'last_n_outputs': 19, 'lr': 0.0012951674496326344, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.09329087724870608}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.01178544432012478, 'info': {'data04': 0.01178544432012478, 'config': "{'batch_size': 64, 'hidden_dim': 43, 'last_n_outputs': 19, 'lr': 0.0012951674496326344, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.09329087724870608}"}}
exception: None

08:01:21 job_callback for (3, 0, 2) started
08:01:21 job_callback for (3, 0, 2) got condition
08:01:21 DISPATCHER: Trying to submit another job.
08:01:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:01:21 Only 7 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
08:01:21 HBMASTER: Trying to run another job!
08:01:21 job_callback for (3, 0, 2) finished
08:01:21 start sampling a new configuration.
08:01:21 done sampling a new configuration.
08:01:21 HBMASTER: schedule new run for iteration 3
08:01:21 HBMASTER: trying submitting job (3, 0, 3) to dispatcher
08:01:21 HBMASTER: submitting job (3, 0, 3) to dispatcher
08:01:21 DISPATCHER: trying to submit job (3, 0, 3)
08:01:21 DISPATCHER: trying to notify the job_runner thread.
08:01:21 HBMASTER: job (3, 0, 3) submitted to dispatcher
08:01:21 DISPATCHER: Trying to submit another job.
08:01:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:01:21 DISPATCHER: starting job (3, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:01:21 DISPATCHER: job (3, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:01:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:01:21 WORKER: start processing job (3, 0, 3)
08:01:21 WORKER: args: ()
08:01:21 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 99, 'last_n_outputs': 10, 'lr': 0.009422418575436063, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.025905312537736352}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-470:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:02:16 DISPATCHER: Starting worker discovery
08:02:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:02:16 DISPATCHER: Finished worker discovery
08:03:16 DISPATCHER: Starting worker discovery
08:03:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:03:16 DISPATCHER: Finished worker discovery
08:04:16 DISPATCHER: Starting worker discovery
08:04:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:04:16 DISPATCHER: Finished worker discovery
08:05:16 DISPATCHER: Starting worker discovery
08:05:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:05:16 DISPATCHER: Finished worker discovery
08:06:16 DISPATCHER: Starting worker discovery
08:06:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:06:16 DISPATCHER: Finished worker discovery
08:07:16 DISPATCHER: Starting worker discovery
08:07:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:07:16 DISPATCHER: Finished worker discovery
08:08:16 DISPATCHER: Starting worker discovery
08:08:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:08:16 DISPATCHER: Finished worker discovery
08:09:16 DISPATCHER: Starting worker discovery
08:09:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:09:16 DISPATCHER: Finished worker discovery
08:10:16 DISPATCHER: Starting worker discovery
08:10:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:10:16 DISPATCHER: Finished worker discovery
08:11:16 DISPATCHER: Starting worker discovery
08:11:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:11:16 DISPATCHER: Finished worker discovery
08:12:16 DISPATCHER: Starting worker discovery
08:12:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:12:16 DISPATCHER: Finished worker discovery
08:13:16 DISPATCHER: Starting worker discovery
08:13:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:13:16 DISPATCHER: Finished worker discovery
08:14:16 DISPATCHER: Starting worker discovery
08:14:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:14:16 DISPATCHER: Finished worker discovery
08:15:16 DISPATCHER: Starting worker discovery
08:15:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:15:16 DISPATCHER: Finished worker discovery
08:16:16 DISPATCHER: Starting worker discovery
08:16:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:16:16 DISPATCHER: Finished worker discovery
08:17:16 DISPATCHER: Starting worker discovery
08:17:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:17:16 DISPATCHER: Finished worker discovery
08:18:16 DISPATCHER: Starting worker discovery
08:18:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:18:16 DISPATCHER: Finished worker discovery
08:19:16 DISPATCHER: Starting worker discovery
08:19:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:19:16 DISPATCHER: Finished worker discovery
08:20:16 DISPATCHER: Starting worker discovery
08:20:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:20:16 DISPATCHER: Finished worker discovery
08:21:16 DISPATCHER: Starting worker discovery
08:21:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:21:16 DISPATCHER: Finished worker discovery
08:21:37 WORKER: done with job (3, 0, 3), trying to register it.
08:21:37 WORKER: registered result for job (3, 0, 3) with dispatcher
08:21:37 DISPATCHER: job (3, 0, 3) finished
08:21:37 DISPATCHER: register_result: lock acquired
08:21:37 DISPATCHER: job (3, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
08:21:37 job_id: (3, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 99, 'last_n_outputs': 10, 'lr': 0.009422418575436063, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.025905312537736352}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': 0.0037845830197166946, 'info': {'data04': -0.0037845830197166946, 'config': "{'batch_size': 16, 'hidden_dim': 99, 'last_n_outputs': 10, 'lr': 0.009422418575436063, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.025905312537736352}"}}
exception: None

08:21:37 job_callback for (3, 0, 3) started
08:21:37 job_callback for (3, 0, 3) got condition
08:21:37 DISPATCHER: Trying to submit another job.
08:21:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:21:37 Only 8 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
08:21:37 HBMASTER: Trying to run another job!
08:21:37 job_callback for (3, 0, 3) finished
08:21:37 start sampling a new configuration.
08:21:37 sampled vector: [0, 0.7198890765803583, 0.8037323148897498, 0.21505977422144035, 0.005408074319795841, 0, 0.4873360315208387, 0.3146190217685949] has EI value inf
08:21:37 data in the KDEs:
[[3.         0.67283955 0.67000007 0.02556037 0.0999984  0.
  0.98351659 0.01501267]
 [2.         0.91975319 0.06999983 0.49134915 0.0999984  0.
  0.34615381 0.2220369 ]
 [1.         0.99382728 0.16999987 0.06463218 0.0999984  0.
  0.04945045 0.09498723]
 [3.         0.94444455 0.55000002 0.69169086 0.0999984  1.
  0.69780224 0.57093564]
 [0.         0.45061727 0.49       0.75725213 0.0999984  1.
  0.77472534 0.04815185]
 [3.         0.82098773 0.26999991 0.846535   0.0999984  1.
  0.29120875 0.67572506]
 [3.         0.90740751 0.32999993 0.74196297 0.2999992  1.
  0.98351659 0.25068711]
 [2.         0.67283955 0.77000011 0.05933137 0.0999984  1.
  0.91758251 0.03312671]
 [1.         0.99382728 0.04999982 0.73851202 0.0999984  0.
  0.12637354 0.0892389 ]]
[[0.         0.56172841 0.97000019 0.75808465 0.5        1.
  0.20329664 0.96083405]
 [2.         0.88271614 0.38999996 0.80879291 0.2999992  1.
  0.40109888 0.65476406]
 [1.         0.43827159 0.26999991 0.5613407  0.2999992  1.
  0.75274731 0.52552923]
 [1.         0.3641975  0.91000016 0.66624211 0.5        1.
  0.48901099 0.55120704]
 [2.         0.72222228 0.16999987 0.9413961  0.0999984  1.
  0.03846144 0.74478876]
 [3.         0.85802478 0.04999982 0.90369329 0.0999984  1.
  0.14835157 0.41206949]
 [0.         0.95679024 0.26999991 0.44141548 0.0999984  1.
  0.6648352  0.05588327]
 [2.         0.88271614 0.0099998  0.80797366 0.0999984  1.
  0.03846144 0.56321253]
 [3.         0.66049387 0.36999995 0.56338374 0.5        1.
  0.41208789 0.4162515 ]]
08:21:37 bandwidth of the KDEs:
[0.93038865 0.15379994 0.2163274  0.28624806 0.05547788 0.43858941
 0.31087773 0.20190567]
[0.94066949 0.17653868 0.28575046 0.14108478 0.15444389 0.001
 0.21688492 0.2078469 ]
08:21:37 l(x) = 0.09092972635513027
08:21:37 g(x) = inf
08:21:37 best_vector: [0, 0.7198890765803583, 0.8037323148897498, 0.21505977422144035, 0.005408074319795841, 0, 0.4873360315208387, 0.3146190217685949], inf, 0.09092972635513027, inf
08:21:37 done sampling a new configuration.
08:21:37 HBMASTER: schedule new run for iteration 4
08:21:37 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
08:21:37 HBMASTER: submitting job (4, 0, 0) to dispatcher
08:21:37 DISPATCHER: trying to submit job (4, 0, 0)
08:21:37 DISPATCHER: trying to notify the job_runner thread.
08:21:37 HBMASTER: job (4, 0, 0) submitted to dispatcher
08:21:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:21:37 DISPATCHER: Trying to submit another job.
08:21:37 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:21:37 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:21:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:21:37 WORKER: start processing job (4, 0, 0)
08:21:37 WORKER: args: ()
08:21:37 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 78, 'last_n_outputs': 41, 'lr': 0.002692275805940447, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.025664262253956842}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-471:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:22:16 DISPATCHER: Starting worker discovery
08:22:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:22:16 DISPATCHER: Finished worker discovery
08:22:36 WORKER: done with job (4, 0, 0), trying to register it.
08:22:36 WORKER: registered result for job (4, 0, 0) with dispatcher
08:22:36 DISPATCHER: job (4, 0, 0) finished
08:22:36 DISPATCHER: register_result: lock acquired
08:22:36 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
08:22:36 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 78, 'last_n_outputs': 41, 'lr': 0.002692275805940447, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.025664262253956842}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.04506342723088861, 'info': {'data04': 0.04506342723088861, 'config': "{'batch_size': 16, 'hidden_dim': 78, 'last_n_outputs': 41, 'lr': 0.002692275805940447, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.025664262253956842}"}}
exception: None

08:22:36 job_callback for (4, 0, 0) started
08:22:36 DISPATCHER: Trying to submit another job.
08:22:36 job_callback for (4, 0, 0) got condition
08:22:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:22:36 HBMASTER: Trying to run another job!
08:22:36 job_callback for (4, 0, 0) finished
08:22:36 start sampling a new configuration.
08:22:36 done sampling a new configuration.
08:22:36 HBMASTER: schedule new run for iteration 4
08:22:36 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
08:22:36 HBMASTER: submitting job (4, 0, 1) to dispatcher
08:22:36 DISPATCHER: trying to submit job (4, 0, 1)
08:22:36 DISPATCHER: trying to notify the job_runner thread.
08:22:36 HBMASTER: job (4, 0, 1) submitted to dispatcher
08:22:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:22:36 DISPATCHER: Trying to submit another job.
08:22:36 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:22:36 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:22:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:22:36 WORKER: start processing job (4, 0, 1)
08:22:36 WORKER: args: ()
08:22:36 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 32, 'last_n_outputs': 12, 'lr': 0.08039702235552157, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.18457590062343923}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-472:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:23:16 DISPATCHER: Starting worker discovery
08:23:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:23:16 DISPATCHER: Finished worker discovery
08:23:35 WORKER: done with job (4, 0, 1), trying to register it.
08:23:35 WORKER: registered result for job (4, 0, 1) with dispatcher
08:23:35 DISPATCHER: job (4, 0, 1) finished
08:23:35 DISPATCHER: register_result: lock acquired
08:23:35 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
08:23:35 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 32, 'last_n_outputs': 12, 'lr': 0.08039702235552157, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.18457590062343923}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 32, 'last_n_outputs': 12, 'lr': 0.08039702235552157, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.18457590062343923}"}}
exception: None

08:23:35 job_callback for (4, 0, 1) started
08:23:35 DISPATCHER: Trying to submit another job.
08:23:35 job_callback for (4, 0, 1) got condition
08:23:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:23:35 HBMASTER: Trying to run another job!
08:23:35 job_callback for (4, 0, 1) finished
08:23:35 start sampling a new configuration.
08:23:35 sampled vector: [0, 0.8245052211956732, 0.747769337768912, 0.7172693142216334, 0.14034080003217445, 0, 0.8760403596327664, 0.009578307833101138] has EI value inf
08:23:35 data in the KDEs:
[[3.         0.67283955 0.67000007 0.02556037 0.0999984  0.
  0.98351659 0.01501267]
 [2.         0.91975319 0.06999983 0.49134915 0.0999984  0.
  0.34615381 0.2220369 ]
 [1.         0.99382728 0.16999987 0.06463218 0.0999984  0.
  0.04945045 0.09498723]
 [3.         0.94444455 0.55000002 0.69169086 0.0999984  1.
  0.69780224 0.57093564]
 [0.         0.45061727 0.49       0.75725213 0.0999984  1.
  0.77472534 0.04815185]
 [3.         0.82098773 0.26999991 0.846535   0.0999984  1.
  0.29120875 0.67572506]
 [3.         0.90740751 0.32999993 0.74196297 0.2999992  1.
  0.98351659 0.25068711]
 [2.         0.67283955 0.77000011 0.05933137 0.0999984  1.
  0.91758251 0.03312671]
 [1.         0.99382728 0.04999982 0.73851202 0.0999984  0.
  0.12637354 0.0892389 ]]
[[0.         0.56172841 0.97000019 0.75808465 0.5        1.
  0.20329664 0.96083405]
 [2.         0.88271614 0.38999996 0.80879291 0.2999992  1.
  0.40109888 0.65476406]
 [1.         0.43827159 0.26999991 0.5613407  0.2999992  1.
  0.75274731 0.52552923]
 [1.         0.3641975  0.91000016 0.66624211 0.5        1.
  0.48901099 0.55120704]
 [2.         0.72222228 0.16999987 0.9413961  0.0999984  1.
  0.03846144 0.74478876]
 [3.         0.85802478 0.04999982 0.90369329 0.0999984  1.
  0.14835157 0.41206949]
 [0.         0.95679024 0.26999991 0.44141548 0.0999984  1.
  0.6648352  0.05588327]
 [2.         0.88271614 0.0099998  0.80797366 0.0999984  1.
  0.03846144 0.56321253]
 [3.         0.66049387 0.36999995 0.56338374 0.5        1.
  0.41208789 0.4162515 ]]
08:23:35 bandwidth of the KDEs:
[0.93038865 0.15379994 0.2163274  0.28624806 0.05547788 0.43858941
 0.31087773 0.20190567]
[0.94066949 0.17653868 0.28575046 0.14108478 0.15444389 0.001
 0.21688492 0.2078469 ]
08:23:35 l(x) = 0.13629082947556292
08:23:35 g(x) = inf
08:23:35 best_vector: [0, 0.8245052211956732, 0.747769337768912, 0.7172693142216334, 0.14034080003217445, 0, 0.8760403596327664, 0.009578307833101138], inf, 0.13629082947556292, inf
08:23:35 done sampling a new configuration.
08:23:35 HBMASTER: schedule new run for iteration 4
08:23:35 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
08:23:35 HBMASTER: submitting job (4, 0, 2) to dispatcher
08:23:35 DISPATCHER: trying to submit job (4, 0, 2)
08:23:35 DISPATCHER: trying to notify the job_runner thread.
08:23:35 HBMASTER: job (4, 0, 2) submitted to dispatcher
08:23:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:23:35 DISPATCHER: Trying to submit another job.
08:23:35 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:23:35 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:23:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:23:35 WORKER: start processing job (4, 0, 2)
08:23:35 WORKER: args: ()
08:23:35 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 86, 'last_n_outputs': 38, 'lr': 0.027198103896308865, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.010291096859777452}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-473:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:24:16 DISPATCHER: Starting worker discovery
08:24:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:24:16 DISPATCHER: Finished worker discovery
08:24:32 WORKER: done with job (4, 0, 2), trying to register it.
08:24:32 WORKER: registered result for job (4, 0, 2) with dispatcher
08:24:32 DISPATCHER: job (4, 0, 2) finished
08:24:32 DISPATCHER: register_result: lock acquired
08:24:32 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
08:24:32 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 86, 'last_n_outputs': 38, 'lr': 0.027198103896308865, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.010291096859777452}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.014485083100436632, 'info': {'data04': 0.014485083100436632, 'config': "{'batch_size': 16, 'hidden_dim': 86, 'last_n_outputs': 38, 'lr': 0.027198103896308865, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.010291096859777452}"}}
exception: None

08:24:32 job_callback for (4, 0, 2) started
08:24:32 job_callback for (4, 0, 2) got condition
08:24:32 DISPATCHER: Trying to submit another job.
08:24:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:24:32 HBMASTER: Trying to run another job!
08:24:32 job_callback for (4, 0, 2) finished
08:24:32 start sampling a new configuration.
08:24:32 done sampling a new configuration.
08:24:32 HBMASTER: schedule new run for iteration 4
08:24:32 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
08:24:32 HBMASTER: submitting job (4, 0, 3) to dispatcher
08:24:32 DISPATCHER: trying to submit job (4, 0, 3)
08:24:32 DISPATCHER: trying to notify the job_runner thread.
08:24:32 HBMASTER: job (4, 0, 3) submitted to dispatcher
08:24:32 DISPATCHER: Trying to submit another job.
08:24:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:24:32 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:24:32 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:24:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:24:32 WORKER: start processing job (4, 0, 3)
08:24:32 WORKER: args: ()
08:24:32 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 20, 'last_n_outputs': 27, 'lr': 0.005934531232413164, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.08194598218939812}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-474:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:25:16 DISPATCHER: Starting worker discovery
08:25:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:25:16 DISPATCHER: Finished worker discovery
08:25:31 WORKER: done with job (4, 0, 3), trying to register it.
08:25:31 WORKER: registered result for job (4, 0, 3) with dispatcher
08:25:31 DISPATCHER: job (4, 0, 3) finished
08:25:31 DISPATCHER: register_result: lock acquired
08:25:31 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
08:25:31 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 20, 'last_n_outputs': 27, 'lr': 0.005934531232413164, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.08194598218939812}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.014638338177437923, 'info': {'data04': 0.014638338177437923, 'config': "{'batch_size': 32, 'hidden_dim': 20, 'last_n_outputs': 27, 'lr': 0.005934531232413164, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.08194598218939812}"}}
exception: None

08:25:31 job_callback for (4, 0, 3) started
08:25:31 job_callback for (4, 0, 3) got condition
08:25:31 DISPATCHER: Trying to submit another job.
08:25:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:25:31 HBMASTER: Trying to run another job!
08:25:31 job_callback for (4, 0, 3) finished
08:25:31 start sampling a new configuration.
08:25:31 sampled vector: [0, 0.8858564826204126, 0.30115843373757784, 0.17694844648352226, 0.15780132494147098, 0, 0.9257586924804352, 0.3856970341215922] has EI value inf
08:25:31 data in the KDEs:
[[3.         0.67283955 0.67000007 0.02556037 0.0999984  0.
  0.98351659 0.01501267]
 [2.         0.91975319 0.06999983 0.49134915 0.0999984  0.
  0.34615381 0.2220369 ]
 [1.         0.99382728 0.16999987 0.06463218 0.0999984  0.
  0.04945045 0.09498723]
 [3.         0.94444455 0.55000002 0.69169086 0.0999984  1.
  0.69780224 0.57093564]
 [0.         0.45061727 0.49       0.75725213 0.0999984  1.
  0.77472534 0.04815185]
 [3.         0.82098773 0.26999991 0.846535   0.0999984  1.
  0.29120875 0.67572506]
 [3.         0.90740751 0.32999993 0.74196297 0.2999992  1.
  0.98351659 0.25068711]
 [2.         0.67283955 0.77000011 0.05933137 0.0999984  1.
  0.91758251 0.03312671]
 [1.         0.99382728 0.04999982 0.73851202 0.0999984  0.
  0.12637354 0.0892389 ]]
[[0.         0.56172841 0.97000019 0.75808465 0.5        1.
  0.20329664 0.96083405]
 [2.         0.88271614 0.38999996 0.80879291 0.2999992  1.
  0.40109888 0.65476406]
 [1.         0.43827159 0.26999991 0.5613407  0.2999992  1.
  0.75274731 0.52552923]
 [1.         0.3641975  0.91000016 0.66624211 0.5        1.
  0.48901099 0.55120704]
 [2.         0.72222228 0.16999987 0.9413961  0.0999984  1.
  0.03846144 0.74478876]
 [3.         0.85802478 0.04999982 0.90369329 0.0999984  1.
  0.14835157 0.41206949]
 [0.         0.95679024 0.26999991 0.44141548 0.0999984  1.
  0.6648352  0.05588327]
 [2.         0.88271614 0.0099998  0.80797366 0.0999984  1.
  0.03846144 0.56321253]
 [3.         0.66049387 0.36999995 0.56338374 0.5        1.
  0.41208789 0.4162515 ]]
08:25:31 bandwidth of the KDEs:
[0.93038865 0.15379994 0.2163274  0.28624806 0.05547788 0.43858941
 0.31087773 0.20190567]
[0.94066949 0.17653868 0.28575046 0.14108478 0.15444389 0.001
 0.21688492 0.2078469 ]
08:25:31 l(x) = 0.14736444040288615
08:25:31 g(x) = inf
08:25:31 best_vector: [0, 0.8858564826204126, 0.30115843373757784, 0.17694844648352226, 0.15780132494147098, 0, 0.9257586924804352, 0.3856970341215922], inf, 0.14736444040288615, inf
08:25:31 done sampling a new configuration.
08:25:31 HBMASTER: schedule new run for iteration 4
08:25:31 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
08:25:31 HBMASTER: submitting job (4, 0, 4) to dispatcher
08:25:31 DISPATCHER: trying to submit job (4, 0, 4)
08:25:31 DISPATCHER: trying to notify the job_runner thread.
08:25:31 HBMASTER: job (4, 0, 4) submitted to dispatcher
08:25:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:25:31 DISPATCHER: Trying to submit another job.
08:25:31 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:25:31 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:25:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:25:31 WORKER: start processing job (4, 0, 4)
08:25:31 WORKER: args: ()
08:25:31 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 91, 'last_n_outputs': 16, 'lr': 0.002258899415107016, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.03175436340345553}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-475:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:26:16 DISPATCHER: Starting worker discovery
08:26:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:26:16 DISPATCHER: Finished worker discovery
08:26:28 WORKER: done with job (4, 0, 4), trying to register it.
08:26:28 WORKER: registered result for job (4, 0, 4) with dispatcher
08:26:28 DISPATCHER: job (4, 0, 4) finished
08:26:28 DISPATCHER: register_result: lock acquired
08:26:28 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
08:26:28 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 91, 'last_n_outputs': 16, 'lr': 0.002258899415107016, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.03175436340345553}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.08754768121208266, 'info': {'data04': 0.08754768121208266, 'config': "{'batch_size': 16, 'hidden_dim': 91, 'last_n_outputs': 16, 'lr': 0.002258899415107016, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.03175436340345553}"}}
exception: None

08:26:28 job_callback for (4, 0, 4) started
08:26:28 job_callback for (4, 0, 4) got condition
08:26:28 DISPATCHER: Trying to submit another job.
08:26:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:26:28 HBMASTER: Trying to run another job!
08:26:28 job_callback for (4, 0, 4) finished
08:26:28 start sampling a new configuration.
08:26:28 sampled vector: [1, 0.6709813114583407, 0.9323208616601087, 0.24660845931185515, 0.0262757149078401, 0, 0.9254135626729701, 0.26317393916865517] has EI value inf
08:26:28 data in the KDEs:
[[3.         0.67283955 0.67000007 0.02556037 0.0999984  0.
  0.98351659 0.01501267]
 [2.         0.91975319 0.06999983 0.49134915 0.0999984  0.
  0.34615381 0.2220369 ]
 [1.         0.99382728 0.16999987 0.06463218 0.0999984  0.
  0.04945045 0.09498723]
 [3.         0.94444455 0.55000002 0.69169086 0.0999984  1.
  0.69780224 0.57093564]
 [0.         0.45061727 0.49       0.75725213 0.0999984  1.
  0.77472534 0.04815185]
 [3.         0.82098773 0.26999991 0.846535   0.0999984  1.
  0.29120875 0.67572506]
 [3.         0.90740751 0.32999993 0.74196297 0.2999992  1.
  0.98351659 0.25068711]
 [2.         0.67283955 0.77000011 0.05933137 0.0999984  1.
  0.91758251 0.03312671]
 [1.         0.99382728 0.04999982 0.73851202 0.0999984  0.
  0.12637354 0.0892389 ]]
[[0.         0.56172841 0.97000019 0.75808465 0.5        1.
  0.20329664 0.96083405]
 [2.         0.88271614 0.38999996 0.80879291 0.2999992  1.
  0.40109888 0.65476406]
 [1.         0.43827159 0.26999991 0.5613407  0.2999992  1.
  0.75274731 0.52552923]
 [1.         0.3641975  0.91000016 0.66624211 0.5        1.
  0.48901099 0.55120704]
 [2.         0.72222228 0.16999987 0.9413961  0.0999984  1.
  0.03846144 0.74478876]
 [3.         0.85802478 0.04999982 0.90369329 0.0999984  1.
  0.14835157 0.41206949]
 [0.         0.95679024 0.26999991 0.44141548 0.0999984  1.
  0.6648352  0.05588327]
 [2.         0.88271614 0.0099998  0.80797366 0.0999984  1.
  0.03846144 0.56321253]
 [3.         0.66049387 0.36999995 0.56338374 0.5        1.
  0.41208789 0.4162515 ]]
08:26:28 bandwidth of the KDEs:
[0.93038865 0.15379994 0.2163274  0.28624806 0.05547788 0.43858941
 0.31087773 0.20190567]
[0.94066949 0.17653868 0.28575046 0.14108478 0.15444389 0.001
 0.21688492 0.2078469 ]
08:26:28 l(x) = 0.40736169990748183
08:26:28 g(x) = inf
08:26:28 best_vector: [1, 0.6709813114583407, 0.9323208616601087, 0.24660845931185515, 0.0262757149078401, 0, 0.9254135626729701, 0.26317393916865517], 0.009105164290589314, 0.40736169990748183, inf
08:26:28 done sampling a new configuration.
08:26:28 HBMASTER: schedule new run for iteration 4
08:26:28 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
08:26:28 HBMASTER: submitting job (4, 0, 5) to dispatcher
08:26:28 DISPATCHER: trying to submit job (4, 0, 5)
08:26:28 DISPATCHER: trying to notify the job_runner thread.
08:26:28 HBMASTER: job (4, 0, 5) submitted to dispatcher
08:26:28 DISPATCHER: Trying to submit another job.
08:26:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:26:28 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:26:28 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:26:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:26:28 WORKER: start processing job (4, 0, 5)
08:26:28 WORKER: args: ()
08:26:28 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 74, 'last_n_outputs': 47, 'lr': 0.003113270945444529, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.0219987086986536}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-476:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:27:16 DISPATCHER: Starting worker discovery
08:27:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:27:16 DISPATCHER: Finished worker discovery
08:27:26 WORKER: done with job (4, 0, 5), trying to register it.
08:27:26 WORKER: registered result for job (4, 0, 5) with dispatcher
08:27:26 DISPATCHER: job (4, 0, 5) finished
08:27:26 DISPATCHER: register_result: lock acquired
08:27:26 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
08:27:26 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 74, 'last_n_outputs': 47, 'lr': 0.003113270945444529, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.0219987086986536}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.11853910849248156, 'info': {'data04': 0.11853910849248156, 'config': "{'batch_size': 32, 'hidden_dim': 74, 'last_n_outputs': 47, 'lr': 0.003113270945444529, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.0219987086986536}"}}
exception: None

08:27:26 job_callback for (4, 0, 5) started
08:27:26 job_callback for (4, 0, 5) got condition
08:27:26 DISPATCHER: Trying to submit another job.
08:27:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:27:26 HBMASTER: Trying to run another job!
08:27:26 job_callback for (4, 0, 5) finished
08:27:26 start sampling a new configuration.
08:27:26 done sampling a new configuration.
08:27:26 HBMASTER: schedule new run for iteration 4
08:27:26 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
08:27:26 HBMASTER: submitting job (4, 0, 6) to dispatcher
08:27:26 DISPATCHER: trying to submit job (4, 0, 6)
08:27:26 DISPATCHER: trying to notify the job_runner thread.
08:27:26 HBMASTER: job (4, 0, 6) submitted to dispatcher
08:27:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:27:26 DISPATCHER: Trying to submit another job.
08:27:26 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:27:26 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:27:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:27:26 WORKER: start processing job (4, 0, 6)
08:27:26 WORKER: args: ()
08:27:26 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 15, 'lr': 0.0470941802216858, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.13616476167052566}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-477:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:28:16 DISPATCHER: Starting worker discovery
08:28:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:28:16 DISPATCHER: Finished worker discovery
08:28:23 WORKER: done with job (4, 0, 6), trying to register it.
08:28:23 WORKER: registered result for job (4, 0, 6) with dispatcher
08:28:23 DISPATCHER: job (4, 0, 6) finished
08:28:23 DISPATCHER: register_result: lock acquired
08:28:23 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
08:28:23 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 15, 'lr': 0.0470941802216858, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.13616476167052566}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.006242323151039125, 'info': {'data04': 0.006242323151039125, 'config': "{'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 15, 'lr': 0.0470941802216858, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.13616476167052566}"}}
exception: None

08:28:23 job_callback for (4, 0, 6) started
08:28:23 job_callback for (4, 0, 6) got condition
08:28:23 DISPATCHER: Trying to submit another job.
08:28:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:28:23 HBMASTER: Trying to run another job!
08:28:23 job_callback for (4, 0, 6) finished
08:28:23 start sampling a new configuration.
08:28:23 done sampling a new configuration.
08:28:23 HBMASTER: schedule new run for iteration 4
08:28:23 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
08:28:23 HBMASTER: submitting job (4, 0, 7) to dispatcher
08:28:23 DISPATCHER: trying to submit job (4, 0, 7)
08:28:23 DISPATCHER: trying to notify the job_runner thread.
08:28:23 HBMASTER: job (4, 0, 7) submitted to dispatcher
08:28:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:28:23 DISPATCHER: Trying to submit another job.
08:28:23 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:28:23 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:28:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:28:23 WORKER: start processing job (4, 0, 7)
08:28:23 WORKER: args: ()
08:28:23 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 54, 'last_n_outputs': 45, 'lr': 0.00948774335936977, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.015879238341631574}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-478:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:29:16 DISPATCHER: Starting worker discovery
08:29:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:29:16 DISPATCHER: Finished worker discovery
08:29:22 WORKER: done with job (4, 0, 7), trying to register it.
08:29:22 WORKER: registered result for job (4, 0, 7) with dispatcher
08:29:22 DISPATCHER: job (4, 0, 7) finished
08:29:22 DISPATCHER: register_result: lock acquired
08:29:22 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
08:29:22 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 54, 'last_n_outputs': 45, 'lr': 0.00948774335936977, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.015879238341631574}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 54, 'last_n_outputs': 45, 'lr': 0.00948774335936977, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.015879238341631574}"}}
exception: None

08:29:22 job_callback for (4, 0, 7) started
08:29:22 DISPATCHER: Trying to submit another job.
08:29:22 job_callback for (4, 0, 7) got condition
08:29:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:29:22 HBMASTER: Trying to run another job!
08:29:22 job_callback for (4, 0, 7) finished
08:29:22 start sampling a new configuration.
08:29:22 sampled vector: [0, 0.635047072773442, 0.11295807779137157, 0.7850057493664626, 0.1852893909626186, 0, 0.8651469443023386, 0.9983784419800548] has EI value inf
08:29:22 data in the KDEs:
[[3.         0.67283955 0.67000007 0.02556037 0.0999984  0.
  0.98351659 0.01501267]
 [2.         0.91975319 0.06999983 0.49134915 0.0999984  0.
  0.34615381 0.2220369 ]
 [1.         0.99382728 0.16999987 0.06463218 0.0999984  0.
  0.04945045 0.09498723]
 [3.         0.94444455 0.55000002 0.69169086 0.0999984  1.
  0.69780224 0.57093564]
 [0.         0.45061727 0.49       0.75725213 0.0999984  1.
  0.77472534 0.04815185]
 [3.         0.82098773 0.26999991 0.846535   0.0999984  1.
  0.29120875 0.67572506]
 [3.         0.90740751 0.32999993 0.74196297 0.2999992  1.
  0.98351659 0.25068711]
 [2.         0.67283955 0.77000011 0.05933137 0.0999984  1.
  0.91758251 0.03312671]
 [1.         0.99382728 0.04999982 0.73851202 0.0999984  0.
  0.12637354 0.0892389 ]]
[[0.         0.56172841 0.97000019 0.75808465 0.5        1.
  0.20329664 0.96083405]
 [2.         0.88271614 0.38999996 0.80879291 0.2999992  1.
  0.40109888 0.65476406]
 [1.         0.43827159 0.26999991 0.5613407  0.2999992  1.
  0.75274731 0.52552923]
 [1.         0.3641975  0.91000016 0.66624211 0.5        1.
  0.48901099 0.55120704]
 [2.         0.72222228 0.16999987 0.9413961  0.0999984  1.
  0.03846144 0.74478876]
 [3.         0.85802478 0.04999982 0.90369329 0.0999984  1.
  0.14835157 0.41206949]
 [0.         0.95679024 0.26999991 0.44141548 0.0999984  1.
  0.6648352  0.05588327]
 [2.         0.88271614 0.0099998  0.80797366 0.0999984  1.
  0.03846144 0.56321253]
 [3.         0.66049387 0.36999995 0.56338374 0.5        1.
  0.41208789 0.4162515 ]]
08:29:22 bandwidth of the KDEs:
[0.93038865 0.15379994 0.2163274  0.28624806 0.05547788 0.43858941
 0.31087773 0.20190567]
[0.94066949 0.17653868 0.28575046 0.14108478 0.15444389 0.001
 0.21688492 0.2078469 ]
08:29:22 l(x) = 0.011219742104099907
08:29:22 g(x) = inf
08:29:22 best_vector: [0, 0.635047072773442, 0.11295807779137157, 0.7850057493664626, 0.1852893909626186, 0, 0.8651469443023386, 0.9983784419800548], inf, 0.011219742104099907, inf
08:29:22 done sampling a new configuration.
08:29:22 HBMASTER: schedule new run for iteration 4
08:29:22 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
08:29:22 HBMASTER: submitting job (4, 0, 8) to dispatcher
08:29:22 DISPATCHER: trying to submit job (4, 0, 8)
08:29:22 DISPATCHER: trying to notify the job_runner thread.
08:29:22 HBMASTER: job (4, 0, 8) submitted to dispatcher
08:29:22 DISPATCHER: Trying to submit another job.
08:29:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:29:22 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:29:22 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:29:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:29:22 WORKER: start processing job (4, 0, 8)
08:29:22 WORKER: args: ()
08:29:22 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 6, 'lr': 0.03715450662954498, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.19903080522190084}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-479:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:30:16 DISPATCHER: Starting worker discovery
08:30:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:30:16 DISPATCHER: Finished worker discovery
08:30:19 WORKER: done with job (4, 0, 8), trying to register it.
08:30:19 WORKER: registered result for job (4, 0, 8) with dispatcher
08:30:19 DISPATCHER: job (4, 0, 8) finished
08:30:19 DISPATCHER: register_result: lock acquired
08:30:19 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
08:30:19 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 6, 'lr': 0.03715450662954498, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.19903080522190084}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.013234470823817991, 'info': {'data04': 0.013234470823817991, 'config': "{'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 6, 'lr': 0.03715450662954498, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.19903080522190084}"}}
exception: None

08:30:19 job_callback for (4, 0, 8) started
08:30:19 DISPATCHER: Trying to submit another job.
08:30:19 job_callback for (4, 0, 8) got condition
08:30:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:30:19 HBMASTER: Trying to run another job!
08:30:19 job_callback for (4, 0, 8) finished
08:30:19 start sampling a new configuration.
08:30:19 sampled vector: [1, 0.8703082457600662, 0.9185180224735281, 0.6517406431858718, 0.5143074215221372, 0, 0.052361193276853624, 0.3966828779896534] has EI value inf
08:30:19 data in the KDEs:
[[3.         0.67283955 0.67000007 0.02556037 0.0999984  0.
  0.98351659 0.01501267]
 [2.         0.91975319 0.06999983 0.49134915 0.0999984  0.
  0.34615381 0.2220369 ]
 [1.         0.99382728 0.16999987 0.06463218 0.0999984  0.
  0.04945045 0.09498723]
 [3.         0.94444455 0.55000002 0.69169086 0.0999984  1.
  0.69780224 0.57093564]
 [0.         0.45061727 0.49       0.75725213 0.0999984  1.
  0.77472534 0.04815185]
 [3.         0.82098773 0.26999991 0.846535   0.0999984  1.
  0.29120875 0.67572506]
 [3.         0.90740751 0.32999993 0.74196297 0.2999992  1.
  0.98351659 0.25068711]
 [2.         0.67283955 0.77000011 0.05933137 0.0999984  1.
  0.91758251 0.03312671]
 [1.         0.99382728 0.04999982 0.73851202 0.0999984  0.
  0.12637354 0.0892389 ]]
[[0.         0.56172841 0.97000019 0.75808465 0.5        1.
  0.20329664 0.96083405]
 [2.         0.88271614 0.38999996 0.80879291 0.2999992  1.
  0.40109888 0.65476406]
 [1.         0.43827159 0.26999991 0.5613407  0.2999992  1.
  0.75274731 0.52552923]
 [1.         0.3641975  0.91000016 0.66624211 0.5        1.
  0.48901099 0.55120704]
 [2.         0.72222228 0.16999987 0.9413961  0.0999984  1.
  0.03846144 0.74478876]
 [3.         0.85802478 0.04999982 0.90369329 0.0999984  1.
  0.14835157 0.41206949]
 [0.         0.95679024 0.26999991 0.44141548 0.0999984  1.
  0.6648352  0.05588327]
 [2.         0.88271614 0.0099998  0.80797366 0.0999984  1.
  0.03846144 0.56321253]
 [3.         0.66049387 0.36999995 0.56338374 0.5        1.
  0.41208789 0.4162515 ]]
08:30:19 bandwidth of the KDEs:
[0.93038865 0.15379994 0.2163274  0.28624806 0.05547788 0.43858941
 0.31087773 0.20190567]
[0.94066949 0.17653868 0.28575046 0.14108478 0.15444389 0.001
 0.21688492 0.2078469 ]
08:30:19 l(x) = 2.0930904260013828e-07
08:30:19 g(x) = inf
08:30:19 best_vector: [1, 0.8703082457600662, 0.9185180224735281, 0.6517406431858718, 0.5143074215221372, 0, 0.052361193276853624, 0.3966828779896534], inf, 2.0930904260013828e-07, inf
08:30:19 done sampling a new configuration.
08:30:19 HBMASTER: schedule new run for iteration 4
08:30:19 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
08:30:19 HBMASTER: submitting job (4, 0, 9) to dispatcher
08:30:19 DISPATCHER: trying to submit job (4, 0, 9)
08:30:19 DISPATCHER: trying to notify the job_runner thread.
08:30:19 HBMASTER: job (4, 0, 9) submitted to dispatcher
08:30:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:30:19 DISPATCHER: Trying to submit another job.
08:30:19 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:30:19 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:30:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:30:19 WORKER: start processing job (4, 0, 9)
08:30:19 WORKER: args: ()
08:30:19 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 90, 'last_n_outputs': 46, 'lr': 0.020113205290922854, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.032816807008652873}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-480:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:31:16 DISPATCHER: Starting worker discovery
08:31:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:31:16 DISPATCHER: Finished worker discovery
08:31:17 WORKER: done with job (4, 0, 9), trying to register it.
08:31:17 WORKER: registered result for job (4, 0, 9) with dispatcher
08:31:17 DISPATCHER: job (4, 0, 9) finished
08:31:17 DISPATCHER: register_result: lock acquired
08:31:17 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
08:31:17 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 90, 'last_n_outputs': 46, 'lr': 0.020113205290922854, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.032816807008652873}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.004594880532434894, 'info': {'data04': 0.004594880532434894, 'config': "{'batch_size': 32, 'hidden_dim': 90, 'last_n_outputs': 46, 'lr': 0.020113205290922854, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.032816807008652873}"}}
exception: None

08:31:17 job_callback for (4, 0, 9) started
08:31:17 DISPATCHER: Trying to submit another job.
08:31:17 job_callback for (4, 0, 9) got condition
08:31:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:31:17 HBMASTER: Trying to run another job!
08:31:17 job_callback for (4, 0, 9) finished
08:31:17 start sampling a new configuration.
08:31:17 done sampling a new configuration.
08:31:17 HBMASTER: schedule new run for iteration 4
08:31:17 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
08:31:17 HBMASTER: submitting job (4, 0, 10) to dispatcher
08:31:17 DISPATCHER: trying to submit job (4, 0, 10)
08:31:17 DISPATCHER: trying to notify the job_runner thread.
08:31:17 HBMASTER: job (4, 0, 10) submitted to dispatcher
08:31:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:31:17 DISPATCHER: Trying to submit another job.
08:31:17 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:31:17 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:31:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:31:17 WORKER: start processing job (4, 0, 10)
08:31:17 WORKER: args: ()
08:31:17 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 99, 'last_n_outputs': 1, 'lr': 0.003247620139961376, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.17171035973892718}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-481:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:32:16 DISPATCHER: Starting worker discovery
08:32:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:32:17 DISPATCHER: Finished worker discovery
08:32:17 WORKER: done with job (4, 0, 10), trying to register it.
08:32:17 WORKER: registered result for job (4, 0, 10) with dispatcher
08:32:17 DISPATCHER: job (4, 0, 10) finished
08:32:17 DISPATCHER: register_result: lock acquired
08:32:17 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
08:32:17 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 99, 'last_n_outputs': 1, 'lr': 0.003247620139961376, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.17171035973892718}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.01180319473315753, 'info': {'data04': -0.01180319473315753, 'config': "{'batch_size': 128, 'hidden_dim': 99, 'last_n_outputs': 1, 'lr': 0.003247620139961376, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.17171035973892718}"}}
exception: None

08:32:17 job_callback for (4, 0, 10) started
08:32:17 job_callback for (4, 0, 10) got condition
08:32:17 DISPATCHER: Trying to submit another job.
08:32:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:32:17 HBMASTER: Trying to run another job!
08:32:17 job_callback for (4, 0, 10) finished
08:32:17 start sampling a new configuration.
08:32:17 sampled vector: [3, 0.25906377378800804, 0.6808710503531763, 0.5595183906275472, 0.041616384550768985, 0, 0.5333487666084438, 0.3692168152596081] has EI value inf
08:32:17 data in the KDEs:
[[3.         0.67283955 0.67000007 0.02556037 0.0999984  0.
  0.98351659 0.01501267]
 [2.         0.91975319 0.06999983 0.49134915 0.0999984  0.
  0.34615381 0.2220369 ]
 [1.         0.99382728 0.16999987 0.06463218 0.0999984  0.
  0.04945045 0.09498723]
 [3.         0.94444455 0.55000002 0.69169086 0.0999984  1.
  0.69780224 0.57093564]
 [0.         0.45061727 0.49       0.75725213 0.0999984  1.
  0.77472534 0.04815185]
 [3.         0.82098773 0.26999991 0.846535   0.0999984  1.
  0.29120875 0.67572506]
 [3.         0.90740751 0.32999993 0.74196297 0.2999992  1.
  0.98351659 0.25068711]
 [2.         0.67283955 0.77000011 0.05933137 0.0999984  1.
  0.91758251 0.03312671]
 [1.         0.99382728 0.04999982 0.73851202 0.0999984  0.
  0.12637354 0.0892389 ]]
[[0.         0.56172841 0.97000019 0.75808465 0.5        1.
  0.20329664 0.96083405]
 [2.         0.88271614 0.38999996 0.80879291 0.2999992  1.
  0.40109888 0.65476406]
 [1.         0.43827159 0.26999991 0.5613407  0.2999992  1.
  0.75274731 0.52552923]
 [1.         0.3641975  0.91000016 0.66624211 0.5        1.
  0.48901099 0.55120704]
 [2.         0.72222228 0.16999987 0.9413961  0.0999984  1.
  0.03846144 0.74478876]
 [3.         0.85802478 0.04999982 0.90369329 0.0999984  1.
  0.14835157 0.41206949]
 [0.         0.95679024 0.26999991 0.44141548 0.0999984  1.
  0.6648352  0.05588327]
 [2.         0.88271614 0.0099998  0.80797366 0.0999984  1.
  0.03846144 0.56321253]
 [3.         0.66049387 0.36999995 0.56338374 0.5        1.
  0.41208789 0.4162515 ]]
08:32:17 bandwidth of the KDEs:
[0.93038865 0.15379994 0.2163274  0.28624806 0.05547788 0.43858941
 0.31087773 0.20190567]
[0.94066949 0.17653868 0.28575046 0.14108478 0.15444389 0.001
 0.21688492 0.2078469 ]
08:32:17 l(x) = 0.05500074339359968
08:32:17 g(x) = inf
08:32:17 best_vector: [3, 0.25906377378800804, 0.6808710503531763, 0.5595183906275472, 0.041616384550768985, 0, 0.5333487666084438, 0.3692168152596081], 0.5233013550770838, 0.05500074339359968, inf
08:32:17 done sampling a new configuration.
08:32:17 HBMASTER: schedule new run for iteration 4
08:32:17 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
08:32:17 HBMASTER: submitting job (4, 0, 11) to dispatcher
08:32:17 DISPATCHER: trying to submit job (4, 0, 11)
08:32:17 DISPATCHER: trying to notify the job_runner thread.
08:32:17 HBMASTER: job (4, 0, 11) submitted to dispatcher
08:32:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:32:17 DISPATCHER: Trying to submit another job.
08:32:17 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:32:17 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:32:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:32:17 WORKER: start processing job (4, 0, 11)
08:32:17 WORKER: args: ()
08:32:17 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 40, 'last_n_outputs': 35, 'lr': 0.013153362258908608, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.03022471062437051}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-482:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:33:14 WORKER: done with job (4, 0, 11), trying to register it.
08:33:14 WORKER: registered result for job (4, 0, 11) with dispatcher
08:33:14 DISPATCHER: job (4, 0, 11) finished
08:33:14 DISPATCHER: register_result: lock acquired
08:33:14 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
08:33:14 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 40, 'last_n_outputs': 35, 'lr': 0.013153362258908608, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.03022471062437051}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1193814183366693, 'info': {'data04': 0.1193814183366693, 'config': "{'batch_size': 128, 'hidden_dim': 40, 'last_n_outputs': 35, 'lr': 0.013153362258908608, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.03022471062437051}"}}
exception: None

08:33:14 job_callback for (4, 0, 11) started
08:33:14 job_callback for (4, 0, 11) got condition
08:33:14 DISPATCHER: Trying to submit another job.
08:33:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:33:14 HBMASTER: Trying to run another job!
08:33:14 job_callback for (4, 0, 11) finished
08:33:14 start sampling a new configuration.
08:33:14 sampled vector: [2, 0.9031252146060108, 0.9282794603523613, 0.24833536481886845, 0.16235519430849388, 0, 0.38417008388057433, 0.18685416310722994] has EI value inf
08:33:14 data in the KDEs:
[[3.         0.67283955 0.67000007 0.02556037 0.0999984  0.
  0.98351659 0.01501267]
 [2.         0.91975319 0.06999983 0.49134915 0.0999984  0.
  0.34615381 0.2220369 ]
 [1.         0.99382728 0.16999987 0.06463218 0.0999984  0.
  0.04945045 0.09498723]
 [3.         0.94444455 0.55000002 0.69169086 0.0999984  1.
  0.69780224 0.57093564]
 [0.         0.45061727 0.49       0.75725213 0.0999984  1.
  0.77472534 0.04815185]
 [3.         0.82098773 0.26999991 0.846535   0.0999984  1.
  0.29120875 0.67572506]
 [3.         0.90740751 0.32999993 0.74196297 0.2999992  1.
  0.98351659 0.25068711]
 [2.         0.67283955 0.77000011 0.05933137 0.0999984  1.
  0.91758251 0.03312671]
 [1.         0.99382728 0.04999982 0.73851202 0.0999984  0.
  0.12637354 0.0892389 ]]
[[0.         0.56172841 0.97000019 0.75808465 0.5        1.
  0.20329664 0.96083405]
 [2.         0.88271614 0.38999996 0.80879291 0.2999992  1.
  0.40109888 0.65476406]
 [1.         0.43827159 0.26999991 0.5613407  0.2999992  1.
  0.75274731 0.52552923]
 [1.         0.3641975  0.91000016 0.66624211 0.5        1.
  0.48901099 0.55120704]
 [2.         0.72222228 0.16999987 0.9413961  0.0999984  1.
  0.03846144 0.74478876]
 [3.         0.85802478 0.04999982 0.90369329 0.0999984  1.
  0.14835157 0.41206949]
 [0.         0.95679024 0.26999991 0.44141548 0.0999984  1.
  0.6648352  0.05588327]
 [2.         0.88271614 0.0099998  0.80797366 0.0999984  1.
  0.03846144 0.56321253]
 [3.         0.66049387 0.36999995 0.56338374 0.5        1.
  0.41208789 0.4162515 ]]
08:33:14 bandwidth of the KDEs:
[0.93038865 0.15379994 0.2163274  0.28624806 0.05547788 0.43858941
 0.31087773 0.20190567]
[0.94066949 0.17653868 0.28575046 0.14108478 0.15444389 0.001
 0.21688492 0.2078469 ]
08:33:14 l(x) = 0.03090639730750679
08:33:14 g(x) = inf
08:33:14 best_vector: [2, 0.9031252146060108, 0.9282794603523613, 0.24833536481886845, 0.16235519430849388, 0, 0.38417008388057433, 0.18685416310722994], 7.197038918702007, 0.03090639730750679, inf
08:33:14 done sampling a new configuration.
08:33:14 HBMASTER: schedule new run for iteration 4
08:33:14 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
08:33:14 HBMASTER: submitting job (4, 0, 12) to dispatcher
08:33:14 DISPATCHER: trying to submit job (4, 0, 12)
08:33:14 DISPATCHER: trying to notify the job_runner thread.
08:33:14 HBMASTER: job (4, 0, 12) submitted to dispatcher
08:33:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:33:14 DISPATCHER: Trying to submit another job.
08:33:14 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:33:14 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:33:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:33:14 WORKER: start processing job (4, 0, 12)
08:33:14 WORKER: args: ()
08:33:14 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 93, 'last_n_outputs': 47, 'lr': 0.003138128547286713, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.017502612226268692}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:33:17 DISPATCHER: Starting worker discovery
08:33:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:33:17 DISPATCHER: Finished worker discovery
Exception in thread Thread-483:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:34:11 WORKER: done with job (4, 0, 12), trying to register it.
08:34:11 WORKER: registered result for job (4, 0, 12) with dispatcher
08:34:11 DISPATCHER: job (4, 0, 12) finished
08:34:11 DISPATCHER: register_result: lock acquired
08:34:11 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
08:34:11 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 93, 'last_n_outputs': 47, 'lr': 0.003138128547286713, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.017502612226268692}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.15741168991896567, 'info': {'data04': 0.15741168991896567, 'config': "{'batch_size': 64, 'hidden_dim': 93, 'last_n_outputs': 47, 'lr': 0.003138128547286713, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.017502612226268692}"}}
exception: None

08:34:11 job_callback for (4, 0, 12) started
08:34:11 job_callback for (4, 0, 12) got condition
08:34:11 DISPATCHER: Trying to submit another job.
08:34:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:34:11 HBMASTER: Trying to run another job!
08:34:11 job_callback for (4, 0, 12) finished
08:34:11 start sampling a new configuration.
08:34:11 done sampling a new configuration.
08:34:11 HBMASTER: schedule new run for iteration 4
08:34:11 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
08:34:11 HBMASTER: submitting job (4, 0, 13) to dispatcher
08:34:11 DISPATCHER: trying to submit job (4, 0, 13)
08:34:11 DISPATCHER: trying to notify the job_runner thread.
08:34:11 HBMASTER: job (4, 0, 13) submitted to dispatcher
08:34:11 DISPATCHER: Trying to submit another job.
08:34:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:34:11 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:34:11 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:34:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:34:11 WORKER: start processing job (4, 0, 13)
08:34:11 WORKER: args: ()
08:34:11 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 40, 'lr': 0.001049957141582828, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.038455157149066575}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:34:17 DISPATCHER: Starting worker discovery
08:34:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:34:17 DISPATCHER: Finished worker discovery
Exception in thread Thread-484:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:35:11 WORKER: done with job (4, 0, 13), trying to register it.
08:35:11 WORKER: registered result for job (4, 0, 13) with dispatcher
08:35:11 DISPATCHER: job (4, 0, 13) finished
08:35:11 DISPATCHER: register_result: lock acquired
08:35:11 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
08:35:11 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 40, 'lr': 0.001049957141582828, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.038455157149066575}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.08504940116803138, 'info': {'data04': 0.08504940116803138, 'config': "{'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 40, 'lr': 0.001049957141582828, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.038455157149066575}"}}
exception: None

08:35:11 job_callback for (4, 0, 13) started
08:35:11 job_callback for (4, 0, 13) got condition
08:35:11 DISPATCHER: Trying to submit another job.
08:35:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:35:11 HBMASTER: Trying to run another job!
08:35:11 job_callback for (4, 0, 13) finished
08:35:11 start sampling a new configuration.
08:35:11 done sampling a new configuration.
08:35:11 HBMASTER: schedule new run for iteration 4
08:35:11 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
08:35:11 HBMASTER: submitting job (4, 0, 14) to dispatcher
08:35:11 DISPATCHER: trying to submit job (4, 0, 14)
08:35:11 DISPATCHER: trying to notify the job_runner thread.
08:35:11 HBMASTER: job (4, 0, 14) submitted to dispatcher
08:35:11 DISPATCHER: Trying to submit another job.
08:35:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:35:11 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:35:11 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:35:11 WORKER: start processing job (4, 0, 14)
08:35:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:35:11 WORKER: args: ()
08:35:11 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 95, 'last_n_outputs': 28, 'lr': 0.022996218017665316, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.12205630789202963}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:35:17 DISPATCHER: Starting worker discovery
08:35:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:35:17 DISPATCHER: Finished worker discovery
Exception in thread Thread-485:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:36:08 WORKER: done with job (4, 0, 14), trying to register it.
08:36:08 WORKER: registered result for job (4, 0, 14) with dispatcher
08:36:08 DISPATCHER: job (4, 0, 14) finished
08:36:08 DISPATCHER: register_result: lock acquired
08:36:08 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
08:36:08 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 95, 'last_n_outputs': 28, 'lr': 0.022996218017665316, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.12205630789202963}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 95, 'last_n_outputs': 28, 'lr': 0.022996218017665316, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.12205630789202963}"}}
exception: None

08:36:08 job_callback for (4, 0, 14) started
08:36:08 DISPATCHER: Trying to submit another job.
08:36:08 job_callback for (4, 0, 14) got condition
08:36:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:36:08 HBMASTER: Trying to run another job!
08:36:08 job_callback for (4, 0, 14) finished
08:36:08 start sampling a new configuration.
08:36:08 sampled vector: [3, 0.8061834636979168, 0.8584911597808802, 0.82688350320088, 0.5537897068745868, 0, 0.9807092718164793, 0.31319224081157815] has EI value inf
08:36:08 data in the KDEs:
[[3.         0.67283955 0.67000007 0.02556037 0.0999984  0.
  0.98351659 0.01501267]
 [2.         0.91975319 0.06999983 0.49134915 0.0999984  0.
  0.34615381 0.2220369 ]
 [1.         0.99382728 0.16999987 0.06463218 0.0999984  0.
  0.04945045 0.09498723]
 [3.         0.94444455 0.55000002 0.69169086 0.0999984  1.
  0.69780224 0.57093564]
 [0.         0.45061727 0.49       0.75725213 0.0999984  1.
  0.77472534 0.04815185]
 [3.         0.82098773 0.26999991 0.846535   0.0999984  1.
  0.29120875 0.67572506]
 [3.         0.90740751 0.32999993 0.74196297 0.2999992  1.
  0.98351659 0.25068711]
 [2.         0.67283955 0.77000011 0.05933137 0.0999984  1.
  0.91758251 0.03312671]
 [1.         0.99382728 0.04999982 0.73851202 0.0999984  0.
  0.12637354 0.0892389 ]]
[[0.         0.56172841 0.97000019 0.75808465 0.5        1.
  0.20329664 0.96083405]
 [2.         0.88271614 0.38999996 0.80879291 0.2999992  1.
  0.40109888 0.65476406]
 [1.         0.43827159 0.26999991 0.5613407  0.2999992  1.
  0.75274731 0.52552923]
 [1.         0.3641975  0.91000016 0.66624211 0.5        1.
  0.48901099 0.55120704]
 [2.         0.72222228 0.16999987 0.9413961  0.0999984  1.
  0.03846144 0.74478876]
 [3.         0.85802478 0.04999982 0.90369329 0.0999984  1.
  0.14835157 0.41206949]
 [0.         0.95679024 0.26999991 0.44141548 0.0999984  1.
  0.6648352  0.05588327]
 [2.         0.88271614 0.0099998  0.80797366 0.0999984  1.
  0.03846144 0.56321253]
 [3.         0.66049387 0.36999995 0.56338374 0.5        1.
  0.41208789 0.4162515 ]]
08:36:08 bandwidth of the KDEs:
[0.93038865 0.15379994 0.2163274  0.28624806 0.05547788 0.43858941
 0.31087773 0.20190567]
[0.94066949 0.17653868 0.28575046 0.14108478 0.15444389 0.001
 0.21688492 0.2078469 ]
08:36:08 l(x) = 4.375211143897299e-07
08:36:08 g(x) = inf
08:36:08 best_vector: [3, 0.8061834636979168, 0.8584911597808802, 0.82688350320088, 0.5537897068745868, 0, 0.9807092718164793, 0.31319224081157815], inf, 4.375211143897299e-07, inf
08:36:08 done sampling a new configuration.
08:36:08 HBMASTER: schedule new run for iteration 4
08:36:08 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
08:36:08 HBMASTER: submitting job (4, 0, 15) to dispatcher
08:36:08 DISPATCHER: trying to submit job (4, 0, 15)
08:36:08 DISPATCHER: trying to notify the job_runner thread.
08:36:08 HBMASTER: job (4, 0, 15) submitted to dispatcher
08:36:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:36:08 DISPATCHER: Trying to submit another job.
08:36:08 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:36:08 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:36:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:36:08 WORKER: start processing job (4, 0, 15)
08:36:08 WORKER: args: ()
08:36:08 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 85, 'last_n_outputs': 43, 'lr': 0.04505749118410712, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.025554800784211892}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:36:17 DISPATCHER: Starting worker discovery
08:36:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:36:17 DISPATCHER: Finished worker discovery
Exception in thread Thread-486:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:37:06 WORKER: done with job (4, 0, 15), trying to register it.
08:37:06 WORKER: registered result for job (4, 0, 15) with dispatcher
08:37:06 DISPATCHER: job (4, 0, 15) finished
08:37:06 DISPATCHER: register_result: lock acquired
08:37:06 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
08:37:06 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 85, 'last_n_outputs': 43, 'lr': 0.04505749118410712, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.025554800784211892}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 85, 'last_n_outputs': 43, 'lr': 0.04505749118410712, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.025554800784211892}"}}
exception: None

08:37:06 job_callback for (4, 0, 15) started
08:37:06 DISPATCHER: Trying to submit another job.
08:37:06 job_callback for (4, 0, 15) got condition
08:37:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:37:06 HBMASTER: Trying to run another job!
08:37:06 job_callback for (4, 0, 15) finished
08:37:06 start sampling a new configuration.
08:37:06 done sampling a new configuration.
08:37:06 HBMASTER: schedule new run for iteration 4
08:37:06 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
08:37:06 HBMASTER: submitting job (4, 0, 16) to dispatcher
08:37:06 DISPATCHER: trying to submit job (4, 0, 16)
08:37:06 DISPATCHER: trying to notify the job_runner thread.
08:37:06 HBMASTER: job (4, 0, 16) submitted to dispatcher
08:37:06 DISPATCHER: Trying to submit another job.
08:37:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:37:06 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:37:06 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:37:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:37:06 WORKER: start processing job (4, 0, 16)
08:37:06 WORKER: args: ()
08:37:06 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 29, 'last_n_outputs': 26, 'lr': 0.0511938463313695, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.10730172804134934}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:37:17 DISPATCHER: Starting worker discovery
08:37:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:37:17 DISPATCHER: Finished worker discovery
Exception in thread Thread-487:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:38:06 WORKER: done with job (4, 0, 16), trying to register it.
08:38:06 WORKER: registered result for job (4, 0, 16) with dispatcher
08:38:06 DISPATCHER: job (4, 0, 16) finished
08:38:06 DISPATCHER: register_result: lock acquired
08:38:06 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
08:38:06 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 29, 'last_n_outputs': 26, 'lr': 0.0511938463313695, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.10730172804134934}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 29, 'last_n_outputs': 26, 'lr': 0.0511938463313695, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.10730172804134934}"}}
exception: None

08:38:06 job_callback for (4, 0, 16) started
08:38:06 DISPATCHER: Trying to submit another job.
08:38:06 job_callback for (4, 0, 16) got condition
08:38:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:38:06 HBMASTER: Trying to run another job!
08:38:06 job_callback for (4, 0, 16) finished
08:38:06 start sampling a new configuration.
08:38:06 done sampling a new configuration.
08:38:06 HBMASTER: schedule new run for iteration 4
08:38:06 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
08:38:06 HBMASTER: submitting job (4, 0, 17) to dispatcher
08:38:06 DISPATCHER: trying to submit job (4, 0, 17)
08:38:06 DISPATCHER: trying to notify the job_runner thread.
08:38:06 HBMASTER: job (4, 0, 17) submitted to dispatcher
08:38:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:38:06 DISPATCHER: Trying to submit another job.
08:38:06 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:38:06 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:38:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:38:06 WORKER: start processing job (4, 0, 17)
08:38:06 WORKER: args: ()
08:38:06 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 31, 'last_n_outputs': 25, 'lr': 0.004136436984600525, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.0354907282003867}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:38:17 DISPATCHER: Starting worker discovery
08:38:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:38:17 DISPATCHER: Finished worker discovery
Exception in thread Thread-488:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:39:03 WORKER: done with job (4, 0, 17), trying to register it.
08:39:03 WORKER: registered result for job (4, 0, 17) with dispatcher
08:39:03 DISPATCHER: job (4, 0, 17) finished
08:39:03 DISPATCHER: register_result: lock acquired
08:39:03 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
08:39:03 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 31, 'last_n_outputs': 25, 'lr': 0.004136436984600525, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.0354907282003867}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 31, 'last_n_outputs': 25, 'lr': 0.004136436984600525, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.0354907282003867}"}}
exception: None

08:39:03 job_callback for (4, 0, 17) started
08:39:03 DISPATCHER: Trying to submit another job.
08:39:03 job_callback for (4, 0, 17) got condition
08:39:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:39:03 HBMASTER: Trying to run another job!
08:39:03 job_callback for (4, 0, 17) finished
08:39:03 start sampling a new configuration.
08:39:03 sampled vector: [3, 0.9155204185628784, 0.19600797509213339, 0.6498506726055433, 0.2895303993433621, 0, 0.7937046518310954, 0.44924464131521313] has EI value inf
08:39:03 data in the KDEs:
[[3.         0.67283955 0.67000007 0.02556037 0.0999984  0.
  0.98351659 0.01501267]
 [2.         0.91975319 0.06999983 0.49134915 0.0999984  0.
  0.34615381 0.2220369 ]
 [1.         0.99382728 0.16999987 0.06463218 0.0999984  0.
  0.04945045 0.09498723]
 [3.         0.94444455 0.55000002 0.69169086 0.0999984  1.
  0.69780224 0.57093564]
 [0.         0.45061727 0.49       0.75725213 0.0999984  1.
  0.77472534 0.04815185]
 [3.         0.82098773 0.26999991 0.846535   0.0999984  1.
  0.29120875 0.67572506]
 [3.         0.90740751 0.32999993 0.74196297 0.2999992  1.
  0.98351659 0.25068711]
 [2.         0.67283955 0.77000011 0.05933137 0.0999984  1.
  0.91758251 0.03312671]
 [1.         0.99382728 0.04999982 0.73851202 0.0999984  0.
  0.12637354 0.0892389 ]]
[[0.         0.56172841 0.97000019 0.75808465 0.5        1.
  0.20329664 0.96083405]
 [2.         0.88271614 0.38999996 0.80879291 0.2999992  1.
  0.40109888 0.65476406]
 [1.         0.43827159 0.26999991 0.5613407  0.2999992  1.
  0.75274731 0.52552923]
 [1.         0.3641975  0.91000016 0.66624211 0.5        1.
  0.48901099 0.55120704]
 [2.         0.72222228 0.16999987 0.9413961  0.0999984  1.
  0.03846144 0.74478876]
 [3.         0.85802478 0.04999982 0.90369329 0.0999984  1.
  0.14835157 0.41206949]
 [0.         0.95679024 0.26999991 0.44141548 0.0999984  1.
  0.6648352  0.05588327]
 [2.         0.88271614 0.0099998  0.80797366 0.0999984  1.
  0.03846144 0.56321253]
 [3.         0.66049387 0.36999995 0.56338374 0.5        1.
  0.41208789 0.4162515 ]]
08:39:03 bandwidth of the KDEs:
[0.93038865 0.15379994 0.2163274  0.28624806 0.05547788 0.43858941
 0.31087773 0.20190567]
[0.94066949 0.17653868 0.28575046 0.14108478 0.15444389 0.001
 0.21688492 0.2078469 ]
08:39:03 l(x) = 0.16365009339831954
08:39:03 g(x) = inf
08:39:03 best_vector: [3, 0.9155204185628784, 0.19600797509213339, 0.6498506726055433, 0.2895303993433621, 0, 0.7937046518310954, 0.44924464131521313], inf, 0.16365009339831954, inf
08:39:03 done sampling a new configuration.
08:39:03 HBMASTER: schedule new run for iteration 4
08:39:03 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
08:39:03 HBMASTER: submitting job (4, 0, 18) to dispatcher
08:39:03 DISPATCHER: trying to submit job (4, 0, 18)
08:39:03 DISPATCHER: trying to notify the job_runner thread.
08:39:03 HBMASTER: job (4, 0, 18) submitted to dispatcher
08:39:03 DISPATCHER: Trying to submit another job.
08:39:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:39:03 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:39:03 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:39:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:39:03 WORKER: start processing job (4, 0, 18)
08:39:03 WORKER: args: ()
08:39:03 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 94, 'last_n_outputs': 10, 'lr': 0.019938906885139152, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.03841322355413753}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:39:17 DISPATCHER: Starting worker discovery
08:39:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:39:17 DISPATCHER: Finished worker discovery
Exception in thread Thread-489:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:40:01 WORKER: done with job (4, 0, 18), trying to register it.
08:40:01 WORKER: registered result for job (4, 0, 18) with dispatcher
08:40:01 DISPATCHER: job (4, 0, 18) finished
08:40:01 DISPATCHER: register_result: lock acquired
08:40:01 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
08:40:01 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 94, 'last_n_outputs': 10, 'lr': 0.019938906885139152, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.03841322355413753}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 94, 'last_n_outputs': 10, 'lr': 0.019938906885139152, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.03841322355413753}"}}
exception: None

08:40:01 job_callback for (4, 0, 18) started
08:40:01 DISPATCHER: Trying to submit another job.
08:40:01 job_callback for (4, 0, 18) got condition
08:40:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:40:01 HBMASTER: Trying to run another job!
08:40:01 job_callback for (4, 0, 18) finished
08:40:01 start sampling a new configuration.
08:40:01 sampled vector: [3, 0.6082532058765299, 0.3573862975103982, 0.18161480347074765, 0.03102149429476904, 0, 0.0952526981852534, 0.4486794129024135] has EI value inf
08:40:01 data in the KDEs:
[[3.         0.67283955 0.67000007 0.02556037 0.0999984  0.
  0.98351659 0.01501267]
 [2.         0.91975319 0.06999983 0.49134915 0.0999984  0.
  0.34615381 0.2220369 ]
 [1.         0.99382728 0.16999987 0.06463218 0.0999984  0.
  0.04945045 0.09498723]
 [3.         0.94444455 0.55000002 0.69169086 0.0999984  1.
  0.69780224 0.57093564]
 [0.         0.45061727 0.49       0.75725213 0.0999984  1.
  0.77472534 0.04815185]
 [3.         0.82098773 0.26999991 0.846535   0.0999984  1.
  0.29120875 0.67572506]
 [3.         0.90740751 0.32999993 0.74196297 0.2999992  1.
  0.98351659 0.25068711]
 [2.         0.67283955 0.77000011 0.05933137 0.0999984  1.
  0.91758251 0.03312671]
 [1.         0.99382728 0.04999982 0.73851202 0.0999984  0.
  0.12637354 0.0892389 ]]
[[0.         0.56172841 0.97000019 0.75808465 0.5        1.
  0.20329664 0.96083405]
 [2.         0.88271614 0.38999996 0.80879291 0.2999992  1.
  0.40109888 0.65476406]
 [1.         0.43827159 0.26999991 0.5613407  0.2999992  1.
  0.75274731 0.52552923]
 [1.         0.3641975  0.91000016 0.66624211 0.5        1.
  0.48901099 0.55120704]
 [2.         0.72222228 0.16999987 0.9413961  0.0999984  1.
  0.03846144 0.74478876]
 [3.         0.85802478 0.04999982 0.90369329 0.0999984  1.
  0.14835157 0.41206949]
 [0.         0.95679024 0.26999991 0.44141548 0.0999984  1.
  0.6648352  0.05588327]
 [2.         0.88271614 0.0099998  0.80797366 0.0999984  1.
  0.03846144 0.56321253]
 [3.         0.66049387 0.36999995 0.56338374 0.5        1.
  0.41208789 0.4162515 ]]
08:40:01 bandwidth of the KDEs:
[0.93038865 0.15379994 0.2163274  0.28624806 0.05547788 0.43858941
 0.31087773 0.20190567]
[0.94066949 0.17653868 0.28575046 0.14108478 0.15444389 0.001
 0.21688492 0.2078469 ]
08:40:01 l(x) = 0.022736483653747353
08:40:01 g(x) = inf
08:40:01 best_vector: [3, 0.6082532058765299, 0.3573862975103982, 0.18161480347074765, 0.03102149429476904, 0, 0.0952526981852534, 0.4486794129024135], 2.5984183847282654, 0.022736483653747353, inf
08:40:01 done sampling a new configuration.
08:40:01 HBMASTER: schedule new run for iteration 4
08:40:01 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
08:40:01 HBMASTER: submitting job (4, 0, 19) to dispatcher
08:40:01 DISPATCHER: trying to submit job (4, 0, 19)
08:40:01 DISPATCHER: trying to notify the job_runner thread.
08:40:01 HBMASTER: job (4, 0, 19) submitted to dispatcher
08:40:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:40:01 DISPATCHER: Trying to submit another job.
08:40:01 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:40:01 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:40:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:40:01 WORKER: start processing job (4, 0, 19)
08:40:01 WORKER: args: ()
08:40:01 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 69, 'last_n_outputs': 18, 'lr': 0.0023079670642250152, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.0383482345175396}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-490:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:40:17 DISPATCHER: Starting worker discovery
08:40:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:40:17 DISPATCHER: Finished worker discovery
08:41:00 WORKER: done with job (4, 0, 19), trying to register it.
08:41:00 WORKER: registered result for job (4, 0, 19) with dispatcher
08:41:00 DISPATCHER: job (4, 0, 19) finished
08:41:00 DISPATCHER: register_result: lock acquired
08:41:00 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
08:41:00 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 69, 'last_n_outputs': 18, 'lr': 0.0023079670642250152, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.0383482345175396}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.07854166973528469, 'info': {'data04': 0.07854166973528469, 'config': "{'batch_size': 128, 'hidden_dim': 69, 'last_n_outputs': 18, 'lr': 0.0023079670642250152, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.0383482345175396}"}}
exception: None

08:41:00 job_callback for (4, 0, 19) started
08:41:00 job_callback for (4, 0, 19) got condition
08:41:00 DISPATCHER: Trying to submit another job.
08:41:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:41:00 HBMASTER: Trying to run another job!
08:41:00 job_callback for (4, 0, 19) finished
08:41:00 start sampling a new configuration.
08:41:00 sampled vector: [0, 0.9978429782509846, 0.12577462138180495, 0.6090998174511688, 0.39914671973813987, 0, 0.3457051536458299, 0.015552486535273219] has EI value inf
08:41:00 data in the KDEs:
[[3.         0.67283955 0.67000007 0.02556037 0.0999984  0.
  0.98351659 0.01501267]
 [2.         0.91975319 0.06999983 0.49134915 0.0999984  0.
  0.34615381 0.2220369 ]
 [1.         0.99382728 0.16999987 0.06463218 0.0999984  0.
  0.04945045 0.09498723]
 [3.         0.94444455 0.55000002 0.69169086 0.0999984  1.
  0.69780224 0.57093564]
 [0.         0.45061727 0.49       0.75725213 0.0999984  1.
  0.77472534 0.04815185]
 [3.         0.82098773 0.26999991 0.846535   0.0999984  1.
  0.29120875 0.67572506]
 [3.         0.90740751 0.32999993 0.74196297 0.2999992  1.
  0.98351659 0.25068711]
 [2.         0.67283955 0.77000011 0.05933137 0.0999984  1.
  0.91758251 0.03312671]
 [1.         0.99382728 0.04999982 0.73851202 0.0999984  0.
  0.12637354 0.0892389 ]]
[[0.         0.56172841 0.97000019 0.75808465 0.5        1.
  0.20329664 0.96083405]
 [2.         0.88271614 0.38999996 0.80879291 0.2999992  1.
  0.40109888 0.65476406]
 [1.         0.43827159 0.26999991 0.5613407  0.2999992  1.
  0.75274731 0.52552923]
 [1.         0.3641975  0.91000016 0.66624211 0.5        1.
  0.48901099 0.55120704]
 [2.         0.72222228 0.16999987 0.9413961  0.0999984  1.
  0.03846144 0.74478876]
 [3.         0.85802478 0.04999982 0.90369329 0.0999984  1.
  0.14835157 0.41206949]
 [0.         0.95679024 0.26999991 0.44141548 0.0999984  1.
  0.6648352  0.05588327]
 [2.         0.88271614 0.0099998  0.80797366 0.0999984  1.
  0.03846144 0.56321253]
 [3.         0.66049387 0.36999995 0.56338374 0.5        1.
  0.41208789 0.4162515 ]]
08:41:00 bandwidth of the KDEs:
[0.93038865 0.15379994 0.2163274  0.28624806 0.05547788 0.43858941
 0.31087773 0.20190567]
[0.94066949 0.17653868 0.28575046 0.14108478 0.15444389 0.001
 0.21688492 0.2078469 ]
08:41:00 l(x) = 0.011135985455284984
08:41:00 g(x) = inf
08:41:00 best_vector: [0, 0.9978429782509846, 0.12577462138180495, 0.6090998174511688, 0.39914671973813987, 0, 0.3457051536458299, 0.015552486535273219], inf, 0.011135985455284984, inf
08:41:00 done sampling a new configuration.
08:41:00 HBMASTER: schedule new run for iteration 4
08:41:00 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
08:41:00 HBMASTER: submitting job (4, 0, 20) to dispatcher
08:41:00 DISPATCHER: trying to submit job (4, 0, 20)
08:41:00 DISPATCHER: trying to notify the job_runner thread.
08:41:00 HBMASTER: job (4, 0, 20) submitted to dispatcher
08:41:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:41:00 DISPATCHER: Trying to submit another job.
08:41:00 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:41:00 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:41:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:41:00 WORKER: start processing job (4, 0, 20)
08:41:00 WORKER: args: ()
08:41:00 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 7, 'lr': 0.016527213405574837, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.010476935047735482}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-491:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:41:17 DISPATCHER: Starting worker discovery
08:41:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:41:17 DISPATCHER: Finished worker discovery
08:41:58 WORKER: done with job (4, 0, 20), trying to register it.
08:41:58 WORKER: registered result for job (4, 0, 20) with dispatcher
08:41:58 DISPATCHER: job (4, 0, 20) finished
08:41:58 DISPATCHER: register_result: lock acquired
08:41:58 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
08:41:58 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 7, 'lr': 0.016527213405574837, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.010476935047735482}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.013197593443832029, 'info': {'data04': 0.013197593443832029, 'config': "{'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 7, 'lr': 0.016527213405574837, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.010476935047735482}"}}
exception: None

08:41:58 job_callback for (4, 0, 20) started
08:41:58 job_callback for (4, 0, 20) got condition
08:41:58 DISPATCHER: Trying to submit another job.
08:41:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:41:58 HBMASTER: Trying to run another job!
08:41:58 job_callback for (4, 0, 20) finished
08:41:58 start sampling a new configuration.
08:41:58 done sampling a new configuration.
08:41:58 HBMASTER: schedule new run for iteration 4
08:41:58 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
08:41:58 HBMASTER: submitting job (4, 0, 21) to dispatcher
08:41:58 DISPATCHER: trying to submit job (4, 0, 21)
08:41:58 DISPATCHER: trying to notify the job_runner thread.
08:41:58 HBMASTER: job (4, 0, 21) submitted to dispatcher
08:41:58 DISPATCHER: Trying to submit another job.
08:41:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:41:58 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:41:58 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:41:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:41:58 WORKER: start processing job (4, 0, 21)
08:41:58 WORKER: args: ()
08:41:58 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 86, 'last_n_outputs': 39, 'lr': 0.037247807838680425, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.0167794441270268}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-492:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:42:17 DISPATCHER: Starting worker discovery
08:42:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:42:17 DISPATCHER: Finished worker discovery
08:42:56 WORKER: done with job (4, 0, 21), trying to register it.
08:42:56 WORKER: registered result for job (4, 0, 21) with dispatcher
08:42:56 DISPATCHER: job (4, 0, 21) finished
08:42:56 DISPATCHER: register_result: lock acquired
08:42:56 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
08:42:56 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 86, 'last_n_outputs': 39, 'lr': 0.037247807838680425, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.0167794441270268}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 86, 'last_n_outputs': 39, 'lr': 0.037247807838680425, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.0167794441270268}"}}
exception: None

08:42:56 job_callback for (4, 0, 21) started
08:42:56 DISPATCHER: Trying to submit another job.
08:42:56 job_callback for (4, 0, 21) got condition
08:42:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:42:56 HBMASTER: Trying to run another job!
08:42:56 job_callback for (4, 0, 21) finished
08:42:56 start sampling a new configuration.
08:42:56 sampled vector: [3, 0.38708849763663056, 0.35503406552586203, 0.4804729327580071, 0.16183504372245278, 0, 0.09779662551385947, 0.6450925846925029] has EI value inf
08:42:56 data in the KDEs:
[[3.         0.67283955 0.67000007 0.02556037 0.0999984  0.
  0.98351659 0.01501267]
 [2.         0.91975319 0.06999983 0.49134915 0.0999984  0.
  0.34615381 0.2220369 ]
 [1.         0.99382728 0.16999987 0.06463218 0.0999984  0.
  0.04945045 0.09498723]
 [3.         0.94444455 0.55000002 0.69169086 0.0999984  1.
  0.69780224 0.57093564]
 [0.         0.45061727 0.49       0.75725213 0.0999984  1.
  0.77472534 0.04815185]
 [3.         0.82098773 0.26999991 0.846535   0.0999984  1.
  0.29120875 0.67572506]
 [3.         0.90740751 0.32999993 0.74196297 0.2999992  1.
  0.98351659 0.25068711]
 [2.         0.67283955 0.77000011 0.05933137 0.0999984  1.
  0.91758251 0.03312671]
 [1.         0.99382728 0.04999982 0.73851202 0.0999984  0.
  0.12637354 0.0892389 ]]
[[0.         0.56172841 0.97000019 0.75808465 0.5        1.
  0.20329664 0.96083405]
 [2.         0.88271614 0.38999996 0.80879291 0.2999992  1.
  0.40109888 0.65476406]
 [1.         0.43827159 0.26999991 0.5613407  0.2999992  1.
  0.75274731 0.52552923]
 [1.         0.3641975  0.91000016 0.66624211 0.5        1.
  0.48901099 0.55120704]
 [2.         0.72222228 0.16999987 0.9413961  0.0999984  1.
  0.03846144 0.74478876]
 [3.         0.85802478 0.04999982 0.90369329 0.0999984  1.
  0.14835157 0.41206949]
 [0.         0.95679024 0.26999991 0.44141548 0.0999984  1.
  0.6648352  0.05588327]
 [2.         0.88271614 0.0099998  0.80797366 0.0999984  1.
  0.03846144 0.56321253]
 [3.         0.66049387 0.36999995 0.56338374 0.5        1.
  0.41208789 0.4162515 ]]
08:42:56 bandwidth of the KDEs:
[0.93038865 0.15379994 0.2163274  0.28624806 0.05547788 0.43858941
 0.31087773 0.20190567]
[0.94066949 0.17653868 0.28575046 0.14108478 0.15444389 0.001
 0.21688492 0.2078469 ]
08:42:56 l(x) = 0.002070207943943716
08:42:56 g(x) = inf
08:42:56 best_vector: [3, 0.38708849763663056, 0.35503406552586203, 0.4804729327580071, 0.16183504372245278, 0, 0.09779662551385947, 0.6450925846925029], inf, 0.002070207943943716, inf
08:42:56 done sampling a new configuration.
08:42:56 HBMASTER: schedule new run for iteration 4
08:42:56 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
08:42:56 HBMASTER: submitting job (4, 0, 22) to dispatcher
08:42:56 DISPATCHER: trying to submit job (4, 0, 22)
08:42:56 DISPATCHER: trying to notify the job_runner thread.
08:42:56 HBMASTER: job (4, 0, 22) submitted to dispatcher
08:42:56 DISPATCHER: Trying to submit another job.
08:42:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:42:56 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:42:56 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:42:56 WORKER: start processing job (4, 0, 22)
08:42:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:42:56 WORKER: args: ()
08:42:56 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 51, 'last_n_outputs': 18, 'lr': 0.009139993050361384, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.06906925993872796}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-493:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:43:17 DISPATCHER: Starting worker discovery
08:43:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:43:17 DISPATCHER: Finished worker discovery
08:43:54 WORKER: done with job (4, 0, 22), trying to register it.
08:43:54 WORKER: registered result for job (4, 0, 22) with dispatcher
08:43:54 DISPATCHER: job (4, 0, 22) finished
08:43:54 DISPATCHER: register_result: lock acquired
08:43:54 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
08:43:54 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 51, 'last_n_outputs': 18, 'lr': 0.009139993050361384, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.06906925993872796}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.027925650592398113, 'info': {'data04': 0.027925650592398113, 'config': "{'batch_size': 128, 'hidden_dim': 51, 'last_n_outputs': 18, 'lr': 0.009139993050361384, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.06906925993872796}"}}
exception: None

08:43:54 job_callback for (4, 0, 22) started
08:43:54 job_callback for (4, 0, 22) got condition
08:43:54 DISPATCHER: Trying to submit another job.
08:43:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:43:54 HBMASTER: Trying to run another job!
08:43:54 job_callback for (4, 0, 22) finished
08:43:54 start sampling a new configuration.
08:43:54 done sampling a new configuration.
08:43:54 HBMASTER: schedule new run for iteration 4
08:43:54 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
08:43:54 HBMASTER: submitting job (4, 0, 23) to dispatcher
08:43:54 DISPATCHER: trying to submit job (4, 0, 23)
08:43:54 DISPATCHER: trying to notify the job_runner thread.
08:43:54 HBMASTER: job (4, 0, 23) submitted to dispatcher
08:43:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:43:54 DISPATCHER: Trying to submit another job.
08:43:54 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:43:54 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:43:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:43:54 WORKER: start processing job (4, 0, 23)
08:43:54 WORKER: args: ()
08:43:54 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 100, 'last_n_outputs': 36, 'lr': 0.035557102422082154, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.12043422194055291}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-494:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:44:17 DISPATCHER: Starting worker discovery
08:44:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:44:17 DISPATCHER: Finished worker discovery
08:44:54 WORKER: done with job (4, 0, 23), trying to register it.
08:44:54 WORKER: registered result for job (4, 0, 23) with dispatcher
08:44:54 DISPATCHER: job (4, 0, 23) finished
08:44:54 DISPATCHER: register_result: lock acquired
08:44:54 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
08:44:54 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 100, 'last_n_outputs': 36, 'lr': 0.035557102422082154, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.12043422194055291}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 100, 'last_n_outputs': 36, 'lr': 0.035557102422082154, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.12043422194055291}"}}
exception: None

08:44:54 job_callback for (4, 0, 23) started
08:44:54 job_callback for (4, 0, 23) got condition
08:44:54 DISPATCHER: Trying to submit another job.
08:44:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:44:54 HBMASTER: Trying to run another job!
08:44:54 job_callback for (4, 0, 23) finished
08:44:54 start sampling a new configuration.
08:44:54 sampled vector: [0, 0.5434232960455777, 0.20614518539856674, 0.2728696969819187, 0.48758043043427035, 0, 0.03254851431350947, 0.15577078499554067] has EI value inf
08:44:54 data in the KDEs:
[[3.         0.67283955 0.67000007 0.02556037 0.0999984  0.
  0.98351659 0.01501267]
 [2.         0.91975319 0.06999983 0.49134915 0.0999984  0.
  0.34615381 0.2220369 ]
 [1.         0.99382728 0.16999987 0.06463218 0.0999984  0.
  0.04945045 0.09498723]
 [3.         0.94444455 0.55000002 0.69169086 0.0999984  1.
  0.69780224 0.57093564]
 [0.         0.45061727 0.49       0.75725213 0.0999984  1.
  0.77472534 0.04815185]
 [3.         0.82098773 0.26999991 0.846535   0.0999984  1.
  0.29120875 0.67572506]
 [3.         0.90740751 0.32999993 0.74196297 0.2999992  1.
  0.98351659 0.25068711]
 [2.         0.67283955 0.77000011 0.05933137 0.0999984  1.
  0.91758251 0.03312671]
 [1.         0.99382728 0.04999982 0.73851202 0.0999984  0.
  0.12637354 0.0892389 ]]
[[0.         0.56172841 0.97000019 0.75808465 0.5        1.
  0.20329664 0.96083405]
 [2.         0.88271614 0.38999996 0.80879291 0.2999992  1.
  0.40109888 0.65476406]
 [1.         0.43827159 0.26999991 0.5613407  0.2999992  1.
  0.75274731 0.52552923]
 [1.         0.3641975  0.91000016 0.66624211 0.5        1.
  0.48901099 0.55120704]
 [2.         0.72222228 0.16999987 0.9413961  0.0999984  1.
  0.03846144 0.74478876]
 [3.         0.85802478 0.04999982 0.90369329 0.0999984  1.
  0.14835157 0.41206949]
 [0.         0.95679024 0.26999991 0.44141548 0.0999984  1.
  0.6648352  0.05588327]
 [2.         0.88271614 0.0099998  0.80797366 0.0999984  1.
  0.03846144 0.56321253]
 [3.         0.66049387 0.36999995 0.56338374 0.5        1.
  0.41208789 0.4162515 ]]
08:44:54 bandwidth of the KDEs:
[0.93038865 0.15379994 0.2163274  0.28624806 0.05547788 0.43858941
 0.31087773 0.20190567]
[0.94066949 0.17653868 0.28575046 0.14108478 0.15444389 0.001
 0.21688492 0.2078469 ]
08:44:54 l(x) = 6.779115610666832e-07
08:44:54 g(x) = inf
08:44:54 best_vector: [0, 0.5434232960455777, 0.20614518539856674, 0.2728696969819187, 0.48758043043427035, 0, 0.03254851431350947, 0.15577078499554067], inf, 6.779115610666832e-07, inf
08:44:54 done sampling a new configuration.
08:44:54 HBMASTER: schedule new run for iteration 4
08:44:54 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
08:44:54 HBMASTER: submitting job (4, 0, 24) to dispatcher
08:44:54 DISPATCHER: trying to submit job (4, 0, 24)
08:44:54 DISPATCHER: trying to notify the job_runner thread.
08:44:54 HBMASTER: job (4, 0, 24) submitted to dispatcher
08:44:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:44:54 DISPATCHER: Trying to submit another job.
08:44:54 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:44:54 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:44:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:44:54 WORKER: start processing job (4, 0, 24)
08:44:54 WORKER: args: ()
08:44:54 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 64, 'last_n_outputs': 11, 'lr': 0.0035134954379010728, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.01594639302274364}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-495:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:45:17 DISPATCHER: Starting worker discovery
08:45:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:45:17 DISPATCHER: Finished worker discovery
08:45:51 WORKER: done with job (4, 0, 24), trying to register it.
08:45:51 WORKER: registered result for job (4, 0, 24) with dispatcher
08:45:51 DISPATCHER: job (4, 0, 24) finished
08:45:51 DISPATCHER: register_result: lock acquired
08:45:51 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
08:45:51 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 64, 'last_n_outputs': 11, 'lr': 0.0035134954379010728, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.01594639302274364}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 64, 'last_n_outputs': 11, 'lr': 0.0035134954379010728, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.01594639302274364}"}}
exception: None

08:45:51 job_callback for (4, 0, 24) started
08:45:51 DISPATCHER: Trying to submit another job.
08:45:51 job_callback for (4, 0, 24) got condition
08:45:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:45:51 HBMASTER: Trying to run another job!
08:45:51 job_callback for (4, 0, 24) finished
08:45:51 start sampling a new configuration.
08:45:51 sampled vector: [3, 0.6162796344152934, 0.41396975692646354, 0.35689918690760575, 0.13460031451876253, 0, 0.016158900483554284, 0.08793546280012746] has EI value inf
08:45:51 data in the KDEs:
[[3.         0.67283955 0.67000007 0.02556037 0.0999984  0.
  0.98351659 0.01501267]
 [2.         0.91975319 0.06999983 0.49134915 0.0999984  0.
  0.34615381 0.2220369 ]
 [1.         0.99382728 0.16999987 0.06463218 0.0999984  0.
  0.04945045 0.09498723]
 [3.         0.94444455 0.55000002 0.69169086 0.0999984  1.
  0.69780224 0.57093564]
 [0.         0.45061727 0.49       0.75725213 0.0999984  1.
  0.77472534 0.04815185]
 [3.         0.82098773 0.26999991 0.846535   0.0999984  1.
  0.29120875 0.67572506]
 [3.         0.90740751 0.32999993 0.74196297 0.2999992  1.
  0.98351659 0.25068711]
 [2.         0.67283955 0.77000011 0.05933137 0.0999984  1.
  0.91758251 0.03312671]
 [1.         0.99382728 0.04999982 0.73851202 0.0999984  0.
  0.12637354 0.0892389 ]]
[[0.         0.56172841 0.97000019 0.75808465 0.5        1.
  0.20329664 0.96083405]
 [2.         0.88271614 0.38999996 0.80879291 0.2999992  1.
  0.40109888 0.65476406]
 [1.         0.43827159 0.26999991 0.5613407  0.2999992  1.
  0.75274731 0.52552923]
 [1.         0.3641975  0.91000016 0.66624211 0.5        1.
  0.48901099 0.55120704]
 [2.         0.72222228 0.16999987 0.9413961  0.0999984  1.
  0.03846144 0.74478876]
 [3.         0.85802478 0.04999982 0.90369329 0.0999984  1.
  0.14835157 0.41206949]
 [0.         0.95679024 0.26999991 0.44141548 0.0999984  1.
  0.6648352  0.05588327]
 [2.         0.88271614 0.0099998  0.80797366 0.0999984  1.
  0.03846144 0.56321253]
 [3.         0.66049387 0.36999995 0.56338374 0.5        1.
  0.41208789 0.4162515 ]]
08:45:51 bandwidth of the KDEs:
[0.93038865 0.15379994 0.2163274  0.28624806 0.05547788 0.43858941
 0.31087773 0.20190567]
[0.94066949 0.17653868 0.28575046 0.14108478 0.15444389 0.001
 0.21688492 0.2078469 ]
08:45:51 l(x) = 0.08967291579100906
08:45:51 g(x) = inf
08:45:51 best_vector: [3, 0.6162796344152934, 0.41396975692646354, 0.35689918690760575, 0.13460031451876253, 0, 0.016158900483554284, 0.08793546280012746], 0.025853903255973316, 0.08967291579100906, inf
08:45:51 done sampling a new configuration.
08:45:51 HBMASTER: schedule new run for iteration 4
08:45:51 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
08:45:51 HBMASTER: submitting job (4, 0, 25) to dispatcher
08:45:51 DISPATCHER: trying to submit job (4, 0, 25)
08:45:51 DISPATCHER: trying to notify the job_runner thread.
08:45:51 HBMASTER: job (4, 0, 25) submitted to dispatcher
08:45:51 DISPATCHER: Trying to submit another job.
08:45:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:45:51 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:45:51 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:45:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:45:51 WORKER: start processing job (4, 0, 25)
08:45:51 WORKER: args: ()
08:45:51 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 69, 'last_n_outputs': 21, 'lr': 0.005173665828270741, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 11, 'weight_decay': 0.013013876313208798}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-496:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:46:17 DISPATCHER: Starting worker discovery
08:46:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:46:17 DISPATCHER: Finished worker discovery
08:46:49 WORKER: done with job (4, 0, 25), trying to register it.
08:46:49 WORKER: registered result for job (4, 0, 25) with dispatcher
08:46:49 DISPATCHER: job (4, 0, 25) finished
08:46:49 DISPATCHER: register_result: lock acquired
08:46:49 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
08:46:49 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 69, 'last_n_outputs': 21, 'lr': 0.005173665828270741, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 11, 'weight_decay': 0.013013876313208798}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1022887165328995, 'info': {'data04': 0.1022887165328995, 'config': "{'batch_size': 128, 'hidden_dim': 69, 'last_n_outputs': 21, 'lr': 0.005173665828270741, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 11, 'weight_decay': 0.013013876313208798}"}}
exception: None

08:46:49 job_callback for (4, 0, 25) started
08:46:49 job_callback for (4, 0, 25) got condition
08:46:49 DISPATCHER: Trying to submit another job.
08:46:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:46:49 HBMASTER: Trying to run another job!
08:46:49 job_callback for (4, 0, 25) finished
08:46:49 start sampling a new configuration.
08:46:49 done sampling a new configuration.
08:46:49 HBMASTER: schedule new run for iteration 4
08:46:49 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
08:46:49 HBMASTER: submitting job (4, 0, 26) to dispatcher
08:46:49 DISPATCHER: trying to submit job (4, 0, 26)
08:46:49 DISPATCHER: trying to notify the job_runner thread.
08:46:49 HBMASTER: job (4, 0, 26) submitted to dispatcher
08:46:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:46:49 DISPATCHER: Trying to submit another job.
08:46:49 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:46:49 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:46:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:46:49 WORKER: start processing job (4, 0, 26)
08:46:49 WORKER: args: ()
08:46:49 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 66, 'last_n_outputs': 5, 'lr': 0.05407708291841526, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.011833284766786904}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-497:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:47:17 DISPATCHER: Starting worker discovery
08:47:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:47:17 DISPATCHER: Finished worker discovery
08:47:49 WORKER: done with job (4, 0, 26), trying to register it.
08:47:49 WORKER: registered result for job (4, 0, 26) with dispatcher
08:47:49 DISPATCHER: job (4, 0, 26) finished
08:47:49 DISPATCHER: register_result: lock acquired
08:47:49 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
08:47:49 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 66, 'last_n_outputs': 5, 'lr': 0.05407708291841526, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.011833284766786904}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 66, 'last_n_outputs': 5, 'lr': 0.05407708291841526, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.011833284766786904}"}}
exception: None

08:47:49 job_callback for (4, 0, 26) started
08:47:49 DISPATCHER: Trying to submit another job.
08:47:49 job_callback for (4, 0, 26) got condition
08:47:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:47:49 HBMASTER: Trying to run another job!
08:47:49 job_callback for (4, 0, 26) finished
08:47:49 ITERATION: Advancing config (4, 0, 0) to next budget 133.333333
08:47:49 ITERATION: Advancing config (4, 0, 4) to next budget 133.333333
08:47:49 ITERATION: Advancing config (4, 0, 5) to next budget 133.333333
08:47:49 ITERATION: Advancing config (4, 0, 11) to next budget 133.333333
08:47:49 ITERATION: Advancing config (4, 0, 12) to next budget 133.333333
08:47:49 ITERATION: Advancing config (4, 0, 13) to next budget 133.333333
08:47:49 ITERATION: Advancing config (4, 0, 19) to next budget 133.333333
08:47:49 ITERATION: Advancing config (4, 0, 22) to next budget 133.333333
08:47:49 ITERATION: Advancing config (4, 0, 25) to next budget 133.333333
08:47:49 HBMASTER: schedule new run for iteration 4
08:47:49 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
08:47:49 HBMASTER: submitting job (4, 0, 0) to dispatcher
08:47:49 DISPATCHER: trying to submit job (4, 0, 0)
08:47:49 DISPATCHER: trying to notify the job_runner thread.
08:47:49 HBMASTER: job (4, 0, 0) submitted to dispatcher
08:47:49 DISPATCHER: Trying to submit another job.
08:47:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:47:49 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:47:49 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:47:49 WORKER: start processing job (4, 0, 0)
08:47:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:47:49 WORKER: args: ()
08:47:49 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 78, 'last_n_outputs': 41, 'lr': 0.002692275805940447, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.025664262253956842}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-498:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:48:17 DISPATCHER: Starting worker discovery
08:48:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:48:17 DISPATCHER: Finished worker discovery
08:49:17 DISPATCHER: Starting worker discovery
08:49:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:49:17 DISPATCHER: Finished worker discovery
08:50:15 WORKER: done with job (4, 0, 0), trying to register it.
08:50:15 WORKER: registered result for job (4, 0, 0) with dispatcher
08:50:15 DISPATCHER: job (4, 0, 0) finished
08:50:15 DISPATCHER: register_result: lock acquired
08:50:15 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
08:50:15 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 78, 'last_n_outputs': 41, 'lr': 0.002692275805940447, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.025664262253956842}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.11241783511265957, 'info': {'data04': 0.11241783511265957, 'config': "{'batch_size': 16, 'hidden_dim': 78, 'last_n_outputs': 41, 'lr': 0.002692275805940447, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.025664262253956842}"}}
exception: None

08:50:15 job_callback for (4, 0, 0) started
08:50:15 DISPATCHER: Trying to submit another job.
08:50:15 job_callback for (4, 0, 0) got condition
08:50:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:50:15 done building a new model for budget 133.333333 based on 9/16 split
Best loss for this budget:-0.190645





08:50:15 HBMASTER: Trying to run another job!
08:50:15 job_callback for (4, 0, 0) finished
08:50:15 HBMASTER: schedule new run for iteration 4
08:50:15 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
08:50:15 HBMASTER: submitting job (4, 0, 4) to dispatcher
08:50:15 DISPATCHER: trying to submit job (4, 0, 4)
08:50:15 DISPATCHER: trying to notify the job_runner thread.
08:50:15 HBMASTER: job (4, 0, 4) submitted to dispatcher
08:50:15 DISPATCHER: Trying to submit another job.
08:50:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:50:15 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:50:15 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:50:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:50:15 WORKER: start processing job (4, 0, 4)
08:50:15 WORKER: args: ()
08:50:15 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 91, 'last_n_outputs': 16, 'lr': 0.002258899415107016, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.03175436340345553}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:50:17 DISPATCHER: Starting worker discovery
08:50:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:50:17 DISPATCHER: Finished worker discovery
Exception in thread Thread-499:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:51:17 DISPATCHER: Starting worker discovery
08:51:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:51:17 DISPATCHER: Finished worker discovery
08:52:17 DISPATCHER: Starting worker discovery
08:52:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:52:17 DISPATCHER: Finished worker discovery
08:52:42 WORKER: done with job (4, 0, 4), trying to register it.
08:52:42 WORKER: registered result for job (4, 0, 4) with dispatcher
08:52:42 DISPATCHER: job (4, 0, 4) finished
08:52:42 DISPATCHER: register_result: lock acquired
08:52:42 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
08:52:42 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 91, 'last_n_outputs': 16, 'lr': 0.002258899415107016, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.03175436340345553}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.044344269488045714, 'info': {'data04': 0.044344269488045714, 'config': "{'batch_size': 16, 'hidden_dim': 91, 'last_n_outputs': 16, 'lr': 0.002258899415107016, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.03175436340345553}"}}
exception: None

08:52:42 job_callback for (4, 0, 4) started
08:52:42 job_callback for (4, 0, 4) got condition
08:52:42 DISPATCHER: Trying to submit another job.
08:52:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:52:42 done building a new model for budget 133.333333 based on 9/17 split
Best loss for this budget:-0.190645





08:52:42 HBMASTER: Trying to run another job!
08:52:42 job_callback for (4, 0, 4) finished
08:52:42 HBMASTER: schedule new run for iteration 4
08:52:42 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
08:52:42 HBMASTER: submitting job (4, 0, 5) to dispatcher
08:52:42 DISPATCHER: trying to submit job (4, 0, 5)
08:52:42 DISPATCHER: trying to notify the job_runner thread.
08:52:42 HBMASTER: job (4, 0, 5) submitted to dispatcher
08:52:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:52:42 DISPATCHER: Trying to submit another job.
08:52:42 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:52:42 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:52:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:52:42 WORKER: start processing job (4, 0, 5)
08:52:42 WORKER: args: ()
08:52:42 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 74, 'last_n_outputs': 47, 'lr': 0.003113270945444529, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.0219987086986536}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-500:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:53:17 DISPATCHER: Starting worker discovery
08:53:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:53:17 DISPATCHER: Finished worker discovery
08:54:17 DISPATCHER: Starting worker discovery
08:54:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:54:17 DISPATCHER: Finished worker discovery
08:55:08 WORKER: done with job (4, 0, 5), trying to register it.
08:55:08 WORKER: registered result for job (4, 0, 5) with dispatcher
08:55:08 DISPATCHER: job (4, 0, 5) finished
08:55:08 DISPATCHER: register_result: lock acquired
08:55:08 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
08:55:08 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 74, 'last_n_outputs': 47, 'lr': 0.003113270945444529, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.0219987086986536}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.12632991166018806, 'info': {'data04': 0.12632991166018806, 'config': "{'batch_size': 32, 'hidden_dim': 74, 'last_n_outputs': 47, 'lr': 0.003113270945444529, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.0219987086986536}"}}
exception: None

08:55:08 job_callback for (4, 0, 5) started
08:55:08 DISPATCHER: Trying to submit another job.
08:55:08 job_callback for (4, 0, 5) got condition
08:55:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:55:08 done building a new model for budget 133.333333 based on 9/17 split
Best loss for this budget:-0.190645





08:55:08 HBMASTER: Trying to run another job!
08:55:08 job_callback for (4, 0, 5) finished
08:55:08 HBMASTER: schedule new run for iteration 4
08:55:08 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
08:55:08 HBMASTER: submitting job (4, 0, 11) to dispatcher
08:55:08 DISPATCHER: trying to submit job (4, 0, 11)
08:55:08 DISPATCHER: trying to notify the job_runner thread.
08:55:08 HBMASTER: job (4, 0, 11) submitted to dispatcher
08:55:08 DISPATCHER: Trying to submit another job.
08:55:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:55:08 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:55:08 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:55:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:55:08 WORKER: start processing job (4, 0, 11)
08:55:08 WORKER: args: ()
08:55:08 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 40, 'last_n_outputs': 35, 'lr': 0.013153362258908608, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.03022471062437051}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:55:17 DISPATCHER: Starting worker discovery
08:55:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:55:17 DISPATCHER: Finished worker discovery
Exception in thread Thread-501:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:56:17 DISPATCHER: Starting worker discovery
08:56:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:56:17 DISPATCHER: Finished worker discovery
08:57:17 DISPATCHER: Starting worker discovery
08:57:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:57:17 DISPATCHER: Finished worker discovery
08:57:35 WORKER: done with job (4, 0, 11), trying to register it.
08:57:35 WORKER: registered result for job (4, 0, 11) with dispatcher
08:57:35 DISPATCHER: job (4, 0, 11) finished
08:57:35 DISPATCHER: register_result: lock acquired
08:57:35 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
08:57:35 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 40, 'last_n_outputs': 35, 'lr': 0.013153362258908608, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.03022471062437051}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.05361962528865852, 'info': {'data04': 0.05361962528865852, 'config': "{'batch_size': 128, 'hidden_dim': 40, 'last_n_outputs': 35, 'lr': 0.013153362258908608, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.03022471062437051}"}}
exception: None

08:57:35 job_callback for (4, 0, 11) started
08:57:35 DISPATCHER: Trying to submit another job.
08:57:35 job_callback for (4, 0, 11) got condition
08:57:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:57:35 done building a new model for budget 133.333333 based on 9/18 split
Best loss for this budget:-0.190645





08:57:35 HBMASTER: Trying to run another job!
08:57:35 job_callback for (4, 0, 11) finished
08:57:35 HBMASTER: schedule new run for iteration 4
08:57:35 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
08:57:35 HBMASTER: submitting job (4, 0, 12) to dispatcher
08:57:35 DISPATCHER: trying to submit job (4, 0, 12)
08:57:35 DISPATCHER: trying to notify the job_runner thread.
08:57:35 HBMASTER: job (4, 0, 12) submitted to dispatcher
08:57:35 DISPATCHER: Trying to submit another job.
08:57:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:57:35 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:57:35 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
08:57:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:57:35 WORKER: start processing job (4, 0, 12)
08:57:35 WORKER: args: ()
08:57:35 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 93, 'last_n_outputs': 47, 'lr': 0.003138128547286713, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.017502612226268692}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-502:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:58:17 DISPATCHER: Starting worker discovery
08:58:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:58:17 DISPATCHER: Finished worker discovery
08:59:17 DISPATCHER: Starting worker discovery
08:59:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:59:17 DISPATCHER: Finished worker discovery
09:00:02 WORKER: done with job (4, 0, 12), trying to register it.
09:00:02 WORKER: registered result for job (4, 0, 12) with dispatcher
09:00:02 DISPATCHER: job (4, 0, 12) finished
09:00:02 DISPATCHER: register_result: lock acquired
09:00:02 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:00:02 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 93, 'last_n_outputs': 47, 'lr': 0.003138128547286713, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.017502612226268692}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.10023564938012836, 'info': {'data04': 0.10023564938012836, 'config': "{'batch_size': 64, 'hidden_dim': 93, 'last_n_outputs': 47, 'lr': 0.003138128547286713, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.017502612226268692}"}}
exception: None

09:00:02 job_callback for (4, 0, 12) started
09:00:02 DISPATCHER: Trying to submit another job.
09:00:02 job_callback for (4, 0, 12) got condition
09:00:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:00:02 done building a new model for budget 133.333333 based on 9/19 split
Best loss for this budget:-0.190645





09:00:02 HBMASTER: Trying to run another job!
09:00:02 job_callback for (4, 0, 12) finished
09:00:02 HBMASTER: schedule new run for iteration 4
09:00:02 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
09:00:02 HBMASTER: submitting job (4, 0, 13) to dispatcher
09:00:02 DISPATCHER: trying to submit job (4, 0, 13)
09:00:02 DISPATCHER: trying to notify the job_runner thread.
09:00:02 HBMASTER: job (4, 0, 13) submitted to dispatcher
09:00:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:00:02 DISPATCHER: Trying to submit another job.
09:00:02 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:00:02 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:00:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:00:02 WORKER: start processing job (4, 0, 13)
09:00:02 WORKER: args: ()
09:00:02 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 40, 'lr': 0.001049957141582828, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.038455157149066575}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-503:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:00:17 DISPATCHER: Starting worker discovery
09:00:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:00:17 DISPATCHER: Finished worker discovery
09:01:17 DISPATCHER: Starting worker discovery
09:01:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:01:17 DISPATCHER: Finished worker discovery
09:02:17 DISPATCHER: Starting worker discovery
09:02:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:02:17 DISPATCHER: Finished worker discovery
09:02:28 WORKER: done with job (4, 0, 13), trying to register it.
09:02:28 WORKER: registered result for job (4, 0, 13) with dispatcher
09:02:28 DISPATCHER: job (4, 0, 13) finished
09:02:28 DISPATCHER: register_result: lock acquired
09:02:28 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:02:28 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 40, 'lr': 0.001049957141582828, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.038455157149066575}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.10816083085471132, 'info': {'data04': 0.10816083085471132, 'config': "{'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 40, 'lr': 0.001049957141582828, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.038455157149066575}"}}
exception: None

09:02:28 job_callback for (4, 0, 13) started
09:02:28 DISPATCHER: Trying to submit another job.
09:02:28 job_callback for (4, 0, 13) got condition
09:02:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:02:28 done building a new model for budget 133.333333 based on 9/20 split
Best loss for this budget:-0.190645





09:02:28 HBMASTER: Trying to run another job!
09:02:28 job_callback for (4, 0, 13) finished
09:02:28 HBMASTER: schedule new run for iteration 4
09:02:28 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
09:02:28 HBMASTER: submitting job (4, 0, 19) to dispatcher
09:02:28 DISPATCHER: trying to submit job (4, 0, 19)
09:02:28 DISPATCHER: trying to notify the job_runner thread.
09:02:28 HBMASTER: job (4, 0, 19) submitted to dispatcher
09:02:28 DISPATCHER: Trying to submit another job.
09:02:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:02:28 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:02:28 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:02:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:02:28 WORKER: start processing job (4, 0, 19)
09:02:28 WORKER: args: ()
09:02:28 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 69, 'last_n_outputs': 18, 'lr': 0.0023079670642250152, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.0383482345175396}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-504:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:03:17 DISPATCHER: Starting worker discovery
09:03:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:03:17 DISPATCHER: Finished worker discovery
09:04:17 DISPATCHER: Starting worker discovery
09:04:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:04:17 DISPATCHER: Finished worker discovery
09:04:54 WORKER: done with job (4, 0, 19), trying to register it.
09:04:54 WORKER: registered result for job (4, 0, 19) with dispatcher
09:04:54 DISPATCHER: job (4, 0, 19) finished
09:04:54 DISPATCHER: register_result: lock acquired
09:04:54 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:04:54 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 69, 'last_n_outputs': 18, 'lr': 0.0023079670642250152, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.0383482345175396}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.03559287911816427, 'info': {'data04': 0.03559287911816427, 'config': "{'batch_size': 128, 'hidden_dim': 69, 'last_n_outputs': 18, 'lr': 0.0023079670642250152, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.0383482345175396}"}}
exception: None

09:04:54 job_callback for (4, 0, 19) started
09:04:54 job_callback for (4, 0, 19) got condition
09:04:54 DISPATCHER: Trying to submit another job.
09:04:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:04:54 done building a new model for budget 133.333333 based on 9/21 split
Best loss for this budget:-0.190645





09:04:54 HBMASTER: Trying to run another job!
09:04:54 job_callback for (4, 0, 19) finished
09:04:54 HBMASTER: schedule new run for iteration 4
09:04:54 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
09:04:54 HBMASTER: submitting job (4, 0, 22) to dispatcher
09:04:54 DISPATCHER: trying to submit job (4, 0, 22)
09:04:54 DISPATCHER: trying to notify the job_runner thread.
09:04:54 HBMASTER: job (4, 0, 22) submitted to dispatcher
09:04:54 DISPATCHER: Trying to submit another job.
09:04:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:04:54 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:04:54 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:04:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:04:54 WORKER: start processing job (4, 0, 22)
09:04:54 WORKER: args: ()
09:04:54 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 51, 'last_n_outputs': 18, 'lr': 0.009139993050361384, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.06906925993872796}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-505:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:05:17 DISPATCHER: Starting worker discovery
09:05:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:05:17 DISPATCHER: Finished worker discovery
09:06:17 DISPATCHER: Starting worker discovery
09:06:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:06:17 DISPATCHER: Finished worker discovery
09:07:17 DISPATCHER: Starting worker discovery
09:07:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:07:17 DISPATCHER: Finished worker discovery
09:07:21 WORKER: done with job (4, 0, 22), trying to register it.
09:07:21 WORKER: registered result for job (4, 0, 22) with dispatcher
09:07:21 DISPATCHER: job (4, 0, 22) finished
09:07:21 DISPATCHER: register_result: lock acquired
09:07:21 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:07:21 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 51, 'last_n_outputs': 18, 'lr': 0.009139993050361384, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.06906925993872796}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.008653245239226972, 'info': {'data04': 0.008653245239226972, 'config': "{'batch_size': 128, 'hidden_dim': 51, 'last_n_outputs': 18, 'lr': 0.009139993050361384, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.06906925993872796}"}}
exception: None

09:07:21 job_callback for (4, 0, 22) started
09:07:21 job_callback for (4, 0, 22) got condition
09:07:21 DISPATCHER: Trying to submit another job.
09:07:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:07:21 done building a new model for budget 133.333333 based on 9/22 split
Best loss for this budget:-0.190645





09:07:21 HBMASTER: Trying to run another job!
09:07:21 job_callback for (4, 0, 22) finished
09:07:21 HBMASTER: schedule new run for iteration 4
09:07:21 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
09:07:21 HBMASTER: submitting job (4, 0, 25) to dispatcher
09:07:21 DISPATCHER: trying to submit job (4, 0, 25)
09:07:21 DISPATCHER: trying to notify the job_runner thread.
09:07:21 HBMASTER: job (4, 0, 25) submitted to dispatcher
09:07:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:07:21 DISPATCHER: Trying to submit another job.
09:07:21 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:07:21 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:07:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:07:21 WORKER: start processing job (4, 0, 25)
09:07:21 WORKER: args: ()
09:07:21 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 69, 'last_n_outputs': 21, 'lr': 0.005173665828270741, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 11, 'weight_decay': 0.013013876313208798}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-506:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:08:17 DISPATCHER: Starting worker discovery
09:08:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:08:17 DISPATCHER: Finished worker discovery
09:09:17 DISPATCHER: Starting worker discovery
09:09:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:09:17 DISPATCHER: Finished worker discovery
09:09:47 WORKER: done with job (4, 0, 25), trying to register it.
09:09:47 WORKER: registered result for job (4, 0, 25) with dispatcher
09:09:47 DISPATCHER: job (4, 0, 25) finished
09:09:47 DISPATCHER: register_result: lock acquired
09:09:47 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:09:47 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 69, 'last_n_outputs': 21, 'lr': 0.005173665828270741, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 11, 'weight_decay': 0.013013876313208798}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.06556565555840976, 'info': {'data04': 0.06556565555840976, 'config': "{'batch_size': 128, 'hidden_dim': 69, 'last_n_outputs': 21, 'lr': 0.005173665828270741, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 11, 'weight_decay': 0.013013876313208798}"}}
exception: None

09:09:47 job_callback for (4, 0, 25) started
09:09:47 job_callback for (4, 0, 25) got condition
09:09:47 DISPATCHER: Trying to submit another job.
09:09:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:09:47 done building a new model for budget 133.333333 based on 9/22 split
Best loss for this budget:-0.190645





09:09:47 HBMASTER: Trying to run another job!
09:09:47 job_callback for (4, 0, 25) finished
09:09:47 ITERATION: Advancing config (4, 0, 0) to next budget 400.000000
09:09:47 ITERATION: Advancing config (4, 0, 5) to next budget 400.000000
09:09:47 ITERATION: Advancing config (4, 0, 13) to next budget 400.000000
09:09:47 HBMASTER: schedule new run for iteration 4
09:09:47 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
09:09:47 HBMASTER: submitting job (4, 0, 0) to dispatcher
09:09:47 DISPATCHER: trying to submit job (4, 0, 0)
09:09:47 DISPATCHER: trying to notify the job_runner thread.
09:09:47 HBMASTER: job (4, 0, 0) submitted to dispatcher
09:09:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:09:47 DISPATCHER: Trying to submit another job.
09:09:47 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:09:47 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:09:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:09:47 WORKER: start processing job (4, 0, 0)
09:09:47 WORKER: args: ()
09:09:47 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 78, 'last_n_outputs': 41, 'lr': 0.002692275805940447, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.025664262253956842}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-507:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:10:17 DISPATCHER: Starting worker discovery
09:10:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:10:17 DISPATCHER: Finished worker discovery
09:11:17 DISPATCHER: Starting worker discovery
09:11:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:11:17 DISPATCHER: Finished worker discovery
09:12:17 DISPATCHER: Starting worker discovery
09:12:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:12:17 DISPATCHER: Finished worker discovery
09:13:17 DISPATCHER: Starting worker discovery
09:13:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:13:17 DISPATCHER: Finished worker discovery
09:14:17 DISPATCHER: Starting worker discovery
09:14:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:14:17 DISPATCHER: Finished worker discovery
09:15:17 DISPATCHER: Starting worker discovery
09:15:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:15:17 DISPATCHER: Finished worker discovery
09:16:17 DISPATCHER: Starting worker discovery
09:16:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:16:17 DISPATCHER: Finished worker discovery
09:16:40 WORKER: done with job (4, 0, 0), trying to register it.
09:16:40 WORKER: registered result for job (4, 0, 0) with dispatcher
09:16:40 DISPATCHER: job (4, 0, 0) finished
09:16:40 DISPATCHER: register_result: lock acquired
09:16:40 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:16:40 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 78, 'last_n_outputs': 41, 'lr': 0.002692275805940447, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.025664262253956842}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.08224688587451966, 'info': {'data04': 0.08224688587451966, 'config': "{'batch_size': 16, 'hidden_dim': 78, 'last_n_outputs': 41, 'lr': 0.002692275805940447, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.025664262253956842}"}}
exception: None

09:16:40 job_callback for (4, 0, 0) started
09:16:40 job_callback for (4, 0, 0) got condition
09:16:40 DISPATCHER: Trying to submit another job.
09:16:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:16:40 HBMASTER: Trying to run another job!
09:16:40 job_callback for (4, 0, 0) finished
09:16:40 HBMASTER: schedule new run for iteration 4
09:16:40 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
09:16:40 HBMASTER: submitting job (4, 0, 5) to dispatcher
09:16:40 DISPATCHER: trying to submit job (4, 0, 5)
09:16:40 DISPATCHER: trying to notify the job_runner thread.
09:16:40 HBMASTER: job (4, 0, 5) submitted to dispatcher
09:16:40 DISPATCHER: Trying to submit another job.
09:16:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:16:40 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:16:40 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:16:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:16:40 WORKER: start processing job (4, 0, 5)
09:16:40 WORKER: args: ()
09:16:40 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 74, 'last_n_outputs': 47, 'lr': 0.003113270945444529, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.0219987086986536}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-508:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:17:17 DISPATCHER: Starting worker discovery
09:17:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:17:17 DISPATCHER: Finished worker discovery
09:18:17 DISPATCHER: Starting worker discovery
09:18:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:18:17 DISPATCHER: Finished worker discovery
09:19:17 DISPATCHER: Starting worker discovery
09:19:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:19:17 DISPATCHER: Finished worker discovery
09:20:17 DISPATCHER: Starting worker discovery
09:20:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:20:17 DISPATCHER: Finished worker discovery
09:21:17 DISPATCHER: Starting worker discovery
09:21:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:21:17 DISPATCHER: Finished worker discovery
09:22:17 DISPATCHER: Starting worker discovery
09:22:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:22:17 DISPATCHER: Finished worker discovery
09:23:17 DISPATCHER: Starting worker discovery
09:23:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:23:17 DISPATCHER: Finished worker discovery
09:23:33 WORKER: done with job (4, 0, 5), trying to register it.
09:23:33 WORKER: registered result for job (4, 0, 5) with dispatcher
09:23:33 DISPATCHER: job (4, 0, 5) finished
09:23:33 DISPATCHER: register_result: lock acquired
09:23:33 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:23:33 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 74, 'last_n_outputs': 47, 'lr': 0.003113270945444529, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.0219987086986536}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.09660169135604356, 'info': {'data04': 0.09660169135604356, 'config': "{'batch_size': 32, 'hidden_dim': 74, 'last_n_outputs': 47, 'lr': 0.003113270945444529, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.0219987086986536}"}}
exception: None

09:23:33 job_callback for (4, 0, 5) started
09:23:33 job_callback for (4, 0, 5) got condition
09:23:33 DISPATCHER: Trying to submit another job.
09:23:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:23:33 HBMASTER: Trying to run another job!
09:23:33 job_callback for (4, 0, 5) finished
09:23:33 HBMASTER: schedule new run for iteration 4
09:23:33 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
09:23:33 HBMASTER: submitting job (4, 0, 13) to dispatcher
09:23:33 DISPATCHER: trying to submit job (4, 0, 13)
09:23:33 DISPATCHER: trying to notify the job_runner thread.
09:23:33 HBMASTER: job (4, 0, 13) submitted to dispatcher
09:23:33 DISPATCHER: Trying to submit another job.
09:23:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:23:33 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:23:33 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:23:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:23:33 WORKER: start processing job (4, 0, 13)
09:23:33 WORKER: args: ()
09:23:33 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 40, 'lr': 0.001049957141582828, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.038455157149066575}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-509:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:24:17 DISPATCHER: Starting worker discovery
09:24:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:24:17 DISPATCHER: Finished worker discovery
09:25:17 DISPATCHER: Starting worker discovery
09:25:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:25:17 DISPATCHER: Finished worker discovery
09:26:17 DISPATCHER: Starting worker discovery
09:26:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:26:17 DISPATCHER: Finished worker discovery
09:27:17 DISPATCHER: Starting worker discovery
09:27:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:27:17 DISPATCHER: Finished worker discovery
09:28:17 DISPATCHER: Starting worker discovery
09:28:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:28:17 DISPATCHER: Finished worker discovery
09:29:17 DISPATCHER: Starting worker discovery
09:29:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:29:17 DISPATCHER: Finished worker discovery
09:30:17 DISPATCHER: Starting worker discovery
09:30:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:30:17 DISPATCHER: Finished worker discovery
09:30:26 WORKER: done with job (4, 0, 13), trying to register it.
09:30:26 WORKER: registered result for job (4, 0, 13) with dispatcher
09:30:26 DISPATCHER: job (4, 0, 13) finished
09:30:26 DISPATCHER: register_result: lock acquired
09:30:26 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:30:26 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 40, 'lr': 0.001049957141582828, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.038455157149066575}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0729862310220495, 'info': {'data04': 0.0729862310220495, 'config': "{'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 40, 'lr': 0.001049957141582828, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.038455157149066575}"}}
exception: None

09:30:26 job_callback for (4, 0, 13) started
09:30:26 DISPATCHER: Trying to submit another job.
09:30:26 job_callback for (4, 0, 13) got condition
09:30:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:30:26 HBMASTER: Trying to run another job!
09:30:26 job_callback for (4, 0, 13) finished
09:30:26 ITERATION: Advancing config (4, 0, 5) to next budget 1200.000000
09:30:26 HBMASTER: schedule new run for iteration 4
09:30:26 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
09:30:26 HBMASTER: submitting job (4, 0, 5) to dispatcher
09:30:26 DISPATCHER: trying to submit job (4, 0, 5)
09:30:26 DISPATCHER: trying to notify the job_runner thread.
09:30:26 HBMASTER: job (4, 0, 5) submitted to dispatcher
09:30:26 DISPATCHER: Trying to submit another job.
09:30:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:30:26 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:30:26 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:30:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:30:26 WORKER: start processing job (4, 0, 5)
09:30:26 WORKER: args: ()
09:30:26 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 74, 'last_n_outputs': 47, 'lr': 0.003113270945444529, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.0219987086986536}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-510:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:31:17 DISPATCHER: Starting worker discovery
09:31:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:31:17 DISPATCHER: Finished worker discovery
09:32:17 DISPATCHER: Starting worker discovery
09:32:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:32:17 DISPATCHER: Finished worker discovery
09:33:17 DISPATCHER: Starting worker discovery
09:33:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:33:17 DISPATCHER: Finished worker discovery
09:34:17 DISPATCHER: Starting worker discovery
09:34:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:34:17 DISPATCHER: Finished worker discovery
09:35:17 DISPATCHER: Starting worker discovery
09:35:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:35:17 DISPATCHER: Finished worker discovery
09:36:17 DISPATCHER: Starting worker discovery
09:36:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:36:17 DISPATCHER: Finished worker discovery
09:37:17 DISPATCHER: Starting worker discovery
09:37:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:37:17 DISPATCHER: Finished worker discovery
09:38:17 DISPATCHER: Starting worker discovery
09:38:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:38:17 DISPATCHER: Finished worker discovery
09:39:17 DISPATCHER: Starting worker discovery
09:39:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:39:17 DISPATCHER: Finished worker discovery
09:40:17 DISPATCHER: Starting worker discovery
09:40:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:40:17 DISPATCHER: Finished worker discovery
09:41:17 DISPATCHER: Starting worker discovery
09:41:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:41:17 DISPATCHER: Finished worker discovery
09:42:17 DISPATCHER: Starting worker discovery
09:42:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:42:17 DISPATCHER: Finished worker discovery
09:43:17 DISPATCHER: Starting worker discovery
09:43:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:43:17 DISPATCHER: Finished worker discovery
09:44:17 DISPATCHER: Starting worker discovery
09:44:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:44:17 DISPATCHER: Finished worker discovery
09:45:17 DISPATCHER: Starting worker discovery
09:45:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:45:17 DISPATCHER: Finished worker discovery
09:46:17 DISPATCHER: Starting worker discovery
09:46:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:46:17 DISPATCHER: Finished worker discovery
09:47:17 DISPATCHER: Starting worker discovery
09:47:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:47:17 DISPATCHER: Finished worker discovery
09:48:17 DISPATCHER: Starting worker discovery
09:48:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:48:17 DISPATCHER: Finished worker discovery
09:49:17 DISPATCHER: Starting worker discovery
09:49:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:49:17 DISPATCHER: Finished worker discovery
09:50:17 DISPATCHER: Starting worker discovery
09:50:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:50:17 DISPATCHER: Finished worker discovery
09:50:41 WORKER: done with job (4, 0, 5), trying to register it.
09:50:41 WORKER: registered result for job (4, 0, 5) with dispatcher
09:50:41 DISPATCHER: job (4, 0, 5) finished
09:50:41 DISPATCHER: register_result: lock acquired
09:50:41 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:50:41 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 74, 'last_n_outputs': 47, 'lr': 0.003113270945444529, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.0219987086986536}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.10113056813776494, 'info': {'data04': 0.10113056813776494, 'config': "{'batch_size': 32, 'hidden_dim': 74, 'last_n_outputs': 47, 'lr': 0.003113270945444529, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.0219987086986536}"}}
exception: None

09:50:41 job_callback for (4, 0, 5) started
09:50:41 job_callback for (4, 0, 5) got condition
09:50:41 DISPATCHER: Trying to submit another job.
09:50:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:50:41 HBMASTER: Trying to run another job!
09:50:41 job_callback for (4, 0, 5) finished
09:50:41 start sampling a new configuration.
09:50:41 done sampling a new configuration.
09:50:41 HBMASTER: schedule new run for iteration 5
09:50:41 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
09:50:41 HBMASTER: submitting job (5, 0, 0) to dispatcher
09:50:41 DISPATCHER: trying to submit job (5, 0, 0)
09:50:41 DISPATCHER: trying to notify the job_runner thread.
09:50:41 HBMASTER: job (5, 0, 0) submitted to dispatcher
09:50:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:50:41 DISPATCHER: Trying to submit another job.
09:50:41 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:50:41 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:50:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:50:41 WORKER: start processing job (5, 0, 0)
09:50:41 WORKER: args: ()
09:50:41 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 22, 'last_n_outputs': 48, 'lr': 0.05033577045047994, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.07862909224957672}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-511:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:51:17 DISPATCHER: Starting worker discovery
09:51:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:51:17 DISPATCHER: Finished worker discovery
09:52:17 DISPATCHER: Starting worker discovery
09:52:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:52:17 DISPATCHER: Finished worker discovery
09:53:08 WORKER: done with job (5, 0, 0), trying to register it.
09:53:08 WORKER: registered result for job (5, 0, 0) with dispatcher
09:53:08 DISPATCHER: job (5, 0, 0) finished
09:53:08 DISPATCHER: register_result: lock acquired
09:53:08 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:53:08 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 22, 'last_n_outputs': 48, 'lr': 0.05033577045047994, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.07862909224957672}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 22, 'last_n_outputs': 48, 'lr': 0.05033577045047994, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.07862909224957672}"}}
exception: None

09:53:08 job_callback for (5, 0, 0) started
09:53:08 job_callback for (5, 0, 0) got condition
09:53:08 DISPATCHER: Trying to submit another job.
09:53:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:53:08 done building a new model for budget 133.333333 based on 9/23 split
Best loss for this budget:-0.190645





09:53:08 HBMASTER: Trying to run another job!
09:53:08 job_callback for (5, 0, 0) finished
09:53:08 start sampling a new configuration.
09:53:08 best_vector: [2, 0.17650112952392272, 0.9878738249793866, 0.5938344496798973, 0.0999273038964734, 0, 0.869851327163154, 0.2817087902862369], 6.841336993864092e-05, 97.13234622699312, 0.006645151135435433
09:53:08 done sampling a new configuration.
09:53:08 HBMASTER: schedule new run for iteration 5
09:53:08 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
09:53:08 HBMASTER: submitting job (5, 0, 1) to dispatcher
09:53:08 DISPATCHER: trying to submit job (5, 0, 1)
09:53:08 DISPATCHER: trying to notify the job_runner thread.
09:53:08 HBMASTER: job (5, 0, 1) submitted to dispatcher
09:53:08 DISPATCHER: Trying to submit another job.
09:53:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:53:08 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:53:08 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:53:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:53:08 WORKER: start processing job (5, 0, 1)
09:53:08 WORKER: args: ()
09:53:08 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 34, 'last_n_outputs': 50, 'lr': 0.015405255278830377, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.023254745245714917}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:53:17 DISPATCHER: Starting worker discovery
09:53:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:53:17 DISPATCHER: Finished worker discovery
Exception in thread Thread-512:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:54:17 DISPATCHER: Starting worker discovery
09:54:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:54:17 DISPATCHER: Finished worker discovery
09:55:17 DISPATCHER: Starting worker discovery
09:55:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:55:17 DISPATCHER: Finished worker discovery
09:55:34 WORKER: done with job (5, 0, 1), trying to register it.
09:55:34 WORKER: registered result for job (5, 0, 1) with dispatcher
09:55:34 DISPATCHER: job (5, 0, 1) finished
09:55:34 DISPATCHER: register_result: lock acquired
09:55:34 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:55:34 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 34, 'last_n_outputs': 50, 'lr': 0.015405255278830377, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.023254745245714917}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.055370024348861145, 'info': {'data04': 0.055370024348861145, 'config': "{'batch_size': 64, 'hidden_dim': 34, 'last_n_outputs': 50, 'lr': 0.015405255278830377, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.023254745245714917}"}}
exception: None

09:55:34 job_callback for (5, 0, 1) started
09:55:34 DISPATCHER: Trying to submit another job.
09:55:34 job_callback for (5, 0, 1) got condition
09:55:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:55:34 done building a new model for budget 133.333333 based on 9/24 split
Best loss for this budget:-0.190645





09:55:34 HBMASTER: Trying to run another job!
09:55:34 job_callback for (5, 0, 1) finished
09:55:34 start sampling a new configuration.
09:55:34 best_vector: [1, 0.41486761353641444, 0.9678451407255911, 0.5471659454513927, 0.1003249113123707, 0, 0.680265918298801, 0.19864612919598118], 0.001043572248789837, 141.32561870712786, 0.1474834937258125
09:55:34 done sampling a new configuration.
09:55:34 HBMASTER: schedule new run for iteration 5
09:55:34 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
09:55:34 HBMASTER: submitting job (5, 0, 2) to dispatcher
09:55:34 DISPATCHER: trying to submit job (5, 0, 2)
09:55:34 DISPATCHER: trying to notify the job_runner thread.
09:55:34 HBMASTER: job (5, 0, 2) submitted to dispatcher
09:55:34 DISPATCHER: Trying to submit another job.
09:55:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:55:34 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:55:34 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:55:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:55:34 WORKER: start processing job (5, 0, 2)
09:55:34 WORKER: args: ()
09:55:34 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 53, 'last_n_outputs': 49, 'lr': 0.012426015496961842, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.018131952497203487}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-513:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:56:17 DISPATCHER: Starting worker discovery
09:56:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:56:17 DISPATCHER: Finished worker discovery
09:57:17 DISPATCHER: Starting worker discovery
09:57:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:57:17 DISPATCHER: Finished worker discovery
09:58:01 WORKER: done with job (5, 0, 2), trying to register it.
09:58:01 WORKER: registered result for job (5, 0, 2) with dispatcher
09:58:01 DISPATCHER: job (5, 0, 2) finished
09:58:01 DISPATCHER: register_result: lock acquired
09:58:01 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
09:58:01 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 53, 'last_n_outputs': 49, 'lr': 0.012426015496961842, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.018131952497203487}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.04931725175598507, 'info': {'data04': 0.04931725175598507, 'config': "{'batch_size': 32, 'hidden_dim': 53, 'last_n_outputs': 49, 'lr': 0.012426015496961842, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.018131952497203487}"}}
exception: None

09:58:01 job_callback for (5, 0, 2) started
09:58:01 DISPATCHER: Trying to submit another job.
09:58:01 job_callback for (5, 0, 2) got condition
09:58:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:58:01 done building a new model for budget 133.333333 based on 9/25 split
Best loss for this budget:-0.190645





09:58:01 HBMASTER: Trying to run another job!
09:58:01 job_callback for (5, 0, 2) finished
09:58:01 start sampling a new configuration.
09:58:01 best_vector: [3, 0.7551429286516804, 0.8820480819590557, 0.02161622912215953, 0.09854576658230604, 0, 0.18175830381068792, 0.2333659574883403], 8.26914698379019e-05, 75.57909048878015, 0.006249746081529022
09:58:01 done sampling a new configuration.
09:58:01 HBMASTER: schedule new run for iteration 5
09:58:01 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
09:58:01 HBMASTER: submitting job (5, 0, 3) to dispatcher
09:58:01 DISPATCHER: trying to submit job (5, 0, 3)
09:58:01 DISPATCHER: trying to notify the job_runner thread.
09:58:01 HBMASTER: job (5, 0, 3) submitted to dispatcher
09:58:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:58:01 DISPATCHER: Trying to submit another job.
09:58:01 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:58:01 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
09:58:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:58:01 WORKER: start processing job (5, 0, 3)
09:58:01 WORKER: args: ()
09:58:01 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 81, 'last_n_outputs': 45, 'lr': 0.0011046697415665037, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.020119450292071798}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-514:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:58:17 DISPATCHER: Starting worker discovery
09:58:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:58:17 DISPATCHER: Finished worker discovery
09:59:17 DISPATCHER: Starting worker discovery
09:59:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:59:17 DISPATCHER: Finished worker discovery
10:00:17 DISPATCHER: Starting worker discovery
10:00:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:00:17 DISPATCHER: Finished worker discovery
10:00:30 WORKER: done with job (5, 0, 3), trying to register it.
10:00:30 WORKER: registered result for job (5, 0, 3) with dispatcher
10:00:30 DISPATCHER: job (5, 0, 3) finished
10:00:30 DISPATCHER: register_result: lock acquired
10:00:30 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
10:00:30 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 81, 'last_n_outputs': 45, 'lr': 0.0011046697415665037, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.020119450292071798}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.12009320235403183, 'info': {'data04': 0.12009320235403183, 'config': "{'batch_size': 128, 'hidden_dim': 81, 'last_n_outputs': 45, 'lr': 0.0011046697415665037, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.020119450292071798}"}}
exception: None

10:00:30 job_callback for (5, 0, 3) started
10:00:30 DISPATCHER: Trying to submit another job.
10:00:30 job_callback for (5, 0, 3) got condition
10:00:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:00:30 done building a new model for budget 133.333333 based on 9/26 split
Best loss for this budget:-0.190645





10:00:30 HBMASTER: Trying to run another job!
10:00:30 job_callback for (5, 0, 3) finished
10:00:30 start sampling a new configuration.
10:00:30 done sampling a new configuration.
10:00:30 HBMASTER: schedule new run for iteration 5
10:00:30 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
10:00:30 HBMASTER: submitting job (5, 0, 4) to dispatcher
10:00:30 DISPATCHER: trying to submit job (5, 0, 4)
10:00:30 DISPATCHER: trying to notify the job_runner thread.
10:00:30 HBMASTER: job (5, 0, 4) submitted to dispatcher
10:00:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:00:30 DISPATCHER: Trying to submit another job.
10:00:30 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:00:30 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:00:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:00:30 WORKER: start processing job (5, 0, 4)
10:00:30 WORKER: args: ()
10:00:30 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 30, 'last_n_outputs': 9, 'lr': 0.0028099685423717013, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.09548174906662285}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-515:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:01:17 DISPATCHER: Starting worker discovery
10:01:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:01:17 DISPATCHER: Finished worker discovery
10:02:17 DISPATCHER: Starting worker discovery
10:02:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:02:17 DISPATCHER: Finished worker discovery
10:02:57 WORKER: done with job (5, 0, 4), trying to register it.
10:02:57 WORKER: registered result for job (5, 0, 4) with dispatcher
10:02:57 DISPATCHER: job (5, 0, 4) finished
10:02:57 DISPATCHER: register_result: lock acquired
10:02:57 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
10:02:57 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 30, 'last_n_outputs': 9, 'lr': 0.0028099685423717013, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.09548174906662285}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.004185684059488549, 'info': {'data04': 0.004185684059488549, 'config': "{'batch_size': 128, 'hidden_dim': 30, 'last_n_outputs': 9, 'lr': 0.0028099685423717013, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.09548174906662285}"}}
exception: None

10:02:57 job_callback for (5, 0, 4) started
10:02:57 DISPATCHER: Trying to submit another job.
10:02:57 job_callback for (5, 0, 4) got condition
10:02:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:02:57 done building a new model for budget 133.333333 based on 9/27 split
Best loss for this budget:-0.190645





10:02:57 HBMASTER: Trying to run another job!
10:02:57 job_callback for (5, 0, 4) finished
10:02:57 start sampling a new configuration.
10:02:57 best_vector: [0, 0.8350705039306167, 0.7510006428124687, 0.11790227850258017, 0.09940019457709875, 0, 0.31322029834692733, 0.10932714734469476], 4.158465707498816e-05, 566.2568988792966, 0.0235475989562418
10:02:57 done sampling a new configuration.
10:02:57 HBMASTER: schedule new run for iteration 5
10:02:57 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
10:02:57 HBMASTER: submitting job (5, 0, 5) to dispatcher
10:02:57 DISPATCHER: trying to submit job (5, 0, 5)
10:02:57 DISPATCHER: trying to notify the job_runner thread.
10:02:57 HBMASTER: job (5, 0, 5) submitted to dispatcher
10:02:57 DISPATCHER: Trying to submit another job.
10:02:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:02:57 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:02:57 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:02:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:02:57 WORKER: start processing job (5, 0, 5)
10:02:57 WORKER: args: ()
10:02:57 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 87, 'last_n_outputs': 38, 'lr': 0.0017210938669164268, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.013875156747282683}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-516:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:03:17 DISPATCHER: Starting worker discovery
10:03:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:03:17 DISPATCHER: Finished worker discovery
10:04:17 DISPATCHER: Starting worker discovery
10:04:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:04:17 DISPATCHER: Finished worker discovery
10:05:17 DISPATCHER: Starting worker discovery
10:05:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:05:17 DISPATCHER: Finished worker discovery
10:05:24 WORKER: done with job (5, 0, 5), trying to register it.
10:05:24 WORKER: registered result for job (5, 0, 5) with dispatcher
10:05:24 DISPATCHER: job (5, 0, 5) finished
10:05:24 DISPATCHER: register_result: lock acquired
10:05:24 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
10:05:24 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 87, 'last_n_outputs': 38, 'lr': 0.0017210938669164268, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.013875156747282683}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.10897569760852066, 'info': {'data04': 0.10897569760852066, 'config': "{'batch_size': 16, 'hidden_dim': 87, 'last_n_outputs': 38, 'lr': 0.0017210938669164268, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.013875156747282683}"}}
exception: None

10:05:24 job_callback for (5, 0, 5) started
10:05:24 DISPATCHER: Trying to submit another job.
10:05:24 job_callback for (5, 0, 5) got condition
10:05:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:05:24 done building a new model for budget 133.333333 based on 9/28 split
Best loss for this budget:-0.190645





10:05:24 HBMASTER: Trying to run another job!
10:05:24 job_callback for (5, 0, 5) finished
10:05:24 start sampling a new configuration.
10:05:24 best_vector: [0, 0.6773282445801457, 0.6502093286209429, 0.053289839863572, 0.10019774718477331, 0, 0.7954428766437402, 0.12042800007859453], 0.00019018190910773702, 848.7012747516928, 0.161407628694447
10:05:24 done sampling a new configuration.
10:05:24 HBMASTER: schedule new run for iteration 5
10:05:24 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
10:05:24 HBMASTER: submitting job (5, 0, 6) to dispatcher
10:05:24 DISPATCHER: trying to submit job (5, 0, 6)
10:05:24 DISPATCHER: trying to notify the job_runner thread.
10:05:24 HBMASTER: job (5, 0, 6) submitted to dispatcher
10:05:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:05:24 DISPATCHER: Trying to submit another job.
10:05:24 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:05:24 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:05:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:05:24 WORKER: start processing job (5, 0, 6)
10:05:24 WORKER: args: ()
10:05:24 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 74, 'last_n_outputs': 33, 'lr': 0.0012781436882499683, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.014344335698944492}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-517:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:06:17 DISPATCHER: Starting worker discovery
10:06:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:06:17 DISPATCHER: Finished worker discovery
10:07:17 DISPATCHER: Starting worker discovery
10:07:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:07:17 DISPATCHER: Finished worker discovery
10:07:51 WORKER: done with job (5, 0, 6), trying to register it.
10:07:51 WORKER: registered result for job (5, 0, 6) with dispatcher
10:07:51 DISPATCHER: job (5, 0, 6) finished
10:07:51 DISPATCHER: register_result: lock acquired
10:07:51 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
10:07:51 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 74, 'last_n_outputs': 33, 'lr': 0.0012781436882499683, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.014344335698944492}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.11120169460226294, 'info': {'data04': 0.11120169460226294, 'config': "{'batch_size': 16, 'hidden_dim': 74, 'last_n_outputs': 33, 'lr': 0.0012781436882499683, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.014344335698944492}"}}
exception: None

10:07:51 job_callback for (5, 0, 6) started
10:07:51 DISPATCHER: Trying to submit another job.
10:07:51 job_callback for (5, 0, 6) got condition
10:07:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:07:51 done building a new model for budget 133.333333 based on 9/28 split
Best loss for this budget:-0.190645





10:07:51 HBMASTER: Trying to run another job!
10:07:51 job_callback for (5, 0, 6) finished
10:07:51 start sampling a new configuration.
10:07:52 best_vector: [0, 0.894010407488218, 0.8456662553587941, 0.10806915929675945, 0.1005039808847221, 0, 0.3508650464699683, 0.14252144803828548], 2.9869699431545082e-05, 906.0836274713663, 0.027064445612413775
10:07:52 done sampling a new configuration.
10:07:52 HBMASTER: schedule new run for iteration 5
10:07:52 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
10:07:52 HBMASTER: submitting job (5, 0, 7) to dispatcher
10:07:52 DISPATCHER: trying to submit job (5, 0, 7)
10:07:52 DISPATCHER: trying to notify the job_runner thread.
10:07:52 HBMASTER: job (5, 0, 7) submitted to dispatcher
10:07:52 DISPATCHER: Trying to submit another job.
10:07:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:07:52 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:07:52 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:07:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:07:52 WORKER: start processing job (5, 0, 7)
10:07:52 WORKER: args: ()
10:07:52 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 92, 'last_n_outputs': 43, 'lr': 0.001644895523118377, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.015325853821428261}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-518:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:08:17 DISPATCHER: Starting worker discovery
10:08:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:08:17 DISPATCHER: Finished worker discovery
10:09:17 DISPATCHER: Starting worker discovery
10:09:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:09:17 DISPATCHER: Finished worker discovery
10:10:17 DISPATCHER: Starting worker discovery
10:10:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:10:17 DISPATCHER: Finished worker discovery
10:10:18 WORKER: done with job (5, 0, 7), trying to register it.
10:10:18 WORKER: registered result for job (5, 0, 7) with dispatcher
10:10:18 DISPATCHER: job (5, 0, 7) finished
10:10:18 DISPATCHER: register_result: lock acquired
10:10:18 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
10:10:18 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 92, 'last_n_outputs': 43, 'lr': 0.001644895523118377, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.015325853821428261}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.12337881042544138, 'info': {'data04': 0.12337881042544138, 'config': "{'batch_size': 16, 'hidden_dim': 92, 'last_n_outputs': 43, 'lr': 0.001644895523118377, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.015325853821428261}"}}
exception: None

10:10:18 job_callback for (5, 0, 7) started
10:10:18 DISPATCHER: Trying to submit another job.
10:10:18 job_callback for (5, 0, 7) got condition
10:10:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:10:18 done building a new model for budget 133.333333 based on 9/29 split
Best loss for this budget:-0.190645





10:10:18 HBMASTER: Trying to run another job!
10:10:18 job_callback for (5, 0, 7) finished
10:10:18 start sampling a new configuration.
10:10:18 best_vector: [3, 0.8301492743499768, 0.9664438898731532, 0.24336644360432244, 0.09997707785775083, 0, 0.26741966702042175, 0.08838893302413765], 3.1833750483833167e-06, 4430.615743493601, 0.014104311606811828
10:10:18 done sampling a new configuration.
10:10:18 HBMASTER: schedule new run for iteration 5
10:10:18 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
10:10:18 HBMASTER: submitting job (5, 0, 8) to dispatcher
10:10:18 DISPATCHER: trying to submit job (5, 0, 8)
10:10:18 DISPATCHER: trying to notify the job_runner thread.
10:10:18 HBMASTER: job (5, 0, 8) submitted to dispatcher
10:10:18 DISPATCHER: Trying to submit another job.
10:10:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:10:18 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:10:18 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:10:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:10:18 WORKER: start processing job (5, 0, 8)
10:10:18 WORKER: args: ()
10:10:18 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 87, 'last_n_outputs': 49, 'lr': 0.0030671349669930347, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.013031567357549316}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-519:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:11:17 DISPATCHER: Starting worker discovery
10:11:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:11:17 DISPATCHER: Finished worker discovery
10:12:17 DISPATCHER: Starting worker discovery
10:12:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:12:17 DISPATCHER: Finished worker discovery
10:12:44 WORKER: done with job (5, 0, 8), trying to register it.
10:12:44 WORKER: registered result for job (5, 0, 8) with dispatcher
10:12:44 DISPATCHER: job (5, 0, 8) finished
10:12:44 DISPATCHER: register_result: lock acquired
10:12:44 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
10:12:44 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 87, 'last_n_outputs': 49, 'lr': 0.0030671349669930347, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.013031567357549316}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.11717182127425517, 'info': {'data04': 0.11717182127425517, 'config': "{'batch_size': 128, 'hidden_dim': 87, 'last_n_outputs': 49, 'lr': 0.0030671349669930347, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.013031567357549316}"}}
exception: None

10:12:44 job_callback for (5, 0, 8) started
10:12:44 DISPATCHER: Trying to submit another job.
10:12:44 job_callback for (5, 0, 8) got condition
10:12:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:12:44 done building a new model for budget 133.333333 based on 9/30 split
Best loss for this budget:-0.190645





10:12:44 HBMASTER: Trying to run another job!
10:12:44 job_callback for (5, 0, 8) finished
10:12:44 ITERATION: Advancing config (5, 0, 3) to next budget 400.000000
10:12:44 ITERATION: Advancing config (5, 0, 7) to next budget 400.000000
10:12:44 ITERATION: Advancing config (5, 0, 8) to next budget 400.000000
10:12:44 HBMASTER: schedule new run for iteration 5
10:12:44 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
10:12:44 HBMASTER: submitting job (5, 0, 3) to dispatcher
10:12:44 DISPATCHER: trying to submit job (5, 0, 3)
10:12:44 DISPATCHER: trying to notify the job_runner thread.
10:12:44 HBMASTER: job (5, 0, 3) submitted to dispatcher
10:12:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:12:44 DISPATCHER: Trying to submit another job.
10:12:44 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:12:44 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:12:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:12:44 WORKER: start processing job (5, 0, 3)
10:12:44 WORKER: args: ()
10:12:44 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 81, 'last_n_outputs': 45, 'lr': 0.0011046697415665037, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.020119450292071798}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-520:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:13:17 DISPATCHER: Starting worker discovery
10:13:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:13:17 DISPATCHER: Finished worker discovery
10:14:17 DISPATCHER: Starting worker discovery
10:14:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:14:17 DISPATCHER: Finished worker discovery
10:15:17 DISPATCHER: Starting worker discovery
10:15:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:15:17 DISPATCHER: Finished worker discovery
10:16:17 DISPATCHER: Starting worker discovery
10:16:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:16:17 DISPATCHER: Finished worker discovery
10:17:17 DISPATCHER: Starting worker discovery
10:17:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:17:17 DISPATCHER: Finished worker discovery
10:18:17 DISPATCHER: Starting worker discovery
10:18:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:18:17 DISPATCHER: Finished worker discovery
10:19:17 DISPATCHER: Starting worker discovery
10:19:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:19:17 DISPATCHER: Finished worker discovery
10:19:40 WORKER: done with job (5, 0, 3), trying to register it.
10:19:40 WORKER: registered result for job (5, 0, 3) with dispatcher
10:19:40 DISPATCHER: job (5, 0, 3) finished
10:19:40 DISPATCHER: register_result: lock acquired
10:19:40 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
10:19:40 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 81, 'last_n_outputs': 45, 'lr': 0.0011046697415665037, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.020119450292071798}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.11746655807278823, 'info': {'data04': 0.11746655807278823, 'config': "{'batch_size': 128, 'hidden_dim': 81, 'last_n_outputs': 45, 'lr': 0.0011046697415665037, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.020119450292071798}"}}
exception: None

10:19:40 job_callback for (5, 0, 3) started
10:19:40 job_callback for (5, 0, 3) got condition
10:19:40 DISPATCHER: Trying to submit another job.
10:19:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:19:40 HBMASTER: Trying to run another job!
10:19:40 job_callback for (5, 0, 3) finished
10:19:40 HBMASTER: schedule new run for iteration 5
10:19:40 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
10:19:40 HBMASTER: submitting job (5, 0, 7) to dispatcher
10:19:40 DISPATCHER: trying to submit job (5, 0, 7)
10:19:40 DISPATCHER: trying to notify the job_runner thread.
10:19:40 HBMASTER: job (5, 0, 7) submitted to dispatcher
10:19:40 DISPATCHER: Trying to submit another job.
10:19:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:19:40 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:19:40 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:19:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:19:40 WORKER: start processing job (5, 0, 7)
10:19:40 WORKER: args: ()
10:19:40 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 92, 'last_n_outputs': 43, 'lr': 0.001644895523118377, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.015325853821428261}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-521:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:20:17 DISPATCHER: Starting worker discovery
10:20:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:20:17 DISPATCHER: Finished worker discovery
10:21:17 DISPATCHER: Starting worker discovery
10:21:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:21:17 DISPATCHER: Finished worker discovery
10:22:17 DISPATCHER: Starting worker discovery
10:22:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:22:17 DISPATCHER: Finished worker discovery
10:23:17 DISPATCHER: Starting worker discovery
10:23:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:23:17 DISPATCHER: Finished worker discovery
10:24:17 DISPATCHER: Starting worker discovery
10:24:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:24:17 DISPATCHER: Finished worker discovery
10:25:17 DISPATCHER: Starting worker discovery
10:25:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:25:17 DISPATCHER: Finished worker discovery
10:26:17 DISPATCHER: Starting worker discovery
10:26:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:26:17 DISPATCHER: Finished worker discovery
10:26:33 WORKER: done with job (5, 0, 7), trying to register it.
10:26:33 WORKER: registered result for job (5, 0, 7) with dispatcher
10:26:33 DISPATCHER: job (5, 0, 7) finished
10:26:33 DISPATCHER: register_result: lock acquired
10:26:33 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
10:26:33 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 92, 'last_n_outputs': 43, 'lr': 0.001644895523118377, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.015325853821428261}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.09033743342668805, 'info': {'data04': 0.09033743342668805, 'config': "{'batch_size': 16, 'hidden_dim': 92, 'last_n_outputs': 43, 'lr': 0.001644895523118377, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.015325853821428261}"}}
exception: None

10:26:33 job_callback for (5, 0, 7) started
10:26:33 DISPATCHER: Trying to submit another job.
10:26:33 job_callback for (5, 0, 7) got condition
10:26:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:26:33 HBMASTER: Trying to run another job!
10:26:33 job_callback for (5, 0, 7) finished
10:26:33 HBMASTER: schedule new run for iteration 5
10:26:33 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
10:26:33 HBMASTER: submitting job (5, 0, 8) to dispatcher
10:26:33 DISPATCHER: trying to submit job (5, 0, 8)
10:26:33 DISPATCHER: trying to notify the job_runner thread.
10:26:33 HBMASTER: job (5, 0, 8) submitted to dispatcher
10:26:33 DISPATCHER: Trying to submit another job.
10:26:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:26:33 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:26:33 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:26:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:26:33 WORKER: start processing job (5, 0, 8)
10:26:33 WORKER: args: ()
10:26:33 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 87, 'last_n_outputs': 49, 'lr': 0.0030671349669930347, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.013031567357549316}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-522:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:27:17 DISPATCHER: Starting worker discovery
10:27:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:27:17 DISPATCHER: Finished worker discovery
10:28:17 DISPATCHER: Starting worker discovery
10:28:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:28:17 DISPATCHER: Finished worker discovery
10:29:17 DISPATCHER: Starting worker discovery
10:29:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:29:17 DISPATCHER: Finished worker discovery
10:30:17 DISPATCHER: Starting worker discovery
10:30:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:30:17 DISPATCHER: Finished worker discovery
10:31:17 DISPATCHER: Starting worker discovery
10:31:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:31:17 DISPATCHER: Finished worker discovery
10:32:17 DISPATCHER: Starting worker discovery
10:32:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:32:17 DISPATCHER: Finished worker discovery
10:33:17 DISPATCHER: Starting worker discovery
10:33:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:33:17 DISPATCHER: Finished worker discovery
10:33:26 WORKER: done with job (5, 0, 8), trying to register it.
10:33:26 WORKER: registered result for job (5, 0, 8) with dispatcher
10:33:26 DISPATCHER: job (5, 0, 8) finished
10:33:26 DISPATCHER: register_result: lock acquired
10:33:26 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
10:33:26 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 87, 'last_n_outputs': 49, 'lr': 0.0030671349669930347, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.013031567357549316}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.1825035273571527, 'info': {'data04': 0.1825035273571527, 'config': "{'batch_size': 128, 'hidden_dim': 87, 'last_n_outputs': 49, 'lr': 0.0030671349669930347, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.013031567357549316}"}}
exception: None

10:33:26 job_callback for (5, 0, 8) started
10:33:26 job_callback for (5, 0, 8) got condition
10:33:26 DISPATCHER: Trying to submit another job.
10:33:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:33:26 done building a new model for budget 400.000000 based on 9/15 split
Best loss for this budget:-0.183181





10:33:26 HBMASTER: Trying to run another job!
10:33:26 job_callback for (5, 0, 8) finished
10:33:26 ITERATION: Advancing config (5, 0, 8) to next budget 1200.000000
10:33:26 HBMASTER: schedule new run for iteration 5
10:33:26 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
10:33:26 HBMASTER: submitting job (5, 0, 8) to dispatcher
10:33:26 DISPATCHER: trying to submit job (5, 0, 8)
10:33:26 DISPATCHER: trying to notify the job_runner thread.
10:33:26 HBMASTER: job (5, 0, 8) submitted to dispatcher
10:33:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:33:26 DISPATCHER: Trying to submit another job.
10:33:26 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:33:26 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:33:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:33:26 WORKER: start processing job (5, 0, 8)
10:33:26 WORKER: args: ()
10:33:26 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 87, 'last_n_outputs': 49, 'lr': 0.0030671349669930347, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.013031567357549316}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-523:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:34:17 DISPATCHER: Starting worker discovery
10:34:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:34:17 DISPATCHER: Finished worker discovery
10:35:17 DISPATCHER: Starting worker discovery
10:35:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:35:17 DISPATCHER: Finished worker discovery
10:36:17 DISPATCHER: Starting worker discovery
10:36:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:36:17 DISPATCHER: Finished worker discovery
10:37:17 DISPATCHER: Starting worker discovery
10:37:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:37:17 DISPATCHER: Finished worker discovery
10:38:17 DISPATCHER: Starting worker discovery
10:38:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:38:17 DISPATCHER: Finished worker discovery
10:39:17 DISPATCHER: Starting worker discovery
10:39:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:39:17 DISPATCHER: Finished worker discovery
10:40:17 DISPATCHER: Starting worker discovery
10:40:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:40:17 DISPATCHER: Finished worker discovery
10:41:17 DISPATCHER: Starting worker discovery
10:41:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:41:17 DISPATCHER: Finished worker discovery
10:42:17 DISPATCHER: Starting worker discovery
10:42:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:42:17 DISPATCHER: Finished worker discovery
10:43:17 DISPATCHER: Starting worker discovery
10:43:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:43:17 DISPATCHER: Finished worker discovery
10:44:17 DISPATCHER: Starting worker discovery
10:44:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:44:17 DISPATCHER: Finished worker discovery
10:45:17 DISPATCHER: Starting worker discovery
10:45:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:45:17 DISPATCHER: Finished worker discovery
10:46:17 DISPATCHER: Starting worker discovery
10:46:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:46:17 DISPATCHER: Finished worker discovery
10:47:17 DISPATCHER: Starting worker discovery
10:47:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:47:17 DISPATCHER: Finished worker discovery
10:48:17 DISPATCHER: Starting worker discovery
10:48:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:48:17 DISPATCHER: Finished worker discovery
10:49:17 DISPATCHER: Starting worker discovery
10:49:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:49:17 DISPATCHER: Finished worker discovery
10:50:17 DISPATCHER: Starting worker discovery
10:50:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:50:17 DISPATCHER: Finished worker discovery
10:51:17 DISPATCHER: Starting worker discovery
10:51:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:51:17 DISPATCHER: Finished worker discovery
10:52:17 DISPATCHER: Starting worker discovery
10:52:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:52:17 DISPATCHER: Finished worker discovery
10:53:17 DISPATCHER: Starting worker discovery
10:53:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:53:17 DISPATCHER: Finished worker discovery
10:53:39 WORKER: done with job (5, 0, 8), trying to register it.
10:53:39 WORKER: registered result for job (5, 0, 8) with dispatcher
10:53:39 DISPATCHER: job (5, 0, 8) finished
10:53:39 DISPATCHER: register_result: lock acquired
10:53:39 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
10:53:39 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 87, 'last_n_outputs': 49, 'lr': 0.0030671349669930347, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.013031567357549316}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.133718183922899, 'info': {'data04': 0.133718183922899, 'config': "{'batch_size': 128, 'hidden_dim': 87, 'last_n_outputs': 49, 'lr': 0.0030671349669930347, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.013031567357549316}"}}
exception: None

10:53:39 job_callback for (5, 0, 8) started
10:53:39 job_callback for (5, 0, 8) got condition
10:53:39 DISPATCHER: Trying to submit another job.
10:53:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:53:39 HBMASTER: Trying to run another job!
10:53:39 job_callback for (5, 0, 8) finished
10:53:39 start sampling a new configuration.
10:53:39 done sampling a new configuration.
10:53:39 HBMASTER: schedule new run for iteration 6
10:53:39 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
10:53:39 HBMASTER: submitting job (6, 0, 0) to dispatcher
10:53:39 DISPATCHER: trying to submit job (6, 0, 0)
10:53:39 DISPATCHER: trying to notify the job_runner thread.
10:53:39 HBMASTER: job (6, 0, 0) submitted to dispatcher
10:53:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:53:39 DISPATCHER: Trying to submit another job.
10:53:39 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:53:39 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
10:53:39 WORKER: start processing job (6, 0, 0)
10:53:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:53:39 WORKER: args: ()
10:53:39 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 47, 'last_n_outputs': 17, 'lr': 0.014752337400734254, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.197649675882251}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-524:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:54:17 DISPATCHER: Starting worker discovery
10:54:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:54:17 DISPATCHER: Finished worker discovery
10:55:17 DISPATCHER: Starting worker discovery
10:55:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:55:17 DISPATCHER: Finished worker discovery
10:56:17 DISPATCHER: Starting worker discovery
10:56:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:56:18 DISPATCHER: Finished worker discovery
10:57:18 DISPATCHER: Starting worker discovery
10:57:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:57:18 DISPATCHER: Finished worker discovery
10:58:18 DISPATCHER: Starting worker discovery
10:58:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:58:18 DISPATCHER: Finished worker discovery
10:59:18 DISPATCHER: Starting worker discovery
10:59:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:59:18 DISPATCHER: Finished worker discovery
11:00:18 DISPATCHER: Starting worker discovery
11:00:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:00:18 DISPATCHER: Finished worker discovery
11:00:32 WORKER: done with job (6, 0, 0), trying to register it.
11:00:32 WORKER: registered result for job (6, 0, 0) with dispatcher
11:00:32 DISPATCHER: job (6, 0, 0) finished
11:00:32 DISPATCHER: register_result: lock acquired
11:00:32 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
11:00:32 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 47, 'last_n_outputs': 17, 'lr': 0.014752337400734254, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.197649675882251}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 47, 'last_n_outputs': 17, 'lr': 0.014752337400734254, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.197649675882251}"}}
exception: None

11:00:32 job_callback for (6, 0, 0) started
11:00:32 DISPATCHER: Trying to submit another job.
11:00:32 job_callback for (6, 0, 0) got condition
11:00:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:00:32 done building a new model for budget 400.000000 based on 9/16 split
Best loss for this budget:-0.183181





11:00:32 HBMASTER: Trying to run another job!
11:00:32 job_callback for (6, 0, 0) finished
11:00:32 start sampling a new configuration.
11:00:32 best_vector: [1, 0.9859521116475081, 0.9646588793623442, 0.3907450418157299, 0.09842466710796895, 0, 0.008669791568373109, 0.35665421726743013], 6.090085358867044e-06, 30.4330106491909, 0.00018533963258088234
11:00:32 done sampling a new configuration.
11:00:32 HBMASTER: schedule new run for iteration 6
11:00:32 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
11:00:32 HBMASTER: submitting job (6, 0, 1) to dispatcher
11:00:32 DISPATCHER: trying to submit job (6, 0, 1)
11:00:32 DISPATCHER: trying to notify the job_runner thread.
11:00:32 HBMASTER: job (6, 0, 1) submitted to dispatcher
11:00:32 DISPATCHER: Trying to submit another job.
11:00:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:00:32 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:00:32 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:00:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:00:32 WORKER: start processing job (6, 0, 1)
11:00:32 WORKER: args: ()
11:00:32 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 49, 'lr': 0.006046305454871648, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 10, 'weight_decay': 0.02910836652082372}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-525:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:01:18 DISPATCHER: Starting worker discovery
11:01:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:01:18 DISPATCHER: Finished worker discovery
11:02:18 DISPATCHER: Starting worker discovery
11:02:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:02:18 DISPATCHER: Finished worker discovery
11:03:18 DISPATCHER: Starting worker discovery
11:03:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:03:18 DISPATCHER: Finished worker discovery
11:04:18 DISPATCHER: Starting worker discovery
11:04:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:04:18 DISPATCHER: Finished worker discovery
11:05:18 DISPATCHER: Starting worker discovery
11:05:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:05:18 DISPATCHER: Finished worker discovery
11:06:18 DISPATCHER: Starting worker discovery
11:06:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:06:18 DISPATCHER: Finished worker discovery
11:07:18 DISPATCHER: Starting worker discovery
11:07:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:07:18 DISPATCHER: Finished worker discovery
11:07:26 WORKER: done with job (6, 0, 1), trying to register it.
11:07:26 WORKER: registered result for job (6, 0, 1) with dispatcher
11:07:26 DISPATCHER: job (6, 0, 1) finished
11:07:26 DISPATCHER: register_result: lock acquired
11:07:26 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
11:07:26 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 49, 'lr': 0.006046305454871648, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 10, 'weight_decay': 0.02910836652082372}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.07710511189094484, 'info': {'data04': 0.07710511189094484, 'config': "{'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 49, 'lr': 0.006046305454871648, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 10, 'weight_decay': 0.02910836652082372}"}}
exception: None

11:07:26 job_callback for (6, 0, 1) started
11:07:26 job_callback for (6, 0, 1) got condition
11:07:26 DISPATCHER: Trying to submit another job.
11:07:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:07:26 done building a new model for budget 400.000000 based on 9/17 split
Best loss for this budget:-0.183181





11:07:26 HBMASTER: Trying to run another job!
11:07:26 job_callback for (6, 0, 1) finished
11:07:26 start sampling a new configuration.
11:07:26 best_vector: [2, 0.9158569510805931, 0.9723370569519068, 0.2010136658114538, 0.10196580219407271, 0, 0.12695038650991913, 0.2937966638611819], 1.8183991988590581e-06, 268.728037050222, 0.000488654847283091
11:07:26 done sampling a new configuration.
11:07:26 HBMASTER: schedule new run for iteration 6
11:07:26 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
11:07:26 HBMASTER: submitting job (6, 0, 2) to dispatcher
11:07:26 DISPATCHER: trying to submit job (6, 0, 2)
11:07:26 DISPATCHER: trying to notify the job_runner thread.
11:07:26 HBMASTER: job (6, 0, 2) submitted to dispatcher
11:07:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:07:26 DISPATCHER: Trying to submit another job.
11:07:26 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:07:26 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:07:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:07:26 WORKER: start processing job (6, 0, 2)
11:07:26 WORKER: args: ()
11:07:26 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 49, 'lr': 0.0025236395886711832, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.02411227967433113}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-526:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:08:18 DISPATCHER: Starting worker discovery
11:08:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:08:18 DISPATCHER: Finished worker discovery
11:09:18 DISPATCHER: Starting worker discovery
11:09:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:09:18 DISPATCHER: Finished worker discovery
11:10:18 DISPATCHER: Starting worker discovery
11:10:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:10:18 DISPATCHER: Finished worker discovery
11:11:18 DISPATCHER: Starting worker discovery
11:11:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:11:18 DISPATCHER: Finished worker discovery
11:12:18 DISPATCHER: Starting worker discovery
11:12:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:12:18 DISPATCHER: Finished worker discovery
11:13:18 DISPATCHER: Starting worker discovery
11:13:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:13:18 DISPATCHER: Finished worker discovery
11:14:18 DISPATCHER: Starting worker discovery
11:14:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:14:18 DISPATCHER: Finished worker discovery
11:14:20 WORKER: done with job (6, 0, 2), trying to register it.
11:14:20 WORKER: registered result for job (6, 0, 2) with dispatcher
11:14:20 DISPATCHER: job (6, 0, 2) finished
11:14:20 DISPATCHER: register_result: lock acquired
11:14:20 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
11:14:20 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 49, 'lr': 0.0025236395886711832, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.02411227967433113}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.10307795931385089, 'info': {'data04': 0.10307795931385089, 'config': "{'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 49, 'lr': 0.0025236395886711832, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.02411227967433113}"}}
exception: None

11:14:20 job_callback for (6, 0, 2) started
11:14:20 job_callback for (6, 0, 2) got condition
11:14:20 DISPATCHER: Trying to submit another job.
11:14:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:14:20 done building a new model for budget 400.000000 based on 9/17 split
Best loss for this budget:-0.183181





11:14:20 HBMASTER: Trying to run another job!
11:14:20 job_callback for (6, 0, 2) finished
11:14:20 start sampling a new configuration.
11:14:20 done sampling a new configuration.
11:14:20 HBMASTER: schedule new run for iteration 6
11:14:20 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
11:14:20 HBMASTER: submitting job (6, 0, 3) to dispatcher
11:14:20 DISPATCHER: trying to submit job (6, 0, 3)
11:14:20 DISPATCHER: trying to notify the job_runner thread.
11:14:20 HBMASTER: job (6, 0, 3) submitted to dispatcher
11:14:20 DISPATCHER: Trying to submit another job.
11:14:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:14:20 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:14:20 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:14:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:14:20 WORKER: start processing job (6, 0, 3)
11:14:20 WORKER: args: ()
11:14:20 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 59, 'last_n_outputs': 42, 'lr': 0.006759069015355456, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.047222900717462164}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-527:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:15:18 DISPATCHER: Starting worker discovery
11:15:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:15:18 DISPATCHER: Finished worker discovery
11:16:18 DISPATCHER: Starting worker discovery
11:16:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:16:18 DISPATCHER: Finished worker discovery
11:17:18 DISPATCHER: Starting worker discovery
11:17:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:17:18 DISPATCHER: Finished worker discovery
11:18:18 DISPATCHER: Starting worker discovery
11:18:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:18:18 DISPATCHER: Finished worker discovery
11:19:18 DISPATCHER: Starting worker discovery
11:19:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:19:18 DISPATCHER: Finished worker discovery
11:20:18 DISPATCHER: Starting worker discovery
11:20:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:20:18 DISPATCHER: Finished worker discovery
11:21:13 WORKER: done with job (6, 0, 3), trying to register it.
11:21:13 WORKER: registered result for job (6, 0, 3) with dispatcher
11:21:13 DISPATCHER: job (6, 0, 3) finished
11:21:13 DISPATCHER: register_result: lock acquired
11:21:13 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
11:21:13 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 59, 'last_n_outputs': 42, 'lr': 0.006759069015355456, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.047222900717462164}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': 0.033528333140493145, 'info': {'data04': -0.033528333140493145, 'config': "{'batch_size': 128, 'hidden_dim': 59, 'last_n_outputs': 42, 'lr': 0.006759069015355456, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.047222900717462164}"}}
exception: None

11:21:13 job_callback for (6, 0, 3) started
11:21:13 DISPATCHER: Trying to submit another job.
11:21:13 job_callback for (6, 0, 3) got condition
11:21:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:21:13 done building a new model for budget 400.000000 based on 9/18 split
Best loss for this budget:-0.183181





11:21:13 HBMASTER: Trying to run another job!
11:21:13 job_callback for (6, 0, 3) finished
11:21:13 start sampling a new configuration.
11:21:14 best_vector: [2, 0.8612183305095321, 0.9224301160202222, 0.406508994752404, 0.10081378444704808, 0, 0.03747565994328837, 0.27801020686342437], 8.911551588958051e-07, 1418.427748380439, 0.001264039205490189
11:21:14 done sampling a new configuration.
11:21:14 HBMASTER: schedule new run for iteration 6
11:21:14 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
11:21:14 HBMASTER: submitting job (6, 0, 4) to dispatcher
11:21:14 DISPATCHER: trying to submit job (6, 0, 4)
11:21:14 DISPATCHER: trying to notify the job_runner thread.
11:21:14 HBMASTER: job (6, 0, 4) submitted to dispatcher
11:21:14 DISPATCHER: Trying to submit another job.
11:21:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:21:14 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:21:14 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:21:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:21:14 WORKER: start processing job (6, 0, 4)
11:21:14 WORKER: args: ()
11:21:14 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 89, 'last_n_outputs': 47, 'lr': 0.006501566208105704, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.022998505649838165}, 'budget': 400.0, 'working_directory': '.'}
11:21:18 DISPATCHER: Starting worker discovery
11:21:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:21:18 DISPATCHER: Finished worker discovery
Exception in thread Thread-528:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:22:18 DISPATCHER: Starting worker discovery
11:22:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:22:18 DISPATCHER: Finished worker discovery
11:23:18 DISPATCHER: Starting worker discovery
11:23:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:23:18 DISPATCHER: Finished worker discovery
11:24:18 DISPATCHER: Starting worker discovery
11:24:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:24:18 DISPATCHER: Finished worker discovery
11:25:18 DISPATCHER: Starting worker discovery
11:25:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:25:18 DISPATCHER: Finished worker discovery
11:26:18 DISPATCHER: Starting worker discovery
11:26:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:26:18 DISPATCHER: Finished worker discovery
11:27:18 DISPATCHER: Starting worker discovery
11:27:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:27:18 DISPATCHER: Finished worker discovery
11:28:07 WORKER: done with job (6, 0, 4), trying to register it.
11:28:07 WORKER: registered result for job (6, 0, 4) with dispatcher
11:28:07 DISPATCHER: job (6, 0, 4) finished
11:28:07 DISPATCHER: register_result: lock acquired
11:28:07 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
11:28:07 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 89, 'last_n_outputs': 47, 'lr': 0.006501566208105704, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.022998505649838165}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.08642114712304735, 'info': {'data04': 0.08642114712304735, 'config': "{'batch_size': 64, 'hidden_dim': 89, 'last_n_outputs': 47, 'lr': 0.006501566208105704, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.022998505649838165}"}}
exception: None

11:28:07 job_callback for (6, 0, 4) started
11:28:07 job_callback for (6, 0, 4) got condition
11:28:07 DISPATCHER: Trying to submit another job.
11:28:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:28:07 done building a new model for budget 400.000000 based on 9/19 split
Best loss for this budget:-0.183181





11:28:07 HBMASTER: Trying to run another job!
11:28:07 job_callback for (6, 0, 4) finished
11:28:07 start sampling a new configuration.
11:28:07 done sampling a new configuration.
11:28:07 HBMASTER: schedule new run for iteration 6
11:28:07 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
11:28:07 HBMASTER: submitting job (6, 0, 5) to dispatcher
11:28:07 DISPATCHER: trying to submit job (6, 0, 5)
11:28:07 DISPATCHER: trying to notify the job_runner thread.
11:28:07 HBMASTER: job (6, 0, 5) submitted to dispatcher
11:28:07 DISPATCHER: Trying to submit another job.
11:28:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:28:07 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:28:07 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:28:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:28:07 WORKER: start processing job (6, 0, 5)
11:28:07 WORKER: args: ()
11:28:07 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 83, 'last_n_outputs': 31, 'lr': 0.0041042793511059045, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.0462212766243303}, 'budget': 400.0, 'working_directory': '.'}
11:28:18 DISPATCHER: Starting worker discovery
11:28:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:28:18 DISPATCHER: Finished worker discovery
Exception in thread Thread-529:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:29:18 DISPATCHER: Starting worker discovery
11:29:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:29:18 DISPATCHER: Finished worker discovery
11:30:18 DISPATCHER: Starting worker discovery
11:30:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:30:18 DISPATCHER: Finished worker discovery
11:31:18 DISPATCHER: Starting worker discovery
11:31:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:31:18 DISPATCHER: Finished worker discovery
11:32:18 DISPATCHER: Starting worker discovery
11:32:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:32:18 DISPATCHER: Finished worker discovery
11:33:18 DISPATCHER: Starting worker discovery
11:33:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:33:18 DISPATCHER: Finished worker discovery
11:34:18 DISPATCHER: Starting worker discovery
11:34:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:34:18 DISPATCHER: Finished worker discovery
11:35:00 WORKER: done with job (6, 0, 5), trying to register it.
11:35:00 WORKER: registered result for job (6, 0, 5) with dispatcher
11:35:00 DISPATCHER: job (6, 0, 5) finished
11:35:00 DISPATCHER: register_result: lock acquired
11:35:00 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
11:35:00 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 83, 'last_n_outputs': 31, 'lr': 0.0041042793511059045, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.0462212766243303}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.14979320981755087, 'info': {'data04': 0.14979320981755087, 'config': "{'batch_size': 128, 'hidden_dim': 83, 'last_n_outputs': 31, 'lr': 0.0041042793511059045, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.0462212766243303}"}}
exception: None

11:35:00 job_callback for (6, 0, 5) started
11:35:00 job_callback for (6, 0, 5) got condition
11:35:00 DISPATCHER: Trying to submit another job.
11:35:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:35:00 done building a new model for budget 400.000000 based on 9/20 split
Best loss for this budget:-0.183181





11:35:00 HBMASTER: Trying to run another job!
11:35:00 job_callback for (6, 0, 5) finished
11:35:00 ITERATION: Advancing config (6, 0, 2) to next budget 1200.000000
11:35:00 ITERATION: Advancing config (6, 0, 5) to next budget 1200.000000
11:35:00 HBMASTER: schedule new run for iteration 6
11:35:00 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
11:35:00 HBMASTER: submitting job (6, 0, 2) to dispatcher
11:35:00 DISPATCHER: trying to submit job (6, 0, 2)
11:35:00 DISPATCHER: trying to notify the job_runner thread.
11:35:00 HBMASTER: job (6, 0, 2) submitted to dispatcher
11:35:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:35:00 DISPATCHER: Trying to submit another job.
11:35:00 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:35:00 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:35:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:35:00 WORKER: start processing job (6, 0, 2)
11:35:00 WORKER: args: ()
11:35:00 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 49, 'lr': 0.0025236395886711832, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.02411227967433113}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-530:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:35:18 DISPATCHER: Starting worker discovery
11:35:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:35:18 DISPATCHER: Finished worker discovery
11:36:18 DISPATCHER: Starting worker discovery
11:36:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:36:18 DISPATCHER: Finished worker discovery
11:37:18 DISPATCHER: Starting worker discovery
11:37:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:37:18 DISPATCHER: Finished worker discovery
11:38:18 DISPATCHER: Starting worker discovery
11:38:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:38:18 DISPATCHER: Finished worker discovery
11:39:18 DISPATCHER: Starting worker discovery
11:39:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:39:18 DISPATCHER: Finished worker discovery
11:40:18 DISPATCHER: Starting worker discovery
11:40:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:40:18 DISPATCHER: Finished worker discovery
11:41:18 DISPATCHER: Starting worker discovery
11:41:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:41:18 DISPATCHER: Finished worker discovery
11:42:18 DISPATCHER: Starting worker discovery
11:42:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:42:18 DISPATCHER: Finished worker discovery
11:43:18 DISPATCHER: Starting worker discovery
11:43:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:43:18 DISPATCHER: Finished worker discovery
11:44:18 DISPATCHER: Starting worker discovery
11:44:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:44:18 DISPATCHER: Finished worker discovery
11:45:18 DISPATCHER: Starting worker discovery
11:45:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:45:18 DISPATCHER: Finished worker discovery
11:46:18 DISPATCHER: Starting worker discovery
11:46:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:46:18 DISPATCHER: Finished worker discovery
11:47:18 DISPATCHER: Starting worker discovery
11:47:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:47:18 DISPATCHER: Finished worker discovery
11:48:18 DISPATCHER: Starting worker discovery
11:48:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:48:18 DISPATCHER: Finished worker discovery
11:49:18 DISPATCHER: Starting worker discovery
11:49:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:49:18 DISPATCHER: Finished worker discovery
11:50:18 DISPATCHER: Starting worker discovery
11:50:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:50:18 DISPATCHER: Finished worker discovery
11:51:18 DISPATCHER: Starting worker discovery
11:51:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:51:18 DISPATCHER: Finished worker discovery
11:52:18 DISPATCHER: Starting worker discovery
11:52:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:52:18 DISPATCHER: Finished worker discovery
11:53:18 DISPATCHER: Starting worker discovery
11:53:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:53:18 DISPATCHER: Finished worker discovery
11:54:18 DISPATCHER: Starting worker discovery
11:54:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:54:18 DISPATCHER: Finished worker discovery
11:55:13 WORKER: done with job (6, 0, 2), trying to register it.
11:55:13 WORKER: registered result for job (6, 0, 2) with dispatcher
11:55:13 DISPATCHER: job (6, 0, 2) finished
11:55:13 DISPATCHER: register_result: lock acquired
11:55:13 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
11:55:13 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 49, 'lr': 0.0025236395886711832, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.02411227967433113}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.11306643295271776, 'info': {'data04': 0.11306643295271776, 'config': "{'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 49, 'lr': 0.0025236395886711832, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.02411227967433113}"}}
exception: None

11:55:13 job_callback for (6, 0, 2) started
11:55:13 DISPATCHER: Trying to submit another job.
11:55:13 job_callback for (6, 0, 2) got condition
11:55:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:55:13 HBMASTER: Trying to run another job!
11:55:13 job_callback for (6, 0, 2) finished
11:55:13 HBMASTER: schedule new run for iteration 6
11:55:13 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
11:55:13 HBMASTER: submitting job (6, 0, 5) to dispatcher
11:55:13 DISPATCHER: trying to submit job (6, 0, 5)
11:55:13 DISPATCHER: trying to notify the job_runner thread.
11:55:13 HBMASTER: job (6, 0, 5) submitted to dispatcher
11:55:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:55:13 DISPATCHER: Trying to submit another job.
11:55:13 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:55:13 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
11:55:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:55:13 WORKER: start processing job (6, 0, 5)
11:55:13 WORKER: args: ()
11:55:13 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 83, 'last_n_outputs': 31, 'lr': 0.0041042793511059045, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.0462212766243303}, 'budget': 1200.0, 'working_directory': '.'}
11:55:18 DISPATCHER: Starting worker discovery
11:55:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:55:18 DISPATCHER: Finished worker discovery
Exception in thread Thread-531:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:56:18 DISPATCHER: Starting worker discovery
11:56:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:56:18 DISPATCHER: Finished worker discovery
11:57:18 DISPATCHER: Starting worker discovery
11:57:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:57:18 DISPATCHER: Finished worker discovery
11:58:18 DISPATCHER: Starting worker discovery
11:58:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:58:18 DISPATCHER: Finished worker discovery
11:59:18 DISPATCHER: Starting worker discovery
11:59:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:59:18 DISPATCHER: Finished worker discovery
12:00:18 DISPATCHER: Starting worker discovery
12:00:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:00:18 DISPATCHER: Finished worker discovery
12:01:18 DISPATCHER: Starting worker discovery
12:01:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:01:18 DISPATCHER: Finished worker discovery
12:02:18 DISPATCHER: Starting worker discovery
12:02:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:02:18 DISPATCHER: Finished worker discovery
12:03:18 DISPATCHER: Starting worker discovery
12:03:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:03:18 DISPATCHER: Finished worker discovery
12:04:18 DISPATCHER: Starting worker discovery
12:04:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:04:18 DISPATCHER: Finished worker discovery
12:05:18 DISPATCHER: Starting worker discovery
12:05:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:05:18 DISPATCHER: Finished worker discovery
12:06:18 DISPATCHER: Starting worker discovery
12:06:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:06:18 DISPATCHER: Finished worker discovery
12:07:18 DISPATCHER: Starting worker discovery
12:07:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:07:18 DISPATCHER: Finished worker discovery
12:08:18 DISPATCHER: Starting worker discovery
12:08:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:08:18 DISPATCHER: Finished worker discovery
12:09:18 DISPATCHER: Starting worker discovery
12:09:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:09:18 DISPATCHER: Finished worker discovery
12:10:18 DISPATCHER: Starting worker discovery
12:10:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:10:18 DISPATCHER: Finished worker discovery
12:11:18 DISPATCHER: Starting worker discovery
12:11:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:11:18 DISPATCHER: Finished worker discovery
12:12:18 DISPATCHER: Starting worker discovery
12:12:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:12:18 DISPATCHER: Finished worker discovery
12:13:18 DISPATCHER: Starting worker discovery
12:13:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:13:18 DISPATCHER: Finished worker discovery
12:14:18 DISPATCHER: Starting worker discovery
12:14:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:14:18 DISPATCHER: Finished worker discovery
12:15:18 DISPATCHER: Starting worker discovery
12:15:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:15:18 DISPATCHER: Finished worker discovery
12:15:26 WORKER: done with job (6, 0, 5), trying to register it.
12:15:26 WORKER: registered result for job (6, 0, 5) with dispatcher
12:15:26 DISPATCHER: job (6, 0, 5) finished
12:15:26 DISPATCHER: register_result: lock acquired
12:15:26 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:15:26 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 83, 'last_n_outputs': 31, 'lr': 0.0041042793511059045, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.0462212766243303}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.1178421493818619, 'info': {'data04': 0.1178421493818619, 'config': "{'batch_size': 128, 'hidden_dim': 83, 'last_n_outputs': 31, 'lr': 0.0041042793511059045, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.0462212766243303}"}}
exception: None

12:15:26 job_callback for (6, 0, 5) started
12:15:26 job_callback for (6, 0, 5) got condition
12:15:26 DISPATCHER: Trying to submit another job.
12:15:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:15:26 HBMASTER: Trying to run another job!
12:15:26 job_callback for (6, 0, 5) finished
12:15:26 start sampling a new configuration.
12:15:26 best_vector: [2, 0.650897537047195, 0.9601114227498808, 0.39448596475314, 0.09955643785537986, 0, 0.9276627609701814, 0.3054341951254023], 2.6534863439180614e-05, 1593.9781514914125, 0.04229599257486218
12:15:26 done sampling a new configuration.
12:15:26 HBMASTER: schedule new run for iteration 7
12:15:26 HBMASTER: trying submitting job (7, 0, 0) to dispatcher
12:15:26 HBMASTER: submitting job (7, 0, 0) to dispatcher
12:15:26 DISPATCHER: trying to submit job (7, 0, 0)
12:15:26 DISPATCHER: trying to notify the job_runner thread.
12:15:26 HBMASTER: job (7, 0, 0) submitted to dispatcher
12:15:26 DISPATCHER: Trying to submit another job.
12:15:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:15:26 DISPATCHER: starting job (7, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:15:26 DISPATCHER: job (7, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:15:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:15:26 WORKER: start processing job (7, 0, 0)
12:15:26 WORKER: args: ()
12:15:26 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 72, 'last_n_outputs': 49, 'lr': 0.0061513711222197995, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.02496772944346706}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-532:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:16:18 DISPATCHER: Starting worker discovery
12:16:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:16:18 DISPATCHER: Finished worker discovery
12:17:18 DISPATCHER: Starting worker discovery
12:17:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:17:18 DISPATCHER: Finished worker discovery
12:18:18 DISPATCHER: Starting worker discovery
12:18:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:18:18 DISPATCHER: Finished worker discovery
12:19:18 DISPATCHER: Starting worker discovery
12:19:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:19:18 DISPATCHER: Finished worker discovery
12:20:18 DISPATCHER: Starting worker discovery
12:20:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:20:18 DISPATCHER: Finished worker discovery
12:21:18 DISPATCHER: Starting worker discovery
12:21:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:21:18 DISPATCHER: Finished worker discovery
12:22:18 DISPATCHER: Starting worker discovery
12:22:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:22:18 DISPATCHER: Finished worker discovery
12:23:18 DISPATCHER: Starting worker discovery
12:23:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:23:18 DISPATCHER: Finished worker discovery
12:24:18 DISPATCHER: Starting worker discovery
12:24:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:24:18 DISPATCHER: Finished worker discovery
12:25:18 DISPATCHER: Starting worker discovery
12:25:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:25:18 DISPATCHER: Finished worker discovery
12:26:18 DISPATCHER: Starting worker discovery
12:26:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:26:18 DISPATCHER: Finished worker discovery
12:27:18 DISPATCHER: Starting worker discovery
12:27:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:27:18 DISPATCHER: Finished worker discovery
12:28:18 DISPATCHER: Starting worker discovery
12:28:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:28:18 DISPATCHER: Finished worker discovery
12:29:18 DISPATCHER: Starting worker discovery
12:29:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:29:18 DISPATCHER: Finished worker discovery
12:30:18 DISPATCHER: Starting worker discovery
12:30:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:30:18 DISPATCHER: Finished worker discovery
12:31:18 DISPATCHER: Starting worker discovery
12:31:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:31:18 DISPATCHER: Finished worker discovery
12:32:18 DISPATCHER: Starting worker discovery
12:32:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:32:18 DISPATCHER: Finished worker discovery
12:33:18 DISPATCHER: Starting worker discovery
12:33:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:33:18 DISPATCHER: Finished worker discovery
12:34:18 DISPATCHER: Starting worker discovery
12:34:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:34:18 DISPATCHER: Finished worker discovery
12:35:18 DISPATCHER: Starting worker discovery
12:35:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:35:18 DISPATCHER: Finished worker discovery
12:35:39 WORKER: done with job (7, 0, 0), trying to register it.
12:35:39 WORKER: registered result for job (7, 0, 0) with dispatcher
12:35:39 DISPATCHER: job (7, 0, 0) finished
12:35:39 DISPATCHER: register_result: lock acquired
12:35:39 DISPATCHER: job (7, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:35:39 job_id: (7, 0, 0)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 72, 'last_n_outputs': 49, 'lr': 0.0061513711222197995, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.02496772944346706}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.10691730210586706, 'info': {'data04': 0.10691730210586706, 'config': "{'batch_size': 64, 'hidden_dim': 72, 'last_n_outputs': 49, 'lr': 0.0061513711222197995, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.02496772944346706}"}}
exception: None

12:35:39 job_callback for (7, 0, 0) started
12:35:39 DISPATCHER: Trying to submit another job.
12:35:39 job_callback for (7, 0, 0) got condition
12:35:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:35:39 HBMASTER: Trying to run another job!
12:35:39 job_callback for (7, 0, 0) finished
12:35:39 start sampling a new configuration.
12:35:39 done sampling a new configuration.
12:35:39 HBMASTER: schedule new run for iteration 7
12:35:39 HBMASTER: trying submitting job (7, 0, 1) to dispatcher
12:35:39 HBMASTER: submitting job (7, 0, 1) to dispatcher
12:35:39 DISPATCHER: trying to submit job (7, 0, 1)
12:35:39 DISPATCHER: trying to notify the job_runner thread.
12:35:39 HBMASTER: job (7, 0, 1) submitted to dispatcher
12:35:39 DISPATCHER: Trying to submit another job.
12:35:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:35:39 DISPATCHER: starting job (7, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:35:39 DISPATCHER: job (7, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:35:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:35:40 WORKER: start processing job (7, 0, 1)
12:35:40 WORKER: args: ()
12:35:40 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 34, 'last_n_outputs': 39, 'lr': 0.04233998434883064, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.08332032356807877}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-533:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:36:18 DISPATCHER: Starting worker discovery
12:36:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:36:18 DISPATCHER: Finished worker discovery
12:37:18 DISPATCHER: Starting worker discovery
12:37:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:37:18 DISPATCHER: Finished worker discovery
12:38:18 DISPATCHER: Starting worker discovery
12:38:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:38:18 DISPATCHER: Finished worker discovery
12:39:18 DISPATCHER: Starting worker discovery
12:39:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:39:18 DISPATCHER: Finished worker discovery
12:40:18 DISPATCHER: Starting worker discovery
12:40:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:40:18 DISPATCHER: Finished worker discovery
12:41:18 DISPATCHER: Starting worker discovery
12:41:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:41:18 DISPATCHER: Finished worker discovery
12:42:18 DISPATCHER: Starting worker discovery
12:42:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:42:18 DISPATCHER: Finished worker discovery
12:43:18 DISPATCHER: Starting worker discovery
12:43:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:43:18 DISPATCHER: Finished worker discovery
12:44:18 DISPATCHER: Starting worker discovery
12:44:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:44:18 DISPATCHER: Finished worker discovery
12:45:18 DISPATCHER: Starting worker discovery
12:45:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:45:18 DISPATCHER: Finished worker discovery
12:46:18 DISPATCHER: Starting worker discovery
12:46:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:46:18 DISPATCHER: Finished worker discovery
12:47:18 DISPATCHER: Starting worker discovery
12:47:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:47:18 DISPATCHER: Finished worker discovery
12:48:18 DISPATCHER: Starting worker discovery
12:48:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:48:18 DISPATCHER: Finished worker discovery
12:49:18 DISPATCHER: Starting worker discovery
12:49:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:49:18 DISPATCHER: Finished worker discovery
12:50:18 DISPATCHER: Starting worker discovery
12:50:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:50:18 DISPATCHER: Finished worker discovery
12:51:18 DISPATCHER: Starting worker discovery
12:51:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:51:18 DISPATCHER: Finished worker discovery
12:52:18 DISPATCHER: Starting worker discovery
12:52:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:52:18 DISPATCHER: Finished worker discovery
12:53:18 DISPATCHER: Starting worker discovery
12:53:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:53:18 DISPATCHER: Finished worker discovery
12:54:18 DISPATCHER: Starting worker discovery
12:54:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:54:18 DISPATCHER: Finished worker discovery
12:55:18 DISPATCHER: Starting worker discovery
12:55:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:55:18 DISPATCHER: Finished worker discovery
12:55:53 WORKER: done with job (7, 0, 1), trying to register it.
12:55:53 WORKER: registered result for job (7, 0, 1) with dispatcher
12:55:53 DISPATCHER: job (7, 0, 1) finished
12:55:53 DISPATCHER: register_result: lock acquired
12:55:53 DISPATCHER: job (7, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
12:55:53 job_id: (7, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 34, 'last_n_outputs': 39, 'lr': 0.04233998434883064, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.08332032356807877}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.007937353278455895, 'info': {'data04': 0.007937353278455895, 'config': "{'batch_size': 16, 'hidden_dim': 34, 'last_n_outputs': 39, 'lr': 0.04233998434883064, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.08332032356807877}"}}
exception: None

12:55:53 job_callback for (7, 0, 1) started
12:55:53 DISPATCHER: Trying to submit another job.
12:55:53 job_callback for (7, 0, 1) got condition
12:55:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:55:53 HBMASTER: Trying to run another job!
12:55:53 job_callback for (7, 0, 1) finished
12:55:53 start sampling a new configuration.
12:55:53 best_vector: [3, 0.8495249594330198, 0.8788865513009858, 0.36565350098527694, 0.10004729342723581, 0, 0.01907821898618163, 0.24928317061016497], 4.1707367502432686e-05, 4754.0425970117585, 0.1982786017157889
12:55:54 done sampling a new configuration.
12:55:54 HBMASTER: schedule new run for iteration 7
12:55:54 HBMASTER: trying submitting job (7, 0, 2) to dispatcher
12:55:54 HBMASTER: submitting job (7, 0, 2) to dispatcher
12:55:54 DISPATCHER: trying to submit job (7, 0, 2)
12:55:54 DISPATCHER: trying to notify the job_runner thread.
12:55:54 HBMASTER: job (7, 0, 2) submitted to dispatcher
12:55:54 DISPATCHER: Trying to submit another job.
12:55:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:55:54 DISPATCHER: starting job (7, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:55:54 DISPATCHER: job (7, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
12:55:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:55:54 WORKER: start processing job (7, 0, 2)
12:55:54 WORKER: args: ()
12:55:54 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 88, 'last_n_outputs': 44, 'lr': 0.005386504189553754, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 11, 'weight_decay': 0.0211020614011038}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-534:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:56:18 DISPATCHER: Starting worker discovery
12:56:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:56:18 DISPATCHER: Finished worker discovery
12:57:18 DISPATCHER: Starting worker discovery
12:57:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:57:18 DISPATCHER: Finished worker discovery
12:58:18 DISPATCHER: Starting worker discovery
12:58:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:58:18 DISPATCHER: Finished worker discovery
12:59:18 DISPATCHER: Starting worker discovery
12:59:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:59:18 DISPATCHER: Finished worker discovery
13:00:18 DISPATCHER: Starting worker discovery
13:00:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:00:18 DISPATCHER: Finished worker discovery
13:01:18 DISPATCHER: Starting worker discovery
13:01:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:01:18 DISPATCHER: Finished worker discovery
13:02:18 DISPATCHER: Starting worker discovery
13:02:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:02:18 DISPATCHER: Finished worker discovery
13:03:18 DISPATCHER: Starting worker discovery
13:03:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:03:18 DISPATCHER: Finished worker discovery
13:04:18 DISPATCHER: Starting worker discovery
13:04:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:04:18 DISPATCHER: Finished worker discovery
13:05:18 DISPATCHER: Starting worker discovery
13:05:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:05:18 DISPATCHER: Finished worker discovery
13:06:18 DISPATCHER: Starting worker discovery
13:06:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:06:18 DISPATCHER: Finished worker discovery
13:07:18 DISPATCHER: Starting worker discovery
13:07:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:07:18 DISPATCHER: Finished worker discovery
13:08:18 DISPATCHER: Starting worker discovery
13:08:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:08:18 DISPATCHER: Finished worker discovery
13:09:18 DISPATCHER: Starting worker discovery
13:09:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:09:18 DISPATCHER: Finished worker discovery
13:10:18 DISPATCHER: Starting worker discovery
13:10:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:10:18 DISPATCHER: Finished worker discovery
13:11:18 DISPATCHER: Starting worker discovery
13:11:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:11:18 DISPATCHER: Finished worker discovery
13:12:18 DISPATCHER: Starting worker discovery
13:12:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:12:18 DISPATCHER: Finished worker discovery
13:13:18 DISPATCHER: Starting worker discovery
13:13:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:13:18 DISPATCHER: Finished worker discovery
13:14:18 DISPATCHER: Starting worker discovery
13:14:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:14:18 DISPATCHER: Finished worker discovery
13:15:18 DISPATCHER: Starting worker discovery
13:15:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:15:18 DISPATCHER: Finished worker discovery
13:16:07 WORKER: done with job (7, 0, 2), trying to register it.
13:16:07 WORKER: registered result for job (7, 0, 2) with dispatcher
13:16:07 DISPATCHER: job (7, 0, 2) finished
13:16:07 DISPATCHER: register_result: lock acquired
13:16:07 DISPATCHER: job (7, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
13:16:07 job_id: (7, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 88, 'last_n_outputs': 44, 'lr': 0.005386504189553754, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 11, 'weight_decay': 0.0211020614011038}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.08977243659055302, 'info': {'data04': 0.08977243659055302, 'config': "{'batch_size': 128, 'hidden_dim': 88, 'last_n_outputs': 44, 'lr': 0.005386504189553754, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 11, 'weight_decay': 0.0211020614011038}"}}
exception: None

13:16:07 job_callback for (7, 0, 2) started
13:16:07 job_callback for (7, 0, 2) got condition
13:16:07 DISPATCHER: Trying to submit another job.
13:16:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:16:07 HBMASTER: Trying to run another job!
13:16:07 job_callback for (7, 0, 2) finished
13:16:07 start sampling a new configuration.
13:16:07 best_vector: [2, 0.7236169803293709, 0.7980819692632428, 0.3060445160953057, 0.1010052375729149, 0, 0.5437665837056629, 0.2959326857911825], 3.594513652836852e-05, 2589.4900568709386, 0.09307957363307866
13:16:07 done sampling a new configuration.
13:16:07 HBMASTER: schedule new run for iteration 7
13:16:07 HBMASTER: trying submitting job (7, 0, 3) to dispatcher
13:16:07 HBMASTER: submitting job (7, 0, 3) to dispatcher
13:16:07 DISPATCHER: trying to submit job (7, 0, 3)
13:16:07 DISPATCHER: trying to notify the job_runner thread.
13:16:07 HBMASTER: job (7, 0, 3) submitted to dispatcher
13:16:07 DISPATCHER: Trying to submit another job.
13:16:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:16:07 DISPATCHER: starting job (7, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:16:07 DISPATCHER: job (7, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:16:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:16:07 WORKER: start processing job (7, 0, 3)
13:16:07 WORKER: args: ()
13:16:07 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 78, 'last_n_outputs': 40, 'lr': 0.004093445684825919, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.024267067654410113}, 'budget': 1200.0, 'working_directory': '.'}
13:16:18 DISPATCHER: Starting worker discovery
13:16:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:16:18 DISPATCHER: Finished worker discovery
Exception in thread Thread-535:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:17:18 DISPATCHER: Starting worker discovery
13:17:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:17:18 DISPATCHER: Finished worker discovery
13:18:18 DISPATCHER: Starting worker discovery
13:18:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:18:18 DISPATCHER: Finished worker discovery
13:19:18 DISPATCHER: Starting worker discovery
13:19:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:19:18 DISPATCHER: Finished worker discovery
13:20:18 DISPATCHER: Starting worker discovery
13:20:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:20:18 DISPATCHER: Finished worker discovery
13:21:18 DISPATCHER: Starting worker discovery
13:21:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:21:18 DISPATCHER: Finished worker discovery
13:22:18 DISPATCHER: Starting worker discovery
13:22:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:22:18 DISPATCHER: Finished worker discovery
13:23:18 DISPATCHER: Starting worker discovery
13:23:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:23:18 DISPATCHER: Finished worker discovery
13:24:18 DISPATCHER: Starting worker discovery
13:24:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:24:18 DISPATCHER: Finished worker discovery
13:25:18 DISPATCHER: Starting worker discovery
13:25:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:25:18 DISPATCHER: Finished worker discovery
13:26:18 DISPATCHER: Starting worker discovery
13:26:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:26:18 DISPATCHER: Finished worker discovery
13:27:18 DISPATCHER: Starting worker discovery
13:27:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:27:19 DISPATCHER: Finished worker discovery
13:28:19 DISPATCHER: Starting worker discovery
13:28:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:28:19 DISPATCHER: Finished worker discovery
13:29:19 DISPATCHER: Starting worker discovery
13:29:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:29:19 DISPATCHER: Finished worker discovery
13:30:19 DISPATCHER: Starting worker discovery
13:30:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:30:19 DISPATCHER: Finished worker discovery
13:31:19 DISPATCHER: Starting worker discovery
13:31:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:31:19 DISPATCHER: Finished worker discovery
13:32:19 DISPATCHER: Starting worker discovery
13:32:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:32:19 DISPATCHER: Finished worker discovery
13:33:19 DISPATCHER: Starting worker discovery
13:33:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:33:19 DISPATCHER: Finished worker discovery
13:34:19 DISPATCHER: Starting worker discovery
13:34:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:34:19 DISPATCHER: Finished worker discovery
13:35:19 DISPATCHER: Starting worker discovery
13:35:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:35:19 DISPATCHER: Finished worker discovery
13:36:19 DISPATCHER: Starting worker discovery
13:36:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:36:19 DISPATCHER: Finished worker discovery
13:36:21 WORKER: done with job (7, 0, 3), trying to register it.
13:36:21 WORKER: registered result for job (7, 0, 3) with dispatcher
13:36:21 DISPATCHER: job (7, 0, 3) finished
13:36:21 DISPATCHER: register_result: lock acquired
13:36:21 DISPATCHER: job (7, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
13:36:21 job_id: (7, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 78, 'last_n_outputs': 40, 'lr': 0.004093445684825919, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.024267067654410113}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.1428555337527224, 'info': {'data04': 0.1428555337527224, 'config': "{'batch_size': 64, 'hidden_dim': 78, 'last_n_outputs': 40, 'lr': 0.004093445684825919, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.024267067654410113}"}}
exception: None

13:36:21 job_callback for (7, 0, 3) started
13:36:21 job_callback for (7, 0, 3) got condition
13:36:21 DISPATCHER: Trying to submit another job.
13:36:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:36:21 HBMASTER: Trying to run another job!
13:36:21 job_callback for (7, 0, 3) finished
13:36:21 start sampling a new configuration.
13:36:21 best_vector: [1, 0.7629608454874248, 0.9583082801546444, 0.11046330812320984, 0.10017107121743737, 0, 0.3669018474843695, 0.38564282699195707], 5.8749733891698846e-05, 2238.5040217569604, 0.13151151559371907
13:36:21 done sampling a new configuration.
13:36:21 HBMASTER: schedule new run for iteration 8
13:36:21 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
13:36:21 HBMASTER: submitting job (8, 0, 0) to dispatcher
13:36:21 DISPATCHER: trying to submit job (8, 0, 0)
13:36:21 DISPATCHER: trying to notify the job_runner thread.
13:36:21 HBMASTER: job (8, 0, 0) submitted to dispatcher
13:36:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:36:21 DISPATCHER: Trying to submit another job.
13:36:21 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:36:21 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:36:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:36:21 WORKER: start processing job (8, 0, 0)
13:36:21 WORKER: args: ()
13:36:21 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 81, 'last_n_outputs': 48, 'lr': 0.0016631316033923886, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.03174920722953461}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-536:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:37:19 DISPATCHER: Starting worker discovery
13:37:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:37:19 DISPATCHER: Finished worker discovery
13:37:20 WORKER: done with job (8, 0, 0), trying to register it.
13:37:20 WORKER: registered result for job (8, 0, 0) with dispatcher
13:37:20 DISPATCHER: job (8, 0, 0) finished
13:37:20 DISPATCHER: register_result: lock acquired
13:37:20 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
13:37:20 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 81, 'last_n_outputs': 48, 'lr': 0.0016631316033923886, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.03174920722953461}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.11407477336464869, 'info': {'data04': 0.11407477336464869, 'config': "{'batch_size': 32, 'hidden_dim': 81, 'last_n_outputs': 48, 'lr': 0.0016631316033923886, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.03174920722953461}"}}
exception: None

13:37:20 job_callback for (8, 0, 0) started
13:37:20 job_callback for (8, 0, 0) got condition
13:37:20 DISPATCHER: Trying to submit another job.
13:37:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:37:20 HBMASTER: Trying to run another job!
13:37:20 job_callback for (8, 0, 0) finished
13:37:20 start sampling a new configuration.
13:37:20 best_vector: [2, 0.7470581072751503, 0.9470543175107473, 0.2994729186149232, 0.09972277329149326, 0, 0.7103002438305984, 0.4364516829662207], 4.2263521934790626e-05, 1438.3577758985532, 0.06079006541176516
13:37:20 done sampling a new configuration.
13:37:20 HBMASTER: schedule new run for iteration 8
13:37:20 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
13:37:20 HBMASTER: submitting job (8, 0, 1) to dispatcher
13:37:20 DISPATCHER: trying to submit job (8, 0, 1)
13:37:20 DISPATCHER: trying to notify the job_runner thread.
13:37:20 HBMASTER: job (8, 0, 1) submitted to dispatcher
13:37:20 DISPATCHER: Trying to submit another job.
13:37:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:37:20 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:37:20 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:37:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:37:20 WORKER: start processing job (8, 0, 1)
13:37:20 WORKER: args: ()
13:37:20 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 80, 'last_n_outputs': 48, 'lr': 0.0039714201705753314, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.036968917258990396}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-537:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:38:18 WORKER: done with job (8, 0, 1), trying to register it.
13:38:18 WORKER: registered result for job (8, 0, 1) with dispatcher
13:38:18 DISPATCHER: job (8, 0, 1) finished
13:38:18 DISPATCHER: register_result: lock acquired
13:38:18 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
13:38:18 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 80, 'last_n_outputs': 48, 'lr': 0.0039714201705753314, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.036968917258990396}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1034682748997816, 'info': {'data04': 0.1034682748997816, 'config': "{'batch_size': 64, 'hidden_dim': 80, 'last_n_outputs': 48, 'lr': 0.0039714201705753314, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.036968917258990396}"}}
exception: None

13:38:18 job_callback for (8, 0, 1) started
13:38:18 job_callback for (8, 0, 1) got condition
13:38:18 DISPATCHER: Trying to submit another job.
13:38:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:38:18 HBMASTER: Trying to run another job!
13:38:18 job_callback for (8, 0, 1) finished
13:38:18 start sampling a new configuration.
13:38:18 done sampling a new configuration.
13:38:18 HBMASTER: schedule new run for iteration 8
13:38:18 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
13:38:18 HBMASTER: submitting job (8, 0, 2) to dispatcher
13:38:18 DISPATCHER: trying to submit job (8, 0, 2)
13:38:18 DISPATCHER: trying to notify the job_runner thread.
13:38:18 HBMASTER: job (8, 0, 2) submitted to dispatcher
13:38:18 DISPATCHER: Trying to submit another job.
13:38:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:38:18 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:38:18 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:38:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:38:18 WORKER: start processing job (8, 0, 2)
13:38:18 WORKER: args: ()
13:38:18 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 82, 'last_n_outputs': 14, 'lr': 0.027453993959259917, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.010916883800270486}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:38:19 DISPATCHER: Starting worker discovery
13:38:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:38:19 DISPATCHER: Finished worker discovery
Exception in thread Thread-538:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:39:17 WORKER: done with job (8, 0, 2), trying to register it.
13:39:17 WORKER: registered result for job (8, 0, 2) with dispatcher
13:39:17 DISPATCHER: job (8, 0, 2) finished
13:39:17 DISPATCHER: register_result: lock acquired
13:39:17 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
13:39:17 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 82, 'last_n_outputs': 14, 'lr': 0.027453993959259917, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.010916883800270486}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 82, 'last_n_outputs': 14, 'lr': 0.027453993959259917, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.010916883800270486}"}}
exception: None

13:39:17 job_callback for (8, 0, 2) started
13:39:17 job_callback for (8, 0, 2) got condition
13:39:17 DISPATCHER: Trying to submit another job.
13:39:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:39:17 HBMASTER: Trying to run another job!
13:39:17 job_callback for (8, 0, 2) finished
13:39:17 start sampling a new configuration.
13:39:17 done sampling a new configuration.
13:39:17 HBMASTER: schedule new run for iteration 8
13:39:17 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
13:39:17 HBMASTER: submitting job (8, 0, 3) to dispatcher
13:39:17 DISPATCHER: trying to submit job (8, 0, 3)
13:39:17 DISPATCHER: trying to notify the job_runner thread.
13:39:17 HBMASTER: job (8, 0, 3) submitted to dispatcher
13:39:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:39:17 DISPATCHER: Trying to submit another job.
13:39:17 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:39:17 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:39:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:39:17 WORKER: start processing job (8, 0, 3)
13:39:17 WORKER: args: ()
13:39:17 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 46, 'lr': 0.005731093009857891, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.1879251401989948}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:39:19 DISPATCHER: Starting worker discovery
13:39:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:39:19 DISPATCHER: Finished worker discovery
Exception in thread Thread-539:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:40:15 WORKER: done with job (8, 0, 3), trying to register it.
13:40:15 WORKER: registered result for job (8, 0, 3) with dispatcher
13:40:15 DISPATCHER: job (8, 0, 3) finished
13:40:15 DISPATCHER: register_result: lock acquired
13:40:15 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
13:40:15 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 46, 'lr': 0.005731093009857891, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.1879251401989948}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 48, 'last_n_outputs': 46, 'lr': 0.005731093009857891, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.1879251401989948}"}}
exception: None

13:40:15 job_callback for (8, 0, 3) started
13:40:15 DISPATCHER: Trying to submit another job.
13:40:15 job_callback for (8, 0, 3) got condition
13:40:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:40:15 HBMASTER: Trying to run another job!
13:40:15 job_callback for (8, 0, 3) finished
13:40:15 start sampling a new configuration.
13:40:15 done sampling a new configuration.
13:40:15 HBMASTER: schedule new run for iteration 8
13:40:15 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
13:40:15 HBMASTER: submitting job (8, 0, 4) to dispatcher
13:40:15 DISPATCHER: trying to submit job (8, 0, 4)
13:40:15 DISPATCHER: trying to notify the job_runner thread.
13:40:15 HBMASTER: job (8, 0, 4) submitted to dispatcher
13:40:15 DISPATCHER: Trying to submit another job.
13:40:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:40:15 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:40:15 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:40:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:40:15 WORKER: start processing job (8, 0, 4)
13:40:15 WORKER: args: ()
13:40:15 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 66, 'last_n_outputs': 31, 'lr': 0.05077976955363977, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.011016188744614798}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:40:19 DISPATCHER: Starting worker discovery
13:40:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:40:19 DISPATCHER: Finished worker discovery
Exception in thread Thread-540:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:41:13 WORKER: done with job (8, 0, 4), trying to register it.
13:41:13 WORKER: registered result for job (8, 0, 4) with dispatcher
13:41:13 DISPATCHER: job (8, 0, 4) finished
13:41:13 DISPATCHER: register_result: lock acquired
13:41:13 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
13:41:13 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 66, 'last_n_outputs': 31, 'lr': 0.05077976955363977, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.011016188744614798}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 66, 'last_n_outputs': 31, 'lr': 0.05077976955363977, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.011016188744614798}"}}
exception: None

13:41:13 job_callback for (8, 0, 4) started
13:41:13 job_callback for (8, 0, 4) got condition
13:41:13 DISPATCHER: Trying to submit another job.
13:41:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:41:13 HBMASTER: Trying to run another job!
13:41:13 job_callback for (8, 0, 4) finished
13:41:13 start sampling a new configuration.
13:41:13 done sampling a new configuration.
13:41:13 HBMASTER: schedule new run for iteration 8
13:41:13 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
13:41:13 HBMASTER: submitting job (8, 0, 5) to dispatcher
13:41:13 DISPATCHER: trying to submit job (8, 0, 5)
13:41:13 DISPATCHER: trying to notify the job_runner thread.
13:41:13 HBMASTER: job (8, 0, 5) submitted to dispatcher
13:41:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:41:13 DISPATCHER: Trying to submit another job.
13:41:13 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:41:13 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:41:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:41:13 WORKER: start processing job (8, 0, 5)
13:41:13 WORKER: args: ()
13:41:13 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 79, 'last_n_outputs': 39, 'lr': 0.06633963032254127, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.16748479714047473}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:41:19 DISPATCHER: Starting worker discovery
13:41:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:41:19 DISPATCHER: Finished worker discovery
Exception in thread Thread-541:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:42:12 WORKER: done with job (8, 0, 5), trying to register it.
13:42:12 WORKER: registered result for job (8, 0, 5) with dispatcher
13:42:12 DISPATCHER: job (8, 0, 5) finished
13:42:12 DISPATCHER: register_result: lock acquired
13:42:12 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
13:42:12 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 79, 'last_n_outputs': 39, 'lr': 0.06633963032254127, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.16748479714047473}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 79, 'last_n_outputs': 39, 'lr': 0.06633963032254127, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.16748479714047473}"}}
exception: None

13:42:12 job_callback for (8, 0, 5) started
13:42:12 DISPATCHER: Trying to submit another job.
13:42:12 job_callback for (8, 0, 5) got condition
13:42:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:42:12 HBMASTER: Trying to run another job!
13:42:12 job_callback for (8, 0, 5) finished
13:42:12 start sampling a new configuration.
13:42:12 done sampling a new configuration.
13:42:12 HBMASTER: schedule new run for iteration 8
13:42:12 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
13:42:12 HBMASTER: submitting job (8, 0, 6) to dispatcher
13:42:12 DISPATCHER: trying to submit job (8, 0, 6)
13:42:12 DISPATCHER: trying to notify the job_runner thread.
13:42:12 HBMASTER: job (8, 0, 6) submitted to dispatcher
13:42:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:42:12 DISPATCHER: Trying to submit another job.
13:42:12 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:42:12 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:42:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:42:12 WORKER: start processing job (8, 0, 6)
13:42:12 WORKER: args: ()
13:42:12 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 35, 'last_n_outputs': 33, 'lr': 0.006815986650689676, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.030989399176920406}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:42:19 DISPATCHER: Starting worker discovery
13:42:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:42:19 DISPATCHER: Finished worker discovery
Exception in thread Thread-542:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:43:09 WORKER: done with job (8, 0, 6), trying to register it.
13:43:09 WORKER: registered result for job (8, 0, 6) with dispatcher
13:43:09 DISPATCHER: job (8, 0, 6) finished
13:43:09 DISPATCHER: register_result: lock acquired
13:43:09 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
13:43:09 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 35, 'last_n_outputs': 33, 'lr': 0.006815986650689676, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.030989399176920406}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 35, 'last_n_outputs': 33, 'lr': 0.006815986650689676, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.030989399176920406}"}}
exception: None

13:43:09 job_callback for (8, 0, 6) started
13:43:09 job_callback for (8, 0, 6) got condition
13:43:09 DISPATCHER: Trying to submit another job.
13:43:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:43:09 HBMASTER: Trying to run another job!
13:43:09 job_callback for (8, 0, 6) finished
13:43:09 start sampling a new configuration.
13:43:09 sampled vector: [0, 0.7776480633375746, 0.959694146502829, 0.3371495377568019, 0.09489002613770996, 1, 0.6548580064469128, 0.28518632939084376] has EI value nan
13:43:09 data in the KDEs:
[[3.         0.67283955 0.67000007 0.02556037 0.0999984  0.
  0.98351659 0.01501267]
 [3.         0.83333342 0.97000019 0.24336644 0.0999984  0.
  0.26923072 0.08838893]
 [3.         0.78395069 0.61000004 0.30661846 0.0999984  0.
  0.77472534 0.511012  ]
 [3.         0.75925932 0.89000016 0.02161623 0.0999984  0.
  0.18131861 0.23336596]
 [2.         0.91975319 0.97000019 0.20101367 0.0999984  0.
  0.12637354 0.29379666]
 [1.         0.67283955 0.93000017 0.24660846 0.0999984  0.
  0.92857152 0.26317394]
 [0.         0.89506183 0.85000014 0.10806916 0.0999984  0.
  0.34615381 0.14252145]
 [2.         0.85802478 0.93000017 0.40650899 0.0999984  0.
  0.03846144 0.27801021]
 [0.         0.72222228 0.81000012 0.21505977 0.0999984  0.
  0.48901099 0.31461902]]
[[1.         0.9814816  0.97000019 0.39074504 0.0999984  0.
  0.0054944  0.35665422]
 [0.         0.99382728 0.79000012 0.01058579 0.0999984  0.
  0.46703296 0.44960884]
 [1.         0.99382728 0.16999987 0.06463218 0.0999984  0.
  0.04945045 0.09498723]
 [3.         0.94444455 0.55000002 0.69169086 0.0999984  1.
  0.69780224 0.57093564]
 [2.         0.91975319 0.06999983 0.49134915 0.0999984  0.
  0.34615381 0.2220369 ]
 [2.         0.72222228 0.28999992 0.72934799 0.0999984  0.
  0.52197803 0.0982098 ]
 [1.         0.5        0.49       0.65702451 0.0999984  1.
  0.76373632 0.44683656]
 [0.         0.45061727 0.49       0.75725213 0.0999984  1.
  0.77472534 0.04815185]
 [1.         0.58641977 0.12999985 0.46669579 0.2999992  0.
  0.39010987 0.01183133]
 [2.         0.67283955 0.77000011 0.05933137 0.0999984  1.
  0.91758251 0.03312671]
 [2.         0.83333342 0.12999985 0.34949506 0.7000008  1.
  0.76373632 0.78580064]
 [2.         0.2901234  0.51       0.03713136 0.5        0.
  0.39010987 0.05604344]
 [1.         0.33950613 0.32999993 0.58443042 0.5        0.
  0.71978027 0.99605398]
 [2.         0.10493817 0.93000017 0.1767329  0.0999984  1.
  0.02747242 0.70928124]
 [3.         0.48765432 0.83000013 0.41494344 0.7000008  1.
  0.46703296 0.51816842]]
13:43:09 bandwidth of the KDEs:
[1.05626318e+00 7.63835381e-02 1.08003521e-01 1.05640220e-01
 1.00000000e-03 1.00000000e-03 2.95614848e-01 1.20231917e-01]
[0.74810634 0.23527    0.25044056 0.21814494 0.19006314 0.42198889
 0.23875361 0.25548755]
13:43:09 l(x) = nan
13:43:09 g(x) = 0.064648664304979
13:43:09 best_vector: [0, 0.8536516168771485, 0.8500307244434621, 0.3267911704889097, 0.09876232917640491, 0, 0.031051179023919448, 0.07884895264764075], 0.00010782173939601952, 1062.596187778525, 0.11457096924185994
13:43:09 done sampling a new configuration.
13:43:09 HBMASTER: schedule new run for iteration 8
13:43:09 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
13:43:09 HBMASTER: submitting job (8, 0, 7) to dispatcher
13:43:09 DISPATCHER: trying to submit job (8, 0, 7)
13:43:09 DISPATCHER: trying to notify the job_runner thread.
13:43:09 HBMASTER: job (8, 0, 7) submitted to dispatcher
13:43:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:43:09 DISPATCHER: Trying to submit another job.
13:43:09 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:43:09 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:43:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:43:09 WORKER: start processing job (8, 0, 7)
13:43:09 WORKER: args: ()
13:43:09 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 89, 'last_n_outputs': 43, 'lr': 0.004503833645770678, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.012664406807112392}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:43:19 DISPATCHER: Starting worker discovery
13:43:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:43:19 DISPATCHER: Finished worker discovery
Exception in thread Thread-543:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:44:08 WORKER: done with job (8, 0, 7), trying to register it.
13:44:08 WORKER: registered result for job (8, 0, 7) with dispatcher
13:44:08 DISPATCHER: job (8, 0, 7) finished
13:44:08 DISPATCHER: register_result: lock acquired
13:44:08 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
13:44:08 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 89, 'last_n_outputs': 43, 'lr': 0.004503833645770678, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.012664406807112392}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.03390192184808628, 'info': {'data04': 0.03390192184808628, 'config': "{'batch_size': 16, 'hidden_dim': 89, 'last_n_outputs': 43, 'lr': 0.004503833645770678, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.012664406807112392}"}}
exception: None

13:44:08 job_callback for (8, 0, 7) started
13:44:08 DISPATCHER: Trying to submit another job.
13:44:08 job_callback for (8, 0, 7) got condition
13:44:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:44:08 HBMASTER: Trying to run another job!
13:44:08 job_callback for (8, 0, 7) finished
13:44:08 start sampling a new configuration.
13:44:08 done sampling a new configuration.
13:44:08 HBMASTER: schedule new run for iteration 8
13:44:08 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
13:44:08 HBMASTER: submitting job (8, 0, 8) to dispatcher
13:44:08 DISPATCHER: trying to submit job (8, 0, 8)
13:44:08 DISPATCHER: trying to notify the job_runner thread.
13:44:08 HBMASTER: job (8, 0, 8) submitted to dispatcher
13:44:08 DISPATCHER: Trying to submit another job.
13:44:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:44:08 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:44:08 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:44:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:44:08 WORKER: start processing job (8, 0, 8)
13:44:08 WORKER: args: ()
13:44:08 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 71, 'last_n_outputs': 50, 'lr': 0.004948785711599662, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.015199227171460338}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:44:19 DISPATCHER: Starting worker discovery
13:44:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:44:19 DISPATCHER: Finished worker discovery
Exception in thread Thread-544:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:45:06 WORKER: done with job (8, 0, 8), trying to register it.
13:45:06 WORKER: registered result for job (8, 0, 8) with dispatcher
13:45:06 DISPATCHER: job (8, 0, 8) finished
13:45:06 DISPATCHER: register_result: lock acquired
13:45:06 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
13:45:06 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 71, 'last_n_outputs': 50, 'lr': 0.004948785711599662, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.015199227171460338}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0289934197619383, 'info': {'data04': 0.0289934197619383, 'config': "{'batch_size': 64, 'hidden_dim': 71, 'last_n_outputs': 50, 'lr': 0.004948785711599662, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.015199227171460338}"}}
exception: None

13:45:06 job_callback for (8, 0, 8) started
13:45:06 job_callback for (8, 0, 8) got condition
13:45:06 DISPATCHER: Trying to submit another job.
13:45:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:45:06 HBMASTER: Trying to run another job!
13:45:06 job_callback for (8, 0, 8) finished
13:45:06 start sampling a new configuration.
13:45:07 best_vector: [0, 0.8778175205449769, 0.5566442775834087, 0.34361061155056977, 0.10074033115733999, 0, 0.6250124053961019, 0.4965574740281681], 9.308622137639041e-05, 1319.3896369672323, 0.12281699582844716
13:45:07 done sampling a new configuration.
13:45:07 HBMASTER: schedule new run for iteration 8
13:45:07 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
13:45:07 HBMASTER: submitting job (8, 0, 9) to dispatcher
13:45:07 DISPATCHER: trying to submit job (8, 0, 9)
13:45:07 DISPATCHER: trying to notify the job_runner thread.
13:45:07 HBMASTER: job (8, 0, 9) submitted to dispatcher
13:45:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:45:07 DISPATCHER: Trying to submit another job.
13:45:07 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:45:07 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:45:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:45:07 WORKER: start processing job (8, 0, 9)
13:45:07 WORKER: args: ()
13:45:07 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 91, 'last_n_outputs': 28, 'lr': 0.004866550373486926, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.0442625232899003}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:45:19 DISPATCHER: Starting worker discovery
13:45:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:45:19 DISPATCHER: Finished worker discovery
Exception in thread Thread-545:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:46:05 WORKER: done with job (8, 0, 9), trying to register it.
13:46:05 WORKER: registered result for job (8, 0, 9) with dispatcher
13:46:05 DISPATCHER: job (8, 0, 9) finished
13:46:05 DISPATCHER: register_result: lock acquired
13:46:05 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
13:46:05 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 91, 'last_n_outputs': 28, 'lr': 0.004866550373486926, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.0442625232899003}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.04171085415667998, 'info': {'data04': 0.04171085415667998, 'config': "{'batch_size': 16, 'hidden_dim': 91, 'last_n_outputs': 28, 'lr': 0.004866550373486926, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.0442625232899003}"}}
exception: None

13:46:05 job_callback for (8, 0, 9) started
13:46:05 job_callback for (8, 0, 9) got condition
13:46:05 DISPATCHER: Trying to submit another job.
13:46:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:46:05 HBMASTER: Trying to run another job!
13:46:05 job_callback for (8, 0, 9) finished
13:46:05 start sampling a new configuration.
13:46:05 best_vector: [2, 0.8073845842367556, 0.8233685654521878, 0.13977276289077695, 0.10037626413480298, 0, 0.4132935112042361, 0.05809853871966253], 2.358246082662735e-05, 3347.5238413325005, 0.0789428498544248
13:46:05 done sampling a new configuration.
13:46:05 HBMASTER: schedule new run for iteration 8
13:46:05 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
13:46:05 HBMASTER: submitting job (8, 0, 10) to dispatcher
13:46:05 DISPATCHER: trying to submit job (8, 0, 10)
13:46:05 DISPATCHER: trying to notify the job_runner thread.
13:46:05 HBMASTER: job (8, 0, 10) submitted to dispatcher
13:46:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:46:05 DISPATCHER: Trying to submit another job.
13:46:05 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:46:05 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:46:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:46:05 WORKER: start processing job (8, 0, 10)
13:46:05 WORKER: args: ()
13:46:05 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 85, 'last_n_outputs': 42, 'lr': 0.0019034677619067394, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.01190112294132778}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:46:19 DISPATCHER: Starting worker discovery
13:46:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:46:19 DISPATCHER: Finished worker discovery
Exception in thread Thread-546:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:47:05 WORKER: done with job (8, 0, 10), trying to register it.
13:47:05 WORKER: registered result for job (8, 0, 10) with dispatcher
13:47:05 DISPATCHER: job (8, 0, 10) finished
13:47:05 DISPATCHER: register_result: lock acquired
13:47:05 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
13:47:05 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 85, 'last_n_outputs': 42, 'lr': 0.0019034677619067394, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.01190112294132778}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.14527165944774242, 'info': {'data04': 0.14527165944774242, 'config': "{'batch_size': 64, 'hidden_dim': 85, 'last_n_outputs': 42, 'lr': 0.0019034677619067394, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.01190112294132778}"}}
exception: None

13:47:05 job_callback for (8, 0, 10) started
13:47:05 DISPATCHER: Trying to submit another job.
13:47:05 job_callback for (8, 0, 10) got condition
13:47:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:47:05 HBMASTER: Trying to run another job!
13:47:05 job_callback for (8, 0, 10) finished
13:47:05 start sampling a new configuration.
13:47:05 best_vector: [0, 0.6515366461688301, 0.8624189950410791, 0.2601680504617418, 0.10049992319096339, 0, 0.8043345695194534, 0.44038527862313503], 6.108682256170255e-05, 1016.553262686485, 0.062098008782249116
13:47:05 done sampling a new configuration.
13:47:05 HBMASTER: schedule new run for iteration 8
13:47:05 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
13:47:05 HBMASTER: submitting job (8, 0, 11) to dispatcher
13:47:05 DISPATCHER: trying to submit job (8, 0, 11)
13:47:05 DISPATCHER: trying to notify the job_runner thread.
13:47:05 HBMASTER: job (8, 0, 11) submitted to dispatcher
13:47:05 DISPATCHER: Trying to submit another job.
13:47:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:47:05 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:47:05 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:47:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:47:05 WORKER: start processing job (8, 0, 11)
13:47:05 WORKER: args: ()
13:47:05 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 72, 'last_n_outputs': 44, 'lr': 0.003313874833673032, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.037407135872977615}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:47:19 DISPATCHER: Starting worker discovery
13:47:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:47:19 DISPATCHER: Finished worker discovery
Exception in thread Thread-547:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:48:03 WORKER: done with job (8, 0, 11), trying to register it.
13:48:03 WORKER: registered result for job (8, 0, 11) with dispatcher
13:48:03 DISPATCHER: job (8, 0, 11) finished
13:48:03 DISPATCHER: register_result: lock acquired
13:48:03 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
13:48:03 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 72, 'last_n_outputs': 44, 'lr': 0.003313874833673032, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.037407135872977615}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.04254651997328221, 'info': {'data04': 0.04254651997328221, 'config': "{'batch_size': 16, 'hidden_dim': 72, 'last_n_outputs': 44, 'lr': 0.003313874833673032, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.037407135872977615}"}}
exception: None

13:48:03 job_callback for (8, 0, 11) started
13:48:03 job_callback for (8, 0, 11) got condition
13:48:03 DISPATCHER: Trying to submit another job.
13:48:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:48:03 HBMASTER: Trying to run another job!
13:48:03 job_callback for (8, 0, 11) finished
13:48:03 start sampling a new configuration.
13:48:03 best_vector: [1, 0.7773910663137819, 0.7976285978063345, 0.15272919603898033, 0.09984630568164898, 0, 0.22054018048789248, 0.1505136961492848], 2.2324978486314263e-05, 3997.194010086377, 0.08923727028080261
13:48:03 done sampling a new configuration.
13:48:03 HBMASTER: schedule new run for iteration 8
13:48:03 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
13:48:03 HBMASTER: submitting job (8, 0, 12) to dispatcher
13:48:03 DISPATCHER: trying to submit job (8, 0, 12)
13:48:03 DISPATCHER: trying to notify the job_runner thread.
13:48:03 HBMASTER: job (8, 0, 12) submitted to dispatcher
13:48:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:48:03 DISPATCHER: Trying to submit another job.
13:48:03 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:48:03 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:48:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:48:03 WORKER: start processing job (8, 0, 12)
13:48:03 WORKER: args: ()
13:48:03 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 82, 'last_n_outputs': 40, 'lr': 0.002020497847344791, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.015697223195146603}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-548:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:48:19 DISPATCHER: Starting worker discovery
13:48:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:48:19 DISPATCHER: Finished worker discovery
13:49:01 WORKER: done with job (8, 0, 12), trying to register it.
13:49:01 WORKER: registered result for job (8, 0, 12) with dispatcher
13:49:01 DISPATCHER: job (8, 0, 12) finished
13:49:01 DISPATCHER: register_result: lock acquired
13:49:01 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
13:49:01 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 82, 'last_n_outputs': 40, 'lr': 0.002020497847344791, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.015697223195146603}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.09583383549631752, 'info': {'data04': 0.09583383549631752, 'config': "{'batch_size': 32, 'hidden_dim': 82, 'last_n_outputs': 40, 'lr': 0.002020497847344791, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.015697223195146603}"}}
exception: None

13:49:01 job_callback for (8, 0, 12) started
13:49:01 job_callback for (8, 0, 12) got condition
13:49:01 DISPATCHER: Trying to submit another job.
13:49:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:49:01 HBMASTER: Trying to run another job!
13:49:01 job_callback for (8, 0, 12) finished
13:49:01 start sampling a new configuration.
13:49:01 best_vector: [0, 0.8039009916255572, 0.9107044433479972, 0.08056645793819518, 0.10015905539375661, 0, 0.6264740970717553, 0.06744649629043573], 0.00011456069939675111, 956.1437931964031, 0.1095365016724425
13:49:01 done sampling a new configuration.
13:49:01 HBMASTER: schedule new run for iteration 8
13:49:01 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
13:49:01 HBMASTER: submitting job (8, 0, 13) to dispatcher
13:49:01 DISPATCHER: trying to submit job (8, 0, 13)
13:49:01 DISPATCHER: trying to notify the job_runner thread.
13:49:01 HBMASTER: job (8, 0, 13) submitted to dispatcher
13:49:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:49:01 DISPATCHER: Trying to submit another job.
13:49:01 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:49:01 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:49:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:49:01 WORKER: start processing job (8, 0, 13)
13:49:01 WORKER: args: ()
13:49:01 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 85, 'last_n_outputs': 46, 'lr': 0.0014492153181957582, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.012239112162005197}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-549:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:49:19 DISPATCHER: Starting worker discovery
13:49:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:49:19 DISPATCHER: Finished worker discovery
13:50:00 WORKER: done with job (8, 0, 13), trying to register it.
13:50:00 WORKER: registered result for job (8, 0, 13) with dispatcher
13:50:00 DISPATCHER: job (8, 0, 13) finished
13:50:00 DISPATCHER: register_result: lock acquired
13:50:00 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
13:50:00 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 85, 'last_n_outputs': 46, 'lr': 0.0014492153181957582, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.012239112162005197}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1554611360847396, 'info': {'data04': 0.1554611360847396, 'config': "{'batch_size': 16, 'hidden_dim': 85, 'last_n_outputs': 46, 'lr': 0.0014492153181957582, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.012239112162005197}"}}
exception: None

13:50:00 job_callback for (8, 0, 13) started
13:50:00 job_callback for (8, 0, 13) got condition
13:50:00 DISPATCHER: Trying to submit another job.
13:50:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:50:00 HBMASTER: Trying to run another job!
13:50:00 job_callback for (8, 0, 13) finished
13:50:00 start sampling a new configuration.
13:50:00 best_vector: [2, 0.8653234722979645, 0.6960060693099115, 0.15333527459308582, 0.09943474204682126, 0, 0.07787487769121898, 0.15208577799530404], 8.689708917505359e-05, 1112.9075646034194, 0.09670842788493504
13:50:00 done sampling a new configuration.
13:50:00 HBMASTER: schedule new run for iteration 8
13:50:00 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
13:50:00 HBMASTER: submitting job (8, 0, 14) to dispatcher
13:50:00 DISPATCHER: trying to submit job (8, 0, 14)
13:50:00 DISPATCHER: trying to notify the job_runner thread.
13:50:00 HBMASTER: job (8, 0, 14) submitted to dispatcher
13:50:00 DISPATCHER: Trying to submit another job.
13:50:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:50:00 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:50:00 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:50:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:50:00 WORKER: start processing job (8, 0, 14)
13:50:00 WORKER: args: ()
13:50:00 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 90, 'last_n_outputs': 35, 'lr': 0.002026145125936271, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.01577132419165673}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-550:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:50:19 DISPATCHER: Starting worker discovery
13:50:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:50:19 DISPATCHER: Finished worker discovery
13:50:57 WORKER: done with job (8, 0, 14), trying to register it.
13:50:57 WORKER: registered result for job (8, 0, 14) with dispatcher
13:50:57 DISPATCHER: job (8, 0, 14) finished
13:50:57 DISPATCHER: register_result: lock acquired
13:50:57 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
13:50:57 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 90, 'last_n_outputs': 35, 'lr': 0.002026145125936271, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.01577132419165673}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.09148159192360251, 'info': {'data04': 0.09148159192360251, 'config': "{'batch_size': 64, 'hidden_dim': 90, 'last_n_outputs': 35, 'lr': 0.002026145125936271, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.01577132419165673}"}}
exception: None

13:50:57 job_callback for (8, 0, 14) started
13:50:57 DISPATCHER: Trying to submit another job.
13:50:57 job_callback for (8, 0, 14) got condition
13:50:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:50:57 HBMASTER: Trying to run another job!
13:50:57 job_callback for (8, 0, 14) finished
13:50:57 start sampling a new configuration.
13:50:57 done sampling a new configuration.
13:50:57 HBMASTER: schedule new run for iteration 8
13:50:57 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
13:50:57 HBMASTER: submitting job (8, 0, 15) to dispatcher
13:50:57 DISPATCHER: trying to submit job (8, 0, 15)
13:50:57 DISPATCHER: trying to notify the job_runner thread.
13:50:57 HBMASTER: job (8, 0, 15) submitted to dispatcher
13:50:57 DISPATCHER: Trying to submit another job.
13:50:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:50:57 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:50:57 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:50:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:50:57 WORKER: start processing job (8, 0, 15)
13:50:57 WORKER: args: ()
13:50:57 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 68, 'last_n_outputs': 45, 'lr': 0.004107909789887677, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.05630060919165264}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-551:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:51:19 DISPATCHER: Starting worker discovery
13:51:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:51:19 DISPATCHER: Finished worker discovery
13:51:56 WORKER: done with job (8, 0, 15), trying to register it.
13:51:56 WORKER: registered result for job (8, 0, 15) with dispatcher
13:51:56 DISPATCHER: job (8, 0, 15) finished
13:51:56 DISPATCHER: register_result: lock acquired
13:51:56 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
13:51:56 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 68, 'last_n_outputs': 45, 'lr': 0.004107909789887677, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.05630060919165264}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.004319521580662426, 'info': {'data04': -0.004319521580662426, 'config': "{'batch_size': 32, 'hidden_dim': 68, 'last_n_outputs': 45, 'lr': 0.004107909789887677, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.05630060919165264}"}}
exception: None

13:51:56 job_callback for (8, 0, 15) started
13:51:56 job_callback for (8, 0, 15) got condition
13:51:56 DISPATCHER: Trying to submit another job.
13:51:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:51:56 HBMASTER: Trying to run another job!
13:51:56 job_callback for (8, 0, 15) finished
13:51:56 start sampling a new configuration.
13:51:56 best_vector: [0, 0.9213039631834208, 0.8236871323731876, 0.22754842401948688, 0.10067468898234296, 0, 0.16896367484656796, 0.027194483803420738], 0.00011437314113183648, 705.9447128335006, 0.08074111427217974
13:51:56 done sampling a new configuration.
13:51:56 HBMASTER: schedule new run for iteration 8
13:51:56 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
13:51:56 HBMASTER: submitting job (8, 0, 16) to dispatcher
13:51:56 DISPATCHER: trying to submit job (8, 0, 16)
13:51:56 DISPATCHER: trying to notify the job_runner thread.
13:51:56 HBMASTER: job (8, 0, 16) submitted to dispatcher
13:51:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:51:56 DISPATCHER: Trying to submit another job.
13:51:56 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:51:56 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:51:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:51:56 WORKER: start processing job (8, 0, 16)
13:51:56 WORKER: args: ()
13:51:56 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 94, 'last_n_outputs': 42, 'lr': 0.002851654117898239, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.010848778421703975}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-552:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:52:19 DISPATCHER: Starting worker discovery
13:52:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:52:19 DISPATCHER: Finished worker discovery
13:52:55 WORKER: done with job (8, 0, 16), trying to register it.
13:52:55 WORKER: registered result for job (8, 0, 16) with dispatcher
13:52:55 DISPATCHER: job (8, 0, 16) finished
13:52:55 DISPATCHER: register_result: lock acquired
13:52:55 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
13:52:55 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 94, 'last_n_outputs': 42, 'lr': 0.002851654117898239, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.010848778421703975}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.09526594722621431, 'info': {'data04': 0.09526594722621431, 'config': "{'batch_size': 16, 'hidden_dim': 94, 'last_n_outputs': 42, 'lr': 0.002851654117898239, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.010848778421703975}"}}
exception: None

13:52:55 job_callback for (8, 0, 16) started
13:52:55 DISPATCHER: Trying to submit another job.
13:52:55 job_callback for (8, 0, 16) got condition
13:52:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:52:55 HBMASTER: Trying to run another job!
13:52:55 job_callback for (8, 0, 16) finished
13:52:55 start sampling a new configuration.
13:52:55 best_vector: [0, 0.7880674394926579, 0.6666597355460037, 0.3684273260163578, 0.10027406003704051, 0, 0.7482298048880589, 0.7033756342728197], 7.388164197386707e-05, 994.2500585929286, 0.0734568268614591
13:52:55 done sampling a new configuration.
13:52:55 HBMASTER: schedule new run for iteration 8
13:52:55 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
13:52:55 HBMASTER: submitting job (8, 0, 17) to dispatcher
13:52:55 DISPATCHER: trying to submit job (8, 0, 17)
13:52:55 DISPATCHER: trying to notify the job_runner thread.
13:52:55 HBMASTER: job (8, 0, 17) submitted to dispatcher
13:52:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:52:55 DISPATCHER: Trying to submit another job.
13:52:55 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:52:55 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:52:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:52:55 WORKER: start processing job (8, 0, 17)
13:52:55 WORKER: args: ()
13:52:55 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 83, 'last_n_outputs': 34, 'lr': 0.005455752395603297, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.08224562370670713}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-553:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:53:19 DISPATCHER: Starting worker discovery
13:53:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:53:19 DISPATCHER: Finished worker discovery
13:53:53 WORKER: done with job (8, 0, 17), trying to register it.
13:53:53 WORKER: registered result for job (8, 0, 17) with dispatcher
13:53:53 DISPATCHER: job (8, 0, 17) finished
13:53:53 DISPATCHER: register_result: lock acquired
13:53:53 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
13:53:53 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 83, 'last_n_outputs': 34, 'lr': 0.005455752395603297, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.08224562370670713}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.015194059438195908, 'info': {'data04': 0.015194059438195908, 'config': "{'batch_size': 16, 'hidden_dim': 83, 'last_n_outputs': 34, 'lr': 0.005455752395603297, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.08224562370670713}"}}
exception: None

13:53:53 job_callback for (8, 0, 17) started
13:53:53 DISPATCHER: Trying to submit another job.
13:53:53 job_callback for (8, 0, 17) got condition
13:53:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:53:53 HBMASTER: Trying to run another job!
13:53:53 job_callback for (8, 0, 17) finished
13:53:53 start sampling a new configuration.
13:53:53 done sampling a new configuration.
13:53:53 HBMASTER: schedule new run for iteration 8
13:53:53 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
13:53:53 HBMASTER: submitting job (8, 0, 18) to dispatcher
13:53:53 DISPATCHER: trying to submit job (8, 0, 18)
13:53:53 DISPATCHER: trying to notify the job_runner thread.
13:53:53 HBMASTER: job (8, 0, 18) submitted to dispatcher
13:53:53 DISPATCHER: Trying to submit another job.
13:53:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:53:53 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:53:53 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:53:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:53:53 WORKER: start processing job (8, 0, 18)
13:53:53 WORKER: args: ()
13:53:53 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 65, 'last_n_outputs': 32, 'lr': 0.0094454970558667, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.02219309042669285}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-554:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:54:19 DISPATCHER: Starting worker discovery
13:54:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:54:19 DISPATCHER: Finished worker discovery
13:54:52 WORKER: done with job (8, 0, 18), trying to register it.
13:54:52 WORKER: registered result for job (8, 0, 18) with dispatcher
13:54:52 DISPATCHER: job (8, 0, 18) finished
13:54:52 DISPATCHER: register_result: lock acquired
13:54:52 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
13:54:52 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 65, 'last_n_outputs': 32, 'lr': 0.0094454970558667, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.02219309042669285}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.05547826112235323, 'info': {'data04': 0.05547826112235323, 'config': "{'batch_size': 32, 'hidden_dim': 65, 'last_n_outputs': 32, 'lr': 0.0094454970558667, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.02219309042669285}"}}
exception: None

13:54:52 job_callback for (8, 0, 18) started
13:54:52 DISPATCHER: Trying to submit another job.
13:54:52 job_callback for (8, 0, 18) got condition
13:54:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:54:52 HBMASTER: Trying to run another job!
13:54:52 job_callback for (8, 0, 18) finished
13:54:52 start sampling a new configuration.
13:54:52 best_vector: [2, 0.7044933466024428, 0.8355605289259677, 0.21141505698274607, 0.10019613119979781, 0, 0.23009633860099643, 0.24575361266773157], 2.330760469493306e-05, 3871.275194103149, 0.09023015188945645
13:54:52 done sampling a new configuration.
13:54:52 HBMASTER: schedule new run for iteration 8
13:54:52 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
13:54:52 HBMASTER: submitting job (8, 0, 19) to dispatcher
13:54:52 DISPATCHER: trying to submit job (8, 0, 19)
13:54:52 DISPATCHER: trying to notify the job_runner thread.
13:54:52 HBMASTER: job (8, 0, 19) submitted to dispatcher
13:54:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:54:52 DISPATCHER: Trying to submit another job.
13:54:52 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:54:52 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:54:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:54:52 WORKER: start processing job (8, 0, 19)
13:54:52 WORKER: args: ()
13:54:52 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 77, 'last_n_outputs': 42, 'lr': 0.0026474643087437016, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.020880111891852095}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-555:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:55:19 DISPATCHER: Starting worker discovery
13:55:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:55:19 DISPATCHER: Finished worker discovery
13:55:49 WORKER: done with job (8, 0, 19), trying to register it.
13:55:49 WORKER: registered result for job (8, 0, 19) with dispatcher
13:55:49 DISPATCHER: job (8, 0, 19) finished
13:55:49 DISPATCHER: register_result: lock acquired
13:55:49 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
13:55:49 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 77, 'last_n_outputs': 42, 'lr': 0.0026474643087437016, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.020880111891852095}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.12826995172482356, 'info': {'data04': 0.12826995172482356, 'config': "{'batch_size': 64, 'hidden_dim': 77, 'last_n_outputs': 42, 'lr': 0.0026474643087437016, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.020880111891852095}"}}
exception: None

13:55:49 job_callback for (8, 0, 19) started
13:55:49 DISPATCHER: Trying to submit another job.
13:55:49 job_callback for (8, 0, 19) got condition
13:55:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:55:49 HBMASTER: Trying to run another job!
13:55:49 job_callback for (8, 0, 19) finished
13:55:49 start sampling a new configuration.
13:55:49 done sampling a new configuration.
13:55:49 HBMASTER: schedule new run for iteration 8
13:55:49 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
13:55:49 HBMASTER: submitting job (8, 0, 20) to dispatcher
13:55:49 DISPATCHER: trying to submit job (8, 0, 20)
13:55:49 DISPATCHER: trying to notify the job_runner thread.
13:55:49 HBMASTER: job (8, 0, 20) submitted to dispatcher
13:55:49 DISPATCHER: Trying to submit another job.
13:55:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:55:49 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:55:49 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:55:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:55:49 WORKER: start processing job (8, 0, 20)
13:55:49 WORKER: args: ()
13:55:49 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 48, 'lr': 0.0010342246772974766, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.035776562911925325}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-556:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:56:19 DISPATCHER: Starting worker discovery
13:56:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:56:19 DISPATCHER: Finished worker discovery
13:56:48 WORKER: done with job (8, 0, 20), trying to register it.
13:56:48 WORKER: registered result for job (8, 0, 20) with dispatcher
13:56:48 DISPATCHER: job (8, 0, 20) finished
13:56:48 DISPATCHER: register_result: lock acquired
13:56:48 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
13:56:48 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 48, 'lr': 0.0010342246772974766, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.035776562911925325}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.008509925478946809, 'info': {'data04': -0.008509925478946809, 'config': "{'batch_size': 32, 'hidden_dim': 96, 'last_n_outputs': 48, 'lr': 0.0010342246772974766, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.035776562911925325}"}}
exception: None

13:56:48 job_callback for (8, 0, 20) started
13:56:48 DISPATCHER: Trying to submit another job.
13:56:48 job_callback for (8, 0, 20) got condition
13:56:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:56:48 HBMASTER: Trying to run another job!
13:56:48 job_callback for (8, 0, 20) finished
13:56:48 start sampling a new configuration.
13:56:48 done sampling a new configuration.
13:56:48 HBMASTER: schedule new run for iteration 8
13:56:48 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
13:56:48 HBMASTER: submitting job (8, 0, 21) to dispatcher
13:56:48 DISPATCHER: trying to submit job (8, 0, 21)
13:56:48 DISPATCHER: trying to notify the job_runner thread.
13:56:48 HBMASTER: job (8, 0, 21) submitted to dispatcher
13:56:48 DISPATCHER: Trying to submit another job.
13:56:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:56:48 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:56:48 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:56:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:56:48 WORKER: start processing job (8, 0, 21)
13:56:48 WORKER: args: ()
13:56:48 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 50, 'last_n_outputs': 24, 'lr': 0.005013147644370718, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.028461710688215038}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-557:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:57:19 DISPATCHER: Starting worker discovery
13:57:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:57:19 DISPATCHER: Finished worker discovery
13:57:46 WORKER: done with job (8, 0, 21), trying to register it.
13:57:46 WORKER: registered result for job (8, 0, 21) with dispatcher
13:57:46 DISPATCHER: job (8, 0, 21) finished
13:57:46 DISPATCHER: register_result: lock acquired
13:57:46 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
13:57:46 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 50, 'last_n_outputs': 24, 'lr': 0.005013147644370718, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.028461710688215038}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 50, 'last_n_outputs': 24, 'lr': 0.005013147644370718, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.028461710688215038}"}}
exception: None

13:57:46 job_callback for (8, 0, 21) started
13:57:46 DISPATCHER: Trying to submit another job.
13:57:46 job_callback for (8, 0, 21) got condition
13:57:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:57:46 HBMASTER: Trying to run another job!
13:57:46 job_callback for (8, 0, 21) finished
13:57:46 start sampling a new configuration.
13:57:46 done sampling a new configuration.
13:57:46 HBMASTER: schedule new run for iteration 8
13:57:46 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
13:57:46 HBMASTER: submitting job (8, 0, 22) to dispatcher
13:57:46 DISPATCHER: trying to submit job (8, 0, 22)
13:57:46 DISPATCHER: trying to notify the job_runner thread.
13:57:46 HBMASTER: job (8, 0, 22) submitted to dispatcher
13:57:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:57:46 DISPATCHER: Trying to submit another job.
13:57:46 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:57:46 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:57:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:57:46 WORKER: start processing job (8, 0, 22)
13:57:46 WORKER: args: ()
13:57:46 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 67, 'last_n_outputs': 20, 'lr': 0.06148583237393933, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.12120248108019721}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-558:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:58:19 DISPATCHER: Starting worker discovery
13:58:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:58:19 DISPATCHER: Finished worker discovery
13:58:43 WORKER: done with job (8, 0, 22), trying to register it.
13:58:43 WORKER: registered result for job (8, 0, 22) with dispatcher
13:58:43 DISPATCHER: job (8, 0, 22) finished
13:58:43 DISPATCHER: register_result: lock acquired
13:58:43 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
13:58:43 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 67, 'last_n_outputs': 20, 'lr': 0.06148583237393933, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.12120248108019721}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 67, 'last_n_outputs': 20, 'lr': 0.06148583237393933, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.12120248108019721}"}}
exception: None

13:58:43 job_callback for (8, 0, 22) started
13:58:43 DISPATCHER: Trying to submit another job.
13:58:43 job_callback for (8, 0, 22) got condition
13:58:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:58:43 HBMASTER: Trying to run another job!
13:58:43 job_callback for (8, 0, 22) finished
13:58:43 start sampling a new configuration.
13:58:44 best_vector: [3, 0.8729622040303764, 0.9163626106177868, 0.325679988068784, 0.09967649474848683, 0, 0.3335767791805969, 0.23013475626963542], 3.574241993863579e-05, 3483.587415581732, 0.12451184430066921
13:58:44 done sampling a new configuration.
13:58:44 HBMASTER: schedule new run for iteration 8
13:58:44 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
13:58:44 HBMASTER: submitting job (8, 0, 23) to dispatcher
13:58:44 DISPATCHER: trying to submit job (8, 0, 23)
13:58:44 DISPATCHER: trying to notify the job_runner thread.
13:58:44 HBMASTER: job (8, 0, 23) submitted to dispatcher
13:58:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:58:44 DISPATCHER: Trying to submit another job.
13:58:44 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:58:44 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:58:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:58:44 WORKER: start processing job (8, 0, 23)
13:58:44 WORKER: args: ()
13:58:44 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 90, 'last_n_outputs': 46, 'lr': 0.004480845566893129, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.019925637310145433}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-559:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:59:19 DISPATCHER: Starting worker discovery
13:59:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:59:19 DISPATCHER: Finished worker discovery
13:59:42 WORKER: done with job (8, 0, 23), trying to register it.
13:59:42 WORKER: registered result for job (8, 0, 23) with dispatcher
13:59:42 DISPATCHER: job (8, 0, 23) finished
13:59:42 DISPATCHER: register_result: lock acquired
13:59:42 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
13:59:42 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 90, 'last_n_outputs': 46, 'lr': 0.004480845566893129, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.019925637310145433}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1430188261107088, 'info': {'data04': 0.1430188261107088, 'config': "{'batch_size': 128, 'hidden_dim': 90, 'last_n_outputs': 46, 'lr': 0.004480845566893129, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.019925637310145433}"}}
exception: None

13:59:42 job_callback for (8, 0, 23) started
13:59:42 job_callback for (8, 0, 23) got condition
13:59:42 DISPATCHER: Trying to submit another job.
13:59:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:59:42 HBMASTER: Trying to run another job!
13:59:42 job_callback for (8, 0, 23) finished
13:59:42 start sampling a new configuration.
13:59:42 done sampling a new configuration.
13:59:42 HBMASTER: schedule new run for iteration 8
13:59:42 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
13:59:42 HBMASTER: submitting job (8, 0, 24) to dispatcher
13:59:42 DISPATCHER: trying to submit job (8, 0, 24)
13:59:42 DISPATCHER: trying to notify the job_runner thread.
13:59:42 HBMASTER: job (8, 0, 24) submitted to dispatcher
13:59:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:59:42 DISPATCHER: Trying to submit another job.
13:59:42 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:59:42 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
13:59:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:59:42 WORKER: start processing job (8, 0, 24)
13:59:42 WORKER: args: ()
13:59:42 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 66, 'last_n_outputs': 32, 'lr': 0.06861676943951811, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.025272567537686634}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-560:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:00:19 DISPATCHER: Starting worker discovery
14:00:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:00:19 DISPATCHER: Finished worker discovery
14:00:40 WORKER: done with job (8, 0, 24), trying to register it.
14:00:40 WORKER: registered result for job (8, 0, 24) with dispatcher
14:00:40 DISPATCHER: job (8, 0, 24) finished
14:00:40 DISPATCHER: register_result: lock acquired
14:00:40 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
14:00:40 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 66, 'last_n_outputs': 32, 'lr': 0.06861676943951811, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.025272567537686634}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.0021941557154933275, 'info': {'data04': -0.0021941557154933275, 'config': "{'batch_size': 32, 'hidden_dim': 66, 'last_n_outputs': 32, 'lr': 0.06861676943951811, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.025272567537686634}"}}
exception: None

14:00:40 job_callback for (8, 0, 24) started
14:00:40 DISPATCHER: Trying to submit another job.
14:00:40 job_callback for (8, 0, 24) got condition
14:00:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:00:40 HBMASTER: Trying to run another job!
14:00:40 job_callback for (8, 0, 24) finished
14:00:40 start sampling a new configuration.
14:00:40 done sampling a new configuration.
14:00:40 HBMASTER: schedule new run for iteration 8
14:00:40 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
14:00:40 HBMASTER: submitting job (8, 0, 25) to dispatcher
14:00:40 DISPATCHER: trying to submit job (8, 0, 25)
14:00:40 DISPATCHER: trying to notify the job_runner thread.
14:00:40 HBMASTER: job (8, 0, 25) submitted to dispatcher
14:00:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:00:40 DISPATCHER: Trying to submit another job.
14:00:40 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:00:40 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:00:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:00:40 WORKER: start processing job (8, 0, 25)
14:00:40 WORKER: args: ()
14:00:40 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 46, 'last_n_outputs': 46, 'lr': 0.0380041092899755, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.020515425290436512}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-561:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:01:19 DISPATCHER: Starting worker discovery
14:01:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:01:19 DISPATCHER: Finished worker discovery
14:01:39 WORKER: done with job (8, 0, 25), trying to register it.
14:01:39 WORKER: registered result for job (8, 0, 25) with dispatcher
14:01:39 DISPATCHER: job (8, 0, 25) finished
14:01:39 DISPATCHER: register_result: lock acquired
14:01:39 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
14:01:39 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 46, 'last_n_outputs': 46, 'lr': 0.0380041092899755, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.020515425290436512}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.03220893730704958, 'info': {'data04': 0.03220893730704958, 'config': "{'batch_size': 32, 'hidden_dim': 46, 'last_n_outputs': 46, 'lr': 0.0380041092899755, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.020515425290436512}"}}
exception: None

14:01:39 job_callback for (8, 0, 25) started
14:01:39 job_callback for (8, 0, 25) got condition
14:01:39 DISPATCHER: Trying to submit another job.
14:01:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:01:39 HBMASTER: Trying to run another job!
14:01:39 job_callback for (8, 0, 25) finished
14:01:39 start sampling a new configuration.
14:01:39 best_vector: [0, 0.6480451340771856, 0.9932982217865641, 0.20705552403145694, 0.10012706539820945, 0, 0.7742620234840153, 0.34038876510851823], 2.3771658744930237e-05, 2624.7657565388076, 0.062395035849819175
14:01:39 done sampling a new configuration.
14:01:39 HBMASTER: schedule new run for iteration 8
14:01:39 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
14:01:39 HBMASTER: submitting job (8, 0, 26) to dispatcher
14:01:39 DISPATCHER: trying to submit job (8, 0, 26)
14:01:39 DISPATCHER: trying to notify the job_runner thread.
14:01:39 HBMASTER: job (8, 0, 26) submitted to dispatcher
14:01:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:01:39 DISPATCHER: Trying to submit another job.
14:01:39 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:01:39 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:01:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:01:39 WORKER: start processing job (8, 0, 26)
14:01:39 WORKER: args: ()
14:01:39 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 72, 'last_n_outputs': 50, 'lr': 0.002594842772405299, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.027724006601891518}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-562:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:02:19 DISPATCHER: Starting worker discovery
14:02:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:02:19 DISPATCHER: Finished worker discovery
14:02:37 WORKER: done with job (8, 0, 26), trying to register it.
14:02:37 WORKER: registered result for job (8, 0, 26) with dispatcher
14:02:37 DISPATCHER: job (8, 0, 26) finished
14:02:37 DISPATCHER: register_result: lock acquired
14:02:37 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
14:02:37 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 72, 'last_n_outputs': 50, 'lr': 0.002594842772405299, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.027724006601891518}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.08930025152306985, 'info': {'data04': 0.08930025152306985, 'config': "{'batch_size': 16, 'hidden_dim': 72, 'last_n_outputs': 50, 'lr': 0.002594842772405299, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.027724006601891518}"}}
exception: None

14:02:37 job_callback for (8, 0, 26) started
14:02:37 DISPATCHER: Trying to submit another job.
14:02:37 job_callback for (8, 0, 26) got condition
14:02:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:02:37 HBMASTER: Trying to run another job!
14:02:37 job_callback for (8, 0, 26) finished
14:02:37 ITERATION: Advancing config (8, 0, 0) to next budget 133.333333
14:02:37 ITERATION: Advancing config (8, 0, 1) to next budget 133.333333
14:02:37 ITERATION: Advancing config (8, 0, 10) to next budget 133.333333
14:02:37 ITERATION: Advancing config (8, 0, 12) to next budget 133.333333
14:02:37 ITERATION: Advancing config (8, 0, 13) to next budget 133.333333
14:02:37 ITERATION: Advancing config (8, 0, 14) to next budget 133.333333
14:02:37 ITERATION: Advancing config (8, 0, 16) to next budget 133.333333
14:02:37 ITERATION: Advancing config (8, 0, 19) to next budget 133.333333
14:02:37 ITERATION: Advancing config (8, 0, 23) to next budget 133.333333
14:02:37 HBMASTER: schedule new run for iteration 8
14:02:37 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
14:02:37 HBMASTER: submitting job (8, 0, 0) to dispatcher
14:02:37 DISPATCHER: trying to submit job (8, 0, 0)
14:02:37 DISPATCHER: trying to notify the job_runner thread.
14:02:37 HBMASTER: job (8, 0, 0) submitted to dispatcher
14:02:37 DISPATCHER: Trying to submit another job.
14:02:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:02:37 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:02:37 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:02:37 WORKER: start processing job (8, 0, 0)
14:02:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:02:37 WORKER: args: ()
14:02:37 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 81, 'last_n_outputs': 48, 'lr': 0.0016631316033923886, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.03174920722953461}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-563:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:03:19 DISPATCHER: Starting worker discovery
14:03:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:03:19 DISPATCHER: Finished worker discovery
14:04:19 DISPATCHER: Starting worker discovery
14:04:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:04:19 DISPATCHER: Finished worker discovery
14:05:04 WORKER: done with job (8, 0, 0), trying to register it.
14:05:04 WORKER: registered result for job (8, 0, 0) with dispatcher
14:05:04 DISPATCHER: job (8, 0, 0) finished
14:05:04 DISPATCHER: register_result: lock acquired
14:05:04 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
14:05:04 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 81, 'last_n_outputs': 48, 'lr': 0.0016631316033923886, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.03174920722953461}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.11459984857477899, 'info': {'data04': 0.11459984857477899, 'config': "{'batch_size': 32, 'hidden_dim': 81, 'last_n_outputs': 48, 'lr': 0.0016631316033923886, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.03174920722953461}"}}
exception: None

14:05:04 job_callback for (8, 0, 0) started
14:05:04 DISPATCHER: Trying to submit another job.
14:05:04 job_callback for (8, 0, 0) got condition
14:05:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:05:04 HBMASTER: Trying to run another job!
14:05:04 job_callback for (8, 0, 0) finished
14:05:04 HBMASTER: schedule new run for iteration 8
14:05:04 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
14:05:04 HBMASTER: submitting job (8, 0, 1) to dispatcher
14:05:04 DISPATCHER: trying to submit job (8, 0, 1)
14:05:04 DISPATCHER: trying to notify the job_runner thread.
14:05:04 HBMASTER: job (8, 0, 1) submitted to dispatcher
14:05:04 DISPATCHER: Trying to submit another job.
14:05:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:05:04 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:05:04 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:05:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:05:04 WORKER: start processing job (8, 0, 1)
14:05:04 WORKER: args: ()
14:05:04 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 80, 'last_n_outputs': 48, 'lr': 0.0039714201705753314, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.036968917258990396}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:05:19 DISPATCHER: Starting worker discovery
14:05:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:05:19 DISPATCHER: Finished worker discovery
Exception in thread Thread-564:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:06:19 DISPATCHER: Starting worker discovery
14:06:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:06:19 DISPATCHER: Finished worker discovery
14:07:19 DISPATCHER: Starting worker discovery
14:07:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:07:19 DISPATCHER: Finished worker discovery
14:07:32 WORKER: done with job (8, 0, 1), trying to register it.
14:07:32 WORKER: registered result for job (8, 0, 1) with dispatcher
14:07:32 DISPATCHER: job (8, 0, 1) finished
14:07:32 DISPATCHER: register_result: lock acquired
14:07:32 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
14:07:32 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 80, 'last_n_outputs': 48, 'lr': 0.0039714201705753314, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.036968917258990396}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.12415708553401253, 'info': {'data04': 0.12415708553401253, 'config': "{'batch_size': 64, 'hidden_dim': 80, 'last_n_outputs': 48, 'lr': 0.0039714201705753314, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.036968917258990396}"}}
exception: None

14:07:32 job_callback for (8, 0, 1) started
14:07:32 job_callback for (8, 0, 1) got condition
14:07:32 DISPATCHER: Trying to submit another job.
14:07:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:07:32 HBMASTER: Trying to run another job!
14:07:32 job_callback for (8, 0, 1) finished
14:07:32 HBMASTER: schedule new run for iteration 8
14:07:32 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
14:07:32 HBMASTER: submitting job (8, 0, 10) to dispatcher
14:07:32 DISPATCHER: trying to submit job (8, 0, 10)
14:07:32 DISPATCHER: trying to notify the job_runner thread.
14:07:32 HBMASTER: job (8, 0, 10) submitted to dispatcher
14:07:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:07:32 DISPATCHER: Trying to submit another job.
14:07:32 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:07:32 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:07:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:07:32 WORKER: start processing job (8, 0, 10)
14:07:32 WORKER: args: ()
14:07:32 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 85, 'last_n_outputs': 42, 'lr': 0.0019034677619067394, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.01190112294132778}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-565:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:08:19 DISPATCHER: Starting worker discovery
14:08:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:08:19 DISPATCHER: Finished worker discovery
14:09:19 DISPATCHER: Starting worker discovery
14:09:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:09:19 DISPATCHER: Finished worker discovery
14:09:58 WORKER: done with job (8, 0, 10), trying to register it.
14:09:58 WORKER: registered result for job (8, 0, 10) with dispatcher
14:09:58 DISPATCHER: job (8, 0, 10) finished
14:09:58 DISPATCHER: register_result: lock acquired
14:09:58 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
14:09:58 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 85, 'last_n_outputs': 42, 'lr': 0.0019034677619067394, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.01190112294132778}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.14304655698072075, 'info': {'data04': 0.14304655698072075, 'config': "{'batch_size': 64, 'hidden_dim': 85, 'last_n_outputs': 42, 'lr': 0.0019034677619067394, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.01190112294132778}"}}
exception: None

14:09:58 job_callback for (8, 0, 10) started
14:09:58 DISPATCHER: Trying to submit another job.
14:09:58 job_callback for (8, 0, 10) got condition
14:09:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:09:58 HBMASTER: Trying to run another job!
14:09:58 job_callback for (8, 0, 10) finished
14:09:58 HBMASTER: schedule new run for iteration 8
14:09:58 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
14:09:58 HBMASTER: submitting job (8, 0, 12) to dispatcher
14:09:58 DISPATCHER: trying to submit job (8, 0, 12)
14:09:58 DISPATCHER: trying to notify the job_runner thread.
14:09:58 HBMASTER: job (8, 0, 12) submitted to dispatcher
14:09:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:09:58 DISPATCHER: Trying to submit another job.
14:09:58 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:09:58 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:09:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:09:58 WORKER: start processing job (8, 0, 12)
14:09:58 WORKER: args: ()
14:09:58 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 82, 'last_n_outputs': 40, 'lr': 0.002020497847344791, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.015697223195146603}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-566:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:10:19 DISPATCHER: Starting worker discovery
14:10:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:10:19 DISPATCHER: Finished worker discovery
14:11:19 DISPATCHER: Starting worker discovery
14:11:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:11:19 DISPATCHER: Finished worker discovery
14:12:19 DISPATCHER: Starting worker discovery
14:12:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:12:19 DISPATCHER: Finished worker discovery
14:12:26 WORKER: done with job (8, 0, 12), trying to register it.
14:12:26 WORKER: registered result for job (8, 0, 12) with dispatcher
14:12:26 DISPATCHER: job (8, 0, 12) finished
14:12:26 DISPATCHER: register_result: lock acquired
14:12:26 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
14:12:26 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 82, 'last_n_outputs': 40, 'lr': 0.002020497847344791, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.015697223195146603}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.08235667430130375, 'info': {'data04': 0.08235667430130375, 'config': "{'batch_size': 32, 'hidden_dim': 82, 'last_n_outputs': 40, 'lr': 0.002020497847344791, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.015697223195146603}"}}
exception: None

14:12:26 job_callback for (8, 0, 12) started
14:12:26 job_callback for (8, 0, 12) got condition
14:12:26 DISPATCHER: Trying to submit another job.
14:12:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:12:26 HBMASTER: Trying to run another job!
14:12:26 job_callback for (8, 0, 12) finished
14:12:26 HBMASTER: schedule new run for iteration 8
14:12:26 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
14:12:26 HBMASTER: submitting job (8, 0, 13) to dispatcher
14:12:26 DISPATCHER: trying to submit job (8, 0, 13)
14:12:26 DISPATCHER: trying to notify the job_runner thread.
14:12:26 HBMASTER: job (8, 0, 13) submitted to dispatcher
14:12:26 DISPATCHER: Trying to submit another job.
14:12:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:12:26 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:12:26 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:12:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:12:26 WORKER: start processing job (8, 0, 13)
14:12:26 WORKER: args: ()
14:12:26 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 85, 'last_n_outputs': 46, 'lr': 0.0014492153181957582, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.012239112162005197}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-567:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:13:19 DISPATCHER: Starting worker discovery
14:13:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:13:19 DISPATCHER: Finished worker discovery
14:14:19 DISPATCHER: Starting worker discovery
14:14:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:14:19 DISPATCHER: Finished worker discovery
14:14:53 WORKER: done with job (8, 0, 13), trying to register it.
14:14:53 WORKER: registered result for job (8, 0, 13) with dispatcher
14:14:53 DISPATCHER: job (8, 0, 13) finished
14:14:53 DISPATCHER: register_result: lock acquired
14:14:53 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
14:14:53 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 85, 'last_n_outputs': 46, 'lr': 0.0014492153181957582, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.012239112162005197}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.12476418536602656, 'info': {'data04': 0.12476418536602656, 'config': "{'batch_size': 16, 'hidden_dim': 85, 'last_n_outputs': 46, 'lr': 0.0014492153181957582, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.012239112162005197}"}}
exception: None

14:14:53 job_callback for (8, 0, 13) started
14:14:53 job_callback for (8, 0, 13) got condition
14:14:53 DISPATCHER: Trying to submit another job.
14:14:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:14:53 HBMASTER: Trying to run another job!
14:14:53 job_callback for (8, 0, 13) finished
14:14:53 HBMASTER: schedule new run for iteration 8
14:14:53 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
14:14:53 HBMASTER: submitting job (8, 0, 14) to dispatcher
14:14:53 DISPATCHER: trying to submit job (8, 0, 14)
14:14:53 DISPATCHER: trying to notify the job_runner thread.
14:14:53 HBMASTER: job (8, 0, 14) submitted to dispatcher
14:14:53 DISPATCHER: Trying to submit another job.
14:14:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:14:53 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:14:53 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:14:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:14:53 WORKER: start processing job (8, 0, 14)
14:14:53 WORKER: args: ()
14:14:53 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 90, 'last_n_outputs': 35, 'lr': 0.002026145125936271, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.01577132419165673}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-568:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:15:19 DISPATCHER: Starting worker discovery
14:15:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:15:19 DISPATCHER: Finished worker discovery
14:16:19 DISPATCHER: Starting worker discovery
14:16:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:16:19 DISPATCHER: Finished worker discovery
14:17:19 DISPATCHER: Starting worker discovery
14:17:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:17:19 DISPATCHER: Finished worker discovery
14:17:21 WORKER: done with job (8, 0, 14), trying to register it.
14:17:21 WORKER: registered result for job (8, 0, 14) with dispatcher
14:17:21 DISPATCHER: job (8, 0, 14) finished
14:17:21 DISPATCHER: register_result: lock acquired
14:17:21 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
14:17:21 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 90, 'last_n_outputs': 35, 'lr': 0.002026145125936271, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.01577132419165673}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1106972325595224, 'info': {'data04': 0.1106972325595224, 'config': "{'batch_size': 64, 'hidden_dim': 90, 'last_n_outputs': 35, 'lr': 0.002026145125936271, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.01577132419165673}"}}
exception: None

14:17:21 job_callback for (8, 0, 14) started
14:17:21 job_callback for (8, 0, 14) got condition
14:17:21 DISPATCHER: Trying to submit another job.
14:17:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:17:21 HBMASTER: Trying to run another job!
14:17:21 job_callback for (8, 0, 14) finished
14:17:21 HBMASTER: schedule new run for iteration 8
14:17:21 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
14:17:21 HBMASTER: submitting job (8, 0, 16) to dispatcher
14:17:21 DISPATCHER: trying to submit job (8, 0, 16)
14:17:21 DISPATCHER: trying to notify the job_runner thread.
14:17:21 HBMASTER: job (8, 0, 16) submitted to dispatcher
14:17:21 DISPATCHER: Trying to submit another job.
14:17:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:17:21 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:17:21 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:17:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:17:21 WORKER: start processing job (8, 0, 16)
14:17:21 WORKER: args: ()
14:17:21 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 94, 'last_n_outputs': 42, 'lr': 0.002851654117898239, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.010848778421703975}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-569:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:18:19 DISPATCHER: Starting worker discovery
14:18:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:18:19 DISPATCHER: Finished worker discovery
14:19:19 DISPATCHER: Starting worker discovery
14:19:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:19:19 DISPATCHER: Finished worker discovery
14:19:48 WORKER: done with job (8, 0, 16), trying to register it.
14:19:48 WORKER: registered result for job (8, 0, 16) with dispatcher
14:19:48 DISPATCHER: job (8, 0, 16) finished
14:19:48 DISPATCHER: register_result: lock acquired
14:19:48 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
14:19:48 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 94, 'last_n_outputs': 42, 'lr': 0.002851654117898239, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.010848778421703975}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.07055557205908407, 'info': {'data04': 0.07055557205908407, 'config': "{'batch_size': 16, 'hidden_dim': 94, 'last_n_outputs': 42, 'lr': 0.002851654117898239, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.010848778421703975}"}}
exception: None

14:19:48 job_callback for (8, 0, 16) started
14:19:48 job_callback for (8, 0, 16) got condition
14:19:48 DISPATCHER: Trying to submit another job.
14:19:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:19:48 HBMASTER: Trying to run another job!
14:19:48 job_callback for (8, 0, 16) finished
14:19:48 HBMASTER: schedule new run for iteration 8
14:19:48 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
14:19:48 HBMASTER: submitting job (8, 0, 19) to dispatcher
14:19:48 DISPATCHER: trying to submit job (8, 0, 19)
14:19:48 DISPATCHER: trying to notify the job_runner thread.
14:19:48 HBMASTER: job (8, 0, 19) submitted to dispatcher
14:19:48 DISPATCHER: Trying to submit another job.
14:19:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:19:48 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:19:48 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:19:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:19:48 WORKER: start processing job (8, 0, 19)
14:19:48 WORKER: args: ()
14:19:48 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 77, 'last_n_outputs': 42, 'lr': 0.0026474643087437016, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.020880111891852095}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-570:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:20:19 DISPATCHER: Starting worker discovery
14:20:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:20:19 DISPATCHER: Finished worker discovery
14:21:19 DISPATCHER: Starting worker discovery
14:21:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:21:19 DISPATCHER: Finished worker discovery
14:22:15 WORKER: done with job (8, 0, 19), trying to register it.
14:22:15 WORKER: registered result for job (8, 0, 19) with dispatcher
14:22:15 DISPATCHER: job (8, 0, 19) finished
14:22:15 DISPATCHER: register_result: lock acquired
14:22:15 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
14:22:15 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 77, 'last_n_outputs': 42, 'lr': 0.0026474643087437016, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.020880111891852095}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.12902414245879013, 'info': {'data04': 0.12902414245879013, 'config': "{'batch_size': 64, 'hidden_dim': 77, 'last_n_outputs': 42, 'lr': 0.0026474643087437016, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.020880111891852095}"}}
exception: None

14:22:15 job_callback for (8, 0, 19) started
14:22:15 DISPATCHER: Trying to submit another job.
14:22:15 job_callback for (8, 0, 19) got condition
14:22:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:22:15 HBMASTER: Trying to run another job!
14:22:15 job_callback for (8, 0, 19) finished
14:22:15 HBMASTER: schedule new run for iteration 8
14:22:15 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
14:22:15 HBMASTER: submitting job (8, 0, 23) to dispatcher
14:22:15 DISPATCHER: trying to submit job (8, 0, 23)
14:22:15 DISPATCHER: trying to notify the job_runner thread.
14:22:15 HBMASTER: job (8, 0, 23) submitted to dispatcher
14:22:15 DISPATCHER: Trying to submit another job.
14:22:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:22:15 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:22:15 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:22:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:22:15 WORKER: start processing job (8, 0, 23)
14:22:15 WORKER: args: ()
14:22:15 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 90, 'last_n_outputs': 46, 'lr': 0.004480845566893129, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.019925637310145433}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:22:19 DISPATCHER: Starting worker discovery
14:22:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:22:19 DISPATCHER: Finished worker discovery
Exception in thread Thread-571:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:23:19 DISPATCHER: Starting worker discovery
14:23:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:23:19 DISPATCHER: Finished worker discovery
14:24:19 DISPATCHER: Starting worker discovery
14:24:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:24:19 DISPATCHER: Finished worker discovery
14:24:42 WORKER: done with job (8, 0, 23), trying to register it.
14:24:42 WORKER: registered result for job (8, 0, 23) with dispatcher
14:24:42 DISPATCHER: job (8, 0, 23) finished
14:24:42 DISPATCHER: register_result: lock acquired
14:24:42 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
14:24:42 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 90, 'last_n_outputs': 46, 'lr': 0.004480845566893129, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.019925637310145433}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.15847202590461432, 'info': {'data04': 0.15847202590461432, 'config': "{'batch_size': 128, 'hidden_dim': 90, 'last_n_outputs': 46, 'lr': 0.004480845566893129, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.019925637310145433}"}}
exception: None

14:24:42 job_callback for (8, 0, 23) started
14:24:42 DISPATCHER: Trying to submit another job.
14:24:42 job_callback for (8, 0, 23) got condition
14:24:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:24:42 HBMASTER: Trying to run another job!
14:24:42 job_callback for (8, 0, 23) finished
14:24:42 ITERATION: Advancing config (8, 0, 10) to next budget 400.000000
14:24:42 ITERATION: Advancing config (8, 0, 19) to next budget 400.000000
14:24:42 ITERATION: Advancing config (8, 0, 23) to next budget 400.000000
14:24:42 HBMASTER: schedule new run for iteration 8
14:24:42 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
14:24:42 HBMASTER: submitting job (8, 0, 10) to dispatcher
14:24:42 DISPATCHER: trying to submit job (8, 0, 10)
14:24:42 DISPATCHER: trying to notify the job_runner thread.
14:24:42 HBMASTER: job (8, 0, 10) submitted to dispatcher
14:24:42 DISPATCHER: Trying to submit another job.
14:24:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:24:42 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:24:42 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:24:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:24:42 WORKER: start processing job (8, 0, 10)
14:24:42 WORKER: args: ()
14:24:42 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 85, 'last_n_outputs': 42, 'lr': 0.0019034677619067394, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.01190112294132778}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-572:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:25:19 DISPATCHER: Starting worker discovery
14:25:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:25:19 DISPATCHER: Finished worker discovery
14:26:19 DISPATCHER: Starting worker discovery
14:26:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:26:19 DISPATCHER: Finished worker discovery
14:27:19 DISPATCHER: Starting worker discovery
14:27:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:27:19 DISPATCHER: Finished worker discovery
14:28:19 DISPATCHER: Starting worker discovery
14:28:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:28:19 DISPATCHER: Finished worker discovery
14:29:19 DISPATCHER: Starting worker discovery
14:29:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:29:19 DISPATCHER: Finished worker discovery
14:30:19 DISPATCHER: Starting worker discovery
14:30:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:30:19 DISPATCHER: Finished worker discovery
14:31:19 DISPATCHER: Starting worker discovery
14:31:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:31:19 DISPATCHER: Finished worker discovery
14:31:37 WORKER: done with job (8, 0, 10), trying to register it.
14:31:37 WORKER: registered result for job (8, 0, 10) with dispatcher
14:31:37 DISPATCHER: job (8, 0, 10) finished
14:31:37 DISPATCHER: register_result: lock acquired
14:31:37 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
14:31:37 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 85, 'last_n_outputs': 42, 'lr': 0.0019034677619067394, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.01190112294132778}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.16268379579324896, 'info': {'data04': 0.16268379579324896, 'config': "{'batch_size': 64, 'hidden_dim': 85, 'last_n_outputs': 42, 'lr': 0.0019034677619067394, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.01190112294132778}"}}
exception: None

14:31:37 job_callback for (8, 0, 10) started
14:31:37 DISPATCHER: Trying to submit another job.
14:31:37 job_callback for (8, 0, 10) got condition
14:31:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:31:37 done building a new model for budget 400.000000 based on 9/21 split
Best loss for this budget:-0.183181





14:31:37 HBMASTER: Trying to run another job!
14:31:37 job_callback for (8, 0, 10) finished
14:31:37 HBMASTER: schedule new run for iteration 8
14:31:37 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
14:31:37 HBMASTER: submitting job (8, 0, 19) to dispatcher
14:31:37 DISPATCHER: trying to submit job (8, 0, 19)
14:31:37 DISPATCHER: trying to notify the job_runner thread.
14:31:37 HBMASTER: job (8, 0, 19) submitted to dispatcher
14:31:37 DISPATCHER: Trying to submit another job.
14:31:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:31:37 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:31:37 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:31:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:31:37 WORKER: start processing job (8, 0, 19)
14:31:37 WORKER: args: ()
14:31:37 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 77, 'last_n_outputs': 42, 'lr': 0.0026474643087437016, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.020880111891852095}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-573:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:32:19 DISPATCHER: Starting worker discovery
14:32:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:32:19 DISPATCHER: Finished worker discovery
14:33:19 DISPATCHER: Starting worker discovery
14:33:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:33:19 DISPATCHER: Finished worker discovery
14:34:19 DISPATCHER: Starting worker discovery
14:34:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:34:19 DISPATCHER: Finished worker discovery
14:35:19 DISPATCHER: Starting worker discovery
14:35:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:35:19 DISPATCHER: Finished worker discovery
14:36:19 DISPATCHER: Starting worker discovery
14:36:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:36:19 DISPATCHER: Finished worker discovery
14:37:19 DISPATCHER: Starting worker discovery
14:37:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:37:19 DISPATCHER: Finished worker discovery
14:38:19 DISPATCHER: Starting worker discovery
14:38:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:38:19 DISPATCHER: Finished worker discovery
14:38:31 WORKER: done with job (8, 0, 19), trying to register it.
14:38:31 WORKER: registered result for job (8, 0, 19) with dispatcher
14:38:31 DISPATCHER: job (8, 0, 19) finished
14:38:31 DISPATCHER: register_result: lock acquired
14:38:31 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
14:38:31 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 77, 'last_n_outputs': 42, 'lr': 0.0026474643087437016, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.020880111891852095}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.1275499648387687, 'info': {'data04': 0.1275499648387687, 'config': "{'batch_size': 64, 'hidden_dim': 77, 'last_n_outputs': 42, 'lr': 0.0026474643087437016, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.020880111891852095}"}}
exception: None

14:38:31 job_callback for (8, 0, 19) started
14:38:31 job_callback for (8, 0, 19) got condition
14:38:31 DISPATCHER: Trying to submit another job.
14:38:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:38:31 done building a new model for budget 400.000000 based on 9/22 split
Best loss for this budget:-0.183181





14:38:31 HBMASTER: Trying to run another job!
14:38:31 job_callback for (8, 0, 19) finished
14:38:31 HBMASTER: schedule new run for iteration 8
14:38:31 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
14:38:31 HBMASTER: submitting job (8, 0, 23) to dispatcher
14:38:31 DISPATCHER: trying to submit job (8, 0, 23)
14:38:31 DISPATCHER: trying to notify the job_runner thread.
14:38:31 HBMASTER: job (8, 0, 23) submitted to dispatcher
14:38:31 DISPATCHER: Trying to submit another job.
14:38:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:38:31 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:38:31 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:38:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:38:31 WORKER: start processing job (8, 0, 23)
14:38:31 WORKER: args: ()
14:38:31 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 90, 'last_n_outputs': 46, 'lr': 0.004480845566893129, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.019925637310145433}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-574:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:39:19 DISPATCHER: Starting worker discovery
14:39:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:39:19 DISPATCHER: Finished worker discovery
14:40:19 DISPATCHER: Starting worker discovery
14:40:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:40:19 DISPATCHER: Finished worker discovery
14:41:19 DISPATCHER: Starting worker discovery
14:41:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:41:19 DISPATCHER: Finished worker discovery
14:42:19 DISPATCHER: Starting worker discovery
14:42:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:42:19 DISPATCHER: Finished worker discovery
14:43:19 DISPATCHER: Starting worker discovery
14:43:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:43:19 DISPATCHER: Finished worker discovery
14:44:19 DISPATCHER: Starting worker discovery
14:44:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:44:19 DISPATCHER: Finished worker discovery
14:45:19 DISPATCHER: Starting worker discovery
14:45:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:45:19 DISPATCHER: Finished worker discovery
14:45:24 WORKER: done with job (8, 0, 23), trying to register it.
14:45:24 WORKER: registered result for job (8, 0, 23) with dispatcher
14:45:24 DISPATCHER: job (8, 0, 23) finished
14:45:24 DISPATCHER: register_result: lock acquired
14:45:24 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
14:45:24 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 90, 'last_n_outputs': 46, 'lr': 0.004480845566893129, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.019925637310145433}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.11197894577517023, 'info': {'data04': 0.11197894577517023, 'config': "{'batch_size': 128, 'hidden_dim': 90, 'last_n_outputs': 46, 'lr': 0.004480845566893129, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.019925637310145433}"}}
exception: None

14:45:24 job_callback for (8, 0, 23) started
14:45:24 DISPATCHER: Trying to submit another job.
14:45:24 job_callback for (8, 0, 23) got condition
14:45:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:45:24 done building a new model for budget 400.000000 based on 9/22 split
Best loss for this budget:-0.183181





14:45:24 HBMASTER: Trying to run another job!
14:45:24 job_callback for (8, 0, 23) finished
14:45:24 ITERATION: Advancing config (8, 0, 10) to next budget 1200.000000
14:45:24 HBMASTER: schedule new run for iteration 8
14:45:24 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
14:45:24 HBMASTER: submitting job (8, 0, 10) to dispatcher
14:45:24 DISPATCHER: trying to submit job (8, 0, 10)
14:45:24 DISPATCHER: trying to notify the job_runner thread.
14:45:24 HBMASTER: job (8, 0, 10) submitted to dispatcher
14:45:24 DISPATCHER: Trying to submit another job.
14:45:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:45:24 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:45:24 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
14:45:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:45:24 WORKER: start processing job (8, 0, 10)
14:45:24 WORKER: args: ()
14:45:24 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 85, 'last_n_outputs': 42, 'lr': 0.0019034677619067394, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.01190112294132778}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-575:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:46:19 DISPATCHER: Starting worker discovery
14:46:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:46:19 DISPATCHER: Finished worker discovery
14:47:19 DISPATCHER: Starting worker discovery
14:47:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:47:19 DISPATCHER: Finished worker discovery
14:48:19 DISPATCHER: Starting worker discovery
14:48:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:48:19 DISPATCHER: Finished worker discovery
14:49:19 DISPATCHER: Starting worker discovery
14:49:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:49:19 DISPATCHER: Finished worker discovery
14:50:19 DISPATCHER: Starting worker discovery
14:50:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:50:19 DISPATCHER: Finished worker discovery
14:51:19 DISPATCHER: Starting worker discovery
14:51:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:51:19 DISPATCHER: Finished worker discovery
14:52:19 DISPATCHER: Starting worker discovery
14:52:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:52:19 DISPATCHER: Finished worker discovery
14:53:19 DISPATCHER: Starting worker discovery
14:53:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:53:19 DISPATCHER: Finished worker discovery
14:54:19 DISPATCHER: Starting worker discovery
14:54:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:54:19 DISPATCHER: Finished worker discovery
14:55:19 DISPATCHER: Starting worker discovery
14:55:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:55:19 DISPATCHER: Finished worker discovery
14:56:19 DISPATCHER: Starting worker discovery
14:56:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:56:19 DISPATCHER: Finished worker discovery
14:57:19 DISPATCHER: Starting worker discovery
14:57:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:57:19 DISPATCHER: Finished worker discovery
14:58:19 DISPATCHER: Starting worker discovery
14:58:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:58:19 DISPATCHER: Finished worker discovery
14:59:19 DISPATCHER: Starting worker discovery
14:59:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:59:19 DISPATCHER: Finished worker discovery
15:00:19 DISPATCHER: Starting worker discovery
15:00:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:00:19 DISPATCHER: Finished worker discovery
15:01:19 DISPATCHER: Starting worker discovery
15:01:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:01:19 DISPATCHER: Finished worker discovery
15:02:19 DISPATCHER: Starting worker discovery
15:02:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:02:19 DISPATCHER: Finished worker discovery
15:03:19 DISPATCHER: Starting worker discovery
15:03:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:03:19 DISPATCHER: Finished worker discovery
15:04:19 DISPATCHER: Starting worker discovery
15:04:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:04:19 DISPATCHER: Finished worker discovery
15:05:19 DISPATCHER: Starting worker discovery
15:05:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:05:19 DISPATCHER: Finished worker discovery
15:05:38 WORKER: done with job (8, 0, 10), trying to register it.
15:05:38 WORKER: registered result for job (8, 0, 10) with dispatcher
15:05:38 DISPATCHER: job (8, 0, 10) finished
15:05:38 DISPATCHER: register_result: lock acquired
15:05:38 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
15:05:38 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 85, 'last_n_outputs': 42, 'lr': 0.0019034677619067394, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.01190112294132778}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.14686779952154486, 'info': {'data04': 0.14686779952154486, 'config': "{'batch_size': 64, 'hidden_dim': 85, 'last_n_outputs': 42, 'lr': 0.0019034677619067394, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.01190112294132778}"}}
exception: None

15:05:38 job_callback for (8, 0, 10) started
15:05:38 DISPATCHER: Trying to submit another job.
15:05:38 job_callback for (8, 0, 10) got condition
15:05:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:05:38 HBMASTER: Trying to run another job!
15:05:38 job_callback for (8, 0, 10) finished
15:05:38 start sampling a new configuration.
15:05:38 done sampling a new configuration.
15:05:38 HBMASTER: schedule new run for iteration 9
15:05:38 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
15:05:38 HBMASTER: submitting job (9, 0, 0) to dispatcher
15:05:38 DISPATCHER: trying to submit job (9, 0, 0)
15:05:38 DISPATCHER: trying to notify the job_runner thread.
15:05:38 HBMASTER: job (9, 0, 0) submitted to dispatcher
15:05:38 DISPATCHER: Trying to submit another job.
15:05:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:05:38 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:05:38 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:05:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:05:38 WORKER: start processing job (9, 0, 0)
15:05:38 WORKER: args: ()
15:05:38 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 28, 'last_n_outputs': 20, 'lr': 0.0023444405065428287, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.04857031790213098}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-576:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:06:19 DISPATCHER: Starting worker discovery
15:06:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:06:19 DISPATCHER: Finished worker discovery
15:07:19 DISPATCHER: Starting worker discovery
15:07:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:07:19 DISPATCHER: Finished worker discovery
15:08:06 WORKER: done with job (9, 0, 0), trying to register it.
15:08:06 WORKER: registered result for job (9, 0, 0) with dispatcher
15:08:06 DISPATCHER: job (9, 0, 0) finished
15:08:06 DISPATCHER: register_result: lock acquired
15:08:06 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
15:08:06 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 28, 'last_n_outputs': 20, 'lr': 0.0023444405065428287, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.04857031790213098}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': 0.00265599345825972, 'info': {'data04': -0.00265599345825972, 'config': "{'batch_size': 32, 'hidden_dim': 28, 'last_n_outputs': 20, 'lr': 0.0023444405065428287, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.04857031790213098}"}}
exception: None

15:08:06 job_callback for (9, 0, 0) started
15:08:06 DISPATCHER: Trying to submit another job.
15:08:06 job_callback for (9, 0, 0) got condition
15:08:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:08:06 HBMASTER: Trying to run another job!
15:08:06 job_callback for (9, 0, 0) finished
15:08:06 start sampling a new configuration.
15:08:06 best_vector: [2, 0.7226346492424041, 0.9315081442993746, 0.15038476982751584, 0.10023524359390767, 0, 0.08703072246602689, 0.03411035448222783], 7.596202152017628e-05, 2975.003000953166, 0.2259872419809934
15:08:06 done sampling a new configuration.
15:08:06 HBMASTER: schedule new run for iteration 9
15:08:06 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
15:08:06 HBMASTER: submitting job (9, 0, 1) to dispatcher
15:08:06 DISPATCHER: trying to submit job (9, 0, 1)
15:08:06 DISPATCHER: trying to notify the job_runner thread.
15:08:06 HBMASTER: job (9, 0, 1) submitted to dispatcher
15:08:06 DISPATCHER: Trying to submit another job.
15:08:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:08:06 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:08:06 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:08:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:08:06 WORKER: start processing job (9, 0, 1)
15:08:06 WORKER: args: ()
15:08:06 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 78, 'last_n_outputs': 47, 'lr': 0.0019988009153475614, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.011075888991015206}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:08:19 DISPATCHER: Starting worker discovery
15:08:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:08:19 DISPATCHER: Finished worker discovery
Exception in thread Thread-577:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:09:19 DISPATCHER: Starting worker discovery
15:09:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:09:19 DISPATCHER: Finished worker discovery
15:10:19 DISPATCHER: Starting worker discovery
15:10:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:10:19 DISPATCHER: Finished worker discovery
15:10:33 WORKER: done with job (9, 0, 1), trying to register it.
15:10:33 WORKER: registered result for job (9, 0, 1) with dispatcher
15:10:33 DISPATCHER: job (9, 0, 1) finished
15:10:33 DISPATCHER: register_result: lock acquired
15:10:33 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
15:10:33 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 78, 'last_n_outputs': 47, 'lr': 0.0019988009153475614, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.011075888991015206}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.12403805455163701, 'info': {'data04': 0.12403805455163701, 'config': "{'batch_size': 64, 'hidden_dim': 78, 'last_n_outputs': 47, 'lr': 0.0019988009153475614, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.011075888991015206}"}}
exception: None

15:10:33 job_callback for (9, 0, 1) started
15:10:33 DISPATCHER: Trying to submit another job.
15:10:33 job_callback for (9, 0, 1) got condition
15:10:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:10:33 HBMASTER: Trying to run another job!
15:10:33 job_callback for (9, 0, 1) finished
15:10:33 start sampling a new configuration.
15:10:33 done sampling a new configuration.
15:10:33 HBMASTER: schedule new run for iteration 9
15:10:33 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
15:10:33 HBMASTER: submitting job (9, 0, 2) to dispatcher
15:10:33 DISPATCHER: trying to submit job (9, 0, 2)
15:10:33 DISPATCHER: trying to notify the job_runner thread.
15:10:33 HBMASTER: job (9, 0, 2) submitted to dispatcher
15:10:33 DISPATCHER: Trying to submit another job.
15:10:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:10:33 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:10:33 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:10:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:10:33 WORKER: start processing job (9, 0, 2)
15:10:33 WORKER: args: ()
15:10:33 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 58, 'last_n_outputs': 31, 'lr': 0.002282445775183781, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.13026757030360897}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-578:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:11:19 DISPATCHER: Starting worker discovery
15:11:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:11:19 DISPATCHER: Finished worker discovery
15:12:19 DISPATCHER: Starting worker discovery
15:12:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:12:19 DISPATCHER: Finished worker discovery
15:13:00 WORKER: done with job (9, 0, 2), trying to register it.
15:13:00 WORKER: registered result for job (9, 0, 2) with dispatcher
15:13:00 DISPATCHER: job (9, 0, 2) finished
15:13:00 DISPATCHER: register_result: lock acquired
15:13:00 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
15:13:00 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 58, 'last_n_outputs': 31, 'lr': 0.002282445775183781, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.13026757030360897}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0009365547401064584, 'info': {'data04': 0.0009365547401064584, 'config': "{'batch_size': 64, 'hidden_dim': 58, 'last_n_outputs': 31, 'lr': 0.002282445775183781, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.13026757030360897}"}}
exception: None

15:13:00 job_callback for (9, 0, 2) started
15:13:00 job_callback for (9, 0, 2) got condition
15:13:00 DISPATCHER: Trying to submit another job.
15:13:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:13:00 HBMASTER: Trying to run another job!
15:13:00 job_callback for (9, 0, 2) finished
15:13:00 start sampling a new configuration.
15:13:00 best_vector: [3, 0.9564123487903538, 0.9465950708497437, 0.3617872394845797, 0.09999969937711901, 0, 0.5751207230553178, 0.11185890630733195], 0.00011577813528899588, 1858.8902219825302, 0.21521884360808496
15:13:00 done sampling a new configuration.
15:13:00 HBMASTER: schedule new run for iteration 9
15:13:00 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
15:13:00 HBMASTER: submitting job (9, 0, 3) to dispatcher
15:13:00 DISPATCHER: trying to submit job (9, 0, 3)
15:13:00 DISPATCHER: trying to notify the job_runner thread.
15:13:00 HBMASTER: job (9, 0, 3) submitted to dispatcher
15:13:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:13:00 DISPATCHER: Trying to submit another job.
15:13:00 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:13:00 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:13:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:13:00 WORKER: start processing job (9, 0, 3)
15:13:00 WORKER: args: ()
15:13:00 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 48, 'lr': 0.005291447346628616, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.01398079257519605}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-579:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:13:19 DISPATCHER: Starting worker discovery
15:13:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:13:19 DISPATCHER: Finished worker discovery
15:14:19 DISPATCHER: Starting worker discovery
15:14:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:14:19 DISPATCHER: Finished worker discovery
15:15:19 DISPATCHER: Starting worker discovery
15:15:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:15:19 DISPATCHER: Finished worker discovery
15:15:28 WORKER: done with job (9, 0, 3), trying to register it.
15:15:28 WORKER: registered result for job (9, 0, 3) with dispatcher
15:15:28 DISPATCHER: job (9, 0, 3) finished
15:15:28 DISPATCHER: register_result: lock acquired
15:15:28 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
15:15:28 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 48, 'lr': 0.005291447346628616, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.01398079257519605}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1519895408779627, 'info': {'data04': 0.1519895408779627, 'config': "{'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 48, 'lr': 0.005291447346628616, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.01398079257519605}"}}
exception: None

15:15:28 job_callback for (9, 0, 3) started
15:15:28 job_callback for (9, 0, 3) got condition
15:15:28 DISPATCHER: Trying to submit another job.
15:15:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:15:28 HBMASTER: Trying to run another job!
15:15:28 job_callback for (9, 0, 3) finished
15:15:28 start sampling a new configuration.
15:15:28 done sampling a new configuration.
15:15:28 HBMASTER: schedule new run for iteration 9
15:15:28 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
15:15:28 HBMASTER: submitting job (9, 0, 4) to dispatcher
15:15:28 DISPATCHER: trying to submit job (9, 0, 4)
15:15:28 DISPATCHER: trying to notify the job_runner thread.
15:15:28 HBMASTER: job (9, 0, 4) submitted to dispatcher
15:15:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:15:28 DISPATCHER: Trying to submit another job.
15:15:28 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:15:28 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:15:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:15:28 WORKER: start processing job (9, 0, 4)
15:15:28 WORKER: args: ()
15:15:28 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 20, 'last_n_outputs': 34, 'lr': 0.0015949786182527794, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.01138517430676492}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-580:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:16:19 DISPATCHER: Starting worker discovery
15:16:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:16:19 DISPATCHER: Finished worker discovery
15:17:19 DISPATCHER: Starting worker discovery
15:17:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:17:19 DISPATCHER: Finished worker discovery
15:17:55 WORKER: done with job (9, 0, 4), trying to register it.
15:17:55 WORKER: registered result for job (9, 0, 4) with dispatcher
15:17:55 DISPATCHER: job (9, 0, 4) finished
15:17:55 DISPATCHER: register_result: lock acquired
15:17:55 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
15:17:55 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 20, 'last_n_outputs': 34, 'lr': 0.0015949786182527794, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.01138517430676492}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.01509328184489659, 'info': {'data04': 0.01509328184489659, 'config': "{'batch_size': 128, 'hidden_dim': 20, 'last_n_outputs': 34, 'lr': 0.0015949786182527794, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.01138517430676492}"}}
exception: None

15:17:55 job_callback for (9, 0, 4) started
15:17:55 job_callback for (9, 0, 4) got condition
15:17:55 DISPATCHER: Trying to submit another job.
15:17:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:17:55 HBMASTER: Trying to run another job!
15:17:55 job_callback for (9, 0, 4) finished
15:17:55 start sampling a new configuration.
15:17:55 best_vector: [1, 0.7025658502011729, 0.720971668177505, 0.12309907160598517, 0.10000903744324041, 0, 0.9316010053675214, 0.3490381773368923], 0.0002707195253556549, 543.169729774782, 0.14704665143218834
15:17:55 done sampling a new configuration.
15:17:55 HBMASTER: schedule new run for iteration 9
15:17:55 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
15:17:55 HBMASTER: submitting job (9, 0, 5) to dispatcher
15:17:55 DISPATCHER: trying to submit job (9, 0, 5)
15:17:55 DISPATCHER: trying to notify the job_runner thread.
15:17:55 HBMASTER: job (9, 0, 5) submitted to dispatcher
15:17:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:17:55 DISPATCHER: Trying to submit another job.
15:17:55 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:17:55 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:17:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:17:55 WORKER: start processing job (9, 0, 5)
15:17:55 WORKER: args: ()
15:17:55 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 76, 'last_n_outputs': 37, 'lr': 0.0017627801166042517, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.028451760112905913}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-581:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:18:19 DISPATCHER: Starting worker discovery
15:18:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:18:19 DISPATCHER: Finished worker discovery
15:19:19 DISPATCHER: Starting worker discovery
15:19:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:19:19 DISPATCHER: Finished worker discovery
15:20:19 DISPATCHER: Starting worker discovery
15:20:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:20:19 DISPATCHER: Finished worker discovery
15:20:22 WORKER: done with job (9, 0, 5), trying to register it.
15:20:22 WORKER: registered result for job (9, 0, 5) with dispatcher
15:20:22 DISPATCHER: job (9, 0, 5) finished
15:20:22 DISPATCHER: register_result: lock acquired
15:20:22 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
15:20:22 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 76, 'last_n_outputs': 37, 'lr': 0.0017627801166042517, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.028451760112905913}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.14307703934000646, 'info': {'data04': 0.14307703934000646, 'config': "{'batch_size': 32, 'hidden_dim': 76, 'last_n_outputs': 37, 'lr': 0.0017627801166042517, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.028451760112905913}"}}
exception: None

15:20:22 job_callback for (9, 0, 5) started
15:20:22 job_callback for (9, 0, 5) got condition
15:20:22 DISPATCHER: Trying to submit another job.
15:20:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:20:22 HBMASTER: Trying to run another job!
15:20:22 job_callback for (9, 0, 5) finished
15:20:22 start sampling a new configuration.
15:20:22 best_vector: [3, 0.8872553640744678, 0.8500669635744369, 0.4077156233933702, 0.0990520759305948, 0, 0.514895394538689, 0.21984036268014007], 0.00014155947904859653, 2313.243736778135, 0.3274615782907415
15:20:22 done sampling a new configuration.
15:20:22 HBMASTER: schedule new run for iteration 9
15:20:22 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
15:20:22 HBMASTER: submitting job (9, 0, 6) to dispatcher
15:20:22 DISPATCHER: trying to submit job (9, 0, 6)
15:20:22 DISPATCHER: trying to notify the job_runner thread.
15:20:22 HBMASTER: job (9, 0, 6) submitted to dispatcher
15:20:22 DISPATCHER: Trying to submit another job.
15:20:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:20:22 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:20:22 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:20:22 WORKER: start processing job (9, 0, 6)
15:20:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:20:22 WORKER: args: ()
15:20:22 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 91, 'last_n_outputs': 43, 'lr': 0.006537794219104519, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.01932052423058995}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-582:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:21:19 DISPATCHER: Starting worker discovery
15:21:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:21:19 DISPATCHER: Finished worker discovery
15:22:19 DISPATCHER: Starting worker discovery
15:22:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:22:19 DISPATCHER: Finished worker discovery
15:22:49 WORKER: done with job (9, 0, 6), trying to register it.
15:22:49 WORKER: registered result for job (9, 0, 6) with dispatcher
15:22:49 DISPATCHER: job (9, 0, 6) finished
15:22:49 DISPATCHER: register_result: lock acquired
15:22:49 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
15:22:49 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 91, 'last_n_outputs': 43, 'lr': 0.006537794219104519, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.01932052423058995}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.14785851906462477, 'info': {'data04': 0.14785851906462477, 'config': "{'batch_size': 128, 'hidden_dim': 91, 'last_n_outputs': 43, 'lr': 0.006537794219104519, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.01932052423058995}"}}
exception: None

15:22:49 job_callback for (9, 0, 6) started
15:22:49 job_callback for (9, 0, 6) got condition
15:22:49 DISPATCHER: Trying to submit another job.
15:22:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:22:49 HBMASTER: Trying to run another job!
15:22:49 job_callback for (9, 0, 6) finished
15:22:49 start sampling a new configuration.
15:22:49 done sampling a new configuration.
15:22:49 HBMASTER: schedule new run for iteration 9
15:22:49 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
15:22:49 HBMASTER: submitting job (9, 0, 7) to dispatcher
15:22:49 DISPATCHER: trying to submit job (9, 0, 7)
15:22:49 DISPATCHER: trying to notify the job_runner thread.
15:22:49 HBMASTER: job (9, 0, 7) submitted to dispatcher
15:22:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:22:49 DISPATCHER: Trying to submit another job.
15:22:49 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:22:49 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:22:49 WORKER: start processing job (9, 0, 7)
15:22:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:22:49 WORKER: args: ()
15:22:49 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 61, 'last_n_outputs': 35, 'lr': 0.0018193119732205047, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.02842347910017341}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-583:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:23:19 DISPATCHER: Starting worker discovery
15:23:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:23:19 DISPATCHER: Finished worker discovery
15:24:19 DISPATCHER: Starting worker discovery
15:24:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:24:19 DISPATCHER: Finished worker discovery
15:25:16 WORKER: done with job (9, 0, 7), trying to register it.
15:25:16 WORKER: registered result for job (9, 0, 7) with dispatcher
15:25:16 DISPATCHER: job (9, 0, 7) finished
15:25:16 DISPATCHER: register_result: lock acquired
15:25:16 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
15:25:16 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 61, 'last_n_outputs': 35, 'lr': 0.0018193119732205047, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.02842347910017341}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': 0.007908171615445434, 'info': {'data04': -0.007908171615445434, 'config': "{'batch_size': 128, 'hidden_dim': 61, 'last_n_outputs': 35, 'lr': 0.0018193119732205047, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.02842347910017341}"}}
exception: None

15:25:16 job_callback for (9, 0, 7) started
15:25:16 job_callback for (9, 0, 7) got condition
15:25:16 DISPATCHER: Trying to submit another job.
15:25:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:25:16 HBMASTER: Trying to run another job!
15:25:16 job_callback for (9, 0, 7) finished
15:25:16 start sampling a new configuration.
15:25:16 best_vector: [0, 0.949027362193849, 0.8452884117932523, 0.26809969939538825, 0.09944502903834271, 0, 0.1560175903093285, 0.18861065482455458], 0.00017034804484240745, 3108.7467995315415, 0.5295689392102897
15:25:16 done sampling a new configuration.
15:25:16 HBMASTER: schedule new run for iteration 9
15:25:16 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
15:25:16 HBMASTER: submitting job (9, 0, 8) to dispatcher
15:25:16 DISPATCHER: trying to submit job (9, 0, 8)
15:25:16 DISPATCHER: trying to notify the job_runner thread.
15:25:16 HBMASTER: job (9, 0, 8) submitted to dispatcher
15:25:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:25:16 DISPATCHER: Trying to submit another job.
15:25:16 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:25:16 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:25:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:25:16 WORKER: start processing job (9, 0, 8)
15:25:16 WORKER: args: ()
15:25:16 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 96, 'last_n_outputs': 43, 'lr': 0.0034371572279936467, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.017594953338378187}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:25:19 DISPATCHER: Starting worker discovery
15:25:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:25:19 DISPATCHER: Finished worker discovery
Exception in thread Thread-584:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:26:19 DISPATCHER: Starting worker discovery
15:26:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:26:19 DISPATCHER: Finished worker discovery
15:27:19 DISPATCHER: Starting worker discovery
15:27:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:27:19 DISPATCHER: Finished worker discovery
15:27:43 WORKER: done with job (9, 0, 8), trying to register it.
15:27:43 WORKER: registered result for job (9, 0, 8) with dispatcher
15:27:43 DISPATCHER: job (9, 0, 8) finished
15:27:43 DISPATCHER: register_result: lock acquired
15:27:43 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
15:27:43 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 96, 'last_n_outputs': 43, 'lr': 0.0034371572279936467, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.017594953338378187}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.10480386137801816, 'info': {'data04': 0.10480386137801816, 'config': "{'batch_size': 16, 'hidden_dim': 96, 'last_n_outputs': 43, 'lr': 0.0034371572279936467, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.017594953338378187}"}}
exception: None

15:27:43 job_callback for (9, 0, 8) started
15:27:43 job_callback for (9, 0, 8) got condition
15:27:43 DISPATCHER: Trying to submit another job.
15:27:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:27:43 HBMASTER: Trying to run another job!
15:27:43 job_callback for (9, 0, 8) finished
15:27:43 ITERATION: Advancing config (9, 0, 3) to next budget 400.000000
15:27:43 ITERATION: Advancing config (9, 0, 5) to next budget 400.000000
15:27:43 ITERATION: Advancing config (9, 0, 6) to next budget 400.000000
15:27:43 HBMASTER: schedule new run for iteration 9
15:27:43 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
15:27:43 HBMASTER: submitting job (9, 0, 3) to dispatcher
15:27:43 DISPATCHER: trying to submit job (9, 0, 3)
15:27:43 DISPATCHER: trying to notify the job_runner thread.
15:27:43 HBMASTER: job (9, 0, 3) submitted to dispatcher
15:27:43 DISPATCHER: Trying to submit another job.
15:27:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:27:43 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:27:43 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:27:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:27:43 WORKER: start processing job (9, 0, 3)
15:27:43 WORKER: args: ()
15:27:43 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 48, 'lr': 0.005291447346628616, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.01398079257519605}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-585:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:28:19 DISPATCHER: Starting worker discovery
15:28:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:28:19 DISPATCHER: Finished worker discovery
15:29:19 DISPATCHER: Starting worker discovery
15:29:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:29:19 DISPATCHER: Finished worker discovery
15:30:19 DISPATCHER: Starting worker discovery
15:30:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:30:19 DISPATCHER: Finished worker discovery
15:31:19 DISPATCHER: Starting worker discovery
15:31:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:31:19 DISPATCHER: Finished worker discovery
15:32:19 DISPATCHER: Starting worker discovery
15:32:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:32:19 DISPATCHER: Finished worker discovery
15:33:19 DISPATCHER: Starting worker discovery
15:33:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:33:19 DISPATCHER: Finished worker discovery
15:34:19 DISPATCHER: Starting worker discovery
15:34:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:34:19 DISPATCHER: Finished worker discovery
15:34:37 WORKER: done with job (9, 0, 3), trying to register it.
15:34:37 WORKER: registered result for job (9, 0, 3) with dispatcher
15:34:37 DISPATCHER: job (9, 0, 3) finished
15:34:37 DISPATCHER: register_result: lock acquired
15:34:37 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
15:34:37 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 48, 'lr': 0.005291447346628616, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.01398079257519605}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.13781188777459433, 'info': {'data04': 0.13781188777459433, 'config': "{'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 48, 'lr': 0.005291447346628616, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.01398079257519605}"}}
exception: None

15:34:37 job_callback for (9, 0, 3) started
15:34:37 job_callback for (9, 0, 3) got condition
15:34:37 DISPATCHER: Trying to submit another job.
15:34:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:34:37 done building a new model for budget 400.000000 based on 9/23 split
Best loss for this budget:-0.183181





15:34:37 HBMASTER: Trying to run another job!
15:34:37 job_callback for (9, 0, 3) finished
15:34:37 HBMASTER: schedule new run for iteration 9
15:34:37 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
15:34:37 HBMASTER: submitting job (9, 0, 5) to dispatcher
15:34:37 DISPATCHER: trying to submit job (9, 0, 5)
15:34:37 DISPATCHER: trying to notify the job_runner thread.
15:34:37 HBMASTER: job (9, 0, 5) submitted to dispatcher
15:34:37 DISPATCHER: Trying to submit another job.
15:34:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:34:37 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:34:37 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:34:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:34:37 WORKER: start processing job (9, 0, 5)
15:34:37 WORKER: args: ()
15:34:37 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 76, 'last_n_outputs': 37, 'lr': 0.0017627801166042517, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.028451760112905913}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-586:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:35:19 DISPATCHER: Starting worker discovery
15:35:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:35:19 DISPATCHER: Finished worker discovery
15:36:19 DISPATCHER: Starting worker discovery
15:36:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:36:19 DISPATCHER: Finished worker discovery
15:37:19 DISPATCHER: Starting worker discovery
15:37:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:37:19 DISPATCHER: Finished worker discovery
15:38:19 DISPATCHER: Starting worker discovery
15:38:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:38:19 DISPATCHER: Finished worker discovery
15:39:19 DISPATCHER: Starting worker discovery
15:39:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:39:19 DISPATCHER: Finished worker discovery
15:40:19 DISPATCHER: Starting worker discovery
15:40:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:40:19 DISPATCHER: Finished worker discovery
15:41:19 DISPATCHER: Starting worker discovery
15:41:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:41:19 DISPATCHER: Finished worker discovery
15:41:30 WORKER: done with job (9, 0, 5), trying to register it.
15:41:30 WORKER: registered result for job (9, 0, 5) with dispatcher
15:41:30 DISPATCHER: job (9, 0, 5) finished
15:41:30 DISPATCHER: register_result: lock acquired
15:41:30 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
15:41:30 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 76, 'last_n_outputs': 37, 'lr': 0.0017627801166042517, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.028451760112905913}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.12373073983337779, 'info': {'data04': 0.12373073983337779, 'config': "{'batch_size': 32, 'hidden_dim': 76, 'last_n_outputs': 37, 'lr': 0.0017627801166042517, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.028451760112905913}"}}
exception: None

15:41:30 job_callback for (9, 0, 5) started
15:41:30 DISPATCHER: Trying to submit another job.
15:41:30 job_callback for (9, 0, 5) got condition
15:41:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:41:30 done building a new model for budget 400.000000 based on 9/24 split
Best loss for this budget:-0.183181





15:41:30 HBMASTER: Trying to run another job!
15:41:30 job_callback for (9, 0, 5) finished
15:41:30 HBMASTER: schedule new run for iteration 9
15:41:30 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
15:41:30 HBMASTER: submitting job (9, 0, 6) to dispatcher
15:41:30 DISPATCHER: trying to submit job (9, 0, 6)
15:41:30 DISPATCHER: trying to notify the job_runner thread.
15:41:30 HBMASTER: job (9, 0, 6) submitted to dispatcher
15:41:30 DISPATCHER: Trying to submit another job.
15:41:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:41:30 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:41:30 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:41:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:41:30 WORKER: start processing job (9, 0, 6)
15:41:30 WORKER: args: ()
15:41:30 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 91, 'last_n_outputs': 43, 'lr': 0.006537794219104519, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.01932052423058995}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-587:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:42:19 DISPATCHER: Starting worker discovery
15:42:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:42:19 DISPATCHER: Finished worker discovery
15:43:19 DISPATCHER: Starting worker discovery
15:43:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:43:19 DISPATCHER: Finished worker discovery
15:44:19 DISPATCHER: Starting worker discovery
15:44:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:44:19 DISPATCHER: Finished worker discovery
15:45:19 DISPATCHER: Starting worker discovery
15:45:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:45:19 DISPATCHER: Finished worker discovery
15:46:19 DISPATCHER: Starting worker discovery
15:46:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:46:19 DISPATCHER: Finished worker discovery
15:47:19 DISPATCHER: Starting worker discovery
15:47:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:47:19 DISPATCHER: Finished worker discovery
15:48:19 DISPATCHER: Starting worker discovery
15:48:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:48:19 DISPATCHER: Finished worker discovery
15:48:24 WORKER: done with job (9, 0, 6), trying to register it.
15:48:24 WORKER: registered result for job (9, 0, 6) with dispatcher
15:48:24 DISPATCHER: job (9, 0, 6) finished
15:48:24 DISPATCHER: register_result: lock acquired
15:48:24 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
15:48:24 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 91, 'last_n_outputs': 43, 'lr': 0.006537794219104519, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.01932052423058995}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.12513858044011933, 'info': {'data04': 0.12513858044011933, 'config': "{'batch_size': 128, 'hidden_dim': 91, 'last_n_outputs': 43, 'lr': 0.006537794219104519, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.01932052423058995}"}}
exception: None

15:48:24 job_callback for (9, 0, 6) started
15:48:24 job_callback for (9, 0, 6) got condition
15:48:24 DISPATCHER: Trying to submit another job.
15:48:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:48:24 done building a new model for budget 400.000000 based on 9/25 split
Best loss for this budget:-0.183181





15:48:24 HBMASTER: Trying to run another job!
15:48:24 job_callback for (9, 0, 6) finished
15:48:24 ITERATION: Advancing config (9, 0, 3) to next budget 1200.000000
15:48:24 HBMASTER: schedule new run for iteration 9
15:48:24 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
15:48:24 HBMASTER: submitting job (9, 0, 3) to dispatcher
15:48:24 DISPATCHER: trying to submit job (9, 0, 3)
15:48:24 DISPATCHER: trying to notify the job_runner thread.
15:48:24 HBMASTER: job (9, 0, 3) submitted to dispatcher
15:48:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:48:24 DISPATCHER: Trying to submit another job.
15:48:24 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:48:24 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
15:48:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:48:24 WORKER: start processing job (9, 0, 3)
15:48:24 WORKER: args: ()
15:48:24 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 48, 'lr': 0.005291447346628616, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.01398079257519605}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-588:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:49:19 DISPATCHER: Starting worker discovery
15:49:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:49:19 DISPATCHER: Finished worker discovery
15:50:19 DISPATCHER: Starting worker discovery
15:50:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:50:19 DISPATCHER: Finished worker discovery
15:51:19 DISPATCHER: Starting worker discovery
15:51:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:51:19 DISPATCHER: Finished worker discovery
15:52:19 DISPATCHER: Starting worker discovery
15:52:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:52:19 DISPATCHER: Finished worker discovery
15:53:19 DISPATCHER: Starting worker discovery
15:53:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:53:19 DISPATCHER: Finished worker discovery
15:54:19 DISPATCHER: Starting worker discovery
15:54:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:54:19 DISPATCHER: Finished worker discovery
15:55:19 DISPATCHER: Starting worker discovery
15:55:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:55:19 DISPATCHER: Finished worker discovery
15:56:19 DISPATCHER: Starting worker discovery
15:56:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:56:19 DISPATCHER: Finished worker discovery
15:57:19 DISPATCHER: Starting worker discovery
15:57:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:57:19 DISPATCHER: Finished worker discovery
15:58:19 DISPATCHER: Starting worker discovery
15:58:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:58:19 DISPATCHER: Finished worker discovery
15:59:19 DISPATCHER: Starting worker discovery
15:59:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:59:19 DISPATCHER: Finished worker discovery
16:00:19 DISPATCHER: Starting worker discovery
16:00:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:00:19 DISPATCHER: Finished worker discovery
16:01:19 DISPATCHER: Starting worker discovery
16:01:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:01:19 DISPATCHER: Finished worker discovery
16:02:19 DISPATCHER: Starting worker discovery
16:02:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:02:19 DISPATCHER: Finished worker discovery
16:03:19 DISPATCHER: Starting worker discovery
16:03:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:03:19 DISPATCHER: Finished worker discovery
16:04:19 DISPATCHER: Starting worker discovery
16:04:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:04:19 DISPATCHER: Finished worker discovery
16:05:19 DISPATCHER: Starting worker discovery
16:05:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:05:19 DISPATCHER: Finished worker discovery
16:06:19 DISPATCHER: Starting worker discovery
16:06:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:06:19 DISPATCHER: Finished worker discovery
16:07:19 DISPATCHER: Starting worker discovery
16:07:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:07:20 DISPATCHER: Finished worker discovery
16:08:20 DISPATCHER: Starting worker discovery
16:08:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:08:20 DISPATCHER: Finished worker discovery
16:08:39 WORKER: done with job (9, 0, 3), trying to register it.
16:08:39 WORKER: registered result for job (9, 0, 3) with dispatcher
16:08:39 DISPATCHER: job (9, 0, 3) finished
16:08:39 DISPATCHER: register_result: lock acquired
16:08:39 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:08:39 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 48, 'lr': 0.005291447346628616, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.01398079257519605}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.17044597625151964, 'info': {'data04': 0.17044597625151964, 'config': "{'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 48, 'lr': 0.005291447346628616, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.01398079257519605}"}}
exception: None

16:08:39 job_callback for (9, 0, 3) started
16:08:39 DISPATCHER: Trying to submit another job.
16:08:39 job_callback for (9, 0, 3) got condition
16:08:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:08:39 done building a new model for budget 1200.000000 based on 9/15 split
Best loss for this budget:-0.190623





16:08:39 HBMASTER: Trying to run another job!
16:08:39 job_callback for (9, 0, 3) finished
16:08:39 HBMASTER: shutdown initiated, shutdown_workers = True
16:08:39 WORKER: shutting down now!
16:08:39 DISPATCHER: Dispatcher shutting down
16:08:39 DISPATCHER: discover_workers shutting down
16:08:39 DISPATCHER: Trying to submit another job.
16:08:39 DISPATCHER: 'discover_worker' thread exited
16:08:39 DISPATCHER: job_runner shutting down
16:08:39 DISPATCHER: 'job_runner' thread exited
16:08:39 DISPATCHER: shut down complete
16:08:39 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7fb980affac8; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:30418>
16:08:39 WORKER: No dispatcher found. Waiting for one to initiate contact.
16:08:39 WORKER: start listening for jobs
16:08:39 wait_for_workers trying to get the condition
16:08:39 DISPATCHER: started the 'discover_worker' thread
16:08:39 DISPATCHER: started the 'job_runner' thread
16:08:39 DISPATCHER: Pyro daemon running on localhost:43333
16:08:39 DISPATCHER: Starting worker discovery
16:08:39 DISPATCHER: Found 1 potential workers, 0 currently in the pool.
16:08:39 DISPATCHER: discovered new worker, hpbandster.run_0.worker.metagpuj.13102140436472194880
16:08:39 HBMASTER: number of workers changed to 1
16:08:39 Enough workers to start this run!
16:08:39 adjust_queue_size: lock accquired
16:08:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:08:39 HBMASTER: starting run at 1583939319.5622008
16:08:39 HBMASTER: adjusted queue size to (0, 1)
16:08:39 DISPATCHER: Finished worker discovery
16:08:39 start sampling a new configuration.
16:08:39 DISPATCHER: Trying to submit another job.
16:08:39 done sampling a new configuration.
16:08:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:08:39 HBMASTER: schedule new run for iteration 0
16:08:39 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
16:08:39 HBMASTER: submitting job (0, 0, 0) to dispatcher
16:08:39 DISPATCHER: trying to submit job (0, 0, 0)
16:08:39 DISPATCHER: trying to notify the job_runner thread.
16:08:39 HBMASTER: job (0, 0, 0) submitted to dispatcher
16:08:39 DISPATCHER: Trying to submit another job.
16:08:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:08:39 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:08:39 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:08:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:08:39 WORKER: start processing job (0, 0, 0)
16:08:39 WORKER: args: ()
16:08:39 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006853836383820816, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.0133321974879746, 'kernel_size_2': 3, 'num_filters_2': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:09:39 DISPATCHER: Starting worker discovery
16:09:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:09:39 DISPATCHER: Finished worker discovery
16:09:41 WORKER: done with job (0, 0, 0), trying to register it.
16:09:41 WORKER: registered result for job (0, 0, 0) with dispatcher
16:09:41 DISPATCHER: job (0, 0, 0) finished
16:09:41 DISPATCHER: register_result: lock acquired
16:09:41 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:09:41 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006853836383820816, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.0133321974879746, 'kernel_size_2': 3, 'num_filters_2': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.05774637512822547, 'info': {'data04': 0.05774637512822547, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006853836383820816, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.0133321974879746, 'kernel_size_2': 3, 'num_filters_2': 17}"}}
exception: None

16:09:41 job_callback for (0, 0, 0) started
16:09:41 job_callback for (0, 0, 0) got condition
16:09:41 DISPATCHER: Trying to submit another job.
16:09:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:09:41 Only 1 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
16:09:41 HBMASTER: Trying to run another job!
16:09:41 job_callback for (0, 0, 0) finished
16:09:41 start sampling a new configuration.
16:09:41 done sampling a new configuration.
16:09:41 HBMASTER: schedule new run for iteration 0
16:09:41 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
16:09:41 HBMASTER: submitting job (0, 0, 1) to dispatcher
16:09:41 DISPATCHER: trying to submit job (0, 0, 1)
16:09:41 DISPATCHER: trying to notify the job_runner thread.
16:09:41 HBMASTER: job (0, 0, 1) submitted to dispatcher
16:09:41 DISPATCHER: Trying to submit another job.
16:09:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:09:41 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:09:41 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:09:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:09:41 WORKER: start processing job (0, 0, 1)
16:09:41 WORKER: args: ()
16:09:41 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0020552740258678133, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.08256069330332905, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 95, 'num_filters_3': 34, 'num_filters_4': 67}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:10:39 DISPATCHER: Starting worker discovery
16:10:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:10:39 DISPATCHER: Finished worker discovery
16:10:43 WORKER: done with job (0, 0, 1), trying to register it.
16:10:43 WORKER: registered result for job (0, 0, 1) with dispatcher
16:10:43 DISPATCHER: job (0, 0, 1) finished
16:10:43 DISPATCHER: register_result: lock acquired
16:10:43 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:10:43 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0020552740258678133, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.08256069330332905, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 95, 'num_filters_3': 34, 'num_filters_4': 67}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0714119226441212, 'info': {'data04': 0.0714119226441212, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0020552740258678133, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.08256069330332905, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 95, 'num_filters_3': 34, 'num_filters_4': 67}"}}
exception: None

16:10:43 job_callback for (0, 0, 1) started
16:10:43 DISPATCHER: Trying to submit another job.
16:10:43 job_callback for (0, 0, 1) got condition
16:10:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:10:43 Only 2 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
16:10:43 HBMASTER: Trying to run another job!
16:10:43 job_callback for (0, 0, 1) finished
16:10:43 start sampling a new configuration.
16:10:43 done sampling a new configuration.
16:10:43 HBMASTER: schedule new run for iteration 0
16:10:43 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
16:10:43 HBMASTER: submitting job (0, 0, 2) to dispatcher
16:10:43 DISPATCHER: trying to submit job (0, 0, 2)
16:10:43 DISPATCHER: trying to notify the job_runner thread.
16:10:43 HBMASTER: job (0, 0, 2) submitted to dispatcher
16:10:43 DISPATCHER: Trying to submit another job.
16:10:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:10:43 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:10:43 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:10:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:10:43 WORKER: start processing job (0, 0, 2)
16:10:43 WORKER: args: ()
16:10:43 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.07102745387258562, 'num_filters_1': 58, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.1847703048275051, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 82, 'num_filters_3': 81, 'num_filters_4': 103}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:11:39 DISPATCHER: Starting worker discovery
16:11:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:11:39 DISPATCHER: Finished worker discovery
16:11:43 WORKER: done with job (0, 0, 2), trying to register it.
16:11:43 WORKER: registered result for job (0, 0, 2) with dispatcher
16:11:43 DISPATCHER: job (0, 0, 2) finished
16:11:43 DISPATCHER: register_result: lock acquired
16:11:43 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:11:43 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.07102745387258562, 'num_filters_1': 58, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.1847703048275051, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 82, 'num_filters_3': 81, 'num_filters_4': 103}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.07102745387258562, 'num_filters_1': 58, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.1847703048275051, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 82, 'num_filters_3': 81, 'num_filters_4': 103}"}}
exception: None

16:11:43 job_callback for (0, 0, 2) started
16:11:43 job_callback for (0, 0, 2) got condition
16:11:43 DISPATCHER: Trying to submit another job.
16:11:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:11:43 Only 3 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
16:11:43 HBMASTER: Trying to run another job!
16:11:43 job_callback for (0, 0, 2) finished
16:11:43 start sampling a new configuration.
16:11:43 done sampling a new configuration.
16:11:43 HBMASTER: schedule new run for iteration 0
16:11:43 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
16:11:43 HBMASTER: submitting job (0, 0, 3) to dispatcher
16:11:43 DISPATCHER: trying to submit job (0, 0, 3)
16:11:43 DISPATCHER: trying to notify the job_runner thread.
16:11:43 HBMASTER: job (0, 0, 3) submitted to dispatcher
16:11:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:11:43 DISPATCHER: Trying to submit another job.
16:11:43 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:11:43 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:11:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:11:43 WORKER: start processing job (0, 0, 3)
16:11:43 WORKER: args: ()
16:11:43 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.009265082680991266, 'num_filters_1': 85, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.1390893959653359, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 24, 'num_filters_3': 76, 'num_filters_4': 43, 'num_filters_5': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:12:39 DISPATCHER: Starting worker discovery
16:12:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:12:39 DISPATCHER: Finished worker discovery
16:12:45 WORKER: done with job (0, 0, 3), trying to register it.
16:12:45 WORKER: registered result for job (0, 0, 3) with dispatcher
16:12:45 DISPATCHER: job (0, 0, 3) finished
16:12:45 DISPATCHER: register_result: lock acquired
16:12:45 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:12:45 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.009265082680991266, 'num_filters_1': 85, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.1390893959653359, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 24, 'num_filters_3': 76, 'num_filters_4': 43, 'num_filters_5': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.009265082680991266, 'num_filters_1': 85, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.1390893959653359, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 24, 'num_filters_3': 76, 'num_filters_4': 43, 'num_filters_5': 18}"}}
exception: None

16:12:45 job_callback for (0, 0, 3) started
16:12:45 DISPATCHER: Trying to submit another job.
16:12:45 job_callback for (0, 0, 3) got condition
16:12:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:12:45 Only 4 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
16:12:45 HBMASTER: Trying to run another job!
16:12:45 job_callback for (0, 0, 3) finished
16:12:45 start sampling a new configuration.
16:12:45 done sampling a new configuration.
16:12:45 HBMASTER: schedule new run for iteration 0
16:12:45 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
16:12:45 HBMASTER: submitting job (0, 0, 4) to dispatcher
16:12:45 DISPATCHER: trying to submit job (0, 0, 4)
16:12:45 DISPATCHER: trying to notify the job_runner thread.
16:12:45 HBMASTER: job (0, 0, 4) submitted to dispatcher
16:12:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:12:45 DISPATCHER: Trying to submit another job.
16:12:45 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:12:45 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:12:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:12:45 WORKER: start processing job (0, 0, 4)
16:12:45 WORKER: args: ()
16:12:45 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.054708261357100454, 'num_filters_1': 78, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.01507169740128756, 'kernel_size_2': 3, 'num_filters_2': 30}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:13:39 DISPATCHER: Starting worker discovery
16:13:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:13:39 DISPATCHER: Finished worker discovery
16:13:47 WORKER: done with job (0, 0, 4), trying to register it.
16:13:47 WORKER: registered result for job (0, 0, 4) with dispatcher
16:13:47 DISPATCHER: job (0, 0, 4) finished
16:13:47 DISPATCHER: register_result: lock acquired
16:13:47 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:13:47 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.054708261357100454, 'num_filters_1': 78, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.01507169740128756, 'kernel_size_2': 3, 'num_filters_2': 30}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.07992087246037612, 'info': {'data04': 0.07992087246037612, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.054708261357100454, 'num_filters_1': 78, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.01507169740128756, 'kernel_size_2': 3, 'num_filters_2': 30}"}}
exception: None

16:13:47 job_callback for (0, 0, 4) started
16:13:47 DISPATCHER: Trying to submit another job.
16:13:47 job_callback for (0, 0, 4) got condition
16:13:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:13:47 Only 5 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
16:13:47 HBMASTER: Trying to run another job!
16:13:47 job_callback for (0, 0, 4) finished
16:13:47 start sampling a new configuration.
16:13:47 done sampling a new configuration.
16:13:47 HBMASTER: schedule new run for iteration 0
16:13:47 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
16:13:47 HBMASTER: submitting job (0, 0, 5) to dispatcher
16:13:47 DISPATCHER: trying to submit job (0, 0, 5)
16:13:47 DISPATCHER: trying to notify the job_runner thread.
16:13:47 HBMASTER: job (0, 0, 5) submitted to dispatcher
16:13:47 DISPATCHER: Trying to submit another job.
16:13:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:13:47 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:13:47 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:13:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:13:47 WORKER: start processing job (0, 0, 5)
16:13:47 WORKER: args: ()
16:13:47 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.04652782863847605, 'num_filters_1': 26, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.04200401829388735, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 110, 'num_filters_3': 38}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:14:39 DISPATCHER: Starting worker discovery
16:14:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:14:39 DISPATCHER: Finished worker discovery
16:14:48 WORKER: done with job (0, 0, 5), trying to register it.
16:14:48 WORKER: registered result for job (0, 0, 5) with dispatcher
16:14:48 DISPATCHER: job (0, 0, 5) finished
16:14:48 DISPATCHER: register_result: lock acquired
16:14:48 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:14:48 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.04652782863847605, 'num_filters_1': 26, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.04200401829388735, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 110, 'num_filters_3': 38}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.04652782863847605, 'num_filters_1': 26, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.04200401829388735, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 110, 'num_filters_3': 38}"}}
exception: None

16:14:48 job_callback for (0, 0, 5) started
16:14:48 DISPATCHER: Trying to submit another job.
16:14:48 job_callback for (0, 0, 5) got condition
16:14:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:14:48 Only 6 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
16:14:48 HBMASTER: Trying to run another job!
16:14:48 job_callback for (0, 0, 5) finished
16:14:48 start sampling a new configuration.
16:14:48 done sampling a new configuration.
16:14:48 HBMASTER: schedule new run for iteration 0
16:14:48 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
16:14:48 HBMASTER: submitting job (0, 0, 6) to dispatcher
16:14:48 DISPATCHER: trying to submit job (0, 0, 6)
16:14:48 DISPATCHER: trying to notify the job_runner thread.
16:14:48 HBMASTER: job (0, 0, 6) submitted to dispatcher
16:14:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:14:48 DISPATCHER: Trying to submit another job.
16:14:48 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:14:48 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:14:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:14:48 WORKER: start processing job (0, 0, 6)
16:14:48 WORKER: args: ()
16:14:48 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0012595272977388803, 'num_filters_1': 28, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.08131332156642622, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 126, 'num_filters_3': 62, 'num_filters_4': 97}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:15:39 DISPATCHER: Starting worker discovery
16:15:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:15:39 DISPATCHER: Finished worker discovery
16:15:48 WORKER: done with job (0, 0, 6), trying to register it.
16:15:48 WORKER: registered result for job (0, 0, 6) with dispatcher
16:15:48 DISPATCHER: job (0, 0, 6) finished
16:15:48 DISPATCHER: register_result: lock acquired
16:15:48 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:15:48 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0012595272977388803, 'num_filters_1': 28, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.08131332156642622, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 126, 'num_filters_3': 62, 'num_filters_4': 97}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1462592072785993, 'info': {'data04': 0.1462592072785993, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0012595272977388803, 'num_filters_1': 28, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.08131332156642622, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 126, 'num_filters_3': 62, 'num_filters_4': 97}"}}
exception: None

16:15:48 job_callback for (0, 0, 6) started
16:15:48 DISPATCHER: Trying to submit another job.
16:15:48 job_callback for (0, 0, 6) got condition
16:15:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:15:48 Only 7 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
16:15:48 HBMASTER: Trying to run another job!
16:15:48 job_callback for (0, 0, 6) finished
16:15:48 start sampling a new configuration.
16:15:48 done sampling a new configuration.
16:15:48 HBMASTER: schedule new run for iteration 0
16:15:48 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
16:15:48 HBMASTER: submitting job (0, 0, 7) to dispatcher
16:15:48 DISPATCHER: trying to submit job (0, 0, 7)
16:15:48 DISPATCHER: trying to notify the job_runner thread.
16:15:48 HBMASTER: job (0, 0, 7) submitted to dispatcher
16:15:48 DISPATCHER: Trying to submit another job.
16:15:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:15:48 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:15:48 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:15:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:15:48 WORKER: start processing job (0, 0, 7)
16:15:48 WORKER: args: ()
16:15:48 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.03947426985982389, 'num_filters_1': 113, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.13113474453980795}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:16:39 DISPATCHER: Starting worker discovery
16:16:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:16:39 DISPATCHER: Finished worker discovery
16:16:50 WORKER: done with job (0, 0, 7), trying to register it.
16:16:50 WORKER: registered result for job (0, 0, 7) with dispatcher
16:16:50 DISPATCHER: job (0, 0, 7) finished
16:16:50 DISPATCHER: register_result: lock acquired
16:16:50 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:16:50 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.03947426985982389, 'num_filters_1': 113, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.13113474453980795}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.030673177270240482, 'info': {'data04': 0.030673177270240482, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.03947426985982389, 'num_filters_1': 113, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.13113474453980795}"}}
exception: None

16:16:50 job_callback for (0, 0, 7) started
16:16:50 DISPATCHER: Trying to submit another job.
16:16:50 job_callback for (0, 0, 7) got condition
16:16:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:16:50 Only 8 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
16:16:50 HBMASTER: Trying to run another job!
16:16:50 job_callback for (0, 0, 7) finished
16:16:50 start sampling a new configuration.
16:16:50 done sampling a new configuration.
16:16:50 HBMASTER: schedule new run for iteration 0
16:16:50 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
16:16:50 HBMASTER: submitting job (0, 0, 8) to dispatcher
16:16:50 DISPATCHER: trying to submit job (0, 0, 8)
16:16:50 DISPATCHER: trying to notify the job_runner thread.
16:16:50 HBMASTER: job (0, 0, 8) submitted to dispatcher
16:16:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:16:50 DISPATCHER: Trying to submit another job.
16:16:50 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:16:50 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:16:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:16:50 WORKER: start processing job (0, 0, 8)
16:16:50 WORKER: args: ()
16:16:50 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.01457004470049227, 'num_filters_1': 31, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.015150093373003751, 'kernel_size_2': 7, 'num_filters_2': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:17:39 DISPATCHER: Starting worker discovery
16:17:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:17:39 DISPATCHER: Finished worker discovery
16:17:52 WORKER: done with job (0, 0, 8), trying to register it.
16:17:52 WORKER: registered result for job (0, 0, 8) with dispatcher
16:17:52 DISPATCHER: job (0, 0, 8) finished
16:17:52 DISPATCHER: register_result: lock acquired
16:17:52 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:17:52 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.01457004470049227, 'num_filters_1': 31, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.015150093373003751, 'kernel_size_2': 7, 'num_filters_2': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.01457004470049227, 'num_filters_1': 31, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.015150093373003751, 'kernel_size_2': 7, 'num_filters_2': 27}"}}
exception: None

16:17:52 job_callback for (0, 0, 8) started
16:17:52 DISPATCHER: Trying to submit another job.
16:17:52 job_callback for (0, 0, 8) got condition
16:17:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:17:52 Only 9 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
16:17:52 HBMASTER: Trying to run another job!
16:17:52 job_callback for (0, 0, 8) finished
16:17:52 start sampling a new configuration.
16:17:52 done sampling a new configuration.
16:17:52 HBMASTER: schedule new run for iteration 0
16:17:52 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
16:17:52 HBMASTER: submitting job (0, 0, 9) to dispatcher
16:17:52 DISPATCHER: trying to submit job (0, 0, 9)
16:17:52 DISPATCHER: trying to notify the job_runner thread.
16:17:52 HBMASTER: job (0, 0, 9) submitted to dispatcher
16:17:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:17:52 DISPATCHER: Trying to submit another job.
16:17:52 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:17:52 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:17:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:17:52 WORKER: start processing job (0, 0, 9)
16:17:52 WORKER: args: ()
16:17:52 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0017553987477699727, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.053854543679096166, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 101, 'num_filters_3': 60}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:18:39 DISPATCHER: Starting worker discovery
16:18:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:18:39 DISPATCHER: Finished worker discovery
16:18:54 WORKER: done with job (0, 0, 9), trying to register it.
16:18:54 WORKER: registered result for job (0, 0, 9) with dispatcher
16:18:54 DISPATCHER: job (0, 0, 9) finished
16:18:54 DISPATCHER: register_result: lock acquired
16:18:54 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:18:54 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0017553987477699727, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.053854543679096166, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 101, 'num_filters_3': 60}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1261214728871953, 'info': {'data04': 0.1261214728871953, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0017553987477699727, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.053854543679096166, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 101, 'num_filters_3': 60}"}}
exception: None

16:18:54 job_callback for (0, 0, 9) started
16:18:54 DISPATCHER: Trying to submit another job.
16:18:54 job_callback for (0, 0, 9) got condition
16:18:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:18:54 Only 10 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
16:18:54 HBMASTER: Trying to run another job!
16:18:54 job_callback for (0, 0, 9) finished
16:18:54 start sampling a new configuration.
16:18:54 done sampling a new configuration.
16:18:54 HBMASTER: schedule new run for iteration 0
16:18:54 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
16:18:54 HBMASTER: submitting job (0, 0, 10) to dispatcher
16:18:54 DISPATCHER: trying to submit job (0, 0, 10)
16:18:54 DISPATCHER: trying to notify the job_runner thread.
16:18:54 HBMASTER: job (0, 0, 10) submitted to dispatcher
16:18:54 DISPATCHER: Trying to submit another job.
16:18:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:18:54 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:18:54 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:18:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:18:54 WORKER: start processing job (0, 0, 10)
16:18:54 WORKER: args: ()
16:18:54 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012461151986749013, 'num_filters_1': 123, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.02106746513490477, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 26, 'num_filters_3': 30, 'num_filters_4': 73}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:19:39 DISPATCHER: Starting worker discovery
16:19:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:19:39 DISPATCHER: Finished worker discovery
16:19:57 WORKER: done with job (0, 0, 10), trying to register it.
16:19:57 WORKER: registered result for job (0, 0, 10) with dispatcher
16:19:57 DISPATCHER: job (0, 0, 10) finished
16:19:57 DISPATCHER: register_result: lock acquired
16:19:57 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:19:57 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012461151986749013, 'num_filters_1': 123, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.02106746513490477, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 26, 'num_filters_3': 30, 'num_filters_4': 73}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1374653046363235, 'info': {'data04': 0.1374653046363235, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012461151986749013, 'num_filters_1': 123, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.02106746513490477, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 26, 'num_filters_3': 30, 'num_filters_4': 73}"}}
exception: None

16:19:57 job_callback for (0, 0, 10) started
16:19:57 job_callback for (0, 0, 10) got condition
16:19:57 DISPATCHER: Trying to submit another job.
16:19:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:19:57 Only 11 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
16:19:57 HBMASTER: Trying to run another job!
16:19:57 job_callback for (0, 0, 10) finished
16:19:57 start sampling a new configuration.
16:19:57 done sampling a new configuration.
16:19:57 HBMASTER: schedule new run for iteration 0
16:19:57 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
16:19:57 HBMASTER: submitting job (0, 0, 11) to dispatcher
16:19:57 DISPATCHER: trying to submit job (0, 0, 11)
16:19:57 DISPATCHER: trying to notify the job_runner thread.
16:19:57 HBMASTER: job (0, 0, 11) submitted to dispatcher
16:19:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:19:57 DISPATCHER: Trying to submit another job.
16:19:57 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:19:57 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:19:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:19:57 WORKER: start processing job (0, 0, 11)
16:19:57 WORKER: args: ()
16:19:57 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.017883143208704887, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.06090495711476374}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:20:39 DISPATCHER: Starting worker discovery
16:20:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:20:39 DISPATCHER: Finished worker discovery
16:21:00 WORKER: done with job (0, 0, 11), trying to register it.
16:21:00 WORKER: registered result for job (0, 0, 11) with dispatcher
16:21:00 DISPATCHER: job (0, 0, 11) finished
16:21:00 DISPATCHER: register_result: lock acquired
16:21:00 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:21:00 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.017883143208704887, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.06090495711476374}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.08859806353561889, 'info': {'data04': 0.08859806353561889, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.017883143208704887, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.06090495711476374}"}}
exception: None

16:21:00 job_callback for (0, 0, 11) started
16:21:00 DISPATCHER: Trying to submit another job.
16:21:00 job_callback for (0, 0, 11) got condition
16:21:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:21:00 Only 12 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
16:21:00 HBMASTER: Trying to run another job!
16:21:00 job_callback for (0, 0, 11) finished
16:21:00 start sampling a new configuration.
16:21:00 done sampling a new configuration.
16:21:00 HBMASTER: schedule new run for iteration 0
16:21:00 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
16:21:00 HBMASTER: submitting job (0, 0, 12) to dispatcher
16:21:00 DISPATCHER: trying to submit job (0, 0, 12)
16:21:00 DISPATCHER: trying to notify the job_runner thread.
16:21:00 HBMASTER: job (0, 0, 12) submitted to dispatcher
16:21:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:21:00 DISPATCHER: Trying to submit another job.
16:21:00 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:21:00 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:21:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:21:00 WORKER: start processing job (0, 0, 12)
16:21:00 WORKER: args: ()
16:21:00 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.03929669529688009, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.026570665957920743}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:21:39 DISPATCHER: Starting worker discovery
16:21:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:21:39 DISPATCHER: Finished worker discovery
16:22:01 WORKER: done with job (0, 0, 12), trying to register it.
16:22:01 WORKER: registered result for job (0, 0, 12) with dispatcher
16:22:01 DISPATCHER: job (0, 0, 12) finished
16:22:01 DISPATCHER: register_result: lock acquired
16:22:01 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:22:01 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.03929669529688009, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.026570665957920743}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0843499342622644, 'info': {'data04': 0.0843499342622644, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.03929669529688009, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.026570665957920743}"}}
exception: None

16:22:01 job_callback for (0, 0, 12) started
16:22:01 job_callback for (0, 0, 12) got condition
16:22:01 DISPATCHER: Trying to submit another job.
16:22:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:22:01 Only 13 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
16:22:01 HBMASTER: Trying to run another job!
16:22:01 job_callback for (0, 0, 12) finished
16:22:01 start sampling a new configuration.
16:22:01 done sampling a new configuration.
16:22:01 HBMASTER: schedule new run for iteration 0
16:22:01 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
16:22:01 HBMASTER: submitting job (0, 0, 13) to dispatcher
16:22:01 DISPATCHER: trying to submit job (0, 0, 13)
16:22:01 DISPATCHER: trying to notify the job_runner thread.
16:22:01 HBMASTER: job (0, 0, 13) submitted to dispatcher
16:22:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:22:01 DISPATCHER: Trying to submit another job.
16:22:01 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:22:01 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:22:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:22:01 WORKER: start processing job (0, 0, 13)
16:22:01 WORKER: args: ()
16:22:01 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004311604626381228, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.14710217998330305, 'kernel_size_2': 5, 'num_filters_2': 126}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:22:39 DISPATCHER: Starting worker discovery
16:22:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:22:39 DISPATCHER: Finished worker discovery
16:23:04 WORKER: done with job (0, 0, 13), trying to register it.
16:23:04 WORKER: registered result for job (0, 0, 13) with dispatcher
16:23:04 DISPATCHER: job (0, 0, 13) finished
16:23:04 DISPATCHER: register_result: lock acquired
16:23:04 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:23:04 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004311604626381228, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.14710217998330305, 'kernel_size_2': 5, 'num_filters_2': 126}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.00013832781909817947, 'info': {'data04': 0.00013832781909817947, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004311604626381228, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.14710217998330305, 'kernel_size_2': 5, 'num_filters_2': 126}"}}
exception: None

16:23:04 job_callback for (0, 0, 13) started
16:23:04 job_callback for (0, 0, 13) got condition
16:23:04 DISPATCHER: Trying to submit another job.
16:23:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:23:04 Only 14 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
16:23:04 HBMASTER: Trying to run another job!
16:23:04 job_callback for (0, 0, 13) finished
16:23:04 start sampling a new configuration.
16:23:04 done sampling a new configuration.
16:23:04 HBMASTER: schedule new run for iteration 0
16:23:04 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
16:23:04 HBMASTER: submitting job (0, 0, 14) to dispatcher
16:23:04 DISPATCHER: trying to submit job (0, 0, 14)
16:23:04 DISPATCHER: trying to notify the job_runner thread.
16:23:04 HBMASTER: job (0, 0, 14) submitted to dispatcher
16:23:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:23:04 DISPATCHER: Trying to submit another job.
16:23:04 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:23:04 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:23:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:23:04 WORKER: start processing job (0, 0, 14)
16:23:04 WORKER: args: ()
16:23:04 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0036081184041939353, 'num_filters_1': 19, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.07589944711874404, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 45, 'num_filters_3': 22, 'num_filters_4': 28}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:23:39 DISPATCHER: Starting worker discovery
16:23:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:23:39 DISPATCHER: Finished worker discovery
16:24:05 WORKER: done with job (0, 0, 14), trying to register it.
16:24:05 WORKER: registered result for job (0, 0, 14) with dispatcher
16:24:05 DISPATCHER: job (0, 0, 14) finished
16:24:05 DISPATCHER: register_result: lock acquired
16:24:05 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:24:05 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0036081184041939353, 'num_filters_1': 19, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.07589944711874404, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 45, 'num_filters_3': 22, 'num_filters_4': 28}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0036081184041939353, 'num_filters_1': 19, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.07589944711874404, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 45, 'num_filters_3': 22, 'num_filters_4': 28}"}}
exception: None

16:24:05 job_callback for (0, 0, 14) started
16:24:05 DISPATCHER: Trying to submit another job.
16:24:05 job_callback for (0, 0, 14) got condition
16:24:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:24:05 Only 15 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
16:24:05 HBMASTER: Trying to run another job!
16:24:05 job_callback for (0, 0, 14) finished
16:24:05 start sampling a new configuration.
16:24:05 done sampling a new configuration.
16:24:05 HBMASTER: schedule new run for iteration 0
16:24:05 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
16:24:05 HBMASTER: submitting job (0, 0, 15) to dispatcher
16:24:05 DISPATCHER: trying to submit job (0, 0, 15)
16:24:05 DISPATCHER: trying to notify the job_runner thread.
16:24:05 HBMASTER: job (0, 0, 15) submitted to dispatcher
16:24:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:24:05 DISPATCHER: Trying to submit another job.
16:24:05 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:24:05 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:24:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:24:05 WORKER: start processing job (0, 0, 15)
16:24:05 WORKER: args: ()
16:24:05 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0044224375804824976, 'num_filters_1': 91, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.010787150293859002, 'kernel_size_2': 7, 'num_filters_2': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:24:39 DISPATCHER: Starting worker discovery
16:24:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:24:39 DISPATCHER: Finished worker discovery
16:25:07 WORKER: done with job (0, 0, 15), trying to register it.
16:25:07 WORKER: registered result for job (0, 0, 15) with dispatcher
16:25:07 DISPATCHER: job (0, 0, 15) finished
16:25:07 DISPATCHER: register_result: lock acquired
16:25:07 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:25:07 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0044224375804824976, 'num_filters_1': 91, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.010787150293859002, 'kernel_size_2': 7, 'num_filters_2': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.17306638048719142, 'info': {'data04': 0.17306638048719142, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0044224375804824976, 'num_filters_1': 91, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.010787150293859002, 'kernel_size_2': 7, 'num_filters_2': 18}"}}
exception: None

16:25:07 job_callback for (0, 0, 15) started
16:25:07 DISPATCHER: Trying to submit another job.
16:25:07 job_callback for (0, 0, 15) got condition
16:25:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:25:07 Only 16 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
16:25:07 HBMASTER: Trying to run another job!
16:25:07 job_callback for (0, 0, 15) finished
16:25:07 start sampling a new configuration.
16:25:07 done sampling a new configuration.
16:25:07 HBMASTER: schedule new run for iteration 0
16:25:07 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
16:25:07 HBMASTER: submitting job (0, 0, 16) to dispatcher
16:25:07 DISPATCHER: trying to submit job (0, 0, 16)
16:25:07 DISPATCHER: trying to notify the job_runner thread.
16:25:07 HBMASTER: job (0, 0, 16) submitted to dispatcher
16:25:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:25:07 DISPATCHER: Trying to submit another job.
16:25:07 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:25:07 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:25:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:25:07 WORKER: start processing job (0, 0, 16)
16:25:07 WORKER: args: ()
16:25:07 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.007462506804798212, 'num_filters_1': 54, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.07878244320743923, 'kernel_size_2': 7, 'num_filters_2': 33}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:25:39 DISPATCHER: Starting worker discovery
16:25:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:25:39 DISPATCHER: Finished worker discovery
16:26:07 WORKER: done with job (0, 0, 16), trying to register it.
16:26:07 WORKER: registered result for job (0, 0, 16) with dispatcher
16:26:07 DISPATCHER: job (0, 0, 16) finished
16:26:07 DISPATCHER: register_result: lock acquired
16:26:07 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:26:07 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.007462506804798212, 'num_filters_1': 54, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.07878244320743923, 'kernel_size_2': 7, 'num_filters_2': 33}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.04518890231874027, 'info': {'data04': 0.04518890231874027, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.007462506804798212, 'num_filters_1': 54, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.07878244320743923, 'kernel_size_2': 7, 'num_filters_2': 33}"}}
exception: None

16:26:07 job_callback for (0, 0, 16) started
16:26:07 job_callback for (0, 0, 16) got condition
16:26:07 DISPATCHER: Trying to submit another job.
16:26:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:26:07 HBMASTER: Trying to run another job!
16:26:07 job_callback for (0, 0, 16) finished
16:26:07 start sampling a new configuration.
16:26:07 done sampling a new configuration.
16:26:07 HBMASTER: schedule new run for iteration 0
16:26:07 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
16:26:07 HBMASTER: submitting job (0, 0, 17) to dispatcher
16:26:07 DISPATCHER: trying to submit job (0, 0, 17)
16:26:07 DISPATCHER: trying to notify the job_runner thread.
16:26:07 HBMASTER: job (0, 0, 17) submitted to dispatcher
16:26:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:26:07 DISPATCHER: Trying to submit another job.
16:26:07 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:26:07 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:26:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:26:07 WORKER: start processing job (0, 0, 17)
16:26:07 WORKER: args: ()
16:26:07 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.018274872615197627, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.09732409562678143, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 16, 'num_filters_3': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:26:39 DISPATCHER: Starting worker discovery
16:26:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:26:39 DISPATCHER: Finished worker discovery
16:27:17 WORKER: done with job (0, 0, 17), trying to register it.
16:27:17 WORKER: registered result for job (0, 0, 17) with dispatcher
16:27:17 DISPATCHER: job (0, 0, 17) finished
16:27:17 DISPATCHER: register_result: lock acquired
16:27:17 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:27:17 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.018274872615197627, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.09732409562678143, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 16, 'num_filters_3': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0006865813568408119, 'info': {'data04': 0.0006865813568408119, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.018274872615197627, 'num_filters_1': 22, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.09732409562678143, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 16, 'num_filters_3': 24}"}}
exception: None

16:27:17 job_callback for (0, 0, 17) started
16:27:17 DISPATCHER: Trying to submit another job.
16:27:17 job_callback for (0, 0, 17) got condition
16:27:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:27:17 HBMASTER: Trying to run another job!
16:27:17 job_callback for (0, 0, 17) finished
16:27:17 start sampling a new configuration.
16:27:17 done sampling a new configuration.
16:27:17 HBMASTER: schedule new run for iteration 0
16:27:17 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
16:27:17 HBMASTER: submitting job (0, 0, 18) to dispatcher
16:27:17 DISPATCHER: trying to submit job (0, 0, 18)
16:27:17 DISPATCHER: trying to notify the job_runner thread.
16:27:17 HBMASTER: job (0, 0, 18) submitted to dispatcher
16:27:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:27:17 DISPATCHER: Trying to submit another job.
16:27:17 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:27:17 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:27:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:27:17 WORKER: start processing job (0, 0, 18)
16:27:17 WORKER: args: ()
16:27:17 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.004323867715896891, 'num_filters_1': 60, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.15948239024254224, 'kernel_size_2': 3, 'num_filters_2': 65}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:27:39 DISPATCHER: Starting worker discovery
16:27:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:27:39 DISPATCHER: Finished worker discovery
16:28:19 WORKER: done with job (0, 0, 18), trying to register it.
16:28:19 WORKER: registered result for job (0, 0, 18) with dispatcher
16:28:19 DISPATCHER: job (0, 0, 18) finished
16:28:19 DISPATCHER: register_result: lock acquired
16:28:19 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:28:19 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.004323867715896891, 'num_filters_1': 60, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.15948239024254224, 'kernel_size_2': 3, 'num_filters_2': 65}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.005589102700206473, 'info': {'data04': 0.005589102700206473, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.004323867715896891, 'num_filters_1': 60, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.15948239024254224, 'kernel_size_2': 3, 'num_filters_2': 65}"}}
exception: None

16:28:19 job_callback for (0, 0, 18) started
16:28:19 DISPATCHER: Trying to submit another job.
16:28:19 job_callback for (0, 0, 18) got condition
16:28:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:28:19 HBMASTER: Trying to run another job!
16:28:19 job_callback for (0, 0, 18) finished
16:28:19 start sampling a new configuration.
16:28:19 done sampling a new configuration.
16:28:19 HBMASTER: schedule new run for iteration 0
16:28:19 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
16:28:19 HBMASTER: submitting job (0, 0, 19) to dispatcher
16:28:19 DISPATCHER: trying to submit job (0, 0, 19)
16:28:19 DISPATCHER: trying to notify the job_runner thread.
16:28:19 HBMASTER: job (0, 0, 19) submitted to dispatcher
16:28:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:28:19 DISPATCHER: Trying to submit another job.
16:28:19 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:28:19 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:28:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:28:19 WORKER: start processing job (0, 0, 19)
16:28:19 WORKER: args: ()
16:28:19 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.00528185749155362, 'num_filters_1': 69, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.08458420487163115, 'kernel_size_2': 7, 'num_filters_2': 101}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:28:39 DISPATCHER: Starting worker discovery
16:28:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:28:39 DISPATCHER: Finished worker discovery
16:29:28 WORKER: done with job (0, 0, 19), trying to register it.
16:29:28 WORKER: registered result for job (0, 0, 19) with dispatcher
16:29:28 DISPATCHER: job (0, 0, 19) finished
16:29:28 DISPATCHER: register_result: lock acquired
16:29:28 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:29:28 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.00528185749155362, 'num_filters_1': 69, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.08458420487163115, 'kernel_size_2': 7, 'num_filters_2': 101}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.03023559540045128, 'info': {'data04': 0.03023559540045128, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.00528185749155362, 'num_filters_1': 69, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.08458420487163115, 'kernel_size_2': 7, 'num_filters_2': 101}"}}
exception: None

16:29:28 job_callback for (0, 0, 19) started
16:29:28 DISPATCHER: Trying to submit another job.
16:29:28 job_callback for (0, 0, 19) got condition
16:29:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:29:28 HBMASTER: Trying to run another job!
16:29:28 job_callback for (0, 0, 19) finished
16:29:28 start sampling a new configuration.
16:29:28 done sampling a new configuration.
16:29:28 HBMASTER: schedule new run for iteration 0
16:29:28 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
16:29:28 HBMASTER: submitting job (0, 0, 20) to dispatcher
16:29:28 DISPATCHER: trying to submit job (0, 0, 20)
16:29:28 DISPATCHER: trying to notify the job_runner thread.
16:29:28 HBMASTER: job (0, 0, 20) submitted to dispatcher
16:29:28 DISPATCHER: Trying to submit another job.
16:29:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:29:28 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:29:28 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:29:28 WORKER: start processing job (0, 0, 20)
16:29:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:29:28 WORKER: args: ()
16:29:28 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.001016116880577936, 'num_filters_1': 35, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.0637627880770341, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 61, 'num_filters_3': 26, 'num_filters_4': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:29:39 DISPATCHER: Starting worker discovery
16:29:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:29:39 DISPATCHER: Finished worker discovery
16:30:31 WORKER: done with job (0, 0, 20), trying to register it.
16:30:31 WORKER: registered result for job (0, 0, 20) with dispatcher
16:30:31 DISPATCHER: job (0, 0, 20) finished
16:30:31 DISPATCHER: register_result: lock acquired
16:30:31 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:30:31 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.001016116880577936, 'num_filters_1': 35, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.0637627880770341, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 61, 'num_filters_3': 26, 'num_filters_4': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0018733535206987804, 'info': {'data04': 0.0018733535206987804, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.001016116880577936, 'num_filters_1': 35, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.0637627880770341, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 61, 'num_filters_3': 26, 'num_filters_4': 44}"}}
exception: None

16:30:31 job_callback for (0, 0, 20) started
16:30:31 DISPATCHER: Trying to submit another job.
16:30:31 job_callback for (0, 0, 20) got condition
16:30:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:30:31 HBMASTER: Trying to run another job!
16:30:31 job_callback for (0, 0, 20) finished
16:30:31 start sampling a new configuration.
16:30:31 done sampling a new configuration.
16:30:31 HBMASTER: schedule new run for iteration 0
16:30:31 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
16:30:31 HBMASTER: submitting job (0, 0, 21) to dispatcher
16:30:31 DISPATCHER: trying to submit job (0, 0, 21)
16:30:31 DISPATCHER: trying to notify the job_runner thread.
16:30:31 HBMASTER: job (0, 0, 21) submitted to dispatcher
16:30:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:30:31 DISPATCHER: Trying to submit another job.
16:30:31 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:30:31 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:30:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:30:31 WORKER: start processing job (0, 0, 21)
16:30:31 WORKER: args: ()
16:30:31 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0014895483386087882, 'num_filters_1': 21, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.05220012457651198, 'kernel_size_2': 5, 'num_filters_2': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:30:39 DISPATCHER: Starting worker discovery
16:30:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:30:39 DISPATCHER: Finished worker discovery
16:31:36 WORKER: done with job (0, 0, 21), trying to register it.
16:31:36 WORKER: registered result for job (0, 0, 21) with dispatcher
16:31:36 DISPATCHER: job (0, 0, 21) finished
16:31:36 DISPATCHER: register_result: lock acquired
16:31:36 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:31:36 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0014895483386087882, 'num_filters_1': 21, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.05220012457651198, 'kernel_size_2': 5, 'num_filters_2': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.11007762029755061, 'info': {'data04': 0.11007762029755061, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0014895483386087882, 'num_filters_1': 21, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.05220012457651198, 'kernel_size_2': 5, 'num_filters_2': 20}"}}
exception: None

16:31:36 job_callback for (0, 0, 21) started
16:31:36 job_callback for (0, 0, 21) got condition
16:31:36 DISPATCHER: Trying to submit another job.
16:31:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:31:36 HBMASTER: Trying to run another job!
16:31:36 job_callback for (0, 0, 21) finished
16:31:36 start sampling a new configuration.
16:31:36 done sampling a new configuration.
16:31:36 HBMASTER: schedule new run for iteration 0
16:31:36 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
16:31:36 HBMASTER: submitting job (0, 0, 22) to dispatcher
16:31:36 DISPATCHER: trying to submit job (0, 0, 22)
16:31:36 DISPATCHER: trying to notify the job_runner thread.
16:31:36 HBMASTER: job (0, 0, 22) submitted to dispatcher
16:31:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:31:36 DISPATCHER: Trying to submit another job.
16:31:36 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:31:36 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:31:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:31:36 WORKER: start processing job (0, 0, 22)
16:31:36 WORKER: args: ()
16:31:36 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0021120792317803803, 'num_filters_1': 94, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.04305217969278708, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 42, 'num_filters_3': 26, 'num_filters_4': 72, 'num_filters_5': 96}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:31:39 DISPATCHER: Starting worker discovery
16:31:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:31:39 DISPATCHER: Finished worker discovery
16:32:36 WORKER: done with job (0, 0, 22), trying to register it.
16:32:36 WORKER: registered result for job (0, 0, 22) with dispatcher
16:32:36 DISPATCHER: job (0, 0, 22) finished
16:32:36 DISPATCHER: register_result: lock acquired
16:32:36 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:32:36 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0021120792317803803, 'num_filters_1': 94, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.04305217969278708, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 42, 'num_filters_3': 26, 'num_filters_4': 72, 'num_filters_5': 96}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0003819451482472056, 'info': {'data04': 0.0003819451482472056, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0021120792317803803, 'num_filters_1': 94, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 96, 'weight_decay': 0.04305217969278708, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 42, 'num_filters_3': 26, 'num_filters_4': 72, 'num_filters_5': 96}"}}
exception: None

16:32:36 job_callback for (0, 0, 22) started
16:32:36 DISPATCHER: Trying to submit another job.
16:32:36 job_callback for (0, 0, 22) got condition
16:32:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:32:36 HBMASTER: Trying to run another job!
16:32:36 job_callback for (0, 0, 22) finished
16:32:36 start sampling a new configuration.
16:32:36 done sampling a new configuration.
16:32:36 HBMASTER: schedule new run for iteration 0
16:32:36 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
16:32:36 HBMASTER: submitting job (0, 0, 23) to dispatcher
16:32:36 DISPATCHER: trying to submit job (0, 0, 23)
16:32:36 DISPATCHER: trying to notify the job_runner thread.
16:32:36 HBMASTER: job (0, 0, 23) submitted to dispatcher
16:32:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:32:36 DISPATCHER: Trying to submit another job.
16:32:36 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:32:36 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:32:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:32:36 WORKER: start processing job (0, 0, 23)
16:32:36 WORKER: args: ()
16:32:36 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.025223126249188082, 'num_filters_1': 24, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.16790808798359358, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 22, 'num_filters_3': 110, 'num_filters_4': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:32:39 DISPATCHER: Starting worker discovery
16:32:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:32:39 DISPATCHER: Finished worker discovery
16:33:37 WORKER: done with job (0, 0, 23), trying to register it.
16:33:37 WORKER: registered result for job (0, 0, 23) with dispatcher
16:33:37 DISPATCHER: job (0, 0, 23) finished
16:33:37 DISPATCHER: register_result: lock acquired
16:33:37 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:33:37 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.025223126249188082, 'num_filters_1': 24, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.16790808798359358, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 22, 'num_filters_3': 110, 'num_filters_4': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.0012246312783050703, 'info': {'data04': -0.0012246312783050703, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.025223126249188082, 'num_filters_1': 24, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.16790808798359358, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 22, 'num_filters_3': 110, 'num_filters_4': 27}"}}
exception: None

16:33:37 job_callback for (0, 0, 23) started
16:33:37 job_callback for (0, 0, 23) got condition
16:33:37 DISPATCHER: Trying to submit another job.
16:33:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:33:37 HBMASTER: Trying to run another job!
16:33:37 job_callback for (0, 0, 23) finished
16:33:37 start sampling a new configuration.
16:33:37 done sampling a new configuration.
16:33:37 HBMASTER: schedule new run for iteration 0
16:33:37 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
16:33:37 HBMASTER: submitting job (0, 0, 24) to dispatcher
16:33:37 DISPATCHER: trying to submit job (0, 0, 24)
16:33:37 DISPATCHER: trying to notify the job_runner thread.
16:33:37 HBMASTER: job (0, 0, 24) submitted to dispatcher
16:33:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:33:37 DISPATCHER: Trying to submit another job.
16:33:37 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:33:37 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:33:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:33:37 WORKER: start processing job (0, 0, 24)
16:33:37 WORKER: args: ()
16:33:37 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.04456115178315119, 'num_filters_1': 43, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.01863668319673775}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:33:39 DISPATCHER: Starting worker discovery
16:33:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:33:39 DISPATCHER: Finished worker discovery
16:34:39 WORKER: done with job (0, 0, 24), trying to register it.
16:34:39 WORKER: registered result for job (0, 0, 24) with dispatcher
16:34:39 DISPATCHER: job (0, 0, 24) finished
16:34:39 DISPATCHER: register_result: lock acquired
16:34:39 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:34:39 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.04456115178315119, 'num_filters_1': 43, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.01863668319673775}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.011499862003086357, 'info': {'data04': 0.011499862003086357, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.04456115178315119, 'num_filters_1': 43, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.01863668319673775}"}}
exception: None

16:34:39 job_callback for (0, 0, 24) started
16:34:39 DISPATCHER: Trying to submit another job.
16:34:39 job_callback for (0, 0, 24) got condition
16:34:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:34:39 HBMASTER: Trying to run another job!
16:34:39 job_callback for (0, 0, 24) finished
16:34:39 start sampling a new configuration.
16:34:39 done sampling a new configuration.
16:34:39 HBMASTER: schedule new run for iteration 0
16:34:39 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
16:34:39 HBMASTER: submitting job (0, 0, 25) to dispatcher
16:34:39 DISPATCHER: trying to submit job (0, 0, 25)
16:34:39 DISPATCHER: trying to notify the job_runner thread.
16:34:39 HBMASTER: job (0, 0, 25) submitted to dispatcher
16:34:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:34:39 DISPATCHER: Trying to submit another job.
16:34:39 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:34:39 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:34:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:34:39 WORKER: start processing job (0, 0, 25)
16:34:39 WORKER: args: ()
16:34:39 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.027347328305688534, 'num_filters_1': 98, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.12126345644036637, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 21, 'num_filters_3': 51, 'num_filters_4': 105, 'num_filters_5': 82}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:34:39 DISPATCHER: Starting worker discovery
16:34:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:34:39 DISPATCHER: Finished worker discovery
16:35:39 DISPATCHER: Starting worker discovery
16:35:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:35:40 DISPATCHER: Finished worker discovery
16:35:44 WORKER: done with job (0, 0, 25), trying to register it.
16:35:44 WORKER: registered result for job (0, 0, 25) with dispatcher
16:35:44 DISPATCHER: job (0, 0, 25) finished
16:35:44 DISPATCHER: register_result: lock acquired
16:35:44 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:35:44 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.027347328305688534, 'num_filters_1': 98, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.12126345644036637, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 21, 'num_filters_3': 51, 'num_filters_4': 105, 'num_filters_5': 82}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.027347328305688534, 'num_filters_1': 98, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.12126345644036637, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 21, 'num_filters_3': 51, 'num_filters_4': 105, 'num_filters_5': 82}"}}
exception: None

16:35:44 job_callback for (0, 0, 25) started
16:35:44 DISPATCHER: Trying to submit another job.
16:35:44 job_callback for (0, 0, 25) got condition
16:35:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:35:44 HBMASTER: Trying to run another job!
16:35:44 job_callback for (0, 0, 25) finished
16:35:44 start sampling a new configuration.
16:35:44 done sampling a new configuration.
16:35:44 HBMASTER: schedule new run for iteration 0
16:35:44 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
16:35:44 HBMASTER: submitting job (0, 0, 26) to dispatcher
16:35:44 DISPATCHER: trying to submit job (0, 0, 26)
16:35:44 DISPATCHER: trying to notify the job_runner thread.
16:35:44 HBMASTER: job (0, 0, 26) submitted to dispatcher
16:35:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:35:44 DISPATCHER: Trying to submit another job.
16:35:44 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:35:44 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:35:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:35:44 WORKER: start processing job (0, 0, 26)
16:35:44 WORKER: args: ()
16:35:44 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.030603461930959166, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.014275062004191586, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 84, 'num_filters_3': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
16:36:40 DISPATCHER: Starting worker discovery
16:36:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:36:40 DISPATCHER: Finished worker discovery
16:36:44 WORKER: done with job (0, 0, 26), trying to register it.
16:36:44 WORKER: registered result for job (0, 0, 26) with dispatcher
16:36:44 DISPATCHER: job (0, 0, 26) finished
16:36:44 DISPATCHER: register_result: lock acquired
16:36:44 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:36:44 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.030603461930959166, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.014275062004191586, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 84, 'num_filters_3': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.00041241293724157056, 'info': {'data04': 0.00041241293724157056, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.030603461930959166, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.014275062004191586, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 84, 'num_filters_3': 23}"}}
exception: None

16:36:44 job_callback for (0, 0, 26) started
16:36:44 DISPATCHER: Trying to submit another job.
16:36:44 job_callback for (0, 0, 26) got condition
16:36:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:36:44 HBMASTER: Trying to run another job!
16:36:44 job_callback for (0, 0, 26) finished
16:36:44 ITERATION: Advancing config (0, 0, 1) to next budget 133.333333
16:36:44 ITERATION: Advancing config (0, 0, 4) to next budget 133.333333
16:36:44 ITERATION: Advancing config (0, 0, 6) to next budget 133.333333
16:36:44 ITERATION: Advancing config (0, 0, 9) to next budget 133.333333
16:36:44 ITERATION: Advancing config (0, 0, 10) to next budget 133.333333
16:36:44 ITERATION: Advancing config (0, 0, 11) to next budget 133.333333
16:36:44 ITERATION: Advancing config (0, 0, 12) to next budget 133.333333
16:36:44 ITERATION: Advancing config (0, 0, 15) to next budget 133.333333
16:36:44 ITERATION: Advancing config (0, 0, 21) to next budget 133.333333
16:36:44 HBMASTER: schedule new run for iteration 0
16:36:44 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
16:36:44 HBMASTER: submitting job (0, 0, 1) to dispatcher
16:36:44 DISPATCHER: trying to submit job (0, 0, 1)
16:36:44 DISPATCHER: trying to notify the job_runner thread.
16:36:44 HBMASTER: job (0, 0, 1) submitted to dispatcher
16:36:44 DISPATCHER: Trying to submit another job.
16:36:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:36:44 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:36:44 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:36:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:36:44 WORKER: start processing job (0, 0, 1)
16:36:44 WORKER: args: ()
16:36:44 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0020552740258678133, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.08256069330332905, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 95, 'num_filters_3': 34, 'num_filters_4': 67}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:37:40 DISPATCHER: Starting worker discovery
16:37:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:37:40 DISPATCHER: Finished worker discovery
16:38:40 DISPATCHER: Starting worker discovery
16:38:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:38:40 DISPATCHER: Finished worker discovery
16:39:20 WORKER: done with job (0, 0, 1), trying to register it.
16:39:20 WORKER: registered result for job (0, 0, 1) with dispatcher
16:39:20 DISPATCHER: job (0, 0, 1) finished
16:39:20 DISPATCHER: register_result: lock acquired
16:39:20 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:39:20 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0020552740258678133, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.08256069330332905, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 95, 'num_filters_3': 34, 'num_filters_4': 67}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.018987334764397505, 'info': {'data04': 0.018987334764397505, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0020552740258678133, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.08256069330332905, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 95, 'num_filters_3': 34, 'num_filters_4': 67}"}}
exception: None

16:39:20 job_callback for (0, 0, 1) started
16:39:20 DISPATCHER: Trying to submit another job.
16:39:20 job_callback for (0, 0, 1) got condition
16:39:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:39:20 Only 1 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
16:39:20 HBMASTER: Trying to run another job!
16:39:20 job_callback for (0, 0, 1) finished
16:39:20 HBMASTER: schedule new run for iteration 0
16:39:20 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
16:39:20 HBMASTER: submitting job (0, 0, 4) to dispatcher
16:39:20 DISPATCHER: trying to submit job (0, 0, 4)
16:39:20 DISPATCHER: trying to notify the job_runner thread.
16:39:20 HBMASTER: job (0, 0, 4) submitted to dispatcher
16:39:20 DISPATCHER: Trying to submit another job.
16:39:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:39:20 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:39:20 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:39:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:39:20 WORKER: start processing job (0, 0, 4)
16:39:20 WORKER: args: ()
16:39:20 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.054708261357100454, 'num_filters_1': 78, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.01507169740128756, 'kernel_size_2': 3, 'num_filters_2': 30}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:39:40 DISPATCHER: Starting worker discovery
16:39:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:39:40 DISPATCHER: Finished worker discovery
16:40:40 DISPATCHER: Starting worker discovery
16:40:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:40:40 DISPATCHER: Finished worker discovery
16:41:40 DISPATCHER: Starting worker discovery
16:41:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:41:40 DISPATCHER: Finished worker discovery
16:42:01 WORKER: done with job (0, 0, 4), trying to register it.
16:42:01 WORKER: registered result for job (0, 0, 4) with dispatcher
16:42:01 DISPATCHER: job (0, 0, 4) finished
16:42:01 DISPATCHER: register_result: lock acquired
16:42:01 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:42:01 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.054708261357100454, 'num_filters_1': 78, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.01507169740128756, 'kernel_size_2': 3, 'num_filters_2': 30}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.05292128254825533, 'info': {'data04': 0.05292128254825533, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.054708261357100454, 'num_filters_1': 78, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.01507169740128756, 'kernel_size_2': 3, 'num_filters_2': 30}"}}
exception: None

16:42:01 job_callback for (0, 0, 4) started
16:42:01 DISPATCHER: Trying to submit another job.
16:42:01 job_callback for (0, 0, 4) got condition
16:42:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:42:01 Only 2 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
16:42:01 HBMASTER: Trying to run another job!
16:42:01 job_callback for (0, 0, 4) finished
16:42:01 HBMASTER: schedule new run for iteration 0
16:42:01 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
16:42:01 HBMASTER: submitting job (0, 0, 6) to dispatcher
16:42:01 DISPATCHER: trying to submit job (0, 0, 6)
16:42:01 DISPATCHER: trying to notify the job_runner thread.
16:42:01 HBMASTER: job (0, 0, 6) submitted to dispatcher
16:42:01 DISPATCHER: Trying to submit another job.
16:42:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:42:01 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:42:01 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:42:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:42:01 WORKER: start processing job (0, 0, 6)
16:42:01 WORKER: args: ()
16:42:01 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0012595272977388803, 'num_filters_1': 28, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.08131332156642622, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 126, 'num_filters_3': 62, 'num_filters_4': 97}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:42:40 DISPATCHER: Starting worker discovery
16:42:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:42:40 DISPATCHER: Finished worker discovery
16:43:40 DISPATCHER: Starting worker discovery
16:43:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:43:40 DISPATCHER: Finished worker discovery
16:44:33 WORKER: done with job (0, 0, 6), trying to register it.
16:44:33 WORKER: registered result for job (0, 0, 6) with dispatcher
16:44:33 DISPATCHER: job (0, 0, 6) finished
16:44:33 DISPATCHER: register_result: lock acquired
16:44:33 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:44:33 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0012595272977388803, 'num_filters_1': 28, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.08131332156642622, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 126, 'num_filters_3': 62, 'num_filters_4': 97}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.07587907642834191, 'info': {'data04': 0.07587907642834191, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0012595272977388803, 'num_filters_1': 28, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.08131332156642622, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 126, 'num_filters_3': 62, 'num_filters_4': 97}"}}
exception: None

16:44:33 job_callback for (0, 0, 6) started
16:44:33 DISPATCHER: Trying to submit another job.
16:44:33 job_callback for (0, 0, 6) got condition
16:44:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:44:33 Only 3 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
16:44:33 HBMASTER: Trying to run another job!
16:44:33 job_callback for (0, 0, 6) finished
16:44:33 HBMASTER: schedule new run for iteration 0
16:44:33 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
16:44:33 HBMASTER: submitting job (0, 0, 9) to dispatcher
16:44:33 DISPATCHER: trying to submit job (0, 0, 9)
16:44:33 DISPATCHER: trying to notify the job_runner thread.
16:44:33 HBMASTER: job (0, 0, 9) submitted to dispatcher
16:44:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:44:33 DISPATCHER: Trying to submit another job.
16:44:33 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:44:33 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:44:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:44:33 WORKER: start processing job (0, 0, 9)
16:44:33 WORKER: args: ()
16:44:33 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0017553987477699727, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.053854543679096166, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 101, 'num_filters_3': 60}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:44:40 DISPATCHER: Starting worker discovery
16:44:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:44:40 DISPATCHER: Finished worker discovery
16:45:40 DISPATCHER: Starting worker discovery
16:45:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:45:40 DISPATCHER: Finished worker discovery
16:46:40 DISPATCHER: Starting worker discovery
16:46:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:46:40 DISPATCHER: Finished worker discovery
16:47:09 WORKER: done with job (0, 0, 9), trying to register it.
16:47:09 WORKER: registered result for job (0, 0, 9) with dispatcher
16:47:09 DISPATCHER: job (0, 0, 9) finished
16:47:09 DISPATCHER: register_result: lock acquired
16:47:09 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:47:09 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0017553987477699727, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.053854543679096166, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 101, 'num_filters_3': 60}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.11024768431259477, 'info': {'data04': 0.11024768431259477, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0017553987477699727, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.053854543679096166, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 101, 'num_filters_3': 60}"}}
exception: None

16:47:09 job_callback for (0, 0, 9) started
16:47:09 job_callback for (0, 0, 9) got condition
16:47:09 DISPATCHER: Trying to submit another job.
16:47:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:47:09 Only 4 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
16:47:09 HBMASTER: Trying to run another job!
16:47:09 job_callback for (0, 0, 9) finished
16:47:09 HBMASTER: schedule new run for iteration 0
16:47:09 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
16:47:09 HBMASTER: submitting job (0, 0, 10) to dispatcher
16:47:09 DISPATCHER: trying to submit job (0, 0, 10)
16:47:09 DISPATCHER: trying to notify the job_runner thread.
16:47:09 HBMASTER: job (0, 0, 10) submitted to dispatcher
16:47:09 DISPATCHER: Trying to submit another job.
16:47:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:47:09 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:47:09 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:47:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:47:09 WORKER: start processing job (0, 0, 10)
16:47:09 WORKER: args: ()
16:47:09 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012461151986749013, 'num_filters_1': 123, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.02106746513490477, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 26, 'num_filters_3': 30, 'num_filters_4': 73}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:47:40 DISPATCHER: Starting worker discovery
16:47:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:47:40 DISPATCHER: Finished worker discovery
16:48:40 DISPATCHER: Starting worker discovery
16:48:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:48:40 DISPATCHER: Finished worker discovery
16:49:40 DISPATCHER: Starting worker discovery
16:49:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:49:40 DISPATCHER: Finished worker discovery
16:49:53 WORKER: done with job (0, 0, 10), trying to register it.
16:49:53 WORKER: registered result for job (0, 0, 10) with dispatcher
16:49:53 DISPATCHER: job (0, 0, 10) finished
16:49:53 DISPATCHER: register_result: lock acquired
16:49:53 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:49:53 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012461151986749013, 'num_filters_1': 123, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.02106746513490477, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 26, 'num_filters_3': 30, 'num_filters_4': 73}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.06486975752967891, 'info': {'data04': 0.06486975752967891, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012461151986749013, 'num_filters_1': 123, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.02106746513490477, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 26, 'num_filters_3': 30, 'num_filters_4': 73}"}}
exception: None

16:49:53 job_callback for (0, 0, 10) started
16:49:53 DISPATCHER: Trying to submit another job.
16:49:53 job_callback for (0, 0, 10) got condition
16:49:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:49:53 Only 5 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
16:49:53 HBMASTER: Trying to run another job!
16:49:53 job_callback for (0, 0, 10) finished
16:49:53 HBMASTER: schedule new run for iteration 0
16:49:53 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
16:49:53 HBMASTER: submitting job (0, 0, 11) to dispatcher
16:49:53 DISPATCHER: trying to submit job (0, 0, 11)
16:49:53 DISPATCHER: trying to notify the job_runner thread.
16:49:53 HBMASTER: job (0, 0, 11) submitted to dispatcher
16:49:53 DISPATCHER: Trying to submit another job.
16:49:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:49:53 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:49:53 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:49:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:49:53 WORKER: start processing job (0, 0, 11)
16:49:53 WORKER: args: ()
16:49:53 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.017883143208704887, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.06090495711476374}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:50:40 DISPATCHER: Starting worker discovery
16:50:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:50:40 DISPATCHER: Finished worker discovery
16:51:40 DISPATCHER: Starting worker discovery
16:51:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:51:40 DISPATCHER: Finished worker discovery
16:52:38 WORKER: done with job (0, 0, 11), trying to register it.
16:52:38 WORKER: registered result for job (0, 0, 11) with dispatcher
16:52:38 DISPATCHER: job (0, 0, 11) finished
16:52:38 DISPATCHER: register_result: lock acquired
16:52:38 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:52:38 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.017883143208704887, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.06090495711476374}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.08481013305638946, 'info': {'data04': 0.08481013305638946, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.017883143208704887, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.06090495711476374}"}}
exception: None

16:52:38 job_callback for (0, 0, 11) started
16:52:38 DISPATCHER: Trying to submit another job.
16:52:38 job_callback for (0, 0, 11) got condition
16:52:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:52:38 Only 6 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
16:52:38 HBMASTER: Trying to run another job!
16:52:38 job_callback for (0, 0, 11) finished
16:52:38 HBMASTER: schedule new run for iteration 0
16:52:38 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
16:52:38 HBMASTER: submitting job (0, 0, 12) to dispatcher
16:52:38 DISPATCHER: trying to submit job (0, 0, 12)
16:52:38 DISPATCHER: trying to notify the job_runner thread.
16:52:38 HBMASTER: job (0, 0, 12) submitted to dispatcher
16:52:38 DISPATCHER: Trying to submit another job.
16:52:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:52:38 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:52:38 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:52:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:52:38 WORKER: start processing job (0, 0, 12)
16:52:38 WORKER: args: ()
16:52:38 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.03929669529688009, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.026570665957920743}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:52:40 DISPATCHER: Starting worker discovery
16:52:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:52:40 DISPATCHER: Finished worker discovery
16:53:40 DISPATCHER: Starting worker discovery
16:53:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:53:40 DISPATCHER: Finished worker discovery
16:54:40 DISPATCHER: Starting worker discovery
16:54:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:54:40 DISPATCHER: Finished worker discovery
16:55:17 WORKER: done with job (0, 0, 12), trying to register it.
16:55:17 WORKER: registered result for job (0, 0, 12) with dispatcher
16:55:17 DISPATCHER: job (0, 0, 12) finished
16:55:17 DISPATCHER: register_result: lock acquired
16:55:17 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:55:17 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.03929669529688009, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.026570665957920743}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1070587476175602, 'info': {'data04': 0.1070587476175602, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.03929669529688009, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.026570665957920743}"}}
exception: None

16:55:17 job_callback for (0, 0, 12) started
16:55:17 DISPATCHER: Trying to submit another job.
16:55:17 job_callback for (0, 0, 12) got condition
16:55:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:55:17 Only 7 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
16:55:17 HBMASTER: Trying to run another job!
16:55:17 job_callback for (0, 0, 12) finished
16:55:17 HBMASTER: schedule new run for iteration 0
16:55:17 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
16:55:17 HBMASTER: submitting job (0, 0, 15) to dispatcher
16:55:17 DISPATCHER: trying to submit job (0, 0, 15)
16:55:17 DISPATCHER: trying to notify the job_runner thread.
16:55:17 HBMASTER: job (0, 0, 15) submitted to dispatcher
16:55:17 DISPATCHER: Trying to submit another job.
16:55:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:55:17 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:55:17 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:55:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:55:17 WORKER: start processing job (0, 0, 15)
16:55:17 WORKER: args: ()
16:55:17 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0044224375804824976, 'num_filters_1': 91, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.010787150293859002, 'kernel_size_2': 7, 'num_filters_2': 18}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:55:40 DISPATCHER: Starting worker discovery
16:55:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:55:40 DISPATCHER: Finished worker discovery
16:56:40 DISPATCHER: Starting worker discovery
16:56:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:56:40 DISPATCHER: Finished worker discovery
16:57:40 DISPATCHER: Starting worker discovery
16:57:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:57:40 DISPATCHER: Finished worker discovery
16:57:57 WORKER: done with job (0, 0, 15), trying to register it.
16:57:57 WORKER: registered result for job (0, 0, 15) with dispatcher
16:57:57 DISPATCHER: job (0, 0, 15) finished
16:57:57 DISPATCHER: register_result: lock acquired
16:57:57 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
16:57:57 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0044224375804824976, 'num_filters_1': 91, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.010787150293859002, 'kernel_size_2': 7, 'num_filters_2': 18}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.16116091675076316, 'info': {'data04': 0.16116091675076316, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0044224375804824976, 'num_filters_1': 91, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.010787150293859002, 'kernel_size_2': 7, 'num_filters_2': 18}"}}
exception: None

16:57:57 job_callback for (0, 0, 15) started
16:57:57 DISPATCHER: Trying to submit another job.
16:57:57 job_callback for (0, 0, 15) got condition
16:57:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:57:57 Only 8 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
16:57:57 HBMASTER: Trying to run another job!
16:57:57 job_callback for (0, 0, 15) finished
16:57:57 HBMASTER: schedule new run for iteration 0
16:57:57 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
16:57:57 HBMASTER: submitting job (0, 0, 21) to dispatcher
16:57:57 DISPATCHER: trying to submit job (0, 0, 21)
16:57:57 DISPATCHER: trying to notify the job_runner thread.
16:57:57 HBMASTER: job (0, 0, 21) submitted to dispatcher
16:57:57 DISPATCHER: Trying to submit another job.
16:57:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:57:57 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:57:57 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
16:57:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:57:57 WORKER: start processing job (0, 0, 21)
16:57:57 WORKER: args: ()
16:57:57 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0014895483386087882, 'num_filters_1': 21, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.05220012457651198, 'kernel_size_2': 5, 'num_filters_2': 20}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:58:40 DISPATCHER: Starting worker discovery
16:58:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:58:40 DISPATCHER: Finished worker discovery
16:59:40 DISPATCHER: Starting worker discovery
16:59:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:59:40 DISPATCHER: Finished worker discovery
17:00:40 DISPATCHER: Starting worker discovery
17:00:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:00:40 DISPATCHER: Finished worker discovery
17:00:44 WORKER: done with job (0, 0, 21), trying to register it.
17:00:44 WORKER: registered result for job (0, 0, 21) with dispatcher
17:00:44 DISPATCHER: job (0, 0, 21) finished
17:00:44 DISPATCHER: register_result: lock acquired
17:00:44 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
17:00:44 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0014895483386087882, 'num_filters_1': 21, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.05220012457651198, 'kernel_size_2': 5, 'num_filters_2': 20}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.09419325843497244, 'info': {'data04': 0.09419325843497244, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0014895483386087882, 'num_filters_1': 21, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.05220012457651198, 'kernel_size_2': 5, 'num_filters_2': 20}"}}
exception: None

17:00:44 job_callback for (0, 0, 21) started
17:00:44 DISPATCHER: Trying to submit another job.
17:00:44 job_callback for (0, 0, 21) got condition
17:00:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:00:44 Only 9 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
17:00:44 HBMASTER: Trying to run another job!
17:00:44 job_callback for (0, 0, 21) finished
17:00:44 ITERATION: Advancing config (0, 0, 9) to next budget 400.000000
17:00:44 ITERATION: Advancing config (0, 0, 12) to next budget 400.000000
17:00:44 ITERATION: Advancing config (0, 0, 15) to next budget 400.000000
17:00:44 HBMASTER: schedule new run for iteration 0
17:00:44 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
17:00:44 HBMASTER: submitting job (0, 0, 9) to dispatcher
17:00:44 DISPATCHER: trying to submit job (0, 0, 9)
17:00:44 DISPATCHER: trying to notify the job_runner thread.
17:00:44 HBMASTER: job (0, 0, 9) submitted to dispatcher
17:00:44 DISPATCHER: Trying to submit another job.
17:00:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:00:44 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.13102140436472194880
17:00:44 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
17:00:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:00:44 WORKER: start processing job (0, 0, 9)
17:00:44 WORKER: args: ()
17:00:44 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0017553987477699727, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.053854543679096166, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 101, 'num_filters_3': 60}, 'budget': 400.0, 'working_directory': '.'}
17:01:40 DISPATCHER: Starting worker discovery
17:01:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:01:40 DISPATCHER: Finished worker discovery
17:02:40 DISPATCHER: Starting worker discovery
17:02:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:02:40 DISPATCHER: Finished worker discovery
17:03:40 DISPATCHER: Starting worker discovery
17:03:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:03:40 DISPATCHER: Finished worker discovery
17:04:40 DISPATCHER: Starting worker discovery
17:04:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:04:40 DISPATCHER: Finished worker discovery
17:05:40 DISPATCHER: Starting worker discovery
17:05:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:05:40 DISPATCHER: Finished worker discovery
17:06:40 DISPATCHER: Starting worker discovery
17:06:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:06:40 DISPATCHER: Finished worker discovery
17:07:40 DISPATCHER: Starting worker discovery
17:07:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:07:40 DISPATCHER: Finished worker discovery
17:08:01 WORKER: done with job (0, 0, 9), trying to register it.
17:08:01 WORKER: registered result for job (0, 0, 9) with dispatcher
17:08:01 DISPATCHER: job (0, 0, 9) finished
17:08:01 DISPATCHER: register_result: lock acquired
17:08:01 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
17:08:01 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0017553987477699727, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.053854543679096166, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 101, 'num_filters_3': 60}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.04145848188947768, 'info': {'data04': 0.04145848188947768, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0017553987477699727, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.053854543679096166, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 101, 'num_filters_3': 60}"}}
exception: None

17:08:01 job_callback for (0, 0, 9) started
17:08:01 job_callback for (0, 0, 9) got condition
17:08:01 DISPATCHER: Trying to submit another job.
17:08:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:08:01 Only 1 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
17:08:01 HBMASTER: Trying to run another job!
17:08:01 job_callback for (0, 0, 9) finished
17:08:01 HBMASTER: schedule new run for iteration 0
17:08:01 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
17:08:01 HBMASTER: submitting job (0, 0, 12) to dispatcher
17:08:01 DISPATCHER: trying to submit job (0, 0, 12)
17:08:01 DISPATCHER: trying to notify the job_runner thread.
17:08:01 HBMASTER: job (0, 0, 12) submitted to dispatcher
17:08:01 DISPATCHER: Trying to submit another job.
17:08:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:08:01 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880
17:08:01 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
17:08:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:08:01 WORKER: start processing job (0, 0, 12)
17:08:01 WORKER: args: ()
17:08:01 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.03929669529688009, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.026570665957920743}, 'budget': 400.0, 'working_directory': '.'}
17:08:40 DISPATCHER: Starting worker discovery
17:08:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:08:40 DISPATCHER: Finished worker discovery
17:09:40 DISPATCHER: Starting worker discovery
17:09:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:09:40 DISPATCHER: Finished worker discovery
17:10:40 DISPATCHER: Starting worker discovery
17:10:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:10:41 DISPATCHER: Finished worker discovery
17:11:41 DISPATCHER: Starting worker discovery
17:11:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:11:41 DISPATCHER: Finished worker discovery
17:12:41 DISPATCHER: Starting worker discovery
17:12:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:12:41 DISPATCHER: Finished worker discovery
17:13:41 DISPATCHER: Starting worker discovery
17:13:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:13:41 DISPATCHER: Finished worker discovery
17:14:41 DISPATCHER: Starting worker discovery
17:14:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:14:41 DISPATCHER: Finished worker discovery
17:15:29 WORKER: done with job (0, 0, 12), trying to register it.
17:15:29 WORKER: registered result for job (0, 0, 12) with dispatcher
17:15:29 DISPATCHER: job (0, 0, 12) finished
17:15:29 DISPATCHER: register_result: lock acquired
17:15:29 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
17:15:29 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.03929669529688009, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.026570665957920743}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.10280240287071656, 'info': {'data04': 0.10280240287071656, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.03929669529688009, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.026570665957920743}"}}
exception: None

17:15:29 job_callback for (0, 0, 12) started
17:15:29 job_callback for (0, 0, 12) got condition
17:15:29 DISPATCHER: Trying to submit another job.
17:15:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:15:29 Only 2 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
17:15:29 HBMASTER: Trying to run another job!
17:15:29 job_callback for (0, 0, 12) finished
17:15:29 HBMASTER: schedule new run for iteration 0
17:15:29 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
17:15:29 HBMASTER: submitting job (0, 0, 15) to dispatcher
17:15:29 DISPATCHER: trying to submit job (0, 0, 15)
17:15:29 DISPATCHER: trying to notify the job_runner thread.
17:15:29 HBMASTER: job (0, 0, 15) submitted to dispatcher
17:15:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:15:29 DISPATCHER: Trying to submit another job.
17:15:29 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.13102140436472194880
17:15:29 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
17:15:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:15:29 WORKER: start processing job (0, 0, 15)
17:15:29 WORKER: args: ()
17:15:29 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0044224375804824976, 'num_filters_1': 91, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.010787150293859002, 'kernel_size_2': 7, 'num_filters_2': 18}, 'budget': 400.0, 'working_directory': '.'}
17:15:41 DISPATCHER: Starting worker discovery
17:15:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:15:41 DISPATCHER: Finished worker discovery
17:16:41 DISPATCHER: Starting worker discovery
17:16:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:16:41 DISPATCHER: Finished worker discovery
17:17:41 DISPATCHER: Starting worker discovery
17:17:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:17:41 DISPATCHER: Finished worker discovery
17:18:41 DISPATCHER: Starting worker discovery
17:18:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:18:41 DISPATCHER: Finished worker discovery
17:19:41 DISPATCHER: Starting worker discovery
17:19:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:19:41 DISPATCHER: Finished worker discovery
17:20:41 DISPATCHER: Starting worker discovery
17:20:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:20:41 DISPATCHER: Finished worker discovery
17:21:41 DISPATCHER: Starting worker discovery
17:21:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:21:41 DISPATCHER: Finished worker discovery
17:22:41 DISPATCHER: Starting worker discovery
17:22:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:22:41 DISPATCHER: Finished worker discovery
17:22:58 WORKER: done with job (0, 0, 15), trying to register it.
17:22:58 WORKER: registered result for job (0, 0, 15) with dispatcher
17:22:58 DISPATCHER: job (0, 0, 15) finished
17:22:58 DISPATCHER: register_result: lock acquired
17:22:58 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
17:22:58 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0044224375804824976, 'num_filters_1': 91, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.010787150293859002, 'kernel_size_2': 7, 'num_filters_2': 18}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.13287111532712695, 'info': {'data04': 0.13287111532712695, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0044224375804824976, 'num_filters_1': 91, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.010787150293859002, 'kernel_size_2': 7, 'num_filters_2': 18}"}}
exception: None

17:22:58 job_callback for (0, 0, 15) started
17:22:58 job_callback for (0, 0, 15) got condition
17:22:58 DISPATCHER: Trying to submit another job.
17:22:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:22:58 Only 3 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
17:22:58 HBMASTER: Trying to run another job!
17:22:58 job_callback for (0, 0, 15) finished
17:22:58 ITERATION: Advancing config (0, 0, 15) to next budget 1200.000000
17:22:58 HBMASTER: schedule new run for iteration 0
17:22:58 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
17:22:58 HBMASTER: submitting job (0, 0, 15) to dispatcher
17:22:58 DISPATCHER: trying to submit job (0, 0, 15)
17:22:58 DISPATCHER: trying to notify the job_runner thread.
17:22:58 HBMASTER: job (0, 0, 15) submitted to dispatcher
17:22:58 DISPATCHER: Trying to submit another job.
17:22:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:22:58 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.13102140436472194880
17:22:58 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
17:22:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:22:58 WORKER: start processing job (0, 0, 15)
17:22:58 WORKER: args: ()
17:22:58 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0044224375804824976, 'num_filters_1': 91, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.010787150293859002, 'kernel_size_2': 7, 'num_filters_2': 18}, 'budget': 1200.0, 'working_directory': '.'}
17:23:41 DISPATCHER: Starting worker discovery
17:23:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:23:41 DISPATCHER: Finished worker discovery
17:24:41 DISPATCHER: Starting worker discovery
17:24:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:24:41 DISPATCHER: Finished worker discovery
17:25:41 DISPATCHER: Starting worker discovery
17:25:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:25:41 DISPATCHER: Finished worker discovery
17:26:41 DISPATCHER: Starting worker discovery
17:26:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:26:41 DISPATCHER: Finished worker discovery
17:27:41 DISPATCHER: Starting worker discovery
17:27:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:27:41 DISPATCHER: Finished worker discovery
17:28:41 DISPATCHER: Starting worker discovery
17:28:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:28:41 DISPATCHER: Finished worker discovery
17:29:41 DISPATCHER: Starting worker discovery
17:29:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:29:41 DISPATCHER: Finished worker discovery
17:30:41 DISPATCHER: Starting worker discovery
17:30:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:30:41 DISPATCHER: Finished worker discovery
17:31:41 DISPATCHER: Starting worker discovery
17:31:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:31:41 DISPATCHER: Finished worker discovery
17:32:41 DISPATCHER: Starting worker discovery
17:32:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:32:41 DISPATCHER: Finished worker discovery
17:33:41 DISPATCHER: Starting worker discovery
17:33:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:33:41 DISPATCHER: Finished worker discovery
17:34:41 DISPATCHER: Starting worker discovery
17:34:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:34:41 DISPATCHER: Finished worker discovery
17:35:41 DISPATCHER: Starting worker discovery
17:35:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:35:41 DISPATCHER: Finished worker discovery
17:36:41 DISPATCHER: Starting worker discovery
17:36:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:36:41 DISPATCHER: Finished worker discovery
17:37:41 DISPATCHER: Starting worker discovery
17:37:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:37:41 DISPATCHER: Finished worker discovery
17:38:41 DISPATCHER: Starting worker discovery
17:38:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:38:41 DISPATCHER: Finished worker discovery
17:39:41 DISPATCHER: Starting worker discovery
17:39:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:39:41 DISPATCHER: Finished worker discovery
17:40:41 DISPATCHER: Starting worker discovery
17:40:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:40:41 DISPATCHER: Finished worker discovery
17:41:41 DISPATCHER: Starting worker discovery
17:41:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:41:41 DISPATCHER: Finished worker discovery
17:42:41 DISPATCHER: Starting worker discovery
17:42:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:42:41 DISPATCHER: Finished worker discovery
17:43:41 DISPATCHER: Starting worker discovery
17:43:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:43:41 DISPATCHER: Finished worker discovery
17:44:41 DISPATCHER: Starting worker discovery
17:44:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:44:41 DISPATCHER: Finished worker discovery
17:44:57 WORKER: done with job (0, 0, 15), trying to register it.
17:44:57 WORKER: registered result for job (0, 0, 15) with dispatcher
17:44:57 DISPATCHER: job (0, 0, 15) finished
17:44:57 DISPATCHER: register_result: lock acquired
17:44:57 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
17:44:57 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0044224375804824976, 'num_filters_1': 91, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.010787150293859002, 'kernel_size_2': 7, 'num_filters_2': 18}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.09419572651057066, 'info': {'data04': 0.09419572651057066, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0044224375804824976, 'num_filters_1': 91, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.010787150293859002, 'kernel_size_2': 7, 'num_filters_2': 18}"}}
exception: None

17:44:57 job_callback for (0, 0, 15) started
17:44:57 job_callback for (0, 0, 15) got condition
17:44:57 DISPATCHER: Trying to submit another job.
17:44:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:44:57 Only 1 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
17:44:57 HBMASTER: Trying to run another job!
17:44:57 job_callback for (0, 0, 15) finished
17:44:57 start sampling a new configuration.
17:44:57 done sampling a new configuration.
17:44:57 HBMASTER: schedule new run for iteration 1
17:44:57 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
17:44:57 HBMASTER: submitting job (1, 0, 0) to dispatcher
17:44:57 DISPATCHER: trying to submit job (1, 0, 0)
17:44:57 DISPATCHER: trying to notify the job_runner thread.
17:44:57 HBMASTER: job (1, 0, 0) submitted to dispatcher
17:44:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:44:57 DISPATCHER: Trying to submit another job.
17:44:57 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
17:44:57 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
17:44:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:44:57 WORKER: start processing job (1, 0, 0)
17:44:57 WORKER: args: ()
17:44:57 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0014714639929260076, 'num_filters_1': 28, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.02392737584395979, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 53, 'num_filters_3': 91}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:45:41 DISPATCHER: Starting worker discovery
17:45:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:45:41 DISPATCHER: Finished worker discovery
17:46:41 DISPATCHER: Starting worker discovery
17:46:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:46:41 DISPATCHER: Finished worker discovery
17:47:34 WORKER: done with job (1, 0, 0), trying to register it.
17:47:34 WORKER: registered result for job (1, 0, 0) with dispatcher
17:47:34 DISPATCHER: job (1, 0, 0) finished
17:47:34 DISPATCHER: register_result: lock acquired
17:47:34 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
17:47:34 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0014714639929260076, 'num_filters_1': 28, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.02392737584395979, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 53, 'num_filters_3': 91}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.17979479871870782, 'info': {'data04': 0.17979479871870782, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0014714639929260076, 'num_filters_1': 28, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.02392737584395979, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 53, 'num_filters_3': 91}"}}
exception: None

17:47:34 job_callback for (1, 0, 0) started
17:47:34 job_callback for (1, 0, 0) got condition
17:47:34 DISPATCHER: Trying to submit another job.
17:47:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:47:34 Only 10 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
17:47:34 HBMASTER: Trying to run another job!
17:47:34 job_callback for (1, 0, 0) finished
17:47:34 start sampling a new configuration.
17:47:34 done sampling a new configuration.
17:47:34 HBMASTER: schedule new run for iteration 1
17:47:34 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
17:47:34 HBMASTER: submitting job (1, 0, 1) to dispatcher
17:47:34 DISPATCHER: trying to submit job (1, 0, 1)
17:47:34 DISPATCHER: trying to notify the job_runner thread.
17:47:34 HBMASTER: job (1, 0, 1) submitted to dispatcher
17:47:34 DISPATCHER: Trying to submit another job.
17:47:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:47:34 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
17:47:34 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
17:47:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:47:34 WORKER: start processing job (1, 0, 1)
17:47:34 WORKER: args: ()
17:47:34 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0010868961282560427, 'num_filters_1': 37, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.03237621161159341, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 43, 'num_filters_3': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:47:41 DISPATCHER: Starting worker discovery
17:47:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:47:41 DISPATCHER: Finished worker discovery
17:48:41 DISPATCHER: Starting worker discovery
17:48:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:48:41 DISPATCHER: Finished worker discovery
17:49:41 DISPATCHER: Starting worker discovery
17:49:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:49:41 DISPATCHER: Finished worker discovery
17:50:08 WORKER: done with job (1, 0, 1), trying to register it.
17:50:08 WORKER: registered result for job (1, 0, 1) with dispatcher
17:50:08 DISPATCHER: job (1, 0, 1) finished
17:50:08 DISPATCHER: register_result: lock acquired
17:50:08 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
17:50:08 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0010868961282560427, 'num_filters_1': 37, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.03237621161159341, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 43, 'num_filters_3': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.15361559326074195, 'info': {'data04': 0.15361559326074195, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0010868961282560427, 'num_filters_1': 37, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.03237621161159341, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 43, 'num_filters_3': 43}"}}
exception: None

17:50:08 job_callback for (1, 0, 1) started
17:50:08 DISPATCHER: Trying to submit another job.
17:50:08 job_callback for (1, 0, 1) got condition
17:50:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:50:08 Only 11 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
17:50:08 HBMASTER: Trying to run another job!
17:50:08 job_callback for (1, 0, 1) finished
17:50:08 start sampling a new configuration.
17:50:08 done sampling a new configuration.
17:50:08 HBMASTER: schedule new run for iteration 1
17:50:08 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
17:50:08 HBMASTER: submitting job (1, 0, 2) to dispatcher
17:50:08 DISPATCHER: trying to submit job (1, 0, 2)
17:50:08 DISPATCHER: trying to notify the job_runner thread.
17:50:08 HBMASTER: job (1, 0, 2) submitted to dispatcher
17:50:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:50:08 DISPATCHER: Trying to submit another job.
17:50:08 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
17:50:08 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
17:50:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:50:08 WORKER: start processing job (1, 0, 2)
17:50:08 WORKER: args: ()
17:50:08 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006200001597476645, 'num_filters_1': 95, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.1501501775612067, 'kernel_size_2': 7, 'num_filters_2': 78}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:50:41 DISPATCHER: Starting worker discovery
17:50:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:50:41 DISPATCHER: Finished worker discovery
17:51:41 DISPATCHER: Starting worker discovery
17:51:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:51:41 DISPATCHER: Finished worker discovery
17:52:41 DISPATCHER: Starting worker discovery
17:52:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:52:42 DISPATCHER: Finished worker discovery
17:52:47 WORKER: done with job (1, 0, 2), trying to register it.
17:52:47 WORKER: registered result for job (1, 0, 2) with dispatcher
17:52:47 DISPATCHER: job (1, 0, 2) finished
17:52:47 DISPATCHER: register_result: lock acquired
17:52:47 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
17:52:47 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006200001597476645, 'num_filters_1': 95, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.1501501775612067, 'kernel_size_2': 7, 'num_filters_2': 78}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.003813829061558691, 'info': {'data04': 0.003813829061558691, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006200001597476645, 'num_filters_1': 95, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.1501501775612067, 'kernel_size_2': 7, 'num_filters_2': 78}"}}
exception: None

17:52:47 job_callback for (1, 0, 2) started
17:52:47 job_callback for (1, 0, 2) got condition
17:52:47 DISPATCHER: Trying to submit another job.
17:52:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:52:47 Only 12 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
17:52:47 HBMASTER: Trying to run another job!
17:52:47 job_callback for (1, 0, 2) finished
17:52:47 start sampling a new configuration.
17:52:47 done sampling a new configuration.
17:52:47 HBMASTER: schedule new run for iteration 1
17:52:47 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
17:52:47 HBMASTER: submitting job (1, 0, 3) to dispatcher
17:52:47 DISPATCHER: trying to submit job (1, 0, 3)
17:52:47 DISPATCHER: trying to notify the job_runner thread.
17:52:47 HBMASTER: job (1, 0, 3) submitted to dispatcher
17:52:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:52:47 DISPATCHER: Trying to submit another job.
17:52:47 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
17:52:47 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
17:52:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:52:47 WORKER: start processing job (1, 0, 3)
17:52:47 WORKER: args: ()
17:52:47 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0011452682220772419, 'num_filters_1': 30, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.02107777898726943, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 23, 'num_filters_3': 50}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:53:42 DISPATCHER: Starting worker discovery
17:53:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:53:42 DISPATCHER: Finished worker discovery
17:54:42 DISPATCHER: Starting worker discovery
17:54:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:54:42 DISPATCHER: Finished worker discovery
17:55:25 WORKER: done with job (1, 0, 3), trying to register it.
17:55:25 WORKER: registered result for job (1, 0, 3) with dispatcher
17:55:25 DISPATCHER: job (1, 0, 3) finished
17:55:25 DISPATCHER: register_result: lock acquired
17:55:25 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
17:55:25 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0011452682220772419, 'num_filters_1': 30, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.02107777898726943, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 23, 'num_filters_3': 50}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.053900532081577995, 'info': {'data04': 0.053900532081577995, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0011452682220772419, 'num_filters_1': 30, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.02107777898726943, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 23, 'num_filters_3': 50}"}}
exception: None

17:55:25 job_callback for (1, 0, 3) started
17:55:25 job_callback for (1, 0, 3) got condition
17:55:25 DISPATCHER: Trying to submit another job.
17:55:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:55:25 Only 13 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
17:55:25 HBMASTER: Trying to run another job!
17:55:25 job_callback for (1, 0, 3) finished
17:55:25 start sampling a new configuration.
17:55:25 done sampling a new configuration.
17:55:25 HBMASTER: schedule new run for iteration 1
17:55:25 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
17:55:25 HBMASTER: submitting job (1, 0, 4) to dispatcher
17:55:25 DISPATCHER: trying to submit job (1, 0, 4)
17:55:25 DISPATCHER: trying to notify the job_runner thread.
17:55:25 HBMASTER: job (1, 0, 4) submitted to dispatcher
17:55:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:55:25 DISPATCHER: Trying to submit another job.
17:55:25 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
17:55:25 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
17:55:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:55:25 WORKER: start processing job (1, 0, 4)
17:55:25 WORKER: args: ()
17:55:25 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.06288858488394627, 'num_filters_1': 85, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.021317593334631492}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:55:42 DISPATCHER: Starting worker discovery
17:55:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:55:42 DISPATCHER: Finished worker discovery
17:56:42 DISPATCHER: Starting worker discovery
17:56:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:56:42 DISPATCHER: Finished worker discovery
17:57:42 DISPATCHER: Starting worker discovery
17:57:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:57:42 DISPATCHER: Finished worker discovery
17:58:42 DISPATCHER: Starting worker discovery
17:58:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:58:42 DISPATCHER: Finished worker discovery
17:59:27 WORKER: done with job (1, 0, 4), trying to register it.
17:59:27 WORKER: registered result for job (1, 0, 4) with dispatcher
17:59:27 DISPATCHER: job (1, 0, 4) finished
17:59:27 DISPATCHER: register_result: lock acquired
17:59:27 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
17:59:27 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.06288858488394627, 'num_filters_1': 85, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.021317593334631492}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.11084535800635964, 'info': {'data04': 0.11084535800635964, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.06288858488394627, 'num_filters_1': 85, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.021317593334631492}"}}
exception: None

17:59:27 job_callback for (1, 0, 4) started
17:59:27 job_callback for (1, 0, 4) got condition
17:59:27 DISPATCHER: Trying to submit another job.
17:59:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:59:27 Only 14 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
17:59:27 HBMASTER: Trying to run another job!
17:59:27 job_callback for (1, 0, 4) finished
17:59:27 start sampling a new configuration.
17:59:27 done sampling a new configuration.
17:59:27 HBMASTER: schedule new run for iteration 1
17:59:27 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
17:59:27 HBMASTER: submitting job (1, 0, 5) to dispatcher
17:59:27 DISPATCHER: trying to submit job (1, 0, 5)
17:59:27 DISPATCHER: trying to notify the job_runner thread.
17:59:27 HBMASTER: job (1, 0, 5) submitted to dispatcher
17:59:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:59:27 DISPATCHER: Trying to submit another job.
17:59:27 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
17:59:27 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
17:59:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:59:27 WORKER: start processing job (1, 0, 5)
17:59:27 WORKER: args: ()
17:59:27 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.027543966559041663, 'num_filters_1': 28, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.021176497992996788, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 80, 'num_filters_3': 52}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:59:42 DISPATCHER: Starting worker discovery
17:59:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:59:42 DISPATCHER: Finished worker discovery
18:00:42 DISPATCHER: Starting worker discovery
18:00:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:00:42 DISPATCHER: Finished worker discovery
18:01:42 DISPATCHER: Starting worker discovery
18:01:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:01:42 DISPATCHER: Finished worker discovery
18:02:03 WORKER: done with job (1, 0, 5), trying to register it.
18:02:03 WORKER: registered result for job (1, 0, 5) with dispatcher
18:02:03 DISPATCHER: job (1, 0, 5) finished
18:02:03 DISPATCHER: register_result: lock acquired
18:02:03 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:02:03 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.027543966559041663, 'num_filters_1': 28, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.021176497992996788, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 80, 'num_filters_3': 52}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.027543966559041663, 'num_filters_1': 28, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.021176497992996788, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 80, 'num_filters_3': 52}"}}
exception: None

18:02:03 job_callback for (1, 0, 5) started
18:02:03 job_callback for (1, 0, 5) got condition
18:02:03 DISPATCHER: Trying to submit another job.
18:02:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:02:03 Only 15 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
18:02:03 HBMASTER: Trying to run another job!
18:02:03 job_callback for (1, 0, 5) finished
18:02:03 start sampling a new configuration.
18:02:03 done sampling a new configuration.
18:02:03 HBMASTER: schedule new run for iteration 1
18:02:03 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
18:02:03 HBMASTER: submitting job (1, 0, 6) to dispatcher
18:02:03 DISPATCHER: trying to submit job (1, 0, 6)
18:02:03 DISPATCHER: trying to notify the job_runner thread.
18:02:03 HBMASTER: job (1, 0, 6) submitted to dispatcher
18:02:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:02:03 DISPATCHER: Trying to submit another job.
18:02:03 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:02:03 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:02:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:02:03 WORKER: start processing job (1, 0, 6)
18:02:03 WORKER: args: ()
18:02:03 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0031796995254270914, 'num_filters_1': 116, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.14420882547816508, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 88, 'num_filters_3': 33, 'num_filters_4': 59}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:02:42 DISPATCHER: Starting worker discovery
18:02:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:02:42 DISPATCHER: Finished worker discovery
18:03:42 DISPATCHER: Starting worker discovery
18:03:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:03:42 DISPATCHER: Finished worker discovery
18:04:42 DISPATCHER: Starting worker discovery
18:04:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:04:42 DISPATCHER: Finished worker discovery
18:04:45 WORKER: done with job (1, 0, 6), trying to register it.
18:04:45 WORKER: registered result for job (1, 0, 6) with dispatcher
18:04:45 DISPATCHER: job (1, 0, 6) finished
18:04:45 DISPATCHER: register_result: lock acquired
18:04:45 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:04:45 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0031796995254270914, 'num_filters_1': 116, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.14420882547816508, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 88, 'num_filters_3': 33, 'num_filters_4': 59}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0036147514267042703, 'info': {'data04': 0.0036147514267042703, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0031796995254270914, 'num_filters_1': 116, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.14420882547816508, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 88, 'num_filters_3': 33, 'num_filters_4': 59}"}}
exception: None

18:04:45 job_callback for (1, 0, 6) started
18:04:45 job_callback for (1, 0, 6) got condition
18:04:45 DISPATCHER: Trying to submit another job.
18:04:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:04:45 Only 16 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
18:04:45 HBMASTER: Trying to run another job!
18:04:45 job_callback for (1, 0, 6) finished
18:04:45 start sampling a new configuration.
18:04:45 done sampling a new configuration.
18:04:45 HBMASTER: schedule new run for iteration 1
18:04:45 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
18:04:45 HBMASTER: submitting job (1, 0, 7) to dispatcher
18:04:45 DISPATCHER: trying to submit job (1, 0, 7)
18:04:45 DISPATCHER: trying to notify the job_runner thread.
18:04:45 HBMASTER: job (1, 0, 7) submitted to dispatcher
18:04:45 DISPATCHER: Trying to submit another job.
18:04:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:04:45 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:04:45 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:04:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:04:45 WORKER: start processing job (1, 0, 7)
18:04:45 WORKER: args: ()
18:04:45 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.07981713573094974, 'num_filters_1': 106, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.04753719430493525}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:05:42 DISPATCHER: Starting worker discovery
18:05:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:05:42 DISPATCHER: Finished worker discovery
18:06:42 DISPATCHER: Starting worker discovery
18:06:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:06:42 DISPATCHER: Finished worker discovery
18:07:29 WORKER: done with job (1, 0, 7), trying to register it.
18:07:29 WORKER: registered result for job (1, 0, 7) with dispatcher
18:07:29 DISPATCHER: job (1, 0, 7) finished
18:07:29 DISPATCHER: register_result: lock acquired
18:07:29 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:07:29 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.07981713573094974, 'num_filters_1': 106, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.04753719430493525}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.030161606952710418, 'info': {'data04': 0.030161606952710418, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.07981713573094974, 'num_filters_1': 106, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.04753719430493525}"}}
exception: None

18:07:29 job_callback for (1, 0, 7) started
18:07:29 job_callback for (1, 0, 7) got condition
18:07:29 DISPATCHER: Trying to submit another job.
18:07:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:07:29 HBMASTER: Trying to run another job!
18:07:29 job_callback for (1, 0, 7) finished
18:07:29 start sampling a new configuration.
18:07:29 done sampling a new configuration.
18:07:29 HBMASTER: schedule new run for iteration 1
18:07:29 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
18:07:29 HBMASTER: submitting job (1, 0, 8) to dispatcher
18:07:29 DISPATCHER: trying to submit job (1, 0, 8)
18:07:29 DISPATCHER: trying to notify the job_runner thread.
18:07:29 HBMASTER: job (1, 0, 8) submitted to dispatcher
18:07:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:07:29 DISPATCHER: Trying to submit another job.
18:07:29 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:07:29 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:07:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:07:29 WORKER: start processing job (1, 0, 8)
18:07:29 WORKER: args: ()
18:07:29 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.017642171248160435, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.03531419931271938, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 40, 'num_filters_3': 77}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:07:42 DISPATCHER: Starting worker discovery
18:07:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:07:42 DISPATCHER: Finished worker discovery
18:08:42 DISPATCHER: Starting worker discovery
18:08:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:08:42 DISPATCHER: Finished worker discovery
18:09:42 DISPATCHER: Starting worker discovery
18:09:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:09:42 DISPATCHER: Finished worker discovery
18:10:03 WORKER: done with job (1, 0, 8), trying to register it.
18:10:03 WORKER: registered result for job (1, 0, 8) with dispatcher
18:10:03 DISPATCHER: job (1, 0, 8) finished
18:10:03 DISPATCHER: register_result: lock acquired
18:10:03 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:10:03 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.017642171248160435, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.03531419931271938, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 40, 'num_filters_3': 77}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0413482104730818, 'info': {'data04': 0.0413482104730818, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.017642171248160435, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.03531419931271938, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 40, 'num_filters_3': 77}"}}
exception: None

18:10:03 job_callback for (1, 0, 8) started
18:10:03 DISPATCHER: Trying to submit another job.
18:10:03 job_callback for (1, 0, 8) got condition
18:10:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:10:03 HBMASTER: Trying to run another job!
18:10:03 job_callback for (1, 0, 8) finished
18:10:03 ITERATION: Advancing config (1, 0, 0) to next budget 400.000000
18:10:03 ITERATION: Advancing config (1, 0, 1) to next budget 400.000000
18:10:03 ITERATION: Advancing config (1, 0, 4) to next budget 400.000000
18:10:03 HBMASTER: schedule new run for iteration 1
18:10:03 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
18:10:03 HBMASTER: submitting job (1, 0, 0) to dispatcher
18:10:03 DISPATCHER: trying to submit job (1, 0, 0)
18:10:03 DISPATCHER: trying to notify the job_runner thread.
18:10:03 HBMASTER: job (1, 0, 0) submitted to dispatcher
18:10:03 DISPATCHER: Trying to submit another job.
18:10:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:10:03 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:10:03 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:10:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:10:03 WORKER: start processing job (1, 0, 0)
18:10:03 WORKER: args: ()
18:10:03 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0014714639929260076, 'num_filters_1': 28, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.02392737584395979, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 53, 'num_filters_3': 91}, 'budget': 400.0, 'working_directory': '.'}
18:10:42 DISPATCHER: Starting worker discovery
18:10:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:10:42 DISPATCHER: Finished worker discovery
18:11:42 DISPATCHER: Starting worker discovery
18:11:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:11:42 DISPATCHER: Finished worker discovery
18:12:42 DISPATCHER: Starting worker discovery
18:12:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:12:42 DISPATCHER: Finished worker discovery
18:13:42 DISPATCHER: Starting worker discovery
18:13:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:13:42 DISPATCHER: Finished worker discovery
18:14:42 DISPATCHER: Starting worker discovery
18:14:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:14:42 DISPATCHER: Finished worker discovery
18:15:42 DISPATCHER: Starting worker discovery
18:15:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:15:42 DISPATCHER: Finished worker discovery
18:16:42 DISPATCHER: Starting worker discovery
18:16:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:16:42 DISPATCHER: Finished worker discovery
18:17:25 WORKER: done with job (1, 0, 0), trying to register it.
18:17:25 WORKER: registered result for job (1, 0, 0) with dispatcher
18:17:25 DISPATCHER: job (1, 0, 0) finished
18:17:25 DISPATCHER: register_result: lock acquired
18:17:25 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:17:25 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0014714639929260076, 'num_filters_1': 28, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.02392737584395979, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 53, 'num_filters_3': 91}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.1420216396247984, 'info': {'data04': 0.1420216396247984, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0014714639929260076, 'num_filters_1': 28, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.02392737584395979, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 53, 'num_filters_3': 91}"}}
exception: None

18:17:25 job_callback for (1, 0, 0) started
18:17:25 job_callback for (1, 0, 0) got condition
18:17:25 DISPATCHER: Trying to submit another job.
18:17:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:17:25 Only 4 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
18:17:25 HBMASTER: Trying to run another job!
18:17:25 job_callback for (1, 0, 0) finished
18:17:25 HBMASTER: schedule new run for iteration 1
18:17:25 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
18:17:25 HBMASTER: submitting job (1, 0, 1) to dispatcher
18:17:25 DISPATCHER: trying to submit job (1, 0, 1)
18:17:25 DISPATCHER: trying to notify the job_runner thread.
18:17:25 HBMASTER: job (1, 0, 1) submitted to dispatcher
18:17:25 DISPATCHER: Trying to submit another job.
18:17:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:17:25 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:17:25 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:17:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:17:25 WORKER: start processing job (1, 0, 1)
18:17:25 WORKER: args: ()
18:17:25 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0010868961282560427, 'num_filters_1': 37, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.03237621161159341, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 43, 'num_filters_3': 43}, 'budget': 400.0, 'working_directory': '.'}
18:17:42 DISPATCHER: Starting worker discovery
18:17:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:17:42 DISPATCHER: Finished worker discovery
18:18:42 DISPATCHER: Starting worker discovery
18:18:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:18:42 DISPATCHER: Finished worker discovery
18:19:42 DISPATCHER: Starting worker discovery
18:19:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:19:42 DISPATCHER: Finished worker discovery
18:20:42 DISPATCHER: Starting worker discovery
18:20:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:20:42 DISPATCHER: Finished worker discovery
18:21:42 DISPATCHER: Starting worker discovery
18:21:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:21:42 DISPATCHER: Finished worker discovery
18:22:42 DISPATCHER: Starting worker discovery
18:22:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:22:42 DISPATCHER: Finished worker discovery
18:23:42 DISPATCHER: Starting worker discovery
18:23:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:23:42 DISPATCHER: Finished worker discovery
18:24:32 WORKER: done with job (1, 0, 1), trying to register it.
18:24:32 WORKER: registered result for job (1, 0, 1) with dispatcher
18:24:32 DISPATCHER: job (1, 0, 1) finished
18:24:32 DISPATCHER: register_result: lock acquired
18:24:32 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:24:32 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0010868961282560427, 'num_filters_1': 37, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.03237621161159341, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 43, 'num_filters_3': 43}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.14725270333382146, 'info': {'data04': 0.14725270333382146, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0010868961282560427, 'num_filters_1': 37, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.03237621161159341, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 43, 'num_filters_3': 43}"}}
exception: None

18:24:32 job_callback for (1, 0, 1) started
18:24:32 DISPATCHER: Trying to submit another job.
18:24:32 job_callback for (1, 0, 1) got condition
18:24:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:24:32 Only 5 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
18:24:32 HBMASTER: Trying to run another job!
18:24:32 job_callback for (1, 0, 1) finished
18:24:32 HBMASTER: schedule new run for iteration 1
18:24:32 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
18:24:32 HBMASTER: submitting job (1, 0, 4) to dispatcher
18:24:32 DISPATCHER: trying to submit job (1, 0, 4)
18:24:32 DISPATCHER: trying to notify the job_runner thread.
18:24:32 HBMASTER: job (1, 0, 4) submitted to dispatcher
18:24:32 DISPATCHER: Trying to submit another job.
18:24:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:24:32 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:24:32 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:24:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:24:32 WORKER: start processing job (1, 0, 4)
18:24:32 WORKER: args: ()
18:24:32 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.06288858488394627, 'num_filters_1': 85, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.021317593334631492}, 'budget': 400.0, 'working_directory': '.'}
18:24:42 DISPATCHER: Starting worker discovery
18:24:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:24:42 DISPATCHER: Finished worker discovery
18:25:42 DISPATCHER: Starting worker discovery
18:25:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:25:42 DISPATCHER: Finished worker discovery
18:26:42 DISPATCHER: Starting worker discovery
18:26:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:26:42 DISPATCHER: Finished worker discovery
18:27:42 DISPATCHER: Starting worker discovery
18:27:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:27:42 DISPATCHER: Finished worker discovery
18:28:42 DISPATCHER: Starting worker discovery
18:28:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:28:42 DISPATCHER: Finished worker discovery
18:29:42 DISPATCHER: Starting worker discovery
18:29:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:29:42 DISPATCHER: Finished worker discovery
18:30:42 DISPATCHER: Starting worker discovery
18:30:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:30:42 DISPATCHER: Finished worker discovery
18:31:42 DISPATCHER: Starting worker discovery
18:31:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:31:43 DISPATCHER: Finished worker discovery
18:32:43 DISPATCHER: Starting worker discovery
18:32:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:32:43 DISPATCHER: Finished worker discovery
18:33:43 DISPATCHER: Starting worker discovery
18:33:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:33:43 DISPATCHER: Finished worker discovery
18:34:42 WORKER: done with job (1, 0, 4), trying to register it.
18:34:42 WORKER: registered result for job (1, 0, 4) with dispatcher
18:34:42 DISPATCHER: job (1, 0, 4) finished
18:34:42 DISPATCHER: register_result: lock acquired
18:34:42 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:34:42 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.06288858488394627, 'num_filters_1': 85, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.021317593334631492}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.08562275616800061, 'info': {'data04': 0.08562275616800061, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.06288858488394627, 'num_filters_1': 85, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.021317593334631492}"}}
exception: None

18:34:42 job_callback for (1, 0, 4) started
18:34:42 job_callback for (1, 0, 4) got condition
18:34:42 DISPATCHER: Trying to submit another job.
18:34:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:34:42 Only 6 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
18:34:42 HBMASTER: Trying to run another job!
18:34:42 job_callback for (1, 0, 4) finished
18:34:42 ITERATION: Advancing config (1, 0, 1) to next budget 1200.000000
18:34:42 HBMASTER: schedule new run for iteration 1
18:34:42 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
18:34:42 HBMASTER: submitting job (1, 0, 1) to dispatcher
18:34:42 DISPATCHER: trying to submit job (1, 0, 1)
18:34:42 DISPATCHER: trying to notify the job_runner thread.
18:34:42 HBMASTER: job (1, 0, 1) submitted to dispatcher
18:34:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:34:42 DISPATCHER: Trying to submit another job.
18:34:42 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:34:42 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:34:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:34:42 WORKER: start processing job (1, 0, 1)
18:34:42 WORKER: args: ()
18:34:42 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0010868961282560427, 'num_filters_1': 37, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.03237621161159341, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 43, 'num_filters_3': 43}, 'budget': 1200.0, 'working_directory': '.'}
18:34:43 DISPATCHER: Starting worker discovery
18:34:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:34:43 DISPATCHER: Finished worker discovery
18:35:43 DISPATCHER: Starting worker discovery
18:35:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:35:43 DISPATCHER: Finished worker discovery
18:36:43 DISPATCHER: Starting worker discovery
18:36:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:36:43 DISPATCHER: Finished worker discovery
18:37:43 DISPATCHER: Starting worker discovery
18:37:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:37:43 DISPATCHER: Finished worker discovery
18:38:43 DISPATCHER: Starting worker discovery
18:38:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:38:43 DISPATCHER: Finished worker discovery
18:39:43 DISPATCHER: Starting worker discovery
18:39:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:39:43 DISPATCHER: Finished worker discovery
18:40:43 DISPATCHER: Starting worker discovery
18:40:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:40:43 DISPATCHER: Finished worker discovery
18:41:43 DISPATCHER: Starting worker discovery
18:41:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:41:43 DISPATCHER: Finished worker discovery
18:42:43 DISPATCHER: Starting worker discovery
18:42:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:42:43 DISPATCHER: Finished worker discovery
18:43:43 DISPATCHER: Starting worker discovery
18:43:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:43:43 DISPATCHER: Finished worker discovery
18:44:43 DISPATCHER: Starting worker discovery
18:44:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:44:43 DISPATCHER: Finished worker discovery
18:45:43 DISPATCHER: Starting worker discovery
18:45:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:45:43 DISPATCHER: Finished worker discovery
18:46:43 DISPATCHER: Starting worker discovery
18:46:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:46:43 DISPATCHER: Finished worker discovery
18:47:43 DISPATCHER: Starting worker discovery
18:47:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:47:43 DISPATCHER: Finished worker discovery
18:48:43 DISPATCHER: Starting worker discovery
18:48:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:48:43 DISPATCHER: Finished worker discovery
18:49:43 DISPATCHER: Starting worker discovery
18:49:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:49:43 DISPATCHER: Finished worker discovery
18:50:43 DISPATCHER: Starting worker discovery
18:50:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:50:43 DISPATCHER: Finished worker discovery
18:51:43 DISPATCHER: Starting worker discovery
18:51:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:51:43 DISPATCHER: Finished worker discovery
18:52:43 DISPATCHER: Starting worker discovery
18:52:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:52:43 DISPATCHER: Finished worker discovery
18:53:43 DISPATCHER: Starting worker discovery
18:53:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:53:43 DISPATCHER: Finished worker discovery
18:54:43 DISPATCHER: Starting worker discovery
18:54:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:54:43 DISPATCHER: Finished worker discovery
18:55:33 WORKER: done with job (1, 0, 1), trying to register it.
18:55:33 WORKER: registered result for job (1, 0, 1) with dispatcher
18:55:33 DISPATCHER: job (1, 0, 1) finished
18:55:33 DISPATCHER: register_result: lock acquired
18:55:33 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
18:55:33 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0010868961282560427, 'num_filters_1': 37, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.03237621161159341, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 43, 'num_filters_3': 43}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.13270334833566888, 'info': {'data04': 0.13270334833566888, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0010868961282560427, 'num_filters_1': 37, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.03237621161159341, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 43, 'num_filters_3': 43}"}}
exception: None

18:55:33 job_callback for (1, 0, 1) started
18:55:33 DISPATCHER: Trying to submit another job.
18:55:33 job_callback for (1, 0, 1) got condition
18:55:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:55:33 Only 2 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
18:55:33 HBMASTER: Trying to run another job!
18:55:33 job_callback for (1, 0, 1) finished
18:55:33 start sampling a new configuration.
18:55:33 done sampling a new configuration.
18:55:33 HBMASTER: schedule new run for iteration 2
18:55:33 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
18:55:33 HBMASTER: submitting job (2, 0, 0) to dispatcher
18:55:33 DISPATCHER: trying to submit job (2, 0, 0)
18:55:33 DISPATCHER: trying to notify the job_runner thread.
18:55:33 HBMASTER: job (2, 0, 0) submitted to dispatcher
18:55:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:55:33 DISPATCHER: Trying to submit another job.
18:55:33 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:55:33 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
18:55:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:55:33 WORKER: start processing job (2, 0, 0)
18:55:33 WORKER: args: ()
18:55:33 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012168033114691858, 'num_filters_1': 72, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.06676119103712362, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 41, 'num_filters_3': 96}, 'budget': 400.0, 'working_directory': '.'}
18:55:43 DISPATCHER: Starting worker discovery
18:55:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:55:43 DISPATCHER: Finished worker discovery
18:56:43 DISPATCHER: Starting worker discovery
18:56:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:56:43 DISPATCHER: Finished worker discovery
18:57:43 DISPATCHER: Starting worker discovery
18:57:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:57:43 DISPATCHER: Finished worker discovery
18:58:43 DISPATCHER: Starting worker discovery
18:58:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:58:43 DISPATCHER: Finished worker discovery
18:59:43 DISPATCHER: Starting worker discovery
18:59:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:59:43 DISPATCHER: Finished worker discovery
19:00:43 DISPATCHER: Starting worker discovery
19:00:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:00:43 DISPATCHER: Finished worker discovery
19:01:43 DISPATCHER: Starting worker discovery
19:01:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:01:43 DISPATCHER: Finished worker discovery
19:02:43 DISPATCHER: Starting worker discovery
19:02:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:02:44 DISPATCHER: Finished worker discovery
19:02:45 WORKER: done with job (2, 0, 0), trying to register it.
19:02:45 WORKER: registered result for job (2, 0, 0) with dispatcher
19:02:45 DISPATCHER: job (2, 0, 0) finished
19:02:45 DISPATCHER: register_result: lock acquired
19:02:45 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
19:02:45 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012168033114691858, 'num_filters_1': 72, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.06676119103712362, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 41, 'num_filters_3': 96}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.008731939614898187, 'info': {'data04': 0.008731939614898187, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012168033114691858, 'num_filters_1': 72, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.06676119103712362, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 41, 'num_filters_3': 96}"}}
exception: None

19:02:45 job_callback for (2, 0, 0) started
19:02:45 DISPATCHER: Trying to submit another job.
19:02:45 job_callback for (2, 0, 0) got condition
19:02:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:02:45 Only 7 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
19:02:45 HBMASTER: Trying to run another job!
19:02:45 job_callback for (2, 0, 0) finished
19:02:45 start sampling a new configuration.
19:02:45 done sampling a new configuration.
19:02:45 HBMASTER: schedule new run for iteration 2
19:02:45 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
19:02:45 HBMASTER: submitting job (2, 0, 1) to dispatcher
19:02:45 DISPATCHER: trying to submit job (2, 0, 1)
19:02:45 DISPATCHER: trying to notify the job_runner thread.
19:02:45 HBMASTER: job (2, 0, 1) submitted to dispatcher
19:02:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:02:45 DISPATCHER: Trying to submit another job.
19:02:45 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
19:02:45 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
19:02:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:02:45 WORKER: start processing job (2, 0, 1)
19:02:45 WORKER: args: ()
19:02:45 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.008958141982894479, 'num_filters_1': 42, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.016858301532938, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 103, 'num_filters_3': 49, 'num_filters_4': 30}, 'budget': 400.0, 'working_directory': '.'}
19:03:44 DISPATCHER: Starting worker discovery
19:03:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:03:44 DISPATCHER: Finished worker discovery
19:04:44 DISPATCHER: Starting worker discovery
19:04:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:04:44 DISPATCHER: Finished worker discovery
19:05:44 DISPATCHER: Starting worker discovery
19:05:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:05:44 DISPATCHER: Finished worker discovery
19:06:44 DISPATCHER: Starting worker discovery
19:06:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:06:44 DISPATCHER: Finished worker discovery
19:07:44 DISPATCHER: Starting worker discovery
19:07:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:07:44 DISPATCHER: Finished worker discovery
19:08:44 DISPATCHER: Starting worker discovery
19:08:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:08:44 DISPATCHER: Finished worker discovery
19:09:44 DISPATCHER: Starting worker discovery
19:09:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:09:44 DISPATCHER: Finished worker discovery
19:09:58 WORKER: done with job (2, 0, 1), trying to register it.
19:09:58 WORKER: registered result for job (2, 0, 1) with dispatcher
19:09:58 DISPATCHER: job (2, 0, 1) finished
19:09:58 DISPATCHER: register_result: lock acquired
19:09:58 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
19:09:58 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.008958141982894479, 'num_filters_1': 42, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.016858301532938, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 103, 'num_filters_3': 49, 'num_filters_4': 30}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.008958141982894479, 'num_filters_1': 42, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.016858301532938, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 103, 'num_filters_3': 49, 'num_filters_4': 30}"}}
exception: None

19:09:58 job_callback for (2, 0, 1) started
19:09:58 job_callback for (2, 0, 1) got condition
19:09:58 DISPATCHER: Trying to submit another job.
19:09:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:09:58 Only 8 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
19:09:58 HBMASTER: Trying to run another job!
19:09:58 job_callback for (2, 0, 1) finished
19:09:58 start sampling a new configuration.
19:09:58 done sampling a new configuration.
19:09:58 HBMASTER: schedule new run for iteration 2
19:09:58 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
19:09:58 HBMASTER: submitting job (2, 0, 2) to dispatcher
19:09:58 DISPATCHER: trying to submit job (2, 0, 2)
19:09:58 DISPATCHER: trying to notify the job_runner thread.
19:09:58 HBMASTER: job (2, 0, 2) submitted to dispatcher
19:09:58 DISPATCHER: Trying to submit another job.
19:09:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:09:58 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
19:09:58 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
19:09:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:09:58 WORKER: start processing job (2, 0, 2)
19:09:58 WORKER: args: ()
19:09:58 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0036198681113468988, 'num_filters_1': 49, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.02409257665983327, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 30, 'num_filters_3': 79}, 'budget': 400.0, 'working_directory': '.'}
19:10:44 DISPATCHER: Starting worker discovery
19:10:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:10:44 DISPATCHER: Finished worker discovery
19:11:44 DISPATCHER: Starting worker discovery
19:11:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:11:44 DISPATCHER: Finished worker discovery
19:12:44 DISPATCHER: Starting worker discovery
19:12:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:12:44 DISPATCHER: Finished worker discovery
19:13:44 DISPATCHER: Starting worker discovery
19:13:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:13:44 DISPATCHER: Finished worker discovery
19:14:44 DISPATCHER: Starting worker discovery
19:14:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:14:44 DISPATCHER: Finished worker discovery
19:15:44 DISPATCHER: Starting worker discovery
19:15:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:15:44 DISPATCHER: Finished worker discovery
19:16:44 DISPATCHER: Starting worker discovery
19:16:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:16:44 DISPATCHER: Finished worker discovery
19:17:44 DISPATCHER: Starting worker discovery
19:17:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:17:44 DISPATCHER: Finished worker discovery
19:17:53 WORKER: done with job (2, 0, 2), trying to register it.
19:17:53 WORKER: registered result for job (2, 0, 2) with dispatcher
19:17:53 DISPATCHER: job (2, 0, 2) finished
19:17:53 DISPATCHER: register_result: lock acquired
19:17:53 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
19:17:53 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0036198681113468988, 'num_filters_1': 49, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.02409257665983327, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 30, 'num_filters_3': 79}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0001332419409475186, 'info': {'data04': 0.0001332419409475186, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0036198681113468988, 'num_filters_1': 49, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.02409257665983327, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 30, 'num_filters_3': 79}"}}
exception: None

19:17:53 job_callback for (2, 0, 2) started
19:17:53 DISPATCHER: Trying to submit another job.
19:17:53 job_callback for (2, 0, 2) got condition
19:17:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:17:53 Only 9 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
19:17:53 HBMASTER: Trying to run another job!
19:17:53 job_callback for (2, 0, 2) finished
19:17:53 start sampling a new configuration.
19:17:53 done sampling a new configuration.
19:17:53 HBMASTER: schedule new run for iteration 2
19:17:53 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
19:17:53 HBMASTER: submitting job (2, 0, 3) to dispatcher
19:17:53 DISPATCHER: trying to submit job (2, 0, 3)
19:17:53 DISPATCHER: trying to notify the job_runner thread.
19:17:53 HBMASTER: job (2, 0, 3) submitted to dispatcher
19:17:53 DISPATCHER: Trying to submit another job.
19:17:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:17:53 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
19:17:53 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
19:17:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:17:53 WORKER: start processing job (2, 0, 3)
19:17:53 WORKER: args: ()
19:17:53 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.01864681000685066, 'num_filters_1': 99, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.13812999493508038, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 32, 'num_filters_3': 33, 'num_filters_4': 33}, 'budget': 400.0, 'working_directory': '.'}
19:18:44 DISPATCHER: Starting worker discovery
19:18:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:18:44 DISPATCHER: Finished worker discovery
19:19:44 DISPATCHER: Starting worker discovery
19:19:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:19:44 DISPATCHER: Finished worker discovery
19:20:44 DISPATCHER: Starting worker discovery
19:20:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:20:44 DISPATCHER: Finished worker discovery
19:21:44 DISPATCHER: Starting worker discovery
19:21:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:21:44 DISPATCHER: Finished worker discovery
19:22:44 DISPATCHER: Starting worker discovery
19:22:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:22:44 DISPATCHER: Finished worker discovery
19:23:44 DISPATCHER: Starting worker discovery
19:23:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:23:44 DISPATCHER: Finished worker discovery
19:24:44 DISPATCHER: Starting worker discovery
19:24:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:24:44 DISPATCHER: Finished worker discovery
19:25:00 WORKER: done with job (2, 0, 3), trying to register it.
19:25:00 WORKER: registered result for job (2, 0, 3) with dispatcher
19:25:00 DISPATCHER: job (2, 0, 3) finished
19:25:00 DISPATCHER: register_result: lock acquired
19:25:00 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
19:25:00 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.01864681000685066, 'num_filters_1': 99, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.13812999493508038, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 32, 'num_filters_3': 33, 'num_filters_4': 33}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.01864681000685066, 'num_filters_1': 99, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.13812999493508038, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 32, 'num_filters_3': 33, 'num_filters_4': 33}"}}
exception: None

19:25:00 job_callback for (2, 0, 3) started
19:25:00 job_callback for (2, 0, 3) got condition
19:25:00 DISPATCHER: Trying to submit another job.
19:25:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:25:00 Only 10 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
19:25:00 HBMASTER: Trying to run another job!
19:25:00 job_callback for (2, 0, 3) finished
19:25:00 start sampling a new configuration.
19:25:00 done sampling a new configuration.
19:25:00 HBMASTER: schedule new run for iteration 2
19:25:00 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
19:25:00 HBMASTER: submitting job (2, 0, 4) to dispatcher
19:25:00 DISPATCHER: trying to submit job (2, 0, 4)
19:25:00 DISPATCHER: trying to notify the job_runner thread.
19:25:00 HBMASTER: job (2, 0, 4) submitted to dispatcher
19:25:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:25:00 DISPATCHER: Trying to submit another job.
19:25:00 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
19:25:00 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
19:25:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:25:00 WORKER: start processing job (2, 0, 4)
19:25:00 WORKER: args: ()
19:25:00 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.016661102728448597, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.03729158964252535, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 31, 'num_filters_3': 31}, 'budget': 400.0, 'working_directory': '.'}
19:25:44 DISPATCHER: Starting worker discovery
19:25:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:25:44 DISPATCHER: Finished worker discovery
19:26:44 DISPATCHER: Starting worker discovery
19:26:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:26:44 DISPATCHER: Finished worker discovery
19:27:44 DISPATCHER: Starting worker discovery
19:27:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:27:44 DISPATCHER: Finished worker discovery
19:28:44 DISPATCHER: Starting worker discovery
19:28:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:28:44 DISPATCHER: Finished worker discovery
19:29:44 DISPATCHER: Starting worker discovery
19:29:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:29:44 DISPATCHER: Finished worker discovery
19:30:44 DISPATCHER: Starting worker discovery
19:30:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:30:44 DISPATCHER: Finished worker discovery
19:31:44 DISPATCHER: Starting worker discovery
19:31:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:31:44 DISPATCHER: Finished worker discovery
19:32:39 WORKER: done with job (2, 0, 4), trying to register it.
19:32:39 WORKER: registered result for job (2, 0, 4) with dispatcher
19:32:39 DISPATCHER: job (2, 0, 4) finished
19:32:39 DISPATCHER: register_result: lock acquired
19:32:39 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
19:32:39 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.016661102728448597, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.03729158964252535, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 31, 'num_filters_3': 31}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.03926763371423436, 'info': {'data04': 0.03926763371423436, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.016661102728448597, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.03729158964252535, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 31, 'num_filters_3': 31}"}}
exception: None

19:32:39 job_callback for (2, 0, 4) started
19:32:39 job_callback for (2, 0, 4) got condition
19:32:39 DISPATCHER: Trying to submit another job.
19:32:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:32:39 Only 11 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
19:32:39 HBMASTER: Trying to run another job!
19:32:39 job_callback for (2, 0, 4) finished
19:32:39 start sampling a new configuration.
19:32:39 done sampling a new configuration.
19:32:39 HBMASTER: schedule new run for iteration 2
19:32:39 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
19:32:39 HBMASTER: submitting job (2, 0, 5) to dispatcher
19:32:39 DISPATCHER: trying to submit job (2, 0, 5)
19:32:39 DISPATCHER: trying to notify the job_runner thread.
19:32:39 HBMASTER: job (2, 0, 5) submitted to dispatcher
19:32:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:32:39 DISPATCHER: Trying to submit another job.
19:32:39 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
19:32:39 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
19:32:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:32:39 WORKER: start processing job (2, 0, 5)
19:32:39 WORKER: args: ()
19:32:39 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.05364222316745557, 'num_filters_1': 47, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.08847334167593027, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 70, 'num_filters_3': 44, 'num_filters_4': 91}, 'budget': 400.0, 'working_directory': '.'}
19:32:44 DISPATCHER: Starting worker discovery
19:32:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:32:44 DISPATCHER: Finished worker discovery
19:33:44 DISPATCHER: Starting worker discovery
19:33:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:33:44 DISPATCHER: Finished worker discovery
19:34:44 DISPATCHER: Starting worker discovery
19:34:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:34:44 DISPATCHER: Finished worker discovery
19:35:44 DISPATCHER: Starting worker discovery
19:35:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:35:44 DISPATCHER: Finished worker discovery
19:36:44 DISPATCHER: Starting worker discovery
19:36:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:36:44 DISPATCHER: Finished worker discovery
19:37:44 DISPATCHER: Starting worker discovery
19:37:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:37:44 DISPATCHER: Finished worker discovery
19:38:44 DISPATCHER: Starting worker discovery
19:38:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:38:44 DISPATCHER: Finished worker discovery
19:39:43 WORKER: done with job (2, 0, 5), trying to register it.
19:39:43 WORKER: registered result for job (2, 0, 5) with dispatcher
19:39:43 DISPATCHER: job (2, 0, 5) finished
19:39:43 DISPATCHER: register_result: lock acquired
19:39:43 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
19:39:43 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.05364222316745557, 'num_filters_1': 47, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.08847334167593027, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 70, 'num_filters_3': 44, 'num_filters_4': 91}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': 1.0475161750412791e-05, 'info': {'data04': -1.0475161750412791e-05, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.05364222316745557, 'num_filters_1': 47, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.08847334167593027, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 70, 'num_filters_3': 44, 'num_filters_4': 91}"}}
exception: None

19:39:43 job_callback for (2, 0, 5) started
19:39:43 job_callback for (2, 0, 5) got condition
19:39:43 DISPATCHER: Trying to submit another job.
19:39:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:39:43 Only 12 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
19:39:43 HBMASTER: Trying to run another job!
19:39:43 job_callback for (2, 0, 5) finished
19:39:43 ITERATION: Advancing config (2, 0, 0) to next budget 1200.000000
19:39:43 ITERATION: Advancing config (2, 0, 4) to next budget 1200.000000
19:39:43 HBMASTER: schedule new run for iteration 2
19:39:43 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
19:39:43 HBMASTER: submitting job (2, 0, 0) to dispatcher
19:39:43 DISPATCHER: trying to submit job (2, 0, 0)
19:39:43 DISPATCHER: trying to notify the job_runner thread.
19:39:43 HBMASTER: job (2, 0, 0) submitted to dispatcher
19:39:43 DISPATCHER: Trying to submit another job.
19:39:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:39:43 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
19:39:43 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
19:39:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:39:43 WORKER: start processing job (2, 0, 0)
19:39:43 WORKER: args: ()
19:39:43 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012168033114691858, 'num_filters_1': 72, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.06676119103712362, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 41, 'num_filters_3': 96}, 'budget': 1200.0, 'working_directory': '.'}
19:39:44 DISPATCHER: Starting worker discovery
19:39:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:39:44 DISPATCHER: Finished worker discovery
19:40:44 DISPATCHER: Starting worker discovery
19:40:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:40:44 DISPATCHER: Finished worker discovery
19:41:44 DISPATCHER: Starting worker discovery
19:41:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:41:44 DISPATCHER: Finished worker discovery
19:42:44 DISPATCHER: Starting worker discovery
19:42:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:42:44 DISPATCHER: Finished worker discovery
19:43:44 DISPATCHER: Starting worker discovery
19:43:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:43:44 DISPATCHER: Finished worker discovery
19:44:44 DISPATCHER: Starting worker discovery
19:44:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:44:44 DISPATCHER: Finished worker discovery
19:45:44 DISPATCHER: Starting worker discovery
19:45:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:45:44 DISPATCHER: Finished worker discovery
19:46:44 DISPATCHER: Starting worker discovery
19:46:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:46:44 DISPATCHER: Finished worker discovery
19:47:44 DISPATCHER: Starting worker discovery
19:47:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:47:45 DISPATCHER: Finished worker discovery
19:48:45 DISPATCHER: Starting worker discovery
19:48:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:48:45 DISPATCHER: Finished worker discovery
19:49:45 DISPATCHER: Starting worker discovery
19:49:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:49:45 DISPATCHER: Finished worker discovery
19:50:45 DISPATCHER: Starting worker discovery
19:50:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:50:45 DISPATCHER: Finished worker discovery
19:51:45 DISPATCHER: Starting worker discovery
19:51:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:51:45 DISPATCHER: Finished worker discovery
19:52:45 DISPATCHER: Starting worker discovery
19:52:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:52:45 DISPATCHER: Finished worker discovery
19:53:45 DISPATCHER: Starting worker discovery
19:53:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:53:45 DISPATCHER: Finished worker discovery
19:54:45 DISPATCHER: Starting worker discovery
19:54:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:54:45 DISPATCHER: Finished worker discovery
19:55:45 DISPATCHER: Starting worker discovery
19:55:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:55:45 DISPATCHER: Finished worker discovery
19:56:45 DISPATCHER: Starting worker discovery
19:56:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:56:45 DISPATCHER: Finished worker discovery
19:57:45 DISPATCHER: Starting worker discovery
19:57:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:57:45 DISPATCHER: Finished worker discovery
19:58:45 DISPATCHER: Starting worker discovery
19:58:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:58:45 DISPATCHER: Finished worker discovery
19:59:45 DISPATCHER: Starting worker discovery
19:59:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:59:45 DISPATCHER: Finished worker discovery
20:00:45 DISPATCHER: Starting worker discovery
20:00:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:00:45 DISPATCHER: Finished worker discovery
20:00:52 WORKER: done with job (2, 0, 0), trying to register it.
20:00:52 WORKER: registered result for job (2, 0, 0) with dispatcher
20:00:52 DISPATCHER: job (2, 0, 0) finished
20:00:52 DISPATCHER: register_result: lock acquired
20:00:52 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
20:00:52 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012168033114691858, 'num_filters_1': 72, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.06676119103712362, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 41, 'num_filters_3': 96}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.009756488148968612, 'info': {'data04': 0.009756488148968612, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012168033114691858, 'num_filters_1': 72, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.06676119103712362, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 41, 'num_filters_3': 96}"}}
exception: None

20:00:52 job_callback for (2, 0, 0) started
20:00:52 job_callback for (2, 0, 0) got condition
20:00:52 DISPATCHER: Trying to submit another job.
20:00:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:00:52 Only 3 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
20:00:52 HBMASTER: Trying to run another job!
20:00:52 job_callback for (2, 0, 0) finished
20:00:52 HBMASTER: schedule new run for iteration 2
20:00:52 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
20:00:52 HBMASTER: submitting job (2, 0, 4) to dispatcher
20:00:52 DISPATCHER: trying to submit job (2, 0, 4)
20:00:52 DISPATCHER: trying to notify the job_runner thread.
20:00:52 HBMASTER: job (2, 0, 4) submitted to dispatcher
20:00:52 DISPATCHER: Trying to submit another job.
20:00:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:00:52 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
20:00:52 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
20:00:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:00:52 WORKER: start processing job (2, 0, 4)
20:00:52 WORKER: args: ()
20:00:52 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.016661102728448597, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.03729158964252535, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 31, 'num_filters_3': 31}, 'budget': 1200.0, 'working_directory': '.'}
20:01:45 DISPATCHER: Starting worker discovery
20:01:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:01:45 DISPATCHER: Finished worker discovery
20:02:45 DISPATCHER: Starting worker discovery
20:02:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:02:45 DISPATCHER: Finished worker discovery
20:03:45 DISPATCHER: Starting worker discovery
20:03:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:03:45 DISPATCHER: Finished worker discovery
20:04:45 DISPATCHER: Starting worker discovery
20:04:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:04:45 DISPATCHER: Finished worker discovery
20:05:45 DISPATCHER: Starting worker discovery
20:05:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:05:45 DISPATCHER: Finished worker discovery
20:06:45 DISPATCHER: Starting worker discovery
20:06:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:06:45 DISPATCHER: Finished worker discovery
20:07:45 DISPATCHER: Starting worker discovery
20:07:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:07:45 DISPATCHER: Finished worker discovery
20:08:45 DISPATCHER: Starting worker discovery
20:08:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:08:45 DISPATCHER: Finished worker discovery
20:09:45 DISPATCHER: Starting worker discovery
20:09:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:09:45 DISPATCHER: Finished worker discovery
20:10:45 DISPATCHER: Starting worker discovery
20:10:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:10:45 DISPATCHER: Finished worker discovery
20:11:45 DISPATCHER: Starting worker discovery
20:11:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:11:45 DISPATCHER: Finished worker discovery
20:12:45 DISPATCHER: Starting worker discovery
20:12:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:12:45 DISPATCHER: Finished worker discovery
20:13:45 DISPATCHER: Starting worker discovery
20:13:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:13:45 DISPATCHER: Finished worker discovery
20:14:45 DISPATCHER: Starting worker discovery
20:14:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:14:45 DISPATCHER: Finished worker discovery
20:15:45 DISPATCHER: Starting worker discovery
20:15:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:15:45 DISPATCHER: Finished worker discovery
20:16:45 DISPATCHER: Starting worker discovery
20:16:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:16:45 DISPATCHER: Finished worker discovery
20:17:45 DISPATCHER: Starting worker discovery
20:17:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:17:45 DISPATCHER: Finished worker discovery
20:18:45 DISPATCHER: Starting worker discovery
20:18:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:18:45 DISPATCHER: Finished worker discovery
20:19:45 DISPATCHER: Starting worker discovery
20:19:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:19:45 DISPATCHER: Finished worker discovery
20:20:45 DISPATCHER: Starting worker discovery
20:20:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:20:45 DISPATCHER: Finished worker discovery
20:21:45 DISPATCHER: Starting worker discovery
20:21:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:21:45 DISPATCHER: Finished worker discovery
20:22:45 DISPATCHER: Starting worker discovery
20:22:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:22:46 DISPATCHER: Finished worker discovery
20:23:30 WORKER: done with job (2, 0, 4), trying to register it.
20:23:30 WORKER: registered result for job (2, 0, 4) with dispatcher
20:23:30 DISPATCHER: job (2, 0, 4) finished
20:23:30 DISPATCHER: register_result: lock acquired
20:23:30 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
20:23:30 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.016661102728448597, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.03729158964252535, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 31, 'num_filters_3': 31}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.03901713898050384, 'info': {'data04': 0.03901713898050384, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.016661102728448597, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.03729158964252535, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 31, 'num_filters_3': 31}"}}
exception: None

20:23:30 job_callback for (2, 0, 4) started
20:23:30 DISPATCHER: Trying to submit another job.
20:23:30 job_callback for (2, 0, 4) got condition
20:23:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:23:30 Only 4 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
20:23:30 HBMASTER: Trying to run another job!
20:23:30 job_callback for (2, 0, 4) finished
20:23:30 start sampling a new configuration.
20:23:30 done sampling a new configuration.
20:23:30 HBMASTER: schedule new run for iteration 3
20:23:30 HBMASTER: trying submitting job (3, 0, 0) to dispatcher
20:23:30 HBMASTER: submitting job (3, 0, 0) to dispatcher
20:23:30 DISPATCHER: trying to submit job (3, 0, 0)
20:23:30 DISPATCHER: trying to notify the job_runner thread.
20:23:30 HBMASTER: job (3, 0, 0) submitted to dispatcher
20:23:30 DISPATCHER: Trying to submit another job.
20:23:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:23:30 DISPATCHER: starting job (3, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
20:23:30 DISPATCHER: job (3, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
20:23:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:23:30 WORKER: start processing job (3, 0, 0)
20:23:30 WORKER: args: ()
20:23:30 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.09643667427727116, 'num_filters_1': 105, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.050922385316546546, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 26, 'num_filters_3': 17, 'num_filters_4': 17, 'num_filters_5': 50}, 'budget': 1200.0, 'working_directory': '.'}
20:23:46 DISPATCHER: Starting worker discovery
20:23:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:23:46 DISPATCHER: Finished worker discovery
20:24:46 DISPATCHER: Starting worker discovery
20:24:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:24:46 DISPATCHER: Finished worker discovery
20:25:46 DISPATCHER: Starting worker discovery
20:25:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:25:46 DISPATCHER: Finished worker discovery
20:26:46 DISPATCHER: Starting worker discovery
20:26:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:26:46 DISPATCHER: Finished worker discovery
20:27:46 DISPATCHER: Starting worker discovery
20:27:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:27:46 DISPATCHER: Finished worker discovery
20:28:46 DISPATCHER: Starting worker discovery
20:28:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:28:46 DISPATCHER: Finished worker discovery
20:29:46 DISPATCHER: Starting worker discovery
20:29:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:29:46 DISPATCHER: Finished worker discovery
20:30:46 DISPATCHER: Starting worker discovery
20:30:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:30:46 DISPATCHER: Finished worker discovery
20:31:46 DISPATCHER: Starting worker discovery
20:31:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:31:46 DISPATCHER: Finished worker discovery
20:32:46 DISPATCHER: Starting worker discovery
20:32:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:32:46 DISPATCHER: Finished worker discovery
20:33:46 DISPATCHER: Starting worker discovery
20:33:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:33:46 DISPATCHER: Finished worker discovery
20:34:46 DISPATCHER: Starting worker discovery
20:34:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:34:46 DISPATCHER: Finished worker discovery
20:35:46 DISPATCHER: Starting worker discovery
20:35:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:35:46 DISPATCHER: Finished worker discovery
20:36:46 DISPATCHER: Starting worker discovery
20:36:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:36:46 DISPATCHER: Finished worker discovery
20:37:46 DISPATCHER: Starting worker discovery
20:37:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:37:46 DISPATCHER: Finished worker discovery
20:38:46 DISPATCHER: Starting worker discovery
20:38:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:38:46 DISPATCHER: Finished worker discovery
20:39:46 DISPATCHER: Starting worker discovery
20:39:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:39:46 DISPATCHER: Finished worker discovery
20:40:46 DISPATCHER: Starting worker discovery
20:40:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:40:46 DISPATCHER: Finished worker discovery
20:41:46 DISPATCHER: Starting worker discovery
20:41:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:41:46 DISPATCHER: Finished worker discovery
20:42:46 DISPATCHER: Starting worker discovery
20:42:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:42:46 DISPATCHER: Finished worker discovery
20:43:46 DISPATCHER: Starting worker discovery
20:43:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:43:46 DISPATCHER: Finished worker discovery
20:44:23 WORKER: done with job (3, 0, 0), trying to register it.
20:44:23 WORKER: registered result for job (3, 0, 0) with dispatcher
20:44:23 DISPATCHER: job (3, 0, 0) finished
20:44:23 DISPATCHER: register_result: lock acquired
20:44:23 DISPATCHER: job (3, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
20:44:23 job_id: (3, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.09643667427727116, 'num_filters_1': 105, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.050922385316546546, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 26, 'num_filters_3': 17, 'num_filters_4': 17, 'num_filters_5': 50}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0006972741637352453, 'info': {'data04': 0.0006972741637352453, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.09643667427727116, 'num_filters_1': 105, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.050922385316546546, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 26, 'num_filters_3': 17, 'num_filters_4': 17, 'num_filters_5': 50}"}}
exception: None

20:44:23 job_callback for (3, 0, 0) started
20:44:23 DISPATCHER: Trying to submit another job.
20:44:23 job_callback for (3, 0, 0) got condition
20:44:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:44:23 Only 5 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
20:44:23 HBMASTER: Trying to run another job!
20:44:23 job_callback for (3, 0, 0) finished
20:44:23 start sampling a new configuration.
20:44:23 done sampling a new configuration.
20:44:23 HBMASTER: schedule new run for iteration 3
20:44:23 HBMASTER: trying submitting job (3, 0, 1) to dispatcher
20:44:23 HBMASTER: submitting job (3, 0, 1) to dispatcher
20:44:23 DISPATCHER: trying to submit job (3, 0, 1)
20:44:23 DISPATCHER: trying to notify the job_runner thread.
20:44:23 HBMASTER: job (3, 0, 1) submitted to dispatcher
20:44:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:44:23 DISPATCHER: Trying to submit another job.
20:44:23 DISPATCHER: starting job (3, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
20:44:23 DISPATCHER: job (3, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
20:44:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:44:23 WORKER: start processing job (3, 0, 1)
20:44:23 WORKER: args: ()
20:44:23 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0681149183203484, 'num_filters_1': 80, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.1539449491847151, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 58, 'num_filters_3': 84}, 'budget': 1200.0, 'working_directory': '.'}
20:44:46 DISPATCHER: Starting worker discovery
20:44:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:44:46 DISPATCHER: Finished worker discovery
20:45:46 DISPATCHER: Starting worker discovery
20:45:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:45:46 DISPATCHER: Finished worker discovery
20:46:46 DISPATCHER: Starting worker discovery
20:46:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:46:46 DISPATCHER: Finished worker discovery
20:47:46 DISPATCHER: Starting worker discovery
20:47:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:47:46 DISPATCHER: Finished worker discovery
20:48:46 DISPATCHER: Starting worker discovery
20:48:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:48:46 DISPATCHER: Finished worker discovery
20:49:46 DISPATCHER: Starting worker discovery
20:49:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:49:46 DISPATCHER: Finished worker discovery
20:50:46 DISPATCHER: Starting worker discovery
20:50:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:50:46 DISPATCHER: Finished worker discovery
20:51:46 DISPATCHER: Starting worker discovery
20:51:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:51:46 DISPATCHER: Finished worker discovery
20:52:46 DISPATCHER: Starting worker discovery
20:52:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:52:46 DISPATCHER: Finished worker discovery
20:53:46 DISPATCHER: Starting worker discovery
20:53:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:53:46 DISPATCHER: Finished worker discovery
20:54:46 DISPATCHER: Starting worker discovery
20:54:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:54:46 DISPATCHER: Finished worker discovery
20:55:46 DISPATCHER: Starting worker discovery
20:55:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:55:46 DISPATCHER: Finished worker discovery
20:56:46 DISPATCHER: Starting worker discovery
20:56:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:56:46 DISPATCHER: Finished worker discovery
20:57:46 DISPATCHER: Starting worker discovery
20:57:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:57:46 DISPATCHER: Finished worker discovery
20:58:46 DISPATCHER: Starting worker discovery
20:58:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:58:46 DISPATCHER: Finished worker discovery
20:59:46 DISPATCHER: Starting worker discovery
20:59:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:59:46 DISPATCHER: Finished worker discovery
21:00:46 DISPATCHER: Starting worker discovery
21:00:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:00:46 DISPATCHER: Finished worker discovery
21:01:46 DISPATCHER: Starting worker discovery
21:01:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:01:46 DISPATCHER: Finished worker discovery
21:02:46 DISPATCHER: Starting worker discovery
21:02:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:02:46 DISPATCHER: Finished worker discovery
21:03:46 DISPATCHER: Starting worker discovery
21:03:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:03:46 DISPATCHER: Finished worker discovery
21:04:46 DISPATCHER: Starting worker discovery
21:04:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:04:46 DISPATCHER: Finished worker discovery
21:05:46 DISPATCHER: Starting worker discovery
21:05:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:05:47 DISPATCHER: Finished worker discovery
21:06:42 WORKER: done with job (3, 0, 1), trying to register it.
21:06:42 WORKER: registered result for job (3, 0, 1) with dispatcher
21:06:42 DISPATCHER: job (3, 0, 1) finished
21:06:42 DISPATCHER: register_result: lock acquired
21:06:42 DISPATCHER: job (3, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
21:06:42 job_id: (3, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0681149183203484, 'num_filters_1': 80, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.1539449491847151, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 58, 'num_filters_3': 84}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0681149183203484, 'num_filters_1': 80, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.1539449491847151, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 58, 'num_filters_3': 84}"}}
exception: None

21:06:42 job_callback for (3, 0, 1) started
21:06:42 DISPATCHER: Trying to submit another job.
21:06:42 job_callback for (3, 0, 1) got condition
21:06:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:06:42 Only 6 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
21:06:42 HBMASTER: Trying to run another job!
21:06:42 job_callback for (3, 0, 1) finished
21:06:42 start sampling a new configuration.
21:06:42 done sampling a new configuration.
21:06:42 HBMASTER: schedule new run for iteration 3
21:06:42 HBMASTER: trying submitting job (3, 0, 2) to dispatcher
21:06:42 HBMASTER: submitting job (3, 0, 2) to dispatcher
21:06:42 DISPATCHER: trying to submit job (3, 0, 2)
21:06:42 DISPATCHER: trying to notify the job_runner thread.
21:06:42 HBMASTER: job (3, 0, 2) submitted to dispatcher
21:06:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:06:42 DISPATCHER: Trying to submit another job.
21:06:42 DISPATCHER: starting job (3, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:06:42 DISPATCHER: job (3, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:06:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:06:42 WORKER: start processing job (3, 0, 2)
21:06:42 WORKER: args: ()
21:06:42 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.014756091535722006, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.10982748434436572, 'kernel_size_2': 7, 'num_filters_2': 30}, 'budget': 1200.0, 'working_directory': '.'}
21:06:47 DISPATCHER: Starting worker discovery
21:06:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:06:47 DISPATCHER: Finished worker discovery
21:07:47 DISPATCHER: Starting worker discovery
21:07:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:07:47 DISPATCHER: Finished worker discovery
21:08:47 DISPATCHER: Starting worker discovery
21:08:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:08:47 DISPATCHER: Finished worker discovery
21:09:47 DISPATCHER: Starting worker discovery
21:09:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:09:47 DISPATCHER: Finished worker discovery
21:10:47 DISPATCHER: Starting worker discovery
21:10:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:10:47 DISPATCHER: Finished worker discovery
21:11:47 DISPATCHER: Starting worker discovery
21:11:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:11:47 DISPATCHER: Finished worker discovery
21:12:47 DISPATCHER: Starting worker discovery
21:12:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:12:47 DISPATCHER: Finished worker discovery
21:13:47 DISPATCHER: Starting worker discovery
21:13:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:13:47 DISPATCHER: Finished worker discovery
21:14:47 DISPATCHER: Starting worker discovery
21:14:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:14:47 DISPATCHER: Finished worker discovery
21:15:47 DISPATCHER: Starting worker discovery
21:15:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:15:47 DISPATCHER: Finished worker discovery
21:16:47 DISPATCHER: Starting worker discovery
21:16:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:16:47 DISPATCHER: Finished worker discovery
21:17:47 DISPATCHER: Starting worker discovery
21:17:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:17:47 DISPATCHER: Finished worker discovery
21:18:47 DISPATCHER: Starting worker discovery
21:18:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:18:47 DISPATCHER: Finished worker discovery
21:19:47 DISPATCHER: Starting worker discovery
21:19:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:19:47 DISPATCHER: Finished worker discovery
21:20:47 DISPATCHER: Starting worker discovery
21:20:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:20:47 DISPATCHER: Finished worker discovery
21:21:47 DISPATCHER: Starting worker discovery
21:21:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:21:47 DISPATCHER: Finished worker discovery
21:22:47 DISPATCHER: Starting worker discovery
21:22:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:22:47 DISPATCHER: Finished worker discovery
21:23:47 DISPATCHER: Starting worker discovery
21:23:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:23:47 DISPATCHER: Finished worker discovery
21:24:47 DISPATCHER: Starting worker discovery
21:24:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:24:47 DISPATCHER: Finished worker discovery
21:25:47 DISPATCHER: Starting worker discovery
21:25:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:25:47 DISPATCHER: Finished worker discovery
21:26:47 DISPATCHER: Starting worker discovery
21:26:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:26:47 DISPATCHER: Finished worker discovery
21:27:31 WORKER: done with job (3, 0, 2), trying to register it.
21:27:31 WORKER: registered result for job (3, 0, 2) with dispatcher
21:27:31 DISPATCHER: job (3, 0, 2) finished
21:27:31 DISPATCHER: register_result: lock acquired
21:27:31 DISPATCHER: job (3, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
21:27:31 job_id: (3, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.014756091535722006, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.10982748434436572, 'kernel_size_2': 7, 'num_filters_2': 30}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -5.613187724650571e-05, 'info': {'data04': 5.613187724650571e-05, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.014756091535722006, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.10982748434436572, 'kernel_size_2': 7, 'num_filters_2': 30}"}}
exception: None

21:27:31 job_callback for (3, 0, 2) started
21:27:31 DISPATCHER: Trying to submit another job.
21:27:31 job_callback for (3, 0, 2) got condition
21:27:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:27:31 Only 7 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
21:27:31 HBMASTER: Trying to run another job!
21:27:31 job_callback for (3, 0, 2) finished
21:27:31 start sampling a new configuration.
21:27:31 done sampling a new configuration.
21:27:31 HBMASTER: schedule new run for iteration 3
21:27:31 HBMASTER: trying submitting job (3, 0, 3) to dispatcher
21:27:31 HBMASTER: submitting job (3, 0, 3) to dispatcher
21:27:31 DISPATCHER: trying to submit job (3, 0, 3)
21:27:31 DISPATCHER: trying to notify the job_runner thread.
21:27:31 HBMASTER: job (3, 0, 3) submitted to dispatcher
21:27:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:27:31 DISPATCHER: Trying to submit another job.
21:27:31 DISPATCHER: starting job (3, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:27:31 DISPATCHER: job (3, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:27:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:27:31 WORKER: start processing job (3, 0, 3)
21:27:31 WORKER: args: ()
21:27:31 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001973674492902854, 'num_filters_1': 116, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.11037817109506079}, 'budget': 1200.0, 'working_directory': '.'}
21:27:47 DISPATCHER: Starting worker discovery
21:27:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:27:47 DISPATCHER: Finished worker discovery
21:28:47 DISPATCHER: Starting worker discovery
21:28:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:28:47 DISPATCHER: Finished worker discovery
21:29:47 DISPATCHER: Starting worker discovery
21:29:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:29:47 DISPATCHER: Finished worker discovery
21:30:47 DISPATCHER: Starting worker discovery
21:30:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:30:47 DISPATCHER: Finished worker discovery
21:31:47 DISPATCHER: Starting worker discovery
21:31:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:31:47 DISPATCHER: Finished worker discovery
21:32:47 DISPATCHER: Starting worker discovery
21:32:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:32:47 DISPATCHER: Finished worker discovery
21:33:47 DISPATCHER: Starting worker discovery
21:33:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:33:47 DISPATCHER: Finished worker discovery
21:34:47 DISPATCHER: Starting worker discovery
21:34:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:34:47 DISPATCHER: Finished worker discovery
21:35:47 DISPATCHER: Starting worker discovery
21:35:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:35:47 DISPATCHER: Finished worker discovery
21:36:47 DISPATCHER: Starting worker discovery
21:36:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:36:47 DISPATCHER: Finished worker discovery
21:37:47 DISPATCHER: Starting worker discovery
21:37:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:37:47 DISPATCHER: Finished worker discovery
21:38:47 DISPATCHER: Starting worker discovery
21:38:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:38:47 DISPATCHER: Finished worker discovery
21:39:47 DISPATCHER: Starting worker discovery
21:39:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:39:47 DISPATCHER: Finished worker discovery
21:40:47 DISPATCHER: Starting worker discovery
21:40:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:40:47 DISPATCHER: Finished worker discovery
21:41:47 DISPATCHER: Starting worker discovery
21:41:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:41:47 DISPATCHER: Finished worker discovery
21:42:47 DISPATCHER: Starting worker discovery
21:42:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:42:47 DISPATCHER: Finished worker discovery
21:43:47 DISPATCHER: Starting worker discovery
21:43:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:43:47 DISPATCHER: Finished worker discovery
21:44:47 DISPATCHER: Starting worker discovery
21:44:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:44:47 DISPATCHER: Finished worker discovery
21:45:47 DISPATCHER: Starting worker discovery
21:45:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:45:47 DISPATCHER: Finished worker discovery
21:46:47 DISPATCHER: Starting worker discovery
21:46:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:46:47 DISPATCHER: Finished worker discovery
21:47:47 DISPATCHER: Starting worker discovery
21:47:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:47:47 DISPATCHER: Finished worker discovery
21:48:38 WORKER: done with job (3, 0, 3), trying to register it.
21:48:38 WORKER: registered result for job (3, 0, 3) with dispatcher
21:48:38 DISPATCHER: job (3, 0, 3) finished
21:48:38 DISPATCHER: register_result: lock acquired
21:48:38 DISPATCHER: job (3, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
21:48:38 job_id: (3, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001973674492902854, 'num_filters_1': 116, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.11037817109506079}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.05360093137688133, 'info': {'data04': 0.05360093137688133, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001973674492902854, 'num_filters_1': 116, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.11037817109506079}"}}
exception: None

21:48:38 job_callback for (3, 0, 3) started
21:48:38 DISPATCHER: Trying to submit another job.
21:48:38 job_callback for (3, 0, 3) got condition
21:48:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:48:38 Only 8 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
21:48:38 HBMASTER: Trying to run another job!
21:48:38 job_callback for (3, 0, 3) finished
21:48:38 start sampling a new configuration.
21:48:38 done sampling a new configuration.
21:48:38 HBMASTER: schedule new run for iteration 4
21:48:38 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
21:48:38 HBMASTER: submitting job (4, 0, 0) to dispatcher
21:48:38 DISPATCHER: trying to submit job (4, 0, 0)
21:48:38 DISPATCHER: trying to notify the job_runner thread.
21:48:38 HBMASTER: job (4, 0, 0) submitted to dispatcher
21:48:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:48:38 DISPATCHER: Trying to submit another job.
21:48:38 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:48:38 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:48:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:48:38 WORKER: start processing job (4, 0, 0)
21:48:38 WORKER: args: ()
21:48:38 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.002222238454775013, 'num_filters_1': 25, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.05428378259225723, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 50, 'num_filters_3': 101}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:48:47 DISPATCHER: Starting worker discovery
21:48:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:48:47 DISPATCHER: Finished worker discovery
21:49:39 WORKER: done with job (4, 0, 0), trying to register it.
21:49:39 WORKER: registered result for job (4, 0, 0) with dispatcher
21:49:39 DISPATCHER: job (4, 0, 0) finished
21:49:39 DISPATCHER: register_result: lock acquired
21:49:39 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
21:49:39 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.002222238454775013, 'num_filters_1': 25, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.05428378259225723, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 50, 'num_filters_3': 101}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1580592468802872, 'info': {'data04': 0.1580592468802872, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.002222238454775013, 'num_filters_1': 25, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.05428378259225723, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 50, 'num_filters_3': 101}"}}
exception: None

21:49:39 job_callback for (4, 0, 0) started
21:49:39 DISPATCHER: Trying to submit another job.
21:49:39 job_callback for (4, 0, 0) got condition
21:49:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:49:39 HBMASTER: Trying to run another job!
21:49:39 job_callback for (4, 0, 0) finished
21:49:39 start sampling a new configuration.
21:49:39 done sampling a new configuration.
21:49:39 HBMASTER: schedule new run for iteration 4
21:49:39 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
21:49:39 HBMASTER: submitting job (4, 0, 1) to dispatcher
21:49:39 DISPATCHER: trying to submit job (4, 0, 1)
21:49:39 DISPATCHER: trying to notify the job_runner thread.
21:49:39 HBMASTER: job (4, 0, 1) submitted to dispatcher
21:49:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:49:39 DISPATCHER: Trying to submit another job.
21:49:39 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:49:39 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:49:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:49:39 WORKER: start processing job (4, 0, 1)
21:49:39 WORKER: args: ()
21:49:39 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.020350171850102648, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.013360691193823498, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 94, 'num_filters_3': 18, 'num_filters_4': 54, 'num_filters_5': 66}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:49:47 DISPATCHER: Starting worker discovery
21:49:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:49:47 DISPATCHER: Finished worker discovery
21:50:43 WORKER: done with job (4, 0, 1), trying to register it.
21:50:43 WORKER: registered result for job (4, 0, 1) with dispatcher
21:50:43 DISPATCHER: job (4, 0, 1) finished
21:50:43 DISPATCHER: register_result: lock acquired
21:50:43 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
21:50:43 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.020350171850102648, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.013360691193823498, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 94, 'num_filters_3': 18, 'num_filters_4': 54, 'num_filters_5': 66}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.14043612310609577, 'info': {'data04': 0.14043612310609577, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.020350171850102648, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.013360691193823498, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 94, 'num_filters_3': 18, 'num_filters_4': 54, 'num_filters_5': 66}"}}
exception: None

21:50:43 job_callback for (4, 0, 1) started
21:50:43 DISPATCHER: Trying to submit another job.
21:50:43 job_callback for (4, 0, 1) got condition
21:50:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:50:43 HBMASTER: Trying to run another job!
21:50:43 job_callback for (4, 0, 1) finished
21:50:43 start sampling a new configuration.
21:50:43 done sampling a new configuration.
21:50:43 HBMASTER: schedule new run for iteration 4
21:50:43 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
21:50:43 HBMASTER: submitting job (4, 0, 2) to dispatcher
21:50:43 DISPATCHER: trying to submit job (4, 0, 2)
21:50:43 DISPATCHER: trying to notify the job_runner thread.
21:50:43 HBMASTER: job (4, 0, 2) submitted to dispatcher
21:50:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:50:43 DISPATCHER: Trying to submit another job.
21:50:43 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:50:43 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:50:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:50:43 WORKER: start processing job (4, 0, 2)
21:50:43 WORKER: args: ()
21:50:43 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.03652498463676342, 'num_filters_1': 116, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.030178856506919594, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 38, 'num_filters_3': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:50:47 DISPATCHER: Starting worker discovery
21:50:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:50:47 DISPATCHER: Finished worker discovery
21:51:45 WORKER: done with job (4, 0, 2), trying to register it.
21:51:45 WORKER: registered result for job (4, 0, 2) with dispatcher
21:51:45 DISPATCHER: job (4, 0, 2) finished
21:51:45 DISPATCHER: register_result: lock acquired
21:51:45 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
21:51:45 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.03652498463676342, 'num_filters_1': 116, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.030178856506919594, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 38, 'num_filters_3': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.03704570801350737, 'info': {'data04': 0.03704570801350737, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.03652498463676342, 'num_filters_1': 116, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.030178856506919594, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 38, 'num_filters_3': 21}"}}
exception: None

21:51:45 job_callback for (4, 0, 2) started
21:51:45 DISPATCHER: Trying to submit another job.
21:51:45 job_callback for (4, 0, 2) got condition
21:51:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:51:45 HBMASTER: Trying to run another job!
21:51:45 job_callback for (4, 0, 2) finished
21:51:45 start sampling a new configuration.
21:51:45 done sampling a new configuration.
21:51:45 HBMASTER: schedule new run for iteration 4
21:51:45 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
21:51:45 HBMASTER: submitting job (4, 0, 3) to dispatcher
21:51:45 DISPATCHER: trying to submit job (4, 0, 3)
21:51:45 DISPATCHER: trying to notify the job_runner thread.
21:51:45 HBMASTER: job (4, 0, 3) submitted to dispatcher
21:51:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:51:45 DISPATCHER: Trying to submit another job.
21:51:45 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:51:45 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:51:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:51:45 WORKER: start processing job (4, 0, 3)
21:51:45 WORKER: args: ()
21:51:45 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.07592397716739084, 'num_filters_1': 77, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.03000671786845474, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 55, 'num_filters_3': 73, 'num_filters_4': 85}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:51:47 DISPATCHER: Starting worker discovery
21:51:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:51:47 DISPATCHER: Finished worker discovery
21:52:45 WORKER: done with job (4, 0, 3), trying to register it.
21:52:45 WORKER: registered result for job (4, 0, 3) with dispatcher
21:52:45 DISPATCHER: job (4, 0, 3) finished
21:52:45 DISPATCHER: register_result: lock acquired
21:52:45 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
21:52:45 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.07592397716739084, 'num_filters_1': 77, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.03000671786845474, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 55, 'num_filters_3': 73, 'num_filters_4': 85}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.003575078438112742, 'info': {'data04': 0.003575078438112742, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.07592397716739084, 'num_filters_1': 77, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.03000671786845474, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 55, 'num_filters_3': 73, 'num_filters_4': 85}"}}
exception: None

21:52:45 job_callback for (4, 0, 3) started
21:52:45 job_callback for (4, 0, 3) got condition
21:52:45 DISPATCHER: Trying to submit another job.
21:52:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:52:45 HBMASTER: Trying to run another job!
21:52:45 job_callback for (4, 0, 3) finished
21:52:45 start sampling a new configuration.
21:52:45 done sampling a new configuration.
21:52:45 HBMASTER: schedule new run for iteration 4
21:52:45 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
21:52:45 HBMASTER: submitting job (4, 0, 4) to dispatcher
21:52:45 DISPATCHER: trying to submit job (4, 0, 4)
21:52:45 DISPATCHER: trying to notify the job_runner thread.
21:52:45 HBMASTER: job (4, 0, 4) submitted to dispatcher
21:52:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:52:45 DISPATCHER: Trying to submit another job.
21:52:45 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:52:45 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:52:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:52:45 WORKER: start processing job (4, 0, 4)
21:52:45 WORKER: args: ()
21:52:45 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.014268506744274363, 'num_filters_1': 108, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.020733416959949763, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 39, 'num_filters_3': 26, 'num_filters_4': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:52:47 DISPATCHER: Starting worker discovery
21:52:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:52:47 DISPATCHER: Finished worker discovery
21:53:47 WORKER: done with job (4, 0, 4), trying to register it.
21:53:47 WORKER: registered result for job (4, 0, 4) with dispatcher
21:53:47 DISPATCHER: job (4, 0, 4) finished
21:53:47 DISPATCHER: register_result: lock acquired
21:53:47 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
21:53:47 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.014268506744274363, 'num_filters_1': 108, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.020733416959949763, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 39, 'num_filters_3': 26, 'num_filters_4': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.16607228496702864, 'info': {'data04': 0.16607228496702864, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.014268506744274363, 'num_filters_1': 108, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.020733416959949763, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 39, 'num_filters_3': 26, 'num_filters_4': 16}"}}
exception: None

21:53:47 job_callback for (4, 0, 4) started
21:53:47 DISPATCHER: Trying to submit another job.
21:53:47 job_callback for (4, 0, 4) got condition
21:53:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:53:47 HBMASTER: Trying to run another job!
21:53:47 job_callback for (4, 0, 4) finished
21:53:47 start sampling a new configuration.
21:53:47 done sampling a new configuration.
21:53:47 HBMASTER: schedule new run for iteration 4
21:53:47 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
21:53:47 HBMASTER: submitting job (4, 0, 5) to dispatcher
21:53:47 DISPATCHER: trying to submit job (4, 0, 5)
21:53:47 DISPATCHER: trying to notify the job_runner thread.
21:53:47 HBMASTER: job (4, 0, 5) submitted to dispatcher
21:53:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:53:47 DISPATCHER: Trying to submit another job.
21:53:47 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:53:47 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:53:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:53:47 WORKER: start processing job (4, 0, 5)
21:53:47 WORKER: args: ()
21:53:47 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.060489623612819045, 'num_filters_1': 77, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.018986844113683732, 'kernel_size_2': 5, 'num_filters_2': 39}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:53:47 DISPATCHER: Starting worker discovery
21:53:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:53:47 DISPATCHER: Finished worker discovery
21:54:46 WORKER: done with job (4, 0, 5), trying to register it.
21:54:46 WORKER: registered result for job (4, 0, 5) with dispatcher
21:54:46 DISPATCHER: job (4, 0, 5) finished
21:54:46 DISPATCHER: register_result: lock acquired
21:54:46 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
21:54:46 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.060489623612819045, 'num_filters_1': 77, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.018986844113683732, 'kernel_size_2': 5, 'num_filters_2': 39}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.0072336443355717865, 'info': {'data04': -0.0072336443355717865, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.060489623612819045, 'num_filters_1': 77, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.018986844113683732, 'kernel_size_2': 5, 'num_filters_2': 39}"}}
exception: None

21:54:46 job_callback for (4, 0, 5) started
21:54:46 DISPATCHER: Trying to submit another job.
21:54:46 job_callback for (4, 0, 5) got condition
21:54:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:54:46 HBMASTER: Trying to run another job!
21:54:46 job_callback for (4, 0, 5) finished
21:54:46 start sampling a new configuration.
21:54:46 done sampling a new configuration.
21:54:46 HBMASTER: schedule new run for iteration 4
21:54:46 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
21:54:46 HBMASTER: submitting job (4, 0, 6) to dispatcher
21:54:46 DISPATCHER: trying to submit job (4, 0, 6)
21:54:46 DISPATCHER: trying to notify the job_runner thread.
21:54:46 HBMASTER: job (4, 0, 6) submitted to dispatcher
21:54:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:54:46 DISPATCHER: Trying to submit another job.
21:54:46 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:54:46 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:54:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:54:46 WORKER: start processing job (4, 0, 6)
21:54:46 WORKER: args: ()
21:54:46 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.009615350265265582, 'num_filters_1': 114, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.04699675753914373, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 52, 'num_filters_3': 33, 'num_filters_4': 18, 'num_filters_5': 64}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:54:47 DISPATCHER: Starting worker discovery
21:54:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:54:47 DISPATCHER: Finished worker discovery
21:55:47 WORKER: done with job (4, 0, 6), trying to register it.
21:55:47 WORKER: registered result for job (4, 0, 6) with dispatcher
21:55:47 DISPATCHER: job (4, 0, 6) finished
21:55:47 DISPATCHER: register_result: lock acquired
21:55:47 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
21:55:47 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.009615350265265582, 'num_filters_1': 114, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.04699675753914373, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 52, 'num_filters_3': 33, 'num_filters_4': 18, 'num_filters_5': 64}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0782463716236215, 'info': {'data04': 0.0782463716236215, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.009615350265265582, 'num_filters_1': 114, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.04699675753914373, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 52, 'num_filters_3': 33, 'num_filters_4': 18, 'num_filters_5': 64}"}}
exception: None

21:55:47 job_callback for (4, 0, 6) started
21:55:47 job_callback for (4, 0, 6) got condition
21:55:47 DISPATCHER: Trying to submit another job.
21:55:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:55:47 done building a new model for budget 44.444444 based on 17/28 split
Best loss for this budget:-0.173066





21:55:47 HBMASTER: Trying to run another job!
21:55:47 job_callback for (4, 0, 6) finished
21:55:47 start sampling a new configuration.
21:55:47 best_vector: [0, 1, 0.6714475351966833, 0.6047534712030487, 0.21656630090978046, 1, 0.8713616619072877, 0.4274765907261856, 2, 1, 2, 0, 0.09359044979535533, 0.7134307423385553, 0.4641279116702947, 0.6804481355951392], 1.8334972476097183e-30, 0.005454057819305011, -1.2589256644530156e-05
21:55:47 done sampling a new configuration.
21:55:47 HBMASTER: schedule new run for iteration 4
21:55:47 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
21:55:47 HBMASTER: submitting job (4, 0, 7) to dispatcher
21:55:47 DISPATCHER: trying to submit job (4, 0, 7)
21:55:47 DISPATCHER: trying to notify the job_runner thread.
21:55:47 HBMASTER: job (4, 0, 7) submitted to dispatcher
21:55:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:55:47 DISPATCHER: Trying to submit another job.
21:55:47 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:55:47 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:55:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:55:47 WORKER: start processing job (4, 0, 7)
21:55:47 WORKER: args: ()
21:55:47 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.022023942797197448, 'num_filters_1': 56, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.03598817858968532, 'kernel_size_2': 7, 'num_filters_2': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:55:47 DISPATCHER: Starting worker discovery
21:55:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:55:47 DISPATCHER: Finished worker discovery
21:56:47 DISPATCHER: Starting worker discovery
21:56:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:56:48 DISPATCHER: Finished worker discovery
21:56:48 WORKER: done with job (4, 0, 7), trying to register it.
21:56:48 WORKER: registered result for job (4, 0, 7) with dispatcher
21:56:48 DISPATCHER: job (4, 0, 7) finished
21:56:48 DISPATCHER: register_result: lock acquired
21:56:48 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
21:56:48 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.022023942797197448, 'num_filters_1': 56, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.03598817858968532, 'kernel_size_2': 7, 'num_filters_2': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.12031874506501404, 'info': {'data04': 0.12031874506501404, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.022023942797197448, 'num_filters_1': 56, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.03598817858968532, 'kernel_size_2': 7, 'num_filters_2': 19}"}}
exception: None

21:56:48 job_callback for (4, 0, 7) started
21:56:48 DISPATCHER: Trying to submit another job.
21:56:48 job_callback for (4, 0, 7) got condition
21:56:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:56:48 done building a new model for budget 44.444444 based on 17/29 split
Best loss for this budget:-0.173066





21:56:48 HBMASTER: Trying to run another job!
21:56:48 job_callback for (4, 0, 7) finished
21:56:48 start sampling a new configuration.
21:56:48 best_vector: [2, 2, 0.5629759949802055, 0.6703053821393637, 0.11124801163197601, 0, 0.14648128344505096, 0.6102139351048355, 2, 1, 1, 0, 0.0019164988931955618, 0.1882923256910659, 0.027284767316930837, 0.6628914982078448], 0.00012602392154603548, 0.0003188227814463164, 4.0179297196079396e-08
21:56:48 done sampling a new configuration.
21:56:48 HBMASTER: schedule new run for iteration 4
21:56:48 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
21:56:48 HBMASTER: submitting job (4, 0, 8) to dispatcher
21:56:48 DISPATCHER: trying to submit job (4, 0, 8)
21:56:48 DISPATCHER: trying to notify the job_runner thread.
21:56:48 HBMASTER: job (4, 0, 8) submitted to dispatcher
21:56:48 DISPATCHER: Trying to submit another job.
21:56:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:56:48 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:56:48 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:56:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:56:48 WORKER: start processing job (4, 0, 8)
21:56:48 WORKER: args: ()
21:56:48 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.013364477678193426, 'num_filters_1': 64, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.06221665145267141}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:57:48 DISPATCHER: Starting worker discovery
21:57:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:57:48 DISPATCHER: Finished worker discovery
21:57:53 WORKER: done with job (4, 0, 8), trying to register it.
21:57:53 WORKER: registered result for job (4, 0, 8) with dispatcher
21:57:53 DISPATCHER: job (4, 0, 8) finished
21:57:53 DISPATCHER: register_result: lock acquired
21:57:53 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
21:57:53 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.013364477678193426, 'num_filters_1': 64, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.06221665145267141}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0004831069661431934, 'info': {'data04': 0.0004831069661431934, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.013364477678193426, 'num_filters_1': 64, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.06221665145267141}"}}
exception: None

21:57:53 job_callback for (4, 0, 8) started
21:57:53 DISPATCHER: Trying to submit another job.
21:57:53 job_callback for (4, 0, 8) got condition
21:57:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:57:53 done building a new model for budget 44.444444 based on 17/30 split
Best loss for this budget:-0.173066





21:57:53 HBMASTER: Trying to run another job!
21:57:53 job_callback for (4, 0, 8) finished
21:57:53 start sampling a new configuration.
21:57:53 done sampling a new configuration.
21:57:53 HBMASTER: schedule new run for iteration 4
21:57:53 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
21:57:53 HBMASTER: submitting job (4, 0, 9) to dispatcher
21:57:53 DISPATCHER: trying to submit job (4, 0, 9)
21:57:53 DISPATCHER: trying to notify the job_runner thread.
21:57:53 HBMASTER: job (4, 0, 9) submitted to dispatcher
21:57:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:57:53 DISPATCHER: Trying to submit another job.
21:57:53 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:57:53 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:57:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:57:53 WORKER: start processing job (4, 0, 9)
21:57:53 WORKER: args: ()
21:57:53 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001429819509865202, 'num_filters_1': 120, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.1768564137109531}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:58:48 DISPATCHER: Starting worker discovery
21:58:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:58:48 DISPATCHER: Finished worker discovery
21:58:54 WORKER: done with job (4, 0, 9), trying to register it.
21:58:54 WORKER: registered result for job (4, 0, 9) with dispatcher
21:58:54 DISPATCHER: job (4, 0, 9) finished
21:58:54 DISPATCHER: register_result: lock acquired
21:58:54 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
21:58:54 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001429819509865202, 'num_filters_1': 120, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.1768564137109531}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.05265281777763056, 'info': {'data04': 0.05265281777763056, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001429819509865202, 'num_filters_1': 120, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.1768564137109531}"}}
exception: None

21:58:54 job_callback for (4, 0, 9) started
21:58:54 job_callback for (4, 0, 9) got condition
21:58:54 DISPATCHER: Trying to submit another job.
21:58:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:58:54 done building a new model for budget 44.444444 based on 17/31 split
Best loss for this budget:-0.173066





21:58:54 HBMASTER: Trying to run another job!
21:58:54 job_callback for (4, 0, 9) finished
21:58:54 start sampling a new configuration.
21:58:54 best_vector: [0, 2, 0.06720483547451384, 0.8991957843760301, 0.8721582105233743, 1, 0.9080111439627958, 0.4700648325876844, 1, 1, 2, 1, 0.551449958566226, 0.039211185671080534, 0.09123885553416711, 0.694644128936341], 6.467703215153402e-28, 1.546143919617502e-05, -5.008967589972371e-07
21:58:54 done sampling a new configuration.
21:58:54 HBMASTER: schedule new run for iteration 4
21:58:54 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
21:58:54 HBMASTER: submitting job (4, 0, 10) to dispatcher
21:58:54 DISPATCHER: trying to submit job (4, 0, 10)
21:58:54 DISPATCHER: trying to notify the job_runner thread.
21:58:54 HBMASTER: job (4, 0, 10) submitted to dispatcher
21:58:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:58:54 DISPATCHER: Trying to submit another job.
21:58:54 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:58:54 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:58:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:58:54 WORKER: start processing job (4, 0, 10)
21:58:54 WORKER: args: ()
21:58:54 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0013627295421679176, 'num_filters_1': 104, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.040885418461170706, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 50, 'num_filters_3': 17, 'num_filters_4': 19, 'num_filters_5': 67}, 'budget': 44.44444444444444, 'working_directory': '.'}
21:59:48 DISPATCHER: Starting worker discovery
21:59:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:59:48 DISPATCHER: Finished worker discovery
21:59:54 WORKER: done with job (4, 0, 10), trying to register it.
21:59:54 WORKER: registered result for job (4, 0, 10) with dispatcher
21:59:54 DISPATCHER: job (4, 0, 10) finished
21:59:54 DISPATCHER: register_result: lock acquired
21:59:54 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
21:59:54 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0013627295421679176, 'num_filters_1': 104, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.040885418461170706, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 50, 'num_filters_3': 17, 'num_filters_4': 19, 'num_filters_5': 67}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1422482151591244, 'info': {'data04': 0.1422482151591244, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0013627295421679176, 'num_filters_1': 104, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.040885418461170706, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 50, 'num_filters_3': 17, 'num_filters_4': 19, 'num_filters_5': 67}"}}
exception: None

21:59:54 job_callback for (4, 0, 10) started
21:59:54 job_callback for (4, 0, 10) got condition
21:59:54 DISPATCHER: Trying to submit another job.
21:59:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:59:54 done building a new model for budget 44.444444 based on 17/32 split
Best loss for this budget:-0.173066





21:59:54 HBMASTER: Trying to run another job!
21:59:54 job_callback for (4, 0, 10) finished
21:59:54 start sampling a new configuration.
21:59:54 best_vector: [1, 2, 0.4079557488574516, 0.44111006514783707, 0.06832141469759528, 1, 0.8575893495625989, 0.8288235239142253, 0, 0, 1, 2, 0.05972095779901865, 0.7547785166852632, 0.18201064522981192, 0.6840924789881202], 0.0006756424578933763, 0.00196767958037261, 1.3294478680295576e-06
21:59:54 done sampling a new configuration.
21:59:54 HBMASTER: schedule new run for iteration 4
21:59:54 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
21:59:54 HBMASTER: submitting job (4, 0, 11) to dispatcher
21:59:54 DISPATCHER: trying to submit job (4, 0, 11)
21:59:54 DISPATCHER: trying to notify the job_runner thread.
21:59:54 HBMASTER: job (4, 0, 11) submitted to dispatcher
21:59:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:59:54 DISPATCHER: Trying to submit another job.
21:59:54 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:59:54 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
21:59:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:59:54 WORKER: start processing job (4, 0, 11)
21:59:54 WORKER: args: ()
21:59:54 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006545027832533699, 'num_filters_1': 39, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.11976344106001408}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:00:48 DISPATCHER: Starting worker discovery
22:00:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:00:48 DISPATCHER: Finished worker discovery
22:00:54 WORKER: done with job (4, 0, 11), trying to register it.
22:00:54 WORKER: registered result for job (4, 0, 11) with dispatcher
22:00:54 DISPATCHER: job (4, 0, 11) finished
22:00:54 DISPATCHER: register_result: lock acquired
22:00:54 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:00:54 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006545027832533699, 'num_filters_1': 39, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.11976344106001408}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.051949343608892196, 'info': {'data04': 0.051949343608892196, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.006545027832533699, 'num_filters_1': 39, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.11976344106001408}"}}
exception: None

22:00:54 job_callback for (4, 0, 11) started
22:00:54 job_callback for (4, 0, 11) got condition
22:00:54 DISPATCHER: Trying to submit another job.
22:00:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:00:54 done building a new model for budget 44.444444 based on 17/33 split
Best loss for this budget:-0.173066





22:00:54 HBMASTER: Trying to run another job!
22:00:54 job_callback for (4, 0, 11) finished
22:00:54 start sampling a new configuration.
22:00:54 done sampling a new configuration.
22:00:54 HBMASTER: schedule new run for iteration 4
22:00:54 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
22:00:54 HBMASTER: submitting job (4, 0, 12) to dispatcher
22:00:54 DISPATCHER: trying to submit job (4, 0, 12)
22:00:54 DISPATCHER: trying to notify the job_runner thread.
22:00:54 HBMASTER: job (4, 0, 12) submitted to dispatcher
22:00:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:00:54 DISPATCHER: Trying to submit another job.
22:00:54 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:00:54 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:00:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:00:54 WORKER: start processing job (4, 0, 12)
22:00:54 WORKER: args: ()
22:00:54 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.007403017721925653, 'num_filters_1': 27, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.010553206430471872, 'kernel_size_2': 5, 'num_filters_2': 80}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:01:48 DISPATCHER: Starting worker discovery
22:01:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:01:48 DISPATCHER: Finished worker discovery
22:01:58 WORKER: done with job (4, 0, 12), trying to register it.
22:01:58 WORKER: registered result for job (4, 0, 12) with dispatcher
22:01:58 DISPATCHER: job (4, 0, 12) finished
22:01:58 DISPATCHER: register_result: lock acquired
22:01:58 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:01:58 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.007403017721925653, 'num_filters_1': 27, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.010553206430471872, 'kernel_size_2': 5, 'num_filters_2': 80}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.17572717876642152, 'info': {'data04': 0.17572717876642152, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.007403017721925653, 'num_filters_1': 27, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.010553206430471872, 'kernel_size_2': 5, 'num_filters_2': 80}"}}
exception: None

22:01:58 job_callback for (4, 0, 12) started
22:01:58 DISPATCHER: Trying to submit another job.
22:01:58 job_callback for (4, 0, 12) got condition
22:01:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:01:58 done building a new model for budget 44.444444 based on 17/34 split
Best loss for this budget:-0.175727





22:01:58 HBMASTER: Trying to run another job!
22:01:58 job_callback for (4, 0, 12) finished
22:01:58 start sampling a new configuration.
22:01:58 best_vector: [3, 0, 0.7383140230378265, 0.9109207040777613, 0.6897050107695695, 1, 0.984873760168128, 0.43812231035225957, 1, 1, 2, 2, 0.14403396436716548, 0.34415172857447873, 0.11598154127818361, 0.6854293683903443], 0.00023595638417046383, 0.0070632989235824275, 1.6666304743236389e-06
22:01:58 done sampling a new configuration.
22:01:58 HBMASTER: schedule new run for iteration 4
22:01:58 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
22:01:58 HBMASTER: submitting job (4, 0, 13) to dispatcher
22:01:58 DISPATCHER: trying to submit job (4, 0, 13)
22:01:58 DISPATCHER: trying to notify the job_runner thread.
22:01:58 HBMASTER: job (4, 0, 13) submitted to dispatcher
22:01:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:01:58 DISPATCHER: Trying to submit another job.
22:01:58 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:01:58 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:01:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:01:58 WORKER: start processing job (4, 0, 13)
22:01:58 WORKER: args: ()
22:01:58 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0299659496922156, 'num_filters_1': 106, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.03715440129921952, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 21, 'num_filters_3': 32, 'num_filters_4': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:02:48 DISPATCHER: Starting worker discovery
22:02:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:02:48 DISPATCHER: Finished worker discovery
22:02:58 WORKER: done with job (4, 0, 13), trying to register it.
22:02:58 WORKER: registered result for job (4, 0, 13) with dispatcher
22:02:58 DISPATCHER: job (4, 0, 13) finished
22:02:58 DISPATCHER: register_result: lock acquired
22:02:58 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:02:58 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0299659496922156, 'num_filters_1': 106, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.03715440129921952, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 21, 'num_filters_3': 32, 'num_filters_4': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.045533737233286575, 'info': {'data04': 0.045533737233286575, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0299659496922156, 'num_filters_1': 106, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.03715440129921952, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 21, 'num_filters_3': 32, 'num_filters_4': 20}"}}
exception: None

22:02:58 job_callback for (4, 0, 13) started
22:02:58 DISPATCHER: Trying to submit another job.
22:02:58 job_callback for (4, 0, 13) got condition
22:02:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:02:58 done building a new model for budget 44.444444 based on 17/34 split
Best loss for this budget:-0.175727





22:02:58 HBMASTER: Trying to run another job!
22:02:58 job_callback for (4, 0, 13) finished
22:02:58 start sampling a new configuration.
22:02:58 done sampling a new configuration.
22:02:58 HBMASTER: schedule new run for iteration 4
22:02:58 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
22:02:58 HBMASTER: submitting job (4, 0, 14) to dispatcher
22:02:58 DISPATCHER: trying to submit job (4, 0, 14)
22:02:58 DISPATCHER: trying to notify the job_runner thread.
22:02:58 HBMASTER: job (4, 0, 14) submitted to dispatcher
22:02:58 DISPATCHER: Trying to submit another job.
22:02:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:02:58 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:02:58 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:02:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:02:58 WORKER: start processing job (4, 0, 14)
22:02:58 WORKER: args: ()
22:02:58 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.01177840431020651, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.010272603581537653, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 66, 'num_filters_3': 35, 'num_filters_4': 20, 'num_filters_5': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:03:48 DISPATCHER: Starting worker discovery
22:03:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:03:48 DISPATCHER: Finished worker discovery
22:04:01 WORKER: done with job (4, 0, 14), trying to register it.
22:04:01 WORKER: registered result for job (4, 0, 14) with dispatcher
22:04:01 DISPATCHER: job (4, 0, 14) finished
22:04:01 DISPATCHER: register_result: lock acquired
22:04:01 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:04:01 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.01177840431020651, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.010272603581537653, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 66, 'num_filters_3': 35, 'num_filters_4': 20, 'num_filters_5': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.13408909660082402, 'info': {'data04': 0.13408909660082402, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.01177840431020651, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.010272603581537653, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 66, 'num_filters_3': 35, 'num_filters_4': 20, 'num_filters_5': 27}"}}
exception: None

22:04:01 job_callback for (4, 0, 14) started
22:04:01 job_callback for (4, 0, 14) got condition
22:04:01 DISPATCHER: Trying to submit another job.
22:04:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:04:01 done building a new model for budget 44.444444 based on 17/35 split
Best loss for this budget:-0.175727





22:04:01 HBMASTER: Trying to run another job!
22:04:01 job_callback for (4, 0, 14) finished
22:04:01 start sampling a new configuration.
22:04:01 best_vector: [2, 2, 0.08280344514055465, 0.023759015045028975, 0.6108027185843994, 1, 0.33952540497031014, 0.16189051698258838, 0, 0, 1, 1, 0.804293976225104, 0.8883549779256839, 0.31949907185678433, 0.011484324715418714], 0.008620421847737408, 0.00016060142441522482, 1.3844520278067519e-06
22:04:01 done sampling a new configuration.
22:04:01 HBMASTER: schedule new run for iteration 4
22:04:01 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
22:04:01 HBMASTER: submitting job (4, 0, 15) to dispatcher
22:04:01 DISPATCHER: trying to submit job (4, 0, 15)
22:04:01 DISPATCHER: trying to notify the job_runner thread.
22:04:01 HBMASTER: job (4, 0, 15) submitted to dispatcher
22:04:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:04:01 DISPATCHER: Trying to submit another job.
22:04:01 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:04:01 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:04:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:04:01 WORKER: start processing job (4, 0, 15)
22:04:01 WORKER: args: ()
22:04:01 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0014642218733024633, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.016241435756888672, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 85, 'num_filters_3': 101, 'num_filters_4': 30}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:04:48 DISPATCHER: Starting worker discovery
22:04:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:04:48 DISPATCHER: Finished worker discovery
22:05:02 WORKER: done with job (4, 0, 15), trying to register it.
22:05:02 WORKER: registered result for job (4, 0, 15) with dispatcher
22:05:02 DISPATCHER: job (4, 0, 15) finished
22:05:02 DISPATCHER: register_result: lock acquired
22:05:02 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:05:02 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0014642218733024633, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.016241435756888672, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 85, 'num_filters_3': 101, 'num_filters_4': 30}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.11404771284961951, 'info': {'data04': 0.11404771284961951, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0014642218733024633, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.016241435756888672, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 85, 'num_filters_3': 101, 'num_filters_4': 30}"}}
exception: None

22:05:02 job_callback for (4, 0, 15) started
22:05:02 DISPATCHER: Trying to submit another job.
22:05:02 job_callback for (4, 0, 15) got condition
22:05:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:05:02 done building a new model for budget 44.444444 based on 17/36 split
Best loss for this budget:-0.175727





22:05:02 HBMASTER: Trying to run another job!
22:05:02 job_callback for (4, 0, 15) finished
22:05:02 start sampling a new configuration.
22:05:03 best_vector: [1, 1, 0.05645075273553534, 0.2694135302091043, 0.9460063466880317, 1, 0.18680686901568616, 0.0064922270946385086, 2, 2, 1, 0, 0.9284829026530743, 0.5898481729787846, 0.46700965138480766, 0.7158563012988779], 0.0008062261886460236, 0.0018692038966773383, 1.507001133420466e-06
22:05:03 done sampling a new configuration.
22:05:03 HBMASTER: schedule new run for iteration 4
22:05:03 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
22:05:03 HBMASTER: submitting job (4, 0, 16) to dispatcher
22:05:03 DISPATCHER: trying to submit job (4, 0, 16)
22:05:03 DISPATCHER: trying to notify the job_runner thread.
22:05:03 HBMASTER: job (4, 0, 16) submitted to dispatcher
22:05:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:05:03 DISPATCHER: Trying to submit another job.
22:05:03 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:05:03 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:05:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:05:03 WORKER: start processing job (4, 0, 16)
22:05:03 WORKER: args: ()
22:05:03 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0012968851144160014, 'num_filters_1': 27, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.010196393376556702, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 110, 'num_filters_3': 54, 'num_filters_4': 42, 'num_filters_5': 70}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:05:48 DISPATCHER: Starting worker discovery
22:05:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:05:48 DISPATCHER: Finished worker discovery
22:06:04 WORKER: done with job (4, 0, 16), trying to register it.
22:06:04 WORKER: registered result for job (4, 0, 16) with dispatcher
22:06:04 DISPATCHER: job (4, 0, 16) finished
22:06:04 DISPATCHER: register_result: lock acquired
22:06:04 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:06:04 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0012968851144160014, 'num_filters_1': 27, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.010196393376556702, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 110, 'num_filters_3': 54, 'num_filters_4': 42, 'num_filters_5': 70}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1263606945757417, 'info': {'data04': 0.1263606945757417, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0012968851144160014, 'num_filters_1': 27, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.010196393376556702, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 110, 'num_filters_3': 54, 'num_filters_4': 42, 'num_filters_5': 70}"}}
exception: None

22:06:04 job_callback for (4, 0, 16) started
22:06:04 job_callback for (4, 0, 16) got condition
22:06:04 DISPATCHER: Trying to submit another job.
22:06:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:06:04 done building a new model for budget 44.444444 based on 17/37 split
Best loss for this budget:-0.175727





22:06:04 HBMASTER: Trying to run another job!
22:06:04 job_callback for (4, 0, 16) finished
22:06:04 start sampling a new configuration.
22:06:04 done sampling a new configuration.
22:06:04 HBMASTER: schedule new run for iteration 4
22:06:04 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
22:06:04 HBMASTER: submitting job (4, 0, 17) to dispatcher
22:06:04 DISPATCHER: trying to submit job (4, 0, 17)
22:06:04 DISPATCHER: trying to notify the job_runner thread.
22:06:04 HBMASTER: job (4, 0, 17) submitted to dispatcher
22:06:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:06:04 DISPATCHER: Trying to submit another job.
22:06:04 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:06:04 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:06:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:06:04 WORKER: start processing job (4, 0, 17)
22:06:04 WORKER: args: ()
22:06:04 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.09169429931065821, 'num_filters_1': 110, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.019126401534062098, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 23, 'num_filters_3': 80, 'num_filters_4': 25, 'num_filters_5': 115}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:06:48 DISPATCHER: Starting worker discovery
22:06:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:06:48 DISPATCHER: Finished worker discovery
22:07:05 WORKER: done with job (4, 0, 17), trying to register it.
22:07:05 WORKER: registered result for job (4, 0, 17) with dispatcher
22:07:05 DISPATCHER: job (4, 0, 17) finished
22:07:05 DISPATCHER: register_result: lock acquired
22:07:05 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:07:05 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.09169429931065821, 'num_filters_1': 110, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.019126401534062098, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 23, 'num_filters_3': 80, 'num_filters_4': 25, 'num_filters_5': 115}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.012840109512023424, 'info': {'data04': 0.012840109512023424, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.09169429931065821, 'num_filters_1': 110, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.019126401534062098, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 23, 'num_filters_3': 80, 'num_filters_4': 25, 'num_filters_5': 115}"}}
exception: None

22:07:05 job_callback for (4, 0, 17) started
22:07:05 DISPATCHER: Trying to submit another job.
22:07:05 job_callback for (4, 0, 17) got condition
22:07:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:07:05 done building a new model for budget 44.444444 based on 17/38 split
Best loss for this budget:-0.175727





22:07:05 HBMASTER: Trying to run another job!
22:07:05 job_callback for (4, 0, 17) finished
22:07:05 start sampling a new configuration.
22:07:06 best_vector: [0, 0, 0.21810658413286435, 0.6140184376993367, 0.20209847615749832, 1, 0.3512236396012411, 0.534420377737483, 1, 2, 0, 2, 0.31793222332401105, 0.9536745522767421, 0.23978825763885886, 0.2058192407215662], 0.0011590310618355938, 0.0007800350410665378, 9.040848419163203e-07
22:07:06 done sampling a new configuration.
22:07:06 HBMASTER: schedule new run for iteration 4
22:07:06 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
22:07:06 HBMASTER: submitting job (4, 0, 18) to dispatcher
22:07:06 DISPATCHER: trying to submit job (4, 0, 18)
22:07:06 DISPATCHER: trying to notify the job_runner thread.
22:07:06 HBMASTER: job (4, 0, 18) submitted to dispatcher
22:07:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:07:06 DISPATCHER: Trying to submit another job.
22:07:06 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:07:06 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:07:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:07:06 WORKER: start processing job (4, 0, 18)
22:07:06 WORKER: args: ()
22:07:06 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0027303175977878664, 'num_filters_1': 57, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.04957890625842848, 'kernel_size_2': 5, 'num_filters_2': 30}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:07:48 DISPATCHER: Starting worker discovery
22:07:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:07:48 DISPATCHER: Finished worker discovery
22:08:07 WORKER: done with job (4, 0, 18), trying to register it.
22:08:07 WORKER: registered result for job (4, 0, 18) with dispatcher
22:08:07 DISPATCHER: job (4, 0, 18) finished
22:08:07 DISPATCHER: register_result: lock acquired
22:08:07 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:08:07 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0027303175977878664, 'num_filters_1': 57, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.04957890625842848, 'kernel_size_2': 5, 'num_filters_2': 30}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1444509635935221, 'info': {'data04': 0.1444509635935221, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0027303175977878664, 'num_filters_1': 57, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.04957890625842848, 'kernel_size_2': 5, 'num_filters_2': 30}"}}
exception: None

22:08:07 job_callback for (4, 0, 18) started
22:08:07 job_callback for (4, 0, 18) got condition
22:08:07 DISPATCHER: Trying to submit another job.
22:08:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:08:07 done building a new model for budget 44.444444 based on 17/39 split
Best loss for this budget:-0.175727





22:08:07 HBMASTER: Trying to run another job!
22:08:07 job_callback for (4, 0, 18) finished
22:08:07 start sampling a new configuration.
22:08:07 done sampling a new configuration.
22:08:07 HBMASTER: schedule new run for iteration 4
22:08:07 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
22:08:07 HBMASTER: submitting job (4, 0, 19) to dispatcher
22:08:07 DISPATCHER: trying to submit job (4, 0, 19)
22:08:07 DISPATCHER: trying to notify the job_runner thread.
22:08:07 HBMASTER: job (4, 0, 19) submitted to dispatcher
22:08:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:08:07 DISPATCHER: Trying to submit another job.
22:08:07 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:08:07 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:08:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:08:07 WORKER: start processing job (4, 0, 19)
22:08:07 WORKER: args: ()
22:08:07 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.006312129642139729, 'num_filters_1': 65, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.18642756197216845}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:08:48 DISPATCHER: Starting worker discovery
22:08:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:08:48 DISPATCHER: Finished worker discovery
22:09:12 WORKER: done with job (4, 0, 19), trying to register it.
22:09:12 WORKER: registered result for job (4, 0, 19) with dispatcher
22:09:12 DISPATCHER: job (4, 0, 19) finished
22:09:12 DISPATCHER: register_result: lock acquired
22:09:12 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:09:12 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.006312129642139729, 'num_filters_1': 65, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.18642756197216845}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -1.1894577222442612e-05, 'info': {'data04': 1.1894577222442612e-05, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.006312129642139729, 'num_filters_1': 65, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.18642756197216845}"}}
exception: None

22:09:12 job_callback for (4, 0, 19) started
22:09:12 DISPATCHER: Trying to submit another job.
22:09:12 job_callback for (4, 0, 19) got condition
22:09:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:09:12 done building a new model for budget 44.444444 based on 17/39 split
Best loss for this budget:-0.175727





22:09:12 HBMASTER: Trying to run another job!
22:09:12 job_callback for (4, 0, 19) finished
22:09:12 start sampling a new configuration.
22:09:12 best_vector: [2, 2, 0.04730271975179692, 0.25283577446087824, 0.656117705388334, 1, 0.927289920386545, 0.08158951098039435, 1, 2, 2, 2, 0.8358376067950428, 0.7268588760003399, 0.8010188146602556, 0.17233491688636426], 7.668972709030524e-05, 0.00024245720341703234, 1.8593976761130833e-08
22:09:12 done sampling a new configuration.
22:09:12 HBMASTER: schedule new run for iteration 4
22:09:12 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
22:09:12 HBMASTER: submitting job (4, 0, 20) to dispatcher
22:09:12 DISPATCHER: trying to submit job (4, 0, 20)
22:09:12 DISPATCHER: trying to notify the job_runner thread.
22:09:12 HBMASTER: job (4, 0, 20) submitted to dispatcher
22:09:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:09:12 DISPATCHER: Trying to submit another job.
22:09:12 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:09:12 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:09:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:09:12 WORKER: start processing job (4, 0, 20)
22:09:12 WORKER: args: ()
22:09:12 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001243384472348685, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.012768809306355438, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 91, 'num_filters_3': 72, 'num_filters_4': 84}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:09:48 DISPATCHER: Starting worker discovery
22:09:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:09:48 DISPATCHER: Finished worker discovery
22:10:12 WORKER: done with job (4, 0, 20), trying to register it.
22:10:12 WORKER: registered result for job (4, 0, 20) with dispatcher
22:10:12 DISPATCHER: job (4, 0, 20) finished
22:10:12 DISPATCHER: register_result: lock acquired
22:10:12 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:10:12 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001243384472348685, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.012768809306355438, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 91, 'num_filters_3': 72, 'num_filters_4': 84}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.17990820292866214, 'info': {'data04': 0.17990820292866214, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001243384472348685, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.012768809306355438, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 91, 'num_filters_3': 72, 'num_filters_4': 84}"}}
exception: None

22:10:12 job_callback for (4, 0, 20) started
22:10:12 DISPATCHER: Trying to submit another job.
22:10:12 job_callback for (4, 0, 20) got condition
22:10:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:10:12 done building a new model for budget 44.444444 based on 17/40 split
Best loss for this budget:-0.179908





22:10:12 HBMASTER: Trying to run another job!
22:10:12 job_callback for (4, 0, 20) finished
22:10:12 start sampling a new configuration.
22:10:12 done sampling a new configuration.
22:10:12 HBMASTER: schedule new run for iteration 4
22:10:12 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
22:10:12 HBMASTER: submitting job (4, 0, 21) to dispatcher
22:10:12 DISPATCHER: trying to submit job (4, 0, 21)
22:10:12 DISPATCHER: trying to notify the job_runner thread.
22:10:12 HBMASTER: job (4, 0, 21) submitted to dispatcher
22:10:12 DISPATCHER: Trying to submit another job.
22:10:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:10:12 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:10:12 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:10:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:10:12 WORKER: start processing job (4, 0, 21)
22:10:12 WORKER: args: ()
22:10:12 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0016252610739490635, 'num_filters_1': 40, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.04292248983593129, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 40, 'num_filters_3': 68}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:10:48 DISPATCHER: Starting worker discovery
22:10:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:10:48 DISPATCHER: Finished worker discovery
22:11:12 WORKER: done with job (4, 0, 21), trying to register it.
22:11:12 WORKER: registered result for job (4, 0, 21) with dispatcher
22:11:12 DISPATCHER: job (4, 0, 21) finished
22:11:12 DISPATCHER: register_result: lock acquired
22:11:12 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:11:12 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0016252610739490635, 'num_filters_1': 40, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.04292248983593129, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 40, 'num_filters_3': 68}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.020202282846725737, 'info': {'data04': 0.020202282846725737, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0016252610739490635, 'num_filters_1': 40, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.04292248983593129, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 40, 'num_filters_3': 68}"}}
exception: None

22:11:12 job_callback for (4, 0, 21) started
22:11:12 job_callback for (4, 0, 21) got condition
22:11:12 DISPATCHER: Trying to submit another job.
22:11:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:11:12 done building a new model for budget 44.444444 based on 17/41 split
Best loss for this budget:-0.179908





22:11:12 HBMASTER: Trying to run another job!
22:11:12 job_callback for (4, 0, 21) finished
22:11:12 start sampling a new configuration.
22:11:12 best_vector: [1, 2, 0.2616773534564924, 0.1825187322827718, 0.6077416465606849, 1, 0.9318533929984492, 0.3006666405904794, 1, 1, 1, 2, 0.41311625902957755, 0.7480231041448399, 0.5751947366548718, 0.20730208318824184], 0.0007459705541146093, 0.0013508006228074676, 1.007657489094046e-06
22:11:12 done sampling a new configuration.
22:11:12 HBMASTER: schedule new run for iteration 4
22:11:12 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
22:11:12 HBMASTER: submitting job (4, 0, 22) to dispatcher
22:11:12 DISPATCHER: trying to submit job (4, 0, 22)
22:11:12 DISPATCHER: trying to notify the job_runner thread.
22:11:12 HBMASTER: job (4, 0, 22) submitted to dispatcher
22:11:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:11:12 DISPATCHER: Trying to submit another job.
22:11:12 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:11:12 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:11:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:11:12 WORKER: start processing job (4, 0, 22)
22:11:12 WORKER: args: ()
22:11:12 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0033369884764140917, 'num_filters_1': 23, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.02461366685279488, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 37, 'num_filters_3': 75, 'num_filters_4': 52}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:11:48 DISPATCHER: Starting worker discovery
22:11:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:11:48 DISPATCHER: Finished worker discovery
22:12:13 WORKER: done with job (4, 0, 22), trying to register it.
22:12:13 WORKER: registered result for job (4, 0, 22) with dispatcher
22:12:13 DISPATCHER: job (4, 0, 22) finished
22:12:13 DISPATCHER: register_result: lock acquired
22:12:13 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:12:13 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0033369884764140917, 'num_filters_1': 23, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.02461366685279488, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 37, 'num_filters_3': 75, 'num_filters_4': 52}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1808869581822636, 'info': {'data04': 0.1808869581822636, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0033369884764140917, 'num_filters_1': 23, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.02461366685279488, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 37, 'num_filters_3': 75, 'num_filters_4': 52}"}}
exception: None

22:12:13 job_callback for (4, 0, 22) started
22:12:13 job_callback for (4, 0, 22) got condition
22:12:13 DISPATCHER: Trying to submit another job.
22:12:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:12:13 done building a new model for budget 44.444444 based on 17/42 split
Best loss for this budget:-0.180887





22:12:13 HBMASTER: Trying to run another job!
22:12:13 job_callback for (4, 0, 22) finished
22:12:13 start sampling a new configuration.
22:12:13 best_vector: [0, 1, 0.16950255437574877, 0.19926901168579947, 0.29590537580653364, 1, 0.31584207959460137, 0.9168112389849296, 0, 0, 0, 0, 0.10852726141979052, 0.20580893073404183, 0.006105999796315931, 0.05892345287535339], 0.0020536033540133765, 0.00024303719514506047, 4.991019990998997e-07
22:12:13 done sampling a new configuration.
22:12:13 HBMASTER: schedule new run for iteration 4
22:12:13 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
22:12:13 HBMASTER: submitting job (4, 0, 23) to dispatcher
22:12:13 DISPATCHER: trying to submit job (4, 0, 23)
22:12:13 DISPATCHER: trying to notify the job_runner thread.
22:12:13 HBMASTER: job (4, 0, 23) submitted to dispatcher
22:12:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:12:13 DISPATCHER: Trying to submit another job.
22:12:13 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:12:13 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:12:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:12:13 WORKER: start processing job (4, 0, 23)
22:12:13 WORKER: args: ()
22:12:13 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0021827555881772796, 'num_filters_1': 24, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.15588305994004711, 'kernel_size_2': 3, 'num_filters_2': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:12:48 DISPATCHER: Starting worker discovery
22:12:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:12:48 DISPATCHER: Finished worker discovery
22:13:16 WORKER: done with job (4, 0, 23), trying to register it.
22:13:16 WORKER: registered result for job (4, 0, 23) with dispatcher
22:13:16 DISPATCHER: job (4, 0, 23) finished
22:13:16 DISPATCHER: register_result: lock acquired
22:13:16 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:13:16 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0021827555881772796, 'num_filters_1': 24, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.15588305994004711, 'kernel_size_2': 3, 'num_filters_2': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.05484053340531282, 'info': {'data04': 0.05484053340531282, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0021827555881772796, 'num_filters_1': 24, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.15588305994004711, 'kernel_size_2': 3, 'num_filters_2': 19}"}}
exception: None

22:13:16 job_callback for (4, 0, 23) started
22:13:16 job_callback for (4, 0, 23) got condition
22:13:16 DISPATCHER: Trying to submit another job.
22:13:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:13:16 done building a new model for budget 44.444444 based on 17/43 split
Best loss for this budget:-0.180887





22:13:16 HBMASTER: Trying to run another job!
22:13:16 job_callback for (4, 0, 23) finished
22:13:16 start sampling a new configuration.
22:13:16 best_vector: [2, 1, 0.7833955444135635, 0.4772235469478894, 0.9310770441687211, 1, 0.1405878076665201, 0.08269975975463584, 1, 1, 2, 1, 0.8870828256009164, 0.19766450867592306, 0.0358106929688492, 0.17884862502401455], 9.975656784126869e-05, 0.0021894728804119756, 2.1841429993143521e-07
22:13:16 done sampling a new configuration.
22:13:16 HBMASTER: schedule new run for iteration 4
22:13:16 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
22:13:16 HBMASTER: submitting job (4, 0, 24) to dispatcher
22:13:16 DISPATCHER: trying to submit job (4, 0, 24)
22:13:16 DISPATCHER: trying to notify the job_runner thread.
22:13:16 HBMASTER: job (4, 0, 24) submitted to dispatcher
22:13:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:13:16 DISPATCHER: Trying to submit another job.
22:13:16 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:13:16 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:13:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:13:16 WORKER: start processing job (4, 0, 24)
22:13:16 WORKER: args: ()
22:13:16 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.03688001498364115, 'num_filters_1': 43, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.01281134917409616, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 101, 'num_filters_3': 24, 'num_filters_4': 17, 'num_filters_5': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:13:48 DISPATCHER: Starting worker discovery
22:13:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:13:48 DISPATCHER: Finished worker discovery
22:14:21 WORKER: done with job (4, 0, 24), trying to register it.
22:14:21 WORKER: registered result for job (4, 0, 24) with dispatcher
22:14:21 DISPATCHER: job (4, 0, 24) finished
22:14:21 DISPATCHER: register_result: lock acquired
22:14:21 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:14:21 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.03688001498364115, 'num_filters_1': 43, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.01281134917409616, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 101, 'num_filters_3': 24, 'num_filters_4': 17, 'num_filters_5': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.12392665820550697, 'info': {'data04': 0.12392665820550697, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.03688001498364115, 'num_filters_1': 43, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.01281134917409616, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 101, 'num_filters_3': 24, 'num_filters_4': 17, 'num_filters_5': 23}"}}
exception: None

22:14:21 job_callback for (4, 0, 24) started
22:14:21 DISPATCHER: Trying to submit another job.
22:14:21 job_callback for (4, 0, 24) got condition
22:14:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:14:21 done building a new model for budget 44.444444 based on 17/44 split
Best loss for this budget:-0.180887





22:14:21 HBMASTER: Trying to run another job!
22:14:21 job_callback for (4, 0, 24) finished
22:14:21 start sampling a new configuration.
22:14:21 done sampling a new configuration.
22:14:21 HBMASTER: schedule new run for iteration 4
22:14:21 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
22:14:21 HBMASTER: submitting job (4, 0, 25) to dispatcher
22:14:21 DISPATCHER: trying to submit job (4, 0, 25)
22:14:21 DISPATCHER: trying to notify the job_runner thread.
22:14:21 HBMASTER: job (4, 0, 25) submitted to dispatcher
22:14:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:14:21 DISPATCHER: Trying to submit another job.
22:14:21 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:14:21 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:14:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:14:21 WORKER: start processing job (4, 0, 25)
22:14:21 WORKER: args: ()
22:14:21 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0027479172507858685, 'num_filters_1': 90, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.0164431328869318, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 16, 'num_filters_3': 33, 'num_filters_4': 23, 'num_filters_5': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:14:48 DISPATCHER: Starting worker discovery
22:14:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:14:48 DISPATCHER: Finished worker discovery
22:15:21 WORKER: done with job (4, 0, 25), trying to register it.
22:15:21 WORKER: registered result for job (4, 0, 25) with dispatcher
22:15:21 DISPATCHER: job (4, 0, 25) finished
22:15:21 DISPATCHER: register_result: lock acquired
22:15:21 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:15:21 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0027479172507858685, 'num_filters_1': 90, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.0164431328869318, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 16, 'num_filters_3': 33, 'num_filters_4': 23, 'num_filters_5': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.03285169286097896, 'info': {'data04': 0.03285169286097896, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0027479172507858685, 'num_filters_1': 90, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.0164431328869318, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 16, 'num_filters_3': 33, 'num_filters_4': 23, 'num_filters_5': 18}"}}
exception: None

22:15:21 job_callback for (4, 0, 25) started
22:15:21 job_callback for (4, 0, 25) got condition
22:15:21 DISPATCHER: Trying to submit another job.
22:15:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:15:21 done building a new model for budget 44.444444 based on 17/45 split
Best loss for this budget:-0.180887





22:15:21 HBMASTER: Trying to run another job!
22:15:21 job_callback for (4, 0, 25) finished
22:15:21 start sampling a new configuration.
22:15:21 done sampling a new configuration.
22:15:21 HBMASTER: schedule new run for iteration 4
22:15:21 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
22:15:21 HBMASTER: submitting job (4, 0, 26) to dispatcher
22:15:21 DISPATCHER: trying to submit job (4, 0, 26)
22:15:21 DISPATCHER: trying to notify the job_runner thread.
22:15:21 HBMASTER: job (4, 0, 26) submitted to dispatcher
22:15:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:15:21 DISPATCHER: Trying to submit another job.
22:15:21 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:15:21 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:15:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:15:21 WORKER: start processing job (4, 0, 26)
22:15:21 WORKER: args: ()
22:15:21 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.057676749284391385, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.05908948657887634, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 118, 'num_filters_3': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:15:48 DISPATCHER: Starting worker discovery
22:15:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:15:48 DISPATCHER: Finished worker discovery
22:16:21 WORKER: done with job (4, 0, 26), trying to register it.
22:16:21 WORKER: registered result for job (4, 0, 26) with dispatcher
22:16:21 DISPATCHER: job (4, 0, 26) finished
22:16:21 DISPATCHER: register_result: lock acquired
22:16:21 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:16:21 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.057676749284391385, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.05908948657887634, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 118, 'num_filters_3': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.003526429981893617, 'info': {'data04': 0.003526429981893617, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.057676749284391385, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.05908948657887634, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 118, 'num_filters_3': 43}"}}
exception: None

22:16:21 job_callback for (4, 0, 26) started
22:16:21 DISPATCHER: Trying to submit another job.
22:16:21 job_callback for (4, 0, 26) got condition
22:16:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:16:21 done building a new model for budget 44.444444 based on 17/45 split
Best loss for this budget:-0.180887





22:16:21 HBMASTER: Trying to run another job!
22:16:21 job_callback for (4, 0, 26) finished
22:16:21 ITERATION: Advancing config (4, 0, 0) to next budget 133.333333
22:16:21 ITERATION: Advancing config (4, 0, 1) to next budget 133.333333
22:16:21 ITERATION: Advancing config (4, 0, 4) to next budget 133.333333
22:16:21 ITERATION: Advancing config (4, 0, 10) to next budget 133.333333
22:16:21 ITERATION: Advancing config (4, 0, 12) to next budget 133.333333
22:16:21 ITERATION: Advancing config (4, 0, 14) to next budget 133.333333
22:16:21 ITERATION: Advancing config (4, 0, 18) to next budget 133.333333
22:16:21 ITERATION: Advancing config (4, 0, 20) to next budget 133.333333
22:16:21 ITERATION: Advancing config (4, 0, 22) to next budget 133.333333
22:16:21 HBMASTER: schedule new run for iteration 4
22:16:21 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
22:16:21 HBMASTER: submitting job (4, 0, 0) to dispatcher
22:16:21 DISPATCHER: trying to submit job (4, 0, 0)
22:16:21 DISPATCHER: trying to notify the job_runner thread.
22:16:21 HBMASTER: job (4, 0, 0) submitted to dispatcher
22:16:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:16:21 DISPATCHER: Trying to submit another job.
22:16:21 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:16:21 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:16:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:16:21 WORKER: start processing job (4, 0, 0)
22:16:21 WORKER: args: ()
22:16:21 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.002222238454775013, 'num_filters_1': 25, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.05428378259225723, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 50, 'num_filters_3': 101}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:16:48 DISPATCHER: Starting worker discovery
22:16:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:16:48 DISPATCHER: Finished worker discovery
22:17:48 DISPATCHER: Starting worker discovery
22:17:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:17:48 DISPATCHER: Finished worker discovery
22:18:48 DISPATCHER: Starting worker discovery
22:18:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:18:48 DISPATCHER: Finished worker discovery
22:18:55 WORKER: done with job (4, 0, 0), trying to register it.
22:18:55 WORKER: registered result for job (4, 0, 0) with dispatcher
22:18:55 DISPATCHER: job (4, 0, 0) finished
22:18:55 DISPATCHER: register_result: lock acquired
22:18:55 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:18:55 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.002222238454775013, 'num_filters_1': 25, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.05428378259225723, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 50, 'num_filters_3': 101}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.11485516705262994, 'info': {'data04': 0.11485516705262994, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.002222238454775013, 'num_filters_1': 25, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.05428378259225723, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 50, 'num_filters_3': 101}"}}
exception: None

22:18:55 job_callback for (4, 0, 0) started
22:18:55 DISPATCHER: Trying to submit another job.
22:18:55 job_callback for (4, 0, 0) got condition
22:18:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:18:55 HBMASTER: Trying to run another job!
22:18:55 job_callback for (4, 0, 0) finished
22:18:55 HBMASTER: schedule new run for iteration 4
22:18:55 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
22:18:55 HBMASTER: submitting job (4, 0, 1) to dispatcher
22:18:55 DISPATCHER: trying to submit job (4, 0, 1)
22:18:55 DISPATCHER: trying to notify the job_runner thread.
22:18:55 HBMASTER: job (4, 0, 1) submitted to dispatcher
22:18:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:18:55 DISPATCHER: Trying to submit another job.
22:18:55 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:18:55 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:18:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:18:55 WORKER: start processing job (4, 0, 1)
22:18:55 WORKER: args: ()
22:18:55 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.020350171850102648, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.013360691193823498, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 94, 'num_filters_3': 18, 'num_filters_4': 54, 'num_filters_5': 66}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:19:48 DISPATCHER: Starting worker discovery
22:19:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:19:48 DISPATCHER: Finished worker discovery
22:20:48 DISPATCHER: Starting worker discovery
22:20:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:20:48 DISPATCHER: Finished worker discovery
22:21:39 WORKER: done with job (4, 0, 1), trying to register it.
22:21:39 WORKER: registered result for job (4, 0, 1) with dispatcher
22:21:39 DISPATCHER: job (4, 0, 1) finished
22:21:39 DISPATCHER: register_result: lock acquired
22:21:39 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:21:39 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.020350171850102648, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.013360691193823498, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 94, 'num_filters_3': 18, 'num_filters_4': 54, 'num_filters_5': 66}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.09517022616271545, 'info': {'data04': 0.09517022616271545, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.020350171850102648, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.013360691193823498, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 94, 'num_filters_3': 18, 'num_filters_4': 54, 'num_filters_5': 66}"}}
exception: None

22:21:39 job_callback for (4, 0, 1) started
22:21:39 DISPATCHER: Trying to submit another job.
22:21:39 job_callback for (4, 0, 1) got condition
22:21:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:21:39 HBMASTER: Trying to run another job!
22:21:39 job_callback for (4, 0, 1) finished
22:21:39 HBMASTER: schedule new run for iteration 4
22:21:39 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
22:21:39 HBMASTER: submitting job (4, 0, 4) to dispatcher
22:21:39 DISPATCHER: trying to submit job (4, 0, 4)
22:21:39 DISPATCHER: trying to notify the job_runner thread.
22:21:39 HBMASTER: job (4, 0, 4) submitted to dispatcher
22:21:39 DISPATCHER: Trying to submit another job.
22:21:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:21:39 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:21:39 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:21:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:21:39 WORKER: start processing job (4, 0, 4)
22:21:39 WORKER: args: ()
22:21:39 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.014268506744274363, 'num_filters_1': 108, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.020733416959949763, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 39, 'num_filters_3': 26, 'num_filters_4': 16}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:21:48 DISPATCHER: Starting worker discovery
22:21:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:21:48 DISPATCHER: Finished worker discovery
22:22:48 DISPATCHER: Starting worker discovery
22:22:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:22:48 DISPATCHER: Finished worker discovery
22:23:48 DISPATCHER: Starting worker discovery
22:23:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:23:48 DISPATCHER: Finished worker discovery
22:24:14 WORKER: done with job (4, 0, 4), trying to register it.
22:24:14 WORKER: registered result for job (4, 0, 4) with dispatcher
22:24:14 DISPATCHER: job (4, 0, 4) finished
22:24:14 DISPATCHER: register_result: lock acquired
22:24:14 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:24:14 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.014268506744274363, 'num_filters_1': 108, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.020733416959949763, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 39, 'num_filters_3': 26, 'num_filters_4': 16}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.14040889460059258, 'info': {'data04': 0.14040889460059258, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.014268506744274363, 'num_filters_1': 108, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.020733416959949763, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 39, 'num_filters_3': 26, 'num_filters_4': 16}"}}
exception: None

22:24:14 job_callback for (4, 0, 4) started
22:24:14 job_callback for (4, 0, 4) got condition
22:24:14 DISPATCHER: Trying to submit another job.
22:24:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:24:14 HBMASTER: Trying to run another job!
22:24:14 job_callback for (4, 0, 4) finished
22:24:14 HBMASTER: schedule new run for iteration 4
22:24:14 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
22:24:14 HBMASTER: submitting job (4, 0, 10) to dispatcher
22:24:14 DISPATCHER: trying to submit job (4, 0, 10)
22:24:14 DISPATCHER: trying to notify the job_runner thread.
22:24:14 HBMASTER: job (4, 0, 10) submitted to dispatcher
22:24:14 DISPATCHER: Trying to submit another job.
22:24:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:24:14 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:24:14 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:24:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:24:14 WORKER: start processing job (4, 0, 10)
22:24:14 WORKER: args: ()
22:24:14 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0013627295421679176, 'num_filters_1': 104, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.040885418461170706, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 50, 'num_filters_3': 17, 'num_filters_4': 19, 'num_filters_5': 67}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:24:48 DISPATCHER: Starting worker discovery
22:24:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:24:48 DISPATCHER: Finished worker discovery
22:25:48 DISPATCHER: Starting worker discovery
22:25:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:25:48 DISPATCHER: Finished worker discovery
22:26:47 WORKER: done with job (4, 0, 10), trying to register it.
22:26:47 WORKER: registered result for job (4, 0, 10) with dispatcher
22:26:47 DISPATCHER: job (4, 0, 10) finished
22:26:47 DISPATCHER: register_result: lock acquired
22:26:47 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:26:47 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0013627295421679176, 'num_filters_1': 104, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.040885418461170706, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 50, 'num_filters_3': 17, 'num_filters_4': 19, 'num_filters_5': 67}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.18144847293641417, 'info': {'data04': 0.18144847293641417, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0013627295421679176, 'num_filters_1': 104, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.040885418461170706, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 50, 'num_filters_3': 17, 'num_filters_4': 19, 'num_filters_5': 67}"}}
exception: None

22:26:47 job_callback for (4, 0, 10) started
22:26:47 DISPATCHER: Trying to submit another job.
22:26:47 job_callback for (4, 0, 10) got condition
22:26:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:26:47 HBMASTER: Trying to run another job!
22:26:47 job_callback for (4, 0, 10) finished
22:26:47 HBMASTER: schedule new run for iteration 4
22:26:47 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
22:26:47 HBMASTER: submitting job (4, 0, 12) to dispatcher
22:26:47 DISPATCHER: trying to submit job (4, 0, 12)
22:26:47 DISPATCHER: trying to notify the job_runner thread.
22:26:47 HBMASTER: job (4, 0, 12) submitted to dispatcher
22:26:47 DISPATCHER: Trying to submit another job.
22:26:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:26:47 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:26:47 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:26:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:26:47 WORKER: start processing job (4, 0, 12)
22:26:47 WORKER: args: ()
22:26:47 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.007403017721925653, 'num_filters_1': 27, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.010553206430471872, 'kernel_size_2': 5, 'num_filters_2': 80}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:26:48 DISPATCHER: Starting worker discovery
22:26:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:26:48 DISPATCHER: Finished worker discovery
22:27:48 DISPATCHER: Starting worker discovery
22:27:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:27:48 DISPATCHER: Finished worker discovery
22:28:48 DISPATCHER: Starting worker discovery
22:28:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:28:48 DISPATCHER: Finished worker discovery
22:29:24 WORKER: done with job (4, 0, 12), trying to register it.
22:29:24 WORKER: registered result for job (4, 0, 12) with dispatcher
22:29:24 DISPATCHER: job (4, 0, 12) finished
22:29:24 DISPATCHER: register_result: lock acquired
22:29:24 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:29:24 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.007403017721925653, 'num_filters_1': 27, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.010553206430471872, 'kernel_size_2': 5, 'num_filters_2': 80}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.13995633534097518, 'info': {'data04': 0.13995633534097518, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.007403017721925653, 'num_filters_1': 27, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.010553206430471872, 'kernel_size_2': 5, 'num_filters_2': 80}"}}
exception: None

22:29:24 job_callback for (4, 0, 12) started
22:29:24 job_callback for (4, 0, 12) got condition
22:29:24 DISPATCHER: Trying to submit another job.
22:29:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:29:24 HBMASTER: Trying to run another job!
22:29:24 job_callback for (4, 0, 12) finished
22:29:24 HBMASTER: schedule new run for iteration 4
22:29:24 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
22:29:24 HBMASTER: submitting job (4, 0, 14) to dispatcher
22:29:24 DISPATCHER: trying to submit job (4, 0, 14)
22:29:24 DISPATCHER: trying to notify the job_runner thread.
22:29:24 HBMASTER: job (4, 0, 14) submitted to dispatcher
22:29:24 DISPATCHER: Trying to submit another job.
22:29:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:29:24 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:29:24 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:29:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:29:24 WORKER: start processing job (4, 0, 14)
22:29:24 WORKER: args: ()
22:29:24 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.01177840431020651, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.010272603581537653, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 66, 'num_filters_3': 35, 'num_filters_4': 20, 'num_filters_5': 27}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:29:48 DISPATCHER: Starting worker discovery
22:29:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:29:48 DISPATCHER: Finished worker discovery
22:30:48 DISPATCHER: Starting worker discovery
22:30:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:30:48 DISPATCHER: Finished worker discovery
22:31:48 DISPATCHER: Starting worker discovery
22:31:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:31:48 DISPATCHER: Finished worker discovery
22:32:07 WORKER: done with job (4, 0, 14), trying to register it.
22:32:07 WORKER: registered result for job (4, 0, 14) with dispatcher
22:32:07 DISPATCHER: job (4, 0, 14) finished
22:32:07 DISPATCHER: register_result: lock acquired
22:32:07 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:32:07 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.01177840431020651, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.010272603581537653, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 66, 'num_filters_3': 35, 'num_filters_4': 20, 'num_filters_5': 27}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.10428884009856398, 'info': {'data04': 0.10428884009856398, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.01177840431020651, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.010272603581537653, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 66, 'num_filters_3': 35, 'num_filters_4': 20, 'num_filters_5': 27}"}}
exception: None

22:32:07 job_callback for (4, 0, 14) started
22:32:07 job_callback for (4, 0, 14) got condition
22:32:07 DISPATCHER: Trying to submit another job.
22:32:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:32:07 HBMASTER: Trying to run another job!
22:32:07 job_callback for (4, 0, 14) finished
22:32:07 HBMASTER: schedule new run for iteration 4
22:32:07 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
22:32:07 HBMASTER: submitting job (4, 0, 18) to dispatcher
22:32:07 DISPATCHER: trying to submit job (4, 0, 18)
22:32:07 DISPATCHER: trying to notify the job_runner thread.
22:32:07 HBMASTER: job (4, 0, 18) submitted to dispatcher
22:32:07 DISPATCHER: Trying to submit another job.
22:32:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:32:07 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:32:07 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:32:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:32:07 WORKER: start processing job (4, 0, 18)
22:32:07 WORKER: args: ()
22:32:07 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0027303175977878664, 'num_filters_1': 57, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.04957890625842848, 'kernel_size_2': 5, 'num_filters_2': 30}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:32:48 DISPATCHER: Starting worker discovery
22:32:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:32:48 DISPATCHER: Finished worker discovery
22:33:48 DISPATCHER: Starting worker discovery
22:33:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:33:48 DISPATCHER: Finished worker discovery
22:34:44 WORKER: done with job (4, 0, 18), trying to register it.
22:34:44 WORKER: registered result for job (4, 0, 18) with dispatcher
22:34:44 DISPATCHER: job (4, 0, 18) finished
22:34:44 DISPATCHER: register_result: lock acquired
22:34:44 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:34:44 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0027303175977878664, 'num_filters_1': 57, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.04957890625842848, 'kernel_size_2': 5, 'num_filters_2': 30}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1071198942102943, 'info': {'data04': 0.1071198942102943, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0027303175977878664, 'num_filters_1': 57, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.04957890625842848, 'kernel_size_2': 5, 'num_filters_2': 30}"}}
exception: None

22:34:44 job_callback for (4, 0, 18) started
22:34:44 job_callback for (4, 0, 18) got condition
22:34:44 DISPATCHER: Trying to submit another job.
22:34:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:34:44 HBMASTER: Trying to run another job!
22:34:44 job_callback for (4, 0, 18) finished
22:34:44 HBMASTER: schedule new run for iteration 4
22:34:44 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
22:34:44 HBMASTER: submitting job (4, 0, 20) to dispatcher
22:34:44 DISPATCHER: trying to submit job (4, 0, 20)
22:34:44 DISPATCHER: trying to notify the job_runner thread.
22:34:44 HBMASTER: job (4, 0, 20) submitted to dispatcher
22:34:44 DISPATCHER: Trying to submit another job.
22:34:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:34:44 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:34:44 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:34:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:34:44 WORKER: start processing job (4, 0, 20)
22:34:44 WORKER: args: ()
22:34:44 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001243384472348685, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.012768809306355438, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 91, 'num_filters_3': 72, 'num_filters_4': 84}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:34:48 DISPATCHER: Starting worker discovery
22:34:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:34:48 DISPATCHER: Finished worker discovery
22:35:48 DISPATCHER: Starting worker discovery
22:35:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:35:48 DISPATCHER: Finished worker discovery
22:36:48 DISPATCHER: Starting worker discovery
22:36:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:36:49 DISPATCHER: Finished worker discovery
22:37:15 WORKER: done with job (4, 0, 20), trying to register it.
22:37:15 WORKER: registered result for job (4, 0, 20) with dispatcher
22:37:15 DISPATCHER: job (4, 0, 20) finished
22:37:15 DISPATCHER: register_result: lock acquired
22:37:15 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:37:15 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001243384472348685, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.012768809306355438, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 91, 'num_filters_3': 72, 'num_filters_4': 84}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.15414889764471135, 'info': {'data04': 0.15414889764471135, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001243384472348685, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.012768809306355438, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 91, 'num_filters_3': 72, 'num_filters_4': 84}"}}
exception: None

22:37:15 job_callback for (4, 0, 20) started
22:37:15 job_callback for (4, 0, 20) got condition
22:37:15 DISPATCHER: Trying to submit another job.
22:37:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:37:15 HBMASTER: Trying to run another job!
22:37:15 job_callback for (4, 0, 20) finished
22:37:15 HBMASTER: schedule new run for iteration 4
22:37:15 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
22:37:15 HBMASTER: submitting job (4, 0, 22) to dispatcher
22:37:15 DISPATCHER: trying to submit job (4, 0, 22)
22:37:15 DISPATCHER: trying to notify the job_runner thread.
22:37:15 HBMASTER: job (4, 0, 22) submitted to dispatcher
22:37:15 DISPATCHER: Trying to submit another job.
22:37:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:37:15 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:37:15 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:37:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:37:15 WORKER: start processing job (4, 0, 22)
22:37:15 WORKER: args: ()
22:37:15 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0033369884764140917, 'num_filters_1': 23, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.02461366685279488, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 37, 'num_filters_3': 75, 'num_filters_4': 52}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:37:49 DISPATCHER: Starting worker discovery
22:37:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:37:49 DISPATCHER: Finished worker discovery
22:38:49 DISPATCHER: Starting worker discovery
22:38:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:38:49 DISPATCHER: Finished worker discovery
22:39:49 DISPATCHER: Starting worker discovery
22:39:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:39:49 DISPATCHER: Finished worker discovery
22:39:49 WORKER: done with job (4, 0, 22), trying to register it.
22:39:49 WORKER: registered result for job (4, 0, 22) with dispatcher
22:39:49 DISPATCHER: job (4, 0, 22) finished
22:39:49 DISPATCHER: register_result: lock acquired
22:39:49 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:39:49 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0033369884764140917, 'num_filters_1': 23, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.02461366685279488, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 37, 'num_filters_3': 75, 'num_filters_4': 52}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.14680474122711676, 'info': {'data04': 0.14680474122711676, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0033369884764140917, 'num_filters_1': 23, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.02461366685279488, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 37, 'num_filters_3': 75, 'num_filters_4': 52}"}}
exception: None

22:39:49 job_callback for (4, 0, 22) started
22:39:49 job_callback for (4, 0, 22) got condition
22:39:49 DISPATCHER: Trying to submit another job.
22:39:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:39:49 HBMASTER: Trying to run another job!
22:39:49 job_callback for (4, 0, 22) finished
22:39:49 ITERATION: Advancing config (4, 0, 10) to next budget 400.000000
22:39:49 ITERATION: Advancing config (4, 0, 20) to next budget 400.000000
22:39:49 ITERATION: Advancing config (4, 0, 22) to next budget 400.000000
22:39:49 HBMASTER: schedule new run for iteration 4
22:39:49 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
22:39:49 HBMASTER: submitting job (4, 0, 10) to dispatcher
22:39:49 DISPATCHER: trying to submit job (4, 0, 10)
22:39:49 DISPATCHER: trying to notify the job_runner thread.
22:39:49 HBMASTER: job (4, 0, 10) submitted to dispatcher
22:39:49 DISPATCHER: Trying to submit another job.
22:39:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:39:49 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:39:49 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:39:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:39:49 WORKER: start processing job (4, 0, 10)
22:39:49 WORKER: args: ()
22:39:49 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0013627295421679176, 'num_filters_1': 104, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.040885418461170706, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 50, 'num_filters_3': 17, 'num_filters_4': 19, 'num_filters_5': 67}, 'budget': 400.0, 'working_directory': '.'}
22:40:49 DISPATCHER: Starting worker discovery
22:40:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:40:49 DISPATCHER: Finished worker discovery
22:41:49 DISPATCHER: Starting worker discovery
22:41:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:41:49 DISPATCHER: Finished worker discovery
22:42:49 DISPATCHER: Starting worker discovery
22:42:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:42:49 DISPATCHER: Finished worker discovery
22:43:49 DISPATCHER: Starting worker discovery
22:43:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:43:49 DISPATCHER: Finished worker discovery
22:44:49 DISPATCHER: Starting worker discovery
22:44:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:44:49 DISPATCHER: Finished worker discovery
22:45:49 DISPATCHER: Starting worker discovery
22:45:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:45:49 DISPATCHER: Finished worker discovery
22:46:49 DISPATCHER: Starting worker discovery
22:46:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:46:49 DISPATCHER: Finished worker discovery
22:46:56 WORKER: done with job (4, 0, 10), trying to register it.
22:46:56 WORKER: registered result for job (4, 0, 10) with dispatcher
22:46:56 DISPATCHER: job (4, 0, 10) finished
22:46:56 DISPATCHER: register_result: lock acquired
22:46:56 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:46:56 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0013627295421679176, 'num_filters_1': 104, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.040885418461170706, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 50, 'num_filters_3': 17, 'num_filters_4': 19, 'num_filters_5': 67}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.13301322581369787, 'info': {'data04': 0.13301322581369787, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0013627295421679176, 'num_filters_1': 104, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.040885418461170706, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 50, 'num_filters_3': 17, 'num_filters_4': 19, 'num_filters_5': 67}"}}
exception: None

22:46:56 job_callback for (4, 0, 10) started
22:46:56 job_callback for (4, 0, 10) got condition
22:46:56 DISPATCHER: Trying to submit another job.
22:46:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:46:56 Only 13 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
22:46:56 HBMASTER: Trying to run another job!
22:46:56 job_callback for (4, 0, 10) finished
22:46:56 HBMASTER: schedule new run for iteration 4
22:46:56 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
22:46:56 HBMASTER: submitting job (4, 0, 20) to dispatcher
22:46:56 DISPATCHER: trying to submit job (4, 0, 20)
22:46:56 DISPATCHER: trying to notify the job_runner thread.
22:46:56 HBMASTER: job (4, 0, 20) submitted to dispatcher
22:46:56 DISPATCHER: Trying to submit another job.
22:46:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:46:56 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:46:56 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:46:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:46:56 WORKER: start processing job (4, 0, 20)
22:46:56 WORKER: args: ()
22:46:56 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001243384472348685, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.012768809306355438, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 91, 'num_filters_3': 72, 'num_filters_4': 84}, 'budget': 400.0, 'working_directory': '.'}
22:47:49 DISPATCHER: Starting worker discovery
22:47:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:47:49 DISPATCHER: Finished worker discovery
22:48:49 DISPATCHER: Starting worker discovery
22:48:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:48:49 DISPATCHER: Finished worker discovery
22:49:49 DISPATCHER: Starting worker discovery
22:49:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:49:49 DISPATCHER: Finished worker discovery
22:50:49 DISPATCHER: Starting worker discovery
22:50:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:50:49 DISPATCHER: Finished worker discovery
22:51:49 DISPATCHER: Starting worker discovery
22:51:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:51:49 DISPATCHER: Finished worker discovery
22:52:49 DISPATCHER: Starting worker discovery
22:52:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:52:49 DISPATCHER: Finished worker discovery
22:53:49 DISPATCHER: Starting worker discovery
22:53:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:53:49 DISPATCHER: Finished worker discovery
22:54:03 WORKER: done with job (4, 0, 20), trying to register it.
22:54:03 WORKER: registered result for job (4, 0, 20) with dispatcher
22:54:03 DISPATCHER: job (4, 0, 20) finished
22:54:03 DISPATCHER: register_result: lock acquired
22:54:03 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
22:54:03 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001243384472348685, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.012768809306355438, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 91, 'num_filters_3': 72, 'num_filters_4': 84}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.1503919776970889, 'info': {'data04': 0.1503919776970889, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001243384472348685, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.012768809306355438, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 91, 'num_filters_3': 72, 'num_filters_4': 84}"}}
exception: None

22:54:03 job_callback for (4, 0, 20) started
22:54:03 job_callback for (4, 0, 20) got condition
22:54:03 DISPATCHER: Trying to submit another job.
22:54:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:54:03 Only 14 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
22:54:03 HBMASTER: Trying to run another job!
22:54:03 job_callback for (4, 0, 20) finished
22:54:03 HBMASTER: schedule new run for iteration 4
22:54:03 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
22:54:03 HBMASTER: submitting job (4, 0, 22) to dispatcher
22:54:03 DISPATCHER: trying to submit job (4, 0, 22)
22:54:03 DISPATCHER: trying to notify the job_runner thread.
22:54:03 HBMASTER: job (4, 0, 22) submitted to dispatcher
22:54:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:54:03 DISPATCHER: Trying to submit another job.
22:54:03 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:54:03 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
22:54:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:54:03 WORKER: start processing job (4, 0, 22)
22:54:03 WORKER: args: ()
22:54:03 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0033369884764140917, 'num_filters_1': 23, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.02461366685279488, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 37, 'num_filters_3': 75, 'num_filters_4': 52}, 'budget': 400.0, 'working_directory': '.'}
22:54:49 DISPATCHER: Starting worker discovery
22:54:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:54:49 DISPATCHER: Finished worker discovery
22:55:49 DISPATCHER: Starting worker discovery
22:55:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:55:49 DISPATCHER: Finished worker discovery
22:56:49 DISPATCHER: Starting worker discovery
22:56:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:56:49 DISPATCHER: Finished worker discovery
22:57:49 DISPATCHER: Starting worker discovery
22:57:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:57:49 DISPATCHER: Finished worker discovery
22:58:49 DISPATCHER: Starting worker discovery
22:58:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:58:49 DISPATCHER: Finished worker discovery
22:59:49 DISPATCHER: Starting worker discovery
22:59:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:59:49 DISPATCHER: Finished worker discovery
23:00:49 DISPATCHER: Starting worker discovery
23:00:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:00:49 DISPATCHER: Finished worker discovery
23:01:11 WORKER: done with job (4, 0, 22), trying to register it.
23:01:11 WORKER: registered result for job (4, 0, 22) with dispatcher
23:01:11 DISPATCHER: job (4, 0, 22) finished
23:01:11 DISPATCHER: register_result: lock acquired
23:01:11 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
23:01:11 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0033369884764140917, 'num_filters_1': 23, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.02461366685279488, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 37, 'num_filters_3': 75, 'num_filters_4': 52}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.12118187544824902, 'info': {'data04': 0.12118187544824902, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0033369884764140917, 'num_filters_1': 23, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.02461366685279488, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 37, 'num_filters_3': 75, 'num_filters_4': 52}"}}
exception: None

23:01:11 job_callback for (4, 0, 22) started
23:01:11 job_callback for (4, 0, 22) got condition
23:01:11 DISPATCHER: Trying to submit another job.
23:01:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:01:11 Only 15 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
23:01:11 HBMASTER: Trying to run another job!
23:01:11 job_callback for (4, 0, 22) finished
23:01:11 ITERATION: Advancing config (4, 0, 20) to next budget 1200.000000
23:01:11 HBMASTER: schedule new run for iteration 4
23:01:11 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
23:01:11 HBMASTER: submitting job (4, 0, 20) to dispatcher
23:01:11 DISPATCHER: trying to submit job (4, 0, 20)
23:01:11 DISPATCHER: trying to notify the job_runner thread.
23:01:11 HBMASTER: job (4, 0, 20) submitted to dispatcher
23:01:11 DISPATCHER: Trying to submit another job.
23:01:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:01:11 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:01:11 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:01:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:01:11 WORKER: start processing job (4, 0, 20)
23:01:11 WORKER: args: ()
23:01:11 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001243384472348685, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.012768809306355438, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 91, 'num_filters_3': 72, 'num_filters_4': 84}, 'budget': 1200.0, 'working_directory': '.'}
23:01:49 DISPATCHER: Starting worker discovery
23:01:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:01:49 DISPATCHER: Finished worker discovery
23:02:49 DISPATCHER: Starting worker discovery
23:02:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:02:49 DISPATCHER: Finished worker discovery
23:03:49 DISPATCHER: Starting worker discovery
23:03:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:03:49 DISPATCHER: Finished worker discovery
23:04:49 DISPATCHER: Starting worker discovery
23:04:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:04:49 DISPATCHER: Finished worker discovery
23:05:49 DISPATCHER: Starting worker discovery
23:05:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:05:49 DISPATCHER: Finished worker discovery
23:06:49 DISPATCHER: Starting worker discovery
23:06:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:06:49 DISPATCHER: Finished worker discovery
23:07:49 DISPATCHER: Starting worker discovery
23:07:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:07:49 DISPATCHER: Finished worker discovery
23:08:49 DISPATCHER: Starting worker discovery
23:08:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:08:49 DISPATCHER: Finished worker discovery
23:09:49 DISPATCHER: Starting worker discovery
23:09:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:09:49 DISPATCHER: Finished worker discovery
23:10:49 DISPATCHER: Starting worker discovery
23:10:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:10:49 DISPATCHER: Finished worker discovery
23:11:49 DISPATCHER: Starting worker discovery
23:11:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:11:49 DISPATCHER: Finished worker discovery
23:12:49 DISPATCHER: Starting worker discovery
23:12:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:12:49 DISPATCHER: Finished worker discovery
23:13:49 DISPATCHER: Starting worker discovery
23:13:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:13:49 DISPATCHER: Finished worker discovery
23:14:49 DISPATCHER: Starting worker discovery
23:14:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:14:49 DISPATCHER: Finished worker discovery
23:15:49 DISPATCHER: Starting worker discovery
23:15:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:15:49 DISPATCHER: Finished worker discovery
23:16:49 DISPATCHER: Starting worker discovery
23:16:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:16:49 DISPATCHER: Finished worker discovery
23:17:49 DISPATCHER: Starting worker discovery
23:17:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:17:49 DISPATCHER: Finished worker discovery
23:18:49 DISPATCHER: Starting worker discovery
23:18:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:18:49 DISPATCHER: Finished worker discovery
23:19:49 DISPATCHER: Starting worker discovery
23:19:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:19:49 DISPATCHER: Finished worker discovery
23:20:49 DISPATCHER: Starting worker discovery
23:20:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:20:49 DISPATCHER: Finished worker discovery
23:21:49 DISPATCHER: Starting worker discovery
23:21:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:21:50 DISPATCHER: Finished worker discovery
23:22:07 WORKER: done with job (4, 0, 20), trying to register it.
23:22:07 WORKER: registered result for job (4, 0, 20) with dispatcher
23:22:07 DISPATCHER: job (4, 0, 20) finished
23:22:07 DISPATCHER: register_result: lock acquired
23:22:07 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
23:22:07 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001243384472348685, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.012768809306355438, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 91, 'num_filters_3': 72, 'num_filters_4': 84}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.1432645756544858, 'info': {'data04': 0.1432645756544858, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.001243384472348685, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.012768809306355438, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 91, 'num_filters_3': 72, 'num_filters_4': 84}"}}
exception: None

23:22:07 job_callback for (4, 0, 20) started
23:22:07 DISPATCHER: Trying to submit another job.
23:22:07 job_callback for (4, 0, 20) got condition
23:22:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:22:07 Only 9 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
23:22:07 HBMASTER: Trying to run another job!
23:22:07 job_callback for (4, 0, 20) finished
23:22:07 start sampling a new configuration.
23:22:08 best_vector: [2, 2, 0.19094652376519636, 0.9987796556847166, 0.2986450775104975, 1, 0.1277594179257572, 0.39566545416188414, 1, 0, 1, 1, 0.35736599897592786, 0.6152098945163477, 0.9790925610276704, 0.5069776518648085], 0.00436609828479564, 0.0006532966830993308, 2.852357527542669e-06
23:22:08 done sampling a new configuration.
23:22:08 HBMASTER: schedule new run for iteration 5
23:22:08 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
23:22:08 HBMASTER: submitting job (5, 0, 0) to dispatcher
23:22:08 DISPATCHER: trying to submit job (5, 0, 0)
23:22:08 DISPATCHER: trying to notify the job_runner thread.
23:22:08 HBMASTER: job (5, 0, 0) submitted to dispatcher
23:22:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:22:08 DISPATCHER: Trying to submit another job.
23:22:08 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:22:08 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:22:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:22:08 WORKER: start processing job (5, 0, 0)
23:22:08 WORKER: args: ()
23:22:08 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0024093120211869496, 'num_filters_1': 128, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.032716935975109634, 'kernel_size_2': 5, 'num_filters_2': 33}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:22:50 DISPATCHER: Starting worker discovery
23:22:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:22:50 DISPATCHER: Finished worker discovery
23:23:50 DISPATCHER: Starting worker discovery
23:23:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:23:50 DISPATCHER: Finished worker discovery
23:24:50 DISPATCHER: Starting worker discovery
23:24:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:24:50 DISPATCHER: Finished worker discovery
23:24:58 WORKER: done with job (5, 0, 0), trying to register it.
23:24:58 WORKER: registered result for job (5, 0, 0) with dispatcher
23:24:58 DISPATCHER: job (5, 0, 0) finished
23:24:58 DISPATCHER: register_result: lock acquired
23:24:58 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
23:24:58 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0024093120211869496, 'num_filters_1': 128, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.032716935975109634, 'kernel_size_2': 5, 'num_filters_2': 33}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.16069424034182223, 'info': {'data04': 0.16069424034182223, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0024093120211869496, 'num_filters_1': 128, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.032716935975109634, 'kernel_size_2': 5, 'num_filters_2': 33}"}}
exception: None

23:24:58 job_callback for (5, 0, 0) started
23:24:58 job_callback for (5, 0, 0) got condition
23:24:58 DISPATCHER: Trying to submit another job.
23:24:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:24:58 HBMASTER: Trying to run another job!
23:24:58 job_callback for (5, 0, 0) finished
23:24:58 start sampling a new configuration.
23:24:58 best_vector: [0, 0, 0.17066458402529877, 0.4865014631646649, 0.7638289626348781, 1, 0.2201132145082434, 0.04678172986653584, 2, 1, 0, 0, 0.6735867831963325, 0.6579661892603896, 0.17134138654488806, 0.2508736854766061], 0.007501416876179999, 0.0006771062147765145, 5.079255986490905e-06
23:24:58 done sampling a new configuration.
23:24:58 HBMASTER: schedule new run for iteration 5
23:24:58 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
23:24:58 HBMASTER: submitting job (5, 0, 1) to dispatcher
23:24:58 DISPATCHER: trying to submit job (5, 0, 1)
23:24:58 DISPATCHER: trying to notify the job_runner thread.
23:24:58 HBMASTER: job (5, 0, 1) submitted to dispatcher
23:24:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:24:58 DISPATCHER: Trying to submit another job.
23:24:58 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:24:58 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:24:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:24:58 WORKER: start processing job (5, 0, 1)
23:24:58 WORKER: args: ()
23:24:58 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0021944675743321694, 'num_filters_1': 43, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.011504412195580438, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 64, 'num_filters_3': 62, 'num_filters_4': 22}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:25:50 DISPATCHER: Starting worker discovery
23:25:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:25:50 DISPATCHER: Finished worker discovery
23:26:50 DISPATCHER: Starting worker discovery
23:26:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:26:50 DISPATCHER: Finished worker discovery
23:27:43 WORKER: done with job (5, 0, 1), trying to register it.
23:27:43 WORKER: registered result for job (5, 0, 1) with dispatcher
23:27:43 DISPATCHER: job (5, 0, 1) finished
23:27:43 DISPATCHER: register_result: lock acquired
23:27:43 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
23:27:43 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0021944675743321694, 'num_filters_1': 43, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.011504412195580438, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 64, 'num_filters_3': 62, 'num_filters_4': 22}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1509057750688686, 'info': {'data04': 0.1509057750688686, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0021944675743321694, 'num_filters_1': 43, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.011504412195580438, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 64, 'num_filters_3': 62, 'num_filters_4': 22}"}}
exception: None

23:27:43 job_callback for (5, 0, 1) started
23:27:43 job_callback for (5, 0, 1) got condition
23:27:43 DISPATCHER: Trying to submit another job.
23:27:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:27:43 HBMASTER: Trying to run another job!
23:27:43 job_callback for (5, 0, 1) finished
23:27:43 start sampling a new configuration.
23:27:43 best_vector: [0, 1, 0.5815786874746804, 0.9658627622640215, 0.8899523678537817, 1, 0.01739777059726251, 0.22286733410698295, 2, 2, 0, 0, 0.6297242844793185, 0.4218244097403452, 0.11669535918200305, 0.014168190249558593], 0.0036527019555200836, 0.0002303667236985592, 8.414609821404819e-07
23:27:43 done sampling a new configuration.
23:27:43 HBMASTER: schedule new run for iteration 5
23:27:43 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
23:27:43 HBMASTER: submitting job (5, 0, 2) to dispatcher
23:27:43 DISPATCHER: trying to submit job (5, 0, 2)
23:27:43 DISPATCHER: trying to notify the job_runner thread.
23:27:43 HBMASTER: job (5, 0, 2) submitted to dispatcher
23:27:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:27:43 DISPATCHER: Trying to submit another job.
23:27:43 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:27:43 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:27:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:27:43 WORKER: start processing job (5, 0, 2)
23:27:43 WORKER: args: ()
23:27:43 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.014559865897134523, 'num_filters_1': 120, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.019496519422789755, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 59, 'num_filters_3': 38, 'num_filters_4': 20, 'num_filters_5': 16}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:27:50 DISPATCHER: Starting worker discovery
23:27:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:27:50 DISPATCHER: Finished worker discovery
23:28:50 DISPATCHER: Starting worker discovery
23:28:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:28:50 DISPATCHER: Finished worker discovery
23:29:50 DISPATCHER: Starting worker discovery
23:29:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:29:50 DISPATCHER: Finished worker discovery
23:30:49 WORKER: done with job (5, 0, 2), trying to register it.
23:30:49 WORKER: registered result for job (5, 0, 2) with dispatcher
23:30:49 DISPATCHER: job (5, 0, 2) finished
23:30:49 DISPATCHER: register_result: lock acquired
23:30:49 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
23:30:49 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.014559865897134523, 'num_filters_1': 120, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.019496519422789755, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 59, 'num_filters_3': 38, 'num_filters_4': 20, 'num_filters_5': 16}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.03525797696991412, 'info': {'data04': 0.03525797696991412, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.014559865897134523, 'num_filters_1': 120, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.019496519422789755, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 59, 'num_filters_3': 38, 'num_filters_4': 20, 'num_filters_5': 16}"}}
exception: None

23:30:49 job_callback for (5, 0, 2) started
23:30:49 job_callback for (5, 0, 2) got condition
23:30:49 DISPATCHER: Trying to submit another job.
23:30:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:30:49 HBMASTER: Trying to run another job!
23:30:49 job_callback for (5, 0, 2) finished
23:30:49 start sampling a new configuration.
23:30:49 best_vector: [2, 0, 0.3329497487303239, 0.9262204239462202, 0.6177757161522811, 1, 0.016542096215467705, 0.013340853187496702, 2, 1, 0, 2, 0.5052819475825345, 0.6034930212365166, 0.6609929220959481, 0.12293690637586022], 0.003603697342489507, 0.0002811550485948296, 1.0131977014486957e-06
23:30:49 done sampling a new configuration.
23:30:49 HBMASTER: schedule new run for iteration 5
23:30:49 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
23:30:49 HBMASTER: submitting job (5, 0, 3) to dispatcher
23:30:49 DISPATCHER: trying to submit job (5, 0, 3)
23:30:49 DISPATCHER: trying to notify the job_runner thread.
23:30:49 HBMASTER: job (5, 0, 3) submitted to dispatcher
23:30:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:30:49 DISPATCHER: Trying to submit another job.
23:30:49 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:30:49 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:30:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:30:49 WORKER: start processing job (5, 0, 3)
23:30:49 WORKER: args: ()
23:30:49 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004633396832751934, 'num_filters_1': 110, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.010407749963650754, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 45, 'num_filters_3': 56, 'num_filters_4': 63}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:30:50 DISPATCHER: Starting worker discovery
23:30:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:30:50 DISPATCHER: Finished worker discovery
23:31:50 DISPATCHER: Starting worker discovery
23:31:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:31:50 DISPATCHER: Finished worker discovery
23:32:50 DISPATCHER: Starting worker discovery
23:32:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:32:50 DISPATCHER: Finished worker discovery
23:33:50 WORKER: done with job (5, 0, 3), trying to register it.
23:33:50 WORKER: registered result for job (5, 0, 3) with dispatcher
23:33:50 DISPATCHER: job (5, 0, 3) finished
23:33:50 DISPATCHER: register_result: lock acquired
23:33:50 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
23:33:50 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004633396832751934, 'num_filters_1': 110, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.010407749963650754, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 45, 'num_filters_3': 56, 'num_filters_4': 63}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.175765217588707, 'info': {'data04': 0.175765217588707, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004633396832751934, 'num_filters_1': 110, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.010407749963650754, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 45, 'num_filters_3': 56, 'num_filters_4': 63}"}}
exception: None

23:33:50 job_callback for (5, 0, 3) started
23:33:50 DISPATCHER: Trying to submit another job.
23:33:50 job_callback for (5, 0, 3) got condition
23:33:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:33:50 HBMASTER: Trying to run another job!
23:33:50 job_callback for (5, 0, 3) finished
23:33:50 start sampling a new configuration.
23:33:50 best_vector: [3, 2, 0.2099595461707286, 0.5267489168719766, 0.7031232017807856, 1, 0.9718959930998363, 0.16813090128179925, 0, 0, 2, 2, 0.6559779770218122, 0.5025990218694457, 0.9168918547732504, 0.032100776738485326], 0.0031847449203936426, 0.0017574351746185621, 5.59698274528758e-06
23:33:50 done sampling a new configuration.
23:33:50 HBMASTER: schedule new run for iteration 5
23:33:50 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
23:33:50 HBMASTER: submitting job (5, 0, 4) to dispatcher
23:33:50 DISPATCHER: trying to submit job (5, 0, 4)
23:33:50 DISPATCHER: trying to notify the job_runner thread.
23:33:50 HBMASTER: job (5, 0, 4) submitted to dispatcher
23:33:50 DISPATCHER: Trying to submit another job.
23:33:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:33:50 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:33:50 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:33:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:33:50 WORKER: start processing job (5, 0, 4)
23:33:50 WORKER: args: ()
23:33:50 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0026297780271091298, 'num_filters_1': 47, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.01654791745127716, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 62, 'num_filters_3': 45, 'num_filters_4': 108}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:33:50 DISPATCHER: Starting worker discovery
23:33:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:33:50 DISPATCHER: Finished worker discovery
23:34:50 DISPATCHER: Starting worker discovery
23:34:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:34:50 DISPATCHER: Finished worker discovery
23:35:50 DISPATCHER: Starting worker discovery
23:35:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:35:50 DISPATCHER: Finished worker discovery
23:36:23 WORKER: done with job (5, 0, 4), trying to register it.
23:36:23 WORKER: registered result for job (5, 0, 4) with dispatcher
23:36:23 DISPATCHER: job (5, 0, 4) finished
23:36:23 DISPATCHER: register_result: lock acquired
23:36:23 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
23:36:23 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0026297780271091298, 'num_filters_1': 47, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.01654791745127716, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 62, 'num_filters_3': 45, 'num_filters_4': 108}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.16492309108208594, 'info': {'data04': 0.16492309108208594, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0026297780271091298, 'num_filters_1': 47, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.01654791745127716, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 62, 'num_filters_3': 45, 'num_filters_4': 108}"}}
exception: None

23:36:23 job_callback for (5, 0, 4) started
23:36:23 DISPATCHER: Trying to submit another job.
23:36:23 job_callback for (5, 0, 4) got condition
23:36:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:36:23 HBMASTER: Trying to run another job!
23:36:23 job_callback for (5, 0, 4) finished
23:36:23 start sampling a new configuration.
23:36:23 best_vector: [0, 0, 0.22531746246814643, 0.1868957578971328, 0.8213072359001701, 1, 0.1982157005434405, 0.09174368164204061, 1, 0, 1, 2, 0.5316285162742261, 0.9280303954415705, 0.9273494361023018, 0.6166464823806521], 0.000583118566059974, 0.0004052581839246743, 2.363135710942253e-07
23:36:23 done sampling a new configuration.
23:36:23 HBMASTER: schedule new run for iteration 5
23:36:23 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
23:36:23 HBMASTER: submitting job (5, 0, 5) to dispatcher
23:36:23 DISPATCHER: trying to submit job (5, 0, 5)
23:36:23 DISPATCHER: trying to notify the job_runner thread.
23:36:23 HBMASTER: job (5, 0, 5) submitted to dispatcher
23:36:23 DISPATCHER: Trying to submit another job.
23:36:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:36:23 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:36:23 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:36:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:36:23 WORKER: start processing job (5, 0, 5)
23:36:23 WORKER: args: ()
23:36:23 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002822506332283367, 'num_filters_1': 23, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.013163193991675072, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 48, 'num_filters_3': 110, 'num_filters_4': 110, 'num_filters_5': 57}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:36:50 DISPATCHER: Starting worker discovery
23:36:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:36:50 DISPATCHER: Finished worker discovery
23:37:50 DISPATCHER: Starting worker discovery
23:37:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:37:50 DISPATCHER: Finished worker discovery
23:38:50 DISPATCHER: Starting worker discovery
23:38:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:38:50 DISPATCHER: Finished worker discovery
23:39:03 WORKER: done with job (5, 0, 5), trying to register it.
23:39:03 WORKER: registered result for job (5, 0, 5) with dispatcher
23:39:03 DISPATCHER: job (5, 0, 5) finished
23:39:03 DISPATCHER: register_result: lock acquired
23:39:03 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
23:39:03 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002822506332283367, 'num_filters_1': 23, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.013163193991675072, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 48, 'num_filters_3': 110, 'num_filters_4': 110, 'num_filters_5': 57}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.14122195042521846, 'info': {'data04': 0.14122195042521846, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002822506332283367, 'num_filters_1': 23, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.013163193991675072, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 48, 'num_filters_3': 110, 'num_filters_4': 110, 'num_filters_5': 57}"}}
exception: None

23:39:03 job_callback for (5, 0, 5) started
23:39:03 DISPATCHER: Trying to submit another job.
23:39:03 job_callback for (5, 0, 5) got condition
23:39:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:39:03 HBMASTER: Trying to run another job!
23:39:03 job_callback for (5, 0, 5) finished
23:39:03 start sampling a new configuration.
23:39:03 done sampling a new configuration.
23:39:03 HBMASTER: schedule new run for iteration 5
23:39:03 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
23:39:03 HBMASTER: submitting job (5, 0, 6) to dispatcher
23:39:03 DISPATCHER: trying to submit job (5, 0, 6)
23:39:03 DISPATCHER: trying to notify the job_runner thread.
23:39:03 HBMASTER: job (5, 0, 6) submitted to dispatcher
23:39:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:39:03 DISPATCHER: Trying to submit another job.
23:39:03 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:39:03 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:39:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:39:03 WORKER: start processing job (5, 0, 6)
23:39:03 WORKER: args: ()
23:39:03 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.029361426762576744, 'num_filters_1': 75, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.05815962802339535, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 80, 'num_filters_3': 68, 'num_filters_4': 25}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:39:50 DISPATCHER: Starting worker discovery
23:39:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:39:50 DISPATCHER: Finished worker discovery
23:40:50 DISPATCHER: Starting worker discovery
23:40:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:40:50 DISPATCHER: Finished worker discovery
23:41:34 WORKER: done with job (5, 0, 6), trying to register it.
23:41:34 WORKER: registered result for job (5, 0, 6) with dispatcher
23:41:34 DISPATCHER: job (5, 0, 6) finished
23:41:34 DISPATCHER: register_result: lock acquired
23:41:34 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
23:41:34 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.029361426762576744, 'num_filters_1': 75, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.05815962802339535, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 80, 'num_filters_3': 68, 'num_filters_4': 25}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.005127057340369975, 'info': {'data04': 0.005127057340369975, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.029361426762576744, 'num_filters_1': 75, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.05815962802339535, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 80, 'num_filters_3': 68, 'num_filters_4': 25}"}}
exception: None

23:41:34 job_callback for (5, 0, 6) started
23:41:34 job_callback for (5, 0, 6) got condition
23:41:34 DISPATCHER: Trying to submit another job.
23:41:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:41:34 done building a new model for budget 133.333333 based on 17/28 split
Best loss for this budget:-0.181448





23:41:34 HBMASTER: Trying to run another job!
23:41:34 job_callback for (5, 0, 6) finished
23:41:34 start sampling a new configuration.
23:41:35 best_vector: [3, 2, 0.306926950316854, 0.5509717610382924, 0.6184464557929358, 1, 0.1804417655171217, 0.03127839430445223, 0, 0, 2, 1, 0.513089974634261, 0.6451964456757125, 0.8330744022521469, 0.7572674435556357], 9.96968269440166e-31, 0.010030409499005785, -1.815256926385275e-05
23:41:35 done sampling a new configuration.
23:41:35 HBMASTER: schedule new run for iteration 5
23:41:35 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
23:41:35 HBMASTER: submitting job (5, 0, 7) to dispatcher
23:41:35 DISPATCHER: trying to submit job (5, 0, 7)
23:41:35 DISPATCHER: trying to notify the job_runner thread.
23:41:35 HBMASTER: job (5, 0, 7) submitted to dispatcher
23:41:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:41:35 DISPATCHER: Trying to submit another job.
23:41:35 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:41:35 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:41:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:41:35 WORKER: start processing job (5, 0, 7)
23:41:35 WORKER: args: ()
23:41:35 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0041101143104191416, 'num_filters_1': 50, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.010982320892360323, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 46, 'num_filters_3': 61, 'num_filters_4': 90}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:41:50 DISPATCHER: Starting worker discovery
23:41:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:41:50 DISPATCHER: Finished worker discovery
23:42:50 DISPATCHER: Starting worker discovery
23:42:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:42:50 DISPATCHER: Finished worker discovery
23:43:50 DISPATCHER: Starting worker discovery
23:43:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:43:50 DISPATCHER: Finished worker discovery
23:44:19 WORKER: done with job (5, 0, 7), trying to register it.
23:44:19 WORKER: registered result for job (5, 0, 7) with dispatcher
23:44:19 DISPATCHER: job (5, 0, 7) finished
23:44:19 DISPATCHER: register_result: lock acquired
23:44:19 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
23:44:19 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0041101143104191416, 'num_filters_1': 50, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.010982320892360323, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 46, 'num_filters_3': 61, 'num_filters_4': 90}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1472250901571795, 'info': {'data04': 0.1472250901571795, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0041101143104191416, 'num_filters_1': 50, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.010982320892360323, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 46, 'num_filters_3': 61, 'num_filters_4': 90}"}}
exception: None

23:44:19 job_callback for (5, 0, 7) started
23:44:19 DISPATCHER: Trying to submit another job.
23:44:19 job_callback for (5, 0, 7) got condition
23:44:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:44:19 done building a new model for budget 133.333333 based on 17/29 split
Best loss for this budget:-0.181448





23:44:19 HBMASTER: Trying to run another job!
23:44:19 job_callback for (5, 0, 7) finished
23:44:19 start sampling a new configuration.
23:44:19 best_vector: [3, 0, 0.6292482842761563, 0.5528466537267451, 0.3062048063252954, 1, 0.529331957440093, 0.6211426838495362, 0, 2, 0, 2, 0.44575614696531735, 0.8219632896636002, 0.10800925921063398, 0.6928738619538068], 2.460305511911083e-29, 0.00040645358682435883, -6.33977325691961e-06
23:44:19 done sampling a new configuration.
23:44:19 HBMASTER: schedule new run for iteration 5
23:44:19 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
23:44:19 HBMASTER: submitting job (5, 0, 8) to dispatcher
23:44:19 DISPATCHER: trying to submit job (5, 0, 8)
23:44:19 DISPATCHER: trying to notify the job_runner thread.
23:44:19 HBMASTER: job (5, 0, 8) submitted to dispatcher
23:44:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:44:19 DISPATCHER: Trying to submit another job.
23:44:19 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:44:19 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:44:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:44:19 WORKER: start processing job (5, 0, 8)
23:44:19 WORKER: args: ()
23:44:19 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.018134123476800275, 'num_filters_1': 50, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.06428731140537439, 'kernel_size_2': 3, 'num_filters_2': 40}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:44:50 DISPATCHER: Starting worker discovery
23:44:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:44:50 DISPATCHER: Finished worker discovery
23:45:50 DISPATCHER: Starting worker discovery
23:45:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:45:50 DISPATCHER: Finished worker discovery
23:46:50 DISPATCHER: Starting worker discovery
23:46:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:46:51 DISPATCHER: Finished worker discovery
23:46:58 WORKER: done with job (5, 0, 8), trying to register it.
23:46:58 WORKER: registered result for job (5, 0, 8) with dispatcher
23:46:58 DISPATCHER: job (5, 0, 8) finished
23:46:58 DISPATCHER: register_result: lock acquired
23:46:58 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
23:46:58 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.018134123476800275, 'num_filters_1': 50, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.06428731140537439, 'kernel_size_2': 3, 'num_filters_2': 40}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.03707197101900536, 'info': {'data04': 0.03707197101900536, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.018134123476800275, 'num_filters_1': 50, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 58, 'weight_decay': 0.06428731140537439, 'kernel_size_2': 3, 'num_filters_2': 40}"}}
exception: None

23:46:58 job_callback for (5, 0, 8) started
23:46:58 DISPATCHER: Trying to submit another job.
23:46:58 job_callback for (5, 0, 8) got condition
23:46:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:46:58 done building a new model for budget 133.333333 based on 17/30 split
Best loss for this budget:-0.181448





23:46:58 HBMASTER: Trying to run another job!
23:46:58 job_callback for (5, 0, 8) finished
23:46:58 ITERATION: Advancing config (5, 0, 0) to next budget 400.000000
23:46:58 ITERATION: Advancing config (5, 0, 3) to next budget 400.000000
23:46:58 ITERATION: Advancing config (5, 0, 4) to next budget 400.000000
23:46:58 HBMASTER: schedule new run for iteration 5
23:46:58 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
23:46:58 HBMASTER: submitting job (5, 0, 0) to dispatcher
23:46:58 DISPATCHER: trying to submit job (5, 0, 0)
23:46:58 DISPATCHER: trying to notify the job_runner thread.
23:46:58 HBMASTER: job (5, 0, 0) submitted to dispatcher
23:46:58 DISPATCHER: Trying to submit another job.
23:46:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:46:58 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:46:58 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:46:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:46:58 WORKER: start processing job (5, 0, 0)
23:46:58 WORKER: args: ()
23:46:58 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0024093120211869496, 'num_filters_1': 128, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.032716935975109634, 'kernel_size_2': 5, 'num_filters_2': 33}, 'budget': 400.0, 'working_directory': '.'}
23:47:51 DISPATCHER: Starting worker discovery
23:47:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:47:51 DISPATCHER: Finished worker discovery
23:48:51 DISPATCHER: Starting worker discovery
23:48:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:48:51 DISPATCHER: Finished worker discovery
23:49:51 DISPATCHER: Starting worker discovery
23:49:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:49:51 DISPATCHER: Finished worker discovery
23:50:51 DISPATCHER: Starting worker discovery
23:50:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:50:51 DISPATCHER: Finished worker discovery
23:51:51 DISPATCHER: Starting worker discovery
23:51:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:51:51 DISPATCHER: Finished worker discovery
23:52:51 DISPATCHER: Starting worker discovery
23:52:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:52:51 DISPATCHER: Finished worker discovery
23:53:51 DISPATCHER: Starting worker discovery
23:53:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:53:51 DISPATCHER: Finished worker discovery
23:54:51 DISPATCHER: Starting worker discovery
23:54:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:54:51 DISPATCHER: Finished worker discovery
23:55:07 WORKER: done with job (5, 0, 0), trying to register it.
23:55:07 WORKER: registered result for job (5, 0, 0) with dispatcher
23:55:07 DISPATCHER: job (5, 0, 0) finished
23:55:07 DISPATCHER: register_result: lock acquired
23:55:07 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
23:55:07 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0024093120211869496, 'num_filters_1': 128, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.032716935975109634, 'kernel_size_2': 5, 'num_filters_2': 33}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.08589043792859885, 'info': {'data04': 0.08589043792859885, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0024093120211869496, 'num_filters_1': 128, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.032716935975109634, 'kernel_size_2': 5, 'num_filters_2': 33}"}}
exception: None

23:55:07 job_callback for (5, 0, 0) started
23:55:07 DISPATCHER: Trying to submit another job.
23:55:07 job_callback for (5, 0, 0) got condition
23:55:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:55:07 Only 16 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
23:55:07 HBMASTER: Trying to run another job!
23:55:07 job_callback for (5, 0, 0) finished
23:55:07 HBMASTER: schedule new run for iteration 5
23:55:07 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
23:55:07 HBMASTER: submitting job (5, 0, 3) to dispatcher
23:55:07 DISPATCHER: trying to submit job (5, 0, 3)
23:55:07 DISPATCHER: trying to notify the job_runner thread.
23:55:07 HBMASTER: job (5, 0, 3) submitted to dispatcher
23:55:07 DISPATCHER: Trying to submit another job.
23:55:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:55:07 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:55:07 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
23:55:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:55:07 WORKER: start processing job (5, 0, 3)
23:55:07 WORKER: args: ()
23:55:07 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004633396832751934, 'num_filters_1': 110, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.010407749963650754, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 45, 'num_filters_3': 56, 'num_filters_4': 63}, 'budget': 400.0, 'working_directory': '.'}
23:55:51 DISPATCHER: Starting worker discovery
23:55:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:55:51 DISPATCHER: Finished worker discovery
23:56:51 DISPATCHER: Starting worker discovery
23:56:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:56:51 DISPATCHER: Finished worker discovery
23:57:51 DISPATCHER: Starting worker discovery
23:57:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:57:51 DISPATCHER: Finished worker discovery
23:58:51 DISPATCHER: Starting worker discovery
23:58:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:58:51 DISPATCHER: Finished worker discovery
23:59:51 DISPATCHER: Starting worker discovery
23:59:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:59:51 DISPATCHER: Finished worker discovery
00:00:51 DISPATCHER: Starting worker discovery
00:00:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:00:51 DISPATCHER: Finished worker discovery
00:01:51 DISPATCHER: Starting worker discovery
00:01:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:01:51 DISPATCHER: Finished worker discovery
00:02:51 DISPATCHER: Starting worker discovery
00:02:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:02:51 DISPATCHER: Finished worker discovery
00:03:47 WORKER: done with job (5, 0, 3), trying to register it.
00:03:47 WORKER: registered result for job (5, 0, 3) with dispatcher
00:03:47 DISPATCHER: job (5, 0, 3) finished
00:03:47 DISPATCHER: register_result: lock acquired
00:03:47 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:03:47 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004633396832751934, 'num_filters_1': 110, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.010407749963650754, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 45, 'num_filters_3': 56, 'num_filters_4': 63}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.13941105428410805, 'info': {'data04': 0.13941105428410805, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004633396832751934, 'num_filters_1': 110, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.010407749963650754, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 45, 'num_filters_3': 56, 'num_filters_4': 63}"}}
exception: None

00:03:47 job_callback for (5, 0, 3) started
00:03:47 job_callback for (5, 0, 3) got condition
00:03:47 DISPATCHER: Trying to submit another job.
00:03:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:03:47 HBMASTER: Trying to run another job!
00:03:47 job_callback for (5, 0, 3) finished
00:03:47 HBMASTER: schedule new run for iteration 5
00:03:47 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
00:03:47 HBMASTER: submitting job (5, 0, 4) to dispatcher
00:03:47 DISPATCHER: trying to submit job (5, 0, 4)
00:03:47 DISPATCHER: trying to notify the job_runner thread.
00:03:47 HBMASTER: job (5, 0, 4) submitted to dispatcher
00:03:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:03:47 DISPATCHER: Trying to submit another job.
00:03:47 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:03:47 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:03:47 WORKER: start processing job (5, 0, 4)
00:03:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:03:47 WORKER: args: ()
00:03:47 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0026297780271091298, 'num_filters_1': 47, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.01654791745127716, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 62, 'num_filters_3': 45, 'num_filters_4': 108}, 'budget': 400.0, 'working_directory': '.'}
00:03:51 DISPATCHER: Starting worker discovery
00:03:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:03:51 DISPATCHER: Finished worker discovery
00:04:51 DISPATCHER: Starting worker discovery
00:04:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:04:51 DISPATCHER: Finished worker discovery
00:05:51 DISPATCHER: Starting worker discovery
00:05:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:05:51 DISPATCHER: Finished worker discovery
00:06:51 DISPATCHER: Starting worker discovery
00:06:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:06:51 DISPATCHER: Finished worker discovery
00:07:51 DISPATCHER: Starting worker discovery
00:07:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:07:51 DISPATCHER: Finished worker discovery
00:08:51 DISPATCHER: Starting worker discovery
00:08:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:08:51 DISPATCHER: Finished worker discovery
00:09:51 DISPATCHER: Starting worker discovery
00:09:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:09:51 DISPATCHER: Finished worker discovery
00:10:51 DISPATCHER: Starting worker discovery
00:10:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:10:51 DISPATCHER: Finished worker discovery
00:10:52 WORKER: done with job (5, 0, 4), trying to register it.
00:10:52 WORKER: registered result for job (5, 0, 4) with dispatcher
00:10:52 DISPATCHER: job (5, 0, 4) finished
00:10:52 DISPATCHER: register_result: lock acquired
00:10:52 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:10:52 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0026297780271091298, 'num_filters_1': 47, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.01654791745127716, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 62, 'num_filters_3': 45, 'num_filters_4': 108}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.14620324905140025, 'info': {'data04': 0.14620324905140025, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0026297780271091298, 'num_filters_1': 47, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.01654791745127716, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 62, 'num_filters_3': 45, 'num_filters_4': 108}"}}
exception: None

00:10:52 job_callback for (5, 0, 4) started
00:10:52 job_callback for (5, 0, 4) got condition
00:10:52 DISPATCHER: Trying to submit another job.
00:10:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:10:52 HBMASTER: Trying to run another job!
00:10:52 job_callback for (5, 0, 4) finished
00:10:52 ITERATION: Advancing config (5, 0, 4) to next budget 1200.000000
00:10:52 HBMASTER: schedule new run for iteration 5
00:10:52 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
00:10:52 HBMASTER: submitting job (5, 0, 4) to dispatcher
00:10:52 DISPATCHER: trying to submit job (5, 0, 4)
00:10:52 DISPATCHER: trying to notify the job_runner thread.
00:10:52 HBMASTER: job (5, 0, 4) submitted to dispatcher
00:10:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:10:52 DISPATCHER: Trying to submit another job.
00:10:52 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:10:52 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:10:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:10:52 WORKER: start processing job (5, 0, 4)
00:10:52 WORKER: args: ()
00:10:52 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0026297780271091298, 'num_filters_1': 47, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.01654791745127716, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 62, 'num_filters_3': 45, 'num_filters_4': 108}, 'budget': 1200.0, 'working_directory': '.'}
00:11:51 DISPATCHER: Starting worker discovery
00:11:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:11:51 DISPATCHER: Finished worker discovery
00:12:51 DISPATCHER: Starting worker discovery
00:12:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:12:51 DISPATCHER: Finished worker discovery
00:13:51 DISPATCHER: Starting worker discovery
00:13:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:13:51 DISPATCHER: Finished worker discovery
00:14:51 DISPATCHER: Starting worker discovery
00:14:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:14:51 DISPATCHER: Finished worker discovery
00:15:51 DISPATCHER: Starting worker discovery
00:15:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:15:51 DISPATCHER: Finished worker discovery
00:16:51 DISPATCHER: Starting worker discovery
00:16:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:16:51 DISPATCHER: Finished worker discovery
00:17:51 DISPATCHER: Starting worker discovery
00:17:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:17:51 DISPATCHER: Finished worker discovery
00:18:51 DISPATCHER: Starting worker discovery
00:18:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:18:51 DISPATCHER: Finished worker discovery
00:19:51 DISPATCHER: Starting worker discovery
00:19:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:19:51 DISPATCHER: Finished worker discovery
00:20:51 DISPATCHER: Starting worker discovery
00:20:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:20:51 DISPATCHER: Finished worker discovery
00:21:51 DISPATCHER: Starting worker discovery
00:21:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:21:51 DISPATCHER: Finished worker discovery
00:22:51 DISPATCHER: Starting worker discovery
00:22:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:22:51 DISPATCHER: Finished worker discovery
00:23:51 DISPATCHER: Starting worker discovery
00:23:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:23:51 DISPATCHER: Finished worker discovery
00:24:51 DISPATCHER: Starting worker discovery
00:24:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:24:51 DISPATCHER: Finished worker discovery
00:25:51 DISPATCHER: Starting worker discovery
00:25:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:25:51 DISPATCHER: Finished worker discovery
00:26:51 DISPATCHER: Starting worker discovery
00:26:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:26:51 DISPATCHER: Finished worker discovery
00:27:51 DISPATCHER: Starting worker discovery
00:27:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:27:52 DISPATCHER: Finished worker discovery
00:28:52 DISPATCHER: Starting worker discovery
00:28:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:28:52 DISPATCHER: Finished worker discovery
00:29:52 DISPATCHER: Starting worker discovery
00:29:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:29:52 DISPATCHER: Finished worker discovery
00:30:52 DISPATCHER: Starting worker discovery
00:30:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:30:52 DISPATCHER: Finished worker discovery
00:31:42 WORKER: done with job (5, 0, 4), trying to register it.
00:31:42 WORKER: registered result for job (5, 0, 4) with dispatcher
00:31:42 DISPATCHER: job (5, 0, 4) finished
00:31:42 DISPATCHER: register_result: lock acquired
00:31:42 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:31:42 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0026297780271091298, 'num_filters_1': 47, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.01654791745127716, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 62, 'num_filters_3': 45, 'num_filters_4': 108}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0994638462630435, 'info': {'data04': 0.0994638462630435, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0026297780271091298, 'num_filters_1': 47, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.01654791745127716, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 62, 'num_filters_3': 45, 'num_filters_4': 108}"}}
exception: None

00:31:42 job_callback for (5, 0, 4) started
00:31:42 job_callback for (5, 0, 4) got condition
00:31:42 DISPATCHER: Trying to submit another job.
00:31:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:31:42 Only 10 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
00:31:42 HBMASTER: Trying to run another job!
00:31:42 job_callback for (5, 0, 4) finished
00:31:42 start sampling a new configuration.
00:31:42 done sampling a new configuration.
00:31:42 HBMASTER: schedule new run for iteration 6
00:31:42 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
00:31:42 HBMASTER: submitting job (6, 0, 0) to dispatcher
00:31:42 DISPATCHER: trying to submit job (6, 0, 0)
00:31:42 DISPATCHER: trying to notify the job_runner thread.
00:31:42 HBMASTER: job (6, 0, 0) submitted to dispatcher
00:31:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:31:42 DISPATCHER: Trying to submit another job.
00:31:42 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:31:42 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:31:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:31:42 WORKER: start processing job (6, 0, 0)
00:31:42 WORKER: args: ()
00:31:42 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0013221303875406679, 'num_filters_1': 25, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.016094639958163303, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 21, 'num_filters_3': 19, 'num_filters_4': 18}, 'budget': 400.0, 'working_directory': '.'}
00:31:52 DISPATCHER: Starting worker discovery
00:31:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:31:52 DISPATCHER: Finished worker discovery
00:32:52 DISPATCHER: Starting worker discovery
00:32:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:32:52 DISPATCHER: Finished worker discovery
00:33:52 DISPATCHER: Starting worker discovery
00:33:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:33:52 DISPATCHER: Finished worker discovery
00:34:52 DISPATCHER: Starting worker discovery
00:34:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:34:52 DISPATCHER: Finished worker discovery
00:35:52 DISPATCHER: Starting worker discovery
00:35:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:35:52 DISPATCHER: Finished worker discovery
00:36:52 DISPATCHER: Starting worker discovery
00:36:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:36:52 DISPATCHER: Finished worker discovery
00:37:52 DISPATCHER: Starting worker discovery
00:37:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:37:52 DISPATCHER: Finished worker discovery
00:38:52 DISPATCHER: Starting worker discovery
00:38:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:38:52 DISPATCHER: Finished worker discovery
00:38:55 WORKER: done with job (6, 0, 0), trying to register it.
00:38:55 WORKER: registered result for job (6, 0, 0) with dispatcher
00:38:55 DISPATCHER: job (6, 0, 0) finished
00:38:55 DISPATCHER: register_result: lock acquired
00:38:55 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:38:55 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0013221303875406679, 'num_filters_1': 25, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.016094639958163303, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 21, 'num_filters_3': 19, 'num_filters_4': 18}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0369524191183585, 'info': {'data04': 0.0369524191183585, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0013221303875406679, 'num_filters_1': 25, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.016094639958163303, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 21, 'num_filters_3': 19, 'num_filters_4': 18}"}}
exception: None

00:38:55 job_callback for (6, 0, 0) started
00:38:55 DISPATCHER: Trying to submit another job.
00:38:55 job_callback for (6, 0, 0) got condition
00:38:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:38:55 HBMASTER: Trying to run another job!
00:38:55 job_callback for (6, 0, 0) finished
00:38:55 start sampling a new configuration.
00:38:55 best_vector: [0, 1, 0.20445605958655277, 0.8289133457727794, 0.5351038496477019, 1, 0.7113491875235457, 0.7439042048005416, 1, 2, 1, 2, 0.6945402162017723, 0.804193351614004, 0.2639631780884848, 0.5608946114597663], 6.367707400208563e-30, 0.0015704239173540652, -1.0282573104632784e-05
00:38:55 done sampling a new configuration.
00:38:55 HBMASTER: schedule new run for iteration 6
00:38:55 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
00:38:55 HBMASTER: submitting job (6, 0, 1) to dispatcher
00:38:55 DISPATCHER: trying to submit job (6, 0, 1)
00:38:55 DISPATCHER: trying to notify the job_runner thread.
00:38:55 HBMASTER: job (6, 0, 1) submitted to dispatcher
00:38:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:38:55 DISPATCHER: Trying to submit another job.
00:38:55 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:38:55 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:38:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:38:55 WORKER: start processing job (6, 0, 1)
00:38:55 WORKER: args: ()
00:38:55 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0025639651577694005, 'num_filters_1': 89, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.09286278074879961, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 67, 'num_filters_3': 85}, 'budget': 400.0, 'working_directory': '.'}
00:39:52 DISPATCHER: Starting worker discovery
00:39:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:39:52 DISPATCHER: Finished worker discovery
00:40:52 DISPATCHER: Starting worker discovery
00:40:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:40:52 DISPATCHER: Finished worker discovery
00:41:52 DISPATCHER: Starting worker discovery
00:41:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:41:52 DISPATCHER: Finished worker discovery
00:42:52 DISPATCHER: Starting worker discovery
00:42:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:42:52 DISPATCHER: Finished worker discovery
00:43:52 DISPATCHER: Starting worker discovery
00:43:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:43:52 DISPATCHER: Finished worker discovery
00:44:52 DISPATCHER: Starting worker discovery
00:44:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:44:52 DISPATCHER: Finished worker discovery
00:45:52 DISPATCHER: Starting worker discovery
00:45:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:45:52 DISPATCHER: Finished worker discovery
00:46:09 WORKER: done with job (6, 0, 1), trying to register it.
00:46:09 WORKER: registered result for job (6, 0, 1) with dispatcher
00:46:09 DISPATCHER: job (6, 0, 1) finished
00:46:09 DISPATCHER: register_result: lock acquired
00:46:09 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:46:09 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0025639651577694005, 'num_filters_1': 89, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.09286278074879961, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 67, 'num_filters_3': 85}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.016247862826887744, 'info': {'data04': 0.016247862826887744, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0025639651577694005, 'num_filters_1': 89, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.09286278074879961, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 67, 'num_filters_3': 85}"}}
exception: None

00:46:09 job_callback for (6, 0, 1) started
00:46:09 job_callback for (6, 0, 1) got condition
00:46:09 DISPATCHER: Trying to submit another job.
00:46:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:46:09 HBMASTER: Trying to run another job!
00:46:09 job_callback for (6, 0, 1) finished
00:46:09 start sampling a new configuration.
00:46:09 done sampling a new configuration.
00:46:09 HBMASTER: schedule new run for iteration 6
00:46:09 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
00:46:09 HBMASTER: submitting job (6, 0, 2) to dispatcher
00:46:09 DISPATCHER: trying to submit job (6, 0, 2)
00:46:09 DISPATCHER: trying to notify the job_runner thread.
00:46:09 HBMASTER: job (6, 0, 2) submitted to dispatcher
00:46:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:46:09 DISPATCHER: Trying to submit another job.
00:46:09 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:46:09 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:46:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:46:09 WORKER: start processing job (6, 0, 2)
00:46:09 WORKER: args: ()
00:46:09 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004155133093692823, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.09037216928454606, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 109, 'num_filters_3': 20, 'num_filters_4': 123}, 'budget': 400.0, 'working_directory': '.'}
00:46:52 DISPATCHER: Starting worker discovery
00:46:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:46:52 DISPATCHER: Finished worker discovery
00:47:52 DISPATCHER: Starting worker discovery
00:47:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:47:52 DISPATCHER: Finished worker discovery
00:48:52 DISPATCHER: Starting worker discovery
00:48:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:48:52 DISPATCHER: Finished worker discovery
00:49:52 DISPATCHER: Starting worker discovery
00:49:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:49:52 DISPATCHER: Finished worker discovery
00:50:52 DISPATCHER: Starting worker discovery
00:50:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:50:52 DISPATCHER: Finished worker discovery
00:51:52 DISPATCHER: Starting worker discovery
00:51:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:51:52 DISPATCHER: Finished worker discovery
00:52:52 DISPATCHER: Starting worker discovery
00:52:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:52:52 DISPATCHER: Finished worker discovery
00:53:17 WORKER: done with job (6, 0, 2), trying to register it.
00:53:17 WORKER: registered result for job (6, 0, 2) with dispatcher
00:53:17 DISPATCHER: job (6, 0, 2) finished
00:53:17 DISPATCHER: register_result: lock acquired
00:53:17 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
00:53:17 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004155133093692823, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.09037216928454606, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 109, 'num_filters_3': 20, 'num_filters_4': 123}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.013079868740473764, 'info': {'data04': 0.013079868740473764, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004155133093692823, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.09037216928454606, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 109, 'num_filters_3': 20, 'num_filters_4': 123}"}}
exception: None

00:53:17 job_callback for (6, 0, 2) started
00:53:17 job_callback for (6, 0, 2) got condition
00:53:17 DISPATCHER: Trying to submit another job.
00:53:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:53:17 HBMASTER: Trying to run another job!
00:53:17 job_callback for (6, 0, 2) finished
00:53:17 start sampling a new configuration.
00:53:17 done sampling a new configuration.
00:53:17 HBMASTER: schedule new run for iteration 6
00:53:17 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
00:53:17 HBMASTER: submitting job (6, 0, 3) to dispatcher
00:53:17 DISPATCHER: trying to submit job (6, 0, 3)
00:53:17 DISPATCHER: trying to notify the job_runner thread.
00:53:17 HBMASTER: job (6, 0, 3) submitted to dispatcher
00:53:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:53:17 DISPATCHER: Trying to submit another job.
00:53:17 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:53:17 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
00:53:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:53:17 WORKER: start processing job (6, 0, 3)
00:53:17 WORKER: args: ()
00:53:17 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.08027311395889833, 'num_filters_1': 101, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.10268877762516153, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 17, 'num_filters_3': 45, 'num_filters_4': 44}, 'budget': 400.0, 'working_directory': '.'}
00:53:52 DISPATCHER: Starting worker discovery
00:53:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:53:52 DISPATCHER: Finished worker discovery
00:54:52 DISPATCHER: Starting worker discovery
00:54:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:54:52 DISPATCHER: Finished worker discovery
00:55:52 DISPATCHER: Starting worker discovery
00:55:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:55:52 DISPATCHER: Finished worker discovery
00:56:52 DISPATCHER: Starting worker discovery
00:56:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:56:52 DISPATCHER: Finished worker discovery
00:57:52 DISPATCHER: Starting worker discovery
00:57:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:57:52 DISPATCHER: Finished worker discovery
00:58:52 DISPATCHER: Starting worker discovery
00:58:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:58:52 DISPATCHER: Finished worker discovery
00:59:52 DISPATCHER: Starting worker discovery
00:59:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:59:52 DISPATCHER: Finished worker discovery
01:00:43 WORKER: done with job (6, 0, 3), trying to register it.
01:00:43 WORKER: registered result for job (6, 0, 3) with dispatcher
01:00:43 DISPATCHER: job (6, 0, 3) finished
01:00:43 DISPATCHER: register_result: lock acquired
01:00:43 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
01:00:43 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.08027311395889833, 'num_filters_1': 101, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.10268877762516153, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 17, 'num_filters_3': 45, 'num_filters_4': 44}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.00028291299019875607, 'info': {'data04': 0.00028291299019875607, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.08027311395889833, 'num_filters_1': 101, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.10268877762516153, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 17, 'num_filters_3': 45, 'num_filters_4': 44}"}}
exception: None

01:00:43 job_callback for (6, 0, 3) started
01:00:43 job_callback for (6, 0, 3) got condition
01:00:43 DISPATCHER: Trying to submit another job.
01:00:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:00:43 HBMASTER: Trying to run another job!
01:00:43 job_callback for (6, 0, 3) finished
01:00:43 start sampling a new configuration.
01:00:43 best_vector: [3, 0, 0.12137123342675193, 0.3990612583879487, 0.698013550822112, 1, 0.9897563396045735, 0.045289215919681186, 1, 2, 0, 1, 0.5800930870371112, 0.2108575450688529, 0.8780434091556286, 0.599332642531299], 2.205219850652716e-30, 0.004534695258180327, -2.86356824455045e-06
01:00:43 done sampling a new configuration.
01:00:43 HBMASTER: schedule new run for iteration 6
01:00:43 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
01:00:43 HBMASTER: submitting job (6, 0, 4) to dispatcher
01:00:43 DISPATCHER: trying to submit job (6, 0, 4)
01:00:43 DISPATCHER: trying to notify the job_runner thread.
01:00:43 HBMASTER: job (6, 0, 4) submitted to dispatcher
01:00:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:00:43 DISPATCHER: Trying to submit another job.
01:00:43 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:00:43 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:00:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:00:43 WORKER: start processing job (6, 0, 4)
01:00:43 WORKER: args: ()
01:00:43 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0017488093511617423, 'num_filters_1': 36, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.011453088810949369, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 53, 'num_filters_3': 24, 'num_filters_4': 99}, 'budget': 400.0, 'working_directory': '.'}
01:00:52 DISPATCHER: Starting worker discovery
01:00:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:00:52 DISPATCHER: Finished worker discovery
01:01:52 DISPATCHER: Starting worker discovery
01:01:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:01:52 DISPATCHER: Finished worker discovery
01:02:52 DISPATCHER: Starting worker discovery
01:02:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:02:52 DISPATCHER: Finished worker discovery
01:03:52 DISPATCHER: Starting worker discovery
01:03:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:03:52 DISPATCHER: Finished worker discovery
01:04:52 DISPATCHER: Starting worker discovery
01:04:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:04:52 DISPATCHER: Finished worker discovery
01:05:52 DISPATCHER: Starting worker discovery
01:05:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:05:52 DISPATCHER: Finished worker discovery
01:06:52 DISPATCHER: Starting worker discovery
01:06:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:06:52 DISPATCHER: Finished worker discovery
01:07:51 WORKER: done with job (6, 0, 4), trying to register it.
01:07:51 WORKER: registered result for job (6, 0, 4) with dispatcher
01:07:51 DISPATCHER: job (6, 0, 4) finished
01:07:51 DISPATCHER: register_result: lock acquired
01:07:51 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
01:07:51 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0017488093511617423, 'num_filters_1': 36, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.011453088810949369, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 53, 'num_filters_3': 24, 'num_filters_4': 99}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.1085421863086595, 'info': {'data04': 0.1085421863086595, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0017488093511617423, 'num_filters_1': 36, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.011453088810949369, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 53, 'num_filters_3': 24, 'num_filters_4': 99}"}}
exception: None

01:07:51 job_callback for (6, 0, 4) started
01:07:51 DISPATCHER: Trying to submit another job.
01:07:51 job_callback for (6, 0, 4) got condition
01:07:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:07:51 HBMASTER: Trying to run another job!
01:07:51 job_callback for (6, 0, 4) finished
01:07:51 start sampling a new configuration.
01:07:51 done sampling a new configuration.
01:07:51 HBMASTER: schedule new run for iteration 6
01:07:51 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
01:07:51 HBMASTER: submitting job (6, 0, 5) to dispatcher
01:07:51 DISPATCHER: trying to submit job (6, 0, 5)
01:07:51 DISPATCHER: trying to notify the job_runner thread.
01:07:51 HBMASTER: job (6, 0, 5) submitted to dispatcher
01:07:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:07:51 DISPATCHER: Trying to submit another job.
01:07:51 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:07:51 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:07:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:07:51 WORKER: start processing job (6, 0, 5)
01:07:51 WORKER: args: ()
01:07:51 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004165030199243478, 'num_filters_1': 70, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.10628740740986697, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 27, 'num_filters_3': 18}, 'budget': 400.0, 'working_directory': '.'}
01:07:52 DISPATCHER: Starting worker discovery
01:07:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:07:52 DISPATCHER: Finished worker discovery
01:08:52 DISPATCHER: Starting worker discovery
01:08:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:08:52 DISPATCHER: Finished worker discovery
01:09:52 DISPATCHER: Starting worker discovery
01:09:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:09:52 DISPATCHER: Finished worker discovery
01:10:52 DISPATCHER: Starting worker discovery
01:10:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:10:52 DISPATCHER: Finished worker discovery
01:11:52 DISPATCHER: Starting worker discovery
01:11:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:11:52 DISPATCHER: Finished worker discovery
01:12:52 DISPATCHER: Starting worker discovery
01:12:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:12:52 DISPATCHER: Finished worker discovery
01:13:52 DISPATCHER: Starting worker discovery
01:13:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:13:52 DISPATCHER: Finished worker discovery
01:14:52 DISPATCHER: Starting worker discovery
01:14:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:14:53 DISPATCHER: Finished worker discovery
01:15:13 WORKER: done with job (6, 0, 5), trying to register it.
01:15:13 WORKER: registered result for job (6, 0, 5) with dispatcher
01:15:13 DISPATCHER: job (6, 0, 5) finished
01:15:13 DISPATCHER: register_result: lock acquired
01:15:13 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
01:15:13 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004165030199243478, 'num_filters_1': 70, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.10628740740986697, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 27, 'num_filters_3': 18}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.010425172824103117, 'info': {'data04': 0.010425172824103117, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004165030199243478, 'num_filters_1': 70, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.10628740740986697, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 27, 'num_filters_3': 18}"}}
exception: None

01:15:13 job_callback for (6, 0, 5) started
01:15:13 job_callback for (6, 0, 5) got condition
01:15:13 DISPATCHER: Trying to submit another job.
01:15:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:15:13 HBMASTER: Trying to run another job!
01:15:13 job_callback for (6, 0, 5) finished
01:15:13 ITERATION: Advancing config (6, 0, 0) to next budget 1200.000000
01:15:13 ITERATION: Advancing config (6, 0, 4) to next budget 1200.000000
01:15:13 HBMASTER: schedule new run for iteration 6
01:15:13 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
01:15:13 HBMASTER: submitting job (6, 0, 0) to dispatcher
01:15:13 DISPATCHER: trying to submit job (6, 0, 0)
01:15:13 DISPATCHER: trying to notify the job_runner thread.
01:15:13 HBMASTER: job (6, 0, 0) submitted to dispatcher
01:15:13 DISPATCHER: Trying to submit another job.
01:15:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:15:13 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:15:13 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:15:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:15:13 WORKER: start processing job (6, 0, 0)
01:15:13 WORKER: args: ()
01:15:13 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0013221303875406679, 'num_filters_1': 25, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.016094639958163303, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 21, 'num_filters_3': 19, 'num_filters_4': 18}, 'budget': 1200.0, 'working_directory': '.'}
01:15:53 DISPATCHER: Starting worker discovery
01:15:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:15:53 DISPATCHER: Finished worker discovery
01:16:53 DISPATCHER: Starting worker discovery
01:16:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:16:53 DISPATCHER: Finished worker discovery
01:17:53 DISPATCHER: Starting worker discovery
01:17:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:17:53 DISPATCHER: Finished worker discovery
01:18:53 DISPATCHER: Starting worker discovery
01:18:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:18:53 DISPATCHER: Finished worker discovery
01:19:53 DISPATCHER: Starting worker discovery
01:19:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:19:53 DISPATCHER: Finished worker discovery
01:20:53 DISPATCHER: Starting worker discovery
01:20:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:20:53 DISPATCHER: Finished worker discovery
01:21:53 DISPATCHER: Starting worker discovery
01:21:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:21:53 DISPATCHER: Finished worker discovery
01:22:53 DISPATCHER: Starting worker discovery
01:22:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:22:53 DISPATCHER: Finished worker discovery
01:23:53 DISPATCHER: Starting worker discovery
01:23:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:23:53 DISPATCHER: Finished worker discovery
01:24:53 DISPATCHER: Starting worker discovery
01:24:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:24:53 DISPATCHER: Finished worker discovery
01:25:53 DISPATCHER: Starting worker discovery
01:25:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:25:53 DISPATCHER: Finished worker discovery
01:26:53 DISPATCHER: Starting worker discovery
01:26:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:26:53 DISPATCHER: Finished worker discovery
01:27:53 DISPATCHER: Starting worker discovery
01:27:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:27:53 DISPATCHER: Finished worker discovery
01:28:53 DISPATCHER: Starting worker discovery
01:28:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:28:53 DISPATCHER: Finished worker discovery
01:29:53 DISPATCHER: Starting worker discovery
01:29:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:29:53 DISPATCHER: Finished worker discovery
01:30:53 DISPATCHER: Starting worker discovery
01:30:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:30:53 DISPATCHER: Finished worker discovery
01:31:53 DISPATCHER: Starting worker discovery
01:31:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:31:53 DISPATCHER: Finished worker discovery
01:32:53 DISPATCHER: Starting worker discovery
01:32:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:32:53 DISPATCHER: Finished worker discovery
01:33:53 DISPATCHER: Starting worker discovery
01:33:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:33:53 DISPATCHER: Finished worker discovery
01:34:53 DISPATCHER: Starting worker discovery
01:34:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:34:53 DISPATCHER: Finished worker discovery
01:35:53 DISPATCHER: Starting worker discovery
01:35:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:35:53 DISPATCHER: Finished worker discovery
01:36:22 WORKER: done with job (6, 0, 0), trying to register it.
01:36:22 WORKER: registered result for job (6, 0, 0) with dispatcher
01:36:22 DISPATCHER: job (6, 0, 0) finished
01:36:22 DISPATCHER: register_result: lock acquired
01:36:22 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
01:36:22 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0013221303875406679, 'num_filters_1': 25, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.016094639958163303, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 21, 'num_filters_3': 19, 'num_filters_4': 18}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.04943080442521304, 'info': {'data04': 0.04943080442521304, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0013221303875406679, 'num_filters_1': 25, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.016094639958163303, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 21, 'num_filters_3': 19, 'num_filters_4': 18}"}}
exception: None

01:36:22 job_callback for (6, 0, 0) started
01:36:22 job_callback for (6, 0, 0) got condition
01:36:22 DISPATCHER: Trying to submit another job.
01:36:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:36:22 Only 11 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
01:36:22 HBMASTER: Trying to run another job!
01:36:22 job_callback for (6, 0, 0) finished
01:36:22 HBMASTER: schedule new run for iteration 6
01:36:22 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
01:36:22 HBMASTER: submitting job (6, 0, 4) to dispatcher
01:36:22 DISPATCHER: trying to submit job (6, 0, 4)
01:36:22 DISPATCHER: trying to notify the job_runner thread.
01:36:22 HBMASTER: job (6, 0, 4) submitted to dispatcher
01:36:22 DISPATCHER: Trying to submit another job.
01:36:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:36:22 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:36:22 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:36:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:36:22 WORKER: start processing job (6, 0, 4)
01:36:22 WORKER: args: ()
01:36:22 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0017488093511617423, 'num_filters_1': 36, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.011453088810949369, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 53, 'num_filters_3': 24, 'num_filters_4': 99}, 'budget': 1200.0, 'working_directory': '.'}
01:36:53 DISPATCHER: Starting worker discovery
01:36:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:36:53 DISPATCHER: Finished worker discovery
01:37:53 DISPATCHER: Starting worker discovery
01:37:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:37:53 DISPATCHER: Finished worker discovery
01:38:53 DISPATCHER: Starting worker discovery
01:38:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:38:53 DISPATCHER: Finished worker discovery
01:39:53 DISPATCHER: Starting worker discovery
01:39:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:39:53 DISPATCHER: Finished worker discovery
01:40:53 DISPATCHER: Starting worker discovery
01:40:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:40:53 DISPATCHER: Finished worker discovery
01:41:53 DISPATCHER: Starting worker discovery
01:41:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:41:53 DISPATCHER: Finished worker discovery
01:42:53 DISPATCHER: Starting worker discovery
01:42:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:42:53 DISPATCHER: Finished worker discovery
01:43:53 DISPATCHER: Starting worker discovery
01:43:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:43:53 DISPATCHER: Finished worker discovery
01:44:53 DISPATCHER: Starting worker discovery
01:44:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:44:53 DISPATCHER: Finished worker discovery
01:45:53 DISPATCHER: Starting worker discovery
01:45:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:45:53 DISPATCHER: Finished worker discovery
01:46:53 DISPATCHER: Starting worker discovery
01:46:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:46:53 DISPATCHER: Finished worker discovery
01:47:53 DISPATCHER: Starting worker discovery
01:47:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:47:53 DISPATCHER: Finished worker discovery
01:48:53 DISPATCHER: Starting worker discovery
01:48:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:48:53 DISPATCHER: Finished worker discovery
01:49:53 DISPATCHER: Starting worker discovery
01:49:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:49:53 DISPATCHER: Finished worker discovery
01:50:53 DISPATCHER: Starting worker discovery
01:50:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:50:53 DISPATCHER: Finished worker discovery
01:51:53 DISPATCHER: Starting worker discovery
01:51:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:51:53 DISPATCHER: Finished worker discovery
01:52:53 DISPATCHER: Starting worker discovery
01:52:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:52:53 DISPATCHER: Finished worker discovery
01:53:53 DISPATCHER: Starting worker discovery
01:53:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:53:53 DISPATCHER: Finished worker discovery
01:54:53 DISPATCHER: Starting worker discovery
01:54:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:54:53 DISPATCHER: Finished worker discovery
01:55:53 DISPATCHER: Starting worker discovery
01:55:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:55:53 DISPATCHER: Finished worker discovery
01:56:53 DISPATCHER: Starting worker discovery
01:56:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:56:53 DISPATCHER: Finished worker discovery
01:57:11 WORKER: done with job (6, 0, 4), trying to register it.
01:57:11 WORKER: registered result for job (6, 0, 4) with dispatcher
01:57:11 DISPATCHER: job (6, 0, 4) finished
01:57:11 DISPATCHER: register_result: lock acquired
01:57:11 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
01:57:11 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0017488093511617423, 'num_filters_1': 36, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.011453088810949369, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 53, 'num_filters_3': 24, 'num_filters_4': 99}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.11702237764933582, 'info': {'data04': 0.11702237764933582, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0017488093511617423, 'num_filters_1': 36, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.011453088810949369, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 53, 'num_filters_3': 24, 'num_filters_4': 99}"}}
exception: None

01:57:11 job_callback for (6, 0, 4) started
01:57:11 job_callback for (6, 0, 4) got condition
01:57:11 DISPATCHER: Trying to submit another job.
01:57:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:57:11 Only 12 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
01:57:11 HBMASTER: Trying to run another job!
01:57:11 job_callback for (6, 0, 4) finished
01:57:11 start sampling a new configuration.
01:57:11 best_vector: [3, 2, 0.16827476535013405, 0.4401667694257293, 0.2790423779429663, 1, 0.7926427871133093, 0.496894064908979, 0, 0, 0, 0, 0.30921609370466496, 0.8310172827490528, 0.6962342344675365, 0.7032395659964398], 3.9941256669755515e-30, 0.0025036768579122454, -4.835603063845931e-05
01:57:11 done sampling a new configuration.
01:57:11 HBMASTER: schedule new run for iteration 7
01:57:11 HBMASTER: trying submitting job (7, 0, 0) to dispatcher
01:57:11 HBMASTER: submitting job (7, 0, 0) to dispatcher
01:57:11 DISPATCHER: trying to submit job (7, 0, 0)
01:57:11 DISPATCHER: trying to notify the job_runner thread.
01:57:11 HBMASTER: job (7, 0, 0) submitted to dispatcher
01:57:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:57:11 DISPATCHER: Trying to submit another job.
01:57:11 DISPATCHER: starting job (7, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:57:11 DISPATCHER: job (7, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
01:57:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:57:11 WORKER: start processing job (7, 0, 0)
01:57:11 WORKER: args: ()
01:57:11 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0021704487262049123, 'num_filters_1': 39, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.04430717730221554, 'kernel_size_2': 3, 'num_filters_2': 30}, 'budget': 1200.0, 'working_directory': '.'}
01:57:53 DISPATCHER: Starting worker discovery
01:57:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:57:53 DISPATCHER: Finished worker discovery
01:58:53 DISPATCHER: Starting worker discovery
01:58:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:58:53 DISPATCHER: Finished worker discovery
01:59:53 DISPATCHER: Starting worker discovery
01:59:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:59:53 DISPATCHER: Finished worker discovery
02:00:53 DISPATCHER: Starting worker discovery
02:00:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:00:53 DISPATCHER: Finished worker discovery
02:01:53 DISPATCHER: Starting worker discovery
02:01:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:01:53 DISPATCHER: Finished worker discovery
02:02:53 DISPATCHER: Starting worker discovery
02:02:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:02:53 DISPATCHER: Finished worker discovery
02:03:53 DISPATCHER: Starting worker discovery
02:03:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:03:54 DISPATCHER: Finished worker discovery
02:04:54 DISPATCHER: Starting worker discovery
02:04:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:04:54 DISPATCHER: Finished worker discovery
02:05:54 DISPATCHER: Starting worker discovery
02:05:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:05:54 DISPATCHER: Finished worker discovery
02:06:54 DISPATCHER: Starting worker discovery
02:06:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:06:54 DISPATCHER: Finished worker discovery
02:07:54 DISPATCHER: Starting worker discovery
02:07:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:07:54 DISPATCHER: Finished worker discovery
02:08:54 DISPATCHER: Starting worker discovery
02:08:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:08:54 DISPATCHER: Finished worker discovery
02:09:54 DISPATCHER: Starting worker discovery
02:09:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:09:54 DISPATCHER: Finished worker discovery
02:10:54 DISPATCHER: Starting worker discovery
02:10:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:10:54 DISPATCHER: Finished worker discovery
02:11:54 DISPATCHER: Starting worker discovery
02:11:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:11:54 DISPATCHER: Finished worker discovery
02:12:54 DISPATCHER: Starting worker discovery
02:12:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:12:54 DISPATCHER: Finished worker discovery
02:13:54 DISPATCHER: Starting worker discovery
02:13:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:13:54 DISPATCHER: Finished worker discovery
02:14:54 DISPATCHER: Starting worker discovery
02:14:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:14:54 DISPATCHER: Finished worker discovery
02:15:54 DISPATCHER: Starting worker discovery
02:15:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:15:54 DISPATCHER: Finished worker discovery
02:16:54 DISPATCHER: Starting worker discovery
02:16:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:16:54 DISPATCHER: Finished worker discovery
02:17:54 DISPATCHER: Starting worker discovery
02:17:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:17:54 DISPATCHER: Finished worker discovery
02:18:22 WORKER: done with job (7, 0, 0), trying to register it.
02:18:22 WORKER: registered result for job (7, 0, 0) with dispatcher
02:18:22 DISPATCHER: job (7, 0, 0) finished
02:18:22 DISPATCHER: register_result: lock acquired
02:18:22 DISPATCHER: job (7, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
02:18:22 job_id: (7, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0021704487262049123, 'num_filters_1': 39, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.04430717730221554, 'kernel_size_2': 3, 'num_filters_2': 30}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.055768540948261655, 'info': {'data04': 0.055768540948261655, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0021704487262049123, 'num_filters_1': 39, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.04430717730221554, 'kernel_size_2': 3, 'num_filters_2': 30}"}}
exception: None

02:18:22 job_callback for (7, 0, 0) started
02:18:22 job_callback for (7, 0, 0) got condition
02:18:22 DISPATCHER: Trying to submit another job.
02:18:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:18:22 Only 13 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
02:18:22 HBMASTER: Trying to run another job!
02:18:22 job_callback for (7, 0, 0) finished
02:18:22 start sampling a new configuration.
02:18:22 done sampling a new configuration.
02:18:22 HBMASTER: schedule new run for iteration 7
02:18:22 HBMASTER: trying submitting job (7, 0, 1) to dispatcher
02:18:22 HBMASTER: submitting job (7, 0, 1) to dispatcher
02:18:22 DISPATCHER: trying to submit job (7, 0, 1)
02:18:22 DISPATCHER: trying to notify the job_runner thread.
02:18:22 HBMASTER: job (7, 0, 1) submitted to dispatcher
02:18:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:18:22 DISPATCHER: Trying to submit another job.
02:18:22 DISPATCHER: starting job (7, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
02:18:22 DISPATCHER: job (7, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
02:18:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:18:22 WORKER: start processing job (7, 0, 1)
02:18:22 WORKER: args: ()
02:18:22 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0341013234461251, 'num_filters_1': 101, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.0799596071963417, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 95, 'num_filters_3': 59}, 'budget': 1200.0, 'working_directory': '.'}
02:18:54 DISPATCHER: Starting worker discovery
02:18:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:18:54 DISPATCHER: Finished worker discovery
02:19:54 DISPATCHER: Starting worker discovery
02:19:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:19:54 DISPATCHER: Finished worker discovery
02:20:54 DISPATCHER: Starting worker discovery
02:20:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:20:54 DISPATCHER: Finished worker discovery
02:21:54 DISPATCHER: Starting worker discovery
02:21:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:21:54 DISPATCHER: Finished worker discovery
02:22:54 DISPATCHER: Starting worker discovery
02:22:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:22:54 DISPATCHER: Finished worker discovery
02:23:54 DISPATCHER: Starting worker discovery
02:23:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:23:54 DISPATCHER: Finished worker discovery
02:24:54 DISPATCHER: Starting worker discovery
02:24:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:24:54 DISPATCHER: Finished worker discovery
02:25:54 DISPATCHER: Starting worker discovery
02:25:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:25:54 DISPATCHER: Finished worker discovery
02:26:54 DISPATCHER: Starting worker discovery
02:26:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:26:54 DISPATCHER: Finished worker discovery
02:27:54 DISPATCHER: Starting worker discovery
02:27:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:27:54 DISPATCHER: Finished worker discovery
02:28:54 DISPATCHER: Starting worker discovery
02:28:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:28:54 DISPATCHER: Finished worker discovery
02:29:54 DISPATCHER: Starting worker discovery
02:29:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:29:54 DISPATCHER: Finished worker discovery
02:30:54 DISPATCHER: Starting worker discovery
02:30:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:30:54 DISPATCHER: Finished worker discovery
02:31:54 DISPATCHER: Starting worker discovery
02:31:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:31:54 DISPATCHER: Finished worker discovery
02:32:54 DISPATCHER: Starting worker discovery
02:32:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:32:54 DISPATCHER: Finished worker discovery
02:33:54 DISPATCHER: Starting worker discovery
02:33:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:33:54 DISPATCHER: Finished worker discovery
02:34:54 DISPATCHER: Starting worker discovery
02:34:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:34:54 DISPATCHER: Finished worker discovery
02:35:54 DISPATCHER: Starting worker discovery
02:35:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:35:54 DISPATCHER: Finished worker discovery
02:36:54 DISPATCHER: Starting worker discovery
02:36:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:36:54 DISPATCHER: Finished worker discovery
02:37:54 DISPATCHER: Starting worker discovery
02:37:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:37:54 DISPATCHER: Finished worker discovery
02:38:54 DISPATCHER: Starting worker discovery
02:38:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:38:54 DISPATCHER: Finished worker discovery
02:39:20 WORKER: done with job (7, 0, 1), trying to register it.
02:39:20 WORKER: registered result for job (7, 0, 1) with dispatcher
02:39:20 DISPATCHER: job (7, 0, 1) finished
02:39:20 DISPATCHER: register_result: lock acquired
02:39:20 DISPATCHER: job (7, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
02:39:20 job_id: (7, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0341013234461251, 'num_filters_1': 101, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.0799596071963417, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 95, 'num_filters_3': 59}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0035129341136268667, 'info': {'data04': 0.0035129341136268667, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0341013234461251, 'num_filters_1': 101, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.0799596071963417, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 95, 'num_filters_3': 59}"}}
exception: None

02:39:20 job_callback for (7, 0, 1) started
02:39:20 job_callback for (7, 0, 1) got condition
02:39:20 DISPATCHER: Trying to submit another job.
02:39:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:39:20 Only 14 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
02:39:20 HBMASTER: Trying to run another job!
02:39:20 job_callback for (7, 0, 1) finished
02:39:20 start sampling a new configuration.
02:39:20 done sampling a new configuration.
02:39:20 HBMASTER: schedule new run for iteration 7
02:39:20 HBMASTER: trying submitting job (7, 0, 2) to dispatcher
02:39:20 HBMASTER: submitting job (7, 0, 2) to dispatcher
02:39:20 DISPATCHER: trying to submit job (7, 0, 2)
02:39:20 DISPATCHER: trying to notify the job_runner thread.
02:39:20 HBMASTER: job (7, 0, 2) submitted to dispatcher
02:39:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:39:20 DISPATCHER: Trying to submit another job.
02:39:20 DISPATCHER: starting job (7, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
02:39:20 DISPATCHER: job (7, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
02:39:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:39:20 WORKER: start processing job (7, 0, 2)
02:39:20 WORKER: args: ()
02:39:20 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.09354004556388824, 'num_filters_1': 70, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.01088326589085555, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 75, 'num_filters_3': 41}, 'budget': 1200.0, 'working_directory': '.'}
02:39:54 DISPATCHER: Starting worker discovery
02:39:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:39:54 DISPATCHER: Finished worker discovery
02:40:54 DISPATCHER: Starting worker discovery
02:40:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:40:54 DISPATCHER: Finished worker discovery
02:41:54 DISPATCHER: Starting worker discovery
02:41:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:41:54 DISPATCHER: Finished worker discovery
02:42:54 DISPATCHER: Starting worker discovery
02:42:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:42:54 DISPATCHER: Finished worker discovery
02:43:54 DISPATCHER: Starting worker discovery
02:43:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:43:54 DISPATCHER: Finished worker discovery
02:44:54 DISPATCHER: Starting worker discovery
02:44:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:44:54 DISPATCHER: Finished worker discovery
02:45:54 DISPATCHER: Starting worker discovery
02:45:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:45:54 DISPATCHER: Finished worker discovery
02:46:54 DISPATCHER: Starting worker discovery
02:46:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:46:54 DISPATCHER: Finished worker discovery
02:47:54 DISPATCHER: Starting worker discovery
02:47:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:47:54 DISPATCHER: Finished worker discovery
02:48:54 DISPATCHER: Starting worker discovery
02:48:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:48:54 DISPATCHER: Finished worker discovery
02:49:54 DISPATCHER: Starting worker discovery
02:49:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:49:54 DISPATCHER: Finished worker discovery
02:50:55 DISPATCHER: Starting worker discovery
02:50:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:50:55 DISPATCHER: Finished worker discovery
02:51:55 DISPATCHER: Starting worker discovery
02:51:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:51:55 DISPATCHER: Finished worker discovery
02:52:55 DISPATCHER: Starting worker discovery
02:52:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:52:55 DISPATCHER: Finished worker discovery
02:53:55 DISPATCHER: Starting worker discovery
02:53:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:53:55 DISPATCHER: Finished worker discovery
02:54:55 DISPATCHER: Starting worker discovery
02:54:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:54:55 DISPATCHER: Finished worker discovery
02:55:55 DISPATCHER: Starting worker discovery
02:55:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:55:55 DISPATCHER: Finished worker discovery
02:56:55 DISPATCHER: Starting worker discovery
02:56:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:56:55 DISPATCHER: Finished worker discovery
02:57:55 DISPATCHER: Starting worker discovery
02:57:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:57:55 DISPATCHER: Finished worker discovery
02:58:55 DISPATCHER: Starting worker discovery
02:58:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:58:55 DISPATCHER: Finished worker discovery
02:59:55 DISPATCHER: Starting worker discovery
02:59:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:59:55 DISPATCHER: Finished worker discovery
03:00:16 WORKER: done with job (7, 0, 2), trying to register it.
03:00:16 WORKER: registered result for job (7, 0, 2) with dispatcher
03:00:16 DISPATCHER: job (7, 0, 2) finished
03:00:16 DISPATCHER: register_result: lock acquired
03:00:16 DISPATCHER: job (7, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:00:16 job_id: (7, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.09354004556388824, 'num_filters_1': 70, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.01088326589085555, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 75, 'num_filters_3': 41}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.04464334041672504, 'info': {'data04': 0.04464334041672504, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.09354004556388824, 'num_filters_1': 70, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.01088326589085555, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 75, 'num_filters_3': 41}"}}
exception: None

03:00:16 job_callback for (7, 0, 2) started
03:00:16 DISPATCHER: Trying to submit another job.
03:00:16 job_callback for (7, 0, 2) got condition
03:00:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:00:16 Only 15 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
03:00:16 HBMASTER: Trying to run another job!
03:00:16 job_callback for (7, 0, 2) finished
03:00:16 start sampling a new configuration.
03:00:16 done sampling a new configuration.
03:00:16 HBMASTER: schedule new run for iteration 7
03:00:16 HBMASTER: trying submitting job (7, 0, 3) to dispatcher
03:00:16 HBMASTER: submitting job (7, 0, 3) to dispatcher
03:00:16 DISPATCHER: trying to submit job (7, 0, 3)
03:00:16 DISPATCHER: trying to notify the job_runner thread.
03:00:16 HBMASTER: job (7, 0, 3) submitted to dispatcher
03:00:16 DISPATCHER: Trying to submit another job.
03:00:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:00:16 DISPATCHER: starting job (7, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:00:16 DISPATCHER: job (7, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:00:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:00:16 WORKER: start processing job (7, 0, 3)
03:00:16 WORKER: args: ()
03:00:16 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.010551245364920449, 'num_filters_1': 46, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.10439270220842269, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 103, 'num_filters_3': 76, 'num_filters_4': 49}, 'budget': 1200.0, 'working_directory': '.'}
03:00:55 DISPATCHER: Starting worker discovery
03:00:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:00:55 DISPATCHER: Finished worker discovery
03:01:55 DISPATCHER: Starting worker discovery
03:01:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:01:55 DISPATCHER: Finished worker discovery
03:02:55 DISPATCHER: Starting worker discovery
03:02:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:02:55 DISPATCHER: Finished worker discovery
03:03:55 DISPATCHER: Starting worker discovery
03:03:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:03:55 DISPATCHER: Finished worker discovery
03:04:55 DISPATCHER: Starting worker discovery
03:04:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:04:55 DISPATCHER: Finished worker discovery
03:05:55 DISPATCHER: Starting worker discovery
03:05:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:05:55 DISPATCHER: Finished worker discovery
03:06:55 DISPATCHER: Starting worker discovery
03:06:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:06:55 DISPATCHER: Finished worker discovery
03:07:55 DISPATCHER: Starting worker discovery
03:07:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:07:55 DISPATCHER: Finished worker discovery
03:08:55 DISPATCHER: Starting worker discovery
03:08:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:08:55 DISPATCHER: Finished worker discovery
03:09:55 DISPATCHER: Starting worker discovery
03:09:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:09:55 DISPATCHER: Finished worker discovery
03:10:55 DISPATCHER: Starting worker discovery
03:10:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:10:55 DISPATCHER: Finished worker discovery
03:11:55 DISPATCHER: Starting worker discovery
03:11:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:11:55 DISPATCHER: Finished worker discovery
03:12:55 DISPATCHER: Starting worker discovery
03:12:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:12:55 DISPATCHER: Finished worker discovery
03:13:55 DISPATCHER: Starting worker discovery
03:13:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:13:55 DISPATCHER: Finished worker discovery
03:14:55 DISPATCHER: Starting worker discovery
03:14:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:14:55 DISPATCHER: Finished worker discovery
03:15:55 DISPATCHER: Starting worker discovery
03:15:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:15:55 DISPATCHER: Finished worker discovery
03:16:55 DISPATCHER: Starting worker discovery
03:16:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:16:55 DISPATCHER: Finished worker discovery
03:17:55 DISPATCHER: Starting worker discovery
03:17:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:17:55 DISPATCHER: Finished worker discovery
03:18:55 DISPATCHER: Starting worker discovery
03:18:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:18:55 DISPATCHER: Finished worker discovery
03:19:55 DISPATCHER: Starting worker discovery
03:19:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:19:55 DISPATCHER: Finished worker discovery
03:20:55 DISPATCHER: Starting worker discovery
03:20:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:20:55 DISPATCHER: Finished worker discovery
03:21:09 WORKER: done with job (7, 0, 3), trying to register it.
03:21:09 WORKER: registered result for job (7, 0, 3) with dispatcher
03:21:09 DISPATCHER: job (7, 0, 3) finished
03:21:09 DISPATCHER: register_result: lock acquired
03:21:09 DISPATCHER: job (7, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:21:09 job_id: (7, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.010551245364920449, 'num_filters_1': 46, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.10439270220842269, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 103, 'num_filters_3': 76, 'num_filters_4': 49}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': 8.804121420596562e-09, 'info': {'data04': -8.804121420596562e-09, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.010551245364920449, 'num_filters_1': 46, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.10439270220842269, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 103, 'num_filters_3': 76, 'num_filters_4': 49}"}}
exception: None

03:21:09 job_callback for (7, 0, 3) started
03:21:09 job_callback for (7, 0, 3) got condition
03:21:09 DISPATCHER: Trying to submit another job.
03:21:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:21:09 Only 16 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
03:21:09 HBMASTER: Trying to run another job!
03:21:09 job_callback for (7, 0, 3) finished
03:21:09 start sampling a new configuration.
03:21:09 done sampling a new configuration.
03:21:09 HBMASTER: schedule new run for iteration 8
03:21:09 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
03:21:09 HBMASTER: submitting job (8, 0, 0) to dispatcher
03:21:09 DISPATCHER: trying to submit job (8, 0, 0)
03:21:09 DISPATCHER: trying to notify the job_runner thread.
03:21:09 HBMASTER: job (8, 0, 0) submitted to dispatcher
03:21:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:21:09 DISPATCHER: Trying to submit another job.
03:21:09 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:21:09 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:21:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:21:09 WORKER: start processing job (8, 0, 0)
03:21:09 WORKER: args: ()
03:21:09 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.01883933787937536, 'num_filters_1': 32, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.08047999212457921, 'kernel_size_2': 3, 'num_filters_2': 51}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:21:55 DISPATCHER: Starting worker discovery
03:21:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:21:55 DISPATCHER: Finished worker discovery
03:22:12 WORKER: done with job (8, 0, 0), trying to register it.
03:22:12 WORKER: registered result for job (8, 0, 0) with dispatcher
03:22:12 DISPATCHER: job (8, 0, 0) finished
03:22:12 DISPATCHER: register_result: lock acquired
03:22:12 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:22:12 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.01883933787937536, 'num_filters_1': 32, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.08047999212457921, 'kernel_size_2': 3, 'num_filters_2': 51}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.006181097725795359, 'info': {'data04': 0.006181097725795359, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.01883933787937536, 'num_filters_1': 32, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.08047999212457921, 'kernel_size_2': 3, 'num_filters_2': 51}"}}
exception: None

03:22:12 job_callback for (8, 0, 0) started
03:22:12 job_callback for (8, 0, 0) got condition
03:22:12 DISPATCHER: Trying to submit another job.
03:22:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:22:12 HBMASTER: Trying to run another job!
03:22:12 job_callback for (8, 0, 0) finished
03:22:12 start sampling a new configuration.
03:22:12 done sampling a new configuration.
03:22:12 HBMASTER: schedule new run for iteration 8
03:22:12 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
03:22:12 HBMASTER: submitting job (8, 0, 1) to dispatcher
03:22:12 DISPATCHER: trying to submit job (8, 0, 1)
03:22:12 DISPATCHER: trying to notify the job_runner thread.
03:22:12 HBMASTER: job (8, 0, 1) submitted to dispatcher
03:22:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:22:12 DISPATCHER: Trying to submit another job.
03:22:12 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:22:12 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:22:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:22:12 WORKER: start processing job (8, 0, 1)
03:22:12 WORKER: args: ()
03:22:12 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004661194507513357, 'num_filters_1': 26, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.015140424560289004}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:22:55 DISPATCHER: Starting worker discovery
03:22:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:22:55 DISPATCHER: Finished worker discovery
03:23:28 WORKER: done with job (8, 0, 1), trying to register it.
03:23:28 WORKER: registered result for job (8, 0, 1) with dispatcher
03:23:28 DISPATCHER: job (8, 0, 1) finished
03:23:28 DISPATCHER: register_result: lock acquired
03:23:28 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:23:28 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004661194507513357, 'num_filters_1': 26, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.015140424560289004}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1570217011355528, 'info': {'data04': 0.1570217011355528, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004661194507513357, 'num_filters_1': 26, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.015140424560289004}"}}
exception: None

03:23:28 job_callback for (8, 0, 1) started
03:23:28 DISPATCHER: Trying to submit another job.
03:23:28 job_callback for (8, 0, 1) got condition
03:23:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:23:28 HBMASTER: Trying to run another job!
03:23:28 job_callback for (8, 0, 1) finished
03:23:28 start sampling a new configuration.
03:23:28 done sampling a new configuration.
03:23:28 HBMASTER: schedule new run for iteration 8
03:23:28 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
03:23:28 HBMASTER: submitting job (8, 0, 2) to dispatcher
03:23:28 DISPATCHER: trying to submit job (8, 0, 2)
03:23:28 DISPATCHER: trying to notify the job_runner thread.
03:23:28 HBMASTER: job (8, 0, 2) submitted to dispatcher
03:23:28 DISPATCHER: Trying to submit another job.
03:23:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:23:28 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:23:28 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:23:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:23:28 WORKER: start processing job (8, 0, 2)
03:23:28 WORKER: args: ()
03:23:28 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.036224473552368464, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.1810088613431808, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 85, 'num_filters_3': 18, 'num_filters_4': 49, 'num_filters_5': 35}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:23:55 DISPATCHER: Starting worker discovery
03:23:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:23:55 DISPATCHER: Finished worker discovery
03:24:29 WORKER: done with job (8, 0, 2), trying to register it.
03:24:29 WORKER: registered result for job (8, 0, 2) with dispatcher
03:24:29 DISPATCHER: job (8, 0, 2) finished
03:24:29 DISPATCHER: register_result: lock acquired
03:24:29 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:24:29 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.036224473552368464, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.1810088613431808, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 85, 'num_filters_3': 18, 'num_filters_4': 49, 'num_filters_5': 35}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -4.1268957684454375e-05, 'info': {'data04': 4.1268957684454375e-05, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.036224473552368464, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.1810088613431808, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 85, 'num_filters_3': 18, 'num_filters_4': 49, 'num_filters_5': 35}"}}
exception: None

03:24:29 job_callback for (8, 0, 2) started
03:24:29 job_callback for (8, 0, 2) got condition
03:24:29 DISPATCHER: Trying to submit another job.
03:24:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:24:29 HBMASTER: Trying to run another job!
03:24:29 job_callback for (8, 0, 2) finished
03:24:29 start sampling a new configuration.
03:24:29 done sampling a new configuration.
03:24:29 HBMASTER: schedule new run for iteration 8
03:24:29 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
03:24:29 HBMASTER: submitting job (8, 0, 3) to dispatcher
03:24:29 DISPATCHER: trying to submit job (8, 0, 3)
03:24:29 DISPATCHER: trying to notify the job_runner thread.
03:24:29 HBMASTER: job (8, 0, 3) submitted to dispatcher
03:24:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:24:29 DISPATCHER: Trying to submit another job.
03:24:29 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:24:29 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:24:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:24:29 WORKER: start processing job (8, 0, 3)
03:24:29 WORKER: args: ()
03:24:29 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003981763364305226, 'num_filters_1': 117, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.011047446034494285, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 22, 'num_filters_3': 88}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:24:55 DISPATCHER: Starting worker discovery
03:24:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:24:55 DISPATCHER: Finished worker discovery
03:25:29 WORKER: done with job (8, 0, 3), trying to register it.
03:25:29 WORKER: registered result for job (8, 0, 3) with dispatcher
03:25:29 DISPATCHER: job (8, 0, 3) finished
03:25:29 DISPATCHER: register_result: lock acquired
03:25:29 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:25:29 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003981763364305226, 'num_filters_1': 117, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.011047446034494285, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 22, 'num_filters_3': 88}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.045693274398330576, 'info': {'data04': 0.045693274398330576, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003981763364305226, 'num_filters_1': 117, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.011047446034494285, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 22, 'num_filters_3': 88}"}}
exception: None

03:25:29 job_callback for (8, 0, 3) started
03:25:29 DISPATCHER: Trying to submit another job.
03:25:29 job_callback for (8, 0, 3) got condition
03:25:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:25:29 HBMASTER: Trying to run another job!
03:25:29 job_callback for (8, 0, 3) finished
03:25:29 start sampling a new configuration.
03:25:29 best_vector: [0, 2, 0.31715241643445846, 0.9195488690044054, 0.23499086944326775, 1, 0.2901426484825794, 0.10373199144244305, 0, 2, 0, 1, 0.625023457612955, 0.4133388178249566, 0.5742535704792372, 0.6188416723583748], 3.1494218973438263e-30, 0.003175185899492807, -8.037622282947127e-06
03:25:29 done sampling a new configuration.
03:25:29 HBMASTER: schedule new run for iteration 8
03:25:29 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
03:25:29 HBMASTER: submitting job (8, 0, 4) to dispatcher
03:25:29 DISPATCHER: trying to submit job (8, 0, 4)
03:25:29 DISPATCHER: trying to notify the job_runner thread.
03:25:29 HBMASTER: job (8, 0, 4) submitted to dispatcher
03:25:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:25:29 DISPATCHER: Trying to submit another job.
03:25:29 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:25:29 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:25:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:25:29 WORKER: start processing job (8, 0, 4)
03:25:29 WORKER: args: ()
03:25:29 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.004308289047563535, 'num_filters_1': 108, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.01364452534507017, 'kernel_size_2': 3, 'num_filters_2': 58}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:25:55 DISPATCHER: Starting worker discovery
03:25:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:25:55 DISPATCHER: Finished worker discovery
03:26:32 WORKER: done with job (8, 0, 4), trying to register it.
03:26:32 WORKER: registered result for job (8, 0, 4) with dispatcher
03:26:32 DISPATCHER: job (8, 0, 4) finished
03:26:32 DISPATCHER: register_result: lock acquired
03:26:32 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:26:32 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.004308289047563535, 'num_filters_1': 108, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.01364452534507017, 'kernel_size_2': 3, 'num_filters_2': 58}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1890533459157975, 'info': {'data04': 0.1890533459157975, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.004308289047563535, 'num_filters_1': 108, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.01364452534507017, 'kernel_size_2': 3, 'num_filters_2': 58}"}}
exception: None

03:26:32 job_callback for (8, 0, 4) started
03:26:32 DISPATCHER: Trying to submit another job.
03:26:32 job_callback for (8, 0, 4) got condition
03:26:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:26:32 HBMASTER: Trying to run another job!
03:26:32 job_callback for (8, 0, 4) finished
03:26:32 start sampling a new configuration.
03:26:32 best_vector: [1, 1, 0.16607222784285586, 0.9445921448942355, 0.6255255512257099, 1, 0.330123327943165, 0.9028824565220317, 1, 0, 2, 1, 0.6576494899732397, 0.6542978574543823, 0.44847548629127637, 0.7706368352323857], 1.3847463969163206e-27, 7.221538920244827e-06, -0.0006501754192349258
03:26:32 done sampling a new configuration.
03:26:32 HBMASTER: schedule new run for iteration 8
03:26:32 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
03:26:32 HBMASTER: submitting job (8, 0, 5) to dispatcher
03:26:32 DISPATCHER: trying to submit job (8, 0, 5)
03:26:32 DISPATCHER: trying to notify the job_runner thread.
03:26:32 HBMASTER: job (8, 0, 5) submitted to dispatcher
03:26:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:26:32 DISPATCHER: Trying to submit another job.
03:26:32 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:26:32 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:26:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:26:32 WORKER: start processing job (8, 0, 5)
03:26:32 WORKER: args: ()
03:26:32 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.002148545007570888, 'num_filters_1': 114, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.14951238126427974, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 62, 'num_filters_3': 62, 'num_filters_4': 40}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:26:55 DISPATCHER: Starting worker discovery
03:26:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:26:55 DISPATCHER: Finished worker discovery
03:27:34 WORKER: done with job (8, 0, 5), trying to register it.
03:27:34 WORKER: registered result for job (8, 0, 5) with dispatcher
03:27:34 DISPATCHER: job (8, 0, 5) finished
03:27:34 DISPATCHER: register_result: lock acquired
03:27:34 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:27:34 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.002148545007570888, 'num_filters_1': 114, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.14951238126427974, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 62, 'num_filters_3': 62, 'num_filters_4': 40}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.006640351446409406, 'info': {'data04': 0.006640351446409406, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.002148545007570888, 'num_filters_1': 114, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.14951238126427974, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 62, 'num_filters_3': 62, 'num_filters_4': 40}"}}
exception: None

03:27:34 job_callback for (8, 0, 5) started
03:27:34 job_callback for (8, 0, 5) got condition
03:27:34 DISPATCHER: Trying to submit another job.
03:27:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:27:34 HBMASTER: Trying to run another job!
03:27:34 job_callback for (8, 0, 5) finished
03:27:34 start sampling a new configuration.
03:27:34 best_vector: [3, 1, 0.42217224441949297, 0.5935238920078417, 0.5544395520974386, 1, 0.9138756404253033, 0.2177527607629685, 1, 0, 2, 1, 0.06002793349997639, 0.5115050237823967, 0.7578075246853825, 0.5650640064088306], 1.1013951535712875e-29, 0.0009079393501573778, -1.1516560283317821e-05
03:27:34 done sampling a new configuration.
03:27:34 HBMASTER: schedule new run for iteration 8
03:27:34 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
03:27:34 HBMASTER: submitting job (8, 0, 6) to dispatcher
03:27:34 DISPATCHER: trying to submit job (8, 0, 6)
03:27:34 DISPATCHER: trying to notify the job_runner thread.
03:27:34 HBMASTER: job (8, 0, 6) submitted to dispatcher
03:27:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:27:34 DISPATCHER: Trying to submit another job.
03:27:34 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:27:34 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:27:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:27:34 WORKER: start processing job (8, 0, 6)
03:27:34 WORKER: args: ()
03:27:34 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006987864721180082, 'num_filters_1': 54, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.01920007271117927, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 18, 'num_filters_3': 46}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:27:55 DISPATCHER: Starting worker discovery
03:27:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:27:55 DISPATCHER: Finished worker discovery
03:28:34 WORKER: done with job (8, 0, 6), trying to register it.
03:28:34 WORKER: registered result for job (8, 0, 6) with dispatcher
03:28:34 DISPATCHER: job (8, 0, 6) finished
03:28:34 DISPATCHER: register_result: lock acquired
03:28:34 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:28:34 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006987864721180082, 'num_filters_1': 54, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.01920007271117927, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 18, 'num_filters_3': 46}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.15598215185018266, 'info': {'data04': 0.15598215185018266, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006987864721180082, 'num_filters_1': 54, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.01920007271117927, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 18, 'num_filters_3': 46}"}}
exception: None

03:28:34 job_callback for (8, 0, 6) started
03:28:34 job_callback for (8, 0, 6) got condition
03:28:34 DISPATCHER: Trying to submit another job.
03:28:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:28:34 HBMASTER: Trying to run another job!
03:28:34 job_callback for (8, 0, 6) finished
03:28:34 start sampling a new configuration.
03:28:34 best_vector: [3, 2, 0.2071286290725072, 0.8203136000063513, 0.894319125851299, 1, 0.8852154134269598, 0.5418018687458792, 0, 1, 1, 1, 0.9320374048166944, 0.5513887330376578, 0.48344301385493216, 0.7271033353667566], 2.88793983751832e-29, 0.00034626760121821837, -9.499623628804846e-05
03:28:34 done sampling a new configuration.
03:28:34 HBMASTER: schedule new run for iteration 8
03:28:34 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
03:28:34 HBMASTER: submitting job (8, 0, 7) to dispatcher
03:28:34 DISPATCHER: trying to submit job (8, 0, 7)
03:28:34 DISPATCHER: trying to notify the job_runner thread.
03:28:34 HBMASTER: job (8, 0, 7) submitted to dispatcher
03:28:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:28:34 DISPATCHER: Trying to submit another job.
03:28:34 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:28:34 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:28:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:28:34 WORKER: start processing job (8, 0, 7)
03:28:34 WORKER: args: ()
03:28:34 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0025957165022385677, 'num_filters_1': 88, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.05068745464445541, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 111, 'num_filters_3': 50, 'num_filters_4': 43, 'num_filters_5': 72}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:28:55 DISPATCHER: Starting worker discovery
03:28:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:28:55 DISPATCHER: Finished worker discovery
03:29:36 WORKER: done with job (8, 0, 7), trying to register it.
03:29:36 WORKER: registered result for job (8, 0, 7) with dispatcher
03:29:36 DISPATCHER: job (8, 0, 7) finished
03:29:36 DISPATCHER: register_result: lock acquired
03:29:36 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:29:36 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0025957165022385677, 'num_filters_1': 88, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.05068745464445541, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 111, 'num_filters_3': 50, 'num_filters_4': 43, 'num_filters_5': 72}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.16153885449477307, 'info': {'data04': 0.16153885449477307, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0025957165022385677, 'num_filters_1': 88, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.05068745464445541, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 111, 'num_filters_3': 50, 'num_filters_4': 43, 'num_filters_5': 72}"}}
exception: None

03:29:36 job_callback for (8, 0, 7) started
03:29:36 job_callback for (8, 0, 7) got condition
03:29:36 DISPATCHER: Trying to submit another job.
03:29:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:29:36 HBMASTER: Trying to run another job!
03:29:36 job_callback for (8, 0, 7) finished
03:29:36 start sampling a new configuration.
03:29:36 done sampling a new configuration.
03:29:36 HBMASTER: schedule new run for iteration 8
03:29:36 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
03:29:36 HBMASTER: submitting job (8, 0, 8) to dispatcher
03:29:36 DISPATCHER: trying to submit job (8, 0, 8)
03:29:36 DISPATCHER: trying to notify the job_runner thread.
03:29:36 HBMASTER: job (8, 0, 8) submitted to dispatcher
03:29:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:29:36 DISPATCHER: Trying to submit another job.
03:29:36 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:29:36 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:29:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:29:36 WORKER: start processing job (8, 0, 8)
03:29:36 WORKER: args: ()
03:29:36 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0019164762053222116, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.1568280960108925, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 36, 'num_filters_3': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:29:55 DISPATCHER: Starting worker discovery
03:29:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:29:55 DISPATCHER: Finished worker discovery
03:30:38 WORKER: done with job (8, 0, 8), trying to register it.
03:30:38 WORKER: registered result for job (8, 0, 8) with dispatcher
03:30:38 DISPATCHER: job (8, 0, 8) finished
03:30:38 DISPATCHER: register_result: lock acquired
03:30:38 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:30:38 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0019164762053222116, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.1568280960108925, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 36, 'num_filters_3': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.032469494954186454, 'info': {'data04': 0.032469494954186454, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0019164762053222116, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.1568280960108925, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 36, 'num_filters_3': 18}"}}
exception: None

03:30:38 job_callback for (8, 0, 8) started
03:30:38 DISPATCHER: Trying to submit another job.
03:30:38 job_callback for (8, 0, 8) got condition
03:30:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:30:38 HBMASTER: Trying to run another job!
03:30:38 job_callback for (8, 0, 8) finished
03:30:38 start sampling a new configuration.
03:30:38 done sampling a new configuration.
03:30:38 HBMASTER: schedule new run for iteration 8
03:30:38 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
03:30:38 HBMASTER: submitting job (8, 0, 9) to dispatcher
03:30:38 DISPATCHER: trying to submit job (8, 0, 9)
03:30:38 DISPATCHER: trying to notify the job_runner thread.
03:30:38 HBMASTER: job (8, 0, 9) submitted to dispatcher
03:30:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:30:38 DISPATCHER: Trying to submit another job.
03:30:38 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:30:38 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:30:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:30:38 WORKER: start processing job (8, 0, 9)
03:30:38 WORKER: args: ()
03:30:38 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.03955646159439059, 'num_filters_1': 39, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.01704567740766604, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 22, 'num_filters_3': 45, 'num_filters_4': 62}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:30:55 DISPATCHER: Starting worker discovery
03:30:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:30:55 DISPATCHER: Finished worker discovery
03:31:46 WORKER: done with job (8, 0, 9), trying to register it.
03:31:46 WORKER: registered result for job (8, 0, 9) with dispatcher
03:31:46 DISPATCHER: job (8, 0, 9) finished
03:31:46 DISPATCHER: register_result: lock acquired
03:31:46 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:31:46 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.03955646159439059, 'num_filters_1': 39, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.01704567740766604, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 22, 'num_filters_3': 45, 'num_filters_4': 62}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.03955646159439059, 'num_filters_1': 39, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.01704567740766604, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 22, 'num_filters_3': 45, 'num_filters_4': 62}"}}
exception: None

03:31:46 job_callback for (8, 0, 9) started
03:31:46 job_callback for (8, 0, 9) got condition
03:31:46 DISPATCHER: Trying to submit another job.
03:31:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:31:46 HBMASTER: Trying to run another job!
03:31:46 job_callback for (8, 0, 9) finished
03:31:46 start sampling a new configuration.
03:31:46 done sampling a new configuration.
03:31:46 HBMASTER: schedule new run for iteration 8
03:31:46 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
03:31:46 HBMASTER: submitting job (8, 0, 10) to dispatcher
03:31:46 DISPATCHER: trying to submit job (8, 0, 10)
03:31:46 DISPATCHER: trying to notify the job_runner thread.
03:31:46 HBMASTER: job (8, 0, 10) submitted to dispatcher
03:31:46 DISPATCHER: Trying to submit another job.
03:31:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:31:46 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:31:46 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:31:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:31:46 WORKER: start processing job (8, 0, 10)
03:31:46 WORKER: args: ()
03:31:46 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.06645313228845028, 'num_filters_1': 53, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.018897472831609054, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 105, 'num_filters_3': 47, 'num_filters_4': 47, 'num_filters_5': 127}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:31:55 DISPATCHER: Starting worker discovery
03:31:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:31:55 DISPATCHER: Finished worker discovery
03:32:46 WORKER: done with job (8, 0, 10), trying to register it.
03:32:46 WORKER: registered result for job (8, 0, 10) with dispatcher
03:32:46 DISPATCHER: job (8, 0, 10) finished
03:32:46 DISPATCHER: register_result: lock acquired
03:32:46 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:32:46 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.06645313228845028, 'num_filters_1': 53, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.018897472831609054, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 105, 'num_filters_3': 47, 'num_filters_4': 47, 'num_filters_5': 127}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.06010878734072613, 'info': {'data04': 0.06010878734072613, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.06645313228845028, 'num_filters_1': 53, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.018897472831609054, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 105, 'num_filters_3': 47, 'num_filters_4': 47, 'num_filters_5': 127}"}}
exception: None

03:32:46 job_callback for (8, 0, 10) started
03:32:46 job_callback for (8, 0, 10) got condition
03:32:46 DISPATCHER: Trying to submit another job.
03:32:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:32:46 HBMASTER: Trying to run another job!
03:32:46 job_callback for (8, 0, 10) finished
03:32:46 start sampling a new configuration.
03:32:47 best_vector: [3, 1, 0.3527503545092009, 0.2063095927275982, 0.29848892225901935, 1, 0.11879956072511307, 0.07911667133566722, 1, 2, 0, 1, 0.5785675194853506, 0.44491096449409046, 0.021418665856017594, 0.5839660032736793], 3.687570882806894e-30, 0.0027118122790871567, -2.963893791103326e-05
03:32:47 done sampling a new configuration.
03:32:47 HBMASTER: schedule new run for iteration 8
03:32:47 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
03:32:47 HBMASTER: submitting job (8, 0, 11) to dispatcher
03:32:47 DISPATCHER: trying to submit job (8, 0, 11)
03:32:47 DISPATCHER: trying to notify the job_runner thread.
03:32:47 HBMASTER: job (8, 0, 11) submitted to dispatcher
03:32:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:32:47 DISPATCHER: Trying to submit another job.
03:32:47 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:32:47 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:32:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:32:47 WORKER: start processing job (8, 0, 11)
03:32:47 WORKER: args: ()
03:32:47 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0050757556768351066, 'num_filters_1': 24, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.01267456790664283, 'kernel_size_2': 5, 'num_filters_2': 53}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:32:55 DISPATCHER: Starting worker discovery
03:32:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:32:55 DISPATCHER: Finished worker discovery
03:33:53 WORKER: done with job (8, 0, 11), trying to register it.
03:33:53 WORKER: registered result for job (8, 0, 11) with dispatcher
03:33:53 DISPATCHER: job (8, 0, 11) finished
03:33:53 DISPATCHER: register_result: lock acquired
03:33:53 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:33:53 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0050757556768351066, 'num_filters_1': 24, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.01267456790664283, 'kernel_size_2': 5, 'num_filters_2': 53}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1626624196754289, 'info': {'data04': 0.1626624196754289, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0050757556768351066, 'num_filters_1': 24, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.01267456790664283, 'kernel_size_2': 5, 'num_filters_2': 53}"}}
exception: None

03:33:53 job_callback for (8, 0, 11) started
03:33:53 job_callback for (8, 0, 11) got condition
03:33:53 DISPATCHER: Trying to submit another job.
03:33:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:33:53 HBMASTER: Trying to run another job!
03:33:53 job_callback for (8, 0, 11) finished
03:33:53 start sampling a new configuration.
03:33:53 best_vector: [3, 0, 0.0006798772721904045, 0.959494159743699, 0.26677323850471035, 1, 0.8844232824645775, 0.20591735294517063, 2, 1, 0, 0, 0.767157439639392, 0.6221716894473063, 0.48836549568341237, 0.709237015455623], 2.829321082501579e-29, 0.0003534416811809276, -2.0726619455448285e-06
03:33:53 done sampling a new configuration.
03:33:53 HBMASTER: schedule new run for iteration 8
03:33:53 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
03:33:53 HBMASTER: submitting job (8, 0, 12) to dispatcher
03:33:53 DISPATCHER: trying to submit job (8, 0, 12)
03:33:53 DISPATCHER: trying to notify the job_runner thread.
03:33:53 HBMASTER: job (8, 0, 12) submitted to dispatcher
03:33:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:33:53 DISPATCHER: Trying to submit another job.
03:33:53 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:33:53 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:33:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:33:53 WORKER: start processing job (8, 0, 12)
03:33:53 WORKER: args: ()
03:33:53 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001003135857089057, 'num_filters_1': 118, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.018531247344448023, 'kernel_size_2': 7, 'num_filters_2': 79}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:33:55 DISPATCHER: Starting worker discovery
03:33:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:33:55 DISPATCHER: Finished worker discovery
03:34:53 WORKER: done with job (8, 0, 12), trying to register it.
03:34:53 WORKER: registered result for job (8, 0, 12) with dispatcher
03:34:53 DISPATCHER: job (8, 0, 12) finished
03:34:53 DISPATCHER: register_result: lock acquired
03:34:53 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:34:53 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001003135857089057, 'num_filters_1': 118, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.018531247344448023, 'kernel_size_2': 7, 'num_filters_2': 79}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1908336901490623, 'info': {'data04': 0.1908336901490623, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001003135857089057, 'num_filters_1': 118, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.018531247344448023, 'kernel_size_2': 7, 'num_filters_2': 79}"}}
exception: None

03:34:53 job_callback for (8, 0, 12) started
03:34:53 job_callback for (8, 0, 12) got condition
03:34:53 DISPATCHER: Trying to submit another job.
03:34:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:34:53 HBMASTER: Trying to run another job!
03:34:53 job_callback for (8, 0, 12) finished
03:34:53 start sampling a new configuration.
03:34:54 best_vector: [0, 1, 0.42258038950998805, 0.3221540095654024, 0.32033342563922657, 1, 0.6958311298961403, 0.0702535054609027, 1, 0, 2, 2, 0.7388454378540505, 0.9590333401041475, 0.28265913598253345, 0.7249418785208316], 3.596568223286578e-30, 0.0027804282802848953, -2.944986983037878e-06
03:34:54 done sampling a new configuration.
03:34:54 HBMASTER: schedule new run for iteration 8
03:34:54 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
03:34:54 HBMASTER: submitting job (8, 0, 13) to dispatcher
03:34:54 DISPATCHER: trying to submit job (8, 0, 13)
03:34:54 DISPATCHER: trying to notify the job_runner thread.
03:34:54 HBMASTER: job (8, 0, 13) submitted to dispatcher
03:34:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:34:54 DISPATCHER: Trying to submit another job.
03:34:54 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:34:54 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:34:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:34:54 WORKER: start processing job (8, 0, 13)
03:34:54 WORKER: args: ()
03:34:54 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.007001011306341091, 'num_filters_1': 31, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.012342465385293674, 'kernel_size_2': 5, 'num_filters_2': 74}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:34:55 DISPATCHER: Starting worker discovery
03:34:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:34:55 DISPATCHER: Finished worker discovery
03:35:54 WORKER: done with job (8, 0, 13), trying to register it.
03:35:54 WORKER: registered result for job (8, 0, 13) with dispatcher
03:35:54 DISPATCHER: job (8, 0, 13) finished
03:35:54 DISPATCHER: register_result: lock acquired
03:35:54 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:35:54 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.007001011306341091, 'num_filters_1': 31, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.012342465385293674, 'kernel_size_2': 5, 'num_filters_2': 74}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.147813009116718, 'info': {'data04': 0.147813009116718, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.007001011306341091, 'num_filters_1': 31, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.012342465385293674, 'kernel_size_2': 5, 'num_filters_2': 74}"}}
exception: None

03:35:54 job_callback for (8, 0, 13) started
03:35:54 DISPATCHER: Trying to submit another job.
03:35:54 job_callback for (8, 0, 13) got condition
03:35:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:35:54 HBMASTER: Trying to run another job!
03:35:54 job_callback for (8, 0, 13) finished
03:35:54 start sampling a new configuration.
03:35:54 done sampling a new configuration.
03:35:54 HBMASTER: schedule new run for iteration 8
03:35:54 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
03:35:54 HBMASTER: submitting job (8, 0, 14) to dispatcher
03:35:54 DISPATCHER: trying to submit job (8, 0, 14)
03:35:54 DISPATCHER: trying to notify the job_runner thread.
03:35:54 HBMASTER: job (8, 0, 14) submitted to dispatcher
03:35:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:35:54 DISPATCHER: Trying to submit another job.
03:35:54 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:35:54 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:35:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:35:54 WORKER: start processing job (8, 0, 14)
03:35:54 WORKER: args: ()
03:35:54 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.022081602092213565, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.018657875842030068, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 29, 'num_filters_3': 62, 'num_filters_4': 56}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:35:55 DISPATCHER: Starting worker discovery
03:35:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:35:55 DISPATCHER: Finished worker discovery
03:36:55 DISPATCHER: Starting worker discovery
03:36:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:36:56 DISPATCHER: Finished worker discovery
03:36:56 WORKER: done with job (8, 0, 14), trying to register it.
03:36:56 WORKER: registered result for job (8, 0, 14) with dispatcher
03:36:56 DISPATCHER: job (8, 0, 14) finished
03:36:56 DISPATCHER: register_result: lock acquired
03:36:56 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:36:56 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.022081602092213565, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.018657875842030068, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 29, 'num_filters_3': 62, 'num_filters_4': 56}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.022081602092213565, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.018657875842030068, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 29, 'num_filters_3': 62, 'num_filters_4': 56}"}}
exception: None

03:36:56 job_callback for (8, 0, 14) started
03:36:56 job_callback for (8, 0, 14) got condition
03:36:56 DISPATCHER: Trying to submit another job.
03:36:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:36:56 HBMASTER: Trying to run another job!
03:36:56 job_callback for (8, 0, 14) finished
03:36:56 start sampling a new configuration.
03:36:56 done sampling a new configuration.
03:36:56 HBMASTER: schedule new run for iteration 8
03:36:56 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
03:36:56 HBMASTER: submitting job (8, 0, 15) to dispatcher
03:36:56 DISPATCHER: trying to submit job (8, 0, 15)
03:36:56 DISPATCHER: trying to notify the job_runner thread.
03:36:56 HBMASTER: job (8, 0, 15) submitted to dispatcher
03:36:56 DISPATCHER: Trying to submit another job.
03:36:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:36:56 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:36:56 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:36:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:36:56 WORKER: start processing job (8, 0, 15)
03:36:56 WORKER: args: ()
03:36:56 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.001101628183396121, 'num_filters_1': 31, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.07429478865623527, 'kernel_size_2': 3, 'num_filters_2': 83}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:37:56 DISPATCHER: Starting worker discovery
03:37:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:37:56 DISPATCHER: Finished worker discovery
03:38:04 WORKER: done with job (8, 0, 15), trying to register it.
03:38:04 WORKER: registered result for job (8, 0, 15) with dispatcher
03:38:04 DISPATCHER: job (8, 0, 15) finished
03:38:04 DISPATCHER: register_result: lock acquired
03:38:04 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:38:04 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.001101628183396121, 'num_filters_1': 31, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.07429478865623527, 'kernel_size_2': 3, 'num_filters_2': 83}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.10422407000258332, 'info': {'data04': 0.10422407000258332, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.001101628183396121, 'num_filters_1': 31, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.07429478865623527, 'kernel_size_2': 3, 'num_filters_2': 83}"}}
exception: None

03:38:04 job_callback for (8, 0, 15) started
03:38:04 DISPATCHER: Trying to submit another job.
03:38:04 job_callback for (8, 0, 15) got condition
03:38:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:38:04 HBMASTER: Trying to run another job!
03:38:04 job_callback for (8, 0, 15) finished
03:38:04 start sampling a new configuration.
03:38:04 done sampling a new configuration.
03:38:04 HBMASTER: schedule new run for iteration 8
03:38:04 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
03:38:04 HBMASTER: submitting job (8, 0, 16) to dispatcher
03:38:04 DISPATCHER: trying to submit job (8, 0, 16)
03:38:04 DISPATCHER: trying to notify the job_runner thread.
03:38:04 HBMASTER: job (8, 0, 16) submitted to dispatcher
03:38:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:38:04 DISPATCHER: Trying to submit another job.
03:38:04 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:38:04 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:38:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:38:04 WORKER: start processing job (8, 0, 16)
03:38:04 WORKER: args: ()
03:38:04 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.005857208589938508, 'num_filters_1': 49, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.10478947729694126, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 27, 'num_filters_3': 20, 'num_filters_4': 21, 'num_filters_5': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:38:56 DISPATCHER: Starting worker discovery
03:38:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:38:56 DISPATCHER: Finished worker discovery
03:39:04 WORKER: done with job (8, 0, 16), trying to register it.
03:39:04 WORKER: registered result for job (8, 0, 16) with dispatcher
03:39:04 DISPATCHER: job (8, 0, 16) finished
03:39:04 DISPATCHER: register_result: lock acquired
03:39:04 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:39:04 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.005857208589938508, 'num_filters_1': 49, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.10478947729694126, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 27, 'num_filters_3': 20, 'num_filters_4': 21, 'num_filters_5': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.005857208589938508, 'num_filters_1': 49, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.10478947729694126, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 27, 'num_filters_3': 20, 'num_filters_4': 21, 'num_filters_5': 20}"}}
exception: None

03:39:04 job_callback for (8, 0, 16) started
03:39:04 job_callback for (8, 0, 16) got condition
03:39:04 DISPATCHER: Trying to submit another job.
03:39:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:39:04 HBMASTER: Trying to run another job!
03:39:04 job_callback for (8, 0, 16) finished
03:39:04 start sampling a new configuration.
03:39:04 best_vector: [0, 1, 0.057444146696468856, 0.1687466161584994, 0.029997420460303736, 1, 0.9391451502804364, 0.23467877956251953, 0, 1, 2, 0, 0.5288758329335752, 0.12844777480962907, 0.5257400753559061, 0.6403549901147819], 2.1344842565058865e-29, 0.0004684972479661118, -1.8268653367496413e-05
03:39:04 done sampling a new configuration.
03:39:04 HBMASTER: schedule new run for iteration 8
03:39:04 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
03:39:04 HBMASTER: submitting job (8, 0, 17) to dispatcher
03:39:04 DISPATCHER: trying to submit job (8, 0, 17)
03:39:04 DISPATCHER: trying to notify the job_runner thread.
03:39:04 HBMASTER: job (8, 0, 17) submitted to dispatcher
03:39:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:39:04 DISPATCHER: Trying to submit another job.
03:39:04 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:39:04 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:39:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:39:04 WORKER: start processing job (8, 0, 17)
03:39:04 WORKER: args: ()
03:39:04 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0013028316288583998, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.02019873314502735}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:39:56 DISPATCHER: Starting worker discovery
03:39:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:39:56 DISPATCHER: Finished worker discovery
03:40:04 WORKER: done with job (8, 0, 17), trying to register it.
03:40:04 WORKER: registered result for job (8, 0, 17) with dispatcher
03:40:04 DISPATCHER: job (8, 0, 17) finished
03:40:04 DISPATCHER: register_result: lock acquired
03:40:04 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:40:04 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0013028316288583998, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.02019873314502735}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.14168503217811776, 'info': {'data04': 0.14168503217811776, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0013028316288583998, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.02019873314502735}"}}
exception: None

03:40:04 job_callback for (8, 0, 17) started
03:40:04 DISPATCHER: Trying to submit another job.
03:40:04 job_callback for (8, 0, 17) got condition
03:40:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:40:04 HBMASTER: Trying to run another job!
03:40:04 job_callback for (8, 0, 17) finished
03:40:04 start sampling a new configuration.
03:40:04 done sampling a new configuration.
03:40:04 HBMASTER: schedule new run for iteration 8
03:40:04 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
03:40:04 HBMASTER: submitting job (8, 0, 18) to dispatcher
03:40:04 DISPATCHER: trying to submit job (8, 0, 18)
03:40:04 DISPATCHER: trying to notify the job_runner thread.
03:40:04 HBMASTER: job (8, 0, 18) submitted to dispatcher
03:40:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:40:04 DISPATCHER: Trying to submit another job.
03:40:04 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:40:04 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:40:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:40:04 WORKER: start processing job (8, 0, 18)
03:40:04 WORKER: args: ()
03:40:04 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.034739031904219175, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.17025479542210503, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 22, 'num_filters_3': 111, 'num_filters_4': 77}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:40:56 DISPATCHER: Starting worker discovery
03:40:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:40:56 DISPATCHER: Finished worker discovery
03:41:08 WORKER: done with job (8, 0, 18), trying to register it.
03:41:08 WORKER: registered result for job (8, 0, 18) with dispatcher
03:41:08 DISPATCHER: job (8, 0, 18) finished
03:41:08 DISPATCHER: register_result: lock acquired
03:41:08 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:41:08 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.034739031904219175, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.17025479542210503, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 22, 'num_filters_3': 111, 'num_filters_4': 77}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.034739031904219175, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.17025479542210503, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 22, 'num_filters_3': 111, 'num_filters_4': 77}"}}
exception: None

03:41:08 job_callback for (8, 0, 18) started
03:41:08 job_callback for (8, 0, 18) got condition
03:41:08 DISPATCHER: Trying to submit another job.
03:41:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:41:08 HBMASTER: Trying to run another job!
03:41:08 job_callback for (8, 0, 18) finished
03:41:08 start sampling a new configuration.
03:41:08 done sampling a new configuration.
03:41:08 HBMASTER: schedule new run for iteration 8
03:41:08 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
03:41:08 HBMASTER: submitting job (8, 0, 19) to dispatcher
03:41:08 DISPATCHER: trying to submit job (8, 0, 19)
03:41:08 DISPATCHER: trying to notify the job_runner thread.
03:41:08 HBMASTER: job (8, 0, 19) submitted to dispatcher
03:41:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:41:08 DISPATCHER: Trying to submit another job.
03:41:08 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:41:08 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:41:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:41:08 WORKER: start processing job (8, 0, 19)
03:41:08 WORKER: args: ()
03:41:08 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.023143448590024145, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.04798057236026314, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 77, 'num_filters_3': 63}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:41:56 DISPATCHER: Starting worker discovery
03:41:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:41:56 DISPATCHER: Finished worker discovery
03:42:10 WORKER: done with job (8, 0, 19), trying to register it.
03:42:10 WORKER: registered result for job (8, 0, 19) with dispatcher
03:42:10 DISPATCHER: job (8, 0, 19) finished
03:42:10 DISPATCHER: register_result: lock acquired
03:42:10 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:42:10 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.023143448590024145, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.04798057236026314, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 77, 'num_filters_3': 63}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.023143448590024145, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.04798057236026314, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 77, 'num_filters_3': 63}"}}
exception: None

03:42:10 job_callback for (8, 0, 19) started
03:42:10 DISPATCHER: Trying to submit another job.
03:42:10 job_callback for (8, 0, 19) got condition
03:42:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:42:10 HBMASTER: Trying to run another job!
03:42:10 job_callback for (8, 0, 19) finished
03:42:10 start sampling a new configuration.
03:42:10 done sampling a new configuration.
03:42:10 HBMASTER: schedule new run for iteration 8
03:42:10 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
03:42:10 HBMASTER: submitting job (8, 0, 20) to dispatcher
03:42:10 DISPATCHER: trying to submit job (8, 0, 20)
03:42:10 DISPATCHER: trying to notify the job_runner thread.
03:42:10 HBMASTER: job (8, 0, 20) submitted to dispatcher
03:42:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:42:10 DISPATCHER: Trying to submit another job.
03:42:10 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:42:10 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:42:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:42:10 WORKER: start processing job (8, 0, 20)
03:42:10 WORKER: args: ()
03:42:10 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0049016901209369135, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.15078347750283175, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 119, 'num_filters_3': 27, 'num_filters_4': 55}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:42:56 DISPATCHER: Starting worker discovery
03:42:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:42:56 DISPATCHER: Finished worker discovery
03:43:15 WORKER: done with job (8, 0, 20), trying to register it.
03:43:15 WORKER: registered result for job (8, 0, 20) with dispatcher
03:43:15 DISPATCHER: job (8, 0, 20) finished
03:43:15 DISPATCHER: register_result: lock acquired
03:43:15 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:43:15 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0049016901209369135, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.15078347750283175, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 119, 'num_filters_3': 27, 'num_filters_4': 55}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0049016901209369135, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.15078347750283175, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 119, 'num_filters_3': 27, 'num_filters_4': 55}"}}
exception: None

03:43:15 job_callback for (8, 0, 20) started
03:43:15 job_callback for (8, 0, 20) got condition
03:43:15 DISPATCHER: Trying to submit another job.
03:43:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:43:15 HBMASTER: Trying to run another job!
03:43:15 job_callback for (8, 0, 20) finished
03:43:15 start sampling a new configuration.
03:43:15 done sampling a new configuration.
03:43:15 HBMASTER: schedule new run for iteration 8
03:43:15 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
03:43:15 HBMASTER: submitting job (8, 0, 21) to dispatcher
03:43:15 DISPATCHER: trying to submit job (8, 0, 21)
03:43:15 DISPATCHER: trying to notify the job_runner thread.
03:43:15 HBMASTER: job (8, 0, 21) submitted to dispatcher
03:43:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:43:15 DISPATCHER: Trying to submit another job.
03:43:15 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:43:15 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:43:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:43:15 WORKER: start processing job (8, 0, 21)
03:43:15 WORKER: args: ()
03:43:15 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.010576429242669515, 'num_filters_1': 38, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.01700855921095355, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 20, 'num_filters_3': 56, 'num_filters_4': 49}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:43:56 DISPATCHER: Starting worker discovery
03:43:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:43:56 DISPATCHER: Finished worker discovery
03:44:16 WORKER: done with job (8, 0, 21), trying to register it.
03:44:16 WORKER: registered result for job (8, 0, 21) with dispatcher
03:44:16 DISPATCHER: job (8, 0, 21) finished
03:44:16 DISPATCHER: register_result: lock acquired
03:44:16 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:44:16 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.010576429242669515, 'num_filters_1': 38, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.01700855921095355, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 20, 'num_filters_3': 56, 'num_filters_4': 49}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.010576429242669515, 'num_filters_1': 38, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.01700855921095355, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 20, 'num_filters_3': 56, 'num_filters_4': 49}"}}
exception: None

03:44:16 job_callback for (8, 0, 21) started
03:44:16 job_callback for (8, 0, 21) got condition
03:44:16 DISPATCHER: Trying to submit another job.
03:44:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:44:16 HBMASTER: Trying to run another job!
03:44:16 job_callback for (8, 0, 21) finished
03:44:16 start sampling a new configuration.
03:44:16 best_vector: [3, 2, 0.8856187505583302, 0.6900138232916706, 0.21426189386159322, 1, 0.06852745931167956, 0.22297620529904408, 1, 0, 2, 1, 0.7364289413891567, 0.016759271606969994, 0.5950262198744741, 0.743524670804564], 2.770657834214205e-29, 0.0003609251159241802, -2.6012179252974423e-06
03:44:16 done sampling a new configuration.
03:44:16 HBMASTER: schedule new run for iteration 8
03:44:16 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
03:44:16 HBMASTER: submitting job (8, 0, 22) to dispatcher
03:44:16 DISPATCHER: trying to submit job (8, 0, 22)
03:44:16 DISPATCHER: trying to notify the job_runner thread.
03:44:16 HBMASTER: job (8, 0, 22) submitted to dispatcher
03:44:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:44:16 DISPATCHER: Trying to submit another job.
03:44:16 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:44:16 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:44:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:44:16 WORKER: start processing job (8, 0, 22)
03:44:16 WORKER: args: ()
03:44:16 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.059052392965877096, 'num_filters_1': 67, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.019502879229071342, 'kernel_size_2': 5, 'num_filters_2': 74}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:44:56 DISPATCHER: Starting worker discovery
03:44:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:44:56 DISPATCHER: Finished worker discovery
03:45:23 WORKER: done with job (8, 0, 22), trying to register it.
03:45:23 WORKER: registered result for job (8, 0, 22) with dispatcher
03:45:23 DISPATCHER: job (8, 0, 22) finished
03:45:23 DISPATCHER: register_result: lock acquired
03:45:23 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:45:23 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.059052392965877096, 'num_filters_1': 67, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.019502879229071342, 'kernel_size_2': 5, 'num_filters_2': 74}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.12080485273613009, 'info': {'data04': 0.12080485273613009, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.059052392965877096, 'num_filters_1': 67, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.019502879229071342, 'kernel_size_2': 5, 'num_filters_2': 74}"}}
exception: None

03:45:23 job_callback for (8, 0, 22) started
03:45:23 DISPATCHER: Trying to submit another job.
03:45:23 job_callback for (8, 0, 22) got condition
03:45:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:45:23 HBMASTER: Trying to run another job!
03:45:23 job_callback for (8, 0, 22) finished
03:45:23 start sampling a new configuration.
03:45:23 done sampling a new configuration.
03:45:23 HBMASTER: schedule new run for iteration 8
03:45:23 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
03:45:23 HBMASTER: submitting job (8, 0, 23) to dispatcher
03:45:23 DISPATCHER: trying to submit job (8, 0, 23)
03:45:23 DISPATCHER: trying to notify the job_runner thread.
03:45:23 HBMASTER: job (8, 0, 23) submitted to dispatcher
03:45:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:45:23 DISPATCHER: Trying to submit another job.
03:45:23 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:45:23 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:45:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:45:23 WORKER: start processing job (8, 0, 23)
03:45:23 WORKER: args: ()
03:45:23 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.011558320094460658, 'num_filters_1': 88, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.041711138497939115, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 122, 'num_filters_3': 63, 'num_filters_4': 56, 'num_filters_5': 29}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:45:56 DISPATCHER: Starting worker discovery
03:45:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:45:56 DISPATCHER: Finished worker discovery
03:46:23 WORKER: done with job (8, 0, 23), trying to register it.
03:46:23 WORKER: registered result for job (8, 0, 23) with dispatcher
03:46:23 DISPATCHER: job (8, 0, 23) finished
03:46:23 DISPATCHER: register_result: lock acquired
03:46:23 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:46:23 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.011558320094460658, 'num_filters_1': 88, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.041711138497939115, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 122, 'num_filters_3': 63, 'num_filters_4': 56, 'num_filters_5': 29}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.17450930348543886, 'info': {'data04': 0.17450930348543886, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.011558320094460658, 'num_filters_1': 88, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.041711138497939115, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 122, 'num_filters_3': 63, 'num_filters_4': 56, 'num_filters_5': 29}"}}
exception: None

03:46:23 job_callback for (8, 0, 23) started
03:46:23 DISPATCHER: Trying to submit another job.
03:46:23 job_callback for (8, 0, 23) got condition
03:46:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:46:23 HBMASTER: Trying to run another job!
03:46:23 job_callback for (8, 0, 23) finished
03:46:23 start sampling a new configuration.
03:46:23 best_vector: [0, 0, 0.6508813375443833, 0.6504106164594918, 0.5892460729593432, 1, 0.42926660839814457, 0.2829297507767297, 1, 0, 1, 2, 0.3266460563971502, 0.33532801931367673, 0.6748843627274335, 0.7423318748342771], 2.908372448687355e-29, 0.00034383491717208817, -0.00033877688599728893
03:46:23 done sampling a new configuration.
03:46:23 HBMASTER: schedule new run for iteration 8
03:46:23 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
03:46:23 HBMASTER: submitting job (8, 0, 24) to dispatcher
03:46:23 DISPATCHER: trying to submit job (8, 0, 24)
03:46:23 DISPATCHER: trying to notify the job_runner thread.
03:46:23 HBMASTER: job (8, 0, 24) submitted to dispatcher
03:46:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:46:23 DISPATCHER: Trying to submit another job.
03:46:23 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:46:23 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:46:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:46:23 WORKER: start processing job (8, 0, 24)
03:46:23 WORKER: args: ()
03:46:23 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.02003376961204511, 'num_filters_1': 61, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.0233399591943886, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 31, 'num_filters_3': 32}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:46:56 DISPATCHER: Starting worker discovery
03:46:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:46:56 DISPATCHER: Finished worker discovery
03:47:25 WORKER: done with job (8, 0, 24), trying to register it.
03:47:25 WORKER: registered result for job (8, 0, 24) with dispatcher
03:47:25 DISPATCHER: job (8, 0, 24) finished
03:47:25 DISPATCHER: register_result: lock acquired
03:47:25 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:47:25 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.02003376961204511, 'num_filters_1': 61, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.0233399591943886, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 31, 'num_filters_3': 32}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.12066879233480822, 'info': {'data04': 0.12066879233480822, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.02003376961204511, 'num_filters_1': 61, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.0233399591943886, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 31, 'num_filters_3': 32}"}}
exception: None

03:47:25 job_callback for (8, 0, 24) started
03:47:25 job_callback for (8, 0, 24) got condition
03:47:25 DISPATCHER: Trying to submit another job.
03:47:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:47:25 HBMASTER: Trying to run another job!
03:47:25 job_callback for (8, 0, 24) finished
03:47:25 start sampling a new configuration.
03:47:25 best_vector: [3, 1, 0.03423740336093918, 0.1230162444616203, 0.6903670084956668, 1, 0.6360468310451144, 0.5286888385510479, 1, 1, 2, 2, 0.5932327802112958, 0.8291401433192558, 0.5503663164570651, 0.6370316193412969], 7.142447286615921e-31, 0.01400080336432974, -3.450042663582553e-05
03:47:25 done sampling a new configuration.
03:47:25 HBMASTER: schedule new run for iteration 8
03:47:25 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
03:47:25 HBMASTER: submitting job (8, 0, 25) to dispatcher
03:47:25 DISPATCHER: trying to submit job (8, 0, 25)
03:47:25 DISPATCHER: trying to notify the job_runner thread.
03:47:25 HBMASTER: job (8, 0, 25) submitted to dispatcher
03:47:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:47:25 DISPATCHER: Trying to submit another job.
03:47:25 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:47:25 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:47:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:47:25 WORKER: start processing job (8, 0, 25)
03:47:25 WORKER: args: ()
03:47:25 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0011707786838691297, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.04873489529394077, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 54, 'num_filters_3': 90, 'num_filters_4': 50}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:47:56 DISPATCHER: Starting worker discovery
03:47:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:47:56 DISPATCHER: Finished worker discovery
03:48:25 WORKER: done with job (8, 0, 25), trying to register it.
03:48:25 WORKER: registered result for job (8, 0, 25) with dispatcher
03:48:25 DISPATCHER: job (8, 0, 25) finished
03:48:25 DISPATCHER: register_result: lock acquired
03:48:25 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:48:25 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0011707786838691297, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.04873489529394077, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 54, 'num_filters_3': 90, 'num_filters_4': 50}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.15091445037128498, 'info': {'data04': 0.15091445037128498, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0011707786838691297, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.04873489529394077, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 54, 'num_filters_3': 90, 'num_filters_4': 50}"}}
exception: None

03:48:25 job_callback for (8, 0, 25) started
03:48:25 job_callback for (8, 0, 25) got condition
03:48:25 DISPATCHER: Trying to submit another job.
03:48:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:48:25 HBMASTER: Trying to run another job!
03:48:25 job_callback for (8, 0, 25) finished
03:48:25 start sampling a new configuration.
03:48:25 best_vector: [0, 2, 0.6204609635588719, 0.7274731347654058, 0.3231856319212238, 1, 0.17225006251231278, 0.0257559993694138, 2, 1, 1, 2, 0.6586955532516868, 0.7042136040400164, 0.6450289609109148, 0.6124180678199495], 3.786615628392482e-30, 0.002640880665314653, -4.350330586049618e-07
03:48:25 done sampling a new configuration.
03:48:25 HBMASTER: schedule new run for iteration 8
03:48:25 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
03:48:25 HBMASTER: submitting job (8, 0, 26) to dispatcher
03:48:25 DISPATCHER: trying to submit job (8, 0, 26)
03:48:25 DISPATCHER: trying to notify the job_runner thread.
03:48:25 HBMASTER: job (8, 0, 26) submitted to dispatcher
03:48:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:48:25 DISPATCHER: Trying to submit another job.
03:48:25 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:48:25 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:48:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:48:25 WORKER: start processing job (8, 0, 26)
03:48:25 WORKER: args: ()
03:48:25 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.01741493777862881, 'num_filters_1': 72, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.010802128213716554, 'kernel_size_2': 7, 'num_filters_2': 62}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:48:56 DISPATCHER: Starting worker discovery
03:48:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:48:56 DISPATCHER: Finished worker discovery
03:49:30 WORKER: done with job (8, 0, 26), trying to register it.
03:49:30 WORKER: registered result for job (8, 0, 26) with dispatcher
03:49:30 DISPATCHER: job (8, 0, 26) finished
03:49:30 DISPATCHER: register_result: lock acquired
03:49:30 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:49:30 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.01741493777862881, 'num_filters_1': 72, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.010802128213716554, 'kernel_size_2': 7, 'num_filters_2': 62}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.16561887093078634, 'info': {'data04': 0.16561887093078634, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.01741493777862881, 'num_filters_1': 72, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.010802128213716554, 'kernel_size_2': 7, 'num_filters_2': 62}"}}
exception: None

03:49:30 job_callback for (8, 0, 26) started
03:49:30 DISPATCHER: Trying to submit another job.
03:49:30 job_callback for (8, 0, 26) got condition
03:49:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:49:30 HBMASTER: Trying to run another job!
03:49:30 job_callback for (8, 0, 26) finished
03:49:30 ITERATION: Advancing config (8, 0, 1) to next budget 133.333333
03:49:30 ITERATION: Advancing config (8, 0, 4) to next budget 133.333333
03:49:30 ITERATION: Advancing config (8, 0, 6) to next budget 133.333333
03:49:30 ITERATION: Advancing config (8, 0, 7) to next budget 133.333333
03:49:30 ITERATION: Advancing config (8, 0, 11) to next budget 133.333333
03:49:30 ITERATION: Advancing config (8, 0, 12) to next budget 133.333333
03:49:30 ITERATION: Advancing config (8, 0, 23) to next budget 133.333333
03:49:30 ITERATION: Advancing config (8, 0, 25) to next budget 133.333333
03:49:30 ITERATION: Advancing config (8, 0, 26) to next budget 133.333333
03:49:30 HBMASTER: schedule new run for iteration 8
03:49:30 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
03:49:30 HBMASTER: submitting job (8, 0, 1) to dispatcher
03:49:30 DISPATCHER: trying to submit job (8, 0, 1)
03:49:30 DISPATCHER: trying to notify the job_runner thread.
03:49:30 HBMASTER: job (8, 0, 1) submitted to dispatcher
03:49:30 DISPATCHER: Trying to submit another job.
03:49:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:49:30 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:49:30 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:49:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:49:30 WORKER: start processing job (8, 0, 1)
03:49:30 WORKER: args: ()
03:49:30 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004661194507513357, 'num_filters_1': 26, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.015140424560289004}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:49:56 DISPATCHER: Starting worker discovery
03:49:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:49:56 DISPATCHER: Finished worker discovery
03:50:56 DISPATCHER: Starting worker discovery
03:50:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:50:56 DISPATCHER: Finished worker discovery
03:51:56 DISPATCHER: Starting worker discovery
03:51:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:51:56 DISPATCHER: Finished worker discovery
03:52:38 WORKER: done with job (8, 0, 1), trying to register it.
03:52:38 WORKER: registered result for job (8, 0, 1) with dispatcher
03:52:38 DISPATCHER: job (8, 0, 1) finished
03:52:38 DISPATCHER: register_result: lock acquired
03:52:38 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:52:38 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004661194507513357, 'num_filters_1': 26, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.015140424560289004}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.16814780092698856, 'info': {'data04': 0.16814780092698856, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004661194507513357, 'num_filters_1': 26, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.015140424560289004}"}}
exception: None

03:52:38 job_callback for (8, 0, 1) started
03:52:38 job_callback for (8, 0, 1) got condition
03:52:38 DISPATCHER: Trying to submit another job.
03:52:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:52:38 done building a new model for budget 133.333333 based on 17/31 split
Best loss for this budget:-0.181448





03:52:38 HBMASTER: Trying to run another job!
03:52:38 job_callback for (8, 0, 1) finished
03:52:38 HBMASTER: schedule new run for iteration 8
03:52:38 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
03:52:38 HBMASTER: submitting job (8, 0, 4) to dispatcher
03:52:38 DISPATCHER: trying to submit job (8, 0, 4)
03:52:38 DISPATCHER: trying to notify the job_runner thread.
03:52:38 HBMASTER: job (8, 0, 4) submitted to dispatcher
03:52:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:52:38 DISPATCHER: Trying to submit another job.
03:52:38 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:52:38 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:52:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:52:38 WORKER: start processing job (8, 0, 4)
03:52:38 WORKER: args: ()
03:52:38 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.004308289047563535, 'num_filters_1': 108, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.01364452534507017, 'kernel_size_2': 3, 'num_filters_2': 58}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:52:56 DISPATCHER: Starting worker discovery
03:52:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:52:56 DISPATCHER: Finished worker discovery
03:53:56 DISPATCHER: Starting worker discovery
03:53:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:53:56 DISPATCHER: Finished worker discovery
03:54:56 DISPATCHER: Starting worker discovery
03:54:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:54:56 DISPATCHER: Finished worker discovery
03:55:21 WORKER: done with job (8, 0, 4), trying to register it.
03:55:21 WORKER: registered result for job (8, 0, 4) with dispatcher
03:55:21 DISPATCHER: job (8, 0, 4) finished
03:55:21 DISPATCHER: register_result: lock acquired
03:55:21 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:55:21 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.004308289047563535, 'num_filters_1': 108, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.01364452534507017, 'kernel_size_2': 3, 'num_filters_2': 58}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.18263236894112128, 'info': {'data04': 0.18263236894112128, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.004308289047563535, 'num_filters_1': 108, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.01364452534507017, 'kernel_size_2': 3, 'num_filters_2': 58}"}}
exception: None

03:55:21 job_callback for (8, 0, 4) started
03:55:21 job_callback for (8, 0, 4) got condition
03:55:21 DISPATCHER: Trying to submit another job.
03:55:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:55:21 done building a new model for budget 133.333333 based on 17/32 split
Best loss for this budget:-0.182632





03:55:21 HBMASTER: Trying to run another job!
03:55:21 job_callback for (8, 0, 4) finished
03:55:21 HBMASTER: schedule new run for iteration 8
03:55:21 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
03:55:21 HBMASTER: submitting job (8, 0, 6) to dispatcher
03:55:21 DISPATCHER: trying to submit job (8, 0, 6)
03:55:21 DISPATCHER: trying to notify the job_runner thread.
03:55:21 HBMASTER: job (8, 0, 6) submitted to dispatcher
03:55:21 DISPATCHER: Trying to submit another job.
03:55:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:55:21 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:55:21 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:55:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:55:21 WORKER: start processing job (8, 0, 6)
03:55:21 WORKER: args: ()
03:55:21 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006987864721180082, 'num_filters_1': 54, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.01920007271117927, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 18, 'num_filters_3': 46}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:55:56 DISPATCHER: Starting worker discovery
03:55:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:55:56 DISPATCHER: Finished worker discovery
03:56:56 DISPATCHER: Starting worker discovery
03:56:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:56:56 DISPATCHER: Finished worker discovery
03:57:53 WORKER: done with job (8, 0, 6), trying to register it.
03:57:53 WORKER: registered result for job (8, 0, 6) with dispatcher
03:57:53 DISPATCHER: job (8, 0, 6) finished
03:57:53 DISPATCHER: register_result: lock acquired
03:57:53 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
03:57:53 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006987864721180082, 'num_filters_1': 54, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.01920007271117927, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 18, 'num_filters_3': 46}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.13448422751828493, 'info': {'data04': 0.13448422751828493, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006987864721180082, 'num_filters_1': 54, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.01920007271117927, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 18, 'num_filters_3': 46}"}}
exception: None

03:57:53 job_callback for (8, 0, 6) started
03:57:53 job_callback for (8, 0, 6) got condition
03:57:53 DISPATCHER: Trying to submit another job.
03:57:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:57:53 done building a new model for budget 133.333333 based on 17/33 split
Best loss for this budget:-0.182632





03:57:53 HBMASTER: Trying to run another job!
03:57:53 job_callback for (8, 0, 6) finished
03:57:53 HBMASTER: schedule new run for iteration 8
03:57:53 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
03:57:53 HBMASTER: submitting job (8, 0, 7) to dispatcher
03:57:53 DISPATCHER: trying to submit job (8, 0, 7)
03:57:53 DISPATCHER: trying to notify the job_runner thread.
03:57:53 HBMASTER: job (8, 0, 7) submitted to dispatcher
03:57:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:57:53 DISPATCHER: Trying to submit another job.
03:57:53 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:57:53 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
03:57:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:57:53 WORKER: start processing job (8, 0, 7)
03:57:53 WORKER: args: ()
03:57:53 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0025957165022385677, 'num_filters_1': 88, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.05068745464445541, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 111, 'num_filters_3': 50, 'num_filters_4': 43, 'num_filters_5': 72}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:57:56 DISPATCHER: Starting worker discovery
03:57:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:57:56 DISPATCHER: Finished worker discovery
03:58:56 DISPATCHER: Starting worker discovery
03:58:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:58:56 DISPATCHER: Finished worker discovery
03:59:56 DISPATCHER: Starting worker discovery
03:59:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:59:56 DISPATCHER: Finished worker discovery
04:00:24 WORKER: done with job (8, 0, 7), trying to register it.
04:00:24 WORKER: registered result for job (8, 0, 7) with dispatcher
04:00:24 DISPATCHER: job (8, 0, 7) finished
04:00:24 DISPATCHER: register_result: lock acquired
04:00:24 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:00:24 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0025957165022385677, 'num_filters_1': 88, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.05068745464445541, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 111, 'num_filters_3': 50, 'num_filters_4': 43, 'num_filters_5': 72}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.15719260312180375, 'info': {'data04': 0.15719260312180375, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0025957165022385677, 'num_filters_1': 88, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.05068745464445541, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 111, 'num_filters_3': 50, 'num_filters_4': 43, 'num_filters_5': 72}"}}
exception: None

04:00:24 job_callback for (8, 0, 7) started
04:00:24 DISPATCHER: Trying to submit another job.
04:00:24 job_callback for (8, 0, 7) got condition
04:00:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:00:24 done building a new model for budget 133.333333 based on 17/34 split
Best loss for this budget:-0.182632





04:00:24 HBMASTER: Trying to run another job!
04:00:24 job_callback for (8, 0, 7) finished
04:00:24 HBMASTER: schedule new run for iteration 8
04:00:24 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
04:00:24 HBMASTER: submitting job (8, 0, 11) to dispatcher
04:00:24 DISPATCHER: trying to submit job (8, 0, 11)
04:00:24 DISPATCHER: trying to notify the job_runner thread.
04:00:24 HBMASTER: job (8, 0, 11) submitted to dispatcher
04:00:24 DISPATCHER: Trying to submit another job.
04:00:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:00:24 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:00:24 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:00:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:00:24 WORKER: start processing job (8, 0, 11)
04:00:24 WORKER: args: ()
04:00:24 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0050757556768351066, 'num_filters_1': 24, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.01267456790664283, 'kernel_size_2': 5, 'num_filters_2': 53}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:00:56 DISPATCHER: Starting worker discovery
04:00:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:00:56 DISPATCHER: Finished worker discovery
04:01:56 DISPATCHER: Starting worker discovery
04:01:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:01:56 DISPATCHER: Finished worker discovery
04:02:56 DISPATCHER: Starting worker discovery
04:02:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:02:56 DISPATCHER: Finished worker discovery
04:03:19 WORKER: done with job (8, 0, 11), trying to register it.
04:03:19 WORKER: registered result for job (8, 0, 11) with dispatcher
04:03:19 DISPATCHER: job (8, 0, 11) finished
04:03:19 DISPATCHER: register_result: lock acquired
04:03:19 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:03:19 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0050757556768351066, 'num_filters_1': 24, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.01267456790664283, 'kernel_size_2': 5, 'num_filters_2': 53}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.14083496269201493, 'info': {'data04': 0.14083496269201493, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0050757556768351066, 'num_filters_1': 24, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.01267456790664283, 'kernel_size_2': 5, 'num_filters_2': 53}"}}
exception: None

04:03:19 job_callback for (8, 0, 11) started
04:03:19 job_callback for (8, 0, 11) got condition
04:03:19 DISPATCHER: Trying to submit another job.
04:03:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:03:19 done building a new model for budget 133.333333 based on 17/34 split
Best loss for this budget:-0.182632





04:03:19 HBMASTER: Trying to run another job!
04:03:19 job_callback for (8, 0, 11) finished
04:03:19 HBMASTER: schedule new run for iteration 8
04:03:19 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
04:03:19 HBMASTER: submitting job (8, 0, 12) to dispatcher
04:03:19 DISPATCHER: trying to submit job (8, 0, 12)
04:03:19 DISPATCHER: trying to notify the job_runner thread.
04:03:19 HBMASTER: job (8, 0, 12) submitted to dispatcher
04:03:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:03:19 DISPATCHER: Trying to submit another job.
04:03:19 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:03:19 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:03:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:03:19 WORKER: start processing job (8, 0, 12)
04:03:19 WORKER: args: ()
04:03:19 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001003135857089057, 'num_filters_1': 118, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.018531247344448023, 'kernel_size_2': 7, 'num_filters_2': 79}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:03:56 DISPATCHER: Starting worker discovery
04:03:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:03:56 DISPATCHER: Finished worker discovery
04:04:56 DISPATCHER: Starting worker discovery
04:04:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:04:56 DISPATCHER: Finished worker discovery
04:05:51 WORKER: done with job (8, 0, 12), trying to register it.
04:05:51 WORKER: registered result for job (8, 0, 12) with dispatcher
04:05:51 DISPATCHER: job (8, 0, 12) finished
04:05:51 DISPATCHER: register_result: lock acquired
04:05:51 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:05:51 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001003135857089057, 'num_filters_1': 118, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.018531247344448023, 'kernel_size_2': 7, 'num_filters_2': 79}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1831596474588422, 'info': {'data04': 0.1831596474588422, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001003135857089057, 'num_filters_1': 118, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.018531247344448023, 'kernel_size_2': 7, 'num_filters_2': 79}"}}
exception: None

04:05:51 job_callback for (8, 0, 12) started
04:05:51 job_callback for (8, 0, 12) got condition
04:05:51 DISPATCHER: Trying to submit another job.
04:05:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:05:51 done building a new model for budget 133.333333 based on 17/35 split
Best loss for this budget:-0.183160





04:05:51 HBMASTER: Trying to run another job!
04:05:51 job_callback for (8, 0, 12) finished
04:05:51 HBMASTER: schedule new run for iteration 8
04:05:51 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
04:05:51 HBMASTER: submitting job (8, 0, 23) to dispatcher
04:05:51 DISPATCHER: trying to submit job (8, 0, 23)
04:05:51 DISPATCHER: trying to notify the job_runner thread.
04:05:51 HBMASTER: job (8, 0, 23) submitted to dispatcher
04:05:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:05:51 DISPATCHER: Trying to submit another job.
04:05:51 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:05:51 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:05:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:05:51 WORKER: start processing job (8, 0, 23)
04:05:51 WORKER: args: ()
04:05:51 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.011558320094460658, 'num_filters_1': 88, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.041711138497939115, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 122, 'num_filters_3': 63, 'num_filters_4': 56, 'num_filters_5': 29}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:05:56 DISPATCHER: Starting worker discovery
04:05:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:05:56 DISPATCHER: Finished worker discovery
04:06:56 DISPATCHER: Starting worker discovery
04:06:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:06:56 DISPATCHER: Finished worker discovery
04:07:56 DISPATCHER: Starting worker discovery
04:07:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:07:56 DISPATCHER: Finished worker discovery
04:08:22 WORKER: done with job (8, 0, 23), trying to register it.
04:08:22 WORKER: registered result for job (8, 0, 23) with dispatcher
04:08:22 DISPATCHER: job (8, 0, 23) finished
04:08:22 DISPATCHER: register_result: lock acquired
04:08:22 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:08:22 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.011558320094460658, 'num_filters_1': 88, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.041711138497939115, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 122, 'num_filters_3': 63, 'num_filters_4': 56, 'num_filters_5': 29}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.026523204666791922, 'info': {'data04': 0.026523204666791922, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.011558320094460658, 'num_filters_1': 88, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.041711138497939115, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 122, 'num_filters_3': 63, 'num_filters_4': 56, 'num_filters_5': 29}"}}
exception: None

04:08:22 job_callback for (8, 0, 23) started
04:08:22 job_callback for (8, 0, 23) got condition
04:08:22 DISPATCHER: Trying to submit another job.
04:08:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:08:22 done building a new model for budget 133.333333 based on 17/36 split
Best loss for this budget:-0.183160





04:08:22 HBMASTER: Trying to run another job!
04:08:22 job_callback for (8, 0, 23) finished
04:08:22 HBMASTER: schedule new run for iteration 8
04:08:22 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
04:08:22 HBMASTER: submitting job (8, 0, 25) to dispatcher
04:08:22 DISPATCHER: trying to submit job (8, 0, 25)
04:08:22 DISPATCHER: trying to notify the job_runner thread.
04:08:22 HBMASTER: job (8, 0, 25) submitted to dispatcher
04:08:22 DISPATCHER: Trying to submit another job.
04:08:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:08:22 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:08:22 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:08:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:08:22 WORKER: start processing job (8, 0, 25)
04:08:22 WORKER: args: ()
04:08:22 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0011707786838691297, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.04873489529394077, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 54, 'num_filters_3': 90, 'num_filters_4': 50}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:08:56 DISPATCHER: Starting worker discovery
04:08:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:08:56 DISPATCHER: Finished worker discovery
04:09:56 DISPATCHER: Starting worker discovery
04:09:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:09:56 DISPATCHER: Finished worker discovery
04:10:53 WORKER: done with job (8, 0, 25), trying to register it.
04:10:53 WORKER: registered result for job (8, 0, 25) with dispatcher
04:10:53 DISPATCHER: job (8, 0, 25) finished
04:10:53 DISPATCHER: register_result: lock acquired
04:10:53 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:10:53 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0011707786838691297, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.04873489529394077, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 54, 'num_filters_3': 90, 'num_filters_4': 50}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.152602161589795, 'info': {'data04': 0.152602161589795, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0011707786838691297, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.04873489529394077, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 54, 'num_filters_3': 90, 'num_filters_4': 50}"}}
exception: None

04:10:53 job_callback for (8, 0, 25) started
04:10:53 DISPATCHER: Trying to submit another job.
04:10:53 job_callback for (8, 0, 25) got condition
04:10:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:10:54 done building a new model for budget 133.333333 based on 17/37 split
Best loss for this budget:-0.183160





04:10:54 HBMASTER: Trying to run another job!
04:10:54 job_callback for (8, 0, 25) finished
04:10:54 HBMASTER: schedule new run for iteration 8
04:10:54 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
04:10:54 HBMASTER: submitting job (8, 0, 26) to dispatcher
04:10:54 DISPATCHER: trying to submit job (8, 0, 26)
04:10:54 DISPATCHER: trying to notify the job_runner thread.
04:10:54 HBMASTER: job (8, 0, 26) submitted to dispatcher
04:10:54 DISPATCHER: Trying to submit another job.
04:10:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:10:54 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:10:54 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:10:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:10:54 WORKER: start processing job (8, 0, 26)
04:10:54 WORKER: args: ()
04:10:54 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.01741493777862881, 'num_filters_1': 72, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.010802128213716554, 'kernel_size_2': 7, 'num_filters_2': 62}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:10:56 DISPATCHER: Starting worker discovery
04:10:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:10:56 DISPATCHER: Finished worker discovery
04:11:56 DISPATCHER: Starting worker discovery
04:11:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:11:56 DISPATCHER: Finished worker discovery
04:12:56 DISPATCHER: Starting worker discovery
04:12:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:12:56 DISPATCHER: Finished worker discovery
04:13:38 WORKER: done with job (8, 0, 26), trying to register it.
04:13:38 WORKER: registered result for job (8, 0, 26) with dispatcher
04:13:38 DISPATCHER: job (8, 0, 26) finished
04:13:38 DISPATCHER: register_result: lock acquired
04:13:38 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:13:38 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.01741493777862881, 'num_filters_1': 72, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.010802128213716554, 'kernel_size_2': 7, 'num_filters_2': 62}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.13867431754234988, 'info': {'data04': 0.13867431754234988, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.01741493777862881, 'num_filters_1': 72, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.010802128213716554, 'kernel_size_2': 7, 'num_filters_2': 62}"}}
exception: None

04:13:38 job_callback for (8, 0, 26) started
04:13:38 DISPATCHER: Trying to submit another job.
04:13:38 job_callback for (8, 0, 26) got condition
04:13:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:13:38 done building a new model for budget 133.333333 based on 17/38 split
Best loss for this budget:-0.183160





04:13:38 HBMASTER: Trying to run another job!
04:13:38 job_callback for (8, 0, 26) finished
04:13:38 ITERATION: Advancing config (8, 0, 1) to next budget 400.000000
04:13:38 ITERATION: Advancing config (8, 0, 4) to next budget 400.000000
04:13:38 ITERATION: Advancing config (8, 0, 12) to next budget 400.000000
04:13:38 HBMASTER: schedule new run for iteration 8
04:13:38 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
04:13:38 HBMASTER: submitting job (8, 0, 1) to dispatcher
04:13:38 DISPATCHER: trying to submit job (8, 0, 1)
04:13:38 DISPATCHER: trying to notify the job_runner thread.
04:13:38 HBMASTER: job (8, 0, 1) submitted to dispatcher
04:13:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:13:38 DISPATCHER: Trying to submit another job.
04:13:38 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:13:38 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:13:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:13:38 WORKER: start processing job (8, 0, 1)
04:13:38 WORKER: args: ()
04:13:38 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004661194507513357, 'num_filters_1': 26, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.015140424560289004}, 'budget': 400.0, 'working_directory': '.'}
04:13:56 DISPATCHER: Starting worker discovery
04:13:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:13:56 DISPATCHER: Finished worker discovery
04:14:56 DISPATCHER: Starting worker discovery
04:14:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:14:56 DISPATCHER: Finished worker discovery
04:15:56 DISPATCHER: Starting worker discovery
04:15:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:15:56 DISPATCHER: Finished worker discovery
04:16:56 DISPATCHER: Starting worker discovery
04:16:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:16:56 DISPATCHER: Finished worker discovery
04:17:56 DISPATCHER: Starting worker discovery
04:17:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:17:56 DISPATCHER: Finished worker discovery
04:18:56 DISPATCHER: Starting worker discovery
04:18:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:18:56 DISPATCHER: Finished worker discovery
04:19:56 DISPATCHER: Starting worker discovery
04:19:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:19:56 DISPATCHER: Finished worker discovery
04:20:56 DISPATCHER: Starting worker discovery
04:20:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:20:56 DISPATCHER: Finished worker discovery
04:21:56 DISPATCHER: Starting worker discovery
04:21:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:21:57 DISPATCHER: Finished worker discovery
04:22:45 WORKER: done with job (8, 0, 1), trying to register it.
04:22:45 WORKER: registered result for job (8, 0, 1) with dispatcher
04:22:45 DISPATCHER: job (8, 0, 1) finished
04:22:45 DISPATCHER: register_result: lock acquired
04:22:45 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:22:45 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004661194507513357, 'num_filters_1': 26, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.015140424560289004}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.13825004226005297, 'info': {'data04': 0.13825004226005297, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004661194507513357, 'num_filters_1': 26, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.015140424560289004}"}}
exception: None

04:22:45 job_callback for (8, 0, 1) started
04:22:45 job_callback for (8, 0, 1) got condition
04:22:45 DISPATCHER: Trying to submit another job.
04:22:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:22:45 HBMASTER: Trying to run another job!
04:22:45 job_callback for (8, 0, 1) finished
04:22:45 HBMASTER: schedule new run for iteration 8
04:22:45 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
04:22:45 HBMASTER: submitting job (8, 0, 4) to dispatcher
04:22:45 DISPATCHER: trying to submit job (8, 0, 4)
04:22:45 DISPATCHER: trying to notify the job_runner thread.
04:22:45 HBMASTER: job (8, 0, 4) submitted to dispatcher
04:22:45 DISPATCHER: Trying to submit another job.
04:22:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:22:45 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:22:45 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:22:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:22:45 WORKER: start processing job (8, 0, 4)
04:22:45 WORKER: args: ()
04:22:45 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.004308289047563535, 'num_filters_1': 108, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.01364452534507017, 'kernel_size_2': 3, 'num_filters_2': 58}, 'budget': 400.0, 'working_directory': '.'}
04:22:57 DISPATCHER: Starting worker discovery
04:22:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:22:57 DISPATCHER: Finished worker discovery
04:23:57 DISPATCHER: Starting worker discovery
04:23:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:23:57 DISPATCHER: Finished worker discovery
04:24:57 DISPATCHER: Starting worker discovery
04:24:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:24:57 DISPATCHER: Finished worker discovery
04:25:57 DISPATCHER: Starting worker discovery
04:25:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:25:57 DISPATCHER: Finished worker discovery
04:26:57 DISPATCHER: Starting worker discovery
04:26:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:26:57 DISPATCHER: Finished worker discovery
04:27:57 DISPATCHER: Starting worker discovery
04:27:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:27:57 DISPATCHER: Finished worker discovery
04:28:57 DISPATCHER: Starting worker discovery
04:28:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:28:57 DISPATCHER: Finished worker discovery
04:29:57 DISPATCHER: Starting worker discovery
04:29:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:29:57 DISPATCHER: Finished worker discovery
04:30:19 WORKER: done with job (8, 0, 4), trying to register it.
04:30:19 WORKER: registered result for job (8, 0, 4) with dispatcher
04:30:19 DISPATCHER: job (8, 0, 4) finished
04:30:19 DISPATCHER: register_result: lock acquired
04:30:19 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:30:19 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.004308289047563535, 'num_filters_1': 108, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.01364452534507017, 'kernel_size_2': 3, 'num_filters_2': 58}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.1509023647354586, 'info': {'data04': 0.1509023647354586, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.004308289047563535, 'num_filters_1': 108, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 36, 'weight_decay': 0.01364452534507017, 'kernel_size_2': 3, 'num_filters_2': 58}"}}
exception: None

04:30:19 job_callback for (8, 0, 4) started
04:30:19 DISPATCHER: Trying to submit another job.
04:30:19 job_callback for (8, 0, 4) got condition
04:30:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:30:19 HBMASTER: Trying to run another job!
04:30:19 job_callback for (8, 0, 4) finished
04:30:19 HBMASTER: schedule new run for iteration 8
04:30:19 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
04:30:19 HBMASTER: submitting job (8, 0, 12) to dispatcher
04:30:19 DISPATCHER: trying to submit job (8, 0, 12)
04:30:19 DISPATCHER: trying to notify the job_runner thread.
04:30:19 HBMASTER: job (8, 0, 12) submitted to dispatcher
04:30:19 DISPATCHER: Trying to submit another job.
04:30:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:30:19 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:30:19 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:30:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:30:19 WORKER: start processing job (8, 0, 12)
04:30:19 WORKER: args: ()
04:30:19 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001003135857089057, 'num_filters_1': 118, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.018531247344448023, 'kernel_size_2': 7, 'num_filters_2': 79}, 'budget': 400.0, 'working_directory': '.'}
04:30:57 DISPATCHER: Starting worker discovery
04:30:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:30:57 DISPATCHER: Finished worker discovery
04:31:57 DISPATCHER: Starting worker discovery
04:31:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:31:57 DISPATCHER: Finished worker discovery
04:32:57 DISPATCHER: Starting worker discovery
04:32:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:32:57 DISPATCHER: Finished worker discovery
04:33:57 DISPATCHER: Starting worker discovery
04:33:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:33:57 DISPATCHER: Finished worker discovery
04:34:57 DISPATCHER: Starting worker discovery
04:34:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:34:57 DISPATCHER: Finished worker discovery
04:35:57 DISPATCHER: Starting worker discovery
04:35:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:35:57 DISPATCHER: Finished worker discovery
04:36:57 DISPATCHER: Starting worker discovery
04:36:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:36:57 DISPATCHER: Finished worker discovery
04:37:25 WORKER: done with job (8, 0, 12), trying to register it.
04:37:25 WORKER: registered result for job (8, 0, 12) with dispatcher
04:37:25 DISPATCHER: job (8, 0, 12) finished
04:37:25 DISPATCHER: register_result: lock acquired
04:37:25 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:37:25 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001003135857089057, 'num_filters_1': 118, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.018531247344448023, 'kernel_size_2': 7, 'num_filters_2': 79}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.17664087530696337, 'info': {'data04': 0.17664087530696337, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001003135857089057, 'num_filters_1': 118, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.018531247344448023, 'kernel_size_2': 7, 'num_filters_2': 79}"}}
exception: None

04:37:25 job_callback for (8, 0, 12) started
04:37:25 DISPATCHER: Trying to submit another job.
04:37:25 job_callback for (8, 0, 12) got condition
04:37:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:37:25 HBMASTER: Trying to run another job!
04:37:25 job_callback for (8, 0, 12) finished
04:37:25 ITERATION: Advancing config (8, 0, 12) to next budget 1200.000000
04:37:25 HBMASTER: schedule new run for iteration 8
04:37:25 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
04:37:25 HBMASTER: submitting job (8, 0, 12) to dispatcher
04:37:25 DISPATCHER: trying to submit job (8, 0, 12)
04:37:25 DISPATCHER: trying to notify the job_runner thread.
04:37:25 HBMASTER: job (8, 0, 12) submitted to dispatcher
04:37:25 DISPATCHER: Trying to submit another job.
04:37:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:37:25 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:37:25 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:37:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:37:25 WORKER: start processing job (8, 0, 12)
04:37:25 WORKER: args: ()
04:37:25 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001003135857089057, 'num_filters_1': 118, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.018531247344448023, 'kernel_size_2': 7, 'num_filters_2': 79}, 'budget': 1200.0, 'working_directory': '.'}
04:37:57 DISPATCHER: Starting worker discovery
04:37:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:37:57 DISPATCHER: Finished worker discovery
04:38:57 DISPATCHER: Starting worker discovery
04:38:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:38:57 DISPATCHER: Finished worker discovery
04:39:57 DISPATCHER: Starting worker discovery
04:39:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:39:57 DISPATCHER: Finished worker discovery
04:40:57 DISPATCHER: Starting worker discovery
04:40:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:40:57 DISPATCHER: Finished worker discovery
04:41:57 DISPATCHER: Starting worker discovery
04:41:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:41:57 DISPATCHER: Finished worker discovery
04:42:57 DISPATCHER: Starting worker discovery
04:42:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:42:57 DISPATCHER: Finished worker discovery
04:43:57 DISPATCHER: Starting worker discovery
04:43:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:43:57 DISPATCHER: Finished worker discovery
04:44:57 DISPATCHER: Starting worker discovery
04:44:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:44:57 DISPATCHER: Finished worker discovery
04:45:57 DISPATCHER: Starting worker discovery
04:45:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:45:57 DISPATCHER: Finished worker discovery
04:46:57 DISPATCHER: Starting worker discovery
04:46:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:46:57 DISPATCHER: Finished worker discovery
04:47:57 DISPATCHER: Starting worker discovery
04:47:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:47:57 DISPATCHER: Finished worker discovery
04:48:57 DISPATCHER: Starting worker discovery
04:48:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:48:57 DISPATCHER: Finished worker discovery
04:49:57 DISPATCHER: Starting worker discovery
04:49:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:49:57 DISPATCHER: Finished worker discovery
04:50:57 DISPATCHER: Starting worker discovery
04:50:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:50:57 DISPATCHER: Finished worker discovery
04:51:57 DISPATCHER: Starting worker discovery
04:51:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:51:57 DISPATCHER: Finished worker discovery
04:52:57 DISPATCHER: Starting worker discovery
04:52:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:52:57 DISPATCHER: Finished worker discovery
04:53:57 DISPATCHER: Starting worker discovery
04:53:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:53:57 DISPATCHER: Finished worker discovery
04:54:57 DISPATCHER: Starting worker discovery
04:54:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:54:57 DISPATCHER: Finished worker discovery
04:55:57 DISPATCHER: Starting worker discovery
04:55:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:55:57 DISPATCHER: Finished worker discovery
04:56:57 DISPATCHER: Starting worker discovery
04:56:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:56:57 DISPATCHER: Finished worker discovery
04:57:57 DISPATCHER: Starting worker discovery
04:57:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:57:57 DISPATCHER: Finished worker discovery
04:58:18 WORKER: done with job (8, 0, 12), trying to register it.
04:58:18 WORKER: registered result for job (8, 0, 12) with dispatcher
04:58:18 DISPATCHER: job (8, 0, 12) finished
04:58:18 DISPATCHER: register_result: lock acquired
04:58:18 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
04:58:18 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001003135857089057, 'num_filters_1': 118, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.018531247344448023, 'kernel_size_2': 7, 'num_filters_2': 79}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.1757580224268157, 'info': {'data04': 0.1757580224268157, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001003135857089057, 'num_filters_1': 118, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.018531247344448023, 'kernel_size_2': 7, 'num_filters_2': 79}"}}
exception: None

04:58:18 job_callback for (8, 0, 12) started
04:58:18 DISPATCHER: Trying to submit another job.
04:58:18 job_callback for (8, 0, 12) got condition
04:58:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:58:18 HBMASTER: Trying to run another job!
04:58:18 job_callback for (8, 0, 12) finished
04:58:18 start sampling a new configuration.
04:58:18 best_vector: [3, 0, 0.010203061340502265, 0.21415204852483435, 0.5197649054886686, 1, 0.9495757547592673, 0.15340226923925485, 1, 2, 0, 1, 0.33593524430929267, 0.6426668156807974, 0.31590434535379774, 0.7287855728129241], 5.503778956376216e-31, 0.01816933434147976, -6.17635851493114e-05
04:58:18 done sampling a new configuration.
04:58:18 HBMASTER: schedule new run for iteration 9
04:58:18 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
04:58:18 HBMASTER: submitting job (9, 0, 0) to dispatcher
04:58:18 DISPATCHER: trying to submit job (9, 0, 0)
04:58:18 DISPATCHER: trying to notify the job_runner thread.
04:58:18 HBMASTER: job (9, 0, 0) submitted to dispatcher
04:58:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:58:18 DISPATCHER: Trying to submit another job.
04:58:18 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:58:18 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
04:58:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:58:18 WORKER: start processing job (9, 0, 0)
04:58:18 WORKER: args: ()
04:58:18 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001048108209481976, 'num_filters_1': 24, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.015833646827222048, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 32, 'num_filters_3': 60}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:58:58 DISPATCHER: Starting worker discovery
04:58:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:58:58 DISPATCHER: Finished worker discovery
04:59:58 DISPATCHER: Starting worker discovery
04:59:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:59:58 DISPATCHER: Finished worker discovery
05:00:51 WORKER: done with job (9, 0, 0), trying to register it.
05:00:51 WORKER: registered result for job (9, 0, 0) with dispatcher
05:00:51 DISPATCHER: job (9, 0, 0) finished
05:00:51 DISPATCHER: register_result: lock acquired
05:00:51 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
05:00:51 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001048108209481976, 'num_filters_1': 24, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.015833646827222048, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 32, 'num_filters_3': 60}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.125258163982646, 'info': {'data04': 0.125258163982646, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001048108209481976, 'num_filters_1': 24, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.015833646827222048, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 32, 'num_filters_3': 60}"}}
exception: None

05:00:51 job_callback for (9, 0, 0) started
05:00:51 DISPATCHER: Trying to submit another job.
05:00:51 job_callback for (9, 0, 0) got condition
05:00:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:00:51 done building a new model for budget 133.333333 based on 17/39 split
Best loss for this budget:-0.183160





05:00:51 HBMASTER: Trying to run another job!
05:00:51 job_callback for (9, 0, 0) finished
05:00:51 start sampling a new configuration.
05:00:51 best_vector: [0, 2, 0.32568980943624476, 0.8831593311704922, 0.8160235619092007, 1, 0.21229430954615403, 0.34400002605147884, 1, 0, 1, 2, 0.16058539704657426, 0.3687832486590399, 0.7484396758636569, 0.6089080465925542], 4.378498017807159e-30, 0.002283888209913637, -0.00021869834023743902
05:00:51 done sampling a new configuration.
05:00:51 HBMASTER: schedule new run for iteration 9
05:00:51 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
05:00:51 HBMASTER: submitting job (9, 0, 1) to dispatcher
05:00:51 DISPATCHER: trying to submit job (9, 0, 1)
05:00:51 DISPATCHER: trying to notify the job_runner thread.
05:00:51 HBMASTER: job (9, 0, 1) submitted to dispatcher
05:00:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:00:51 DISPATCHER: Trying to submit another job.
05:00:51 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:00:51 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:00:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:00:51 WORKER: start processing job (9, 0, 1)
05:00:51 WORKER: args: ()
05:00:51 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.004481048235947966, 'num_filters_1': 100, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.02802556342535435, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 34, 'num_filters_4': 75, 'num_filters_5': 56}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:00:58 DISPATCHER: Starting worker discovery
05:00:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:00:58 DISPATCHER: Finished worker discovery
05:01:58 DISPATCHER: Starting worker discovery
05:01:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:01:58 DISPATCHER: Finished worker discovery
05:02:58 DISPATCHER: Starting worker discovery
05:02:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:02:58 DISPATCHER: Finished worker discovery
05:03:33 WORKER: done with job (9, 0, 1), trying to register it.
05:03:33 WORKER: registered result for job (9, 0, 1) with dispatcher
05:03:33 DISPATCHER: job (9, 0, 1) finished
05:03:33 DISPATCHER: register_result: lock acquired
05:03:33 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
05:03:33 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.004481048235947966, 'num_filters_1': 100, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.02802556342535435, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 34, 'num_filters_4': 75, 'num_filters_5': 56}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.13364943409593458, 'info': {'data04': 0.13364943409593458, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.004481048235947966, 'num_filters_1': 100, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.02802556342535435, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 34, 'num_filters_4': 75, 'num_filters_5': 56}"}}
exception: None

05:03:33 job_callback for (9, 0, 1) started
05:03:33 DISPATCHER: Trying to submit another job.
05:03:33 job_callback for (9, 0, 1) got condition
05:03:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:03:33 done building a new model for budget 133.333333 based on 17/39 split
Best loss for this budget:-0.183160





05:03:33 HBMASTER: Trying to run another job!
05:03:33 job_callback for (9, 0, 1) finished
05:03:33 start sampling a new configuration.
05:03:33 done sampling a new configuration.
05:03:33 HBMASTER: schedule new run for iteration 9
05:03:33 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
05:03:33 HBMASTER: submitting job (9, 0, 2) to dispatcher
05:03:33 DISPATCHER: trying to submit job (9, 0, 2)
05:03:33 DISPATCHER: trying to notify the job_runner thread.
05:03:33 HBMASTER: job (9, 0, 2) submitted to dispatcher
05:03:33 DISPATCHER: Trying to submit another job.
05:03:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:03:33 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:03:33 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:03:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:03:33 WORKER: start processing job (9, 0, 2)
05:03:33 WORKER: args: ()
05:03:33 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.013814447199824798, 'num_filters_1': 103, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.18124175969100026, 'kernel_size_2': 3, 'num_filters_2': 56}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:03:58 DISPATCHER: Starting worker discovery
05:03:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:03:58 DISPATCHER: Finished worker discovery
05:04:58 DISPATCHER: Starting worker discovery
05:04:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:04:58 DISPATCHER: Finished worker discovery
05:05:58 DISPATCHER: Starting worker discovery
05:05:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:05:58 DISPATCHER: Finished worker discovery
05:06:06 WORKER: done with job (9, 0, 2), trying to register it.
05:06:06 WORKER: registered result for job (9, 0, 2) with dispatcher
05:06:06 DISPATCHER: job (9, 0, 2) finished
05:06:06 DISPATCHER: register_result: lock acquired
05:06:06 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
05:06:06 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.013814447199824798, 'num_filters_1': 103, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.18124175969100026, 'kernel_size_2': 3, 'num_filters_2': 56}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.002417800061251429, 'info': {'data04': 0.002417800061251429, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.013814447199824798, 'num_filters_1': 103, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.18124175969100026, 'kernel_size_2': 3, 'num_filters_2': 56}"}}
exception: None

05:06:06 job_callback for (9, 0, 2) started
05:06:06 DISPATCHER: Trying to submit another job.
05:06:06 job_callback for (9, 0, 2) got condition
05:06:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:06:07 done building a new model for budget 133.333333 based on 17/40 split
Best loss for this budget:-0.183160





05:06:07 HBMASTER: Trying to run another job!
05:06:07 job_callback for (9, 0, 2) finished
05:06:07 start sampling a new configuration.
05:06:07 best_vector: [3, 1, 0.15489103186411313, 0.24278145571717533, 0.3407899297950459, 1, 0.3338423178949569, 0.17808140257308996, 2, 1, 0, 1, 0.5619941701831334, 0.656932856684064, 0.6085233106034864, 0.7042332349467242], 3.406643695471119e-31, 0.0293544053735184, -0.0017003290477625832
05:06:07 done sampling a new configuration.
05:06:07 HBMASTER: schedule new run for iteration 9
05:06:07 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
05:06:07 HBMASTER: submitting job (9, 0, 3) to dispatcher
05:06:07 DISPATCHER: trying to submit job (9, 0, 3)
05:06:07 DISPATCHER: trying to notify the job_runner thread.
05:06:07 HBMASTER: job (9, 0, 3) submitted to dispatcher
05:06:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:06:07 DISPATCHER: Trying to submit another job.
05:06:07 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:06:07 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:06:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:06:07 WORKER: start processing job (9, 0, 3)
05:06:07 WORKER: args: ()
05:06:07 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0020407136232783794, 'num_filters_1': 26, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.017048620613146805, 'kernel_size_2': 7, 'num_filters_2': 51}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:06:58 DISPATCHER: Starting worker discovery
05:06:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:06:58 DISPATCHER: Finished worker discovery
05:07:58 DISPATCHER: Starting worker discovery
05:07:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:07:58 DISPATCHER: Finished worker discovery
05:08:47 WORKER: done with job (9, 0, 3), trying to register it.
05:08:47 WORKER: registered result for job (9, 0, 3) with dispatcher
05:08:47 DISPATCHER: job (9, 0, 3) finished
05:08:47 DISPATCHER: register_result: lock acquired
05:08:47 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
05:08:47 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0020407136232783794, 'num_filters_1': 26, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.017048620613146805, 'kernel_size_2': 7, 'num_filters_2': 51}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.17027734974895387, 'info': {'data04': 0.17027734974895387, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0020407136232783794, 'num_filters_1': 26, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.017048620613146805, 'kernel_size_2': 7, 'num_filters_2': 51}"}}
exception: None

05:08:47 job_callback for (9, 0, 3) started
05:08:47 job_callback for (9, 0, 3) got condition
05:08:47 DISPATCHER: Trying to submit another job.
05:08:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:08:47 done building a new model for budget 133.333333 based on 17/41 split
Best loss for this budget:-0.183160





05:08:47 HBMASTER: Trying to run another job!
05:08:47 job_callback for (9, 0, 3) finished
05:08:47 start sampling a new configuration.
05:08:47 best_vector: [2, 1, 0.01732770692332379, 0.6548093700901281, 0.4469395481221942, 1, 0.561885120751741, 0.26122430024526283, 1, 1, 2, 1, 0.1107542417529101, 0.07257328025467516, 0.7332357936703637, 0.7432553358686893], 2.439701774856629e-30, 0.0040988616326221505, -5.871715209212143e-05
05:08:47 done sampling a new configuration.
05:08:47 HBMASTER: schedule new run for iteration 9
05:08:47 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
05:08:47 HBMASTER: submitting job (9, 0, 4) to dispatcher
05:08:47 DISPATCHER: trying to submit job (9, 0, 4)
05:08:47 DISPATCHER: trying to notify the job_runner thread.
05:08:47 HBMASTER: job (9, 0, 4) submitted to dispatcher
05:08:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:08:47 DISPATCHER: Trying to submit another job.
05:08:47 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:08:47 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:08:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:08:47 WORKER: start processing job (9, 0, 4)
05:08:47 WORKER: args: ()
05:08:47 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0010830672252999016, 'num_filters_1': 62, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.021870597609997145, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 20, 'num_filters_3': 18}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:08:58 DISPATCHER: Starting worker discovery
05:08:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:08:58 DISPATCHER: Finished worker discovery
05:09:58 DISPATCHER: Starting worker discovery
05:09:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:09:58 DISPATCHER: Finished worker discovery
05:10:58 DISPATCHER: Starting worker discovery
05:10:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:10:58 DISPATCHER: Finished worker discovery
05:11:23 WORKER: done with job (9, 0, 4), trying to register it.
05:11:23 WORKER: registered result for job (9, 0, 4) with dispatcher
05:11:23 DISPATCHER: job (9, 0, 4) finished
05:11:23 DISPATCHER: register_result: lock acquired
05:11:23 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
05:11:23 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0010830672252999016, 'num_filters_1': 62, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.021870597609997145, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 20, 'num_filters_3': 18}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1691616981194115, 'info': {'data04': 0.1691616981194115, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0010830672252999016, 'num_filters_1': 62, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.021870597609997145, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 20, 'num_filters_3': 18}"}}
exception: None

05:11:23 job_callback for (9, 0, 4) started
05:11:23 job_callback for (9, 0, 4) got condition
05:11:23 DISPATCHER: Trying to submit another job.
05:11:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:11:23 done building a new model for budget 133.333333 based on 17/42 split
Best loss for this budget:-0.183160





05:11:23 HBMASTER: Trying to run another job!
05:11:23 job_callback for (9, 0, 4) finished
05:11:23 start sampling a new configuration.
05:11:23 done sampling a new configuration.
05:11:23 HBMASTER: schedule new run for iteration 9
05:11:23 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
05:11:23 HBMASTER: submitting job (9, 0, 5) to dispatcher
05:11:23 DISPATCHER: trying to submit job (9, 0, 5)
05:11:23 DISPATCHER: trying to notify the job_runner thread.
05:11:23 HBMASTER: job (9, 0, 5) submitted to dispatcher
05:11:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:11:23 DISPATCHER: Trying to submit another job.
05:11:23 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:11:23 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:11:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:11:23 WORKER: start processing job (9, 0, 5)
05:11:23 WORKER: args: ()
05:11:23 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.009304931942358444, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.16934073192563961, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 103, 'num_filters_3': 111, 'num_filters_4': 110, 'num_filters_5': 31}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:11:58 DISPATCHER: Starting worker discovery
05:11:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:11:58 DISPATCHER: Finished worker discovery
05:12:58 DISPATCHER: Starting worker discovery
05:12:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:12:58 DISPATCHER: Finished worker discovery
05:13:55 WORKER: done with job (9, 0, 5), trying to register it.
05:13:55 WORKER: registered result for job (9, 0, 5) with dispatcher
05:13:55 DISPATCHER: job (9, 0, 5) finished
05:13:55 DISPATCHER: register_result: lock acquired
05:13:55 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
05:13:55 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.009304931942358444, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.16934073192563961, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 103, 'num_filters_3': 111, 'num_filters_4': 110, 'num_filters_5': 31}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.009304931942358444, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.16934073192563961, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 103, 'num_filters_3': 111, 'num_filters_4': 110, 'num_filters_5': 31}"}}
exception: None

05:13:55 job_callback for (9, 0, 5) started
05:13:55 DISPATCHER: Trying to submit another job.
05:13:55 job_callback for (9, 0, 5) got condition
05:13:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:13:55 done building a new model for budget 133.333333 based on 17/43 split
Best loss for this budget:-0.183160





05:13:55 HBMASTER: Trying to run another job!
05:13:55 job_callback for (9, 0, 5) finished
05:13:55 start sampling a new configuration.
05:13:55 done sampling a new configuration.
05:13:55 HBMASTER: schedule new run for iteration 9
05:13:55 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
05:13:55 HBMASTER: submitting job (9, 0, 6) to dispatcher
05:13:55 DISPATCHER: trying to submit job (9, 0, 6)
05:13:55 DISPATCHER: trying to notify the job_runner thread.
05:13:55 HBMASTER: job (9, 0, 6) submitted to dispatcher
05:13:55 DISPATCHER: Trying to submit another job.
05:13:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:13:55 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:13:55 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:13:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:13:55 WORKER: start processing job (9, 0, 6)
05:13:55 WORKER: args: ()
05:13:55 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.010550005178308163, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.029703691603653246, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 122, 'num_filters_3': 26, 'num_filters_4': 71}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:13:58 DISPATCHER: Starting worker discovery
05:13:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:13:58 DISPATCHER: Finished worker discovery
05:14:58 DISPATCHER: Starting worker discovery
05:14:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:14:58 DISPATCHER: Finished worker discovery
05:15:58 DISPATCHER: Starting worker discovery
05:15:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:15:58 DISPATCHER: Finished worker discovery
05:16:31 WORKER: done with job (9, 0, 6), trying to register it.
05:16:31 WORKER: registered result for job (9, 0, 6) with dispatcher
05:16:31 DISPATCHER: job (9, 0, 6) finished
05:16:31 DISPATCHER: register_result: lock acquired
05:16:31 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
05:16:31 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.010550005178308163, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.029703691603653246, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 122, 'num_filters_3': 26, 'num_filters_4': 71}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data04': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.010550005178308163, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.029703691603653246, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 122, 'num_filters_3': 26, 'num_filters_4': 71}"}}
exception: None

05:16:31 job_callback for (9, 0, 6) started
05:16:31 DISPATCHER: Trying to submit another job.
05:16:31 job_callback for (9, 0, 6) got condition
05:16:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:16:31 done building a new model for budget 133.333333 based on 17/44 split
Best loss for this budget:-0.183160





05:16:31 HBMASTER: Trying to run another job!
05:16:31 job_callback for (9, 0, 6) finished
05:16:31 start sampling a new configuration.
05:16:31 done sampling a new configuration.
05:16:31 HBMASTER: schedule new run for iteration 9
05:16:31 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
05:16:31 HBMASTER: submitting job (9, 0, 7) to dispatcher
05:16:31 DISPATCHER: trying to submit job (9, 0, 7)
05:16:31 DISPATCHER: trying to notify the job_runner thread.
05:16:31 HBMASTER: job (9, 0, 7) submitted to dispatcher
05:16:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:16:31 DISPATCHER: Trying to submit another job.
05:16:31 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:16:31 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:16:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:16:31 WORKER: start processing job (9, 0, 7)
05:16:31 WORKER: args: ()
05:16:31 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.01163584889246641, 'num_filters_1': 111, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.022111447968729218, 'kernel_size_2': 5, 'num_filters_2': 89}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:16:58 DISPATCHER: Starting worker discovery
05:16:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:16:58 DISPATCHER: Finished worker discovery
05:17:58 DISPATCHER: Starting worker discovery
05:17:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:17:58 DISPATCHER: Finished worker discovery
05:18:58 DISPATCHER: Starting worker discovery
05:18:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:18:58 DISPATCHER: Finished worker discovery
05:19:06 WORKER: done with job (9, 0, 7), trying to register it.
05:19:06 WORKER: registered result for job (9, 0, 7) with dispatcher
05:19:06 DISPATCHER: job (9, 0, 7) finished
05:19:06 DISPATCHER: register_result: lock acquired
05:19:06 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
05:19:06 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.01163584889246641, 'num_filters_1': 111, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.022111447968729218, 'kernel_size_2': 5, 'num_filters_2': 89}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': 2.6495835287609424e-05, 'info': {'data04': -2.6495835287609424e-05, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.01163584889246641, 'num_filters_1': 111, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.022111447968729218, 'kernel_size_2': 5, 'num_filters_2': 89}"}}
exception: None

05:19:06 job_callback for (9, 0, 7) started
05:19:06 job_callback for (9, 0, 7) got condition
05:19:06 DISPATCHER: Trying to submit another job.
05:19:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:19:06 done building a new model for budget 133.333333 based on 17/45 split
Best loss for this budget:-0.183160





05:19:06 HBMASTER: Trying to run another job!
05:19:06 job_callback for (9, 0, 7) finished
05:19:06 start sampling a new configuration.
05:19:06 best_vector: [0, 0, 0.29905969050225867, 0.7239304814524502, 0.7728723739524231, 1, 0.8409816361838425, 0.36651979086796704, 2, 0, 0, 1, 0.5312311226420695, 0.00851999350620769, 0.9135985387105107, 0.691106660836913], 2.755801797405516e-31, 0.03628707989600204, -1.3360856549809426e-05
05:19:06 done sampling a new configuration.
05:19:06 HBMASTER: schedule new run for iteration 9
05:19:06 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
05:19:06 HBMASTER: submitting job (9, 0, 8) to dispatcher
05:19:06 DISPATCHER: trying to submit job (9, 0, 8)
05:19:06 DISPATCHER: trying to notify the job_runner thread.
05:19:06 HBMASTER: job (9, 0, 8) submitted to dispatcher
05:19:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:19:06 DISPATCHER: Trying to submit another job.
05:19:06 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:19:06 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:19:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:19:06 WORKER: start processing job (9, 0, 8)
05:19:06 WORKER: args: ()
05:19:06 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003963869800848308, 'num_filters_1': 72, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.02998149204336304, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 48, 'num_filters_3': 16, 'num_filters_4': 107}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:19:58 DISPATCHER: Starting worker discovery
05:19:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:19:58 DISPATCHER: Finished worker discovery
05:20:58 DISPATCHER: Starting worker discovery
05:20:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:20:58 DISPATCHER: Finished worker discovery
05:21:39 WORKER: done with job (9, 0, 8), trying to register it.
05:21:39 WORKER: registered result for job (9, 0, 8) with dispatcher
05:21:39 DISPATCHER: job (9, 0, 8) finished
05:21:39 DISPATCHER: register_result: lock acquired
05:21:39 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
05:21:39 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003963869800848308, 'num_filters_1': 72, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.02998149204336304, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 48, 'num_filters_3': 16, 'num_filters_4': 107}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1546579150510147, 'info': {'data04': 0.1546579150510147, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003963869800848308, 'num_filters_1': 72, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.02998149204336304, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 48, 'num_filters_3': 16, 'num_filters_4': 107}"}}
exception: None

05:21:39 job_callback for (9, 0, 8) started
05:21:39 job_callback for (9, 0, 8) got condition
05:21:39 DISPATCHER: Trying to submit another job.
05:21:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:21:39 done building a new model for budget 133.333333 based on 17/45 split
Best loss for this budget:-0.183160





05:21:39 HBMASTER: Trying to run another job!
05:21:39 job_callback for (9, 0, 8) finished
05:21:39 ITERATION: Advancing config (9, 0, 3) to next budget 400.000000
05:21:39 ITERATION: Advancing config (9, 0, 4) to next budget 400.000000
05:21:39 ITERATION: Advancing config (9, 0, 8) to next budget 400.000000
05:21:39 HBMASTER: schedule new run for iteration 9
05:21:39 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
05:21:39 HBMASTER: submitting job (9, 0, 3) to dispatcher
05:21:39 DISPATCHER: trying to submit job (9, 0, 3)
05:21:39 DISPATCHER: trying to notify the job_runner thread.
05:21:39 HBMASTER: job (9, 0, 3) submitted to dispatcher
05:21:39 DISPATCHER: Trying to submit another job.
05:21:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:21:39 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:21:39 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:21:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:21:39 WORKER: start processing job (9, 0, 3)
05:21:39 WORKER: args: ()
05:21:39 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0020407136232783794, 'num_filters_1': 26, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.017048620613146805, 'kernel_size_2': 7, 'num_filters_2': 51}, 'budget': 400.0, 'working_directory': '.'}
05:21:58 DISPATCHER: Starting worker discovery
05:21:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:21:58 DISPATCHER: Finished worker discovery
05:22:58 DISPATCHER: Starting worker discovery
05:22:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:22:58 DISPATCHER: Finished worker discovery
05:23:58 DISPATCHER: Starting worker discovery
05:23:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:23:58 DISPATCHER: Finished worker discovery
05:24:58 DISPATCHER: Starting worker discovery
05:24:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:24:58 DISPATCHER: Finished worker discovery
05:25:58 DISPATCHER: Starting worker discovery
05:25:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:25:58 DISPATCHER: Finished worker discovery
05:26:58 DISPATCHER: Starting worker discovery
05:26:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:26:58 DISPATCHER: Finished worker discovery
05:27:58 DISPATCHER: Starting worker discovery
05:27:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:27:58 DISPATCHER: Finished worker discovery
05:28:58 DISPATCHER: Starting worker discovery
05:28:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:28:58 DISPATCHER: Finished worker discovery
05:29:11 WORKER: done with job (9, 0, 3), trying to register it.
05:29:11 WORKER: registered result for job (9, 0, 3) with dispatcher
05:29:11 DISPATCHER: job (9, 0, 3) finished
05:29:11 DISPATCHER: register_result: lock acquired
05:29:11 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
05:29:11 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0020407136232783794, 'num_filters_1': 26, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.017048620613146805, 'kernel_size_2': 7, 'num_filters_2': 51}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.14439477449025453, 'info': {'data04': 0.14439477449025453, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0020407136232783794, 'num_filters_1': 26, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.017048620613146805, 'kernel_size_2': 7, 'num_filters_2': 51}"}}
exception: None

05:29:11 job_callback for (9, 0, 3) started
05:29:11 DISPATCHER: Trying to submit another job.
05:29:11 job_callback for (9, 0, 3) got condition
05:29:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:29:11 HBMASTER: Trying to run another job!
05:29:11 job_callback for (9, 0, 3) finished
05:29:11 HBMASTER: schedule new run for iteration 9
05:29:11 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
05:29:11 HBMASTER: submitting job (9, 0, 4) to dispatcher
05:29:11 DISPATCHER: trying to submit job (9, 0, 4)
05:29:11 DISPATCHER: trying to notify the job_runner thread.
05:29:11 HBMASTER: job (9, 0, 4) submitted to dispatcher
05:29:11 DISPATCHER: Trying to submit another job.
05:29:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:29:11 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:29:11 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:29:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:29:11 WORKER: start processing job (9, 0, 4)
05:29:11 WORKER: args: ()
05:29:11 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0010830672252999016, 'num_filters_1': 62, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.021870597609997145, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 20, 'num_filters_3': 18}, 'budget': 400.0, 'working_directory': '.'}
05:29:58 DISPATCHER: Starting worker discovery
05:29:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:29:58 DISPATCHER: Finished worker discovery
05:30:58 DISPATCHER: Starting worker discovery
05:30:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:30:58 DISPATCHER: Finished worker discovery
05:31:58 DISPATCHER: Starting worker discovery
05:31:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:31:58 DISPATCHER: Finished worker discovery
05:32:58 DISPATCHER: Starting worker discovery
05:32:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:32:58 DISPATCHER: Finished worker discovery
05:33:58 DISPATCHER: Starting worker discovery
05:33:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:33:58 DISPATCHER: Finished worker discovery
05:34:58 DISPATCHER: Starting worker discovery
05:34:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:34:58 DISPATCHER: Finished worker discovery
05:35:58 DISPATCHER: Starting worker discovery
05:35:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:35:58 DISPATCHER: Finished worker discovery
05:36:30 WORKER: done with job (9, 0, 4), trying to register it.
05:36:30 WORKER: registered result for job (9, 0, 4) with dispatcher
05:36:30 DISPATCHER: job (9, 0, 4) finished
05:36:30 DISPATCHER: register_result: lock acquired
05:36:30 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
05:36:30 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0010830672252999016, 'num_filters_1': 62, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.021870597609997145, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 20, 'num_filters_3': 18}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.13666831421199246, 'info': {'data04': 0.13666831421199246, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0010830672252999016, 'num_filters_1': 62, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.021870597609997145, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 20, 'num_filters_3': 18}"}}
exception: None

05:36:30 job_callback for (9, 0, 4) started
05:36:30 job_callback for (9, 0, 4) got condition
05:36:30 DISPATCHER: Trying to submit another job.
05:36:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:36:30 HBMASTER: Trying to run another job!
05:36:30 job_callback for (9, 0, 4) finished
05:36:30 HBMASTER: schedule new run for iteration 9
05:36:30 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
05:36:30 HBMASTER: submitting job (9, 0, 8) to dispatcher
05:36:30 DISPATCHER: trying to submit job (9, 0, 8)
05:36:30 DISPATCHER: trying to notify the job_runner thread.
05:36:30 HBMASTER: job (9, 0, 8) submitted to dispatcher
05:36:30 DISPATCHER: Trying to submit another job.
05:36:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:36:30 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:36:30 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:36:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:36:30 WORKER: start processing job (9, 0, 8)
05:36:30 WORKER: args: ()
05:36:30 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003963869800848308, 'num_filters_1': 72, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.02998149204336304, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 48, 'num_filters_3': 16, 'num_filters_4': 107}, 'budget': 400.0, 'working_directory': '.'}
05:36:58 DISPATCHER: Starting worker discovery
05:36:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:36:58 DISPATCHER: Finished worker discovery
05:37:58 DISPATCHER: Starting worker discovery
05:37:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:37:58 DISPATCHER: Finished worker discovery
05:38:58 DISPATCHER: Starting worker discovery
05:38:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:38:58 DISPATCHER: Finished worker discovery
05:39:58 DISPATCHER: Starting worker discovery
05:39:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:39:58 DISPATCHER: Finished worker discovery
05:40:58 DISPATCHER: Starting worker discovery
05:40:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:40:58 DISPATCHER: Finished worker discovery
05:41:58 DISPATCHER: Starting worker discovery
05:41:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:41:58 DISPATCHER: Finished worker discovery
05:42:58 DISPATCHER: Starting worker discovery
05:42:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:42:58 DISPATCHER: Finished worker discovery
05:43:43 WORKER: done with job (9, 0, 8), trying to register it.
05:43:43 WORKER: registered result for job (9, 0, 8) with dispatcher
05:43:43 DISPATCHER: job (9, 0, 8) finished
05:43:43 DISPATCHER: register_result: lock acquired
05:43:43 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
05:43:43 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003963869800848308, 'num_filters_1': 72, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.02998149204336304, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 48, 'num_filters_3': 16, 'num_filters_4': 107}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.07882560209010775, 'info': {'data04': 0.07882560209010775, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003963869800848308, 'num_filters_1': 72, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.02998149204336304, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 48, 'num_filters_3': 16, 'num_filters_4': 107}"}}
exception: None

05:43:43 job_callback for (9, 0, 8) started
05:43:43 job_callback for (9, 0, 8) got condition
05:43:43 DISPATCHER: Trying to submit another job.
05:43:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:43:43 HBMASTER: Trying to run another job!
05:43:43 job_callback for (9, 0, 8) finished
05:43:43 ITERATION: Advancing config (9, 0, 3) to next budget 1200.000000
05:43:43 HBMASTER: schedule new run for iteration 9
05:43:43 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
05:43:43 HBMASTER: submitting job (9, 0, 3) to dispatcher
05:43:43 DISPATCHER: trying to submit job (9, 0, 3)
05:43:43 DISPATCHER: trying to notify the job_runner thread.
05:43:43 HBMASTER: job (9, 0, 3) submitted to dispatcher
05:43:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:43:43 DISPATCHER: Trying to submit another job.
05:43:43 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:43:43 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpuj.13102140436472194880
05:43:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:43:43 WORKER: start processing job (9, 0, 3)
05:43:43 WORKER: args: ()
05:43:43 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0020407136232783794, 'num_filters_1': 26, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.017048620613146805, 'kernel_size_2': 7, 'num_filters_2': 51}, 'budget': 1200.0, 'working_directory': '.'}
05:43:58 DISPATCHER: Starting worker discovery
05:43:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:43:58 DISPATCHER: Finished worker discovery
05:44:58 DISPATCHER: Starting worker discovery
05:44:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:44:58 DISPATCHER: Finished worker discovery
05:45:58 DISPATCHER: Starting worker discovery
05:45:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:45:58 DISPATCHER: Finished worker discovery
05:46:58 DISPATCHER: Starting worker discovery
05:46:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:46:58 DISPATCHER: Finished worker discovery
05:47:58 DISPATCHER: Starting worker discovery
05:47:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:47:58 DISPATCHER: Finished worker discovery
05:48:58 DISPATCHER: Starting worker discovery
05:48:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:48:58 DISPATCHER: Finished worker discovery
05:49:58 DISPATCHER: Starting worker discovery
05:49:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:49:58 DISPATCHER: Finished worker discovery
05:50:58 DISPATCHER: Starting worker discovery
05:50:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:50:58 DISPATCHER: Finished worker discovery
05:51:58 DISPATCHER: Starting worker discovery
05:51:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:51:58 DISPATCHER: Finished worker discovery
05:52:58 DISPATCHER: Starting worker discovery
05:52:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:52:58 DISPATCHER: Finished worker discovery
05:53:58 DISPATCHER: Starting worker discovery
05:53:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:53:58 DISPATCHER: Finished worker discovery
05:54:58 DISPATCHER: Starting worker discovery
05:54:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:54:58 DISPATCHER: Finished worker discovery
05:55:58 DISPATCHER: Starting worker discovery
05:55:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:55:58 DISPATCHER: Finished worker discovery
05:56:58 DISPATCHER: Starting worker discovery
05:56:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:56:58 DISPATCHER: Finished worker discovery
05:57:58 DISPATCHER: Starting worker discovery
05:57:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:57:58 DISPATCHER: Finished worker discovery
05:58:58 DISPATCHER: Starting worker discovery
05:58:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:58:58 DISPATCHER: Finished worker discovery
05:59:58 DISPATCHER: Starting worker discovery
05:59:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:59:58 DISPATCHER: Finished worker discovery
06:00:58 DISPATCHER: Starting worker discovery
06:00:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:00:58 DISPATCHER: Finished worker discovery
06:01:58 DISPATCHER: Starting worker discovery
06:01:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:01:58 DISPATCHER: Finished worker discovery
06:02:58 DISPATCHER: Starting worker discovery
06:02:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:02:58 DISPATCHER: Finished worker discovery
06:03:58 DISPATCHER: Starting worker discovery
06:03:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:03:59 DISPATCHER: Finished worker discovery
06:04:59 DISPATCHER: Starting worker discovery
06:04:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:04:59 DISPATCHER: Finished worker discovery
06:05:52 WORKER: done with job (9, 0, 3), trying to register it.
06:05:52 WORKER: registered result for job (9, 0, 3) with dispatcher
06:05:52 DISPATCHER: job (9, 0, 3) finished
06:05:52 DISPATCHER: register_result: lock acquired
06:05:52 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpuj.13102140436472194880 finished
06:05:52 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0020407136232783794, 'num_filters_1': 26, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.017048620613146805, 'kernel_size_2': 7, 'num_filters_2': 51}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.12431861537747319, 'info': {'data04': 0.12431861537747319, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0020407136232783794, 'num_filters_1': 26, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.017048620613146805, 'kernel_size_2': 7, 'num_filters_2': 51}"}}
exception: None

06:05:52 job_callback for (9, 0, 3) started
06:05:52 job_callback for (9, 0, 3) got condition
06:05:52 DISPATCHER: Trying to submit another job.
06:05:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:05:52 HBMASTER: Trying to run another job!
06:05:52 job_callback for (9, 0, 3) finished
06:05:52 HBMASTER: shutdown initiated, shutdown_workers = True
06:05:52 WORKER: shutting down now!
06:05:52 DISPATCHER: Dispatcher shutting down
06:05:52 DISPATCHER: discover_workers shutting down
06:05:52 DISPATCHER: Trying to submit another job.
06:05:52 DISPATCHER: 'discover_worker' thread exited
06:05:52 DISPATCHER: job_runner shutting down
06:05:52 DISPATCHER: 'job_runner' thread exited
06:05:52 DISPATCHER: shut down complete
