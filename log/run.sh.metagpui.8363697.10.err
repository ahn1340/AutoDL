/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
WARNING:tensorflow:From /home/ahnj/repo/autodl/AutoDL/model.py:27: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /home/ahnj/repo/autodl/AutoDL/model.py:31: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-03-09 22:02:28.406960: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-03-09 22:02:28.410900: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299865000 Hz
2020-03-09 22:02:28.411313: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5633e54a7fa0 executing computations on platform Host. Devices:
2020-03-09 22:02:28.411331: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-03-09 22:02:28.411840: I tensorflow/core/common_runtime/direct_session.cc:296] Device mapping:
/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device

22:02:28 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7f4dcac88668; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:39294>
22:02:28 WORKER: No dispatcher found. Waiting for one to initiate contact.
22:02:28 WORKER: start listening for jobs
22:02:28 wait_for_workers trying to get the condition
22:02:28 DISPATCHER: started the 'discover_worker' thread
22:02:28 DISPATCHER: started the 'job_runner' thread
22:02:28 DISPATCHER: Pyro daemon running on localhost:44155
22:02:28 DISPATCHER: Starting worker discovery
22:02:28 DISPATCHER: Found 1 potential workers, 0 currently in the pool.
22:02:28 DISPATCHER: discovered new worker, hpbandster.run_0.worker.metagpui.1576139975513683776
22:02:28 HBMASTER: number of workers changed to 1
22:02:28 Enough workers to start this run!
22:02:28 adjust_queue_size: lock accquired
22:02:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:02:28 HBMASTER: starting run at 1583787748.508815
22:02:28 HBMASTER: adjusted queue size to (0, 1)
22:02:28 DISPATCHER: Finished worker discovery
22:02:28 start sampling a new configuration.
22:02:28 DISPATCHER: Trying to submit another job.
22:02:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:02:28 done sampling a new configuration.
22:02:28 HBMASTER: schedule new run for iteration 0
22:02:28 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
22:02:28 HBMASTER: submitting job (0, 0, 0) to dispatcher
22:02:28 DISPATCHER: trying to submit job (0, 0, 0)
22:02:28 DISPATCHER: trying to notify the job_runner thread.
22:02:28 HBMASTER: job (0, 0, 0) submitted to dispatcher
22:02:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:02:28 DISPATCHER: Trying to submit another job.
22:02:28 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:02:28 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:02:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:02:28 WORKER: start processing job (0, 0, 0)
22:02:28 WORKER: args: ()
22:02:28 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 397, 'last_n_outputs': 29, 'leak_rate': 0.8158215223012006, 'lr': 0.09965070642454588, 'optimizer': 'Adam', 'sparsity': 0.8127607681578253, 'steps_to_train': 31, 'weight_decay': 0.04958362608638405}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:03:28 DISPATCHER: Starting worker discovery
22:03:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:03:28 DISPATCHER: Finished worker discovery
22:04:14 WORKER: done with job (0, 0, 0), trying to register it.
22:04:14 WORKER: registered result for job (0, 0, 0) with dispatcher
22:04:14 DISPATCHER: job (0, 0, 0) finished
22:04:14 DISPATCHER: register_result: lock acquired
22:04:14 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:04:14 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 397, 'last_n_outputs': 29, 'leak_rate': 0.8158215223012006, 'lr': 0.09965070642454588, 'optimizer': 'Adam', 'sparsity': 0.8127607681578253, 'steps_to_train': 31, 'weight_decay': 0.04958362608638405}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.24243609074262049, 'info': {'data03': 0.24243609074262049, 'config': "{'batch_size': 128, 'hidden_dim': 397, 'last_n_outputs': 29, 'leak_rate': 0.8158215223012006, 'lr': 0.09965070642454588, 'optimizer': 'Adam', 'sparsity': 0.8127607681578253, 'steps_to_train': 31, 'weight_decay': 0.04958362608638405}"}}
exception: None

22:04:14 job_callback for (0, 0, 0) started
22:04:14 DISPATCHER: Trying to submit another job.
22:04:14 job_callback for (0, 0, 0) got condition
22:04:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:04:14 Only 1 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
22:04:14 HBMASTER: Trying to run another job!
22:04:14 job_callback for (0, 0, 0) finished
22:04:14 start sampling a new configuration.
22:04:14 done sampling a new configuration.
22:04:14 HBMASTER: schedule new run for iteration 0
22:04:14 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
22:04:14 HBMASTER: submitting job (0, 0, 1) to dispatcher
22:04:14 DISPATCHER: trying to submit job (0, 0, 1)
22:04:14 DISPATCHER: trying to notify the job_runner thread.
22:04:14 HBMASTER: job (0, 0, 1) submitted to dispatcher
22:04:14 DISPATCHER: Trying to submit another job.
22:04:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:04:14 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:04:14 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:04:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:04:14 WORKER: start processing job (0, 0, 1)
22:04:14 WORKER: args: ()
22:04:14 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 598, 'last_n_outputs': 14, 'leak_rate': 0.7509057750048445, 'lr': 0.034923457841062204, 'optimizer': 'Adam', 'sparsity': 0.8145256422529232, 'steps_to_train': 83, 'weight_decay': 0.15376105908799814}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:04:28 DISPATCHER: Starting worker discovery
22:04:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:04:28 DISPATCHER: Finished worker discovery
22:05:28 DISPATCHER: Starting worker discovery
22:05:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:05:28 DISPATCHER: Finished worker discovery
22:05:38 WORKER: done with job (0, 0, 1), trying to register it.
22:05:38 WORKER: registered result for job (0, 0, 1) with dispatcher
22:05:38 DISPATCHER: job (0, 0, 1) finished
22:05:38 DISPATCHER: register_result: lock acquired
22:05:38 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:05:38 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 598, 'last_n_outputs': 14, 'leak_rate': 0.7509057750048445, 'lr': 0.034923457841062204, 'optimizer': 'Adam', 'sparsity': 0.8145256422529232, 'steps_to_train': 83, 'weight_decay': 0.15376105908799814}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 598, 'last_n_outputs': 14, 'leak_rate': 0.7509057750048445, 'lr': 0.034923457841062204, 'optimizer': 'Adam', 'sparsity': 0.8145256422529232, 'steps_to_train': 83, 'weight_decay': 0.15376105908799814}"}}
exception: None

22:05:38 DISPATCHER: Trying to submit another job.
22:05:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:05:38 job_callback for (0, 0, 1) started
22:05:38 job_callback for (0, 0, 1) got condition
22:05:38 Only 2 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
22:05:38 HBMASTER: Trying to run another job!
22:05:38 job_callback for (0, 0, 1) finished
22:05:38 start sampling a new configuration.
22:05:38 done sampling a new configuration.
22:05:38 HBMASTER: schedule new run for iteration 0
22:05:38 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
22:05:38 HBMASTER: submitting job (0, 0, 2) to dispatcher
22:05:38 DISPATCHER: trying to submit job (0, 0, 2)
22:05:38 DISPATCHER: trying to notify the job_runner thread.
22:05:38 HBMASTER: job (0, 0, 2) submitted to dispatcher
22:05:38 DISPATCHER: Trying to submit another job.
22:05:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:05:38 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:05:38 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:05:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:05:38 WORKER: start processing job (0, 0, 2)
22:05:38 WORKER: args: ()
22:05:38 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 468, 'last_n_outputs': 39, 'leak_rate': 0.9710154144076799, 'lr': 0.0297887874217718, 'optimizer': 'SGD', 'sparsity': 0.9659744322853937, 'steps_to_train': 27, 'weight_decay': 0.026581259925565683}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:06:28 DISPATCHER: Starting worker discovery
22:06:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:06:28 DISPATCHER: Finished worker discovery
22:07:04 WORKER: done with job (0, 0, 2), trying to register it.
22:07:04 WORKER: registered result for job (0, 0, 2) with dispatcher
22:07:04 DISPATCHER: job (0, 0, 2) finished
22:07:04 DISPATCHER: register_result: lock acquired
22:07:04 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:07:04 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 468, 'last_n_outputs': 39, 'leak_rate': 0.9710154144076799, 'lr': 0.0297887874217718, 'optimizer': 'SGD', 'sparsity': 0.9659744322853937, 'steps_to_train': 27, 'weight_decay': 0.026581259925565683}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0005066518094863437, 'info': {'data03': 0.0005066518094863437, 'config': "{'batch_size': 64, 'hidden_dim': 468, 'last_n_outputs': 39, 'leak_rate': 0.9710154144076799, 'lr': 0.0297887874217718, 'optimizer': 'SGD', 'sparsity': 0.9659744322853937, 'steps_to_train': 27, 'weight_decay': 0.026581259925565683}"}}
exception: None

22:07:04 job_callback for (0, 0, 2) started
22:07:04 DISPATCHER: Trying to submit another job.
22:07:04 job_callback for (0, 0, 2) got condition
22:07:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:07:04 Only 3 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
22:07:04 HBMASTER: Trying to run another job!
22:07:04 job_callback for (0, 0, 2) finished
22:07:04 start sampling a new configuration.
22:07:04 done sampling a new configuration.
22:07:04 HBMASTER: schedule new run for iteration 0
22:07:04 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
22:07:04 HBMASTER: submitting job (0, 0, 3) to dispatcher
22:07:04 DISPATCHER: trying to submit job (0, 0, 3)
22:07:04 DISPATCHER: trying to notify the job_runner thread.
22:07:04 HBMASTER: job (0, 0, 3) submitted to dispatcher
22:07:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:07:04 DISPATCHER: Trying to submit another job.
22:07:04 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:07:04 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:07:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:07:04 WORKER: start processing job (0, 0, 3)
22:07:04 WORKER: args: ()
22:07:04 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 596, 'last_n_outputs': 30, 'leak_rate': 0.8409248207361791, 'lr': 0.015439964563484001, 'optimizer': 'Adam', 'sparsity': 0.8188208398247486, 'steps_to_train': 82, 'weight_decay': 0.0854083402505829}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:07:28 DISPATCHER: Starting worker discovery
22:07:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:07:28 DISPATCHER: Finished worker discovery
22:08:28 DISPATCHER: Starting worker discovery
22:08:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:08:28 DISPATCHER: Finished worker discovery
22:09:10 WORKER: done with job (0, 0, 3), trying to register it.
22:09:10 WORKER: registered result for job (0, 0, 3) with dispatcher
22:09:10 DISPATCHER: job (0, 0, 3) finished
22:09:10 DISPATCHER: register_result: lock acquired
22:09:10 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:09:10 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 596, 'last_n_outputs': 30, 'leak_rate': 0.8409248207361791, 'lr': 0.015439964563484001, 'optimizer': 'Adam', 'sparsity': 0.8188208398247486, 'steps_to_train': 82, 'weight_decay': 0.0854083402505829}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2712034250158214, 'info': {'data03': 0.2712034250158214, 'config': "{'batch_size': 16, 'hidden_dim': 596, 'last_n_outputs': 30, 'leak_rate': 0.8409248207361791, 'lr': 0.015439964563484001, 'optimizer': 'Adam', 'sparsity': 0.8188208398247486, 'steps_to_train': 82, 'weight_decay': 0.0854083402505829}"}}
exception: None

22:09:10 job_callback for (0, 0, 3) started
22:09:10 DISPATCHER: Trying to submit another job.
22:09:10 job_callback for (0, 0, 3) got condition
22:09:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:09:10 Only 4 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
22:09:10 HBMASTER: Trying to run another job!
22:09:10 job_callback for (0, 0, 3) finished
22:09:10 start sampling a new configuration.
22:09:10 done sampling a new configuration.
22:09:10 HBMASTER: schedule new run for iteration 0
22:09:10 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
22:09:10 HBMASTER: submitting job (0, 0, 4) to dispatcher
22:09:10 DISPATCHER: trying to submit job (0, 0, 4)
22:09:10 DISPATCHER: trying to notify the job_runner thread.
22:09:10 HBMASTER: job (0, 0, 4) submitted to dispatcher
22:09:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:09:10 DISPATCHER: Trying to submit another job.
22:09:10 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:09:10 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:09:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:09:10 WORKER: start processing job (0, 0, 4)
22:09:10 WORKER: args: ()
22:09:10 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 363, 'last_n_outputs': 19, 'leak_rate': 0.9263289114526321, 'lr': 0.004694060597150371, 'optimizer': 'SGD', 'sparsity': 0.8619818949844559, 'steps_to_train': 94, 'weight_decay': 0.013687285859841882}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:09:28 DISPATCHER: Starting worker discovery
22:09:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:09:28 DISPATCHER: Finished worker discovery
22:10:28 DISPATCHER: Starting worker discovery
22:10:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:10:28 DISPATCHER: Finished worker discovery
22:10:44 WORKER: done with job (0, 0, 4), trying to register it.
22:10:44 WORKER: registered result for job (0, 0, 4) with dispatcher
22:10:44 DISPATCHER: job (0, 0, 4) finished
22:10:44 DISPATCHER: register_result: lock acquired
22:10:44 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:10:44 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 363, 'last_n_outputs': 19, 'leak_rate': 0.9263289114526321, 'lr': 0.004694060597150371, 'optimizer': 'SGD', 'sparsity': 0.8619818949844559, 'steps_to_train': 94, 'weight_decay': 0.013687285859841882}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 363, 'last_n_outputs': 19, 'leak_rate': 0.9263289114526321, 'lr': 0.004694060597150371, 'optimizer': 'SGD', 'sparsity': 0.8619818949844559, 'steps_to_train': 94, 'weight_decay': 0.013687285859841882}"}}
exception: None

22:10:44 job_callback for (0, 0, 4) started
22:10:44 DISPATCHER: Trying to submit another job.
22:10:44 job_callback for (0, 0, 4) got condition
22:10:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:10:44 Only 5 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
22:10:44 HBMASTER: Trying to run another job!
22:10:44 job_callback for (0, 0, 4) finished
22:10:44 start sampling a new configuration.
22:10:44 done sampling a new configuration.
22:10:44 HBMASTER: schedule new run for iteration 0
22:10:44 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
22:10:44 HBMASTER: submitting job (0, 0, 5) to dispatcher
22:10:44 DISPATCHER: trying to submit job (0, 0, 5)
22:10:44 DISPATCHER: trying to notify the job_runner thread.
22:10:44 HBMASTER: job (0, 0, 5) submitted to dispatcher
22:10:44 DISPATCHER: Trying to submit another job.
22:10:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:10:44 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:10:44 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:10:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:10:44 WORKER: start processing job (0, 0, 5)
22:10:44 WORKER: args: ()
22:10:44 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 219, 'last_n_outputs': 37, 'leak_rate': 0.9875848568010764, 'lr': 0.002181549616568998, 'optimizer': 'Adam', 'sparsity': 0.9255766333905023, 'steps_to_train': 84, 'weight_decay': 0.033569594306870405}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:11:28 DISPATCHER: Starting worker discovery
22:11:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:11:28 DISPATCHER: Finished worker discovery
22:12:07 WORKER: done with job (0, 0, 5), trying to register it.
22:12:07 WORKER: registered result for job (0, 0, 5) with dispatcher
22:12:07 DISPATCHER: job (0, 0, 5) finished
22:12:07 DISPATCHER: register_result: lock acquired
22:12:07 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:12:07 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 219, 'last_n_outputs': 37, 'leak_rate': 0.9875848568010764, 'lr': 0.002181549616568998, 'optimizer': 'Adam', 'sparsity': 0.9255766333905023, 'steps_to_train': 84, 'weight_decay': 0.033569594306870405}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 219, 'last_n_outputs': 37, 'leak_rate': 0.9875848568010764, 'lr': 0.002181549616568998, 'optimizer': 'Adam', 'sparsity': 0.9255766333905023, 'steps_to_train': 84, 'weight_decay': 0.033569594306870405}"}}
exception: None

22:12:07 job_callback for (0, 0, 5) started
22:12:07 DISPATCHER: Trying to submit another job.
22:12:07 job_callback for (0, 0, 5) got condition
22:12:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:12:07 Only 6 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
22:12:07 HBMASTER: Trying to run another job!
22:12:07 job_callback for (0, 0, 5) finished
22:12:07 start sampling a new configuration.
22:12:07 done sampling a new configuration.
22:12:07 HBMASTER: schedule new run for iteration 0
22:12:07 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
22:12:07 HBMASTER: submitting job (0, 0, 6) to dispatcher
22:12:07 DISPATCHER: trying to submit job (0, 0, 6)
22:12:07 DISPATCHER: trying to notify the job_runner thread.
22:12:07 HBMASTER: job (0, 0, 6) submitted to dispatcher
22:12:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:12:07 DISPATCHER: Trying to submit another job.
22:12:07 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:12:07 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:12:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:12:07 WORKER: start processing job (0, 0, 6)
22:12:07 WORKER: args: ()
22:12:07 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 999, 'last_n_outputs': 35, 'leak_rate': 0.8807444959697581, 'lr': 0.04254634906054925, 'optimizer': 'Adam', 'sparsity': 0.8701407998877876, 'steps_to_train': 57, 'weight_decay': 0.02455201526799321}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:12:28 DISPATCHER: Starting worker discovery
22:12:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:12:28 DISPATCHER: Finished worker discovery
22:13:28 DISPATCHER: Starting worker discovery
22:13:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:13:28 DISPATCHER: Finished worker discovery
22:13:46 WORKER: done with job (0, 0, 6), trying to register it.
22:13:46 WORKER: registered result for job (0, 0, 6) with dispatcher
22:13:46 DISPATCHER: job (0, 0, 6) finished
22:13:46 DISPATCHER: register_result: lock acquired
22:13:46 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:13:46 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 999, 'last_n_outputs': 35, 'leak_rate': 0.8807444959697581, 'lr': 0.04254634906054925, 'optimizer': 'Adam', 'sparsity': 0.8701407998877876, 'steps_to_train': 57, 'weight_decay': 0.02455201526799321}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1331458776850165, 'info': {'data03': 0.1331458776850165, 'config': "{'batch_size': 16, 'hidden_dim': 999, 'last_n_outputs': 35, 'leak_rate': 0.8807444959697581, 'lr': 0.04254634906054925, 'optimizer': 'Adam', 'sparsity': 0.8701407998877876, 'steps_to_train': 57, 'weight_decay': 0.02455201526799321}"}}
exception: None

22:13:46 job_callback for (0, 0, 6) started
22:13:46 job_callback for (0, 0, 6) got condition
22:13:46 DISPATCHER: Trying to submit another job.
22:13:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:13:46 Only 7 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
22:13:46 HBMASTER: Trying to run another job!
22:13:46 job_callback for (0, 0, 6) finished
22:13:46 start sampling a new configuration.
22:13:46 done sampling a new configuration.
22:13:46 HBMASTER: schedule new run for iteration 0
22:13:46 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
22:13:46 HBMASTER: submitting job (0, 0, 7) to dispatcher
22:13:46 DISPATCHER: trying to submit job (0, 0, 7)
22:13:46 DISPATCHER: trying to notify the job_runner thread.
22:13:46 HBMASTER: job (0, 0, 7) submitted to dispatcher
22:13:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:13:46 DISPATCHER: Trying to submit another job.
22:13:46 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:13:46 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:13:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:13:46 WORKER: start processing job (0, 0, 7)
22:13:46 WORKER: args: ()
22:13:46 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 518, 'last_n_outputs': 11, 'leak_rate': 0.8448502731103271, 'lr': 0.04803397732869763, 'optimizer': 'SGD', 'sparsity': 0.87179050491499, 'steps_to_train': 68, 'weight_decay': 0.011051845253169183}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:14:28 DISPATCHER: Starting worker discovery
22:14:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:14:28 DISPATCHER: Finished worker discovery
22:15:28 DISPATCHER: Starting worker discovery
22:15:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:15:28 DISPATCHER: Finished worker discovery
22:15:36 WORKER: done with job (0, 0, 7), trying to register it.
22:15:36 WORKER: registered result for job (0, 0, 7) with dispatcher
22:15:36 DISPATCHER: job (0, 0, 7) finished
22:15:36 DISPATCHER: register_result: lock acquired
22:15:36 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:15:36 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 518, 'last_n_outputs': 11, 'leak_rate': 0.8448502731103271, 'lr': 0.04803397732869763, 'optimizer': 'SGD', 'sparsity': 0.87179050491499, 'steps_to_train': 68, 'weight_decay': 0.011051845253169183}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.11725365971084234, 'info': {'data03': 0.11725365971084234, 'config': "{'batch_size': 32, 'hidden_dim': 518, 'last_n_outputs': 11, 'leak_rate': 0.8448502731103271, 'lr': 0.04803397732869763, 'optimizer': 'SGD', 'sparsity': 0.87179050491499, 'steps_to_train': 68, 'weight_decay': 0.011051845253169183}"}}
exception: None

22:15:36 job_callback for (0, 0, 7) started
22:15:36 DISPATCHER: Trying to submit another job.
22:15:36 job_callback for (0, 0, 7) got condition
22:15:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:15:36 Only 8 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
22:15:36 HBMASTER: Trying to run another job!
22:15:36 job_callback for (0, 0, 7) finished
22:15:36 start sampling a new configuration.
22:15:36 done sampling a new configuration.
22:15:36 HBMASTER: schedule new run for iteration 0
22:15:36 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
22:15:36 HBMASTER: submitting job (0, 0, 8) to dispatcher
22:15:36 DISPATCHER: trying to submit job (0, 0, 8)
22:15:36 DISPATCHER: trying to notify the job_runner thread.
22:15:36 HBMASTER: job (0, 0, 8) submitted to dispatcher
22:15:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:15:36 DISPATCHER: Trying to submit another job.
22:15:36 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:15:36 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:15:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:15:36 WORKER: start processing job (0, 0, 8)
22:15:36 WORKER: args: ()
22:15:36 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 964, 'last_n_outputs': 26, 'leak_rate': 0.8654640158697281, 'lr': 0.07102109819677269, 'optimizer': 'SGD', 'sparsity': 0.8912177828047229, 'steps_to_train': 45, 'weight_decay': 0.14408170234464507}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:16:28 DISPATCHER: Starting worker discovery
22:16:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:16:28 DISPATCHER: Finished worker discovery
22:17:07 WORKER: done with job (0, 0, 8), trying to register it.
22:17:07 WORKER: registered result for job (0, 0, 8) with dispatcher
22:17:07 DISPATCHER: job (0, 0, 8) finished
22:17:07 DISPATCHER: register_result: lock acquired
22:17:07 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:17:07 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 964, 'last_n_outputs': 26, 'leak_rate': 0.8654640158697281, 'lr': 0.07102109819677269, 'optimizer': 'SGD', 'sparsity': 0.8912177828047229, 'steps_to_train': 45, 'weight_decay': 0.14408170234464507}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 964, 'last_n_outputs': 26, 'leak_rate': 0.8654640158697281, 'lr': 0.07102109819677269, 'optimizer': 'SGD', 'sparsity': 0.8912177828047229, 'steps_to_train': 45, 'weight_decay': 0.14408170234464507}"}}
exception: None

22:17:07 job_callback for (0, 0, 8) started
22:17:07 job_callback for (0, 0, 8) got condition
22:17:07 DISPATCHER: Trying to submit another job.
22:17:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:17:07 Only 9 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
22:17:07 HBMASTER: Trying to run another job!
22:17:07 job_callback for (0, 0, 8) finished
22:17:07 start sampling a new configuration.
22:17:07 done sampling a new configuration.
22:17:07 HBMASTER: schedule new run for iteration 0
22:17:07 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
22:17:07 HBMASTER: submitting job (0, 0, 9) to dispatcher
22:17:07 DISPATCHER: trying to submit job (0, 0, 9)
22:17:07 DISPATCHER: trying to notify the job_runner thread.
22:17:07 HBMASTER: job (0, 0, 9) submitted to dispatcher
22:17:07 DISPATCHER: Trying to submit another job.
22:17:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:17:07 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:17:07 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:17:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:17:07 WORKER: start processing job (0, 0, 9)
22:17:07 WORKER: args: ()
22:17:07 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 595, 'last_n_outputs': 19, 'leak_rate': 0.8210634383315552, 'lr': 0.032807073680396995, 'optimizer': 'SGD', 'sparsity': 0.8897433796506402, 'steps_to_train': 30, 'weight_decay': 0.19330883442945063}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:17:28 DISPATCHER: Starting worker discovery
22:17:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:17:28 DISPATCHER: Finished worker discovery
22:18:28 DISPATCHER: Starting worker discovery
22:18:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:18:28 DISPATCHER: Finished worker discovery
22:18:38 WORKER: done with job (0, 0, 9), trying to register it.
22:18:38 WORKER: registered result for job (0, 0, 9) with dispatcher
22:18:38 DISPATCHER: job (0, 0, 9) finished
22:18:38 DISPATCHER: register_result: lock acquired
22:18:38 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:18:38 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 595, 'last_n_outputs': 19, 'leak_rate': 0.8210634383315552, 'lr': 0.032807073680396995, 'optimizer': 'SGD', 'sparsity': 0.8897433796506402, 'steps_to_train': 30, 'weight_decay': 0.19330883442945063}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.20353441043008427, 'info': {'data03': 0.20353441043008427, 'config': "{'batch_size': 128, 'hidden_dim': 595, 'last_n_outputs': 19, 'leak_rate': 0.8210634383315552, 'lr': 0.032807073680396995, 'optimizer': 'SGD', 'sparsity': 0.8897433796506402, 'steps_to_train': 30, 'weight_decay': 0.19330883442945063}"}}
exception: None

22:18:38 job_callback for (0, 0, 9) started
22:18:38 job_callback for (0, 0, 9) got condition
22:18:38 DISPATCHER: Trying to submit another job.
22:18:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:18:38 HBMASTER: Trying to run another job!
22:18:38 job_callback for (0, 0, 9) finished
22:18:38 start sampling a new configuration.
22:18:38 done sampling a new configuration.
22:18:38 HBMASTER: schedule new run for iteration 0
22:18:38 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
22:18:38 HBMASTER: submitting job (0, 0, 10) to dispatcher
22:18:38 DISPATCHER: trying to submit job (0, 0, 10)
22:18:38 DISPATCHER: trying to notify the job_runner thread.
22:18:38 HBMASTER: job (0, 0, 10) submitted to dispatcher
22:18:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:18:38 DISPATCHER: Trying to submit another job.
22:18:38 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:18:38 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:18:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:18:38 WORKER: start processing job (0, 0, 10)
22:18:38 WORKER: args: ()
22:18:38 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 651, 'last_n_outputs': 12, 'leak_rate': 0.7991078555596136, 'lr': 0.0012612656605556567, 'optimizer': 'Adam', 'sparsity': 0.7553165419192527, 'steps_to_train': 73, 'weight_decay': 0.06023699179955387}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:19:28 DISPATCHER: Starting worker discovery
22:19:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:19:28 DISPATCHER: Finished worker discovery
22:20:28 DISPATCHER: Starting worker discovery
22:20:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:20:28 DISPATCHER: Finished worker discovery
22:20:40 WORKER: done with job (0, 0, 10), trying to register it.
22:20:40 WORKER: registered result for job (0, 0, 10) with dispatcher
22:20:40 DISPATCHER: job (0, 0, 10) finished
22:20:40 DISPATCHER: register_result: lock acquired
22:20:40 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:20:40 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 651, 'last_n_outputs': 12, 'leak_rate': 0.7991078555596136, 'lr': 0.0012612656605556567, 'optimizer': 'Adam', 'sparsity': 0.7553165419192527, 'steps_to_train': 73, 'weight_decay': 0.06023699179955387}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.034868729905637046, 'info': {'data03': 0.034868729905637046, 'config': "{'batch_size': 64, 'hidden_dim': 651, 'last_n_outputs': 12, 'leak_rate': 0.7991078555596136, 'lr': 0.0012612656605556567, 'optimizer': 'Adam', 'sparsity': 0.7553165419192527, 'steps_to_train': 73, 'weight_decay': 0.06023699179955387}"}}
exception: None

22:20:40 job_callback for (0, 0, 10) started
22:20:40 DISPATCHER: Trying to submit another job.
22:20:40 job_callback for (0, 0, 10) got condition
22:20:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:20:40 HBMASTER: Trying to run another job!
22:20:40 job_callback for (0, 0, 10) finished
22:20:40 start sampling a new configuration.
22:20:40 done sampling a new configuration.
22:20:40 HBMASTER: schedule new run for iteration 0
22:20:40 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
22:20:40 HBMASTER: submitting job (0, 0, 11) to dispatcher
22:20:40 DISPATCHER: trying to submit job (0, 0, 11)
22:20:40 DISPATCHER: trying to notify the job_runner thread.
22:20:40 HBMASTER: job (0, 0, 11) submitted to dispatcher
22:20:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:20:40 DISPATCHER: Trying to submit another job.
22:20:40 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:20:40 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:20:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:20:40 WORKER: start processing job (0, 0, 11)
22:20:40 WORKER: args: ()
22:20:40 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 349, 'last_n_outputs': 46, 'leak_rate': 0.9346604303271233, 'lr': 0.00427071548012511, 'optimizer': 'SGD', 'sparsity': 0.8634961230062116, 'steps_to_train': 11, 'weight_decay': 0.024561642152629452}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:21:28 DISPATCHER: Starting worker discovery
22:21:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:21:28 DISPATCHER: Finished worker discovery
22:22:09 WORKER: done with job (0, 0, 11), trying to register it.
22:22:09 WORKER: registered result for job (0, 0, 11) with dispatcher
22:22:09 DISPATCHER: job (0, 0, 11) finished
22:22:09 DISPATCHER: register_result: lock acquired
22:22:09 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:22:09 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 349, 'last_n_outputs': 46, 'leak_rate': 0.9346604303271233, 'lr': 0.00427071548012511, 'optimizer': 'SGD', 'sparsity': 0.8634961230062116, 'steps_to_train': 11, 'weight_decay': 0.024561642152629452}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1807971396120267, 'info': {'data03': 0.1807971396120267, 'config': "{'batch_size': 16, 'hidden_dim': 349, 'last_n_outputs': 46, 'leak_rate': 0.9346604303271233, 'lr': 0.00427071548012511, 'optimizer': 'SGD', 'sparsity': 0.8634961230062116, 'steps_to_train': 11, 'weight_decay': 0.024561642152629452}"}}
exception: None

22:22:09 job_callback for (0, 0, 11) started
22:22:09 DISPATCHER: Trying to submit another job.
22:22:09 job_callback for (0, 0, 11) got condition
22:22:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:22:09 HBMASTER: Trying to run another job!
22:22:09 job_callback for (0, 0, 11) finished
22:22:09 start sampling a new configuration.
22:22:09 done sampling a new configuration.
22:22:09 HBMASTER: schedule new run for iteration 0
22:22:09 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
22:22:09 HBMASTER: submitting job (0, 0, 12) to dispatcher
22:22:09 DISPATCHER: trying to submit job (0, 0, 12)
22:22:09 DISPATCHER: trying to notify the job_runner thread.
22:22:09 HBMASTER: job (0, 0, 12) submitted to dispatcher
22:22:09 DISPATCHER: Trying to submit another job.
22:22:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:22:09 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:22:09 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:22:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:22:09 WORKER: start processing job (0, 0, 12)
22:22:09 WORKER: args: ()
22:22:09 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 836, 'last_n_outputs': 42, 'leak_rate': 0.9318054055031848, 'lr': 0.027758582951813666, 'optimizer': 'SGD', 'sparsity': 0.8870639333367326, 'steps_to_train': 33, 'weight_decay': 0.0210647229549064}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:22:28 DISPATCHER: Starting worker discovery
22:22:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:22:28 DISPATCHER: Finished worker discovery
22:23:28 DISPATCHER: Starting worker discovery
22:23:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:23:28 DISPATCHER: Finished worker discovery
22:23:42 WORKER: done with job (0, 0, 12), trying to register it.
22:23:42 WORKER: registered result for job (0, 0, 12) with dispatcher
22:23:42 DISPATCHER: job (0, 0, 12) finished
22:23:42 DISPATCHER: register_result: lock acquired
22:23:42 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:23:42 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 836, 'last_n_outputs': 42, 'leak_rate': 0.9318054055031848, 'lr': 0.027758582951813666, 'optimizer': 'SGD', 'sparsity': 0.8870639333367326, 'steps_to_train': 33, 'weight_decay': 0.0210647229549064}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.00889268043265831, 'info': {'data03': 0.00889268043265831, 'config': "{'batch_size': 128, 'hidden_dim': 836, 'last_n_outputs': 42, 'leak_rate': 0.9318054055031848, 'lr': 0.027758582951813666, 'optimizer': 'SGD', 'sparsity': 0.8870639333367326, 'steps_to_train': 33, 'weight_decay': 0.0210647229549064}"}}
exception: None

22:23:42 job_callback for (0, 0, 12) started
22:23:42 job_callback for (0, 0, 12) got condition
22:23:42 DISPATCHER: Trying to submit another job.
22:23:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:23:42 HBMASTER: Trying to run another job!
22:23:42 job_callback for (0, 0, 12) finished
22:23:42 start sampling a new configuration.
22:23:42 done sampling a new configuration.
22:23:42 HBMASTER: schedule new run for iteration 0
22:23:42 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
22:23:42 HBMASTER: submitting job (0, 0, 13) to dispatcher
22:23:42 DISPATCHER: trying to submit job (0, 0, 13)
22:23:42 DISPATCHER: trying to notify the job_runner thread.
22:23:42 HBMASTER: job (0, 0, 13) submitted to dispatcher
22:23:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:23:42 DISPATCHER: Trying to submit another job.
22:23:42 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:23:42 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:23:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:23:42 WORKER: start processing job (0, 0, 13)
22:23:42 WORKER: args: ()
22:23:42 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 969, 'last_n_outputs': 30, 'leak_rate': 0.9910761634606576, 'lr': 0.033712792166029945, 'optimizer': 'Adam', 'sparsity': 0.8551021534391973, 'steps_to_train': 66, 'weight_decay': 0.029714899388483484}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:24:28 DISPATCHER: Starting worker discovery
22:24:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:24:28 DISPATCHER: Finished worker discovery
22:25:28 DISPATCHER: Starting worker discovery
22:25:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:25:28 DISPATCHER: Finished worker discovery
22:25:34 WORKER: done with job (0, 0, 13), trying to register it.
22:25:34 WORKER: registered result for job (0, 0, 13) with dispatcher
22:25:34 DISPATCHER: job (0, 0, 13) finished
22:25:34 DISPATCHER: register_result: lock acquired
22:25:34 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:25:34 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 969, 'last_n_outputs': 30, 'leak_rate': 0.9910761634606576, 'lr': 0.033712792166029945, 'optimizer': 'Adam', 'sparsity': 0.8551021534391973, 'steps_to_train': 66, 'weight_decay': 0.029714899388483484}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.18479925985129883, 'info': {'data03': 0.18479925985129883, 'config': "{'batch_size': 64, 'hidden_dim': 969, 'last_n_outputs': 30, 'leak_rate': 0.9910761634606576, 'lr': 0.033712792166029945, 'optimizer': 'Adam', 'sparsity': 0.8551021534391973, 'steps_to_train': 66, 'weight_decay': 0.029714899388483484}"}}
exception: None

22:25:34 job_callback for (0, 0, 13) started
22:25:34 DISPATCHER: Trying to submit another job.
22:25:34 job_callback for (0, 0, 13) got condition
22:25:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:25:34 HBMASTER: Trying to run another job!
22:25:34 job_callback for (0, 0, 13) finished
22:25:34 start sampling a new configuration.
22:25:34 done sampling a new configuration.
22:25:34 HBMASTER: schedule new run for iteration 0
22:25:34 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
22:25:34 HBMASTER: submitting job (0, 0, 14) to dispatcher
22:25:34 DISPATCHER: trying to submit job (0, 0, 14)
22:25:34 DISPATCHER: trying to notify the job_runner thread.
22:25:34 HBMASTER: job (0, 0, 14) submitted to dispatcher
22:25:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:25:34 DISPATCHER: Trying to submit another job.
22:25:34 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:25:34 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:25:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:25:34 WORKER: start processing job (0, 0, 14)
22:25:34 WORKER: args: ()
22:25:34 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 631, 'last_n_outputs': 31, 'leak_rate': 0.909302163563936, 'lr': 0.05465427432224087, 'optimizer': 'Adam', 'sparsity': 0.93625757699129, 'steps_to_train': 29, 'weight_decay': 0.04240086764997424}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:26:28 DISPATCHER: Starting worker discovery
22:26:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:26:28 DISPATCHER: Finished worker discovery
22:27:00 WORKER: done with job (0, 0, 14), trying to register it.
22:27:00 WORKER: registered result for job (0, 0, 14) with dispatcher
22:27:00 DISPATCHER: job (0, 0, 14) finished
22:27:00 DISPATCHER: register_result: lock acquired
22:27:00 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:27:00 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 631, 'last_n_outputs': 31, 'leak_rate': 0.909302163563936, 'lr': 0.05465427432224087, 'optimizer': 'Adam', 'sparsity': 0.93625757699129, 'steps_to_train': 29, 'weight_decay': 0.04240086764997424}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.25815583632890365, 'info': {'data03': 0.25815583632890365, 'config': "{'batch_size': 64, 'hidden_dim': 631, 'last_n_outputs': 31, 'leak_rate': 0.909302163563936, 'lr': 0.05465427432224087, 'optimizer': 'Adam', 'sparsity': 0.93625757699129, 'steps_to_train': 29, 'weight_decay': 0.04240086764997424}"}}
exception: None

22:27:00 job_callback for (0, 0, 14) started
22:27:00 DISPATCHER: Trying to submit another job.
22:27:00 job_callback for (0, 0, 14) got condition
22:27:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:27:00 HBMASTER: Trying to run another job!
22:27:00 job_callback for (0, 0, 14) finished
22:27:00 start sampling a new configuration.
22:27:00 done sampling a new configuration.
22:27:00 HBMASTER: schedule new run for iteration 0
22:27:00 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
22:27:00 HBMASTER: submitting job (0, 0, 15) to dispatcher
22:27:00 DISPATCHER: trying to submit job (0, 0, 15)
22:27:00 DISPATCHER: trying to notify the job_runner thread.
22:27:00 HBMASTER: job (0, 0, 15) submitted to dispatcher
22:27:00 DISPATCHER: Trying to submit another job.
22:27:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:27:00 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:27:00 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:27:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:27:00 WORKER: start processing job (0, 0, 15)
22:27:00 WORKER: args: ()
22:27:00 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 368, 'last_n_outputs': 30, 'leak_rate': 0.8985332281746368, 'lr': 0.0034832986371500655, 'optimizer': 'Adam', 'sparsity': 0.8369694887405086, 'steps_to_train': 59, 'weight_decay': 0.1599409269078516}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:27:28 DISPATCHER: Starting worker discovery
22:27:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:27:28 DISPATCHER: Finished worker discovery
22:28:28 DISPATCHER: Starting worker discovery
22:28:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:28:28 DISPATCHER: Finished worker discovery
22:28:46 WORKER: done with job (0, 0, 15), trying to register it.
22:28:46 WORKER: registered result for job (0, 0, 15) with dispatcher
22:28:46 DISPATCHER: job (0, 0, 15) finished
22:28:46 DISPATCHER: register_result: lock acquired
22:28:46 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:28:46 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 368, 'last_n_outputs': 30, 'leak_rate': 0.8985332281746368, 'lr': 0.0034832986371500655, 'optimizer': 'Adam', 'sparsity': 0.8369694887405086, 'steps_to_train': 59, 'weight_decay': 0.1599409269078516}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.13184997135533938, 'info': {'data03': 0.13184997135533938, 'config': "{'batch_size': 32, 'hidden_dim': 368, 'last_n_outputs': 30, 'leak_rate': 0.8985332281746368, 'lr': 0.0034832986371500655, 'optimizer': 'Adam', 'sparsity': 0.8369694887405086, 'steps_to_train': 59, 'weight_decay': 0.1599409269078516}"}}
exception: None

22:28:46 job_callback for (0, 0, 15) started
22:28:46 DISPATCHER: Trying to submit another job.
22:28:46 job_callback for (0, 0, 15) got condition
22:28:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:28:46 HBMASTER: Trying to run another job!
22:28:46 job_callback for (0, 0, 15) finished
22:28:46 start sampling a new configuration.
22:28:46 done sampling a new configuration.
22:28:46 HBMASTER: schedule new run for iteration 0
22:28:46 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
22:28:46 HBMASTER: submitting job (0, 0, 16) to dispatcher
22:28:46 DISPATCHER: trying to submit job (0, 0, 16)
22:28:46 DISPATCHER: trying to notify the job_runner thread.
22:28:46 HBMASTER: job (0, 0, 16) submitted to dispatcher
22:28:46 DISPATCHER: Trying to submit another job.
22:28:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:28:46 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:28:46 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:28:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:28:46 WORKER: start processing job (0, 0, 16)
22:28:46 WORKER: args: ()
22:28:46 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 517, 'last_n_outputs': 16, 'leak_rate': 0.9147597534980976, 'lr': 0.005947337584614059, 'optimizer': 'SGD', 'sparsity': 0.7948522395722545, 'steps_to_train': 28, 'weight_decay': 0.048497856310930544}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:29:28 DISPATCHER: Starting worker discovery
22:29:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:29:28 DISPATCHER: Finished worker discovery
22:30:23 WORKER: done with job (0, 0, 16), trying to register it.
22:30:23 WORKER: registered result for job (0, 0, 16) with dispatcher
22:30:23 DISPATCHER: job (0, 0, 16) finished
22:30:23 DISPATCHER: register_result: lock acquired
22:30:23 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:30:23 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 517, 'last_n_outputs': 16, 'leak_rate': 0.9147597534980976, 'lr': 0.005947337584614059, 'optimizer': 'SGD', 'sparsity': 0.7948522395722545, 'steps_to_train': 28, 'weight_decay': 0.048497856310930544}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.22567525426674576, 'info': {'data03': 0.22567525426674576, 'config': "{'batch_size': 64, 'hidden_dim': 517, 'last_n_outputs': 16, 'leak_rate': 0.9147597534980976, 'lr': 0.005947337584614059, 'optimizer': 'SGD', 'sparsity': 0.7948522395722545, 'steps_to_train': 28, 'weight_decay': 0.048497856310930544}"}}
exception: None

22:30:23 job_callback for (0, 0, 16) started
22:30:23 job_callback for (0, 0, 16) got condition
22:30:23 DISPATCHER: Trying to submit another job.
22:30:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:30:23 HBMASTER: Trying to run another job!
22:30:23 job_callback for (0, 0, 16) finished
22:30:23 start sampling a new configuration.
22:30:23 done sampling a new configuration.
22:30:23 HBMASTER: schedule new run for iteration 0
22:30:23 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
22:30:23 HBMASTER: submitting job (0, 0, 17) to dispatcher
22:30:23 DISPATCHER: trying to submit job (0, 0, 17)
22:30:23 DISPATCHER: trying to notify the job_runner thread.
22:30:23 HBMASTER: job (0, 0, 17) submitted to dispatcher
22:30:23 DISPATCHER: Trying to submit another job.
22:30:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:30:23 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:30:23 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:30:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:30:23 WORKER: start processing job (0, 0, 17)
22:30:23 WORKER: args: ()
22:30:23 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 349, 'last_n_outputs': 32, 'leak_rate': 0.7501720335673564, 'lr': 0.04770697507331557, 'optimizer': 'Adam', 'sparsity': 0.9186327070898728, 'steps_to_train': 48, 'weight_decay': 0.04308752538856237}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:30:28 DISPATCHER: Starting worker discovery
22:30:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:30:28 DISPATCHER: Finished worker discovery
22:31:28 DISPATCHER: Starting worker discovery
22:31:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:31:28 DISPATCHER: Finished worker discovery
22:31:53 WORKER: done with job (0, 0, 17), trying to register it.
22:31:53 WORKER: registered result for job (0, 0, 17) with dispatcher
22:31:53 DISPATCHER: job (0, 0, 17) finished
22:31:53 DISPATCHER: register_result: lock acquired
22:31:53 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:31:53 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 349, 'last_n_outputs': 32, 'leak_rate': 0.7501720335673564, 'lr': 0.04770697507331557, 'optimizer': 'Adam', 'sparsity': 0.9186327070898728, 'steps_to_train': 48, 'weight_decay': 0.04308752538856237}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.13173416634304866, 'info': {'data03': 0.13173416634304866, 'config': "{'batch_size': 32, 'hidden_dim': 349, 'last_n_outputs': 32, 'leak_rate': 0.7501720335673564, 'lr': 0.04770697507331557, 'optimizer': 'Adam', 'sparsity': 0.9186327070898728, 'steps_to_train': 48, 'weight_decay': 0.04308752538856237}"}}
exception: None

22:31:53 job_callback for (0, 0, 17) started
22:31:53 job_callback for (0, 0, 17) got condition
22:31:53 DISPATCHER: Trying to submit another job.
22:31:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:31:53 HBMASTER: Trying to run another job!
22:31:53 job_callback for (0, 0, 17) finished
22:31:53 start sampling a new configuration.
22:31:53 done sampling a new configuration.
22:31:53 HBMASTER: schedule new run for iteration 0
22:31:53 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
22:31:53 HBMASTER: submitting job (0, 0, 18) to dispatcher
22:31:53 DISPATCHER: trying to submit job (0, 0, 18)
22:31:53 DISPATCHER: trying to notify the job_runner thread.
22:31:53 HBMASTER: job (0, 0, 18) submitted to dispatcher
22:31:53 DISPATCHER: Trying to submit another job.
22:31:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:31:53 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:31:53 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:31:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:31:53 WORKER: start processing job (0, 0, 18)
22:31:53 WORKER: args: ()
22:31:53 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 835, 'last_n_outputs': 10, 'leak_rate': 0.8898542696969487, 'lr': 0.0036314350979303432, 'optimizer': 'SGD', 'sparsity': 0.8746736390753276, 'steps_to_train': 59, 'weight_decay': 0.044394728348473675}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:32:28 DISPATCHER: Starting worker discovery
22:32:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:32:28 DISPATCHER: Finished worker discovery
22:33:28 DISPATCHER: Starting worker discovery
22:33:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:33:28 DISPATCHER: Finished worker discovery
22:33:31 WORKER: done with job (0, 0, 18), trying to register it.
22:33:31 WORKER: registered result for job (0, 0, 18) with dispatcher
22:33:31 DISPATCHER: job (0, 0, 18) finished
22:33:31 DISPATCHER: register_result: lock acquired
22:33:31 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:33:31 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 835, 'last_n_outputs': 10, 'leak_rate': 0.8898542696969487, 'lr': 0.0036314350979303432, 'optimizer': 'SGD', 'sparsity': 0.8746736390753276, 'steps_to_train': 59, 'weight_decay': 0.044394728348473675}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 835, 'last_n_outputs': 10, 'leak_rate': 0.8898542696969487, 'lr': 0.0036314350979303432, 'optimizer': 'SGD', 'sparsity': 0.8746736390753276, 'steps_to_train': 59, 'weight_decay': 0.044394728348473675}"}}
exception: None

22:33:31 job_callback for (0, 0, 18) started
22:33:31 DISPATCHER: Trying to submit another job.
22:33:31 job_callback for (0, 0, 18) got condition
22:33:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:33:31 HBMASTER: Trying to run another job!
22:33:31 job_callback for (0, 0, 18) finished
22:33:31 start sampling a new configuration.
22:33:31 done sampling a new configuration.
22:33:31 HBMASTER: schedule new run for iteration 0
22:33:31 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
22:33:31 HBMASTER: submitting job (0, 0, 19) to dispatcher
22:33:31 DISPATCHER: trying to submit job (0, 0, 19)
22:33:31 DISPATCHER: trying to notify the job_runner thread.
22:33:31 HBMASTER: job (0, 0, 19) submitted to dispatcher
22:33:31 DISPATCHER: Trying to submit another job.
22:33:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:33:31 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:33:31 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:33:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:33:31 WORKER: start processing job (0, 0, 19)
22:33:31 WORKER: args: ()
22:33:31 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 704, 'last_n_outputs': 47, 'leak_rate': 0.9764401153072582, 'lr': 0.0015954686734114612, 'optimizer': 'Adam', 'sparsity': 0.9876387491195142, 'steps_to_train': 69, 'weight_decay': 0.028846297763280578}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:34:28 DISPATCHER: Starting worker discovery
22:34:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:34:28 DISPATCHER: Finished worker discovery
22:35:15 WORKER: done with job (0, 0, 19), trying to register it.
22:35:15 WORKER: registered result for job (0, 0, 19) with dispatcher
22:35:15 DISPATCHER: job (0, 0, 19) finished
22:35:15 DISPATCHER: register_result: lock acquired
22:35:15 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:35:15 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 704, 'last_n_outputs': 47, 'leak_rate': 0.9764401153072582, 'lr': 0.0015954686734114612, 'optimizer': 'Adam', 'sparsity': 0.9876387491195142, 'steps_to_train': 69, 'weight_decay': 0.028846297763280578}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.21602911598232855, 'info': {'data03': 0.21602911598232855, 'config': "{'batch_size': 32, 'hidden_dim': 704, 'last_n_outputs': 47, 'leak_rate': 0.9764401153072582, 'lr': 0.0015954686734114612, 'optimizer': 'Adam', 'sparsity': 0.9876387491195142, 'steps_to_train': 69, 'weight_decay': 0.028846297763280578}"}}
exception: None

22:35:15 job_callback for (0, 0, 19) started
22:35:15 job_callback for (0, 0, 19) got condition
22:35:15 DISPATCHER: Trying to submit another job.
22:35:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:35:15 done building a new model for budget 44.444444 based on 10/17 split
Best loss for this budget:-0.271203





22:35:15 HBMASTER: Trying to run another job!
22:35:15 job_callback for (0, 0, 19) finished
22:35:15 start sampling a new configuration.
22:35:15 done sampling a new configuration.
22:35:15 HBMASTER: schedule new run for iteration 0
22:35:15 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
22:35:15 HBMASTER: submitting job (0, 0, 20) to dispatcher
22:35:15 DISPATCHER: trying to submit job (0, 0, 20)
22:35:15 DISPATCHER: trying to notify the job_runner thread.
22:35:15 HBMASTER: job (0, 0, 20) submitted to dispatcher
22:35:15 DISPATCHER: Trying to submit another job.
22:35:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:35:15 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:35:15 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:35:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:35:15 WORKER: start processing job (0, 0, 20)
22:35:15 WORKER: args: ()
22:35:15 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 376, 'last_n_outputs': 13, 'leak_rate': 0.8597791959631701, 'lr': 0.002772416943957608, 'optimizer': 'Adam', 'sparsity': 0.8298353154929986, 'steps_to_train': 10, 'weight_decay': 0.03520039789003798}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:35:28 DISPATCHER: Starting worker discovery
22:35:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:35:28 DISPATCHER: Finished worker discovery
22:36:28 DISPATCHER: Starting worker discovery
22:36:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:36:28 DISPATCHER: Finished worker discovery
22:36:42 WORKER: done with job (0, 0, 20), trying to register it.
22:36:42 WORKER: registered result for job (0, 0, 20) with dispatcher
22:36:42 DISPATCHER: job (0, 0, 20) finished
22:36:42 DISPATCHER: register_result: lock acquired
22:36:42 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:36:42 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 376, 'last_n_outputs': 13, 'leak_rate': 0.8597791959631701, 'lr': 0.002772416943957608, 'optimizer': 'Adam', 'sparsity': 0.8298353154929986, 'steps_to_train': 10, 'weight_decay': 0.03520039789003798}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.12405996241757934, 'info': {'data03': 0.12405996241757934, 'config': "{'batch_size': 32, 'hidden_dim': 376, 'last_n_outputs': 13, 'leak_rate': 0.8597791959631701, 'lr': 0.002772416943957608, 'optimizer': 'Adam', 'sparsity': 0.8298353154929986, 'steps_to_train': 10, 'weight_decay': 0.03520039789003798}"}}
exception: None

22:36:42 job_callback for (0, 0, 20) started
22:36:42 DISPATCHER: Trying to submit another job.
22:36:42 job_callback for (0, 0, 20) got condition
22:36:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:36:42 done building a new model for budget 44.444444 based on 10/17 split
Best loss for this budget:-0.271203





22:36:42 HBMASTER: Trying to run another job!
22:36:42 job_callback for (0, 0, 20) finished
22:36:42 start sampling a new configuration.
22:36:42 best_vector: [1, 0.6505700335563374, 0.6825564525650913, 0.6393386670671457, 0.6393359224083683, 1, 0.02148667894658629, 0.8457917009074948, 0.7111665923750361], 0.01118778255725144, 0.08592706213686466, 0.0009613332869706751
22:36:42 done sampling a new configuration.
22:36:42 HBMASTER: schedule new run for iteration 0
22:36:42 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
22:36:42 HBMASTER: submitting job (0, 0, 21) to dispatcher
22:36:42 DISPATCHER: trying to submit job (0, 0, 21)
22:36:42 DISPATCHER: trying to notify the job_runner thread.
22:36:42 HBMASTER: job (0, 0, 21) submitted to dispatcher
22:36:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:36:42 DISPATCHER: Trying to submit another job.
22:36:42 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:36:42 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:36:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:36:42 WORKER: start processing job (0, 0, 21)
22:36:42 WORKER: args: ()
22:36:42 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 721, 'last_n_outputs': 37, 'leak_rate': 0.9098346667667865, 'lr': 0.018996423577897815, 'optimizer': 'SGD', 'sparsity': 0.7551568029471807, 'steps_to_train': 86, 'weight_decay': 0.08418778215275537}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:37:28 DISPATCHER: Starting worker discovery
22:37:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:37:28 DISPATCHER: Finished worker discovery
22:38:10 WORKER: done with job (0, 0, 21), trying to register it.
22:38:10 WORKER: registered result for job (0, 0, 21) with dispatcher
22:38:10 DISPATCHER: job (0, 0, 21) finished
22:38:10 DISPATCHER: register_result: lock acquired
22:38:10 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:38:10 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 721, 'last_n_outputs': 37, 'leak_rate': 0.9098346667667865, 'lr': 0.018996423577897815, 'optimizer': 'SGD', 'sparsity': 0.7551568029471807, 'steps_to_train': 86, 'weight_decay': 0.08418778215275537}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 721, 'last_n_outputs': 37, 'leak_rate': 0.9098346667667865, 'lr': 0.018996423577897815, 'optimizer': 'SGD', 'sparsity': 0.7551568029471807, 'steps_to_train': 86, 'weight_decay': 0.08418778215275537}"}}
exception: None

22:38:10 job_callback for (0, 0, 21) started
22:38:10 DISPATCHER: Trying to submit another job.
22:38:10 job_callback for (0, 0, 21) got condition
22:38:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:38:10 done building a new model for budget 44.444444 based on 10/18 split
Best loss for this budget:-0.271203





22:38:10 HBMASTER: Trying to run another job!
22:38:10 job_callback for (0, 0, 21) finished
22:38:10 start sampling a new configuration.
22:38:10 done sampling a new configuration.
22:38:10 HBMASTER: schedule new run for iteration 0
22:38:10 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
22:38:10 HBMASTER: submitting job (0, 0, 22) to dispatcher
22:38:10 DISPATCHER: trying to submit job (0, 0, 22)
22:38:10 DISPATCHER: trying to notify the job_runner thread.
22:38:10 HBMASTER: job (0, 0, 22) submitted to dispatcher
22:38:10 DISPATCHER: Trying to submit another job.
22:38:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:38:10 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:38:10 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:38:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:38:10 WORKER: start processing job (0, 0, 22)
22:38:10 WORKER: args: ()
22:38:10 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 891, 'last_n_outputs': 28, 'leak_rate': 0.9195657809245886, 'lr': 0.0021188468035018143, 'optimizer': 'Adam', 'sparsity': 0.9093104772077536, 'steps_to_train': 84, 'weight_decay': 0.0149502197815832}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:38:28 DISPATCHER: Starting worker discovery
22:38:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:38:28 DISPATCHER: Finished worker discovery
22:39:28 DISPATCHER: Starting worker discovery
22:39:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:39:28 DISPATCHER: Finished worker discovery
22:39:32 WORKER: done with job (0, 0, 22), trying to register it.
22:39:32 WORKER: registered result for job (0, 0, 22) with dispatcher
22:39:32 DISPATCHER: job (0, 0, 22) finished
22:39:32 DISPATCHER: register_result: lock acquired
22:39:32 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:39:32 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 891, 'last_n_outputs': 28, 'leak_rate': 0.9195657809245886, 'lr': 0.0021188468035018143, 'optimizer': 'Adam', 'sparsity': 0.9093104772077536, 'steps_to_train': 84, 'weight_decay': 0.0149502197815832}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 891, 'last_n_outputs': 28, 'leak_rate': 0.9195657809245886, 'lr': 0.0021188468035018143, 'optimizer': 'Adam', 'sparsity': 0.9093104772077536, 'steps_to_train': 84, 'weight_decay': 0.0149502197815832}"}}
exception: None

22:39:32 job_callback for (0, 0, 22) started
22:39:32 job_callback for (0, 0, 22) got condition
22:39:32 DISPATCHER: Trying to submit another job.
22:39:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:39:32 done building a new model for budget 44.444444 based on 10/19 split
Best loss for this budget:-0.271203





22:39:32 HBMASTER: Trying to run another job!
22:39:32 job_callback for (0, 0, 22) finished
22:39:32 start sampling a new configuration.
22:39:32 best_vector: [1, 0.2052666836171281, 0.3751693144708673, 0.27778958630402234, 0.8369272791680666, 0, 0.3078124296654945, 0.3080407136271707, 0.34088987976504326], 0.036191173693737484, 0.591328074475502, 0.021400857053326228
22:39:32 done sampling a new configuration.
22:39:32 HBMASTER: schedule new run for iteration 0
22:39:32 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
22:39:32 HBMASTER: submitting job (0, 0, 23) to dispatcher
22:39:32 DISPATCHER: trying to submit job (0, 0, 23)
22:39:32 DISPATCHER: trying to notify the job_runner thread.
22:39:32 HBMASTER: job (0, 0, 23) submitted to dispatcher
22:39:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:39:32 DISPATCHER: Trying to submit another job.
22:39:32 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:39:32 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:39:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:39:32 WORKER: start processing job (0, 0, 23)
22:39:32 WORKER: args: ()
22:39:32 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 364, 'last_n_outputs': 25, 'leak_rate': 0.8194473965760056, 'lr': 0.047190497768720314, 'optimizer': 'Adam', 'sparsity': 0.8238749831197186, 'steps_to_train': 38, 'weight_decay': 0.027765657284197873}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:40:28 DISPATCHER: Starting worker discovery
22:40:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:40:28 DISPATCHER: Finished worker discovery
22:41:05 WORKER: done with job (0, 0, 23), trying to register it.
22:41:05 WORKER: registered result for job (0, 0, 23) with dispatcher
22:41:05 DISPATCHER: job (0, 0, 23) finished
22:41:05 DISPATCHER: register_result: lock acquired
22:41:05 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:41:05 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 364, 'last_n_outputs': 25, 'leak_rate': 0.8194473965760056, 'lr': 0.047190497768720314, 'optimizer': 'Adam', 'sparsity': 0.8238749831197186, 'steps_to_train': 38, 'weight_decay': 0.027765657284197873}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0018615512645853956, 'info': {'data03': 0.0018615512645853956, 'config': "{'batch_size': 32, 'hidden_dim': 364, 'last_n_outputs': 25, 'leak_rate': 0.8194473965760056, 'lr': 0.047190497768720314, 'optimizer': 'Adam', 'sparsity': 0.8238749831197186, 'steps_to_train': 38, 'weight_decay': 0.027765657284197873}"}}
exception: None

22:41:05 job_callback for (0, 0, 23) started
22:41:05 DISPATCHER: Trying to submit another job.
22:41:05 job_callback for (0, 0, 23) got condition
22:41:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:41:05 done building a new model for budget 44.444444 based on 10/20 split
Best loss for this budget:-0.271203





22:41:05 HBMASTER: Trying to run another job!
22:41:05 job_callback for (0, 0, 23) finished
22:41:05 start sampling a new configuration.
22:41:05 best_vector: [1, 0.039598194663371056, 0.31357425498804287, 0.34904110450340964, 0.442010900337754, 1, 0.7309138028493813, 0.09096167563228, 0.9351480258276103], 0.02842268740817216, 0.05701566925231416, 0.0016205385445262584
22:41:05 done sampling a new configuration.
22:41:05 HBMASTER: schedule new run for iteration 0
22:41:05 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
22:41:05 HBMASTER: submitting job (0, 0, 24) to dispatcher
22:41:05 DISPATCHER: trying to submit job (0, 0, 24)
22:41:05 DISPATCHER: trying to notify the job_runner thread.
22:41:05 HBMASTER: job (0, 0, 24) submitted to dispatcher
22:41:05 DISPATCHER: Trying to submit another job.
22:41:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:41:05 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:41:06 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:41:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:41:06 WORKER: start processing job (0, 0, 24)
22:41:06 WORKER: args: ()
22:41:06 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 231, 'last_n_outputs': 22, 'leak_rate': 0.8372602761258524, 'lr': 0.0076563503922576735, 'optimizer': 'SGD', 'sparsity': 0.9254193126838515, 'steps_to_train': 18, 'weight_decay': 0.16468560211602665}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:41:28 DISPATCHER: Starting worker discovery
22:41:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:41:28 DISPATCHER: Finished worker discovery
22:42:28 DISPATCHER: Starting worker discovery
22:42:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:42:28 DISPATCHER: Finished worker discovery
22:42:36 WORKER: done with job (0, 0, 24), trying to register it.
22:42:36 WORKER: registered result for job (0, 0, 24) with dispatcher
22:42:36 DISPATCHER: job (0, 0, 24) finished
22:42:36 DISPATCHER: register_result: lock acquired
22:42:36 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:42:36 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 231, 'last_n_outputs': 22, 'leak_rate': 0.8372602761258524, 'lr': 0.0076563503922576735, 'optimizer': 'SGD', 'sparsity': 0.9254193126838515, 'steps_to_train': 18, 'weight_decay': 0.16468560211602665}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.00011687189887373318, 'info': {'data03': -0.00011687189887373318, 'config': "{'batch_size': 32, 'hidden_dim': 231, 'last_n_outputs': 22, 'leak_rate': 0.8372602761258524, 'lr': 0.0076563503922576735, 'optimizer': 'SGD', 'sparsity': 0.9254193126838515, 'steps_to_train': 18, 'weight_decay': 0.16468560211602665}"}}
exception: None

22:42:36 job_callback for (0, 0, 24) started
22:42:36 job_callback for (0, 0, 24) got condition
22:42:36 DISPATCHER: Trying to submit another job.
22:42:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:42:36 done building a new model for budget 44.444444 based on 10/21 split
Best loss for this budget:-0.271203





22:42:36 HBMASTER: Trying to run another job!
22:42:36 job_callback for (0, 0, 24) finished
22:42:36 start sampling a new configuration.
22:42:36 best_vector: [0, 0.21777768807613934, 0.9252316195185433, 0.8053337419477504, 0.5660588607994994, 0, 0.213635245376303, 0.34769710465049203, 0.9595375564759451], 0.07464313566379659, 0.021964776450889033, 0.0016395197884486745
22:42:36 done sampling a new configuration.
22:42:36 HBMASTER: schedule new run for iteration 0
22:42:36 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
22:42:36 HBMASTER: submitting job (0, 0, 25) to dispatcher
22:42:36 DISPATCHER: trying to submit job (0, 0, 25)
22:42:36 DISPATCHER: trying to notify the job_runner thread.
22:42:36 HBMASTER: job (0, 0, 25) submitted to dispatcher
22:42:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:42:36 DISPATCHER: Trying to submit another job.
22:42:36 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:42:36 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:42:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:42:36 WORKER: start processing job (0, 0, 25)
22:42:36 WORKER: args: ()
22:42:36 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 374, 'last_n_outputs': 47, 'leak_rate': 0.9513334354869376, 'lr': 0.01355556805203759, 'optimizer': 'Adam', 'sparsity': 0.8012724588903127, 'steps_to_train': 41, 'weight_decay': 0.17716875892917427}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:43:28 DISPATCHER: Starting worker discovery
22:43:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:43:28 DISPATCHER: Finished worker discovery
22:44:17 WORKER: done with job (0, 0, 25), trying to register it.
22:44:17 WORKER: registered result for job (0, 0, 25) with dispatcher
22:44:17 DISPATCHER: job (0, 0, 25) finished
22:44:17 DISPATCHER: register_result: lock acquired
22:44:17 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:44:17 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 374, 'last_n_outputs': 47, 'leak_rate': 0.9513334354869376, 'lr': 0.01355556805203759, 'optimizer': 'Adam', 'sparsity': 0.8012724588903127, 'steps_to_train': 41, 'weight_decay': 0.17716875892917427}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.23361043600962414, 'info': {'data03': 0.23361043600962414, 'config': "{'batch_size': 16, 'hidden_dim': 374, 'last_n_outputs': 47, 'leak_rate': 0.9513334354869376, 'lr': 0.01355556805203759, 'optimizer': 'Adam', 'sparsity': 0.8012724588903127, 'steps_to_train': 41, 'weight_decay': 0.17716875892917427}"}}
exception: None

22:44:17 DISPATCHER: Trying to submit another job.
22:44:17 job_callback for (0, 0, 25) started
22:44:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:44:17 job_callback for (0, 0, 25) got condition
22:44:17 done building a new model for budget 44.444444 based on 10/22 split
Best loss for this budget:-0.271203





22:44:17 HBMASTER: Trying to run another job!
22:44:17 job_callback for (0, 0, 25) finished
22:44:17 start sampling a new configuration.
22:44:17 best_vector: [1, 0.24605545778376697, 0.8583447786003404, 0.7107352055307722, 0.21322509856556116, 0, 0.19700234019316484, 0.3213897923658219, 0.24139394781495782], 0.019157796638297888, 0.11653216319963548, 0.0022324994843995576
22:44:17 done sampling a new configuration.
22:44:17 HBMASTER: schedule new run for iteration 0
22:44:17 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
22:44:17 HBMASTER: submitting job (0, 0, 26) to dispatcher
22:44:17 DISPATCHER: trying to submit job (0, 0, 26)
22:44:17 DISPATCHER: trying to notify the job_runner thread.
22:44:17 HBMASTER: job (0, 0, 26) submitted to dispatcher
22:44:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:44:17 DISPATCHER: Trying to submit another job.
22:44:17 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:44:17 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:44:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:44:17 WORKER: start processing job (0, 0, 26)
22:44:17 WORKER: args: ()
22:44:17 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 397, 'last_n_outputs': 45, 'leak_rate': 0.927683801382693, 'lr': 0.0026696246094565423, 'optimizer': 'Adam', 'sparsity': 0.7972805616463595, 'steps_to_train': 39, 'weight_decay': 0.020609182586544206}, 'budget': 44.44444444444444, 'working_directory': '.'}
22:44:28 DISPATCHER: Starting worker discovery
22:44:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:44:28 DISPATCHER: Finished worker discovery
22:45:28 DISPATCHER: Starting worker discovery
22:45:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:45:28 DISPATCHER: Finished worker discovery
22:45:56 WORKER: done with job (0, 0, 26), trying to register it.
22:45:56 WORKER: registered result for job (0, 0, 26) with dispatcher
22:45:56 DISPATCHER: job (0, 0, 26) finished
22:45:56 DISPATCHER: register_result: lock acquired
22:45:56 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:45:56 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 397, 'last_n_outputs': 45, 'leak_rate': 0.927683801382693, 'lr': 0.0026696246094565423, 'optimizer': 'Adam', 'sparsity': 0.7972805616463595, 'steps_to_train': 39, 'weight_decay': 0.020609182586544206}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.053714610607740555, 'info': {'data03': 0.053714610607740555, 'config': "{'batch_size': 32, 'hidden_dim': 397, 'last_n_outputs': 45, 'leak_rate': 0.927683801382693, 'lr': 0.0026696246094565423, 'optimizer': 'Adam', 'sparsity': 0.7972805616463595, 'steps_to_train': 39, 'weight_decay': 0.020609182586544206}"}}
exception: None

22:45:56 job_callback for (0, 0, 26) started
22:45:56 DISPATCHER: Trying to submit another job.
22:45:56 job_callback for (0, 0, 26) got condition
22:45:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:45:56 done building a new model for budget 44.444444 based on 10/22 split
Best loss for this budget:-0.271203





22:45:56 HBMASTER: Trying to run another job!
22:45:56 job_callback for (0, 0, 26) finished
22:45:56 ITERATION: Advancing config (0, 0, 0) to next budget 133.333333
22:45:56 ITERATION: Advancing config (0, 0, 3) to next budget 133.333333
22:45:56 ITERATION: Advancing config (0, 0, 9) to next budget 133.333333
22:45:56 ITERATION: Advancing config (0, 0, 11) to next budget 133.333333
22:45:56 ITERATION: Advancing config (0, 0, 13) to next budget 133.333333
22:45:56 ITERATION: Advancing config (0, 0, 14) to next budget 133.333333
22:45:56 ITERATION: Advancing config (0, 0, 16) to next budget 133.333333
22:45:56 ITERATION: Advancing config (0, 0, 19) to next budget 133.333333
22:45:56 ITERATION: Advancing config (0, 0, 25) to next budget 133.333333
22:45:56 HBMASTER: schedule new run for iteration 0
22:45:56 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
22:45:56 HBMASTER: submitting job (0, 0, 0) to dispatcher
22:45:56 DISPATCHER: trying to submit job (0, 0, 0)
22:45:56 DISPATCHER: trying to notify the job_runner thread.
22:45:56 HBMASTER: job (0, 0, 0) submitted to dispatcher
22:45:56 DISPATCHER: Trying to submit another job.
22:45:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:45:56 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:45:56 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:45:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:45:56 WORKER: start processing job (0, 0, 0)
22:45:56 WORKER: args: ()
22:45:56 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 397, 'last_n_outputs': 29, 'leak_rate': 0.8158215223012006, 'lr': 0.09965070642454588, 'optimizer': 'Adam', 'sparsity': 0.8127607681578253, 'steps_to_train': 31, 'weight_decay': 0.04958362608638405}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:46:28 DISPATCHER: Starting worker discovery
22:46:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:46:28 DISPATCHER: Finished worker discovery
22:47:28 DISPATCHER: Starting worker discovery
22:47:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:47:28 DISPATCHER: Finished worker discovery
22:48:28 DISPATCHER: Starting worker discovery
22:48:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:48:28 DISPATCHER: Finished worker discovery
22:48:54 WORKER: done with job (0, 0, 0), trying to register it.
22:48:54 WORKER: registered result for job (0, 0, 0) with dispatcher
22:48:54 DISPATCHER: job (0, 0, 0) finished
22:48:54 DISPATCHER: register_result: lock acquired
22:48:54 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:48:54 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 397, 'last_n_outputs': 29, 'leak_rate': 0.8158215223012006, 'lr': 0.09965070642454588, 'optimizer': 'Adam', 'sparsity': 0.8127607681578253, 'steps_to_train': 31, 'weight_decay': 0.04958362608638405}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.10467845980301918, 'info': {'data03': 0.10467845980301918, 'config': "{'batch_size': 128, 'hidden_dim': 397, 'last_n_outputs': 29, 'leak_rate': 0.8158215223012006, 'lr': 0.09965070642454588, 'optimizer': 'Adam', 'sparsity': 0.8127607681578253, 'steps_to_train': 31, 'weight_decay': 0.04958362608638405}"}}
exception: None

22:48:54 job_callback for (0, 0, 0) started
22:48:54 DISPATCHER: Trying to submit another job.
22:48:54 job_callback for (0, 0, 0) got condition
22:48:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:48:54 Only 1 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
22:48:54 HBMASTER: Trying to run another job!
22:48:54 job_callback for (0, 0, 0) finished
22:48:54 HBMASTER: schedule new run for iteration 0
22:48:54 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
22:48:54 HBMASTER: submitting job (0, 0, 3) to dispatcher
22:48:54 DISPATCHER: trying to submit job (0, 0, 3)
22:48:54 DISPATCHER: trying to notify the job_runner thread.
22:48:54 HBMASTER: job (0, 0, 3) submitted to dispatcher
22:48:54 DISPATCHER: Trying to submit another job.
22:48:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:48:54 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:48:54 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:48:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:48:54 WORKER: start processing job (0, 0, 3)
22:48:54 WORKER: args: ()
22:48:54 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 596, 'last_n_outputs': 30, 'leak_rate': 0.8409248207361791, 'lr': 0.015439964563484001, 'optimizer': 'Adam', 'sparsity': 0.8188208398247486, 'steps_to_train': 82, 'weight_decay': 0.0854083402505829}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:49:28 DISPATCHER: Starting worker discovery
22:49:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:49:28 DISPATCHER: Finished worker discovery
22:50:28 DISPATCHER: Starting worker discovery
22:50:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:50:28 DISPATCHER: Finished worker discovery
22:51:28 DISPATCHER: Starting worker discovery
22:51:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:51:28 DISPATCHER: Finished worker discovery
22:52:16 WORKER: done with job (0, 0, 3), trying to register it.
22:52:16 WORKER: registered result for job (0, 0, 3) with dispatcher
22:52:16 DISPATCHER: job (0, 0, 3) finished
22:52:16 DISPATCHER: register_result: lock acquired
22:52:16 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:52:16 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 596, 'last_n_outputs': 30, 'leak_rate': 0.8409248207361791, 'lr': 0.015439964563484001, 'optimizer': 'Adam', 'sparsity': 0.8188208398247486, 'steps_to_train': 82, 'weight_decay': 0.0854083402505829}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.11051249938393598, 'info': {'data03': 0.11051249938393598, 'config': "{'batch_size': 16, 'hidden_dim': 596, 'last_n_outputs': 30, 'leak_rate': 0.8409248207361791, 'lr': 0.015439964563484001, 'optimizer': 'Adam', 'sparsity': 0.8188208398247486, 'steps_to_train': 82, 'weight_decay': 0.0854083402505829}"}}
exception: None

22:52:16 job_callback for (0, 0, 3) started
22:52:16 DISPATCHER: Trying to submit another job.
22:52:16 job_callback for (0, 0, 3) got condition
22:52:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:52:16 Only 2 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
22:52:16 HBMASTER: Trying to run another job!
22:52:16 job_callback for (0, 0, 3) finished
22:52:16 HBMASTER: schedule new run for iteration 0
22:52:16 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
22:52:16 HBMASTER: submitting job (0, 0, 9) to dispatcher
22:52:16 DISPATCHER: trying to submit job (0, 0, 9)
22:52:16 DISPATCHER: trying to notify the job_runner thread.
22:52:16 HBMASTER: job (0, 0, 9) submitted to dispatcher
22:52:16 DISPATCHER: Trying to submit another job.
22:52:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:52:16 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:52:16 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:52:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:52:16 WORKER: start processing job (0, 0, 9)
22:52:16 WORKER: args: ()
22:52:16 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 595, 'last_n_outputs': 19, 'leak_rate': 0.8210634383315552, 'lr': 0.032807073680396995, 'optimizer': 'SGD', 'sparsity': 0.8897433796506402, 'steps_to_train': 30, 'weight_decay': 0.19330883442945063}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:52:28 DISPATCHER: Starting worker discovery
22:52:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:52:28 DISPATCHER: Finished worker discovery
22:53:28 DISPATCHER: Starting worker discovery
22:53:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:53:28 DISPATCHER: Finished worker discovery
22:54:28 DISPATCHER: Starting worker discovery
22:54:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:54:28 DISPATCHER: Finished worker discovery
22:55:17 WORKER: done with job (0, 0, 9), trying to register it.
22:55:17 WORKER: registered result for job (0, 0, 9) with dispatcher
22:55:17 DISPATCHER: job (0, 0, 9) finished
22:55:17 DISPATCHER: register_result: lock acquired
22:55:17 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:55:17 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 595, 'last_n_outputs': 19, 'leak_rate': 0.8210634383315552, 'lr': 0.032807073680396995, 'optimizer': 'SGD', 'sparsity': 0.8897433796506402, 'steps_to_train': 30, 'weight_decay': 0.19330883442945063}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.010328367494126198, 'info': {'data03': 0.010328367494126198, 'config': "{'batch_size': 128, 'hidden_dim': 595, 'last_n_outputs': 19, 'leak_rate': 0.8210634383315552, 'lr': 0.032807073680396995, 'optimizer': 'SGD', 'sparsity': 0.8897433796506402, 'steps_to_train': 30, 'weight_decay': 0.19330883442945063}"}}
exception: None

22:55:17 job_callback for (0, 0, 9) started
22:55:17 job_callback for (0, 0, 9) got condition
22:55:17 DISPATCHER: Trying to submit another job.
22:55:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:55:17 Only 3 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
22:55:17 HBMASTER: Trying to run another job!
22:55:17 job_callback for (0, 0, 9) finished
22:55:17 HBMASTER: schedule new run for iteration 0
22:55:17 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
22:55:17 HBMASTER: submitting job (0, 0, 11) to dispatcher
22:55:17 DISPATCHER: trying to submit job (0, 0, 11)
22:55:17 DISPATCHER: trying to notify the job_runner thread.
22:55:17 HBMASTER: job (0, 0, 11) submitted to dispatcher
22:55:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:55:17 DISPATCHER: Trying to submit another job.
22:55:17 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:55:17 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:55:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:55:17 WORKER: start processing job (0, 0, 11)
22:55:17 WORKER: args: ()
22:55:17 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 349, 'last_n_outputs': 46, 'leak_rate': 0.9346604303271233, 'lr': 0.00427071548012511, 'optimizer': 'SGD', 'sparsity': 0.8634961230062116, 'steps_to_train': 11, 'weight_decay': 0.024561642152629452}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:55:28 DISPATCHER: Starting worker discovery
22:55:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:55:28 DISPATCHER: Finished worker discovery
22:56:28 DISPATCHER: Starting worker discovery
22:56:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:56:28 DISPATCHER: Finished worker discovery
22:57:28 DISPATCHER: Starting worker discovery
22:57:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:57:28 DISPATCHER: Finished worker discovery
22:58:14 WORKER: done with job (0, 0, 11), trying to register it.
22:58:14 WORKER: registered result for job (0, 0, 11) with dispatcher
22:58:14 DISPATCHER: job (0, 0, 11) finished
22:58:14 DISPATCHER: register_result: lock acquired
22:58:14 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:58:14 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 349, 'last_n_outputs': 46, 'leak_rate': 0.9346604303271233, 'lr': 0.00427071548012511, 'optimizer': 'SGD', 'sparsity': 0.8634961230062116, 'steps_to_train': 11, 'weight_decay': 0.024561642152629452}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.10477432771000679, 'info': {'data03': 0.10477432771000679, 'config': "{'batch_size': 16, 'hidden_dim': 349, 'last_n_outputs': 46, 'leak_rate': 0.9346604303271233, 'lr': 0.00427071548012511, 'optimizer': 'SGD', 'sparsity': 0.8634961230062116, 'steps_to_train': 11, 'weight_decay': 0.024561642152629452}"}}
exception: None

22:58:14 job_callback for (0, 0, 11) started
22:58:14 job_callback for (0, 0, 11) got condition
22:58:14 DISPATCHER: Trying to submit another job.
22:58:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:58:14 Only 4 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
22:58:14 HBMASTER: Trying to run another job!
22:58:14 job_callback for (0, 0, 11) finished
22:58:14 HBMASTER: schedule new run for iteration 0
22:58:14 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
22:58:14 HBMASTER: submitting job (0, 0, 13) to dispatcher
22:58:14 DISPATCHER: trying to submit job (0, 0, 13)
22:58:14 DISPATCHER: trying to notify the job_runner thread.
22:58:14 HBMASTER: job (0, 0, 13) submitted to dispatcher
22:58:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:58:14 DISPATCHER: Trying to submit another job.
22:58:14 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:58:14 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:58:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:58:14 WORKER: start processing job (0, 0, 13)
22:58:14 WORKER: args: ()
22:58:14 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 969, 'last_n_outputs': 30, 'leak_rate': 0.9910761634606576, 'lr': 0.033712792166029945, 'optimizer': 'Adam', 'sparsity': 0.8551021534391973, 'steps_to_train': 66, 'weight_decay': 0.029714899388483484}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:58:28 DISPATCHER: Starting worker discovery
22:58:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:58:28 DISPATCHER: Finished worker discovery
22:59:28 DISPATCHER: Starting worker discovery
22:59:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:59:28 DISPATCHER: Finished worker discovery
23:00:28 DISPATCHER: Starting worker discovery
23:00:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:00:28 DISPATCHER: Finished worker discovery
23:01:04 WORKER: done with job (0, 0, 13), trying to register it.
23:01:04 WORKER: registered result for job (0, 0, 13) with dispatcher
23:01:04 DISPATCHER: job (0, 0, 13) finished
23:01:04 DISPATCHER: register_result: lock acquired
23:01:04 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
23:01:04 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 969, 'last_n_outputs': 30, 'leak_rate': 0.9910761634606576, 'lr': 0.033712792166029945, 'optimizer': 'Adam', 'sparsity': 0.8551021534391973, 'steps_to_train': 66, 'weight_decay': 0.029714899388483484}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0824957614265273, 'info': {'data03': 0.0824957614265273, 'config': "{'batch_size': 64, 'hidden_dim': 969, 'last_n_outputs': 30, 'leak_rate': 0.9910761634606576, 'lr': 0.033712792166029945, 'optimizer': 'Adam', 'sparsity': 0.8551021534391973, 'steps_to_train': 66, 'weight_decay': 0.029714899388483484}"}}
exception: None

23:01:04 job_callback for (0, 0, 13) started
23:01:04 job_callback for (0, 0, 13) got condition
23:01:04 DISPATCHER: Trying to submit another job.
23:01:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:01:04 Only 5 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
23:01:04 HBMASTER: Trying to run another job!
23:01:04 job_callback for (0, 0, 13) finished
23:01:04 HBMASTER: schedule new run for iteration 0
23:01:04 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
23:01:04 HBMASTER: submitting job (0, 0, 14) to dispatcher
23:01:04 DISPATCHER: trying to submit job (0, 0, 14)
23:01:04 DISPATCHER: trying to notify the job_runner thread.
23:01:04 HBMASTER: job (0, 0, 14) submitted to dispatcher
23:01:04 DISPATCHER: Trying to submit another job.
23:01:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:01:04 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776
23:01:04 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
23:01:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:01:04 WORKER: start processing job (0, 0, 14)
23:01:04 WORKER: args: ()
23:01:04 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 631, 'last_n_outputs': 31, 'leak_rate': 0.909302163563936, 'lr': 0.05465427432224087, 'optimizer': 'Adam', 'sparsity': 0.93625757699129, 'steps_to_train': 29, 'weight_decay': 0.04240086764997424}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:01:28 DISPATCHER: Starting worker discovery
23:01:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:01:28 DISPATCHER: Finished worker discovery
23:02:28 DISPATCHER: Starting worker discovery
23:02:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:02:28 DISPATCHER: Finished worker discovery
23:03:28 DISPATCHER: Starting worker discovery
23:03:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:03:28 DISPATCHER: Finished worker discovery
23:04:05 WORKER: done with job (0, 0, 14), trying to register it.
23:04:05 WORKER: registered result for job (0, 0, 14) with dispatcher
23:04:05 DISPATCHER: job (0, 0, 14) finished
23:04:05 DISPATCHER: register_result: lock acquired
23:04:05 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
23:04:05 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 631, 'last_n_outputs': 31, 'leak_rate': 0.909302163563936, 'lr': 0.05465427432224087, 'optimizer': 'Adam', 'sparsity': 0.93625757699129, 'steps_to_train': 29, 'weight_decay': 0.04240086764997424}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.22945171228697783, 'info': {'data03': 0.22945171228697783, 'config': "{'batch_size': 64, 'hidden_dim': 631, 'last_n_outputs': 31, 'leak_rate': 0.909302163563936, 'lr': 0.05465427432224087, 'optimizer': 'Adam', 'sparsity': 0.93625757699129, 'steps_to_train': 29, 'weight_decay': 0.04240086764997424}"}}
exception: None

23:04:05 job_callback for (0, 0, 14) started
23:04:05 job_callback for (0, 0, 14) got condition
23:04:05 DISPATCHER: Trying to submit another job.
23:04:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:04:05 Only 6 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
23:04:05 HBMASTER: Trying to run another job!
23:04:05 job_callback for (0, 0, 14) finished
23:04:05 HBMASTER: schedule new run for iteration 0
23:04:05 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
23:04:05 HBMASTER: submitting job (0, 0, 16) to dispatcher
23:04:05 DISPATCHER: trying to submit job (0, 0, 16)
23:04:05 DISPATCHER: trying to notify the job_runner thread.
23:04:05 HBMASTER: job (0, 0, 16) submitted to dispatcher
23:04:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:04:05 DISPATCHER: Trying to submit another job.
23:04:05 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpui.1576139975513683776
23:04:05 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
23:04:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:04:05 WORKER: start processing job (0, 0, 16)
23:04:05 WORKER: args: ()
23:04:05 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 517, 'last_n_outputs': 16, 'leak_rate': 0.9147597534980976, 'lr': 0.005947337584614059, 'optimizer': 'SGD', 'sparsity': 0.7948522395722545, 'steps_to_train': 28, 'weight_decay': 0.048497856310930544}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:04:28 DISPATCHER: Starting worker discovery
23:04:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:04:28 DISPATCHER: Finished worker discovery
23:05:28 DISPATCHER: Starting worker discovery
23:05:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:05:28 DISPATCHER: Finished worker discovery
23:06:28 DISPATCHER: Starting worker discovery
23:06:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:06:28 DISPATCHER: Finished worker discovery
23:06:57 WORKER: done with job (0, 0, 16), trying to register it.
23:06:57 WORKER: registered result for job (0, 0, 16) with dispatcher
23:06:57 DISPATCHER: job (0, 0, 16) finished
23:06:57 DISPATCHER: register_result: lock acquired
23:06:57 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
23:06:57 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 517, 'last_n_outputs': 16, 'leak_rate': 0.9147597534980976, 'lr': 0.005947337584614059, 'optimizer': 'SGD', 'sparsity': 0.7948522395722545, 'steps_to_train': 28, 'weight_decay': 0.048497856310930544}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0736777608944779, 'info': {'data03': 0.0736777608944779, 'config': "{'batch_size': 64, 'hidden_dim': 517, 'last_n_outputs': 16, 'leak_rate': 0.9147597534980976, 'lr': 0.005947337584614059, 'optimizer': 'SGD', 'sparsity': 0.7948522395722545, 'steps_to_train': 28, 'weight_decay': 0.048497856310930544}"}}
exception: None

23:06:57 job_callback for (0, 0, 16) started
23:06:57 DISPATCHER: Trying to submit another job.
23:06:57 job_callback for (0, 0, 16) got condition
23:06:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:06:57 Only 7 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
23:06:57 HBMASTER: Trying to run another job!
23:06:57 job_callback for (0, 0, 16) finished
23:06:57 HBMASTER: schedule new run for iteration 0
23:06:57 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
23:06:57 HBMASTER: submitting job (0, 0, 19) to dispatcher
23:06:57 DISPATCHER: trying to submit job (0, 0, 19)
23:06:57 DISPATCHER: trying to notify the job_runner thread.
23:06:57 HBMASTER: job (0, 0, 19) submitted to dispatcher
23:06:57 DISPATCHER: Trying to submit another job.
23:06:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:06:57 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpui.1576139975513683776
23:06:57 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
23:06:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:06:57 WORKER: start processing job (0, 0, 19)
23:06:57 WORKER: args: ()
23:06:57 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 704, 'last_n_outputs': 47, 'leak_rate': 0.9764401153072582, 'lr': 0.0015954686734114612, 'optimizer': 'Adam', 'sparsity': 0.9876387491195142, 'steps_to_train': 69, 'weight_decay': 0.028846297763280578}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:07:28 DISPATCHER: Starting worker discovery
23:07:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:07:28 DISPATCHER: Finished worker discovery
23:08:28 DISPATCHER: Starting worker discovery
23:08:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:08:28 DISPATCHER: Finished worker discovery
23:09:28 DISPATCHER: Starting worker discovery
23:09:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:09:28 DISPATCHER: Finished worker discovery
23:09:53 WORKER: done with job (0, 0, 19), trying to register it.
23:09:53 WORKER: registered result for job (0, 0, 19) with dispatcher
23:09:53 DISPATCHER: job (0, 0, 19) finished
23:09:53 DISPATCHER: register_result: lock acquired
23:09:53 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
23:09:53 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 704, 'last_n_outputs': 47, 'leak_rate': 0.9764401153072582, 'lr': 0.0015954686734114612, 'optimizer': 'Adam', 'sparsity': 0.9876387491195142, 'steps_to_train': 69, 'weight_decay': 0.028846297763280578}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3276837156940986, 'info': {'data03': 0.3276837156940986, 'config': "{'batch_size': 32, 'hidden_dim': 704, 'last_n_outputs': 47, 'leak_rate': 0.9764401153072582, 'lr': 0.0015954686734114612, 'optimizer': 'Adam', 'sparsity': 0.9876387491195142, 'steps_to_train': 69, 'weight_decay': 0.028846297763280578}"}}
exception: None

23:09:53 job_callback for (0, 0, 19) started
23:09:53 DISPATCHER: Trying to submit another job.
23:09:53 job_callback for (0, 0, 19) got condition
23:09:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:09:53 Only 8 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
23:09:53 HBMASTER: Trying to run another job!
23:09:53 job_callback for (0, 0, 19) finished
23:09:53 HBMASTER: schedule new run for iteration 0
23:09:53 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
23:09:53 HBMASTER: submitting job (0, 0, 25) to dispatcher
23:09:53 DISPATCHER: trying to submit job (0, 0, 25)
23:09:53 DISPATCHER: trying to notify the job_runner thread.
23:09:53 HBMASTER: job (0, 0, 25) submitted to dispatcher
23:09:53 DISPATCHER: Trying to submit another job.
23:09:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:09:53 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpui.1576139975513683776
23:09:53 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
23:09:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:09:53 WORKER: start processing job (0, 0, 25)
23:09:53 WORKER: args: ()
23:09:53 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 374, 'last_n_outputs': 47, 'leak_rate': 0.9513334354869376, 'lr': 0.01355556805203759, 'optimizer': 'Adam', 'sparsity': 0.8012724588903127, 'steps_to_train': 41, 'weight_decay': 0.17716875892917427}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:10:28 DISPATCHER: Starting worker discovery
23:10:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:10:28 DISPATCHER: Finished worker discovery
23:11:28 DISPATCHER: Starting worker discovery
23:11:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:11:29 DISPATCHER: Finished worker discovery
23:12:29 DISPATCHER: Starting worker discovery
23:12:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:12:29 DISPATCHER: Finished worker discovery
23:12:47 WORKER: done with job (0, 0, 25), trying to register it.
23:12:47 WORKER: registered result for job (0, 0, 25) with dispatcher
23:12:47 DISPATCHER: job (0, 0, 25) finished
23:12:47 DISPATCHER: register_result: lock acquired
23:12:47 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
23:12:47 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 374, 'last_n_outputs': 47, 'leak_rate': 0.9513334354869376, 'lr': 0.01355556805203759, 'optimizer': 'Adam', 'sparsity': 0.8012724588903127, 'steps_to_train': 41, 'weight_decay': 0.17716875892917427}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0310899514492436, 'info': {'data03': 0.0310899514492436, 'config': "{'batch_size': 16, 'hidden_dim': 374, 'last_n_outputs': 47, 'leak_rate': 0.9513334354869376, 'lr': 0.01355556805203759, 'optimizer': 'Adam', 'sparsity': 0.8012724588903127, 'steps_to_train': 41, 'weight_decay': 0.17716875892917427}"}}
exception: None

23:12:47 job_callback for (0, 0, 25) started
23:12:47 job_callback for (0, 0, 25) got condition
23:12:47 DISPATCHER: Trying to submit another job.
23:12:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:12:47 Only 9 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
23:12:47 HBMASTER: Trying to run another job!
23:12:47 job_callback for (0, 0, 25) finished
23:12:47 ITERATION: Advancing config (0, 0, 3) to next budget 400.000000
23:12:47 ITERATION: Advancing config (0, 0, 14) to next budget 400.000000
23:12:47 ITERATION: Advancing config (0, 0, 19) to next budget 400.000000
23:12:47 HBMASTER: schedule new run for iteration 0
23:12:47 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
23:12:47 HBMASTER: submitting job (0, 0, 3) to dispatcher
23:12:47 DISPATCHER: trying to submit job (0, 0, 3)
23:12:47 DISPATCHER: trying to notify the job_runner thread.
23:12:47 HBMASTER: job (0, 0, 3) submitted to dispatcher
23:12:47 DISPATCHER: Trying to submit another job.
23:12:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:12:47 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
23:12:47 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
23:12:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:12:47 WORKER: start processing job (0, 0, 3)
23:12:47 WORKER: args: ()
23:12:47 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 596, 'last_n_outputs': 30, 'leak_rate': 0.8409248207361791, 'lr': 0.015439964563484001, 'optimizer': 'Adam', 'sparsity': 0.8188208398247486, 'steps_to_train': 82, 'weight_decay': 0.0854083402505829}, 'budget': 400.0, 'working_directory': '.'}
23:13:29 DISPATCHER: Starting worker discovery
23:13:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:13:29 DISPATCHER: Finished worker discovery
23:14:29 DISPATCHER: Starting worker discovery
23:14:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:14:29 DISPATCHER: Finished worker discovery
23:15:29 DISPATCHER: Starting worker discovery
23:15:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:15:29 DISPATCHER: Finished worker discovery
23:16:29 DISPATCHER: Starting worker discovery
23:16:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:16:29 DISPATCHER: Finished worker discovery
23:17:29 DISPATCHER: Starting worker discovery
23:17:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:17:29 DISPATCHER: Finished worker discovery
23:18:29 DISPATCHER: Starting worker discovery
23:18:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:18:29 DISPATCHER: Finished worker discovery
23:19:29 DISPATCHER: Starting worker discovery
23:19:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:19:29 DISPATCHER: Finished worker discovery
23:20:21 WORKER: done with job (0, 0, 3), trying to register it.
23:20:21 WORKER: registered result for job (0, 0, 3) with dispatcher
23:20:21 DISPATCHER: job (0, 0, 3) finished
23:20:21 DISPATCHER: register_result: lock acquired
23:20:21 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
23:20:21 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 596, 'last_n_outputs': 30, 'leak_rate': 0.8409248207361791, 'lr': 0.015439964563484001, 'optimizer': 'Adam', 'sparsity': 0.8188208398247486, 'steps_to_train': 82, 'weight_decay': 0.0854083402505829}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.17032614910524646, 'info': {'data03': 0.17032614910524646, 'config': "{'batch_size': 16, 'hidden_dim': 596, 'last_n_outputs': 30, 'leak_rate': 0.8409248207361791, 'lr': 0.015439964563484001, 'optimizer': 'Adam', 'sparsity': 0.8188208398247486, 'steps_to_train': 82, 'weight_decay': 0.0854083402505829}"}}
exception: None

23:20:21 job_callback for (0, 0, 3) started
23:20:21 DISPATCHER: Trying to submit another job.
23:20:21 job_callback for (0, 0, 3) got condition
23:20:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:20:21 Only 1 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
23:20:21 HBMASTER: Trying to run another job!
23:20:21 job_callback for (0, 0, 3) finished
23:20:21 HBMASTER: schedule new run for iteration 0
23:20:21 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
23:20:21 HBMASTER: submitting job (0, 0, 14) to dispatcher
23:20:21 DISPATCHER: trying to submit job (0, 0, 14)
23:20:21 DISPATCHER: trying to notify the job_runner thread.
23:20:21 HBMASTER: job (0, 0, 14) submitted to dispatcher
23:20:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:20:21 DISPATCHER: Trying to submit another job.
23:20:21 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776
23:20:21 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
23:20:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:20:21 WORKER: start processing job (0, 0, 14)
23:20:21 WORKER: args: ()
23:20:21 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 631, 'last_n_outputs': 31, 'leak_rate': 0.909302163563936, 'lr': 0.05465427432224087, 'optimizer': 'Adam', 'sparsity': 0.93625757699129, 'steps_to_train': 29, 'weight_decay': 0.04240086764997424}, 'budget': 400.0, 'working_directory': '.'}
23:20:29 DISPATCHER: Starting worker discovery
23:20:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:20:29 DISPATCHER: Finished worker discovery
23:21:29 DISPATCHER: Starting worker discovery
23:21:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:21:29 DISPATCHER: Finished worker discovery
23:22:29 DISPATCHER: Starting worker discovery
23:22:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:22:29 DISPATCHER: Finished worker discovery
23:23:29 DISPATCHER: Starting worker discovery
23:23:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:23:29 DISPATCHER: Finished worker discovery
23:24:29 DISPATCHER: Starting worker discovery
23:24:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:24:29 DISPATCHER: Finished worker discovery
23:25:29 DISPATCHER: Starting worker discovery
23:25:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:25:29 DISPATCHER: Finished worker discovery
23:26:29 DISPATCHER: Starting worker discovery
23:26:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:26:29 DISPATCHER: Finished worker discovery
23:27:29 DISPATCHER: Starting worker discovery
23:27:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:27:29 DISPATCHER: Finished worker discovery
23:27:39 WORKER: done with job (0, 0, 14), trying to register it.
23:27:39 WORKER: registered result for job (0, 0, 14) with dispatcher
23:27:39 DISPATCHER: job (0, 0, 14) finished
23:27:39 DISPATCHER: register_result: lock acquired
23:27:39 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
23:27:39 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 631, 'last_n_outputs': 31, 'leak_rate': 0.909302163563936, 'lr': 0.05465427432224087, 'optimizer': 'Adam', 'sparsity': 0.93625757699129, 'steps_to_train': 29, 'weight_decay': 0.04240086764997424}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.05208650105804559, 'info': {'data03': 0.05208650105804559, 'config': "{'batch_size': 64, 'hidden_dim': 631, 'last_n_outputs': 31, 'leak_rate': 0.909302163563936, 'lr': 0.05465427432224087, 'optimizer': 'Adam', 'sparsity': 0.93625757699129, 'steps_to_train': 29, 'weight_decay': 0.04240086764997424}"}}
exception: None

23:27:39 job_callback for (0, 0, 14) started
23:27:39 job_callback for (0, 0, 14) got condition
23:27:39 DISPATCHER: Trying to submit another job.
23:27:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:27:39 Only 2 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
23:27:39 HBMASTER: Trying to run another job!
23:27:39 job_callback for (0, 0, 14) finished
23:27:39 HBMASTER: schedule new run for iteration 0
23:27:39 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
23:27:39 HBMASTER: submitting job (0, 0, 19) to dispatcher
23:27:39 DISPATCHER: trying to submit job (0, 0, 19)
23:27:39 DISPATCHER: trying to notify the job_runner thread.
23:27:39 HBMASTER: job (0, 0, 19) submitted to dispatcher
23:27:39 DISPATCHER: Trying to submit another job.
23:27:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:27:39 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpui.1576139975513683776
23:27:39 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
23:27:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:27:39 WORKER: start processing job (0, 0, 19)
23:27:39 WORKER: args: ()
23:27:39 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 704, 'last_n_outputs': 47, 'leak_rate': 0.9764401153072582, 'lr': 0.0015954686734114612, 'optimizer': 'Adam', 'sparsity': 0.9876387491195142, 'steps_to_train': 69, 'weight_decay': 0.028846297763280578}, 'budget': 400.0, 'working_directory': '.'}
23:28:29 DISPATCHER: Starting worker discovery
23:28:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:28:29 DISPATCHER: Finished worker discovery
23:29:29 DISPATCHER: Starting worker discovery
23:29:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:29:29 DISPATCHER: Finished worker discovery
23:30:29 DISPATCHER: Starting worker discovery
23:30:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:30:29 DISPATCHER: Finished worker discovery
23:31:29 DISPATCHER: Starting worker discovery
23:31:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:31:29 DISPATCHER: Finished worker discovery
23:32:29 DISPATCHER: Starting worker discovery
23:32:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:32:29 DISPATCHER: Finished worker discovery
23:33:29 DISPATCHER: Starting worker discovery
23:33:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:33:29 DISPATCHER: Finished worker discovery
23:34:29 DISPATCHER: Starting worker discovery
23:34:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:34:29 DISPATCHER: Finished worker discovery
23:35:08 WORKER: done with job (0, 0, 19), trying to register it.
23:35:08 WORKER: registered result for job (0, 0, 19) with dispatcher
23:35:08 DISPATCHER: job (0, 0, 19) finished
23:35:08 DISPATCHER: register_result: lock acquired
23:35:08 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
23:35:08 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 704, 'last_n_outputs': 47, 'leak_rate': 0.9764401153072582, 'lr': 0.0015954686734114612, 'optimizer': 'Adam', 'sparsity': 0.9876387491195142, 'steps_to_train': 69, 'weight_decay': 0.028846297763280578}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.2733417604515979, 'info': {'data03': 0.2733417604515979, 'config': "{'batch_size': 32, 'hidden_dim': 704, 'last_n_outputs': 47, 'leak_rate': 0.9764401153072582, 'lr': 0.0015954686734114612, 'optimizer': 'Adam', 'sparsity': 0.9876387491195142, 'steps_to_train': 69, 'weight_decay': 0.028846297763280578}"}}
exception: None

23:35:08 job_callback for (0, 0, 19) started
23:35:08 job_callback for (0, 0, 19) got condition
23:35:08 DISPATCHER: Trying to submit another job.
23:35:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:35:08 Only 3 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
23:35:08 HBMASTER: Trying to run another job!
23:35:08 job_callback for (0, 0, 19) finished
23:35:08 ITERATION: Advancing config (0, 0, 19) to next budget 1200.000000
23:35:08 HBMASTER: schedule new run for iteration 0
23:35:08 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
23:35:08 HBMASTER: submitting job (0, 0, 19) to dispatcher
23:35:08 DISPATCHER: trying to submit job (0, 0, 19)
23:35:08 DISPATCHER: trying to notify the job_runner thread.
23:35:08 HBMASTER: job (0, 0, 19) submitted to dispatcher
23:35:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:35:08 DISPATCHER: Trying to submit another job.
23:35:08 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpui.1576139975513683776
23:35:08 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
23:35:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:35:08 WORKER: start processing job (0, 0, 19)
23:35:08 WORKER: args: ()
23:35:08 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 704, 'last_n_outputs': 47, 'leak_rate': 0.9764401153072582, 'lr': 0.0015954686734114612, 'optimizer': 'Adam', 'sparsity': 0.9876387491195142, 'steps_to_train': 69, 'weight_decay': 0.028846297763280578}, 'budget': 1200.0, 'working_directory': '.'}
23:35:29 DISPATCHER: Starting worker discovery
23:35:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:35:29 DISPATCHER: Finished worker discovery
23:36:29 DISPATCHER: Starting worker discovery
23:36:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:36:29 DISPATCHER: Finished worker discovery
23:37:29 DISPATCHER: Starting worker discovery
23:37:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:37:29 DISPATCHER: Finished worker discovery
23:38:29 DISPATCHER: Starting worker discovery
23:38:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:38:29 DISPATCHER: Finished worker discovery
23:39:29 DISPATCHER: Starting worker discovery
23:39:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:39:29 DISPATCHER: Finished worker discovery
23:40:29 DISPATCHER: Starting worker discovery
23:40:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:40:29 DISPATCHER: Finished worker discovery
23:41:29 DISPATCHER: Starting worker discovery
23:41:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:41:29 DISPATCHER: Finished worker discovery
23:42:29 DISPATCHER: Starting worker discovery
23:42:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:42:29 DISPATCHER: Finished worker discovery
23:43:29 DISPATCHER: Starting worker discovery
23:43:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:43:29 DISPATCHER: Finished worker discovery
23:44:29 DISPATCHER: Starting worker discovery
23:44:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:44:29 DISPATCHER: Finished worker discovery
23:45:29 DISPATCHER: Starting worker discovery
23:45:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:45:29 DISPATCHER: Finished worker discovery
23:46:29 DISPATCHER: Starting worker discovery
23:46:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:46:29 DISPATCHER: Finished worker discovery
23:47:29 DISPATCHER: Starting worker discovery
23:47:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:47:29 DISPATCHER: Finished worker discovery
23:48:29 DISPATCHER: Starting worker discovery
23:48:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:48:29 DISPATCHER: Finished worker discovery
23:49:29 DISPATCHER: Starting worker discovery
23:49:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:49:29 DISPATCHER: Finished worker discovery
23:50:29 DISPATCHER: Starting worker discovery
23:50:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:50:29 DISPATCHER: Finished worker discovery
23:51:29 DISPATCHER: Starting worker discovery
23:51:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:51:29 DISPATCHER: Finished worker discovery
23:52:29 DISPATCHER: Starting worker discovery
23:52:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:52:29 DISPATCHER: Finished worker discovery
23:53:29 DISPATCHER: Starting worker discovery
23:53:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:53:29 DISPATCHER: Finished worker discovery
23:54:29 DISPATCHER: Starting worker discovery
23:54:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:54:29 DISPATCHER: Finished worker discovery
23:55:29 DISPATCHER: Starting worker discovery
23:55:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:55:29 DISPATCHER: Finished worker discovery
23:56:10 WORKER: done with job (0, 0, 19), trying to register it.
23:56:10 WORKER: registered result for job (0, 0, 19) with dispatcher
23:56:10 DISPATCHER: job (0, 0, 19) finished
23:56:10 DISPATCHER: register_result: lock acquired
23:56:10 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
23:56:10 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 704, 'last_n_outputs': 47, 'leak_rate': 0.9764401153072582, 'lr': 0.0015954686734114612, 'optimizer': 'Adam', 'sparsity': 0.9876387491195142, 'steps_to_train': 69, 'weight_decay': 0.028846297763280578}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.30984212285629464, 'info': {'data03': 0.30984212285629464, 'config': "{'batch_size': 32, 'hidden_dim': 704, 'last_n_outputs': 47, 'leak_rate': 0.9764401153072582, 'lr': 0.0015954686734114612, 'optimizer': 'Adam', 'sparsity': 0.9876387491195142, 'steps_to_train': 69, 'weight_decay': 0.028846297763280578}"}}
exception: None

23:56:10 job_callback for (0, 0, 19) started
23:56:10 DISPATCHER: Trying to submit another job.
23:56:10 job_callback for (0, 0, 19) got condition
23:56:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:56:10 Only 1 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
23:56:10 HBMASTER: Trying to run another job!
23:56:10 job_callback for (0, 0, 19) finished
23:56:10 start sampling a new configuration.
23:56:10 best_vector: [0, 0.48551678911018936, 0.9300492321682319, 0.7683018245155466, 0.02209075916055621, 1, 0.9162108435759807, 0.6880251825767103, 0.27555917564661275], 0.02239351731864317, 0.478719359772125, 0.010720210273826851
23:56:10 done sampling a new configuration.
23:56:10 HBMASTER: schedule new run for iteration 1
23:56:10 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
23:56:10 HBMASTER: submitting job (1, 0, 0) to dispatcher
23:56:10 DISPATCHER: trying to submit job (1, 0, 0)
23:56:10 DISPATCHER: trying to notify the job_runner thread.
23:56:10 HBMASTER: job (1, 0, 0) submitted to dispatcher
23:56:10 DISPATCHER: Trying to submit another job.
23:56:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:56:10 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
23:56:10 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
23:56:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:56:10 WORKER: start processing job (1, 0, 0)
23:56:10 WORKER: args: ()
23:56:10 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 588, 'last_n_outputs': 48, 'leak_rate': 0.9420754561288867, 'lr': 0.0011070864066543605, 'optimizer': 'SGD', 'sparsity': 0.9698906024582353, 'steps_to_train': 72, 'weight_decay': 0.022830254515072}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:56:29 DISPATCHER: Starting worker discovery
23:56:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:56:29 DISPATCHER: Finished worker discovery
23:57:29 DISPATCHER: Starting worker discovery
23:57:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:57:29 DISPATCHER: Finished worker discovery
23:58:29 DISPATCHER: Starting worker discovery
23:58:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:58:29 DISPATCHER: Finished worker discovery
23:59:02 WORKER: done with job (1, 0, 0), trying to register it.
23:59:02 WORKER: registered result for job (1, 0, 0) with dispatcher
23:59:02 DISPATCHER: job (1, 0, 0) finished
23:59:02 DISPATCHER: register_result: lock acquired
23:59:02 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
23:59:02 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 588, 'last_n_outputs': 48, 'leak_rate': 0.9420754561288867, 'lr': 0.0011070864066543605, 'optimizer': 'SGD', 'sparsity': 0.9698906024582353, 'steps_to_train': 72, 'weight_decay': 0.022830254515072}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.25098982233217276, 'info': {'data03': 0.25098982233217276, 'config': "{'batch_size': 16, 'hidden_dim': 588, 'last_n_outputs': 48, 'leak_rate': 0.9420754561288867, 'lr': 0.0011070864066543605, 'optimizer': 'SGD', 'sparsity': 0.9698906024582353, 'steps_to_train': 72, 'weight_decay': 0.022830254515072}"}}
exception: None

23:59:02 job_callback for (1, 0, 0) started
23:59:02 DISPATCHER: Trying to submit another job.
23:59:02 job_callback for (1, 0, 0) got condition
23:59:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:59:02 HBMASTER: Trying to run another job!
23:59:02 job_callback for (1, 0, 0) finished
23:59:02 start sampling a new configuration.
23:59:02 best_vector: [0, 0.8473046444920715, 0.3612248628871819, 0.8426096472850804, 0.8015216304718865, 0, 0.5189572537757283, 0.40179203008702974, 0.46562764298376114], 0.08630913199212017, 0.4495770308440069, 0.038802603295740874
23:59:02 done sampling a new configuration.
23:59:02 HBMASTER: schedule new run for iteration 1
23:59:02 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
23:59:02 HBMASTER: submitting job (1, 0, 1) to dispatcher
23:59:02 DISPATCHER: trying to submit job (1, 0, 1)
23:59:02 DISPATCHER: trying to notify the job_runner thread.
23:59:02 HBMASTER: job (1, 0, 1) submitted to dispatcher
23:59:02 DISPATCHER: Trying to submit another job.
23:59:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:59:02 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
23:59:02 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
23:59:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:59:02 WORKER: start processing job (1, 0, 1)
23:59:02 WORKER: args: ()
23:59:02 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 878, 'last_n_outputs': 24, 'leak_rate': 0.96065241182127, 'lr': 0.040090665075335555, 'optimizer': 'Adam', 'sparsity': 0.8745497409061748, 'steps_to_train': 46, 'weight_decay': 0.0403455397890046}, 'budget': 133.33333333333331, 'working_directory': '.'}
23:59:29 DISPATCHER: Starting worker discovery
23:59:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:59:29 DISPATCHER: Finished worker discovery
00:00:29 DISPATCHER: Starting worker discovery
00:00:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:00:29 DISPATCHER: Finished worker discovery
00:01:29 DISPATCHER: Starting worker discovery
00:01:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:01:29 DISPATCHER: Finished worker discovery
00:02:13 WORKER: done with job (1, 0, 1), trying to register it.
00:02:13 WORKER: registered result for job (1, 0, 1) with dispatcher
00:02:13 DISPATCHER: job (1, 0, 1) finished
00:02:13 DISPATCHER: register_result: lock acquired
00:02:13 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:02:13 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 878, 'last_n_outputs': 24, 'leak_rate': 0.96065241182127, 'lr': 0.040090665075335555, 'optimizer': 'Adam', 'sparsity': 0.8745497409061748, 'steps_to_train': 46, 'weight_decay': 0.0403455397890046}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.19928978091948826, 'info': {'data03': 0.19928978091948826, 'config': "{'batch_size': 16, 'hidden_dim': 878, 'last_n_outputs': 24, 'leak_rate': 0.96065241182127, 'lr': 0.040090665075335555, 'optimizer': 'Adam', 'sparsity': 0.8745497409061748, 'steps_to_train': 46, 'weight_decay': 0.0403455397890046}"}}
exception: None

00:02:13 job_callback for (1, 0, 1) started
00:02:13 DISPATCHER: Trying to submit another job.
00:02:13 job_callback for (1, 0, 1) got condition
00:02:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:02:13 HBMASTER: Trying to run another job!
00:02:13 job_callback for (1, 0, 1) finished
00:02:13 start sampling a new configuration.
00:02:13 best_vector: [0, 0.6670567593965505, 0.2124750220255336, 0.861694470358026, 0.7390656486259168, 1, 0.19422986295671202, 0.079904657702595, 0.5521512485693658], 0.028822558922321242, 0.11772949191448127, 0.003393265217600079
00:02:13 done sampling a new configuration.
00:02:13 HBMASTER: schedule new run for iteration 1
00:02:13 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
00:02:13 HBMASTER: submitting job (1, 0, 2) to dispatcher
00:02:13 DISPATCHER: trying to submit job (1, 0, 2)
00:02:13 DISPATCHER: trying to notify the job_runner thread.
00:02:13 HBMASTER: job (1, 0, 2) submitted to dispatcher
00:02:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:02:13 DISPATCHER: Trying to submit another job.
00:02:13 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:02:13 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:02:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:02:13 WORKER: start processing job (1, 0, 2)
00:02:13 WORKER: args: ()
00:02:13 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 734, 'last_n_outputs': 18, 'leak_rate': 0.9654236175895066, 'lr': 0.03006985246309729, 'optimizer': 'SGD', 'sparsity': 0.7966151671096109, 'steps_to_train': 17, 'weight_decay': 0.052283582320117934}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:02:29 DISPATCHER: Starting worker discovery
00:02:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:02:29 DISPATCHER: Finished worker discovery
00:03:29 DISPATCHER: Starting worker discovery
00:03:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:03:29 DISPATCHER: Finished worker discovery
00:04:29 DISPATCHER: Starting worker discovery
00:04:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:04:29 DISPATCHER: Finished worker discovery
00:05:09 WORKER: done with job (1, 0, 2), trying to register it.
00:05:09 WORKER: registered result for job (1, 0, 2) with dispatcher
00:05:09 DISPATCHER: job (1, 0, 2) finished
00:05:09 DISPATCHER: register_result: lock acquired
00:05:09 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:05:09 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 734, 'last_n_outputs': 18, 'leak_rate': 0.9654236175895066, 'lr': 0.03006985246309729, 'optimizer': 'SGD', 'sparsity': 0.7966151671096109, 'steps_to_train': 17, 'weight_decay': 0.052283582320117934}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.007261849284551664, 'info': {'data03': 0.007261849284551664, 'config': "{'batch_size': 16, 'hidden_dim': 734, 'last_n_outputs': 18, 'leak_rate': 0.9654236175895066, 'lr': 0.03006985246309729, 'optimizer': 'SGD', 'sparsity': 0.7966151671096109, 'steps_to_train': 17, 'weight_decay': 0.052283582320117934}"}}
exception: None

00:05:09 job_callback for (1, 0, 2) started
00:05:09 job_callback for (1, 0, 2) got condition
00:05:09 DISPATCHER: Trying to submit another job.
00:05:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:05:09 HBMASTER: Trying to run another job!
00:05:09 job_callback for (1, 0, 2) finished
00:05:09 start sampling a new configuration.
00:05:09 best_vector: [1, 0.44401989702592587, 0.7251796699917369, 0.7947772366674264, 0.6184733090925899, 0, 0.42692685570601785, 0.41131758723943374, 0.8735034281693619], 0.10156414941199512, 0.33062371495720394, 0.03357951638506235
00:05:09 done sampling a new configuration.
00:05:09 HBMASTER: schedule new run for iteration 1
00:05:09 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
00:05:09 HBMASTER: submitting job (1, 0, 3) to dispatcher
00:05:09 DISPATCHER: trying to submit job (1, 0, 3)
00:05:09 DISPATCHER: trying to notify the job_runner thread.
00:05:09 HBMASTER: job (1, 0, 3) submitted to dispatcher
00:05:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:05:09 DISPATCHER: Trying to submit another job.
00:05:09 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:05:09 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:05:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:05:09 WORKER: start processing job (1, 0, 3)
00:05:09 WORKER: args: ()
00:05:09 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 555, 'last_n_outputs': 39, 'leak_rate': 0.9486943091668566, 'lr': 0.017256257716414588, 'optimizer': 'Adam', 'sparsity': 0.8524624453694443, 'steps_to_train': 47, 'weight_decay': 0.13691598695539084}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:05:29 DISPATCHER: Starting worker discovery
00:05:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:05:29 DISPATCHER: Finished worker discovery
00:06:29 DISPATCHER: Starting worker discovery
00:06:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:06:29 DISPATCHER: Finished worker discovery
00:07:29 DISPATCHER: Starting worker discovery
00:07:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:07:29 DISPATCHER: Finished worker discovery
00:08:04 WORKER: done with job (1, 0, 3), trying to register it.
00:08:04 WORKER: registered result for job (1, 0, 3) with dispatcher
00:08:04 DISPATCHER: job (1, 0, 3) finished
00:08:04 DISPATCHER: register_result: lock acquired
00:08:04 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:08:04 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 555, 'last_n_outputs': 39, 'leak_rate': 0.9486943091668566, 'lr': 0.017256257716414588, 'optimizer': 'Adam', 'sparsity': 0.8524624453694443, 'steps_to_train': 47, 'weight_decay': 0.13691598695539084}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.035758660526910145, 'info': {'data03': 0.035758660526910145, 'config': "{'batch_size': 32, 'hidden_dim': 555, 'last_n_outputs': 39, 'leak_rate': 0.9486943091668566, 'lr': 0.017256257716414588, 'optimizer': 'Adam', 'sparsity': 0.8524624453694443, 'steps_to_train': 47, 'weight_decay': 0.13691598695539084}"}}
exception: None

00:08:04 job_callback for (1, 0, 3) started
00:08:04 job_callback for (1, 0, 3) got condition
00:08:04 DISPATCHER: Trying to submit another job.
00:08:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:08:04 HBMASTER: Trying to run another job!
00:08:04 job_callback for (1, 0, 3) finished
00:08:04 start sampling a new configuration.
00:08:04 best_vector: [3, 0.8049282223820179, 0.09257146413544816, 0.8384378549894697, 0.410076620719889, 1, 0.21166376486665767, 0.1988072195780852, 0.6625143790444858], 0.09069186559883707, 0.1609554102505511, 0.014597346433848662
00:08:04 done sampling a new configuration.
00:08:04 HBMASTER: schedule new run for iteration 1
00:08:04 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
00:08:04 HBMASTER: submitting job (1, 0, 4) to dispatcher
00:08:04 DISPATCHER: trying to submit job (1, 0, 4)
00:08:04 DISPATCHER: trying to notify the job_runner thread.
00:08:04 HBMASTER: job (1, 0, 4) submitted to dispatcher
00:08:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:08:04 DISPATCHER: Trying to submit another job.
00:08:04 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:08:04 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:08:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:08:04 WORKER: start processing job (1, 0, 4)
00:08:04 WORKER: args: ()
00:08:04 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 844, 'last_n_outputs': 13, 'leak_rate': 0.9596094637473674, 'lr': 0.006609266157863191, 'optimizer': 'SGD', 'sparsity': 0.8007993035679979, 'steps_to_train': 28, 'weight_decay': 0.07276978297341871}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:08:29 DISPATCHER: Starting worker discovery
00:08:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:08:29 DISPATCHER: Finished worker discovery
00:09:29 DISPATCHER: Starting worker discovery
00:09:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:09:29 DISPATCHER: Finished worker discovery
00:10:29 DISPATCHER: Starting worker discovery
00:10:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:10:29 DISPATCHER: Finished worker discovery
00:11:09 WORKER: done with job (1, 0, 4), trying to register it.
00:11:09 WORKER: registered result for job (1, 0, 4) with dispatcher
00:11:09 DISPATCHER: job (1, 0, 4) finished
00:11:09 DISPATCHER: register_result: lock acquired
00:11:09 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:11:09 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 844, 'last_n_outputs': 13, 'leak_rate': 0.9596094637473674, 'lr': 0.006609266157863191, 'optimizer': 'SGD', 'sparsity': 0.8007993035679979, 'steps_to_train': 28, 'weight_decay': 0.07276978297341871}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.051015491488927076, 'info': {'data03': 0.051015491488927076, 'config': "{'batch_size': 128, 'hidden_dim': 844, 'last_n_outputs': 13, 'leak_rate': 0.9596094637473674, 'lr': 0.006609266157863191, 'optimizer': 'SGD', 'sparsity': 0.8007993035679979, 'steps_to_train': 28, 'weight_decay': 0.07276978297341871}"}}
exception: None

00:11:09 job_callback for (1, 0, 4) started
00:11:09 job_callback for (1, 0, 4) got condition
00:11:09 DISPATCHER: Trying to submit another job.
00:11:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:11:09 HBMASTER: Trying to run another job!
00:11:09 job_callback for (1, 0, 4) finished
00:11:09 start sampling a new configuration.
00:11:09 done sampling a new configuration.
00:11:09 HBMASTER: schedule new run for iteration 1
00:11:09 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
00:11:09 HBMASTER: submitting job (1, 0, 5) to dispatcher
00:11:09 DISPATCHER: trying to submit job (1, 0, 5)
00:11:09 DISPATCHER: trying to notify the job_runner thread.
00:11:09 HBMASTER: job (1, 0, 5) submitted to dispatcher
00:11:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:11:09 DISPATCHER: Trying to submit another job.
00:11:09 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:11:09 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:11:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:11:09 WORKER: start processing job (1, 0, 5)
00:11:09 WORKER: args: ()
00:11:09 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 771, 'last_n_outputs': 49, 'leak_rate': 0.7942158580896511, 'lr': 0.04182966079982641, 'optimizer': 'Adam', 'sparsity': 0.8032876750438469, 'steps_to_train': 86, 'weight_decay': 0.12995086887243928}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:11:29 DISPATCHER: Starting worker discovery
00:11:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:11:29 DISPATCHER: Finished worker discovery
00:12:29 DISPATCHER: Starting worker discovery
00:12:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:12:29 DISPATCHER: Finished worker discovery
00:13:29 DISPATCHER: Starting worker discovery
00:13:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:13:29 DISPATCHER: Finished worker discovery
00:14:14 WORKER: done with job (1, 0, 5), trying to register it.
00:14:14 WORKER: registered result for job (1, 0, 5) with dispatcher
00:14:14 DISPATCHER: job (1, 0, 5) finished
00:14:14 DISPATCHER: register_result: lock acquired
00:14:14 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:14:14 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 771, 'last_n_outputs': 49, 'leak_rate': 0.7942158580896511, 'lr': 0.04182966079982641, 'optimizer': 'Adam', 'sparsity': 0.8032876750438469, 'steps_to_train': 86, 'weight_decay': 0.12995086887243928}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.151907479736279, 'info': {'data03': 0.151907479736279, 'config': "{'batch_size': 16, 'hidden_dim': 771, 'last_n_outputs': 49, 'leak_rate': 0.7942158580896511, 'lr': 0.04182966079982641, 'optimizer': 'Adam', 'sparsity': 0.8032876750438469, 'steps_to_train': 86, 'weight_decay': 0.12995086887243928}"}}
exception: None

00:14:14 job_callback for (1, 0, 5) started
00:14:14 DISPATCHER: Trying to submit another job.
00:14:14 job_callback for (1, 0, 5) got condition
00:14:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:14:14 HBMASTER: Trying to run another job!
00:14:14 job_callback for (1, 0, 5) finished
00:14:14 start sampling a new configuration.
00:14:14 done sampling a new configuration.
00:14:14 HBMASTER: schedule new run for iteration 1
00:14:14 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
00:14:14 HBMASTER: submitting job (1, 0, 6) to dispatcher
00:14:14 DISPATCHER: trying to submit job (1, 0, 6)
00:14:14 DISPATCHER: trying to notify the job_runner thread.
00:14:14 HBMASTER: job (1, 0, 6) submitted to dispatcher
00:14:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:14:14 DISPATCHER: Trying to submit another job.
00:14:14 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:14:14 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:14:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:14:14 WORKER: start processing job (1, 0, 6)
00:14:14 WORKER: args: ()
00:14:14 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 440, 'last_n_outputs': 24, 'leak_rate': 0.7949810950942214, 'lr': 0.0017577513954390087, 'optimizer': 'SGD', 'sparsity': 0.7720027894304851, 'steps_to_train': 48, 'weight_decay': 0.022944621499702285}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:14:29 DISPATCHER: Starting worker discovery
00:14:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:14:29 DISPATCHER: Finished worker discovery
00:15:29 DISPATCHER: Starting worker discovery
00:15:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:15:29 DISPATCHER: Finished worker discovery
00:16:29 DISPATCHER: Starting worker discovery
00:16:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:16:29 DISPATCHER: Finished worker discovery
00:17:29 WORKER: done with job (1, 0, 6), trying to register it.
00:17:29 WORKER: registered result for job (1, 0, 6) with dispatcher
00:17:29 DISPATCHER: job (1, 0, 6) finished
00:17:29 DISPATCHER: register_result: lock acquired
00:17:29 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:17:29 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 440, 'last_n_outputs': 24, 'leak_rate': 0.7949810950942214, 'lr': 0.0017577513954390087, 'optimizer': 'SGD', 'sparsity': 0.7720027894304851, 'steps_to_train': 48, 'weight_decay': 0.022944621499702285}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.11566165401372414, 'info': {'data03': 0.11566165401372414, 'config': "{'batch_size': 32, 'hidden_dim': 440, 'last_n_outputs': 24, 'leak_rate': 0.7949810950942214, 'lr': 0.0017577513954390087, 'optimizer': 'SGD', 'sparsity': 0.7720027894304851, 'steps_to_train': 48, 'weight_decay': 0.022944621499702285}"}}
exception: None

00:17:29 job_callback for (1, 0, 6) started
00:17:29 DISPATCHER: Trying to submit another job.
00:17:29 job_callback for (1, 0, 6) got condition
00:17:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:17:29 HBMASTER: Trying to run another job!
00:17:29 job_callback for (1, 0, 6) finished
00:17:29 start sampling a new configuration.
00:17:29 DISPATCHER: Starting worker discovery
00:17:29 best_vector: [3, 0.22928665034540097, 0.982445833193083, 0.7654366094992593, 0.8124109495554389, 0, 0.2360733373192908, 0.06990859825352447, 0.9484948063801366], 0.0021903765921983207, 0.2874834784221373, 0.0006296970817796005
00:17:29 done sampling a new configuration.
00:17:29 HBMASTER: schedule new run for iteration 1
00:17:29 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
00:17:29 HBMASTER: submitting job (1, 0, 7) to dispatcher
00:17:29 DISPATCHER: trying to submit job (1, 0, 7)
00:17:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:17:29 DISPATCHER: Finished worker discovery
00:17:29 DISPATCHER: trying to notify the job_runner thread.
00:17:29 HBMASTER: job (1, 0, 7) submitted to dispatcher
00:17:29 DISPATCHER: Trying to submit another job.
00:17:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:17:29 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:17:29 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:17:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:17:29 WORKER: start processing job (1, 0, 7)
00:17:29 WORKER: args: ()
00:17:29 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 383, 'last_n_outputs': 50, 'leak_rate': 0.9413591523748148, 'lr': 0.04215236043300783, 'optimizer': 'Adam', 'sparsity': 0.8066576009566298, 'steps_to_train': 16, 'weight_decay': 0.17140370049767487}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:18:29 DISPATCHER: Starting worker discovery
00:18:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:18:29 DISPATCHER: Finished worker discovery
00:19:29 DISPATCHER: Starting worker discovery
00:19:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:19:29 DISPATCHER: Finished worker discovery
00:20:25 WORKER: done with job (1, 0, 7), trying to register it.
00:20:25 WORKER: registered result for job (1, 0, 7) with dispatcher
00:20:25 DISPATCHER: job (1, 0, 7) finished
00:20:25 DISPATCHER: register_result: lock acquired
00:20:25 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:20:25 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 383, 'last_n_outputs': 50, 'leak_rate': 0.9413591523748148, 'lr': 0.04215236043300783, 'optimizer': 'Adam', 'sparsity': 0.8066576009566298, 'steps_to_train': 16, 'weight_decay': 0.17140370049767487}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.018846751575083278, 'info': {'data03': 0.018846751575083278, 'config': "{'batch_size': 128, 'hidden_dim': 383, 'last_n_outputs': 50, 'leak_rate': 0.9413591523748148, 'lr': 0.04215236043300783, 'optimizer': 'Adam', 'sparsity': 0.8066576009566298, 'steps_to_train': 16, 'weight_decay': 0.17140370049767487}"}}
exception: None

00:20:25 job_callback for (1, 0, 7) started
00:20:25 job_callback for (1, 0, 7) got condition
00:20:25 DISPATCHER: Trying to submit another job.
00:20:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:20:25 HBMASTER: Trying to run another job!
00:20:25 job_callback for (1, 0, 7) finished
00:20:25 start sampling a new configuration.
00:20:25 best_vector: [0, 0.7129553810655052, 0.7676439944118271, 0.890921833928427, 0.015282211569974502, 0, 0.9455250595844595, 0.42374654109456766, 0.3032128998357067], 0.014756484319934184, 0.4692504587955061, 0.006924487037337807
00:20:25 done sampling a new configuration.
00:20:25 HBMASTER: schedule new run for iteration 1
00:20:25 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
00:20:25 HBMASTER: submitting job (1, 0, 8) to dispatcher
00:20:25 DISPATCHER: trying to submit job (1, 0, 8)
00:20:25 DISPATCHER: trying to notify the job_runner thread.
00:20:25 HBMASTER: job (1, 0, 8) submitted to dispatcher
00:20:25 DISPATCHER: Trying to submit another job.
00:20:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:20:25 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:20:25 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:20:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:20:25 WORKER: start processing job (1, 0, 8)
00:20:25 WORKER: args: ()
00:20:25 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 771, 'last_n_outputs': 41, 'leak_rate': 0.9727304584821068, 'lr': 0.001072912791659389, 'optimizer': 'Adam', 'sparsity': 0.9769260143002703, 'steps_to_train': 48, 'weight_decay': 0.024802135610493953}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:20:29 DISPATCHER: Starting worker discovery
00:20:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:20:29 DISPATCHER: Finished worker discovery
00:21:29 DISPATCHER: Starting worker discovery
00:21:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:21:29 DISPATCHER: Finished worker discovery
00:22:29 DISPATCHER: Starting worker discovery
00:22:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:22:29 DISPATCHER: Finished worker discovery
00:23:29 DISPATCHER: Starting worker discovery
00:23:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:23:29 DISPATCHER: Finished worker discovery
00:23:38 WORKER: done with job (1, 0, 8), trying to register it.
00:23:38 WORKER: registered result for job (1, 0, 8) with dispatcher
00:23:38 DISPATCHER: job (1, 0, 8) finished
00:23:38 DISPATCHER: register_result: lock acquired
00:23:38 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:23:38 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 771, 'last_n_outputs': 41, 'leak_rate': 0.9727304584821068, 'lr': 0.001072912791659389, 'optimizer': 'Adam', 'sparsity': 0.9769260143002703, 'steps_to_train': 48, 'weight_decay': 0.024802135610493953}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.20036395557262993, 'info': {'data03': 0.20036395557262993, 'config': "{'batch_size': 16, 'hidden_dim': 771, 'last_n_outputs': 41, 'leak_rate': 0.9727304584821068, 'lr': 0.001072912791659389, 'optimizer': 'Adam', 'sparsity': 0.9769260143002703, 'steps_to_train': 48, 'weight_decay': 0.024802135610493953}"}}
exception: None

00:23:38 job_callback for (1, 0, 8) started
00:23:38 DISPATCHER: Trying to submit another job.
00:23:38 job_callback for (1, 0, 8) got condition
00:23:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:23:38 HBMASTER: Trying to run another job!
00:23:38 job_callback for (1, 0, 8) finished
00:23:38 ITERATION: Advancing config (1, 0, 0) to next budget 400.000000
00:23:38 ITERATION: Advancing config (1, 0, 1) to next budget 400.000000
00:23:38 ITERATION: Advancing config (1, 0, 8) to next budget 400.000000
00:23:38 HBMASTER: schedule new run for iteration 1
00:23:38 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
00:23:38 HBMASTER: submitting job (1, 0, 0) to dispatcher
00:23:38 DISPATCHER: trying to submit job (1, 0, 0)
00:23:38 DISPATCHER: trying to notify the job_runner thread.
00:23:38 HBMASTER: job (1, 0, 0) submitted to dispatcher
00:23:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:23:38 DISPATCHER: Trying to submit another job.
00:23:38 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:23:38 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:23:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:23:38 WORKER: start processing job (1, 0, 0)
00:23:38 WORKER: args: ()
00:23:38 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 588, 'last_n_outputs': 48, 'leak_rate': 0.9420754561288867, 'lr': 0.0011070864066543605, 'optimizer': 'SGD', 'sparsity': 0.9698906024582353, 'steps_to_train': 72, 'weight_decay': 0.022830254515072}, 'budget': 400.0, 'working_directory': '.'}
00:24:29 DISPATCHER: Starting worker discovery
00:24:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:24:29 DISPATCHER: Finished worker discovery
00:25:29 DISPATCHER: Starting worker discovery
00:25:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:25:29 DISPATCHER: Finished worker discovery
00:26:29 DISPATCHER: Starting worker discovery
00:26:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:26:29 DISPATCHER: Finished worker discovery
00:27:29 DISPATCHER: Starting worker discovery
00:27:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:27:29 DISPATCHER: Finished worker discovery
00:28:29 DISPATCHER: Starting worker discovery
00:28:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:28:29 DISPATCHER: Finished worker discovery
00:29:29 DISPATCHER: Starting worker discovery
00:29:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:29:29 DISPATCHER: Finished worker discovery
00:30:29 DISPATCHER: Starting worker discovery
00:30:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:30:29 DISPATCHER: Finished worker discovery
00:31:12 WORKER: done with job (1, 0, 0), trying to register it.
00:31:12 WORKER: registered result for job (1, 0, 0) with dispatcher
00:31:12 DISPATCHER: job (1, 0, 0) finished
00:31:12 DISPATCHER: register_result: lock acquired
00:31:12 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:31:12 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 588, 'last_n_outputs': 48, 'leak_rate': 0.9420754561288867, 'lr': 0.0011070864066543605, 'optimizer': 'SGD', 'sparsity': 0.9698906024582353, 'steps_to_train': 72, 'weight_decay': 0.022830254515072}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.2498535235266427, 'info': {'data03': 0.2498535235266427, 'config': "{'batch_size': 16, 'hidden_dim': 588, 'last_n_outputs': 48, 'leak_rate': 0.9420754561288867, 'lr': 0.0011070864066543605, 'optimizer': 'SGD', 'sparsity': 0.9698906024582353, 'steps_to_train': 72, 'weight_decay': 0.022830254515072}"}}
exception: None

00:31:12 job_callback for (1, 0, 0) started
00:31:12 job_callback for (1, 0, 0) got condition
00:31:12 DISPATCHER: Trying to submit another job.
00:31:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:31:12 Only 4 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
00:31:12 HBMASTER: Trying to run another job!
00:31:12 job_callback for (1, 0, 0) finished
00:31:12 HBMASTER: schedule new run for iteration 1
00:31:12 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
00:31:12 HBMASTER: submitting job (1, 0, 1) to dispatcher
00:31:12 DISPATCHER: trying to submit job (1, 0, 1)
00:31:12 DISPATCHER: trying to notify the job_runner thread.
00:31:12 HBMASTER: job (1, 0, 1) submitted to dispatcher
00:31:12 DISPATCHER: Trying to submit another job.
00:31:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:31:12 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:31:12 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:31:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:31:12 WORKER: start processing job (1, 0, 1)
00:31:12 WORKER: args: ()
00:31:12 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 878, 'last_n_outputs': 24, 'leak_rate': 0.96065241182127, 'lr': 0.040090665075335555, 'optimizer': 'Adam', 'sparsity': 0.8745497409061748, 'steps_to_train': 46, 'weight_decay': 0.0403455397890046}, 'budget': 400.0, 'working_directory': '.'}
00:31:29 DISPATCHER: Starting worker discovery
00:31:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:31:29 DISPATCHER: Finished worker discovery
00:32:29 DISPATCHER: Starting worker discovery
00:32:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:32:29 DISPATCHER: Finished worker discovery
00:33:29 DISPATCHER: Starting worker discovery
00:33:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:33:29 DISPATCHER: Finished worker discovery
00:34:29 DISPATCHER: Starting worker discovery
00:34:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:34:29 DISPATCHER: Finished worker discovery
00:35:29 DISPATCHER: Starting worker discovery
00:35:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:35:29 DISPATCHER: Finished worker discovery
00:36:29 DISPATCHER: Starting worker discovery
00:36:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:36:29 DISPATCHER: Finished worker discovery
00:37:29 DISPATCHER: Starting worker discovery
00:37:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:37:29 DISPATCHER: Finished worker discovery
00:38:29 DISPATCHER: Starting worker discovery
00:38:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:38:29 DISPATCHER: Finished worker discovery
00:38:37 WORKER: done with job (1, 0, 1), trying to register it.
00:38:37 WORKER: registered result for job (1, 0, 1) with dispatcher
00:38:37 DISPATCHER: job (1, 0, 1) finished
00:38:37 DISPATCHER: register_result: lock acquired
00:38:37 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:38:37 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 878, 'last_n_outputs': 24, 'leak_rate': 0.96065241182127, 'lr': 0.040090665075335555, 'optimizer': 'Adam', 'sparsity': 0.8745497409061748, 'steps_to_train': 46, 'weight_decay': 0.0403455397890046}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.033617065269943125, 'info': {'data03': 0.033617065269943125, 'config': "{'batch_size': 16, 'hidden_dim': 878, 'last_n_outputs': 24, 'leak_rate': 0.96065241182127, 'lr': 0.040090665075335555, 'optimizer': 'Adam', 'sparsity': 0.8745497409061748, 'steps_to_train': 46, 'weight_decay': 0.0403455397890046}"}}
exception: None

00:38:37 job_callback for (1, 0, 1) started
00:38:37 DISPATCHER: Trying to submit another job.
00:38:37 job_callback for (1, 0, 1) got condition
00:38:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:38:37 Only 5 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
00:38:37 HBMASTER: Trying to run another job!
00:38:37 job_callback for (1, 0, 1) finished
00:38:37 HBMASTER: schedule new run for iteration 1
00:38:37 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
00:38:37 HBMASTER: submitting job (1, 0, 8) to dispatcher
00:38:37 DISPATCHER: trying to submit job (1, 0, 8)
00:38:37 DISPATCHER: trying to notify the job_runner thread.
00:38:37 HBMASTER: job (1, 0, 8) submitted to dispatcher
00:38:37 DISPATCHER: Trying to submit another job.
00:38:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:38:37 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:38:37 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:38:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:38:37 WORKER: start processing job (1, 0, 8)
00:38:37 WORKER: args: ()
00:38:37 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 771, 'last_n_outputs': 41, 'leak_rate': 0.9727304584821068, 'lr': 0.001072912791659389, 'optimizer': 'Adam', 'sparsity': 0.9769260143002703, 'steps_to_train': 48, 'weight_decay': 0.024802135610493953}, 'budget': 400.0, 'working_directory': '.'}
00:39:29 DISPATCHER: Starting worker discovery
00:39:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:39:29 DISPATCHER: Finished worker discovery
00:40:29 DISPATCHER: Starting worker discovery
00:40:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:40:29 DISPATCHER: Finished worker discovery
00:41:29 DISPATCHER: Starting worker discovery
00:41:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:41:29 DISPATCHER: Finished worker discovery
00:42:29 DISPATCHER: Starting worker discovery
00:42:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:42:29 DISPATCHER: Finished worker discovery
00:43:29 DISPATCHER: Starting worker discovery
00:43:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:43:29 DISPATCHER: Finished worker discovery
00:44:29 DISPATCHER: Starting worker discovery
00:44:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:44:29 DISPATCHER: Finished worker discovery
00:45:29 DISPATCHER: Starting worker discovery
00:45:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:45:29 DISPATCHER: Finished worker discovery
00:46:11 WORKER: done with job (1, 0, 8), trying to register it.
00:46:11 WORKER: registered result for job (1, 0, 8) with dispatcher
00:46:11 DISPATCHER: job (1, 0, 8) finished
00:46:11 DISPATCHER: register_result: lock acquired
00:46:11 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:46:11 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 771, 'last_n_outputs': 41, 'leak_rate': 0.9727304584821068, 'lr': 0.001072912791659389, 'optimizer': 'Adam', 'sparsity': 0.9769260143002703, 'steps_to_train': 48, 'weight_decay': 0.024802135610493953}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.2992640732395472, 'info': {'data03': 0.2992640732395472, 'config': "{'batch_size': 16, 'hidden_dim': 771, 'last_n_outputs': 41, 'leak_rate': 0.9727304584821068, 'lr': 0.001072912791659389, 'optimizer': 'Adam', 'sparsity': 0.9769260143002703, 'steps_to_train': 48, 'weight_decay': 0.024802135610493953}"}}
exception: None

00:46:11 job_callback for (1, 0, 8) started
00:46:11 DISPATCHER: Trying to submit another job.
00:46:11 job_callback for (1, 0, 8) got condition
00:46:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:46:11 Only 6 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
00:46:11 HBMASTER: Trying to run another job!
00:46:11 job_callback for (1, 0, 8) finished
00:46:11 ITERATION: Advancing config (1, 0, 8) to next budget 1200.000000
00:46:11 HBMASTER: schedule new run for iteration 1
00:46:11 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
00:46:11 HBMASTER: submitting job (1, 0, 8) to dispatcher
00:46:11 DISPATCHER: trying to submit job (1, 0, 8)
00:46:11 DISPATCHER: trying to notify the job_runner thread.
00:46:11 HBMASTER: job (1, 0, 8) submitted to dispatcher
00:46:11 DISPATCHER: Trying to submit another job.
00:46:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:46:11 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:46:11 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:46:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:46:11 WORKER: start processing job (1, 0, 8)
00:46:11 WORKER: args: ()
00:46:11 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 771, 'last_n_outputs': 41, 'leak_rate': 0.9727304584821068, 'lr': 0.001072912791659389, 'optimizer': 'Adam', 'sparsity': 0.9769260143002703, 'steps_to_train': 48, 'weight_decay': 0.024802135610493953}, 'budget': 1200.0, 'working_directory': '.'}
00:46:29 DISPATCHER: Starting worker discovery
00:46:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:46:29 DISPATCHER: Finished worker discovery
00:47:29 DISPATCHER: Starting worker discovery
00:47:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:47:29 DISPATCHER: Finished worker discovery
00:48:29 DISPATCHER: Starting worker discovery
00:48:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:48:29 DISPATCHER: Finished worker discovery
00:49:29 DISPATCHER: Starting worker discovery
00:49:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:49:29 DISPATCHER: Finished worker discovery
00:50:29 DISPATCHER: Starting worker discovery
00:50:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:50:29 DISPATCHER: Finished worker discovery
00:51:29 DISPATCHER: Starting worker discovery
00:51:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:51:29 DISPATCHER: Finished worker discovery
00:52:29 DISPATCHER: Starting worker discovery
00:52:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:52:29 DISPATCHER: Finished worker discovery
00:53:29 DISPATCHER: Starting worker discovery
00:53:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:53:29 DISPATCHER: Finished worker discovery
00:54:29 DISPATCHER: Starting worker discovery
00:54:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:54:29 DISPATCHER: Finished worker discovery
00:55:29 DISPATCHER: Starting worker discovery
00:55:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:55:29 DISPATCHER: Finished worker discovery
00:56:29 DISPATCHER: Starting worker discovery
00:56:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:56:29 DISPATCHER: Finished worker discovery
00:57:29 DISPATCHER: Starting worker discovery
00:57:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:57:29 DISPATCHER: Finished worker discovery
00:58:29 DISPATCHER: Starting worker discovery
00:58:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:58:29 DISPATCHER: Finished worker discovery
00:59:29 DISPATCHER: Starting worker discovery
00:59:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:59:29 DISPATCHER: Finished worker discovery
01:00:29 DISPATCHER: Starting worker discovery
01:00:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:00:29 DISPATCHER: Finished worker discovery
01:01:29 DISPATCHER: Starting worker discovery
01:01:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:01:29 DISPATCHER: Finished worker discovery
01:02:29 DISPATCHER: Starting worker discovery
01:02:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:02:29 DISPATCHER: Finished worker discovery
01:03:29 DISPATCHER: Starting worker discovery
01:03:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:03:29 DISPATCHER: Finished worker discovery
01:04:29 DISPATCHER: Starting worker discovery
01:04:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:04:29 DISPATCHER: Finished worker discovery
01:05:29 DISPATCHER: Starting worker discovery
01:05:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:05:29 DISPATCHER: Finished worker discovery
01:06:29 DISPATCHER: Starting worker discovery
01:06:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:06:29 DISPATCHER: Finished worker discovery
01:06:56 WORKER: done with job (1, 0, 8), trying to register it.
01:06:56 WORKER: registered result for job (1, 0, 8) with dispatcher
01:06:56 DISPATCHER: job (1, 0, 8) finished
01:06:56 DISPATCHER: register_result: lock acquired
01:06:56 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:06:56 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 771, 'last_n_outputs': 41, 'leak_rate': 0.9727304584821068, 'lr': 0.001072912791659389, 'optimizer': 'Adam', 'sparsity': 0.9769260143002703, 'steps_to_train': 48, 'weight_decay': 0.024802135610493953}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.27519331723968826, 'info': {'data03': 0.27519331723968826, 'config': "{'batch_size': 16, 'hidden_dim': 771, 'last_n_outputs': 41, 'leak_rate': 0.9727304584821068, 'lr': 0.001072912791659389, 'optimizer': 'Adam', 'sparsity': 0.9769260143002703, 'steps_to_train': 48, 'weight_decay': 0.024802135610493953}"}}
exception: None

01:06:56 job_callback for (1, 0, 8) started
01:06:56 job_callback for (1, 0, 8) got condition
01:06:56 DISPATCHER: Trying to submit another job.
01:06:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:06:56 Only 2 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
01:06:56 HBMASTER: Trying to run another job!
01:06:56 job_callback for (1, 0, 8) finished
01:06:56 start sampling a new configuration.
01:06:56 best_vector: [1, 0.8363391191610465, 0.6821546066323592, 0.9334802067018686, 0.6044421314649157, 0, 0.11267827858034726, 0.6794952881986772, 0.13393375782720185], 0.057958160202118275, 0.12344127224193721, 0.007154429032151493
01:06:56 done sampling a new configuration.
01:06:56 HBMASTER: schedule new run for iteration 2
01:06:56 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
01:06:56 HBMASTER: submitting job (2, 0, 0) to dispatcher
01:06:56 DISPATCHER: trying to submit job (2, 0, 0)
01:06:56 DISPATCHER: trying to notify the job_runner thread.
01:06:56 HBMASTER: job (2, 0, 0) submitted to dispatcher
01:06:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:06:56 DISPATCHER: Trying to submit another job.
01:06:56 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:06:56 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:06:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:06:56 WORKER: start processing job (2, 0, 0)
01:06:56 WORKER: args: ()
01:06:56 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 869, 'last_n_outputs': 37, 'leak_rate': 0.9833700516754671, 'lr': 0.016176488857417175, 'optimizer': 'Adam', 'sparsity': 0.7770427868592833, 'steps_to_train': 71, 'weight_decay': 0.014936602942582514}, 'budget': 400.0, 'working_directory': '.'}
01:07:29 DISPATCHER: Starting worker discovery
01:07:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:07:29 DISPATCHER: Finished worker discovery
01:08:29 DISPATCHER: Starting worker discovery
01:08:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:08:29 DISPATCHER: Finished worker discovery
01:09:29 DISPATCHER: Starting worker discovery
01:09:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:09:29 DISPATCHER: Finished worker discovery
01:10:29 DISPATCHER: Starting worker discovery
01:10:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:10:29 DISPATCHER: Finished worker discovery
01:11:29 DISPATCHER: Starting worker discovery
01:11:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:11:29 DISPATCHER: Finished worker discovery
01:12:29 DISPATCHER: Starting worker discovery
01:12:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:12:29 DISPATCHER: Finished worker discovery
01:13:29 DISPATCHER: Starting worker discovery
01:13:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:13:29 DISPATCHER: Finished worker discovery
01:14:14 WORKER: done with job (2, 0, 0), trying to register it.
01:14:14 WORKER: registered result for job (2, 0, 0) with dispatcher
01:14:14 DISPATCHER: job (2, 0, 0) finished
01:14:14 DISPATCHER: register_result: lock acquired
01:14:14 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:14:14 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 869, 'last_n_outputs': 37, 'leak_rate': 0.9833700516754671, 'lr': 0.016176488857417175, 'optimizer': 'Adam', 'sparsity': 0.7770427868592833, 'steps_to_train': 71, 'weight_decay': 0.014936602942582514}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.16631338876649288, 'info': {'data03': 0.16631338876649288, 'config': "{'batch_size': 32, 'hidden_dim': 869, 'last_n_outputs': 37, 'leak_rate': 0.9833700516754671, 'lr': 0.016176488857417175, 'optimizer': 'Adam', 'sparsity': 0.7770427868592833, 'steps_to_train': 71, 'weight_decay': 0.014936602942582514}"}}
exception: None

01:14:14 job_callback for (2, 0, 0) started
01:14:14 DISPATCHER: Trying to submit another job.
01:14:14 job_callback for (2, 0, 0) got condition
01:14:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:14:14 Only 7 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
01:14:14 HBMASTER: Trying to run another job!
01:14:14 job_callback for (2, 0, 0) finished
01:14:14 start sampling a new configuration.
01:14:14 best_vector: [3, 0.2842485259871158, 0.17877150331511613, 0.8295937760857217, 0.6598593608408381, 1, 0.0013677535010792607, 0.27818786162101367, 0.7728683767960371], 0.024244638519765015, 0.143199536143811, 0.0034718209900047228
01:14:14 done sampling a new configuration.
01:14:14 HBMASTER: schedule new run for iteration 2
01:14:14 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
01:14:14 HBMASTER: submitting job (2, 0, 1) to dispatcher
01:14:14 DISPATCHER: trying to submit job (2, 0, 1)
01:14:14 DISPATCHER: trying to notify the job_runner thread.
01:14:14 HBMASTER: job (2, 0, 1) submitted to dispatcher
01:14:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:14:14 DISPATCHER: Trying to submit another job.
01:14:14 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:14:14 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:14:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:14:14 WORKER: start processing job (2, 0, 1)
01:14:14 WORKER: args: ()
01:14:14 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 427, 'last_n_outputs': 17, 'leak_rate': 0.9573984440214305, 'lr': 0.02087943400254834, 'optimizer': 'SGD', 'sparsity': 0.750328260840259, 'steps_to_train': 35, 'weight_decay': 0.10128029109689826}, 'budget': 400.0, 'working_directory': '.'}
01:14:29 DISPATCHER: Starting worker discovery
01:14:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:14:29 DISPATCHER: Finished worker discovery
01:15:29 DISPATCHER: Starting worker discovery
01:15:29 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:15:29 DISPATCHER: Finished worker discovery
01:16:30 DISPATCHER: Starting worker discovery
01:16:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:16:30 DISPATCHER: Finished worker discovery
01:17:30 DISPATCHER: Starting worker discovery
01:17:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:17:30 DISPATCHER: Finished worker discovery
01:18:30 DISPATCHER: Starting worker discovery
01:18:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:18:30 DISPATCHER: Finished worker discovery
01:19:30 DISPATCHER: Starting worker discovery
01:19:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:19:30 DISPATCHER: Finished worker discovery
01:20:30 DISPATCHER: Starting worker discovery
01:20:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:20:30 DISPATCHER: Finished worker discovery
01:21:30 DISPATCHER: Starting worker discovery
01:21:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:21:30 DISPATCHER: Finished worker discovery
01:21:35 WORKER: done with job (2, 0, 1), trying to register it.
01:21:35 WORKER: registered result for job (2, 0, 1) with dispatcher
01:21:35 DISPATCHER: job (2, 0, 1) finished
01:21:35 DISPATCHER: register_result: lock acquired
01:21:35 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:21:35 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 427, 'last_n_outputs': 17, 'leak_rate': 0.9573984440214305, 'lr': 0.02087943400254834, 'optimizer': 'SGD', 'sparsity': 0.750328260840259, 'steps_to_train': 35, 'weight_decay': 0.10128029109689826}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.02884403698091914, 'info': {'data03': 0.02884403698091914, 'config': "{'batch_size': 128, 'hidden_dim': 427, 'last_n_outputs': 17, 'leak_rate': 0.9573984440214305, 'lr': 0.02087943400254834, 'optimizer': 'SGD', 'sparsity': 0.750328260840259, 'steps_to_train': 35, 'weight_decay': 0.10128029109689826}"}}
exception: None

01:21:35 job_callback for (2, 0, 1) started
01:21:35 DISPATCHER: Trying to submit another job.
01:21:35 job_callback for (2, 0, 1) got condition
01:21:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:21:35 Only 8 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
01:21:35 HBMASTER: Trying to run another job!
01:21:35 job_callback for (2, 0, 1) finished
01:21:35 start sampling a new configuration.
01:21:35 best_vector: [0, 0.49893609329735583, 0.1962219690166067, 0.8734480080717213, 0.3592025312006367, 0, 0.24243688088850468, 0.21007276784647988, 0.5679081004090801], 0.05259942358827127, 0.4394324206722794, 0.023113892033360638
01:21:35 done sampling a new configuration.
01:21:35 HBMASTER: schedule new run for iteration 2
01:21:35 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
01:21:35 HBMASTER: submitting job (2, 0, 2) to dispatcher
01:21:35 DISPATCHER: trying to submit job (2, 0, 2)
01:21:35 DISPATCHER: trying to notify the job_runner thread.
01:21:35 HBMASTER: job (2, 0, 2) submitted to dispatcher
01:21:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:21:35 DISPATCHER: Trying to submit another job.
01:21:35 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:21:35 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:21:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:21:35 WORKER: start processing job (2, 0, 2)
01:21:35 WORKER: args: ()
01:21:35 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 599, 'last_n_outputs': 18, 'leak_rate': 0.9683620020179303, 'lr': 0.005228836503285519, 'optimizer': 'Adam', 'sparsity': 0.8081848514132411, 'steps_to_train': 29, 'weight_decay': 0.05481071575444535}, 'budget': 400.0, 'working_directory': '.'}
01:22:30 DISPATCHER: Starting worker discovery
01:22:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:22:30 DISPATCHER: Finished worker discovery
01:23:30 DISPATCHER: Starting worker discovery
01:23:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:23:30 DISPATCHER: Finished worker discovery
01:24:30 DISPATCHER: Starting worker discovery
01:24:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:24:30 DISPATCHER: Finished worker discovery
01:25:30 DISPATCHER: Starting worker discovery
01:25:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:25:30 DISPATCHER: Finished worker discovery
01:26:30 DISPATCHER: Starting worker discovery
01:26:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:26:30 DISPATCHER: Finished worker discovery
01:27:30 DISPATCHER: Starting worker discovery
01:27:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:27:30 DISPATCHER: Finished worker discovery
01:28:30 DISPATCHER: Starting worker discovery
01:28:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:28:30 DISPATCHER: Finished worker discovery
01:28:59 WORKER: done with job (2, 0, 2), trying to register it.
01:28:59 WORKER: registered result for job (2, 0, 2) with dispatcher
01:28:59 DISPATCHER: job (2, 0, 2) finished
01:28:59 DISPATCHER: register_result: lock acquired
01:28:59 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:28:59 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 599, 'last_n_outputs': 18, 'leak_rate': 0.9683620020179303, 'lr': 0.005228836503285519, 'optimizer': 'Adam', 'sparsity': 0.8081848514132411, 'steps_to_train': 29, 'weight_decay': 0.05481071575444535}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.13796058106053377, 'info': {'data03': 0.13796058106053377, 'config': "{'batch_size': 16, 'hidden_dim': 599, 'last_n_outputs': 18, 'leak_rate': 0.9683620020179303, 'lr': 0.005228836503285519, 'optimizer': 'Adam', 'sparsity': 0.8081848514132411, 'steps_to_train': 29, 'weight_decay': 0.05481071575444535}"}}
exception: None

01:28:59 job_callback for (2, 0, 2) started
01:28:59 job_callback for (2, 0, 2) got condition
01:28:59 DISPATCHER: Trying to submit another job.
01:28:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:28:59 Only 9 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
01:28:59 HBMASTER: Trying to run another job!
01:28:59 job_callback for (2, 0, 2) finished
01:28:59 start sampling a new configuration.
01:28:59 done sampling a new configuration.
01:28:59 HBMASTER: schedule new run for iteration 2
01:28:59 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
01:28:59 HBMASTER: submitting job (2, 0, 3) to dispatcher
01:28:59 DISPATCHER: trying to submit job (2, 0, 3)
01:28:59 DISPATCHER: trying to notify the job_runner thread.
01:28:59 HBMASTER: job (2, 0, 3) submitted to dispatcher
01:28:59 DISPATCHER: Trying to submit another job.
01:28:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:28:59 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:28:59 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:28:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:28:59 WORKER: start processing job (2, 0, 3)
01:28:59 WORKER: args: ()
01:28:59 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 984, 'last_n_outputs': 48, 'leak_rate': 0.792938086134707, 'lr': 0.0012526425356054931, 'optimizer': 'SGD', 'sparsity': 0.7805013035167191, 'steps_to_train': 92, 'weight_decay': 0.010564003288676651}, 'budget': 400.0, 'working_directory': '.'}
01:29:30 DISPATCHER: Starting worker discovery
01:29:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:29:30 DISPATCHER: Finished worker discovery
01:30:30 DISPATCHER: Starting worker discovery
01:30:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:30:30 DISPATCHER: Finished worker discovery
01:31:30 DISPATCHER: Starting worker discovery
01:31:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:31:30 DISPATCHER: Finished worker discovery
01:32:30 DISPATCHER: Starting worker discovery
01:32:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:32:30 DISPATCHER: Finished worker discovery
01:33:30 DISPATCHER: Starting worker discovery
01:33:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:33:30 DISPATCHER: Finished worker discovery
01:34:30 DISPATCHER: Starting worker discovery
01:34:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:34:30 DISPATCHER: Finished worker discovery
01:35:30 DISPATCHER: Starting worker discovery
01:35:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:35:30 DISPATCHER: Finished worker discovery
01:36:30 DISPATCHER: Starting worker discovery
01:36:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:36:30 DISPATCHER: Finished worker discovery
01:36:47 WORKER: done with job (2, 0, 3), trying to register it.
01:36:47 WORKER: registered result for job (2, 0, 3) with dispatcher
01:36:47 DISPATCHER: job (2, 0, 3) finished
01:36:47 DISPATCHER: register_result: lock acquired
01:36:47 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:36:47 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 984, 'last_n_outputs': 48, 'leak_rate': 0.792938086134707, 'lr': 0.0012526425356054931, 'optimizer': 'SGD', 'sparsity': 0.7805013035167191, 'steps_to_train': 92, 'weight_decay': 0.010564003288676651}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3023426085070877, 'info': {'data03': 0.3023426085070877, 'config': "{'batch_size': 64, 'hidden_dim': 984, 'last_n_outputs': 48, 'leak_rate': 0.792938086134707, 'lr': 0.0012526425356054931, 'optimizer': 'SGD', 'sparsity': 0.7805013035167191, 'steps_to_train': 92, 'weight_decay': 0.010564003288676651}"}}
exception: None

01:36:47 job_callback for (2, 0, 3) started
01:36:47 DISPATCHER: Trying to submit another job.
01:36:47 job_callback for (2, 0, 3) got condition
01:36:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:36:47 HBMASTER: Trying to run another job!
01:36:47 job_callback for (2, 0, 3) finished
01:36:47 start sampling a new configuration.
01:36:47 best_vector: [3, 0.18113255025612945, 0.8950741372442486, 0.9151560862510131, 0.17261797190842793, 0, 0.02371980876789806, 0.34698641975279815, 0.9194433351878373], 0.052732902499875986, 0.1801313450825678, 0.009498848657410564
01:36:47 done sampling a new configuration.
01:36:47 HBMASTER: schedule new run for iteration 2
01:36:47 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
01:36:47 HBMASTER: submitting job (2, 0, 4) to dispatcher
01:36:47 DISPATCHER: trying to submit job (2, 0, 4)
01:36:47 DISPATCHER: trying to notify the job_runner thread.
01:36:47 HBMASTER: job (2, 0, 4) submitted to dispatcher
01:36:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:36:47 DISPATCHER: Trying to submit another job.
01:36:47 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:36:47 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:36:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:36:47 WORKER: start processing job (2, 0, 4)
01:36:47 WORKER: args: ()
01:36:47 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 345, 'last_n_outputs': 46, 'leak_rate': 0.9787890215627533, 'lr': 0.0022142973679438504, 'optimizer': 'Adam', 'sparsity': 0.7556927541042955, 'steps_to_train': 41, 'weight_decay': 0.15711706523229818}, 'budget': 400.0, 'working_directory': '.'}
01:37:30 DISPATCHER: Starting worker discovery
01:37:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:37:30 DISPATCHER: Finished worker discovery
01:38:30 DISPATCHER: Starting worker discovery
01:38:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:38:30 DISPATCHER: Finished worker discovery
01:39:30 DISPATCHER: Starting worker discovery
01:39:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:39:30 DISPATCHER: Finished worker discovery
01:40:30 DISPATCHER: Starting worker discovery
01:40:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:40:30 DISPATCHER: Finished worker discovery
01:41:30 DISPATCHER: Starting worker discovery
01:41:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:41:30 DISPATCHER: Finished worker discovery
01:42:30 DISPATCHER: Starting worker discovery
01:42:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:42:30 DISPATCHER: Finished worker discovery
01:43:30 DISPATCHER: Starting worker discovery
01:43:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:43:30 DISPATCHER: Finished worker discovery
01:44:13 WORKER: done with job (2, 0, 4), trying to register it.
01:44:13 WORKER: registered result for job (2, 0, 4) with dispatcher
01:44:13 DISPATCHER: job (2, 0, 4) finished
01:44:13 DISPATCHER: register_result: lock acquired
01:44:13 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:44:13 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 345, 'last_n_outputs': 46, 'leak_rate': 0.9787890215627533, 'lr': 0.0022142973679438504, 'optimizer': 'Adam', 'sparsity': 0.7556927541042955, 'steps_to_train': 41, 'weight_decay': 0.15711706523229818}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.1257610550454546, 'info': {'data03': 0.1257610550454546, 'config': "{'batch_size': 128, 'hidden_dim': 345, 'last_n_outputs': 46, 'leak_rate': 0.9787890215627533, 'lr': 0.0022142973679438504, 'optimizer': 'Adam', 'sparsity': 0.7556927541042955, 'steps_to_train': 41, 'weight_decay': 0.15711706523229818}"}}
exception: None

01:44:13 job_callback for (2, 0, 4) started
01:44:13 DISPATCHER: Trying to submit another job.
01:44:13 job_callback for (2, 0, 4) got condition
01:44:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:44:13 HBMASTER: Trying to run another job!
01:44:13 job_callback for (2, 0, 4) finished
01:44:13 start sampling a new configuration.
01:44:13 best_vector: [1, 0.5931497139711588, 0.5189352281525085, 0.9172884528471065, 0.892270086534505, 0, 0.4027426135365179, 0.9537824334034087, 0.11135953732175133], 0.07385255387896701, 0.05027333192594561, 0.0037128139547360902
01:44:13 done sampling a new configuration.
01:44:13 HBMASTER: schedule new run for iteration 2
01:44:13 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
01:44:13 HBMASTER: submitting job (2, 0, 5) to dispatcher
01:44:13 DISPATCHER: trying to submit job (2, 0, 5)
01:44:13 DISPATCHER: trying to notify the job_runner thread.
01:44:13 HBMASTER: job (2, 0, 5) submitted to dispatcher
01:44:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:44:13 DISPATCHER: Trying to submit another job.
01:44:13 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:44:13 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:44:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:44:13 WORKER: start processing job (2, 0, 5)
01:44:13 WORKER: args: ()
01:44:13 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 675, 'last_n_outputs': 31, 'leak_rate': 0.9793221132117766, 'lr': 0.060889186681702075, 'optimizer': 'Adam', 'sparsity': 0.8466582272487643, 'steps_to_train': 96, 'weight_decay': 0.01395989328434141}, 'budget': 400.0, 'working_directory': '.'}
01:44:30 DISPATCHER: Starting worker discovery
01:44:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:44:30 DISPATCHER: Finished worker discovery
01:45:30 DISPATCHER: Starting worker discovery
01:45:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:45:30 DISPATCHER: Finished worker discovery
01:46:30 DISPATCHER: Starting worker discovery
01:46:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:46:30 DISPATCHER: Finished worker discovery
01:47:30 DISPATCHER: Starting worker discovery
01:47:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:47:30 DISPATCHER: Finished worker discovery
01:48:30 DISPATCHER: Starting worker discovery
01:48:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:48:30 DISPATCHER: Finished worker discovery
01:49:30 DISPATCHER: Starting worker discovery
01:49:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:49:30 DISPATCHER: Finished worker discovery
01:50:30 DISPATCHER: Starting worker discovery
01:50:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:50:30 DISPATCHER: Finished worker discovery
01:51:30 DISPATCHER: Starting worker discovery
01:51:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:51:30 DISPATCHER: Finished worker discovery
01:52:01 WORKER: done with job (2, 0, 5), trying to register it.
01:52:01 WORKER: registered result for job (2, 0, 5) with dispatcher
01:52:01 DISPATCHER: job (2, 0, 5) finished
01:52:01 DISPATCHER: register_result: lock acquired
01:52:01 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:52:01 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 675, 'last_n_outputs': 31, 'leak_rate': 0.9793221132117766, 'lr': 0.060889186681702075, 'optimizer': 'Adam', 'sparsity': 0.8466582272487643, 'steps_to_train': 96, 'weight_decay': 0.01395989328434141}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.1765744693944916, 'info': {'data03': 0.1765744693944916, 'config': "{'batch_size': 32, 'hidden_dim': 675, 'last_n_outputs': 31, 'leak_rate': 0.9793221132117766, 'lr': 0.060889186681702075, 'optimizer': 'Adam', 'sparsity': 0.8466582272487643, 'steps_to_train': 96, 'weight_decay': 0.01395989328434141}"}}
exception: None

01:52:01 job_callback for (2, 0, 5) started
01:52:01 job_callback for (2, 0, 5) got condition
01:52:01 DISPATCHER: Trying to submit another job.
01:52:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:52:01 HBMASTER: Trying to run another job!
01:52:01 job_callback for (2, 0, 5) finished
01:52:01 ITERATION: Advancing config (2, 0, 3) to next budget 1200.000000
01:52:01 ITERATION: Advancing config (2, 0, 5) to next budget 1200.000000
01:52:01 HBMASTER: schedule new run for iteration 2
01:52:01 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
01:52:01 HBMASTER: submitting job (2, 0, 3) to dispatcher
01:52:01 DISPATCHER: trying to submit job (2, 0, 3)
01:52:01 DISPATCHER: trying to notify the job_runner thread.
01:52:01 HBMASTER: job (2, 0, 3) submitted to dispatcher
01:52:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:52:01 DISPATCHER: Trying to submit another job.
01:52:01 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:52:01 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:52:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:52:01 WORKER: start processing job (2, 0, 3)
01:52:01 WORKER: args: ()
01:52:01 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 984, 'last_n_outputs': 48, 'leak_rate': 0.792938086134707, 'lr': 0.0012526425356054931, 'optimizer': 'SGD', 'sparsity': 0.7805013035167191, 'steps_to_train': 92, 'weight_decay': 0.010564003288676651}, 'budget': 1200.0, 'working_directory': '.'}
01:52:30 DISPATCHER: Starting worker discovery
01:52:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:52:30 DISPATCHER: Finished worker discovery
01:53:30 DISPATCHER: Starting worker discovery
01:53:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:53:30 DISPATCHER: Finished worker discovery
01:54:30 DISPATCHER: Starting worker discovery
01:54:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:54:30 DISPATCHER: Finished worker discovery
01:55:30 DISPATCHER: Starting worker discovery
01:55:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:55:30 DISPATCHER: Finished worker discovery
01:56:30 DISPATCHER: Starting worker discovery
01:56:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:56:30 DISPATCHER: Finished worker discovery
01:57:30 DISPATCHER: Starting worker discovery
01:57:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:57:30 DISPATCHER: Finished worker discovery
01:58:30 DISPATCHER: Starting worker discovery
01:58:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:58:30 DISPATCHER: Finished worker discovery
01:59:30 DISPATCHER: Starting worker discovery
01:59:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:59:30 DISPATCHER: Finished worker discovery
02:00:30 DISPATCHER: Starting worker discovery
02:00:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:00:30 DISPATCHER: Finished worker discovery
02:01:30 DISPATCHER: Starting worker discovery
02:01:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:01:30 DISPATCHER: Finished worker discovery
02:02:30 DISPATCHER: Starting worker discovery
02:02:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:02:30 DISPATCHER: Finished worker discovery
02:03:30 DISPATCHER: Starting worker discovery
02:03:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:03:30 DISPATCHER: Finished worker discovery
02:04:30 DISPATCHER: Starting worker discovery
02:04:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:04:30 DISPATCHER: Finished worker discovery
02:05:30 DISPATCHER: Starting worker discovery
02:05:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:05:30 DISPATCHER: Finished worker discovery
02:06:30 DISPATCHER: Starting worker discovery
02:06:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:06:30 DISPATCHER: Finished worker discovery
02:07:30 DISPATCHER: Starting worker discovery
02:07:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:07:30 DISPATCHER: Finished worker discovery
02:08:30 DISPATCHER: Starting worker discovery
02:08:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:08:30 DISPATCHER: Finished worker discovery
02:09:30 DISPATCHER: Starting worker discovery
02:09:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:09:30 DISPATCHER: Finished worker discovery
02:10:30 DISPATCHER: Starting worker discovery
02:10:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:10:30 DISPATCHER: Finished worker discovery
02:11:30 DISPATCHER: Starting worker discovery
02:11:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:11:30 DISPATCHER: Finished worker discovery
02:12:30 DISPATCHER: Starting worker discovery
02:12:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:12:30 DISPATCHER: Finished worker discovery
02:12:42 WORKER: done with job (2, 0, 3), trying to register it.
02:12:42 WORKER: registered result for job (2, 0, 3) with dispatcher
02:12:42 DISPATCHER: job (2, 0, 3) finished
02:12:42 DISPATCHER: register_result: lock acquired
02:12:42 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
02:12:42 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 984, 'last_n_outputs': 48, 'leak_rate': 0.792938086134707, 'lr': 0.0012526425356054931, 'optimizer': 'SGD', 'sparsity': 0.7805013035167191, 'steps_to_train': 92, 'weight_decay': 0.010564003288676651}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.22238426600248906, 'info': {'data03': 0.22238426600248906, 'config': "{'batch_size': 64, 'hidden_dim': 984, 'last_n_outputs': 48, 'leak_rate': 0.792938086134707, 'lr': 0.0012526425356054931, 'optimizer': 'SGD', 'sparsity': 0.7805013035167191, 'steps_to_train': 92, 'weight_decay': 0.010564003288676651}"}}
exception: None

02:12:42 job_callback for (2, 0, 3) started
02:12:42 DISPATCHER: Trying to submit another job.
02:12:42 job_callback for (2, 0, 3) got condition
02:12:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:12:42 Only 3 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
02:12:42 HBMASTER: Trying to run another job!
02:12:42 job_callback for (2, 0, 3) finished
02:12:42 HBMASTER: schedule new run for iteration 2
02:12:42 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
02:12:42 HBMASTER: submitting job (2, 0, 5) to dispatcher
02:12:42 DISPATCHER: trying to submit job (2, 0, 5)
02:12:42 DISPATCHER: trying to notify the job_runner thread.
02:12:42 HBMASTER: job (2, 0, 5) submitted to dispatcher
02:12:42 DISPATCHER: Trying to submit another job.
02:12:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:12:42 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
02:12:42 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
02:12:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:12:42 WORKER: start processing job (2, 0, 5)
02:12:42 WORKER: args: ()
02:12:42 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 675, 'last_n_outputs': 31, 'leak_rate': 0.9793221132117766, 'lr': 0.060889186681702075, 'optimizer': 'Adam', 'sparsity': 0.8466582272487643, 'steps_to_train': 96, 'weight_decay': 0.01395989328434141}, 'budget': 1200.0, 'working_directory': '.'}
02:13:30 DISPATCHER: Starting worker discovery
02:13:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:13:30 DISPATCHER: Finished worker discovery
02:14:30 DISPATCHER: Starting worker discovery
02:14:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:14:30 DISPATCHER: Finished worker discovery
02:15:30 DISPATCHER: Starting worker discovery
02:15:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:15:30 DISPATCHER: Finished worker discovery
02:16:30 DISPATCHER: Starting worker discovery
02:16:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:16:30 DISPATCHER: Finished worker discovery
02:17:30 DISPATCHER: Starting worker discovery
02:17:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:17:30 DISPATCHER: Finished worker discovery
02:18:30 DISPATCHER: Starting worker discovery
02:18:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:18:30 DISPATCHER: Finished worker discovery
02:19:30 DISPATCHER: Starting worker discovery
02:19:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:19:30 DISPATCHER: Finished worker discovery
02:20:30 DISPATCHER: Starting worker discovery
02:20:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:20:30 DISPATCHER: Finished worker discovery
02:21:30 DISPATCHER: Starting worker discovery
02:21:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:21:30 DISPATCHER: Finished worker discovery
02:22:30 DISPATCHER: Starting worker discovery
02:22:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:22:30 DISPATCHER: Finished worker discovery
02:23:30 DISPATCHER: Starting worker discovery
02:23:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:23:30 DISPATCHER: Finished worker discovery
02:24:30 DISPATCHER: Starting worker discovery
02:24:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:24:30 DISPATCHER: Finished worker discovery
02:25:30 DISPATCHER: Starting worker discovery
02:25:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:25:30 DISPATCHER: Finished worker discovery
02:26:30 DISPATCHER: Starting worker discovery
02:26:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:26:30 DISPATCHER: Finished worker discovery
02:27:30 DISPATCHER: Starting worker discovery
02:27:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:27:30 DISPATCHER: Finished worker discovery
02:28:30 DISPATCHER: Starting worker discovery
02:28:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:28:30 DISPATCHER: Finished worker discovery
02:29:30 DISPATCHER: Starting worker discovery
02:29:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:29:30 DISPATCHER: Finished worker discovery
02:30:30 DISPATCHER: Starting worker discovery
02:30:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:30:30 DISPATCHER: Finished worker discovery
02:31:30 DISPATCHER: Starting worker discovery
02:31:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:31:30 DISPATCHER: Finished worker discovery
02:32:30 DISPATCHER: Starting worker discovery
02:32:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:32:30 DISPATCHER: Finished worker discovery
02:33:30 DISPATCHER: Starting worker discovery
02:33:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:33:30 DISPATCHER: Finished worker discovery
02:33:51 WORKER: done with job (2, 0, 5), trying to register it.
02:33:51 WORKER: registered result for job (2, 0, 5) with dispatcher
02:33:51 DISPATCHER: job (2, 0, 5) finished
02:33:51 DISPATCHER: register_result: lock acquired
02:33:51 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
02:33:51 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 675, 'last_n_outputs': 31, 'leak_rate': 0.9793221132117766, 'lr': 0.060889186681702075, 'optimizer': 'Adam', 'sparsity': 0.8466582272487643, 'steps_to_train': 96, 'weight_decay': 0.01395989328434141}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.15405272374236098, 'info': {'data03': 0.15405272374236098, 'config': "{'batch_size': 32, 'hidden_dim': 675, 'last_n_outputs': 31, 'leak_rate': 0.9793221132117766, 'lr': 0.060889186681702075, 'optimizer': 'Adam', 'sparsity': 0.8466582272487643, 'steps_to_train': 96, 'weight_decay': 0.01395989328434141}"}}
exception: None

02:33:51 job_callback for (2, 0, 5) started
02:33:51 job_callback for (2, 0, 5) got condition
02:33:51 DISPATCHER: Trying to submit another job.
02:33:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:33:51 Only 4 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
02:33:51 HBMASTER: Trying to run another job!
02:33:51 job_callback for (2, 0, 5) finished
02:33:51 start sampling a new configuration.
02:33:51 best_vector: [3, 0.6954481712188816, 0.8203799664766804, 0.8774980825899612, 0.03907088497853839, 0, 0.9424084568805143, 0.9120404525166071, 0.3978398179645719], 0.02449842300292946, 0.47937344238963825, 0.011743893368031794
02:33:51 done sampling a new configuration.
02:33:51 HBMASTER: schedule new run for iteration 3
02:33:51 HBMASTER: trying submitting job (3, 0, 0) to dispatcher
02:33:51 HBMASTER: submitting job (3, 0, 0) to dispatcher
02:33:51 DISPATCHER: trying to submit job (3, 0, 0)
02:33:51 DISPATCHER: trying to notify the job_runner thread.
02:33:51 HBMASTER: job (3, 0, 0) submitted to dispatcher
02:33:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:33:51 DISPATCHER: Trying to submit another job.
02:33:51 DISPATCHER: starting job (3, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
02:33:51 DISPATCHER: job (3, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
02:33:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:33:51 WORKER: start processing job (3, 0, 0)
02:33:51 WORKER: args: ()
02:33:51 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 757, 'last_n_outputs': 43, 'leak_rate': 0.9693745206474903, 'lr': 0.001197131255932645, 'optimizer': 'Adam', 'sparsity': 0.9761780296513234, 'steps_to_train': 92, 'weight_decay': 0.032930743534438846}, 'budget': 1200.0, 'working_directory': '.'}
02:34:30 DISPATCHER: Starting worker discovery
02:34:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:34:30 DISPATCHER: Finished worker discovery
02:35:30 DISPATCHER: Starting worker discovery
02:35:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:35:30 DISPATCHER: Finished worker discovery
02:36:30 DISPATCHER: Starting worker discovery
02:36:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:36:30 DISPATCHER: Finished worker discovery
02:37:30 DISPATCHER: Starting worker discovery
02:37:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:37:30 DISPATCHER: Finished worker discovery
02:38:30 DISPATCHER: Starting worker discovery
02:38:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:38:30 DISPATCHER: Finished worker discovery
02:39:30 DISPATCHER: Starting worker discovery
02:39:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:39:30 DISPATCHER: Finished worker discovery
02:40:30 DISPATCHER: Starting worker discovery
02:40:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:40:30 DISPATCHER: Finished worker discovery
02:41:30 DISPATCHER: Starting worker discovery
02:41:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:41:30 DISPATCHER: Finished worker discovery
02:42:30 DISPATCHER: Starting worker discovery
02:42:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:42:30 DISPATCHER: Finished worker discovery
02:43:30 DISPATCHER: Starting worker discovery
02:43:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:43:30 DISPATCHER: Finished worker discovery
02:44:30 DISPATCHER: Starting worker discovery
02:44:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:44:30 DISPATCHER: Finished worker discovery
02:45:30 DISPATCHER: Starting worker discovery
02:45:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:45:30 DISPATCHER: Finished worker discovery
02:46:30 DISPATCHER: Starting worker discovery
02:46:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:46:30 DISPATCHER: Finished worker discovery
02:47:30 DISPATCHER: Starting worker discovery
02:47:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:47:30 DISPATCHER: Finished worker discovery
02:48:30 DISPATCHER: Starting worker discovery
02:48:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:48:30 DISPATCHER: Finished worker discovery
02:49:30 DISPATCHER: Starting worker discovery
02:49:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:49:30 DISPATCHER: Finished worker discovery
02:50:30 DISPATCHER: Starting worker discovery
02:50:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:50:30 DISPATCHER: Finished worker discovery
02:51:30 DISPATCHER: Starting worker discovery
02:51:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:51:30 DISPATCHER: Finished worker discovery
02:52:30 DISPATCHER: Starting worker discovery
02:52:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:52:30 DISPATCHER: Finished worker discovery
02:53:30 DISPATCHER: Starting worker discovery
02:53:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:53:30 DISPATCHER: Finished worker discovery
02:54:30 DISPATCHER: Starting worker discovery
02:54:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:54:30 DISPATCHER: Finished worker discovery
02:54:53 WORKER: done with job (3, 0, 0), trying to register it.
02:54:53 WORKER: registered result for job (3, 0, 0) with dispatcher
02:54:53 DISPATCHER: job (3, 0, 0) finished
02:54:53 DISPATCHER: register_result: lock acquired
02:54:53 DISPATCHER: job (3, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
02:54:53 job_id: (3, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 757, 'last_n_outputs': 43, 'leak_rate': 0.9693745206474903, 'lr': 0.001197131255932645, 'optimizer': 'Adam', 'sparsity': 0.9761780296513234, 'steps_to_train': 92, 'weight_decay': 0.032930743534438846}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.2589390857511513, 'info': {'data03': 0.2589390857511513, 'config': "{'batch_size': 128, 'hidden_dim': 757, 'last_n_outputs': 43, 'leak_rate': 0.9693745206474903, 'lr': 0.001197131255932645, 'optimizer': 'Adam', 'sparsity': 0.9761780296513234, 'steps_to_train': 92, 'weight_decay': 0.032930743534438846}"}}
exception: None

02:54:53 job_callback for (3, 0, 0) started
02:54:53 DISPATCHER: Trying to submit another job.
02:54:53 job_callback for (3, 0, 0) got condition
02:54:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:54:54 Only 5 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
02:54:54 HBMASTER: Trying to run another job!
02:54:54 job_callback for (3, 0, 0) finished
02:54:54 start sampling a new configuration.
02:54:54 best_vector: [1, 0.6417265720847765, 0.4750208873519189, 0.9417240611250315, 0.9321009989894222, 1, 0.5357740792115671, 0.9241370393660981, 0.44700724463931074], 0.03781438002870674, 0.08645501576284317, 0.003269242821443983
02:54:54 done sampling a new configuration.
02:54:54 HBMASTER: schedule new run for iteration 3
02:54:54 HBMASTER: trying submitting job (3, 0, 1) to dispatcher
02:54:54 HBMASTER: submitting job (3, 0, 1) to dispatcher
02:54:54 DISPATCHER: trying to submit job (3, 0, 1)
02:54:54 DISPATCHER: trying to notify the job_runner thread.
02:54:54 HBMASTER: job (3, 0, 1) submitted to dispatcher
02:54:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:54:54 DISPATCHER: Trying to submit another job.
02:54:54 DISPATCHER: starting job (3, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
02:54:54 DISPATCHER: job (3, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
02:54:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:54:54 WORKER: start processing job (3, 0, 1)
02:54:54 WORKER: args: ()
02:54:54 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 714, 'last_n_outputs': 29, 'leak_rate': 0.9854310152812579, 'lr': 0.07314792281891001, 'optimizer': 'SGD', 'sparsity': 0.8785857790107761, 'steps_to_train': 94, 'weight_decay': 0.038156614430614876}, 'budget': 1200.0, 'working_directory': '.'}
02:55:30 DISPATCHER: Starting worker discovery
02:55:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:55:30 DISPATCHER: Finished worker discovery
02:56:30 DISPATCHER: Starting worker discovery
02:56:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:56:30 DISPATCHER: Finished worker discovery
02:57:30 DISPATCHER: Starting worker discovery
02:57:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:57:30 DISPATCHER: Finished worker discovery
02:58:30 DISPATCHER: Starting worker discovery
02:58:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:58:30 DISPATCHER: Finished worker discovery
02:59:30 DISPATCHER: Starting worker discovery
02:59:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:59:30 DISPATCHER: Finished worker discovery
03:00:30 DISPATCHER: Starting worker discovery
03:00:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:00:30 DISPATCHER: Finished worker discovery
03:01:30 DISPATCHER: Starting worker discovery
03:01:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:01:30 DISPATCHER: Finished worker discovery
03:02:30 DISPATCHER: Starting worker discovery
03:02:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:02:30 DISPATCHER: Finished worker discovery
03:03:30 DISPATCHER: Starting worker discovery
03:03:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:03:30 DISPATCHER: Finished worker discovery
03:04:30 DISPATCHER: Starting worker discovery
03:04:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:04:30 DISPATCHER: Finished worker discovery
03:05:30 DISPATCHER: Starting worker discovery
03:05:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:05:30 DISPATCHER: Finished worker discovery
03:06:30 DISPATCHER: Starting worker discovery
03:06:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:06:30 DISPATCHER: Finished worker discovery
03:07:30 DISPATCHER: Starting worker discovery
03:07:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:07:30 DISPATCHER: Finished worker discovery
03:08:30 DISPATCHER: Starting worker discovery
03:08:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:08:30 DISPATCHER: Finished worker discovery
03:09:30 DISPATCHER: Starting worker discovery
03:09:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:09:30 DISPATCHER: Finished worker discovery
03:10:30 DISPATCHER: Starting worker discovery
03:10:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:10:30 DISPATCHER: Finished worker discovery
03:11:30 DISPATCHER: Starting worker discovery
03:11:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:11:30 DISPATCHER: Finished worker discovery
03:12:30 DISPATCHER: Starting worker discovery
03:12:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:12:30 DISPATCHER: Finished worker discovery
03:13:30 DISPATCHER: Starting worker discovery
03:13:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:13:30 DISPATCHER: Finished worker discovery
03:14:30 DISPATCHER: Starting worker discovery
03:14:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:14:30 DISPATCHER: Finished worker discovery
03:15:30 DISPATCHER: Starting worker discovery
03:15:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:15:30 DISPATCHER: Finished worker discovery
03:15:40 WORKER: done with job (3, 0, 1), trying to register it.
03:15:40 WORKER: registered result for job (3, 0, 1) with dispatcher
03:15:40 DISPATCHER: job (3, 0, 1) finished
03:15:40 DISPATCHER: register_result: lock acquired
03:15:40 DISPATCHER: job (3, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
03:15:40 job_id: (3, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 714, 'last_n_outputs': 29, 'leak_rate': 0.9854310152812579, 'lr': 0.07314792281891001, 'optimizer': 'SGD', 'sparsity': 0.8785857790107761, 'steps_to_train': 94, 'weight_decay': 0.038156614430614876}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.1324252104424564, 'info': {'data03': 0.1324252104424564, 'config': "{'batch_size': 32, 'hidden_dim': 714, 'last_n_outputs': 29, 'leak_rate': 0.9854310152812579, 'lr': 0.07314792281891001, 'optimizer': 'SGD', 'sparsity': 0.8785857790107761, 'steps_to_train': 94, 'weight_decay': 0.038156614430614876}"}}
exception: None

03:15:40 job_callback for (3, 0, 1) started
03:15:40 DISPATCHER: Trying to submit another job.
03:15:40 job_callback for (3, 0, 1) got condition
03:15:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:15:40 Only 6 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
03:15:40 HBMASTER: Trying to run another job!
03:15:40 job_callback for (3, 0, 1) finished
03:15:40 start sampling a new configuration.
03:15:40 done sampling a new configuration.
03:15:40 HBMASTER: schedule new run for iteration 3
03:15:40 HBMASTER: trying submitting job (3, 0, 2) to dispatcher
03:15:40 HBMASTER: submitting job (3, 0, 2) to dispatcher
03:15:40 DISPATCHER: trying to submit job (3, 0, 2)
03:15:40 DISPATCHER: trying to notify the job_runner thread.
03:15:40 HBMASTER: job (3, 0, 2) submitted to dispatcher
03:15:40 DISPATCHER: Trying to submit another job.
03:15:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:15:40 DISPATCHER: starting job (3, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
03:15:40 DISPATCHER: job (3, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
03:15:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:15:40 WORKER: start processing job (3, 0, 2)
03:15:40 WORKER: args: ()
03:15:40 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 839, 'last_n_outputs': 39, 'leak_rate': 0.8887835560883246, 'lr': 0.005344918542148201, 'optimizer': 'Adam', 'sparsity': 0.866422822735456, 'steps_to_train': 100, 'weight_decay': 0.016825352643159}, 'budget': 1200.0, 'working_directory': '.'}
03:16:30 DISPATCHER: Starting worker discovery
03:16:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:16:30 DISPATCHER: Finished worker discovery
03:17:30 DISPATCHER: Starting worker discovery
03:17:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:17:30 DISPATCHER: Finished worker discovery
03:18:30 DISPATCHER: Starting worker discovery
03:18:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:18:30 DISPATCHER: Finished worker discovery
03:19:30 DISPATCHER: Starting worker discovery
03:19:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:19:30 DISPATCHER: Finished worker discovery
03:20:30 DISPATCHER: Starting worker discovery
03:20:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:20:30 DISPATCHER: Finished worker discovery
03:21:30 DISPATCHER: Starting worker discovery
03:21:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:21:30 DISPATCHER: Finished worker discovery
03:22:30 DISPATCHER: Starting worker discovery
03:22:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:22:30 DISPATCHER: Finished worker discovery
03:23:30 DISPATCHER: Starting worker discovery
03:23:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:23:30 DISPATCHER: Finished worker discovery
03:24:30 DISPATCHER: Starting worker discovery
03:24:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:24:30 DISPATCHER: Finished worker discovery
03:25:30 DISPATCHER: Starting worker discovery
03:25:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:25:30 DISPATCHER: Finished worker discovery
03:26:30 DISPATCHER: Starting worker discovery
03:26:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:26:30 DISPATCHER: Finished worker discovery
03:27:30 DISPATCHER: Starting worker discovery
03:27:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:27:30 DISPATCHER: Finished worker discovery
03:28:30 DISPATCHER: Starting worker discovery
03:28:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:28:30 DISPATCHER: Finished worker discovery
03:29:30 DISPATCHER: Starting worker discovery
03:29:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:29:30 DISPATCHER: Finished worker discovery
03:30:30 DISPATCHER: Starting worker discovery
03:30:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:30:30 DISPATCHER: Finished worker discovery
03:31:30 DISPATCHER: Starting worker discovery
03:31:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:31:30 DISPATCHER: Finished worker discovery
03:32:30 DISPATCHER: Starting worker discovery
03:32:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:32:30 DISPATCHER: Finished worker discovery
03:33:30 DISPATCHER: Starting worker discovery
03:33:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:33:30 DISPATCHER: Finished worker discovery
03:34:30 DISPATCHER: Starting worker discovery
03:34:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:34:30 DISPATCHER: Finished worker discovery
03:35:30 DISPATCHER: Starting worker discovery
03:35:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:35:31 DISPATCHER: Finished worker discovery
03:36:31 DISPATCHER: Starting worker discovery
03:36:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:36:31 DISPATCHER: Finished worker discovery
03:36:47 WORKER: done with job (3, 0, 2), trying to register it.
03:36:47 WORKER: registered result for job (3, 0, 2) with dispatcher
03:36:47 DISPATCHER: job (3, 0, 2) finished
03:36:47 DISPATCHER: register_result: lock acquired
03:36:47 DISPATCHER: job (3, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
03:36:47 job_id: (3, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 839, 'last_n_outputs': 39, 'leak_rate': 0.8887835560883246, 'lr': 0.005344918542148201, 'optimizer': 'Adam', 'sparsity': 0.866422822735456, 'steps_to_train': 100, 'weight_decay': 0.016825352643159}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.25024291535304793, 'info': {'data03': 0.25024291535304793, 'config': "{'batch_size': 64, 'hidden_dim': 839, 'last_n_outputs': 39, 'leak_rate': 0.8887835560883246, 'lr': 0.005344918542148201, 'optimizer': 'Adam', 'sparsity': 0.866422822735456, 'steps_to_train': 100, 'weight_decay': 0.016825352643159}"}}
exception: None

03:36:47 job_callback for (3, 0, 2) started
03:36:47 DISPATCHER: Trying to submit another job.
03:36:47 job_callback for (3, 0, 2) got condition
03:36:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:36:47 Only 7 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
03:36:47 HBMASTER: Trying to run another job!
03:36:47 job_callback for (3, 0, 2) finished
03:36:47 start sampling a new configuration.
03:36:47 best_vector: [3, 0.8763330447806135, 0.7409960739756222, 0.31913801448211465, 0.5303546144916474, 0, 0.4480423230735623, 0.8206256711902106, 0.8782928376634671], 0.08971745574872814, 0.11083703401337905, 0.00994401669441561
03:36:47 done sampling a new configuration.
03:36:47 HBMASTER: schedule new run for iteration 3
03:36:47 HBMASTER: trying submitting job (3, 0, 3) to dispatcher
03:36:47 HBMASTER: submitting job (3, 0, 3) to dispatcher
03:36:47 DISPATCHER: trying to submit job (3, 0, 3)
03:36:47 DISPATCHER: trying to notify the job_runner thread.
03:36:47 HBMASTER: job (3, 0, 3) submitted to dispatcher
03:36:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:36:47 DISPATCHER: Trying to submit another job.
03:36:47 DISPATCHER: starting job (3, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
03:36:47 DISPATCHER: job (3, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
03:36:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:36:47 WORKER: start processing job (3, 0, 3)
03:36:47 WORKER: args: ()
03:36:47 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 901, 'last_n_outputs': 40, 'leak_rate': 0.8297845036205287, 'lr': 0.011500301571776879, 'optimizer': 'Adam', 'sparsity': 0.8575301575376549, 'steps_to_train': 84, 'weight_decay': 0.13889458892997397}, 'budget': 1200.0, 'working_directory': '.'}
03:37:31 DISPATCHER: Starting worker discovery
03:37:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:37:31 DISPATCHER: Finished worker discovery
03:38:31 DISPATCHER: Starting worker discovery
03:38:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:38:31 DISPATCHER: Finished worker discovery
03:39:31 DISPATCHER: Starting worker discovery
03:39:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:39:31 DISPATCHER: Finished worker discovery
03:40:31 DISPATCHER: Starting worker discovery
03:40:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:40:31 DISPATCHER: Finished worker discovery
03:41:31 DISPATCHER: Starting worker discovery
03:41:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:41:31 DISPATCHER: Finished worker discovery
03:42:31 DISPATCHER: Starting worker discovery
03:42:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:42:31 DISPATCHER: Finished worker discovery
03:43:31 DISPATCHER: Starting worker discovery
03:43:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:43:31 DISPATCHER: Finished worker discovery
03:44:31 DISPATCHER: Starting worker discovery
03:44:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:44:31 DISPATCHER: Finished worker discovery
03:45:31 DISPATCHER: Starting worker discovery
03:45:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:45:31 DISPATCHER: Finished worker discovery
03:46:31 DISPATCHER: Starting worker discovery
03:46:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:46:31 DISPATCHER: Finished worker discovery
03:47:31 DISPATCHER: Starting worker discovery
03:47:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:47:31 DISPATCHER: Finished worker discovery
03:48:31 DISPATCHER: Starting worker discovery
03:48:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:48:31 DISPATCHER: Finished worker discovery
03:49:31 DISPATCHER: Starting worker discovery
03:49:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:49:31 DISPATCHER: Finished worker discovery
03:50:31 DISPATCHER: Starting worker discovery
03:50:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:50:31 DISPATCHER: Finished worker discovery
03:51:31 DISPATCHER: Starting worker discovery
03:51:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:51:31 DISPATCHER: Finished worker discovery
03:52:31 DISPATCHER: Starting worker discovery
03:52:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:52:31 DISPATCHER: Finished worker discovery
03:53:31 DISPATCHER: Starting worker discovery
03:53:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:53:31 DISPATCHER: Finished worker discovery
03:54:31 DISPATCHER: Starting worker discovery
03:54:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:54:31 DISPATCHER: Finished worker discovery
03:55:31 DISPATCHER: Starting worker discovery
03:55:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:55:31 DISPATCHER: Finished worker discovery
03:56:31 DISPATCHER: Starting worker discovery
03:56:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:56:31 DISPATCHER: Finished worker discovery
03:57:31 DISPATCHER: Starting worker discovery
03:57:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:57:31 DISPATCHER: Finished worker discovery
03:57:54 WORKER: done with job (3, 0, 3), trying to register it.
03:57:54 WORKER: registered result for job (3, 0, 3) with dispatcher
03:57:54 DISPATCHER: job (3, 0, 3) finished
03:57:54 DISPATCHER: register_result: lock acquired
03:57:54 DISPATCHER: job (3, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
03:57:54 job_id: (3, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 901, 'last_n_outputs': 40, 'leak_rate': 0.8297845036205287, 'lr': 0.011500301571776879, 'optimizer': 'Adam', 'sparsity': 0.8575301575376549, 'steps_to_train': 84, 'weight_decay': 0.13889458892997397}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.1896918300884768, 'info': {'data03': 0.1896918300884768, 'config': "{'batch_size': 128, 'hidden_dim': 901, 'last_n_outputs': 40, 'leak_rate': 0.8297845036205287, 'lr': 0.011500301571776879, 'optimizer': 'Adam', 'sparsity': 0.8575301575376549, 'steps_to_train': 84, 'weight_decay': 0.13889458892997397}"}}
exception: None

03:57:54 job_callback for (3, 0, 3) started
03:57:54 job_callback for (3, 0, 3) got condition
03:57:54 DISPATCHER: Trying to submit another job.
03:57:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:57:54 Only 8 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
03:57:54 HBMASTER: Trying to run another job!
03:57:54 job_callback for (3, 0, 3) finished
03:57:54 start sampling a new configuration.
03:57:54 best_vector: [1, 0.013865676099864555, 0.7859459548714971, 0.6895335001643561, 0.7251214153711513, 0, 0.047333000216812, 0.22837652265948177, 0.7906758253155246], 0.01756557888655132, 0.24790620676279365, 0.004354616031357554
03:57:54 done sampling a new configuration.
03:57:54 HBMASTER: schedule new run for iteration 4
03:57:54 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
03:57:54 HBMASTER: submitting job (4, 0, 0) to dispatcher
03:57:54 DISPATCHER: trying to submit job (4, 0, 0)
03:57:54 DISPATCHER: trying to notify the job_runner thread.
03:57:54 HBMASTER: job (4, 0, 0) submitted to dispatcher
03:57:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:57:54 DISPATCHER: Trying to submit another job.
03:57:54 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
03:57:54 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
03:57:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:57:54 WORKER: start processing job (4, 0, 0)
03:57:54 WORKER: args: ()
03:57:54 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 211, 'last_n_outputs': 42, 'leak_rate': 0.922383375041089, 'lr': 0.028199592381664997, 'optimizer': 'Adam', 'sparsity': 0.7613599200520349, 'steps_to_train': 30, 'weight_decay': 0.10682993535215536}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:58:31 DISPATCHER: Starting worker discovery
03:58:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:58:31 DISPATCHER: Finished worker discovery
03:59:16 WORKER: done with job (4, 0, 0), trying to register it.
03:59:16 WORKER: registered result for job (4, 0, 0) with dispatcher
03:59:16 DISPATCHER: job (4, 0, 0) finished
03:59:16 DISPATCHER: register_result: lock acquired
03:59:16 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
03:59:16 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 211, 'last_n_outputs': 42, 'leak_rate': 0.922383375041089, 'lr': 0.028199592381664997, 'optimizer': 'Adam', 'sparsity': 0.7613599200520349, 'steps_to_train': 30, 'weight_decay': 0.10682993535215536}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.004333909113556775, 'info': {'data03': -0.004333909113556775, 'config': "{'batch_size': 32, 'hidden_dim': 211, 'last_n_outputs': 42, 'leak_rate': 0.922383375041089, 'lr': 0.028199592381664997, 'optimizer': 'Adam', 'sparsity': 0.7613599200520349, 'steps_to_train': 30, 'weight_decay': 0.10682993535215536}"}}
exception: None

03:59:16 job_callback for (4, 0, 0) started
03:59:16 DISPATCHER: Trying to submit another job.
03:59:16 job_callback for (4, 0, 0) got condition
03:59:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:59:16 done building a new model for budget 44.444444 based on 10/23 split
Best loss for this budget:-0.271203





03:59:16 HBMASTER: Trying to run another job!
03:59:16 job_callback for (4, 0, 0) finished
03:59:16 start sampling a new configuration.
03:59:17 best_vector: [1, 0.6302732265223122, 0.30192206991517523, 0.9725875104929373, 0.4851217848616909, 1, 0.3480626493332656, 0.20950562286115154, 0.7068404242761304], 0.0637661012400334, 0.11431506399989608, 0.007289425944278271
03:59:17 done sampling a new configuration.
03:59:17 HBMASTER: schedule new run for iteration 4
03:59:17 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
03:59:17 HBMASTER: submitting job (4, 0, 1) to dispatcher
03:59:17 DISPATCHER: trying to submit job (4, 0, 1)
03:59:17 DISPATCHER: trying to notify the job_runner thread.
03:59:17 HBMASTER: job (4, 0, 1) submitted to dispatcher
03:59:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:59:17 DISPATCHER: Trying to submit another job.
03:59:17 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
03:59:17 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
03:59:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:59:17 WORKER: start processing job (4, 0, 1)
03:59:17 WORKER: args: ()
03:59:17 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 704, 'last_n_outputs': 22, 'leak_rate': 0.9931468776232344, 'lr': 0.009337778539533251, 'optimizer': 'SGD', 'sparsity': 0.8335350358399838, 'steps_to_train': 29, 'weight_decay': 0.08310374476891955}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:59:31 DISPATCHER: Starting worker discovery
03:59:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:59:31 DISPATCHER: Finished worker discovery
04:00:31 DISPATCHER: Starting worker discovery
04:00:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:00:31 DISPATCHER: Finished worker discovery
04:00:51 WORKER: done with job (4, 0, 1), trying to register it.
04:00:51 WORKER: registered result for job (4, 0, 1) with dispatcher
04:00:51 DISPATCHER: job (4, 0, 1) finished
04:00:51 DISPATCHER: register_result: lock acquired
04:00:51 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:00:51 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 704, 'last_n_outputs': 22, 'leak_rate': 0.9931468776232344, 'lr': 0.009337778539533251, 'optimizer': 'SGD', 'sparsity': 0.8335350358399838, 'steps_to_train': 29, 'weight_decay': 0.08310374476891955}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.12516983920066965, 'info': {'data03': 0.12516983920066965, 'config': "{'batch_size': 32, 'hidden_dim': 704, 'last_n_outputs': 22, 'leak_rate': 0.9931468776232344, 'lr': 0.009337778539533251, 'optimizer': 'SGD', 'sparsity': 0.8335350358399838, 'steps_to_train': 29, 'weight_decay': 0.08310374476891955}"}}
exception: None

04:00:51 job_callback for (4, 0, 1) started
04:00:51 DISPATCHER: Trying to submit another job.
04:00:51 job_callback for (4, 0, 1) got condition
04:00:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:00:51 done building a new model for budget 44.444444 based on 10/24 split
Best loss for this budget:-0.271203





04:00:51 HBMASTER: Trying to run another job!
04:00:51 job_callback for (4, 0, 1) finished
04:00:51 start sampling a new configuration.
04:00:51 best_vector: [2, 0.4630530819018866, 0.8396429585850528, 0.9290210260895814, 0.17764949626445933, 0, 0.9556862627653339, 0.6917752349904147, 0.21465472355257179], 0.03320105151233722, 0.6958702442992605, 0.02310362382688243
04:00:51 done sampling a new configuration.
04:00:51 HBMASTER: schedule new run for iteration 4
04:00:51 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
04:00:51 HBMASTER: submitting job (4, 0, 2) to dispatcher
04:00:51 DISPATCHER: trying to submit job (4, 0, 2)
04:00:51 DISPATCHER: trying to notify the job_runner thread.
04:00:51 HBMASTER: job (4, 0, 2) submitted to dispatcher
04:00:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:00:51 DISPATCHER: Trying to submit another job.
04:00:51 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:00:51 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:00:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:00:51 WORKER: start processing job (4, 0, 2)
04:00:51 WORKER: args: ()
04:00:51 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 570, 'last_n_outputs': 44, 'leak_rate': 0.9822552565223953, 'lr': 0.002266203951777084, 'optimizer': 'Adam', 'sparsity': 0.9793647030636801, 'steps_to_train': 72, 'weight_decay': 0.019022703293454842}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:01:31 DISPATCHER: Starting worker discovery
04:01:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:01:31 DISPATCHER: Finished worker discovery
04:02:31 DISPATCHER: Starting worker discovery
04:02:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:02:31 DISPATCHER: Finished worker discovery
04:02:33 WORKER: done with job (4, 0, 2), trying to register it.
04:02:33 WORKER: registered result for job (4, 0, 2) with dispatcher
04:02:33 DISPATCHER: job (4, 0, 2) finished
04:02:33 DISPATCHER: register_result: lock acquired
04:02:33 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:02:33 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 570, 'last_n_outputs': 44, 'leak_rate': 0.9822552565223953, 'lr': 0.002266203951777084, 'optimizer': 'Adam', 'sparsity': 0.9793647030636801, 'steps_to_train': 72, 'weight_decay': 0.019022703293454842}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.27078246507773357, 'info': {'data03': 0.27078246507773357, 'config': "{'batch_size': 64, 'hidden_dim': 570, 'last_n_outputs': 44, 'leak_rate': 0.9822552565223953, 'lr': 0.002266203951777084, 'optimizer': 'Adam', 'sparsity': 0.9793647030636801, 'steps_to_train': 72, 'weight_decay': 0.019022703293454842}"}}
exception: None

04:02:33 job_callback for (4, 0, 2) started
04:02:33 job_callback for (4, 0, 2) got condition
04:02:33 DISPATCHER: Trying to submit another job.
04:02:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:02:33 done building a new model for budget 44.444444 based on 10/25 split
Best loss for this budget:-0.271203





04:02:33 HBMASTER: Trying to run another job!
04:02:33 job_callback for (4, 0, 2) finished
04:02:33 start sampling a new configuration.
04:02:33 done sampling a new configuration.
04:02:33 HBMASTER: schedule new run for iteration 4
04:02:33 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
04:02:33 HBMASTER: submitting job (4, 0, 3) to dispatcher
04:02:33 DISPATCHER: trying to submit job (4, 0, 3)
04:02:33 DISPATCHER: trying to notify the job_runner thread.
04:02:33 HBMASTER: job (4, 0, 3) submitted to dispatcher
04:02:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:02:33 DISPATCHER: Trying to submit another job.
04:02:33 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:02:33 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:02:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:02:33 WORKER: start processing job (4, 0, 3)
04:02:33 WORKER: args: ()
04:02:33 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 458, 'last_n_outputs': 27, 'leak_rate': 0.9832557589566734, 'lr': 0.013233739269240721, 'optimizer': 'SGD', 'sparsity': 0.7729839804035581, 'steps_to_train': 86, 'weight_decay': 0.058770997411381386}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:03:31 DISPATCHER: Starting worker discovery
04:03:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:03:31 DISPATCHER: Finished worker discovery
04:04:28 WORKER: done with job (4, 0, 3), trying to register it.
04:04:28 WORKER: registered result for job (4, 0, 3) with dispatcher
04:04:28 DISPATCHER: job (4, 0, 3) finished
04:04:28 DISPATCHER: register_result: lock acquired
04:04:28 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:04:28 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 458, 'last_n_outputs': 27, 'leak_rate': 0.9832557589566734, 'lr': 0.013233739269240721, 'optimizer': 'SGD', 'sparsity': 0.7729839804035581, 'steps_to_train': 86, 'weight_decay': 0.058770997411381386}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.18022485910080738, 'info': {'data03': 0.18022485910080738, 'config': "{'batch_size': 16, 'hidden_dim': 458, 'last_n_outputs': 27, 'leak_rate': 0.9832557589566734, 'lr': 0.013233739269240721, 'optimizer': 'SGD', 'sparsity': 0.7729839804035581, 'steps_to_train': 86, 'weight_decay': 0.058770997411381386}"}}
exception: None

04:04:28 job_callback for (4, 0, 3) started
04:04:28 job_callback for (4, 0, 3) got condition
04:04:28 DISPATCHER: Trying to submit another job.
04:04:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:04:28 done building a new model for budget 44.444444 based on 10/26 split
Best loss for this budget:-0.271203





04:04:28 HBMASTER: Trying to run another job!
04:04:28 job_callback for (4, 0, 3) finished
04:04:28 start sampling a new configuration.
04:04:28 done sampling a new configuration.
04:04:28 HBMASTER: schedule new run for iteration 4
04:04:28 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
04:04:28 HBMASTER: submitting job (4, 0, 4) to dispatcher
04:04:28 DISPATCHER: trying to submit job (4, 0, 4)
04:04:28 DISPATCHER: trying to notify the job_runner thread.
04:04:28 HBMASTER: job (4, 0, 4) submitted to dispatcher
04:04:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:04:28 DISPATCHER: Trying to submit another job.
04:04:28 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:04:28 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:04:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:04:28 WORKER: start processing job (4, 0, 4)
04:04:28 WORKER: args: ()
04:04:28 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 815, 'last_n_outputs': 47, 'leak_rate': 0.9588472179850837, 'lr': 0.06363805776059903, 'optimizer': 'Adam', 'sparsity': 0.8445745346415532, 'steps_to_train': 48, 'weight_decay': 0.1230238994257488}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:04:31 DISPATCHER: Starting worker discovery
04:04:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:04:31 DISPATCHER: Finished worker discovery
04:05:31 DISPATCHER: Starting worker discovery
04:05:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:05:31 DISPATCHER: Finished worker discovery
04:05:54 WORKER: done with job (4, 0, 4), trying to register it.
04:05:54 WORKER: registered result for job (4, 0, 4) with dispatcher
04:05:54 DISPATCHER: job (4, 0, 4) finished
04:05:54 DISPATCHER: register_result: lock acquired
04:05:54 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:05:54 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 815, 'last_n_outputs': 47, 'leak_rate': 0.9588472179850837, 'lr': 0.06363805776059903, 'optimizer': 'Adam', 'sparsity': 0.8445745346415532, 'steps_to_train': 48, 'weight_decay': 0.1230238994257488}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 815, 'last_n_outputs': 47, 'leak_rate': 0.9588472179850837, 'lr': 0.06363805776059903, 'optimizer': 'Adam', 'sparsity': 0.8445745346415532, 'steps_to_train': 48, 'weight_decay': 0.1230238994257488}"}}
exception: None

04:05:54 job_callback for (4, 0, 4) started
04:05:54 DISPATCHER: Trying to submit another job.
04:05:54 job_callback for (4, 0, 4) got condition
04:05:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:05:54 done building a new model for budget 44.444444 based on 10/27 split
Best loss for this budget:-0.271203





04:05:54 HBMASTER: Trying to run another job!
04:05:54 job_callback for (4, 0, 4) finished
04:05:54 start sampling a new configuration.
04:05:54 done sampling a new configuration.
04:05:54 HBMASTER: schedule new run for iteration 4
04:05:54 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
04:05:54 HBMASTER: submitting job (4, 0, 5) to dispatcher
04:05:54 DISPATCHER: trying to submit job (4, 0, 5)
04:05:54 DISPATCHER: trying to notify the job_runner thread.
04:05:54 HBMASTER: job (4, 0, 5) submitted to dispatcher
04:05:54 DISPATCHER: Trying to submit another job.
04:05:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:05:54 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:05:54 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:05:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:05:54 WORKER: start processing job (4, 0, 5)
04:05:54 WORKER: args: ()
04:05:54 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 567, 'last_n_outputs': 37, 'leak_rate': 0.9264491728949493, 'lr': 0.0017890952034430667, 'optimizer': 'SGD', 'sparsity': 0.8871616787857873, 'steps_to_train': 46, 'weight_decay': 0.057972035071093136}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:06:31 DISPATCHER: Starting worker discovery
04:06:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:06:31 DISPATCHER: Finished worker discovery
04:07:19 WORKER: done with job (4, 0, 5), trying to register it.
04:07:19 WORKER: registered result for job (4, 0, 5) with dispatcher
04:07:19 DISPATCHER: job (4, 0, 5) finished
04:07:19 DISPATCHER: register_result: lock acquired
04:07:19 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:07:19 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 567, 'last_n_outputs': 37, 'leak_rate': 0.9264491728949493, 'lr': 0.0017890952034430667, 'optimizer': 'SGD', 'sparsity': 0.8871616787857873, 'steps_to_train': 46, 'weight_decay': 0.057972035071093136}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 567, 'last_n_outputs': 37, 'leak_rate': 0.9264491728949493, 'lr': 0.0017890952034430667, 'optimizer': 'SGD', 'sparsity': 0.8871616787857873, 'steps_to_train': 46, 'weight_decay': 0.057972035071093136}"}}
exception: None

04:07:19 job_callback for (4, 0, 5) started
04:07:19 DISPATCHER: Trying to submit another job.
04:07:19 job_callback for (4, 0, 5) got condition
04:07:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:07:19 done building a new model for budget 44.444444 based on 10/28 split
Best loss for this budget:-0.271203





04:07:19 HBMASTER: Trying to run another job!
04:07:19 job_callback for (4, 0, 5) finished
04:07:19 start sampling a new configuration.
04:07:19 best_vector: [0, 0.4145645594978035, 0.1643176640746613, 0.5717969806466988, 0.47985771451972337, 1, 0.021707382415988546, 0.4035867737114004, 0.6451301081351378], 0.07360334523670746, 0.3965365510225253, 0.02918641666388419
04:07:19 done sampling a new configuration.
04:07:19 HBMASTER: schedule new run for iteration 4
04:07:19 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
04:07:19 HBMASTER: submitting job (4, 0, 6) to dispatcher
04:07:19 DISPATCHER: trying to submit job (4, 0, 6)
04:07:19 DISPATCHER: trying to notify the job_runner thread.
04:07:19 HBMASTER: job (4, 0, 6) submitted to dispatcher
04:07:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:07:19 DISPATCHER: Trying to submit another job.
04:07:19 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:07:19 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:07:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:07:19 WORKER: start processing job (4, 0, 6)
04:07:19 WORKER: args: ()
04:07:19 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 532, 'last_n_outputs': 16, 'leak_rate': 0.8929492451616747, 'lr': 0.009114134410443661, 'optimizer': 'SGD', 'sparsity': 0.7552097717798373, 'steps_to_train': 46, 'weight_decay': 0.06907702446362839}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:07:31 DISPATCHER: Starting worker discovery
04:07:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:07:31 DISPATCHER: Finished worker discovery
04:08:31 DISPATCHER: Starting worker discovery
04:08:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:08:31 DISPATCHER: Finished worker discovery
04:08:44 WORKER: done with job (4, 0, 6), trying to register it.
04:08:44 WORKER: registered result for job (4, 0, 6) with dispatcher
04:08:44 DISPATCHER: job (4, 0, 6) finished
04:08:44 DISPATCHER: register_result: lock acquired
04:08:44 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:08:44 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 532, 'last_n_outputs': 16, 'leak_rate': 0.8929492451616747, 'lr': 0.009114134410443661, 'optimizer': 'SGD', 'sparsity': 0.7552097717798373, 'steps_to_train': 46, 'weight_decay': 0.06907702446362839}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.12687908717134178, 'info': {'data03': 0.12687908717134178, 'config': "{'batch_size': 16, 'hidden_dim': 532, 'last_n_outputs': 16, 'leak_rate': 0.8929492451616747, 'lr': 0.009114134410443661, 'optimizer': 'SGD', 'sparsity': 0.7552097717798373, 'steps_to_train': 46, 'weight_decay': 0.06907702446362839}"}}
exception: None

04:08:44 job_callback for (4, 0, 6) started
04:08:44 job_callback for (4, 0, 6) got condition
04:08:44 DISPATCHER: Trying to submit another job.
04:08:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:08:44 done building a new model for budget 44.444444 based on 10/28 split
Best loss for this budget:-0.271203





04:08:44 HBMASTER: Trying to run another job!
04:08:44 job_callback for (4, 0, 6) finished
04:08:44 start sampling a new configuration.
04:08:44 done sampling a new configuration.
04:08:44 HBMASTER: schedule new run for iteration 4
04:08:44 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
04:08:44 HBMASTER: submitting job (4, 0, 7) to dispatcher
04:08:44 DISPATCHER: trying to submit job (4, 0, 7)
04:08:44 DISPATCHER: trying to notify the job_runner thread.
04:08:44 HBMASTER: job (4, 0, 7) submitted to dispatcher
04:08:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:08:44 DISPATCHER: Trying to submit another job.
04:08:44 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:08:44 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:08:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:08:44 WORKER: start processing job (4, 0, 7)
04:08:44 WORKER: args: ()
04:08:44 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 679, 'last_n_outputs': 41, 'leak_rate': 0.9341300266634744, 'lr': 0.0019437004766188226, 'optimizer': 'Adam', 'sparsity': 0.9042307667810395, 'steps_to_train': 62, 'weight_decay': 0.19240020223798712}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:09:31 DISPATCHER: Starting worker discovery
04:09:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:09:31 DISPATCHER: Finished worker discovery
04:10:28 WORKER: done with job (4, 0, 7), trying to register it.
04:10:28 WORKER: registered result for job (4, 0, 7) with dispatcher
04:10:28 DISPATCHER: job (4, 0, 7) finished
04:10:28 DISPATCHER: register_result: lock acquired
04:10:28 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:10:28 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 679, 'last_n_outputs': 41, 'leak_rate': 0.9341300266634744, 'lr': 0.0019437004766188226, 'optimizer': 'Adam', 'sparsity': 0.9042307667810395, 'steps_to_train': 62, 'weight_decay': 0.19240020223798712}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2769864660572521, 'info': {'data03': 0.2769864660572521, 'config': "{'batch_size': 64, 'hidden_dim': 679, 'last_n_outputs': 41, 'leak_rate': 0.9341300266634744, 'lr': 0.0019437004766188226, 'optimizer': 'Adam', 'sparsity': 0.9042307667810395, 'steps_to_train': 62, 'weight_decay': 0.19240020223798712}"}}
exception: None

04:10:28 job_callback for (4, 0, 7) started
04:10:28 job_callback for (4, 0, 7) got condition
04:10:28 DISPATCHER: Trying to submit another job.
04:10:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:10:28 done building a new model for budget 44.444444 based on 10/29 split
Best loss for this budget:-0.276986





04:10:28 HBMASTER: Trying to run another job!
04:10:28 job_callback for (4, 0, 7) finished
04:10:28 start sampling a new configuration.
04:10:28 best_vector: [3, 0.6924594955443558, 0.7954657396756895, 0.9856961718350336, 0.3492004525594139, 0, 0.8649839210938866, 0.7636897005480419, 0.9175329334785839], 0.009282940854779233, 0.18444581956040584, 0.00171219963389053
04:10:28 done sampling a new configuration.
04:10:28 HBMASTER: schedule new run for iteration 4
04:10:28 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
04:10:28 HBMASTER: submitting job (4, 0, 8) to dispatcher
04:10:28 DISPATCHER: trying to submit job (4, 0, 8)
04:10:28 DISPATCHER: trying to notify the job_runner thread.
04:10:28 HBMASTER: job (4, 0, 8) submitted to dispatcher
04:10:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:10:28 DISPATCHER: Trying to submit another job.
04:10:28 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:10:28 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:10:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:10:28 WORKER: start processing job (4, 0, 8)
04:10:28 WORKER: args: ()
04:10:28 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 754, 'last_n_outputs': 42, 'leak_rate': 0.9964240429587584, 'lr': 0.004993452294122098, 'optimizer': 'Adam', 'sparsity': 0.9575961410625328, 'steps_to_train': 79, 'weight_decay': 0.15622044424068915}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:10:31 DISPATCHER: Starting worker discovery
04:10:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:10:31 DISPATCHER: Finished worker discovery
04:11:31 DISPATCHER: Starting worker discovery
04:11:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:11:31 DISPATCHER: Finished worker discovery
04:11:52 WORKER: done with job (4, 0, 8), trying to register it.
04:11:52 WORKER: registered result for job (4, 0, 8) with dispatcher
04:11:52 DISPATCHER: job (4, 0, 8) finished
04:11:52 DISPATCHER: register_result: lock acquired
04:11:52 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:11:52 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 754, 'last_n_outputs': 42, 'leak_rate': 0.9964240429587584, 'lr': 0.004993452294122098, 'optimizer': 'Adam', 'sparsity': 0.9575961410625328, 'steps_to_train': 79, 'weight_decay': 0.15622044424068915}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 754, 'last_n_outputs': 42, 'leak_rate': 0.9964240429587584, 'lr': 0.004993452294122098, 'optimizer': 'Adam', 'sparsity': 0.9575961410625328, 'steps_to_train': 79, 'weight_decay': 0.15622044424068915}"}}
exception: None

04:11:52 job_callback for (4, 0, 8) started
04:11:52 DISPATCHER: Trying to submit another job.
04:11:52 job_callback for (4, 0, 8) got condition
04:11:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:11:52 done building a new model for budget 44.444444 based on 10/30 split
Best loss for this budget:-0.276986





04:11:52 HBMASTER: Trying to run another job!
04:11:52 job_callback for (4, 0, 8) finished
04:11:52 start sampling a new configuration.
04:11:52 done sampling a new configuration.
04:11:52 HBMASTER: schedule new run for iteration 4
04:11:52 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
04:11:52 HBMASTER: submitting job (4, 0, 9) to dispatcher
04:11:52 DISPATCHER: trying to submit job (4, 0, 9)
04:11:52 DISPATCHER: trying to notify the job_runner thread.
04:11:52 HBMASTER: job (4, 0, 9) submitted to dispatcher
04:11:52 DISPATCHER: Trying to submit another job.
04:11:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:11:52 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:11:52 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:11:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:11:52 WORKER: start processing job (4, 0, 9)
04:11:52 WORKER: args: ()
04:11:52 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 292, 'last_n_outputs': 34, 'leak_rate': 0.8273501477855665, 'lr': 0.046774874872314, 'optimizer': 'Adam', 'sparsity': 0.8469258284338119, 'steps_to_train': 97, 'weight_decay': 0.10977847027200971}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:12:31 DISPATCHER: Starting worker discovery
04:12:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:12:31 DISPATCHER: Finished worker discovery
04:13:23 WORKER: done with job (4, 0, 9), trying to register it.
04:13:23 WORKER: registered result for job (4, 0, 9) with dispatcher
04:13:23 DISPATCHER: job (4, 0, 9) finished
04:13:23 DISPATCHER: register_result: lock acquired
04:13:23 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:13:23 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 292, 'last_n_outputs': 34, 'leak_rate': 0.8273501477855665, 'lr': 0.046774874872314, 'optimizer': 'Adam', 'sparsity': 0.8469258284338119, 'steps_to_train': 97, 'weight_decay': 0.10977847027200971}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 292, 'last_n_outputs': 34, 'leak_rate': 0.8273501477855665, 'lr': 0.046774874872314, 'optimizer': 'Adam', 'sparsity': 0.8469258284338119, 'steps_to_train': 97, 'weight_decay': 0.10977847027200971}"}}
exception: None

04:13:23 job_callback for (4, 0, 9) started
04:13:23 job_callback for (4, 0, 9) got condition
04:13:23 DISPATCHER: Trying to submit another job.
04:13:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:13:23 done building a new model for budget 44.444444 based on 10/31 split
Best loss for this budget:-0.276986





04:13:23 HBMASTER: Trying to run another job!
04:13:23 job_callback for (4, 0, 9) finished
04:13:23 start sampling a new configuration.
04:13:23 done sampling a new configuration.
04:13:23 HBMASTER: schedule new run for iteration 4
04:13:23 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
04:13:23 HBMASTER: submitting job (4, 0, 10) to dispatcher
04:13:23 DISPATCHER: trying to submit job (4, 0, 10)
04:13:23 DISPATCHER: trying to notify the job_runner thread.
04:13:23 HBMASTER: job (4, 0, 10) submitted to dispatcher
04:13:23 DISPATCHER: Trying to submit another job.
04:13:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:13:23 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:13:23 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:13:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:13:23 WORKER: start processing job (4, 0, 10)
04:13:23 WORKER: args: ()
04:13:23 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 523, 'last_n_outputs': 38, 'leak_rate': 0.8461836826021353, 'lr': 0.001767250969395278, 'optimizer': 'Adam', 'sparsity': 0.924829473062398, 'steps_to_train': 38, 'weight_decay': 0.14523020021429514}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:13:31 DISPATCHER: Starting worker discovery
04:13:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:13:31 DISPATCHER: Finished worker discovery
04:14:31 DISPATCHER: Starting worker discovery
04:14:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:14:31 DISPATCHER: Finished worker discovery
04:15:06 WORKER: done with job (4, 0, 10), trying to register it.
04:15:06 WORKER: registered result for job (4, 0, 10) with dispatcher
04:15:06 DISPATCHER: job (4, 0, 10) finished
04:15:06 DISPATCHER: register_result: lock acquired
04:15:06 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:15:06 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 523, 'last_n_outputs': 38, 'leak_rate': 0.8461836826021353, 'lr': 0.001767250969395278, 'optimizer': 'Adam', 'sparsity': 0.924829473062398, 'steps_to_train': 38, 'weight_decay': 0.14523020021429514}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3294377112525148, 'info': {'data03': 0.3294377112525148, 'config': "{'batch_size': 128, 'hidden_dim': 523, 'last_n_outputs': 38, 'leak_rate': 0.8461836826021353, 'lr': 0.001767250969395278, 'optimizer': 'Adam', 'sparsity': 0.924829473062398, 'steps_to_train': 38, 'weight_decay': 0.14523020021429514}"}}
exception: None

04:15:06 job_callback for (4, 0, 10) started
04:15:06 job_callback for (4, 0, 10) got condition
04:15:06 DISPATCHER: Trying to submit another job.
04:15:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:15:06 done building a new model for budget 44.444444 based on 10/32 split
Best loss for this budget:-0.329438





04:15:06 HBMASTER: Trying to run another job!
04:15:06 job_callback for (4, 0, 10) finished
04:15:06 start sampling a new configuration.
04:15:06 best_vector: [3, 0.4236044681809854, 0.9712872353615332, 0.8716575977978004, 0.6120686120110593, 0, 0.6093029337886379, 0.7778306875964468, 0.33454741779063724], 0.06307362674945347, 0.15438593482220875, 0.009737680828341444
04:15:06 done sampling a new configuration.
04:15:06 HBMASTER: schedule new run for iteration 4
04:15:06 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
04:15:06 HBMASTER: submitting job (4, 0, 11) to dispatcher
04:15:06 DISPATCHER: trying to submit job (4, 0, 11)
04:15:06 DISPATCHER: trying to notify the job_runner thread.
04:15:06 HBMASTER: job (4, 0, 11) submitted to dispatcher
04:15:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:15:06 DISPATCHER: Trying to submit another job.
04:15:06 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:15:06 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:15:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:15:06 WORKER: start processing job (4, 0, 11)
04:15:06 WORKER: args: ()
04:15:06 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 539, 'last_n_outputs': 49, 'leak_rate': 0.9679143994494501, 'lr': 0.016754721913258976, 'optimizer': 'Adam', 'sparsity': 0.896232704109273, 'steps_to_train': 80, 'weight_decay': 0.027243081242228996}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:15:31 DISPATCHER: Starting worker discovery
04:15:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:15:31 DISPATCHER: Finished worker discovery
04:16:31 DISPATCHER: Starting worker discovery
04:16:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:16:31 DISPATCHER: Finished worker discovery
04:17:10 WORKER: done with job (4, 0, 11), trying to register it.
04:17:10 WORKER: registered result for job (4, 0, 11) with dispatcher
04:17:10 DISPATCHER: job (4, 0, 11) finished
04:17:10 DISPATCHER: register_result: lock acquired
04:17:10 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:17:10 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 539, 'last_n_outputs': 49, 'leak_rate': 0.9679143994494501, 'lr': 0.016754721913258976, 'optimizer': 'Adam', 'sparsity': 0.896232704109273, 'steps_to_train': 80, 'weight_decay': 0.027243081242228996}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3006022366464818, 'info': {'data03': 0.3006022366464818, 'config': "{'batch_size': 128, 'hidden_dim': 539, 'last_n_outputs': 49, 'leak_rate': 0.9679143994494501, 'lr': 0.016754721913258976, 'optimizer': 'Adam', 'sparsity': 0.896232704109273, 'steps_to_train': 80, 'weight_decay': 0.027243081242228996}"}}
exception: None

04:17:10 job_callback for (4, 0, 11) started
04:17:10 job_callback for (4, 0, 11) got condition
04:17:10 DISPATCHER: Trying to submit another job.
04:17:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:17:10 done building a new model for budget 44.444444 based on 10/33 split
Best loss for this budget:-0.329438





04:17:10 HBMASTER: Trying to run another job!
04:17:10 job_callback for (4, 0, 11) finished
04:17:10 start sampling a new configuration.
04:17:10 best_vector: [0, 0.3852757431485231, 0.9288029026207254, 0.06144777346240349, 0.23984124151311248, 0, 0.31176052164709567, 0.4174069296737497, 0.8201404921233204], 0.036728658209220624, 0.07501293062558148, 0.0027551242902189607
04:17:10 done sampling a new configuration.
04:17:10 HBMASTER: schedule new run for iteration 4
04:17:10 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
04:17:10 HBMASTER: submitting job (4, 0, 12) to dispatcher
04:17:10 DISPATCHER: trying to submit job (4, 0, 12)
04:17:10 DISPATCHER: trying to notify the job_runner thread.
04:17:10 HBMASTER: job (4, 0, 12) submitted to dispatcher
04:17:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:17:10 DISPATCHER: Trying to submit another job.
04:17:10 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:17:10 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:17:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:17:10 WORKER: start processing job (4, 0, 12)
04:17:10 WORKER: args: ()
04:17:10 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 508, 'last_n_outputs': 48, 'leak_rate': 0.7653619433656009, 'lr': 0.003017744610869008, 'optimizer': 'Adam', 'sparsity': 0.824822525195303, 'steps_to_train': 47, 'weight_decay': 0.11668831830831446}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:17:31 DISPATCHER: Starting worker discovery
04:17:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:17:31 DISPATCHER: Finished worker discovery
04:18:31 DISPATCHER: Starting worker discovery
04:18:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:18:31 DISPATCHER: Finished worker discovery
04:18:34 WORKER: done with job (4, 0, 12), trying to register it.
04:18:34 WORKER: registered result for job (4, 0, 12) with dispatcher
04:18:34 DISPATCHER: job (4, 0, 12) finished
04:18:34 DISPATCHER: register_result: lock acquired
04:18:34 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:18:34 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 508, 'last_n_outputs': 48, 'leak_rate': 0.7653619433656009, 'lr': 0.003017744610869008, 'optimizer': 'Adam', 'sparsity': 0.824822525195303, 'steps_to_train': 47, 'weight_decay': 0.11668831830831446}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.13797917711949567, 'info': {'data03': 0.13797917711949567, 'config': "{'batch_size': 16, 'hidden_dim': 508, 'last_n_outputs': 48, 'leak_rate': 0.7653619433656009, 'lr': 0.003017744610869008, 'optimizer': 'Adam', 'sparsity': 0.824822525195303, 'steps_to_train': 47, 'weight_decay': 0.11668831830831446}"}}
exception: None

04:18:34 job_callback for (4, 0, 12) started
04:18:34 DISPATCHER: Trying to submit another job.
04:18:34 job_callback for (4, 0, 12) got condition
04:18:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:18:34 done building a new model for budget 44.444444 based on 10/34 split
Best loss for this budget:-0.329438





04:18:34 HBMASTER: Trying to run another job!
04:18:34 job_callback for (4, 0, 12) finished
04:18:34 start sampling a new configuration.
04:18:34 best_vector: [3, 0.47494509990020073, 0.3024761094464129, 0.41361298427114196, 0.7781606433897688, 0, 0.888375767644889, 0.3338880697381023, 0.7331453559414319], 0.10176817393699784, 0.2619663697733845, 0.026659839084741687
04:18:34 done sampling a new configuration.
04:18:34 HBMASTER: schedule new run for iteration 4
04:18:34 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
04:18:34 HBMASTER: submitting job (4, 0, 13) to dispatcher
04:18:34 DISPATCHER: trying to submit job (4, 0, 13)
04:18:34 DISPATCHER: trying to notify the job_runner thread.
04:18:34 HBMASTER: job (4, 0, 13) submitted to dispatcher
04:18:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:18:34 DISPATCHER: Trying to submit another job.
04:18:34 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:18:34 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:18:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:18:34 WORKER: start processing job (4, 0, 13)
04:18:34 WORKER: args: ()
04:18:34 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 580, 'last_n_outputs': 22, 'leak_rate': 0.8534032460677855, 'lr': 0.03600155726378409, 'optimizer': 'Adam', 'sparsity': 0.9632101842347733, 'steps_to_train': 40, 'weight_decay': 0.0899174742589829}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:19:31 DISPATCHER: Starting worker discovery
04:19:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:19:31 DISPATCHER: Finished worker discovery
04:20:18 WORKER: done with job (4, 0, 13), trying to register it.
04:20:18 WORKER: registered result for job (4, 0, 13) with dispatcher
04:20:18 DISPATCHER: job (4, 0, 13) finished
04:20:18 DISPATCHER: register_result: lock acquired
04:20:18 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:20:18 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 580, 'last_n_outputs': 22, 'leak_rate': 0.8534032460677855, 'lr': 0.03600155726378409, 'optimizer': 'Adam', 'sparsity': 0.9632101842347733, 'steps_to_train': 40, 'weight_decay': 0.0899174742589829}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 580, 'last_n_outputs': 22, 'leak_rate': 0.8534032460677855, 'lr': 0.03600155726378409, 'optimizer': 'Adam', 'sparsity': 0.9632101842347733, 'steps_to_train': 40, 'weight_decay': 0.0899174742589829}"}}
exception: None

04:20:18 job_callback for (4, 0, 13) started
04:20:18 job_callback for (4, 0, 13) got condition
04:20:18 DISPATCHER: Trying to submit another job.
04:20:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:20:18 done building a new model for budget 44.444444 based on 10/34 split
Best loss for this budget:-0.329438





04:20:18 HBMASTER: Trying to run another job!
04:20:18 job_callback for (4, 0, 13) finished
04:20:18 start sampling a new configuration.
04:20:18 done sampling a new configuration.
04:20:18 HBMASTER: schedule new run for iteration 4
04:20:18 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
04:20:18 HBMASTER: submitting job (4, 0, 14) to dispatcher
04:20:18 DISPATCHER: trying to submit job (4, 0, 14)
04:20:18 DISPATCHER: trying to notify the job_runner thread.
04:20:18 HBMASTER: job (4, 0, 14) submitted to dispatcher
04:20:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:20:18 DISPATCHER: Trying to submit another job.
04:20:18 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:20:18 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:20:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:20:18 WORKER: start processing job (4, 0, 14)
04:20:18 WORKER: args: ()
04:20:18 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 943, 'last_n_outputs': 33, 'leak_rate': 0.9612311425870278, 'lr': 0.002196818637355155, 'optimizer': 'SGD', 'sparsity': 0.8687978335864066, 'steps_to_train': 57, 'weight_decay': 0.06270788838455277}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:20:31 DISPATCHER: Starting worker discovery
04:20:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:20:31 DISPATCHER: Finished worker discovery
04:21:31 DISPATCHER: Starting worker discovery
04:21:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:21:31 DISPATCHER: Finished worker discovery
04:21:55 WORKER: done with job (4, 0, 14), trying to register it.
04:21:55 WORKER: registered result for job (4, 0, 14) with dispatcher
04:21:55 DISPATCHER: job (4, 0, 14) finished
04:21:55 DISPATCHER: register_result: lock acquired
04:21:55 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:21:55 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 943, 'last_n_outputs': 33, 'leak_rate': 0.9612311425870278, 'lr': 0.002196818637355155, 'optimizer': 'SGD', 'sparsity': 0.8687978335864066, 'steps_to_train': 57, 'weight_decay': 0.06270788838455277}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 943, 'last_n_outputs': 33, 'leak_rate': 0.9612311425870278, 'lr': 0.002196818637355155, 'optimizer': 'SGD', 'sparsity': 0.8687978335864066, 'steps_to_train': 57, 'weight_decay': 0.06270788838455277}"}}
exception: None

04:21:55 job_callback for (4, 0, 14) started
04:21:55 DISPATCHER: Trying to submit another job.
04:21:55 job_callback for (4, 0, 14) got condition
04:21:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:21:55 done building a new model for budget 44.444444 based on 10/35 split
Best loss for this budget:-0.329438





04:21:55 HBMASTER: Trying to run another job!
04:21:55 job_callback for (4, 0, 14) finished
04:21:55 start sampling a new configuration.
04:21:55 done sampling a new configuration.
04:21:55 HBMASTER: schedule new run for iteration 4
04:21:55 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
04:21:55 HBMASTER: submitting job (4, 0, 15) to dispatcher
04:21:55 DISPATCHER: trying to submit job (4, 0, 15)
04:21:55 DISPATCHER: trying to notify the job_runner thread.
04:21:55 HBMASTER: job (4, 0, 15) submitted to dispatcher
04:21:55 DISPATCHER: Trying to submit another job.
04:21:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:21:55 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:21:55 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:21:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:21:55 WORKER: start processing job (4, 0, 15)
04:21:55 WORKER: args: ()
04:21:55 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 303, 'last_n_outputs': 31, 'leak_rate': 0.7904065548301646, 'lr': 0.0022996259409958065, 'optimizer': 'Adam', 'sparsity': 0.7746594328106844, 'steps_to_train': 89, 'weight_decay': 0.026431252249917322}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:22:31 DISPATCHER: Starting worker discovery
04:22:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:22:31 DISPATCHER: Finished worker discovery
04:23:18 WORKER: done with job (4, 0, 15), trying to register it.
04:23:18 WORKER: registered result for job (4, 0, 15) with dispatcher
04:23:18 DISPATCHER: job (4, 0, 15) finished
04:23:18 DISPATCHER: register_result: lock acquired
04:23:18 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:23:18 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 303, 'last_n_outputs': 31, 'leak_rate': 0.7904065548301646, 'lr': 0.0022996259409958065, 'optimizer': 'Adam', 'sparsity': 0.7746594328106844, 'steps_to_train': 89, 'weight_decay': 0.026431252249917322}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 303, 'last_n_outputs': 31, 'leak_rate': 0.7904065548301646, 'lr': 0.0022996259409958065, 'optimizer': 'Adam', 'sparsity': 0.7746594328106844, 'steps_to_train': 89, 'weight_decay': 0.026431252249917322}"}}
exception: None

04:23:18 job_callback for (4, 0, 15) started
04:23:18 DISPATCHER: Trying to submit another job.
04:23:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:23:18 job_callback for (4, 0, 15) got condition
04:23:18 done building a new model for budget 44.444444 based on 10/36 split
Best loss for this budget:-0.329438





04:23:18 HBMASTER: Trying to run another job!
04:23:18 job_callback for (4, 0, 15) finished
04:23:18 start sampling a new configuration.
04:23:19 best_vector: [0, 0.5330795640069442, 0.9978833785419765, 0.3914266671785136, 0.19162393324876512, 0, 0.9527845599086927, 0.9251429255768704, 0.153755579576289], 0.024157808766473814, 0.04350577371998082, 0.0010510041617647788
04:23:19 done sampling a new configuration.
04:23:19 HBMASTER: schedule new run for iteration 4
04:23:19 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
04:23:19 HBMASTER: submitting job (4, 0, 16) to dispatcher
04:23:19 DISPATCHER: trying to submit job (4, 0, 16)
04:23:19 DISPATCHER: trying to notify the job_runner thread.
04:23:19 HBMASTER: job (4, 0, 16) submitted to dispatcher
04:23:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:23:19 DISPATCHER: Trying to submit another job.
04:23:19 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:23:19 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:23:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:23:19 WORKER: start processing job (4, 0, 16)
04:23:19 WORKER: args: ()
04:23:19 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 626, 'last_n_outputs': 50, 'leak_rate': 0.8478566667946283, 'lr': 0.002416839812826949, 'optimizer': 'Adam', 'sparsity': 0.9786682943780862, 'steps_to_train': 94, 'weight_decay': 0.015850414398063256}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:23:31 DISPATCHER: Starting worker discovery
04:23:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:23:31 DISPATCHER: Finished worker discovery
04:24:31 DISPATCHER: Starting worker discovery
04:24:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:24:31 DISPATCHER: Finished worker discovery
04:24:44 WORKER: done with job (4, 0, 16), trying to register it.
04:24:44 WORKER: registered result for job (4, 0, 16) with dispatcher
04:24:44 DISPATCHER: job (4, 0, 16) finished
04:24:44 DISPATCHER: register_result: lock acquired
04:24:44 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:24:44 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 626, 'last_n_outputs': 50, 'leak_rate': 0.8478566667946283, 'lr': 0.002416839812826949, 'optimizer': 'Adam', 'sparsity': 0.9786682943780862, 'steps_to_train': 94, 'weight_decay': 0.015850414398063256}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 626, 'last_n_outputs': 50, 'leak_rate': 0.8478566667946283, 'lr': 0.002416839812826949, 'optimizer': 'Adam', 'sparsity': 0.9786682943780862, 'steps_to_train': 94, 'weight_decay': 0.015850414398063256}"}}
exception: None

04:24:44 job_callback for (4, 0, 16) started
04:24:44 job_callback for (4, 0, 16) got condition
04:24:44 DISPATCHER: Trying to submit another job.
04:24:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:24:44 done building a new model for budget 44.444444 based on 10/37 split
Best loss for this budget:-0.329438





04:24:44 HBMASTER: Trying to run another job!
04:24:44 job_callback for (4, 0, 16) finished
04:24:44 start sampling a new configuration.
04:24:44 best_vector: [0, 0.16285083038101417, 0.47515716195714497, 0.22641132966887256, 0.8627175540610221, 0, 0.03534100369790333, 0.3042092572968899, 0.7730109574228633], 0.05014552021286412, 0.5703304035677194, 0.028599514780116023
04:24:44 done sampling a new configuration.
04:24:44 HBMASTER: schedule new run for iteration 4
04:24:44 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
04:24:44 HBMASTER: submitting job (4, 0, 17) to dispatcher
04:24:44 DISPATCHER: trying to submit job (4, 0, 17)
04:24:44 DISPATCHER: trying to notify the job_runner thread.
04:24:44 HBMASTER: job (4, 0, 17) submitted to dispatcher
04:24:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:24:44 DISPATCHER: Trying to submit another job.
04:24:44 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:24:44 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:24:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:24:44 WORKER: start processing job (4, 0, 17)
04:24:44 WORKER: args: ()
04:24:44 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 330, 'last_n_outputs': 29, 'leak_rate': 0.8066028324172181, 'lr': 0.053141658980105824, 'optimizer': 'Adam', 'sparsity': 0.7584818408874968, 'steps_to_train': 37, 'weight_decay': 0.10132356053075742}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:25:31 DISPATCHER: Starting worker discovery
04:25:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:25:31 DISPATCHER: Finished worker discovery
04:26:19 WORKER: done with job (4, 0, 17), trying to register it.
04:26:19 WORKER: registered result for job (4, 0, 17) with dispatcher
04:26:19 DISPATCHER: job (4, 0, 17) finished
04:26:19 DISPATCHER: register_result: lock acquired
04:26:19 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:26:19 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 330, 'last_n_outputs': 29, 'leak_rate': 0.8066028324172181, 'lr': 0.053141658980105824, 'optimizer': 'Adam', 'sparsity': 0.7584818408874968, 'steps_to_train': 37, 'weight_decay': 0.10132356053075742}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 330, 'last_n_outputs': 29, 'leak_rate': 0.8066028324172181, 'lr': 0.053141658980105824, 'optimizer': 'Adam', 'sparsity': 0.7584818408874968, 'steps_to_train': 37, 'weight_decay': 0.10132356053075742}"}}
exception: None

04:26:19 job_callback for (4, 0, 17) started
04:26:19 DISPATCHER: Trying to submit another job.
04:26:19 job_callback for (4, 0, 17) got condition
04:26:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:26:19 done building a new model for budget 44.444444 based on 10/38 split
Best loss for this budget:-0.329438





04:26:19 HBMASTER: Trying to run another job!
04:26:19 job_callback for (4, 0, 17) finished
04:26:19 start sampling a new configuration.
04:26:19 best_vector: [0, 0.28025779322262284, 0.8154825476704125, 0.920266139592481, 0.9942786873522471, 1, 0.3177669167261197, 0.7097746118290765, 0.04281118159363184], 0.03730977534050184, 0.0243860791488611, 0.0009098391344797039
04:26:19 done sampling a new configuration.
04:26:19 HBMASTER: schedule new run for iteration 4
04:26:19 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
04:26:19 HBMASTER: submitting job (4, 0, 18) to dispatcher
04:26:19 DISPATCHER: trying to submit job (4, 0, 18)
04:26:19 DISPATCHER: trying to notify the job_runner thread.
04:26:19 HBMASTER: job (4, 0, 18) submitted to dispatcher
04:26:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:26:19 DISPATCHER: Trying to submit another job.
04:26:19 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:26:19 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:26:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:26:19 WORKER: start processing job (4, 0, 18)
04:26:19 WORKER: args: ()
04:26:19 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 424, 'last_n_outputs': 43, 'leak_rate': 0.9800665348981202, 'lr': 0.0973996451636272, 'optimizer': 'SGD', 'sparsity': 0.8262640600142688, 'steps_to_train': 74, 'weight_decay': 0.011368381295574494}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:26:31 DISPATCHER: Starting worker discovery
04:26:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:26:31 DISPATCHER: Finished worker discovery
04:27:31 DISPATCHER: Starting worker discovery
04:27:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:27:31 DISPATCHER: Finished worker discovery
04:28:12 WORKER: done with job (4, 0, 18), trying to register it.
04:28:12 WORKER: registered result for job (4, 0, 18) with dispatcher
04:28:12 DISPATCHER: job (4, 0, 18) finished
04:28:12 DISPATCHER: register_result: lock acquired
04:28:12 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:28:12 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 424, 'last_n_outputs': 43, 'leak_rate': 0.9800665348981202, 'lr': 0.0973996451636272, 'optimizer': 'SGD', 'sparsity': 0.8262640600142688, 'steps_to_train': 74, 'weight_decay': 0.011368381295574494}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.01643475731818364, 'info': {'data03': 0.01643475731818364, 'config': "{'batch_size': 16, 'hidden_dim': 424, 'last_n_outputs': 43, 'leak_rate': 0.9800665348981202, 'lr': 0.0973996451636272, 'optimizer': 'SGD', 'sparsity': 0.8262640600142688, 'steps_to_train': 74, 'weight_decay': 0.011368381295574494}"}}
exception: None

04:28:12 job_callback for (4, 0, 18) started
04:28:12 job_callback for (4, 0, 18) got condition
04:28:12 DISPATCHER: Trying to submit another job.
04:28:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:28:12 done building a new model for budget 44.444444 based on 10/39 split
Best loss for this budget:-0.329438





04:28:12 HBMASTER: Trying to run another job!
04:28:12 job_callback for (4, 0, 18) finished
04:28:12 start sampling a new configuration.
04:28:12 best_vector: [2, 0.4868056377633649, 0.8308294225502301, 0.2845414072633974, 0.010052738477954043, 0, 0.8916444247098365, 0.5615639156462238, 0.9240629633729396], 0.00687772767278998, 0.45521372305042995, 0.003130836020057696
04:28:12 done sampling a new configuration.
04:28:12 HBMASTER: schedule new run for iteration 4
04:28:12 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
04:28:12 HBMASTER: submitting job (4, 0, 19) to dispatcher
04:28:12 DISPATCHER: trying to submit job (4, 0, 19)
04:28:12 DISPATCHER: trying to notify the job_runner thread.
04:28:12 HBMASTER: job (4, 0, 19) submitted to dispatcher
04:28:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:28:12 DISPATCHER: Trying to submit another job.
04:28:12 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:28:12 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:28:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:28:12 WORKER: start processing job (4, 0, 19)
04:28:12 WORKER: args: ()
04:28:12 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 589, 'last_n_outputs': 44, 'leak_rate': 0.8211353518158493, 'lr': 0.00104738289469726, 'optimizer': 'Adam', 'sparsity': 0.9639946619303608, 'steps_to_train': 61, 'weight_decay': 0.15930655027193932}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:28:31 DISPATCHER: Starting worker discovery
04:28:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:28:31 DISPATCHER: Finished worker discovery
04:29:31 DISPATCHER: Starting worker discovery
04:29:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:29:31 DISPATCHER: Finished worker discovery
04:29:54 WORKER: done with job (4, 0, 19), trying to register it.
04:29:54 WORKER: registered result for job (4, 0, 19) with dispatcher
04:29:54 DISPATCHER: job (4, 0, 19) finished
04:29:54 DISPATCHER: register_result: lock acquired
04:29:54 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:29:54 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 589, 'last_n_outputs': 44, 'leak_rate': 0.8211353518158493, 'lr': 0.00104738289469726, 'optimizer': 'Adam', 'sparsity': 0.9639946619303608, 'steps_to_train': 61, 'weight_decay': 0.15930655027193932}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.07200007797062524, 'info': {'data03': 0.07200007797062524, 'config': "{'batch_size': 64, 'hidden_dim': 589, 'last_n_outputs': 44, 'leak_rate': 0.8211353518158493, 'lr': 0.00104738289469726, 'optimizer': 'Adam', 'sparsity': 0.9639946619303608, 'steps_to_train': 61, 'weight_decay': 0.15930655027193932}"}}
exception: None

04:29:54 job_callback for (4, 0, 19) started
04:29:54 DISPATCHER: Trying to submit another job.
04:29:54 job_callback for (4, 0, 19) got condition
04:29:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:29:54 done building a new model for budget 44.444444 based on 10/39 split
Best loss for this budget:-0.329438





04:29:54 HBMASTER: Trying to run another job!
04:29:54 job_callback for (4, 0, 19) finished
04:29:54 start sampling a new configuration.
04:29:54 best_vector: [0, 0.7177809205379098, 0.8603471197561829, 0.6872904260018304, 0.13232648792477442, 0, 0.4020474529935844, 0.3566883171649007, 0.9986931118695662], 0.053215511837194404, 0.4234184606062327, 0.02253243010247761
04:29:54 done sampling a new configuration.
04:29:54 HBMASTER: schedule new run for iteration 4
04:29:54 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
04:29:54 HBMASTER: submitting job (4, 0, 20) to dispatcher
04:29:54 DISPATCHER: trying to submit job (4, 0, 20)
04:29:54 DISPATCHER: trying to notify the job_runner thread.
04:29:54 HBMASTER: job (4, 0, 20) submitted to dispatcher
04:29:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:29:54 DISPATCHER: Trying to submit another job.
04:29:54 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:29:54 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:29:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:29:54 WORKER: start processing job (4, 0, 20)
04:29:54 WORKER: args: ()
04:29:54 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 774, 'last_n_outputs': 45, 'leak_rate': 0.9218226065004576, 'lr': 0.0018393017152456602, 'optimizer': 'Adam', 'sparsity': 0.8464913887184603, 'steps_to_train': 42, 'weight_decay': 0.19921851340214994}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:30:31 DISPATCHER: Starting worker discovery
04:30:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:30:31 DISPATCHER: Finished worker discovery
04:31:31 DISPATCHER: Starting worker discovery
04:31:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:31:31 DISPATCHER: Finished worker discovery
04:31:33 WORKER: done with job (4, 0, 20), trying to register it.
04:31:33 WORKER: registered result for job (4, 0, 20) with dispatcher
04:31:33 DISPATCHER: job (4, 0, 20) finished
04:31:33 DISPATCHER: register_result: lock acquired
04:31:33 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:31:33 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 774, 'last_n_outputs': 45, 'leak_rate': 0.9218226065004576, 'lr': 0.0018393017152456602, 'optimizer': 'Adam', 'sparsity': 0.8464913887184603, 'steps_to_train': 42, 'weight_decay': 0.19921851340214994}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.12533366174175473, 'info': {'data03': 0.12533366174175473, 'config': "{'batch_size': 16, 'hidden_dim': 774, 'last_n_outputs': 45, 'leak_rate': 0.9218226065004576, 'lr': 0.0018393017152456602, 'optimizer': 'Adam', 'sparsity': 0.8464913887184603, 'steps_to_train': 42, 'weight_decay': 0.19921851340214994}"}}
exception: None

04:31:33 job_callback for (4, 0, 20) started
04:31:33 DISPATCHER: Trying to submit another job.
04:31:33 job_callback for (4, 0, 20) got condition
04:31:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:31:33 done building a new model for budget 44.444444 based on 10/40 split
Best loss for this budget:-0.329438





04:31:33 HBMASTER: Trying to run another job!
04:31:33 job_callback for (4, 0, 20) finished
04:31:33 start sampling a new configuration.
04:31:33 best_vector: [3, 0.5521260303633945, 0.9197074788171355, 0.8119504915351514, 0.40503146866600354, 0, 0.7671970037099388, 0.7893606655050128, 0.3192717277977326], 0.02020320233867114, 1.1441390500834026, 0.023115272732409976
04:31:33 done sampling a new configuration.
04:31:33 HBMASTER: schedule new run for iteration 4
04:31:33 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
04:31:33 HBMASTER: submitting job (4, 0, 21) to dispatcher
04:31:33 DISPATCHER: trying to submit job (4, 0, 21)
04:31:33 DISPATCHER: trying to notify the job_runner thread.
04:31:33 HBMASTER: job (4, 0, 21) submitted to dispatcher
04:31:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:31:33 DISPATCHER: Trying to submit another job.
04:31:33 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:31:33 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:31:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:31:33 WORKER: start processing job (4, 0, 21)
04:31:33 WORKER: args: ()
04:31:33 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 642, 'last_n_outputs': 47, 'leak_rate': 0.9529876228837879, 'lr': 0.006457478030975271, 'optimizer': 'Adam', 'sparsity': 0.9341272808903853, 'steps_to_train': 81, 'weight_decay': 0.02602448204233227}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:32:31 DISPATCHER: Starting worker discovery
04:32:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:32:31 DISPATCHER: Finished worker discovery
04:33:31 DISPATCHER: Starting worker discovery
04:33:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:33:31 DISPATCHER: Finished worker discovery
04:33:34 WORKER: done with job (4, 0, 21), trying to register it.
04:33:34 WORKER: registered result for job (4, 0, 21) with dispatcher
04:33:34 DISPATCHER: job (4, 0, 21) finished
04:33:34 DISPATCHER: register_result: lock acquired
04:33:34 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:33:34 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 642, 'last_n_outputs': 47, 'leak_rate': 0.9529876228837879, 'lr': 0.006457478030975271, 'optimizer': 'Adam', 'sparsity': 0.9341272808903853, 'steps_to_train': 81, 'weight_decay': 0.02602448204233227}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.35407895523934635, 'info': {'data03': 0.35407895523934635, 'config': "{'batch_size': 128, 'hidden_dim': 642, 'last_n_outputs': 47, 'leak_rate': 0.9529876228837879, 'lr': 0.006457478030975271, 'optimizer': 'Adam', 'sparsity': 0.9341272808903853, 'steps_to_train': 81, 'weight_decay': 0.02602448204233227}"}}
exception: None

04:33:34 job_callback for (4, 0, 21) started
04:33:34 job_callback for (4, 0, 21) got condition
04:33:34 DISPATCHER: Trying to submit another job.
04:33:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:33:34 done building a new model for budget 44.444444 based on 10/41 split
Best loss for this budget:-0.354079





04:33:34 HBMASTER: Trying to run another job!
04:33:34 job_callback for (4, 0, 21) finished
04:33:34 start sampling a new configuration.
04:33:35 best_vector: [1, 0.5818991296351791, 0.7007295313900997, 0.3177234193430758, 0.4258466137297783, 0, 0.29990554952300374, 0.7879093273762299, 0.6083501085838129], 0.016728205228061076, 1.4165181595666456, 0.023695806482506215
04:33:35 done sampling a new configuration.
04:33:35 HBMASTER: schedule new run for iteration 4
04:33:35 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
04:33:35 HBMASTER: submitting job (4, 0, 22) to dispatcher
04:33:35 DISPATCHER: trying to submit job (4, 0, 22)
04:33:35 DISPATCHER: trying to notify the job_runner thread.
04:33:35 HBMASTER: job (4, 0, 22) submitted to dispatcher
04:33:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:33:35 DISPATCHER: Trying to submit another job.
04:33:35 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:33:35 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:33:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:33:35 WORKER: start processing job (4, 0, 22)
04:33:35 WORKER: args: ()
04:33:35 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 666, 'last_n_outputs': 38, 'leak_rate': 0.829430854835769, 'lr': 0.007107113112412662, 'optimizer': 'Adam', 'sparsity': 0.8219773318855209, 'steps_to_train': 81, 'weight_decay': 0.061870231230632455}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:34:31 DISPATCHER: Starting worker discovery
04:34:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:34:31 DISPATCHER: Finished worker discovery
04:35:31 DISPATCHER: Starting worker discovery
04:35:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:35:31 DISPATCHER: Finished worker discovery
04:35:39 WORKER: done with job (4, 0, 22), trying to register it.
04:35:39 WORKER: registered result for job (4, 0, 22) with dispatcher
04:35:39 DISPATCHER: job (4, 0, 22) finished
04:35:39 DISPATCHER: register_result: lock acquired
04:35:39 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:35:39 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 666, 'last_n_outputs': 38, 'leak_rate': 0.829430854835769, 'lr': 0.007107113112412662, 'optimizer': 'Adam', 'sparsity': 0.8219773318855209, 'steps_to_train': 81, 'weight_decay': 0.061870231230632455}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.26045549912776883, 'info': {'data03': 0.26045549912776883, 'config': "{'batch_size': 32, 'hidden_dim': 666, 'last_n_outputs': 38, 'leak_rate': 0.829430854835769, 'lr': 0.007107113112412662, 'optimizer': 'Adam', 'sparsity': 0.8219773318855209, 'steps_to_train': 81, 'weight_decay': 0.061870231230632455}"}}
exception: None

04:35:39 job_callback for (4, 0, 22) started
04:35:39 job_callback for (4, 0, 22) got condition
04:35:39 DISPATCHER: Trying to submit another job.
04:35:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:35:39 done building a new model for budget 44.444444 based on 10/42 split
Best loss for this budget:-0.354079





04:35:39 HBMASTER: Trying to run another job!
04:35:39 job_callback for (4, 0, 22) finished
04:35:39 start sampling a new configuration.
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/statsmodels/nonparametric/kernels.py:62: RuntimeWarning: divide by zero encountered in true_divide
  kernel_value = np.ones(Xi.size) * h / (num_levels - 1)
04:35:39 best_vector: [0, 0.6144176651157327, 0.895953674552569, 0.24992431559996087, 0.630676789886818, 0, 0.42941997451588837, 0.8882822595987879, 0.14124274290491962], 0.01475929713379928, 0.18085159755554608, 0.002669242465444592
04:35:39 done sampling a new configuration.
04:35:39 HBMASTER: schedule new run for iteration 4
04:35:39 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
04:35:39 HBMASTER: submitting job (4, 0, 23) to dispatcher
04:35:39 DISPATCHER: trying to submit job (4, 0, 23)
04:35:39 DISPATCHER: trying to notify the job_runner thread.
04:35:39 HBMASTER: job (4, 0, 23) submitted to dispatcher
04:35:39 DISPATCHER: Trying to submit another job.
04:35:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:35:39 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:35:39 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:35:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:35:39 WORKER: start processing job (4, 0, 23)
04:35:39 WORKER: args: ()
04:35:39 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 692, 'last_n_outputs': 46, 'leak_rate': 0.8124810788999902, 'lr': 0.018253812271111527, 'optimizer': 'Adam', 'sparsity': 0.8530607938838132, 'steps_to_train': 90, 'weight_decay': 0.015267258015164148}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:36:31 DISPATCHER: Starting worker discovery
04:36:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:36:31 DISPATCHER: Finished worker discovery
04:37:04 WORKER: done with job (4, 0, 23), trying to register it.
04:37:04 WORKER: registered result for job (4, 0, 23) with dispatcher
04:37:04 DISPATCHER: job (4, 0, 23) finished
04:37:04 DISPATCHER: register_result: lock acquired
04:37:04 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:37:04 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 692, 'last_n_outputs': 46, 'leak_rate': 0.8124810788999902, 'lr': 0.018253812271111527, 'optimizer': 'Adam', 'sparsity': 0.8530607938838132, 'steps_to_train': 90, 'weight_decay': 0.015267258015164148}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 692, 'last_n_outputs': 46, 'leak_rate': 0.8124810788999902, 'lr': 0.018253812271111527, 'optimizer': 'Adam', 'sparsity': 0.8530607938838132, 'steps_to_train': 90, 'weight_decay': 0.015267258015164148}"}}
exception: None

04:37:04 job_callback for (4, 0, 23) started
04:37:04 DISPATCHER: Trying to submit another job.
04:37:04 job_callback for (4, 0, 23) got condition
04:37:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:37:04 done building a new model for budget 44.444444 based on 10/43 split
Best loss for this budget:-0.354079





04:37:04 HBMASTER: Trying to run another job!
04:37:04 job_callback for (4, 0, 23) finished
04:37:04 start sampling a new configuration.
04:37:04 best_vector: [0, 0.6513307197738447, 0.7573349954648569, 0.15225561617038252, 0.3398680527024089, 0, 0.08685190225803105, 0.8687040176717126, 0.8588821358190172], 0.008997739921101675, 0.9467727631074293, 0.008518815086823455
04:37:04 done sampling a new configuration.
04:37:04 HBMASTER: schedule new run for iteration 4
04:37:04 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
04:37:04 HBMASTER: submitting job (4, 0, 24) to dispatcher
04:37:04 DISPATCHER: trying to submit job (4, 0, 24)
04:37:04 DISPATCHER: trying to notify the job_runner thread.
04:37:04 HBMASTER: job (4, 0, 24) submitted to dispatcher
04:37:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:37:04 DISPATCHER: Trying to submit another job.
04:37:04 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:37:04 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:37:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:37:04 WORKER: start processing job (4, 0, 24)
04:37:04 WORKER: args: ()
04:37:04 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 721, 'last_n_outputs': 41, 'leak_rate': 0.7880639040425956, 'lr': 0.004783393459911994, 'optimizer': 'Adam', 'sparsity': 0.7708444565419275, 'steps_to_train': 89, 'weight_decay': 0.13104830903038356}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:37:31 DISPATCHER: Starting worker discovery
04:37:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:37:31 DISPATCHER: Finished worker discovery
04:38:31 DISPATCHER: Starting worker discovery
04:38:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:38:31 DISPATCHER: Finished worker discovery
04:39:01 WORKER: done with job (4, 0, 24), trying to register it.
04:39:01 WORKER: registered result for job (4, 0, 24) with dispatcher
04:39:01 DISPATCHER: job (4, 0, 24) finished
04:39:01 DISPATCHER: register_result: lock acquired
04:39:01 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:39:01 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 721, 'last_n_outputs': 41, 'leak_rate': 0.7880639040425956, 'lr': 0.004783393459911994, 'optimizer': 'Adam', 'sparsity': 0.7708444565419275, 'steps_to_train': 89, 'weight_decay': 0.13104830903038356}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.13507164939495991, 'info': {'data03': 0.13507164939495991, 'config': "{'batch_size': 16, 'hidden_dim': 721, 'last_n_outputs': 41, 'leak_rate': 0.7880639040425956, 'lr': 0.004783393459911994, 'optimizer': 'Adam', 'sparsity': 0.7708444565419275, 'steps_to_train': 89, 'weight_decay': 0.13104830903038356}"}}
exception: None

04:39:01 job_callback for (4, 0, 24) started
04:39:01 DISPATCHER: Trying to submit another job.
04:39:01 job_callback for (4, 0, 24) got condition
04:39:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:39:01 done building a new model for budget 44.444444 based on 10/44 split
Best loss for this budget:-0.354079





04:39:01 HBMASTER: Trying to run another job!
04:39:01 job_callback for (4, 0, 24) finished
04:39:01 start sampling a new configuration.
04:39:01 best_vector: [1, 0.4985632283919739, 0.7395327562225414, 0.9180493196040407, 0.8763073222796447, 0, 0.8482483485324206, 0.6623165075987534, 0.6541067253250472], 0.043606369882600866, 0.3454909411807825, 0.015065605772217102
04:39:01 done sampling a new configuration.
04:39:01 HBMASTER: schedule new run for iteration 4
04:39:01 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
04:39:01 HBMASTER: submitting job (4, 0, 25) to dispatcher
04:39:01 DISPATCHER: trying to submit job (4, 0, 25)
04:39:01 DISPATCHER: trying to notify the job_runner thread.
04:39:01 HBMASTER: job (4, 0, 25) submitted to dispatcher
04:39:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:39:01 DISPATCHER: Trying to submit another job.
04:39:01 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:39:01 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:39:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:39:01 WORKER: start processing job (4, 0, 25)
04:39:01 WORKER: args: ()
04:39:01 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 599, 'last_n_outputs': 40, 'leak_rate': 0.9795123299010102, 'lr': 0.05657370800048408, 'optimizer': 'Adam', 'sparsity': 0.9535796036477809, 'steps_to_train': 70, 'weight_decay': 0.07095981425518257}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:39:31 DISPATCHER: Starting worker discovery
04:39:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:39:31 DISPATCHER: Finished worker discovery
04:40:31 DISPATCHER: Starting worker discovery
04:40:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:40:31 DISPATCHER: Finished worker discovery
04:40:45 WORKER: done with job (4, 0, 25), trying to register it.
04:40:45 WORKER: registered result for job (4, 0, 25) with dispatcher
04:40:45 DISPATCHER: job (4, 0, 25) finished
04:40:45 DISPATCHER: register_result: lock acquired
04:40:45 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:40:45 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 599, 'last_n_outputs': 40, 'leak_rate': 0.9795123299010102, 'lr': 0.05657370800048408, 'optimizer': 'Adam', 'sparsity': 0.9535796036477809, 'steps_to_train': 70, 'weight_decay': 0.07095981425518257}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1907582087705299, 'info': {'data03': 0.1907582087705299, 'config': "{'batch_size': 32, 'hidden_dim': 599, 'last_n_outputs': 40, 'leak_rate': 0.9795123299010102, 'lr': 0.05657370800048408, 'optimizer': 'Adam', 'sparsity': 0.9535796036477809, 'steps_to_train': 70, 'weight_decay': 0.07095981425518257}"}}
exception: None

04:40:45 job_callback for (4, 0, 25) started
04:40:45 DISPATCHER: Trying to submit another job.
04:40:45 job_callback for (4, 0, 25) got condition
04:40:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:40:45 done building a new model for budget 44.444444 based on 10/45 split
Best loss for this budget:-0.354079





04:40:45 HBMASTER: Trying to run another job!
04:40:45 job_callback for (4, 0, 25) finished
04:40:45 start sampling a new configuration.
04:40:45 best_vector: [1, 0.5170713229286066, 0.9559786180693786, 0.8210274535879243, 0.7142608702810659, 0, 0.7711132160782751, 0.9461498836837191, 0.4399848471227665], 0.006232741450842459, 3.247478508341564, 0.020240693909660504
04:40:45 done sampling a new configuration.
04:40:45 HBMASTER: schedule new run for iteration 4
04:40:45 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
04:40:45 HBMASTER: submitting job (4, 0, 26) to dispatcher
04:40:45 DISPATCHER: trying to submit job (4, 0, 26)
04:40:45 DISPATCHER: trying to notify the job_runner thread.
04:40:45 HBMASTER: job (4, 0, 26) submitted to dispatcher
04:40:45 DISPATCHER: Trying to submit another job.
04:40:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:40:45 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:40:45 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:40:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:40:45 WORKER: start processing job (4, 0, 26)
04:40:45 WORKER: args: ()
04:40:45 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 614, 'last_n_outputs': 49, 'leak_rate': 0.9552568633969811, 'lr': 0.026823888832785348, 'optimizer': 'Adam', 'sparsity': 0.935067171858786, 'steps_to_train': 96, 'weight_decay': 0.03736228971638566}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:41:31 DISPATCHER: Starting worker discovery
04:41:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:41:31 DISPATCHER: Finished worker discovery
04:42:31 DISPATCHER: Starting worker discovery
04:42:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:42:31 DISPATCHER: Finished worker discovery
04:42:47 WORKER: done with job (4, 0, 26), trying to register it.
04:42:47 WORKER: registered result for job (4, 0, 26) with dispatcher
04:42:47 DISPATCHER: job (4, 0, 26) finished
04:42:47 DISPATCHER: register_result: lock acquired
04:42:47 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:42:47 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 614, 'last_n_outputs': 49, 'leak_rate': 0.9552568633969811, 'lr': 0.026823888832785348, 'optimizer': 'Adam', 'sparsity': 0.935067171858786, 'steps_to_train': 96, 'weight_decay': 0.03736228971638566}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.018978748681501404, 'info': {'data03': 0.018978748681501404, 'config': "{'batch_size': 32, 'hidden_dim': 614, 'last_n_outputs': 49, 'leak_rate': 0.9552568633969811, 'lr': 0.026823888832785348, 'optimizer': 'Adam', 'sparsity': 0.935067171858786, 'steps_to_train': 96, 'weight_decay': 0.03736228971638566}"}}
exception: None

04:42:47 job_callback for (4, 0, 26) started
04:42:47 DISPATCHER: Trying to submit another job.
04:42:47 job_callback for (4, 0, 26) got condition
04:42:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:42:47 done building a new model for budget 44.444444 based on 10/45 split
Best loss for this budget:-0.354079





04:42:47 HBMASTER: Trying to run another job!
04:42:47 job_callback for (4, 0, 26) finished
04:42:47 ITERATION: Advancing config (4, 0, 2) to next budget 133.333333
04:42:47 ITERATION: Advancing config (4, 0, 3) to next budget 133.333333
04:42:47 ITERATION: Advancing config (4, 0, 7) to next budget 133.333333
04:42:47 ITERATION: Advancing config (4, 0, 10) to next budget 133.333333
04:42:47 ITERATION: Advancing config (4, 0, 11) to next budget 133.333333
04:42:47 ITERATION: Advancing config (4, 0, 12) to next budget 133.333333
04:42:47 ITERATION: Advancing config (4, 0, 21) to next budget 133.333333
04:42:47 ITERATION: Advancing config (4, 0, 22) to next budget 133.333333
04:42:47 ITERATION: Advancing config (4, 0, 25) to next budget 133.333333
04:42:47 HBMASTER: schedule new run for iteration 4
04:42:47 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
04:42:47 HBMASTER: submitting job (4, 0, 2) to dispatcher
04:42:47 DISPATCHER: trying to submit job (4, 0, 2)
04:42:47 DISPATCHER: trying to notify the job_runner thread.
04:42:47 HBMASTER: job (4, 0, 2) submitted to dispatcher
04:42:47 DISPATCHER: Trying to submit another job.
04:42:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:42:47 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:42:47 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:42:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:42:47 WORKER: start processing job (4, 0, 2)
04:42:47 WORKER: args: ()
04:42:47 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 570, 'last_n_outputs': 44, 'leak_rate': 0.9822552565223953, 'lr': 0.002266203951777084, 'optimizer': 'Adam', 'sparsity': 0.9793647030636801, 'steps_to_train': 72, 'weight_decay': 0.019022703293454842}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:43:31 DISPATCHER: Starting worker discovery
04:43:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:43:31 DISPATCHER: Finished worker discovery
04:44:31 DISPATCHER: Starting worker discovery
04:44:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:44:31 DISPATCHER: Finished worker discovery
04:45:31 DISPATCHER: Starting worker discovery
04:45:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:45:31 DISPATCHER: Finished worker discovery
04:45:38 WORKER: done with job (4, 0, 2), trying to register it.
04:45:38 WORKER: registered result for job (4, 0, 2) with dispatcher
04:45:38 DISPATCHER: job (4, 0, 2) finished
04:45:38 DISPATCHER: register_result: lock acquired
04:45:38 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:45:38 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 570, 'last_n_outputs': 44, 'leak_rate': 0.9822552565223953, 'lr': 0.002266203951777084, 'optimizer': 'Adam', 'sparsity': 0.9793647030636801, 'steps_to_train': 72, 'weight_decay': 0.019022703293454842}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.29235766341308606, 'info': {'data03': 0.29235766341308606, 'config': "{'batch_size': 64, 'hidden_dim': 570, 'last_n_outputs': 44, 'leak_rate': 0.9822552565223953, 'lr': 0.002266203951777084, 'optimizer': 'Adam', 'sparsity': 0.9793647030636801, 'steps_to_train': 72, 'weight_decay': 0.019022703293454842}"}}
exception: None

04:45:38 job_callback for (4, 0, 2) started
04:45:38 job_callback for (4, 0, 2) got condition
04:45:38 DISPATCHER: Trying to submit another job.
04:45:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:45:38 HBMASTER: Trying to run another job!
04:45:38 job_callback for (4, 0, 2) finished
04:45:38 HBMASTER: schedule new run for iteration 4
04:45:38 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
04:45:38 HBMASTER: submitting job (4, 0, 3) to dispatcher
04:45:38 DISPATCHER: trying to submit job (4, 0, 3)
04:45:38 DISPATCHER: trying to notify the job_runner thread.
04:45:38 HBMASTER: job (4, 0, 3) submitted to dispatcher
04:45:38 DISPATCHER: Trying to submit another job.
04:45:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:45:38 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:45:38 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:45:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:45:38 WORKER: start processing job (4, 0, 3)
04:45:38 WORKER: args: ()
04:45:38 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 458, 'last_n_outputs': 27, 'leak_rate': 0.9832557589566734, 'lr': 0.013233739269240721, 'optimizer': 'SGD', 'sparsity': 0.7729839804035581, 'steps_to_train': 86, 'weight_decay': 0.058770997411381386}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:46:31 DISPATCHER: Starting worker discovery
04:46:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:46:31 DISPATCHER: Finished worker discovery
04:47:31 DISPATCHER: Starting worker discovery
04:47:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:47:31 DISPATCHER: Finished worker discovery
04:48:31 DISPATCHER: Starting worker discovery
04:48:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:48:31 DISPATCHER: Finished worker discovery
04:48:50 WORKER: done with job (4, 0, 3), trying to register it.
04:48:50 WORKER: registered result for job (4, 0, 3) with dispatcher
04:48:50 DISPATCHER: job (4, 0, 3) finished
04:48:50 DISPATCHER: register_result: lock acquired
04:48:50 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:48:50 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 458, 'last_n_outputs': 27, 'leak_rate': 0.9832557589566734, 'lr': 0.013233739269240721, 'optimizer': 'SGD', 'sparsity': 0.7729839804035581, 'steps_to_train': 86, 'weight_decay': 0.058770997411381386}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.01923284353230272, 'info': {'data03': 0.01923284353230272, 'config': "{'batch_size': 16, 'hidden_dim': 458, 'last_n_outputs': 27, 'leak_rate': 0.9832557589566734, 'lr': 0.013233739269240721, 'optimizer': 'SGD', 'sparsity': 0.7729839804035581, 'steps_to_train': 86, 'weight_decay': 0.058770997411381386}"}}
exception: None

04:48:50 job_callback for (4, 0, 3) started
04:48:50 job_callback for (4, 0, 3) got condition
04:48:50 DISPATCHER: Trying to submit another job.
04:48:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:48:50 done building a new model for budget 133.333333 based on 10/17 split
Best loss for this budget:-0.327684





04:48:50 HBMASTER: Trying to run another job!
04:48:50 job_callback for (4, 0, 3) finished
04:48:50 HBMASTER: schedule new run for iteration 4
04:48:50 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
04:48:50 HBMASTER: submitting job (4, 0, 7) to dispatcher
04:48:50 DISPATCHER: trying to submit job (4, 0, 7)
04:48:50 DISPATCHER: trying to notify the job_runner thread.
04:48:50 HBMASTER: job (4, 0, 7) submitted to dispatcher
04:48:50 DISPATCHER: Trying to submit another job.
04:48:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:48:50 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:48:50 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:48:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:48:50 WORKER: start processing job (4, 0, 7)
04:48:50 WORKER: args: ()
04:48:50 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 679, 'last_n_outputs': 41, 'leak_rate': 0.9341300266634744, 'lr': 0.0019437004766188226, 'optimizer': 'Adam', 'sparsity': 0.9042307667810395, 'steps_to_train': 62, 'weight_decay': 0.19240020223798712}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:49:31 DISPATCHER: Starting worker discovery
04:49:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:49:31 DISPATCHER: Finished worker discovery
04:50:31 DISPATCHER: Starting worker discovery
04:50:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:50:31 DISPATCHER: Finished worker discovery
04:51:31 DISPATCHER: Starting worker discovery
04:51:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:51:31 DISPATCHER: Finished worker discovery
04:51:52 WORKER: done with job (4, 0, 7), trying to register it.
04:51:52 WORKER: registered result for job (4, 0, 7) with dispatcher
04:51:52 DISPATCHER: job (4, 0, 7) finished
04:51:52 DISPATCHER: register_result: lock acquired
04:51:52 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:51:52 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 679, 'last_n_outputs': 41, 'leak_rate': 0.9341300266634744, 'lr': 0.0019437004766188226, 'optimizer': 'Adam', 'sparsity': 0.9042307667810395, 'steps_to_train': 62, 'weight_decay': 0.19240020223798712}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2163498578315208, 'info': {'data03': 0.2163498578315208, 'config': "{'batch_size': 64, 'hidden_dim': 679, 'last_n_outputs': 41, 'leak_rate': 0.9341300266634744, 'lr': 0.0019437004766188226, 'optimizer': 'Adam', 'sparsity': 0.9042307667810395, 'steps_to_train': 62, 'weight_decay': 0.19240020223798712}"}}
exception: None

04:51:52 job_callback for (4, 0, 7) started
04:51:52 DISPATCHER: Trying to submit another job.
04:51:52 job_callback for (4, 0, 7) got condition
04:51:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:51:52 done building a new model for budget 133.333333 based on 10/17 split
Best loss for this budget:-0.327684





04:51:52 HBMASTER: Trying to run another job!
04:51:52 job_callback for (4, 0, 7) finished
04:51:52 HBMASTER: schedule new run for iteration 4
04:51:52 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
04:51:52 HBMASTER: submitting job (4, 0, 10) to dispatcher
04:51:52 DISPATCHER: trying to submit job (4, 0, 10)
04:51:52 DISPATCHER: trying to notify the job_runner thread.
04:51:52 HBMASTER: job (4, 0, 10) submitted to dispatcher
04:51:52 DISPATCHER: Trying to submit another job.
04:51:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:51:52 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:51:52 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:51:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:51:52 WORKER: start processing job (4, 0, 10)
04:51:52 WORKER: args: ()
04:51:52 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 523, 'last_n_outputs': 38, 'leak_rate': 0.8461836826021353, 'lr': 0.001767250969395278, 'optimizer': 'Adam', 'sparsity': 0.924829473062398, 'steps_to_train': 38, 'weight_decay': 0.14523020021429514}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:52:31 DISPATCHER: Starting worker discovery
04:52:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:52:31 DISPATCHER: Finished worker discovery
04:53:31 DISPATCHER: Starting worker discovery
04:53:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:53:31 DISPATCHER: Finished worker discovery
04:54:31 DISPATCHER: Starting worker discovery
04:54:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:54:31 DISPATCHER: Finished worker discovery
04:54:50 WORKER: done with job (4, 0, 10), trying to register it.
04:54:50 WORKER: registered result for job (4, 0, 10) with dispatcher
04:54:50 DISPATCHER: job (4, 0, 10) finished
04:54:50 DISPATCHER: register_result: lock acquired
04:54:50 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:54:50 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 523, 'last_n_outputs': 38, 'leak_rate': 0.8461836826021353, 'lr': 0.001767250969395278, 'optimizer': 'Adam', 'sparsity': 0.924829473062398, 'steps_to_train': 38, 'weight_decay': 0.14523020021429514}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.22320329621900892, 'info': {'data03': 0.22320329621900892, 'config': "{'batch_size': 128, 'hidden_dim': 523, 'last_n_outputs': 38, 'leak_rate': 0.8461836826021353, 'lr': 0.001767250969395278, 'optimizer': 'Adam', 'sparsity': 0.924829473062398, 'steps_to_train': 38, 'weight_decay': 0.14523020021429514}"}}
exception: None

04:54:50 job_callback for (4, 0, 10) started
04:54:50 DISPATCHER: Trying to submit another job.
04:54:50 job_callback for (4, 0, 10) got condition
04:54:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:54:50 done building a new model for budget 133.333333 based on 10/18 split
Best loss for this budget:-0.327684





04:54:50 HBMASTER: Trying to run another job!
04:54:50 job_callback for (4, 0, 10) finished
04:54:50 HBMASTER: schedule new run for iteration 4
04:54:50 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
04:54:50 HBMASTER: submitting job (4, 0, 11) to dispatcher
04:54:50 DISPATCHER: trying to submit job (4, 0, 11)
04:54:50 DISPATCHER: trying to notify the job_runner thread.
04:54:50 HBMASTER: job (4, 0, 11) submitted to dispatcher
04:54:50 DISPATCHER: Trying to submit another job.
04:54:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:54:50 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:54:50 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:54:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:54:50 WORKER: start processing job (4, 0, 11)
04:54:50 WORKER: args: ()
04:54:50 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 539, 'last_n_outputs': 49, 'leak_rate': 0.9679143994494501, 'lr': 0.016754721913258976, 'optimizer': 'Adam', 'sparsity': 0.896232704109273, 'steps_to_train': 80, 'weight_decay': 0.027243081242228996}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:55:31 DISPATCHER: Starting worker discovery
04:55:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:55:31 DISPATCHER: Finished worker discovery
04:56:31 DISPATCHER: Starting worker discovery
04:56:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:56:31 DISPATCHER: Finished worker discovery
04:57:31 DISPATCHER: Starting worker discovery
04:57:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:57:31 DISPATCHER: Finished worker discovery
04:58:14 WORKER: done with job (4, 0, 11), trying to register it.
04:58:14 WORKER: registered result for job (4, 0, 11) with dispatcher
04:58:14 DISPATCHER: job (4, 0, 11) finished
04:58:14 DISPATCHER: register_result: lock acquired
04:58:14 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:58:14 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 539, 'last_n_outputs': 49, 'leak_rate': 0.9679143994494501, 'lr': 0.016754721913258976, 'optimizer': 'Adam', 'sparsity': 0.896232704109273, 'steps_to_train': 80, 'weight_decay': 0.027243081242228996}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.12419802215872797, 'info': {'data03': 0.12419802215872797, 'config': "{'batch_size': 128, 'hidden_dim': 539, 'last_n_outputs': 49, 'leak_rate': 0.9679143994494501, 'lr': 0.016754721913258976, 'optimizer': 'Adam', 'sparsity': 0.896232704109273, 'steps_to_train': 80, 'weight_decay': 0.027243081242228996}"}}
exception: None

04:58:14 job_callback for (4, 0, 11) started
04:58:14 DISPATCHER: Trying to submit another job.
04:58:14 job_callback for (4, 0, 11) got condition
04:58:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:58:14 done building a new model for budget 133.333333 based on 10/19 split
Best loss for this budget:-0.327684





04:58:14 HBMASTER: Trying to run another job!
04:58:14 job_callback for (4, 0, 11) finished
04:58:14 HBMASTER: schedule new run for iteration 4
04:58:14 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
04:58:14 HBMASTER: submitting job (4, 0, 12) to dispatcher
04:58:14 DISPATCHER: trying to submit job (4, 0, 12)
04:58:14 DISPATCHER: trying to notify the job_runner thread.
04:58:14 HBMASTER: job (4, 0, 12) submitted to dispatcher
04:58:14 DISPATCHER: Trying to submit another job.
04:58:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:58:14 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:58:14 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:58:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:58:14 WORKER: start processing job (4, 0, 12)
04:58:14 WORKER: args: ()
04:58:14 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 508, 'last_n_outputs': 48, 'leak_rate': 0.7653619433656009, 'lr': 0.003017744610869008, 'optimizer': 'Adam', 'sparsity': 0.824822525195303, 'steps_to_train': 47, 'weight_decay': 0.11668831830831446}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:58:31 DISPATCHER: Starting worker discovery
04:58:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:58:31 DISPATCHER: Finished worker discovery
04:59:31 DISPATCHER: Starting worker discovery
04:59:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:59:31 DISPATCHER: Finished worker discovery
05:00:31 DISPATCHER: Starting worker discovery
05:00:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:00:31 DISPATCHER: Finished worker discovery
05:01:13 WORKER: done with job (4, 0, 12), trying to register it.
05:01:13 WORKER: registered result for job (4, 0, 12) with dispatcher
05:01:13 DISPATCHER: job (4, 0, 12) finished
05:01:13 DISPATCHER: register_result: lock acquired
05:01:13 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:01:13 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 508, 'last_n_outputs': 48, 'leak_rate': 0.7653619433656009, 'lr': 0.003017744610869008, 'optimizer': 'Adam', 'sparsity': 0.824822525195303, 'steps_to_train': 47, 'weight_decay': 0.11668831830831446}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1451171046442747, 'info': {'data03': 0.1451171046442747, 'config': "{'batch_size': 16, 'hidden_dim': 508, 'last_n_outputs': 48, 'leak_rate': 0.7653619433656009, 'lr': 0.003017744610869008, 'optimizer': 'Adam', 'sparsity': 0.824822525195303, 'steps_to_train': 47, 'weight_decay': 0.11668831830831446}"}}
exception: None

05:01:13 job_callback for (4, 0, 12) started
05:01:13 job_callback for (4, 0, 12) got condition
05:01:13 DISPATCHER: Trying to submit another job.
05:01:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:01:13 done building a new model for budget 133.333333 based on 10/20 split
Best loss for this budget:-0.327684





05:01:13 HBMASTER: Trying to run another job!
05:01:13 job_callback for (4, 0, 12) finished
05:01:13 HBMASTER: schedule new run for iteration 4
05:01:13 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
05:01:13 HBMASTER: submitting job (4, 0, 21) to dispatcher
05:01:13 DISPATCHER: trying to submit job (4, 0, 21)
05:01:13 DISPATCHER: trying to notify the job_runner thread.
05:01:13 HBMASTER: job (4, 0, 21) submitted to dispatcher
05:01:13 DISPATCHER: Trying to submit another job.
05:01:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:01:13 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:01:13 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:01:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:01:13 WORKER: start processing job (4, 0, 21)
05:01:13 WORKER: args: ()
05:01:13 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 642, 'last_n_outputs': 47, 'leak_rate': 0.9529876228837879, 'lr': 0.006457478030975271, 'optimizer': 'Adam', 'sparsity': 0.9341272808903853, 'steps_to_train': 81, 'weight_decay': 0.02602448204233227}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:01:31 DISPATCHER: Starting worker discovery
05:01:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:01:31 DISPATCHER: Finished worker discovery
05:02:31 DISPATCHER: Starting worker discovery
05:02:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:02:31 DISPATCHER: Finished worker discovery
05:03:31 DISPATCHER: Starting worker discovery
05:03:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:03:31 DISPATCHER: Finished worker discovery
05:04:31 DISPATCHER: Starting worker discovery
05:04:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:04:31 DISPATCHER: Finished worker discovery
05:04:46 WORKER: done with job (4, 0, 21), trying to register it.
05:04:46 WORKER: registered result for job (4, 0, 21) with dispatcher
05:04:46 DISPATCHER: job (4, 0, 21) finished
05:04:46 DISPATCHER: register_result: lock acquired
05:04:46 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:04:46 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 642, 'last_n_outputs': 47, 'leak_rate': 0.9529876228837879, 'lr': 0.006457478030975271, 'optimizer': 'Adam', 'sparsity': 0.9341272808903853, 'steps_to_train': 81, 'weight_decay': 0.02602448204233227}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2441750657095314, 'info': {'data03': 0.2441750657095314, 'config': "{'batch_size': 128, 'hidden_dim': 642, 'last_n_outputs': 47, 'leak_rate': 0.9529876228837879, 'lr': 0.006457478030975271, 'optimizer': 'Adam', 'sparsity': 0.9341272808903853, 'steps_to_train': 81, 'weight_decay': 0.02602448204233227}"}}
exception: None

05:04:46 job_callback for (4, 0, 21) started
05:04:46 DISPATCHER: Trying to submit another job.
05:04:46 job_callback for (4, 0, 21) got condition
05:04:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:04:46 done building a new model for budget 133.333333 based on 10/21 split
Best loss for this budget:-0.327684





05:04:46 HBMASTER: Trying to run another job!
05:04:46 job_callback for (4, 0, 21) finished
05:04:46 HBMASTER: schedule new run for iteration 4
05:04:46 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
05:04:46 HBMASTER: submitting job (4, 0, 22) to dispatcher
05:04:46 DISPATCHER: trying to submit job (4, 0, 22)
05:04:46 DISPATCHER: trying to notify the job_runner thread.
05:04:46 HBMASTER: job (4, 0, 22) submitted to dispatcher
05:04:46 DISPATCHER: Trying to submit another job.
05:04:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:04:46 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:04:46 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:04:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:04:46 WORKER: start processing job (4, 0, 22)
05:04:46 WORKER: args: ()
05:04:46 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 666, 'last_n_outputs': 38, 'leak_rate': 0.829430854835769, 'lr': 0.007107113112412662, 'optimizer': 'Adam', 'sparsity': 0.8219773318855209, 'steps_to_train': 81, 'weight_decay': 0.061870231230632455}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:05:31 DISPATCHER: Starting worker discovery
05:05:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:05:31 DISPATCHER: Finished worker discovery
05:06:31 DISPATCHER: Starting worker discovery
05:06:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:06:31 DISPATCHER: Finished worker discovery
05:07:31 DISPATCHER: Starting worker discovery
05:07:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:07:31 DISPATCHER: Finished worker discovery
05:08:09 WORKER: done with job (4, 0, 22), trying to register it.
05:08:09 WORKER: registered result for job (4, 0, 22) with dispatcher
05:08:09 DISPATCHER: job (4, 0, 22) finished
05:08:09 DISPATCHER: register_result: lock acquired
05:08:09 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:08:09 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 666, 'last_n_outputs': 38, 'leak_rate': 0.829430854835769, 'lr': 0.007107113112412662, 'optimizer': 'Adam', 'sparsity': 0.8219773318855209, 'steps_to_train': 81, 'weight_decay': 0.061870231230632455}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2601077042941865, 'info': {'data03': 0.2601077042941865, 'config': "{'batch_size': 32, 'hidden_dim': 666, 'last_n_outputs': 38, 'leak_rate': 0.829430854835769, 'lr': 0.007107113112412662, 'optimizer': 'Adam', 'sparsity': 0.8219773318855209, 'steps_to_train': 81, 'weight_decay': 0.061870231230632455}"}}
exception: None

05:08:09 job_callback for (4, 0, 22) started
05:08:09 job_callback for (4, 0, 22) got condition
05:08:09 DISPATCHER: Trying to submit another job.
05:08:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:08:09 done building a new model for budget 133.333333 based on 10/22 split
Best loss for this budget:-0.327684





05:08:09 HBMASTER: Trying to run another job!
05:08:09 job_callback for (4, 0, 22) finished
05:08:09 HBMASTER: schedule new run for iteration 4
05:08:09 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
05:08:09 HBMASTER: submitting job (4, 0, 25) to dispatcher
05:08:09 DISPATCHER: trying to submit job (4, 0, 25)
05:08:09 DISPATCHER: trying to notify the job_runner thread.
05:08:09 HBMASTER: job (4, 0, 25) submitted to dispatcher
05:08:09 DISPATCHER: Trying to submit another job.
05:08:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:08:09 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:08:09 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:08:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:08:09 WORKER: start processing job (4, 0, 25)
05:08:09 WORKER: args: ()
05:08:09 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 599, 'last_n_outputs': 40, 'leak_rate': 0.9795123299010102, 'lr': 0.05657370800048408, 'optimizer': 'Adam', 'sparsity': 0.9535796036477809, 'steps_to_train': 70, 'weight_decay': 0.07095981425518257}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:08:31 DISPATCHER: Starting worker discovery
05:08:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:08:31 DISPATCHER: Finished worker discovery
05:09:31 DISPATCHER: Starting worker discovery
05:09:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:09:31 DISPATCHER: Finished worker discovery
05:10:31 DISPATCHER: Starting worker discovery
05:10:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:10:31 DISPATCHER: Finished worker discovery
05:11:16 WORKER: done with job (4, 0, 25), trying to register it.
05:11:16 WORKER: registered result for job (4, 0, 25) with dispatcher
05:11:16 DISPATCHER: job (4, 0, 25) finished
05:11:16 DISPATCHER: register_result: lock acquired
05:11:16 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:11:16 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 599, 'last_n_outputs': 40, 'leak_rate': 0.9795123299010102, 'lr': 0.05657370800048408, 'optimizer': 'Adam', 'sparsity': 0.9535796036477809, 'steps_to_train': 70, 'weight_decay': 0.07095981425518257}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.08513609395831893, 'info': {'data03': 0.08513609395831893, 'config': "{'batch_size': 32, 'hidden_dim': 599, 'last_n_outputs': 40, 'leak_rate': 0.9795123299010102, 'lr': 0.05657370800048408, 'optimizer': 'Adam', 'sparsity': 0.9535796036477809, 'steps_to_train': 70, 'weight_decay': 0.07095981425518257}"}}
exception: None

05:11:16 job_callback for (4, 0, 25) started
05:11:16 job_callback for (4, 0, 25) got condition
05:11:16 DISPATCHER: Trying to submit another job.
05:11:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:11:16 done building a new model for budget 133.333333 based on 10/22 split
Best loss for this budget:-0.327684





05:11:16 HBMASTER: Trying to run another job!
05:11:16 job_callback for (4, 0, 25) finished
05:11:16 ITERATION: Advancing config (4, 0, 2) to next budget 400.000000
05:11:16 ITERATION: Advancing config (4, 0, 21) to next budget 400.000000
05:11:16 ITERATION: Advancing config (4, 0, 22) to next budget 400.000000
05:11:16 HBMASTER: schedule new run for iteration 4
05:11:16 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
05:11:16 HBMASTER: submitting job (4, 0, 2) to dispatcher
05:11:16 DISPATCHER: trying to submit job (4, 0, 2)
05:11:16 DISPATCHER: trying to notify the job_runner thread.
05:11:16 HBMASTER: job (4, 0, 2) submitted to dispatcher
05:11:16 DISPATCHER: Trying to submit another job.
05:11:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:11:16 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:11:16 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:11:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:11:16 WORKER: start processing job (4, 0, 2)
05:11:16 WORKER: args: ()
05:11:16 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 570, 'last_n_outputs': 44, 'leak_rate': 0.9822552565223953, 'lr': 0.002266203951777084, 'optimizer': 'Adam', 'sparsity': 0.9793647030636801, 'steps_to_train': 72, 'weight_decay': 0.019022703293454842}, 'budget': 400.0, 'working_directory': '.'}
05:11:31 DISPATCHER: Starting worker discovery
05:11:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:11:31 DISPATCHER: Finished worker discovery
05:12:31 DISPATCHER: Starting worker discovery
05:12:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:12:31 DISPATCHER: Finished worker discovery
05:13:31 DISPATCHER: Starting worker discovery
05:13:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:13:31 DISPATCHER: Finished worker discovery
05:14:31 DISPATCHER: Starting worker discovery
05:14:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:14:31 DISPATCHER: Finished worker discovery
05:15:31 DISPATCHER: Starting worker discovery
05:15:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:15:31 DISPATCHER: Finished worker discovery
05:16:31 DISPATCHER: Starting worker discovery
05:16:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:16:31 DISPATCHER: Finished worker discovery
05:17:31 DISPATCHER: Starting worker discovery
05:17:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:17:31 DISPATCHER: Finished worker discovery
05:18:31 DISPATCHER: Starting worker discovery
05:18:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:18:31 DISPATCHER: Finished worker discovery
05:18:58 WORKER: done with job (4, 0, 2), trying to register it.
05:18:58 WORKER: registered result for job (4, 0, 2) with dispatcher
05:18:58 DISPATCHER: job (4, 0, 2) finished
05:18:58 DISPATCHER: register_result: lock acquired
05:18:58 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:18:58 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 570, 'last_n_outputs': 44, 'leak_rate': 0.9822552565223953, 'lr': 0.002266203951777084, 'optimizer': 'Adam', 'sparsity': 0.9793647030636801, 'steps_to_train': 72, 'weight_decay': 0.019022703293454842}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3400203855289117, 'info': {'data03': 0.3400203855289117, 'config': "{'batch_size': 64, 'hidden_dim': 570, 'last_n_outputs': 44, 'leak_rate': 0.9822552565223953, 'lr': 0.002266203951777084, 'optimizer': 'Adam', 'sparsity': 0.9793647030636801, 'steps_to_train': 72, 'weight_decay': 0.019022703293454842}"}}
exception: None

05:18:58 job_callback for (4, 0, 2) started
05:18:58 DISPATCHER: Trying to submit another job.
05:18:58 job_callback for (4, 0, 2) got condition
05:18:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:18:58 HBMASTER: Trying to run another job!
05:18:58 job_callback for (4, 0, 2) finished
05:18:58 HBMASTER: schedule new run for iteration 4
05:18:58 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
05:18:58 HBMASTER: submitting job (4, 0, 21) to dispatcher
05:18:58 DISPATCHER: trying to submit job (4, 0, 21)
05:18:58 DISPATCHER: trying to notify the job_runner thread.
05:18:58 HBMASTER: job (4, 0, 21) submitted to dispatcher
05:18:58 DISPATCHER: Trying to submit another job.
05:18:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:18:58 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:18:58 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:18:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:18:58 WORKER: start processing job (4, 0, 21)
05:18:58 WORKER: args: ()
05:18:58 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 642, 'last_n_outputs': 47, 'leak_rate': 0.9529876228837879, 'lr': 0.006457478030975271, 'optimizer': 'Adam', 'sparsity': 0.9341272808903853, 'steps_to_train': 81, 'weight_decay': 0.02602448204233227}, 'budget': 400.0, 'working_directory': '.'}
05:19:31 DISPATCHER: Starting worker discovery
05:19:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:19:31 DISPATCHER: Finished worker discovery
05:20:31 DISPATCHER: Starting worker discovery
05:20:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:20:31 DISPATCHER: Finished worker discovery
05:21:31 DISPATCHER: Starting worker discovery
05:21:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:21:31 DISPATCHER: Finished worker discovery
05:22:31 DISPATCHER: Starting worker discovery
05:22:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:22:31 DISPATCHER: Finished worker discovery
05:23:31 DISPATCHER: Starting worker discovery
05:23:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:23:31 DISPATCHER: Finished worker discovery
05:24:31 DISPATCHER: Starting worker discovery
05:24:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:24:31 DISPATCHER: Finished worker discovery
05:25:31 DISPATCHER: Starting worker discovery
05:25:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:25:31 DISPATCHER: Finished worker discovery
05:26:20 WORKER: done with job (4, 0, 21), trying to register it.
05:26:20 WORKER: registered result for job (4, 0, 21) with dispatcher
05:26:20 DISPATCHER: job (4, 0, 21) finished
05:26:20 DISPATCHER: register_result: lock acquired
05:26:20 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:26:20 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 642, 'last_n_outputs': 47, 'leak_rate': 0.9529876228837879, 'lr': 0.006457478030975271, 'optimizer': 'Adam', 'sparsity': 0.9341272808903853, 'steps_to_train': 81, 'weight_decay': 0.02602448204233227}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3250625419280089, 'info': {'data03': 0.3250625419280089, 'config': "{'batch_size': 128, 'hidden_dim': 642, 'last_n_outputs': 47, 'leak_rate': 0.9529876228837879, 'lr': 0.006457478030975271, 'optimizer': 'Adam', 'sparsity': 0.9341272808903853, 'steps_to_train': 81, 'weight_decay': 0.02602448204233227}"}}
exception: None

05:26:20 job_callback for (4, 0, 21) started
05:26:20 job_callback for (4, 0, 21) got condition
05:26:20 DISPATCHER: Trying to submit another job.
05:26:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:26:20 HBMASTER: Trying to run another job!
05:26:20 job_callback for (4, 0, 21) finished
05:26:20 HBMASTER: schedule new run for iteration 4
05:26:20 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
05:26:20 HBMASTER: submitting job (4, 0, 22) to dispatcher
05:26:20 DISPATCHER: trying to submit job (4, 0, 22)
05:26:20 DISPATCHER: trying to notify the job_runner thread.
05:26:20 HBMASTER: job (4, 0, 22) submitted to dispatcher
05:26:20 DISPATCHER: Trying to submit another job.
05:26:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:26:20 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:26:20 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:26:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:26:20 WORKER: start processing job (4, 0, 22)
05:26:20 WORKER: args: ()
05:26:20 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 666, 'last_n_outputs': 38, 'leak_rate': 0.829430854835769, 'lr': 0.007107113112412662, 'optimizer': 'Adam', 'sparsity': 0.8219773318855209, 'steps_to_train': 81, 'weight_decay': 0.061870231230632455}, 'budget': 400.0, 'working_directory': '.'}
05:26:31 DISPATCHER: Starting worker discovery
05:26:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:26:31 DISPATCHER: Finished worker discovery
05:27:31 DISPATCHER: Starting worker discovery
05:27:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:27:31 DISPATCHER: Finished worker discovery
05:28:31 DISPATCHER: Starting worker discovery
05:28:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:28:31 DISPATCHER: Finished worker discovery
05:29:31 DISPATCHER: Starting worker discovery
05:29:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:29:31 DISPATCHER: Finished worker discovery
05:30:31 DISPATCHER: Starting worker discovery
05:30:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:30:31 DISPATCHER: Finished worker discovery
05:31:31 DISPATCHER: Starting worker discovery
05:31:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:31:31 DISPATCHER: Finished worker discovery
05:32:31 DISPATCHER: Starting worker discovery
05:32:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:32:31 DISPATCHER: Finished worker discovery
05:33:31 DISPATCHER: Starting worker discovery
05:33:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:33:31 DISPATCHER: Finished worker discovery
05:34:17 WORKER: done with job (4, 0, 22), trying to register it.
05:34:17 WORKER: registered result for job (4, 0, 22) with dispatcher
05:34:17 DISPATCHER: job (4, 0, 22) finished
05:34:17 DISPATCHER: register_result: lock acquired
05:34:17 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:34:17 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 666, 'last_n_outputs': 38, 'leak_rate': 0.829430854835769, 'lr': 0.007107113112412662, 'optimizer': 'Adam', 'sparsity': 0.8219773318855209, 'steps_to_train': 81, 'weight_decay': 0.061870231230632455}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.20826110513165275, 'info': {'data03': 0.20826110513165275, 'config': "{'batch_size': 32, 'hidden_dim': 666, 'last_n_outputs': 38, 'leak_rate': 0.829430854835769, 'lr': 0.007107113112412662, 'optimizer': 'Adam', 'sparsity': 0.8219773318855209, 'steps_to_train': 81, 'weight_decay': 0.061870231230632455}"}}
exception: None

05:34:17 job_callback for (4, 0, 22) started
05:34:17 job_callback for (4, 0, 22) got condition
05:34:17 DISPATCHER: Trying to submit another job.
05:34:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:34:17 HBMASTER: Trying to run another job!
05:34:17 job_callback for (4, 0, 22) finished
05:34:17 ITERATION: Advancing config (4, 0, 2) to next budget 1200.000000
05:34:17 HBMASTER: schedule new run for iteration 4
05:34:17 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
05:34:17 HBMASTER: submitting job (4, 0, 2) to dispatcher
05:34:17 DISPATCHER: trying to submit job (4, 0, 2)
05:34:17 DISPATCHER: trying to notify the job_runner thread.
05:34:17 HBMASTER: job (4, 0, 2) submitted to dispatcher
05:34:17 DISPATCHER: Trying to submit another job.
05:34:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:34:17 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:34:17 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:34:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:34:17 WORKER: start processing job (4, 0, 2)
05:34:17 WORKER: args: ()
05:34:17 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 570, 'last_n_outputs': 44, 'leak_rate': 0.9822552565223953, 'lr': 0.002266203951777084, 'optimizer': 'Adam', 'sparsity': 0.9793647030636801, 'steps_to_train': 72, 'weight_decay': 0.019022703293454842}, 'budget': 1200.0, 'working_directory': '.'}
05:34:31 DISPATCHER: Starting worker discovery
05:34:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:34:31 DISPATCHER: Finished worker discovery
05:35:31 DISPATCHER: Starting worker discovery
05:35:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:35:31 DISPATCHER: Finished worker discovery
05:36:31 DISPATCHER: Starting worker discovery
05:36:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:36:31 DISPATCHER: Finished worker discovery
05:37:31 DISPATCHER: Starting worker discovery
05:37:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:37:31 DISPATCHER: Finished worker discovery
05:38:31 DISPATCHER: Starting worker discovery
05:38:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:38:31 DISPATCHER: Finished worker discovery
05:39:31 DISPATCHER: Starting worker discovery
05:39:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:39:31 DISPATCHER: Finished worker discovery
05:40:31 DISPATCHER: Starting worker discovery
05:40:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:40:31 DISPATCHER: Finished worker discovery
05:41:31 DISPATCHER: Starting worker discovery
05:41:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:41:31 DISPATCHER: Finished worker discovery
05:42:31 DISPATCHER: Starting worker discovery
05:42:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:42:31 DISPATCHER: Finished worker discovery
05:43:31 DISPATCHER: Starting worker discovery
05:43:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:43:31 DISPATCHER: Finished worker discovery
05:44:31 DISPATCHER: Starting worker discovery
05:44:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:44:31 DISPATCHER: Finished worker discovery
05:45:31 DISPATCHER: Starting worker discovery
05:45:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:45:31 DISPATCHER: Finished worker discovery
05:46:31 DISPATCHER: Starting worker discovery
05:46:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:46:31 DISPATCHER: Finished worker discovery
05:47:31 DISPATCHER: Starting worker discovery
05:47:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:47:31 DISPATCHER: Finished worker discovery
05:48:31 DISPATCHER: Starting worker discovery
05:48:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:48:31 DISPATCHER: Finished worker discovery
05:49:31 DISPATCHER: Starting worker discovery
05:49:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:49:31 DISPATCHER: Finished worker discovery
05:50:31 DISPATCHER: Starting worker discovery
05:50:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:50:31 DISPATCHER: Finished worker discovery
05:51:31 DISPATCHER: Starting worker discovery
05:51:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:51:31 DISPATCHER: Finished worker discovery
05:52:31 DISPATCHER: Starting worker discovery
05:52:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:52:31 DISPATCHER: Finished worker discovery
05:53:31 DISPATCHER: Starting worker discovery
05:53:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:53:31 DISPATCHER: Finished worker discovery
05:54:31 DISPATCHER: Starting worker discovery
05:54:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:54:31 DISPATCHER: Finished worker discovery
05:55:11 WORKER: done with job (4, 0, 2), trying to register it.
05:55:11 WORKER: registered result for job (4, 0, 2) with dispatcher
05:55:11 DISPATCHER: job (4, 0, 2) finished
05:55:11 DISPATCHER: register_result: lock acquired
05:55:11 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:55:11 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 570, 'last_n_outputs': 44, 'leak_rate': 0.9822552565223953, 'lr': 0.002266203951777084, 'optimizer': 'Adam', 'sparsity': 0.9793647030636801, 'steps_to_train': 72, 'weight_decay': 0.019022703293454842}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.2951040104278869, 'info': {'data03': 0.2951040104278869, 'config': "{'batch_size': 64, 'hidden_dim': 570, 'last_n_outputs': 44, 'leak_rate': 0.9822552565223953, 'lr': 0.002266203951777084, 'optimizer': 'Adam', 'sparsity': 0.9793647030636801, 'steps_to_train': 72, 'weight_decay': 0.019022703293454842}"}}
exception: None

05:55:11 job_callback for (4, 0, 2) started
05:55:11 job_callback for (4, 0, 2) got condition
05:55:11 DISPATCHER: Trying to submit another job.
05:55:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:55:11 Only 9 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
05:55:11 HBMASTER: Trying to run another job!
05:55:11 job_callback for (4, 0, 2) finished
05:55:11 start sampling a new configuration.
05:55:11 best_vector: [3, 0.38436066482804704, 0.529557611998565, 0.9740345274849708, 0.1720373877389637, 0, 0.49082218276834066, 0.7172877057340203, 0.26250517056258804], 3.0626636003832923e-31, 0.03265131697372346, -0.00010861362013487432
05:55:11 done sampling a new configuration.
05:55:11 HBMASTER: schedule new run for iteration 5
05:55:11 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
05:55:11 HBMASTER: submitting job (5, 0, 0) to dispatcher
05:55:11 DISPATCHER: trying to submit job (5, 0, 0)
05:55:11 DISPATCHER: trying to notify the job_runner thread.
05:55:11 HBMASTER: job (5, 0, 0) submitted to dispatcher
05:55:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:55:11 DISPATCHER: Trying to submit another job.
05:55:11 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:55:11 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:55:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:55:11 WORKER: start processing job (5, 0, 0)
05:55:11 WORKER: args: ()
05:55:11 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 507, 'last_n_outputs': 31, 'leak_rate': 0.9935086318712427, 'lr': 0.0022083849331606797, 'optimizer': 'Adam', 'sparsity': 0.8677973238644018, 'steps_to_train': 75, 'weight_decay': 0.021954679468330504}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:55:31 DISPATCHER: Starting worker discovery
05:55:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:55:31 DISPATCHER: Finished worker discovery
05:56:31 DISPATCHER: Starting worker discovery
05:56:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:56:31 DISPATCHER: Finished worker discovery
05:57:31 DISPATCHER: Starting worker discovery
05:57:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:57:31 DISPATCHER: Finished worker discovery
05:58:31 DISPATCHER: Starting worker discovery
05:58:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:58:31 DISPATCHER: Finished worker discovery
05:58:38 WORKER: done with job (5, 0, 0), trying to register it.
05:58:38 WORKER: registered result for job (5, 0, 0) with dispatcher
05:58:38 DISPATCHER: job (5, 0, 0) finished
05:58:38 DISPATCHER: register_result: lock acquired
05:58:38 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:58:38 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 507, 'last_n_outputs': 31, 'leak_rate': 0.9935086318712427, 'lr': 0.0022083849331606797, 'optimizer': 'Adam', 'sparsity': 0.8677973238644018, 'steps_to_train': 75, 'weight_decay': 0.021954679468330504}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2373894549582339, 'info': {'data03': 0.2373894549582339, 'config': "{'batch_size': 128, 'hidden_dim': 507, 'last_n_outputs': 31, 'leak_rate': 0.9935086318712427, 'lr': 0.0022083849331606797, 'optimizer': 'Adam', 'sparsity': 0.8677973238644018, 'steps_to_train': 75, 'weight_decay': 0.021954679468330504}"}}
exception: None

05:58:38 job_callback for (5, 0, 0) started
05:58:38 job_callback for (5, 0, 0) got condition
05:58:38 DISPATCHER: Trying to submit another job.
05:58:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:58:38 done building a new model for budget 133.333333 based on 10/23 split
Best loss for this budget:-0.327684





05:58:38 HBMASTER: Trying to run another job!
05:58:38 job_callback for (5, 0, 0) finished
05:58:38 start sampling a new configuration.
05:58:38 best_vector: [3, 0.4857279944918147, 0.8459074799549451, 0.8775753829324539, 0.5300540324125104, 1, 0.873791787508831, 0.5718263693601691, 0.19284176461376717], 8.065192680714384e-33, 1.2398959821396653, -0.010094031416175639
05:58:38 done sampling a new configuration.
05:58:38 HBMASTER: schedule new run for iteration 5
05:58:38 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
05:58:38 HBMASTER: submitting job (5, 0, 1) to dispatcher
05:58:38 DISPATCHER: trying to submit job (5, 0, 1)
05:58:38 DISPATCHER: trying to notify the job_runner thread.
05:58:38 HBMASTER: job (5, 0, 1) submitted to dispatcher
05:58:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:58:38 DISPATCHER: Trying to submit another job.
05:58:38 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:58:38 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:58:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:58:38 WORKER: start processing job (5, 0, 1)
05:58:38 WORKER: args: ()
05:58:38 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 589, 'last_n_outputs': 44, 'leak_rate': 0.9693938457331135, 'lr': 0.011484393503360764, 'optimizer': 'SGD', 'sparsity': 0.9597100290021194, 'steps_to_train': 62, 'weight_decay': 0.017819393576008837}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:59:31 DISPATCHER: Starting worker discovery
05:59:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:59:31 DISPATCHER: Finished worker discovery
06:00:31 DISPATCHER: Starting worker discovery
06:00:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:00:31 DISPATCHER: Finished worker discovery
06:01:31 DISPATCHER: Starting worker discovery
06:01:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:01:31 DISPATCHER: Finished worker discovery
06:01:36 WORKER: done with job (5, 0, 1), trying to register it.
06:01:36 WORKER: registered result for job (5, 0, 1) with dispatcher
06:01:36 DISPATCHER: job (5, 0, 1) finished
06:01:36 DISPATCHER: register_result: lock acquired
06:01:36 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
06:01:36 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 589, 'last_n_outputs': 44, 'leak_rate': 0.9693938457331135, 'lr': 0.011484393503360764, 'optimizer': 'SGD', 'sparsity': 0.9597100290021194, 'steps_to_train': 62, 'weight_decay': 0.017819393576008837}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.00986502513943532, 'info': {'data03': 0.00986502513943532, 'config': "{'batch_size': 128, 'hidden_dim': 589, 'last_n_outputs': 44, 'leak_rate': 0.9693938457331135, 'lr': 0.011484393503360764, 'optimizer': 'SGD', 'sparsity': 0.9597100290021194, 'steps_to_train': 62, 'weight_decay': 0.017819393576008837}"}}
exception: None

06:01:36 job_callback for (5, 0, 1) started
06:01:36 DISPATCHER: Trying to submit another job.
06:01:36 job_callback for (5, 0, 1) got condition
06:01:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:01:36 done building a new model for budget 133.333333 based on 10/24 split
Best loss for this budget:-0.327684





06:01:36 HBMASTER: Trying to run another job!
06:01:36 job_callback for (5, 0, 1) finished
06:01:36 start sampling a new configuration.
06:01:37 best_vector: [0, 0.5188349873242281, 0.6175354872165368, 0.4605526884476475, 0.43245820533793145, 0, 0.09976540801483447, 0.6637193565715144, 0.406292595326325], 6.132377833945287e-33, 1.6306888242674482, -0.006591612082790258
06:01:37 done sampling a new configuration.
06:01:37 HBMASTER: schedule new run for iteration 5
06:01:37 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
06:01:37 HBMASTER: submitting job (5, 0, 2) to dispatcher
06:01:37 DISPATCHER: trying to submit job (5, 0, 2)
06:01:37 DISPATCHER: trying to notify the job_runner thread.
06:01:37 HBMASTER: job (5, 0, 2) submitted to dispatcher
06:01:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:01:37 DISPATCHER: Trying to submit another job.
06:01:37 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
06:01:37 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
06:01:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:01:37 WORKER: start processing job (5, 0, 2)
06:01:37 WORKER: args: ()
06:01:37 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 615, 'last_n_outputs': 35, 'leak_rate': 0.8651381721119119, 'lr': 0.00732683498851528, 'optimizer': 'Adam', 'sparsity': 0.7739436979235603, 'steps_to_train': 70, 'weight_decay': 0.033775271872040276}, 'budget': 133.33333333333331, 'working_directory': '.'}
06:02:31 DISPATCHER: Starting worker discovery
06:02:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:02:31 DISPATCHER: Finished worker discovery
06:03:31 DISPATCHER: Starting worker discovery
06:03:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:03:31 DISPATCHER: Finished worker discovery
06:04:31 DISPATCHER: Starting worker discovery
06:04:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:04:31 DISPATCHER: Finished worker discovery
06:04:49 WORKER: done with job (5, 0, 2), trying to register it.
06:04:49 WORKER: registered result for job (5, 0, 2) with dispatcher
06:04:49 DISPATCHER: job (5, 0, 2) finished
06:04:49 DISPATCHER: register_result: lock acquired
06:04:49 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
06:04:49 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 615, 'last_n_outputs': 35, 'leak_rate': 0.8651381721119119, 'lr': 0.00732683498851528, 'optimizer': 'Adam', 'sparsity': 0.7739436979235603, 'steps_to_train': 70, 'weight_decay': 0.033775271872040276}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.09023648540032417, 'info': {'data03': 0.09023648540032417, 'config': "{'batch_size': 16, 'hidden_dim': 615, 'last_n_outputs': 35, 'leak_rate': 0.8651381721119119, 'lr': 0.00732683498851528, 'optimizer': 'Adam', 'sparsity': 0.7739436979235603, 'steps_to_train': 70, 'weight_decay': 0.033775271872040276}"}}
exception: None

06:04:49 job_callback for (5, 0, 2) started
06:04:49 DISPATCHER: Trying to submit another job.
06:04:49 job_callback for (5, 0, 2) got condition
06:04:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:04:49 done building a new model for budget 133.333333 based on 10/25 split
Best loss for this budget:-0.327684





06:04:49 HBMASTER: Trying to run another job!
06:04:49 job_callback for (5, 0, 2) finished
06:04:49 start sampling a new configuration.
06:04:49 best_vector: [0, 0.6828048263544091, 0.6832064026584558, 0.5225591094234303, 0.28803874317480754, 0, 0.012990287639552067, 0.9753270785274273, 0.7233643911189933], 2.550876148403288e-32, 0.3920221687853981, -0.018457227216930508
06:04:49 done sampling a new configuration.
06:04:49 HBMASTER: schedule new run for iteration 5
06:04:49 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
06:04:49 HBMASTER: submitting job (5, 0, 3) to dispatcher
06:04:49 DISPATCHER: trying to submit job (5, 0, 3)
06:04:49 DISPATCHER: trying to notify the job_runner thread.
06:04:49 HBMASTER: job (5, 0, 3) submitted to dispatcher
06:04:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:04:49 DISPATCHER: Trying to submit another job.
06:04:49 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
06:04:49 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
06:04:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:04:49 WORKER: start processing job (5, 0, 3)
06:04:49 WORKER: args: ()
06:04:49 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 746, 'last_n_outputs': 38, 'leak_rate': 0.8806397773558576, 'lr': 0.003767710160626688, 'optimizer': 'Adam', 'sparsity': 0.7531176690334925, 'steps_to_train': 98, 'weight_decay': 0.08732101408161975}, 'budget': 133.33333333333331, 'working_directory': '.'}
06:05:31 DISPATCHER: Starting worker discovery
06:05:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:05:31 DISPATCHER: Finished worker discovery
06:06:31 DISPATCHER: Starting worker discovery
06:06:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:06:31 DISPATCHER: Finished worker discovery
06:07:31 DISPATCHER: Starting worker discovery
06:07:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:07:31 DISPATCHER: Finished worker discovery
06:08:05 WORKER: done with job (5, 0, 3), trying to register it.
06:08:05 WORKER: registered result for job (5, 0, 3) with dispatcher
06:08:05 DISPATCHER: job (5, 0, 3) finished
06:08:05 DISPATCHER: register_result: lock acquired
06:08:05 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
06:08:05 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 746, 'last_n_outputs': 38, 'leak_rate': 0.8806397773558576, 'lr': 0.003767710160626688, 'optimizer': 'Adam', 'sparsity': 0.7531176690334925, 'steps_to_train': 98, 'weight_decay': 0.08732101408161975}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1329447236327953, 'info': {'data03': 0.1329447236327953, 'config': "{'batch_size': 16, 'hidden_dim': 746, 'last_n_outputs': 38, 'leak_rate': 0.8806397773558576, 'lr': 0.003767710160626688, 'optimizer': 'Adam', 'sparsity': 0.7531176690334925, 'steps_to_train': 98, 'weight_decay': 0.08732101408161975}"}}
exception: None

06:08:05 job_callback for (5, 0, 3) started
06:08:05 DISPATCHER: Trying to submit another job.
06:08:05 job_callback for (5, 0, 3) got condition
06:08:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:08:06 done building a new model for budget 133.333333 based on 10/26 split
Best loss for this budget:-0.327684





06:08:06 HBMASTER: Trying to run another job!
06:08:06 job_callback for (5, 0, 3) finished
06:08:06 start sampling a new configuration.
06:08:06 best_vector: [3, 0.5715926558614628, 0.9244696967380992, 0.9795044678017749, 0.6099996252979466, 0, 0.9314303663939891, 0.44633095071492773, 0.29347220104291727], 1.9538497487549848e-32, 0.5118100819355282, -0.06108489557983324
06:08:06 done sampling a new configuration.
06:08:06 HBMASTER: schedule new run for iteration 5
06:08:06 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
06:08:06 HBMASTER: submitting job (5, 0, 4) to dispatcher
06:08:06 DISPATCHER: trying to submit job (5, 0, 4)
06:08:06 DISPATCHER: trying to notify the job_runner thread.
06:08:06 HBMASTER: job (5, 0, 4) submitted to dispatcher
06:08:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:08:06 DISPATCHER: Trying to submit another job.
06:08:06 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
06:08:06 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
06:08:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:08:06 WORKER: start processing job (5, 0, 4)
06:08:06 WORKER: args: ()
06:08:06 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 657, 'last_n_outputs': 47, 'leak_rate': 0.9948761169504438, 'lr': 0.016595840437120868, 'optimizer': 'Adam', 'sparsity': 0.9735432879345574, 'steps_to_train': 50, 'weight_decay': 0.024088853835244253}, 'budget': 133.33333333333331, 'working_directory': '.'}
06:08:31 DISPATCHER: Starting worker discovery
06:08:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:08:31 DISPATCHER: Finished worker discovery
06:09:31 DISPATCHER: Starting worker discovery
06:09:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:09:31 DISPATCHER: Finished worker discovery
06:10:31 DISPATCHER: Starting worker discovery
06:10:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:10:31 DISPATCHER: Finished worker discovery
06:11:03 WORKER: done with job (5, 0, 4), trying to register it.
06:11:03 WORKER: registered result for job (5, 0, 4) with dispatcher
06:11:03 DISPATCHER: job (5, 0, 4) finished
06:11:03 DISPATCHER: register_result: lock acquired
06:11:03 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
06:11:03 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 657, 'last_n_outputs': 47, 'leak_rate': 0.9948761169504438, 'lr': 0.016595840437120868, 'optimizer': 'Adam', 'sparsity': 0.9735432879345574, 'steps_to_train': 50, 'weight_decay': 0.024088853835244253}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.13259121671391044, 'info': {'data03': 0.13259121671391044, 'config': "{'batch_size': 128, 'hidden_dim': 657, 'last_n_outputs': 47, 'leak_rate': 0.9948761169504438, 'lr': 0.016595840437120868, 'optimizer': 'Adam', 'sparsity': 0.9735432879345574, 'steps_to_train': 50, 'weight_decay': 0.024088853835244253}"}}
exception: None

06:11:03 job_callback for (5, 0, 4) started
06:11:03 job_callback for (5, 0, 4) got condition
06:11:03 DISPATCHER: Trying to submit another job.
06:11:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:11:03 done building a new model for budget 133.333333 based on 10/27 split
Best loss for this budget:-0.327684





06:11:03 HBMASTER: Trying to run another job!
06:11:03 job_callback for (5, 0, 4) finished
06:11:03 start sampling a new configuration.
06:11:03 done sampling a new configuration.
06:11:03 HBMASTER: schedule new run for iteration 5
06:11:03 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
06:11:03 HBMASTER: submitting job (5, 0, 5) to dispatcher
06:11:03 DISPATCHER: trying to submit job (5, 0, 5)
06:11:03 DISPATCHER: trying to notify the job_runner thread.
06:11:03 HBMASTER: job (5, 0, 5) submitted to dispatcher
06:11:03 DISPATCHER: Trying to submit another job.
06:11:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:11:03 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
06:11:03 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
06:11:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:11:03 WORKER: start processing job (5, 0, 5)
06:11:03 WORKER: args: ()
06:11:03 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 367, 'last_n_outputs': 23, 'leak_rate': 0.9098976164973873, 'lr': 0.002827551378489271, 'optimizer': 'Adam', 'sparsity': 0.8589158763521623, 'steps_to_train': 98, 'weight_decay': 0.16154069639080612}, 'budget': 133.33333333333331, 'working_directory': '.'}
06:11:32 DISPATCHER: Starting worker discovery
06:11:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:11:32 DISPATCHER: Finished worker discovery
06:12:32 DISPATCHER: Starting worker discovery
06:12:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:12:32 DISPATCHER: Finished worker discovery
06:13:32 DISPATCHER: Starting worker discovery
06:13:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:13:32 DISPATCHER: Finished worker discovery
06:14:15 WORKER: done with job (5, 0, 5), trying to register it.
06:14:15 WORKER: registered result for job (5, 0, 5) with dispatcher
06:14:15 DISPATCHER: job (5, 0, 5) finished
06:14:15 DISPATCHER: register_result: lock acquired
06:14:15 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
06:14:15 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 367, 'last_n_outputs': 23, 'leak_rate': 0.9098976164973873, 'lr': 0.002827551378489271, 'optimizer': 'Adam', 'sparsity': 0.8589158763521623, 'steps_to_train': 98, 'weight_decay': 0.16154069639080612}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.30795508628698165, 'info': {'data03': 0.30795508628698165, 'config': "{'batch_size': 32, 'hidden_dim': 367, 'last_n_outputs': 23, 'leak_rate': 0.9098976164973873, 'lr': 0.002827551378489271, 'optimizer': 'Adam', 'sparsity': 0.8589158763521623, 'steps_to_train': 98, 'weight_decay': 0.16154069639080612}"}}
exception: None

06:14:15 job_callback for (5, 0, 5) started
06:14:15 DISPATCHER: Trying to submit another job.
06:14:15 job_callback for (5, 0, 5) got condition
06:14:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:14:15 done building a new model for budget 133.333333 based on 10/28 split
Best loss for this budget:-0.327684





06:14:15 HBMASTER: Trying to run another job!
06:14:15 job_callback for (5, 0, 5) finished
06:14:15 start sampling a new configuration.
06:14:15 done sampling a new configuration.
06:14:15 HBMASTER: schedule new run for iteration 5
06:14:15 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
06:14:15 HBMASTER: submitting job (5, 0, 6) to dispatcher
06:14:15 DISPATCHER: trying to submit job (5, 0, 6)
06:14:15 DISPATCHER: trying to notify the job_runner thread.
06:14:15 HBMASTER: job (5, 0, 6) submitted to dispatcher
06:14:15 DISPATCHER: Trying to submit another job.
06:14:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:14:15 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776
06:14:15 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
06:14:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:14:15 WORKER: start processing job (5, 0, 6)
06:14:15 WORKER: args: ()
06:14:15 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 630, 'last_n_outputs': 21, 'leak_rate': 0.9780223948747749, 'lr': 0.009528544848813675, 'optimizer': 'Adam', 'sparsity': 0.8438649257450556, 'steps_to_train': 12, 'weight_decay': 0.17035085120460994}, 'budget': 133.33333333333331, 'working_directory': '.'}
06:14:32 DISPATCHER: Starting worker discovery
06:14:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:14:32 DISPATCHER: Finished worker discovery
06:15:32 DISPATCHER: Starting worker discovery
06:15:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:15:32 DISPATCHER: Finished worker discovery
06:16:32 DISPATCHER: Starting worker discovery
06:16:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:16:32 DISPATCHER: Finished worker discovery
06:17:07 WORKER: done with job (5, 0, 6), trying to register it.
06:17:07 WORKER: registered result for job (5, 0, 6) with dispatcher
06:17:07 DISPATCHER: job (5, 0, 6) finished
06:17:07 DISPATCHER: register_result: lock acquired
06:17:07 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
06:17:07 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 630, 'last_n_outputs': 21, 'leak_rate': 0.9780223948747749, 'lr': 0.009528544848813675, 'optimizer': 'Adam', 'sparsity': 0.8438649257450556, 'steps_to_train': 12, 'weight_decay': 0.17035085120460994}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.18315007910110104, 'info': {'data03': 0.18315007910110104, 'config': "{'batch_size': 32, 'hidden_dim': 630, 'last_n_outputs': 21, 'leak_rate': 0.9780223948747749, 'lr': 0.009528544848813675, 'optimizer': 'Adam', 'sparsity': 0.8438649257450556, 'steps_to_train': 12, 'weight_decay': 0.17035085120460994}"}}
exception: None

06:17:07 job_callback for (5, 0, 6) started
06:17:07 DISPATCHER: Trying to submit another job.
06:17:07 job_callback for (5, 0, 6) got condition
06:17:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:17:07 done building a new model for budget 133.333333 based on 10/28 split
Best loss for this budget:-0.327684





06:17:07 HBMASTER: Trying to run another job!
06:17:07 job_callback for (5, 0, 6) finished
06:17:07 start sampling a new configuration.
06:17:08 best_vector: [3, 0.5942240214575404, 0.8888149269497063, 0.41083668698550685, 0.46650388370027673, 1, 0.8570752958518519, 0.6927747240155454, 0.12724723703647803], 1.044809183287798e-31, 0.09571125675343006, -0.014835633711574913
06:17:08 done sampling a new configuration.
06:17:08 HBMASTER: schedule new run for iteration 5
06:17:08 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
06:17:08 HBMASTER: submitting job (5, 0, 7) to dispatcher
06:17:08 DISPATCHER: trying to submit job (5, 0, 7)
06:17:08 DISPATCHER: trying to notify the job_runner thread.
06:17:08 HBMASTER: job (5, 0, 7) submitted to dispatcher
06:17:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:17:08 DISPATCHER: Trying to submit another job.
06:17:08 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776
06:17:08 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
06:17:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:17:08 WORKER: start processing job (5, 0, 7)
06:17:08 WORKER: args: ()
06:17:08 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 675, 'last_n_outputs': 46, 'leak_rate': 0.8527091717463767, 'lr': 0.00857053173575632, 'optimizer': 'SGD', 'sparsity': 0.9556980710044445, 'steps_to_train': 73, 'weight_decay': 0.01464038414651252}, 'budget': 133.33333333333331, 'working_directory': '.'}
06:17:32 DISPATCHER: Starting worker discovery
06:17:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:17:32 DISPATCHER: Finished worker discovery
06:18:32 DISPATCHER: Starting worker discovery
06:18:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:18:32 DISPATCHER: Finished worker discovery
06:19:32 DISPATCHER: Starting worker discovery
06:19:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:19:32 DISPATCHER: Finished worker discovery
06:20:28 WORKER: done with job (5, 0, 7), trying to register it.
06:20:28 WORKER: registered result for job (5, 0, 7) with dispatcher
06:20:28 DISPATCHER: job (5, 0, 7) finished
06:20:28 DISPATCHER: register_result: lock acquired
06:20:28 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
06:20:28 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 675, 'last_n_outputs': 46, 'leak_rate': 0.8527091717463767, 'lr': 0.00857053173575632, 'optimizer': 'SGD', 'sparsity': 0.9556980710044445, 'steps_to_train': 73, 'weight_decay': 0.01464038414651252}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.12674912152781376, 'info': {'data03': 0.12674912152781376, 'config': "{'batch_size': 128, 'hidden_dim': 675, 'last_n_outputs': 46, 'leak_rate': 0.8527091717463767, 'lr': 0.00857053173575632, 'optimizer': 'SGD', 'sparsity': 0.9556980710044445, 'steps_to_train': 73, 'weight_decay': 0.01464038414651252}"}}
exception: None

06:20:28 job_callback for (5, 0, 7) started
06:20:28 job_callback for (5, 0, 7) got condition
06:20:28 DISPATCHER: Trying to submit another job.
06:20:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:20:28 done building a new model for budget 133.333333 based on 10/29 split
Best loss for this budget:-0.327684





06:20:28 HBMASTER: Trying to run another job!
06:20:28 job_callback for (5, 0, 7) finished
06:20:28 start sampling a new configuration.
06:20:28 best_vector: [0, 0.5997400899422851, 0.8657303088251702, 0.5940068500270956, 0.060628886750766595, 1, 0.5000700694466351, 0.7479554487573267, 0.8660557668519637], 1.8292948479083827e-32, 0.5466587309002706, -0.001843553095065236
06:20:28 done sampling a new configuration.
06:20:28 HBMASTER: schedule new run for iteration 5
06:20:28 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
06:20:28 HBMASTER: submitting job (5, 0, 8) to dispatcher
06:20:28 DISPATCHER: trying to submit job (5, 0, 8)
06:20:28 DISPATCHER: trying to notify the job_runner thread.
06:20:28 HBMASTER: job (5, 0, 8) submitted to dispatcher
06:20:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:20:28 DISPATCHER: Trying to submit another job.
06:20:28 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776
06:20:28 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
06:20:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:20:28 WORKER: start processing job (5, 0, 8)
06:20:28 WORKER: args: ()
06:20:28 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 680, 'last_n_outputs': 45, 'leak_rate': 0.8985017125067739, 'lr': 0.0013220801159511033, 'optimizer': 'SGD', 'sparsity': 0.8700168166671924, 'steps_to_train': 78, 'weight_decay': 0.13389505272111016}, 'budget': 133.33333333333331, 'working_directory': '.'}
06:20:32 DISPATCHER: Starting worker discovery
06:20:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:20:32 DISPATCHER: Finished worker discovery
06:21:32 DISPATCHER: Starting worker discovery
06:21:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:21:32 DISPATCHER: Finished worker discovery
06:22:32 DISPATCHER: Starting worker discovery
06:22:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:22:32 DISPATCHER: Finished worker discovery
06:23:32 DISPATCHER: Starting worker discovery
06:23:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:23:32 DISPATCHER: Finished worker discovery
06:23:50 WORKER: done with job (5, 0, 8), trying to register it.
06:23:50 WORKER: registered result for job (5, 0, 8) with dispatcher
06:23:50 DISPATCHER: job (5, 0, 8) finished
06:23:50 DISPATCHER: register_result: lock acquired
06:23:50 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
06:23:50 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 680, 'last_n_outputs': 45, 'leak_rate': 0.8985017125067739, 'lr': 0.0013220801159511033, 'optimizer': 'SGD', 'sparsity': 0.8700168166671924, 'steps_to_train': 78, 'weight_decay': 0.13389505272111016}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.27489857154787634, 'info': {'data03': 0.27489857154787634, 'config': "{'batch_size': 16, 'hidden_dim': 680, 'last_n_outputs': 45, 'leak_rate': 0.8985017125067739, 'lr': 0.0013220801159511033, 'optimizer': 'SGD', 'sparsity': 0.8700168166671924, 'steps_to_train': 78, 'weight_decay': 0.13389505272111016}"}}
exception: None

06:23:50 job_callback for (5, 0, 8) started
06:23:50 DISPATCHER: Trying to submit another job.
06:23:50 job_callback for (5, 0, 8) got condition
06:23:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:23:50 done building a new model for budget 133.333333 based on 10/30 split
Best loss for this budget:-0.327684





06:23:50 HBMASTER: Trying to run another job!
06:23:50 job_callback for (5, 0, 8) finished
06:23:50 ITERATION: Advancing config (5, 0, 0) to next budget 400.000000
06:23:50 ITERATION: Advancing config (5, 0, 5) to next budget 400.000000
06:23:50 ITERATION: Advancing config (5, 0, 8) to next budget 400.000000
06:23:50 HBMASTER: schedule new run for iteration 5
06:23:50 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
06:23:50 HBMASTER: submitting job (5, 0, 0) to dispatcher
06:23:50 DISPATCHER: trying to submit job (5, 0, 0)
06:23:50 DISPATCHER: trying to notify the job_runner thread.
06:23:50 HBMASTER: job (5, 0, 0) submitted to dispatcher
06:23:50 DISPATCHER: Trying to submit another job.
06:23:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:23:50 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
06:23:50 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
06:23:50 WORKER: start processing job (5, 0, 0)
06:23:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:23:50 WORKER: args: ()
06:23:50 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 507, 'last_n_outputs': 31, 'leak_rate': 0.9935086318712427, 'lr': 0.0022083849331606797, 'optimizer': 'Adam', 'sparsity': 0.8677973238644018, 'steps_to_train': 75, 'weight_decay': 0.021954679468330504}, 'budget': 400.0, 'working_directory': '.'}
06:24:32 DISPATCHER: Starting worker discovery
06:24:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:24:32 DISPATCHER: Finished worker discovery
06:25:32 DISPATCHER: Starting worker discovery
06:25:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:25:32 DISPATCHER: Finished worker discovery
06:26:32 DISPATCHER: Starting worker discovery
06:26:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:26:32 DISPATCHER: Finished worker discovery
06:27:32 DISPATCHER: Starting worker discovery
06:27:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:27:32 DISPATCHER: Finished worker discovery
06:28:32 DISPATCHER: Starting worker discovery
06:28:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:28:32 DISPATCHER: Finished worker discovery
06:29:32 DISPATCHER: Starting worker discovery
06:29:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:29:32 DISPATCHER: Finished worker discovery
06:30:32 DISPATCHER: Starting worker discovery
06:30:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:30:32 DISPATCHER: Finished worker discovery
06:31:27 WORKER: done with job (5, 0, 0), trying to register it.
06:31:27 WORKER: registered result for job (5, 0, 0) with dispatcher
06:31:27 DISPATCHER: job (5, 0, 0) finished
06:31:27 DISPATCHER: register_result: lock acquired
06:31:27 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
06:31:27 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 507, 'last_n_outputs': 31, 'leak_rate': 0.9935086318712427, 'lr': 0.0022083849331606797, 'optimizer': 'Adam', 'sparsity': 0.8677973238644018, 'steps_to_train': 75, 'weight_decay': 0.021954679468330504}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.23492828116655654, 'info': {'data03': 0.23492828116655654, 'config': "{'batch_size': 128, 'hidden_dim': 507, 'last_n_outputs': 31, 'leak_rate': 0.9935086318712427, 'lr': 0.0022083849331606797, 'optimizer': 'Adam', 'sparsity': 0.8677973238644018, 'steps_to_train': 75, 'weight_decay': 0.021954679468330504}"}}
exception: None

06:31:27 job_callback for (5, 0, 0) started
06:31:27 job_callback for (5, 0, 0) got condition
06:31:27 DISPATCHER: Trying to submit another job.
06:31:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:31:27 HBMASTER: Trying to run another job!
06:31:27 job_callback for (5, 0, 0) finished
06:31:27 HBMASTER: schedule new run for iteration 5
06:31:27 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
06:31:27 HBMASTER: submitting job (5, 0, 5) to dispatcher
06:31:27 DISPATCHER: trying to submit job (5, 0, 5)
06:31:27 DISPATCHER: trying to notify the job_runner thread.
06:31:27 HBMASTER: job (5, 0, 5) submitted to dispatcher
06:31:27 DISPATCHER: Trying to submit another job.
06:31:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:31:27 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
06:31:27 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
06:31:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:31:27 WORKER: start processing job (5, 0, 5)
06:31:27 WORKER: args: ()
06:31:27 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 367, 'last_n_outputs': 23, 'leak_rate': 0.9098976164973873, 'lr': 0.002827551378489271, 'optimizer': 'Adam', 'sparsity': 0.8589158763521623, 'steps_to_train': 98, 'weight_decay': 0.16154069639080612}, 'budget': 400.0, 'working_directory': '.'}
06:31:32 DISPATCHER: Starting worker discovery
06:31:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:31:32 DISPATCHER: Finished worker discovery
06:32:32 DISPATCHER: Starting worker discovery
06:32:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:32:32 DISPATCHER: Finished worker discovery
06:33:32 DISPATCHER: Starting worker discovery
06:33:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:33:32 DISPATCHER: Finished worker discovery
06:34:32 DISPATCHER: Starting worker discovery
06:34:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:34:32 DISPATCHER: Finished worker discovery
06:35:32 DISPATCHER: Starting worker discovery
06:35:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:35:32 DISPATCHER: Finished worker discovery
06:36:32 DISPATCHER: Starting worker discovery
06:36:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:36:32 DISPATCHER: Finished worker discovery
06:37:32 DISPATCHER: Starting worker discovery
06:37:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:37:32 DISPATCHER: Finished worker discovery
06:38:32 DISPATCHER: Starting worker discovery
06:38:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:38:32 DISPATCHER: Finished worker discovery
06:38:58 WORKER: done with job (5, 0, 5), trying to register it.
06:38:58 WORKER: registered result for job (5, 0, 5) with dispatcher
06:38:58 DISPATCHER: job (5, 0, 5) finished
06:38:58 DISPATCHER: register_result: lock acquired
06:38:58 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
06:38:58 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 367, 'last_n_outputs': 23, 'leak_rate': 0.9098976164973873, 'lr': 0.002827551378489271, 'optimizer': 'Adam', 'sparsity': 0.8589158763521623, 'steps_to_train': 98, 'weight_decay': 0.16154069639080612}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.03947458393458345, 'info': {'data03': 0.03947458393458345, 'config': "{'batch_size': 32, 'hidden_dim': 367, 'last_n_outputs': 23, 'leak_rate': 0.9098976164973873, 'lr': 0.002827551378489271, 'optimizer': 'Adam', 'sparsity': 0.8589158763521623, 'steps_to_train': 98, 'weight_decay': 0.16154069639080612}"}}
exception: None

06:38:58 job_callback for (5, 0, 5) started
06:38:58 job_callback for (5, 0, 5) got condition
06:38:58 DISPATCHER: Trying to submit another job.
06:38:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:38:58 HBMASTER: Trying to run another job!
06:38:58 job_callback for (5, 0, 5) finished
06:38:58 HBMASTER: schedule new run for iteration 5
06:38:58 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
06:38:58 HBMASTER: submitting job (5, 0, 8) to dispatcher
06:38:58 DISPATCHER: trying to submit job (5, 0, 8)
06:38:58 DISPATCHER: trying to notify the job_runner thread.
06:38:58 HBMASTER: job (5, 0, 8) submitted to dispatcher
06:38:58 DISPATCHER: Trying to submit another job.
06:38:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:38:58 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776
06:38:58 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
06:38:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:38:58 WORKER: start processing job (5, 0, 8)
06:38:58 WORKER: args: ()
06:38:58 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 680, 'last_n_outputs': 45, 'leak_rate': 0.8985017125067739, 'lr': 0.0013220801159511033, 'optimizer': 'SGD', 'sparsity': 0.8700168166671924, 'steps_to_train': 78, 'weight_decay': 0.13389505272111016}, 'budget': 400.0, 'working_directory': '.'}
06:39:32 DISPATCHER: Starting worker discovery
06:39:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:39:32 DISPATCHER: Finished worker discovery
06:40:32 DISPATCHER: Starting worker discovery
06:40:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:40:32 DISPATCHER: Finished worker discovery
06:41:32 DISPATCHER: Starting worker discovery
06:41:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:41:32 DISPATCHER: Finished worker discovery
06:42:32 DISPATCHER: Starting worker discovery
06:42:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:42:32 DISPATCHER: Finished worker discovery
06:43:32 DISPATCHER: Starting worker discovery
06:43:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:43:32 DISPATCHER: Finished worker discovery
06:44:32 DISPATCHER: Starting worker discovery
06:44:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:44:32 DISPATCHER: Finished worker discovery
06:45:32 DISPATCHER: Starting worker discovery
06:45:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:45:32 DISPATCHER: Finished worker discovery
06:46:32 DISPATCHER: Starting worker discovery
06:46:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:46:32 DISPATCHER: Finished worker discovery
06:46:36 WORKER: done with job (5, 0, 8), trying to register it.
06:46:36 WORKER: registered result for job (5, 0, 8) with dispatcher
06:46:36 DISPATCHER: job (5, 0, 8) finished
06:46:36 DISPATCHER: register_result: lock acquired
06:46:36 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
06:46:36 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 680, 'last_n_outputs': 45, 'leak_rate': 0.8985017125067739, 'lr': 0.0013220801159511033, 'optimizer': 'SGD', 'sparsity': 0.8700168166671924, 'steps_to_train': 78, 'weight_decay': 0.13389505272111016}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.20339532292141246, 'info': {'data03': 0.20339532292141246, 'config': "{'batch_size': 16, 'hidden_dim': 680, 'last_n_outputs': 45, 'leak_rate': 0.8985017125067739, 'lr': 0.0013220801159511033, 'optimizer': 'SGD', 'sparsity': 0.8700168166671924, 'steps_to_train': 78, 'weight_decay': 0.13389505272111016}"}}
exception: None

06:46:36 job_callback for (5, 0, 8) started
06:46:36 job_callback for (5, 0, 8) got condition
06:46:36 DISPATCHER: Trying to submit another job.
06:46:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:46:36 HBMASTER: Trying to run another job!
06:46:36 job_callback for (5, 0, 8) finished
06:46:36 ITERATION: Advancing config (5, 0, 0) to next budget 1200.000000
06:46:36 HBMASTER: schedule new run for iteration 5
06:46:36 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
06:46:36 HBMASTER: submitting job (5, 0, 0) to dispatcher
06:46:36 DISPATCHER: trying to submit job (5, 0, 0)
06:46:36 DISPATCHER: trying to notify the job_runner thread.
06:46:36 HBMASTER: job (5, 0, 0) submitted to dispatcher
06:46:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:46:36 DISPATCHER: Trying to submit another job.
06:46:36 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
06:46:36 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
06:46:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:46:36 WORKER: start processing job (5, 0, 0)
06:46:36 WORKER: args: ()
06:46:36 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 507, 'last_n_outputs': 31, 'leak_rate': 0.9935086318712427, 'lr': 0.0022083849331606797, 'optimizer': 'Adam', 'sparsity': 0.8677973238644018, 'steps_to_train': 75, 'weight_decay': 0.021954679468330504}, 'budget': 1200.0, 'working_directory': '.'}
06:47:32 DISPATCHER: Starting worker discovery
06:47:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:47:32 DISPATCHER: Finished worker discovery
06:48:32 DISPATCHER: Starting worker discovery
06:48:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:48:32 DISPATCHER: Finished worker discovery
06:49:32 DISPATCHER: Starting worker discovery
06:49:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:49:32 DISPATCHER: Finished worker discovery
06:50:32 DISPATCHER: Starting worker discovery
06:50:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:50:32 DISPATCHER: Finished worker discovery
06:51:32 DISPATCHER: Starting worker discovery
06:51:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:51:32 DISPATCHER: Finished worker discovery
06:52:32 DISPATCHER: Starting worker discovery
06:52:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:52:32 DISPATCHER: Finished worker discovery
06:53:32 DISPATCHER: Starting worker discovery
06:53:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:53:32 DISPATCHER: Finished worker discovery
06:54:32 DISPATCHER: Starting worker discovery
06:54:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:54:32 DISPATCHER: Finished worker discovery
06:55:32 DISPATCHER: Starting worker discovery
06:55:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:55:32 DISPATCHER: Finished worker discovery
06:56:32 DISPATCHER: Starting worker discovery
06:56:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:56:32 DISPATCHER: Finished worker discovery
06:57:32 DISPATCHER: Starting worker discovery
06:57:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:57:32 DISPATCHER: Finished worker discovery
06:58:32 DISPATCHER: Starting worker discovery
06:58:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:58:32 DISPATCHER: Finished worker discovery
06:59:32 DISPATCHER: Starting worker discovery
06:59:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:59:32 DISPATCHER: Finished worker discovery
07:00:32 DISPATCHER: Starting worker discovery
07:00:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:00:32 DISPATCHER: Finished worker discovery
07:01:32 DISPATCHER: Starting worker discovery
07:01:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:01:32 DISPATCHER: Finished worker discovery
07:02:32 DISPATCHER: Starting worker discovery
07:02:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:02:32 DISPATCHER: Finished worker discovery
07:03:32 DISPATCHER: Starting worker discovery
07:03:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:03:32 DISPATCHER: Finished worker discovery
07:04:32 DISPATCHER: Starting worker discovery
07:04:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:04:32 DISPATCHER: Finished worker discovery
07:05:32 DISPATCHER: Starting worker discovery
07:05:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:05:32 DISPATCHER: Finished worker discovery
07:06:32 DISPATCHER: Starting worker discovery
07:06:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:06:32 DISPATCHER: Finished worker discovery
07:07:32 DISPATCHER: Starting worker discovery
07:07:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:07:32 DISPATCHER: Finished worker discovery
07:07:35 WORKER: done with job (5, 0, 0), trying to register it.
07:07:35 WORKER: registered result for job (5, 0, 0) with dispatcher
07:07:35 DISPATCHER: job (5, 0, 0) finished
07:07:35 DISPATCHER: register_result: lock acquired
07:07:35 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
07:07:35 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 507, 'last_n_outputs': 31, 'leak_rate': 0.9935086318712427, 'lr': 0.0022083849331606797, 'optimizer': 'Adam', 'sparsity': 0.8677973238644018, 'steps_to_train': 75, 'weight_decay': 0.021954679468330504}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.2607857352152421, 'info': {'data03': 0.2607857352152421, 'config': "{'batch_size': 128, 'hidden_dim': 507, 'last_n_outputs': 31, 'leak_rate': 0.9935086318712427, 'lr': 0.0022083849331606797, 'optimizer': 'Adam', 'sparsity': 0.8677973238644018, 'steps_to_train': 75, 'weight_decay': 0.021954679468330504}"}}
exception: None

07:07:35 job_callback for (5, 0, 0) started
07:07:35 job_callback for (5, 0, 0) got condition
07:07:35 DISPATCHER: Trying to submit another job.
07:07:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:07:35 HBMASTER: Trying to run another job!
07:07:35 job_callback for (5, 0, 0) finished
07:07:35 start sampling a new configuration.
07:07:35 best_vector: [3, 0.7092927187328147, 0.728506762562716, 0.4257649229677971, 0.33558044521554187, 0, 0.7995021520254114, 0.961761404487936, 0.15030613605283571], 4.784611207916354e-31, 0.020900339788224694, -0.018391544224569803
07:07:35 done sampling a new configuration.
07:07:35 HBMASTER: schedule new run for iteration 6
07:07:35 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
07:07:35 HBMASTER: submitting job (6, 0, 0) to dispatcher
07:07:35 DISPATCHER: trying to submit job (6, 0, 0)
07:07:35 DISPATCHER: trying to notify the job_runner thread.
07:07:35 HBMASTER: job (6, 0, 0) submitted to dispatcher
07:07:35 DISPATCHER: Trying to submit another job.
07:07:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:07:35 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
07:07:35 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
07:07:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:07:35 WORKER: start processing job (6, 0, 0)
07:07:35 WORKER: args: ()
07:07:35 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 768, 'last_n_outputs': 39, 'leak_rate': 0.8564412307419493, 'lr': 0.004689870927578098, 'optimizer': 'Adam', 'sparsity': 0.9418805164860987, 'steps_to_train': 97, 'weight_decay': 0.01568746578228537}, 'budget': 400.0, 'working_directory': '.'}
07:08:32 DISPATCHER: Starting worker discovery
07:08:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:08:32 DISPATCHER: Finished worker discovery
07:09:32 DISPATCHER: Starting worker discovery
07:09:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:09:32 DISPATCHER: Finished worker discovery
07:10:32 DISPATCHER: Starting worker discovery
07:10:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:10:32 DISPATCHER: Finished worker discovery
07:11:32 DISPATCHER: Starting worker discovery
07:11:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:11:32 DISPATCHER: Finished worker discovery
07:12:32 DISPATCHER: Starting worker discovery
07:12:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:12:32 DISPATCHER: Finished worker discovery
07:13:32 DISPATCHER: Starting worker discovery
07:13:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:13:32 DISPATCHER: Finished worker discovery
07:14:32 DISPATCHER: Starting worker discovery
07:14:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:14:32 DISPATCHER: Finished worker discovery
07:15:14 WORKER: done with job (6, 0, 0), trying to register it.
07:15:14 WORKER: registered result for job (6, 0, 0) with dispatcher
07:15:14 DISPATCHER: job (6, 0, 0) finished
07:15:14 DISPATCHER: register_result: lock acquired
07:15:14 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
07:15:14 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 768, 'last_n_outputs': 39, 'leak_rate': 0.8564412307419493, 'lr': 0.004689870927578098, 'optimizer': 'Adam', 'sparsity': 0.9418805164860987, 'steps_to_train': 97, 'weight_decay': 0.01568746578228537}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3310075631855323, 'info': {'data03': 0.3310075631855323, 'config': "{'batch_size': 128, 'hidden_dim': 768, 'last_n_outputs': 39, 'leak_rate': 0.8564412307419493, 'lr': 0.004689870927578098, 'optimizer': 'Adam', 'sparsity': 0.9418805164860987, 'steps_to_train': 97, 'weight_decay': 0.01568746578228537}"}}
exception: None

07:15:14 job_callback for (6, 0, 0) started
07:15:14 DISPATCHER: Trying to submit another job.
07:15:14 job_callback for (6, 0, 0) got condition
07:15:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:15:14 HBMASTER: Trying to run another job!
07:15:14 job_callback for (6, 0, 0) finished
07:15:15 start sampling a new configuration.
07:15:15 best_vector: [3, 0.2798259065222558, 0.39044641774163896, 0.0202755188469691, 0.9022555421124374, 1, 0.924401196374088, 0.5051913755903431, 0.5814824645840287], 8.930715998625041e-29, 0.00011197310497321363, -0.0006085645932726897
07:15:15 done sampling a new configuration.
07:15:15 HBMASTER: schedule new run for iteration 6
07:15:15 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
07:15:15 HBMASTER: submitting job (6, 0, 1) to dispatcher
07:15:15 DISPATCHER: trying to submit job (6, 0, 1)
07:15:15 DISPATCHER: trying to notify the job_runner thread.
07:15:15 HBMASTER: job (6, 0, 1) submitted to dispatcher
07:15:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:15:15 DISPATCHER: Trying to submit another job.
07:15:15 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
07:15:15 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
07:15:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:15:15 WORKER: start processing job (6, 0, 1)
07:15:15 WORKER: args: ()
07:15:15 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 424, 'last_n_outputs': 26, 'leak_rate': 0.7550688797117423, 'lr': 0.0637545352496256, 'optimizer': 'SGD', 'sparsity': 0.9718562871297811, 'steps_to_train': 55, 'weight_decay': 0.05708554194049537}, 'budget': 400.0, 'working_directory': '.'}
07:15:32 DISPATCHER: Starting worker discovery
07:15:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:15:32 DISPATCHER: Finished worker discovery
07:16:32 DISPATCHER: Starting worker discovery
07:16:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:16:32 DISPATCHER: Finished worker discovery
07:17:32 DISPATCHER: Starting worker discovery
07:17:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:17:32 DISPATCHER: Finished worker discovery
07:18:32 DISPATCHER: Starting worker discovery
07:18:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:18:32 DISPATCHER: Finished worker discovery
07:19:32 DISPATCHER: Starting worker discovery
07:19:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:19:32 DISPATCHER: Finished worker discovery
07:20:32 DISPATCHER: Starting worker discovery
07:20:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:20:32 DISPATCHER: Finished worker discovery
07:21:32 DISPATCHER: Starting worker discovery
07:21:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:21:32 DISPATCHER: Finished worker discovery
07:22:32 DISPATCHER: Starting worker discovery
07:22:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:22:32 DISPATCHER: Finished worker discovery
07:22:55 WORKER: done with job (6, 0, 1), trying to register it.
07:22:55 WORKER: registered result for job (6, 0, 1) with dispatcher
07:22:55 DISPATCHER: job (6, 0, 1) finished
07:22:55 DISPATCHER: register_result: lock acquired
07:22:55 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
07:22:55 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 424, 'last_n_outputs': 26, 'leak_rate': 0.7550688797117423, 'lr': 0.0637545352496256, 'optimizer': 'SGD', 'sparsity': 0.9718562871297811, 'steps_to_train': 55, 'weight_decay': 0.05708554194049537}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.15662539515517807, 'info': {'data03': 0.15662539515517807, 'config': "{'batch_size': 128, 'hidden_dim': 424, 'last_n_outputs': 26, 'leak_rate': 0.7550688797117423, 'lr': 0.0637545352496256, 'optimizer': 'SGD', 'sparsity': 0.9718562871297811, 'steps_to_train': 55, 'weight_decay': 0.05708554194049537}"}}
exception: None

07:22:55 job_callback for (6, 0, 1) started
07:22:55 DISPATCHER: Trying to submit another job.
07:22:55 job_callback for (6, 0, 1) got condition
07:22:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:22:55 done building a new model for budget 400.000000 based on 10/17 split
Best loss for this budget:-0.340020





07:22:55 HBMASTER: Trying to run another job!
07:22:55 job_callback for (6, 0, 1) finished
07:22:55 start sampling a new configuration.
07:22:55 best_vector: [1, 0.6368531283971596, 0.8757658087979175, 0.8006623821976221, 0.15355310117180646, 0, 0.5067160103852097, 0.9517320753366165, 0.3747374563750603], 1.6913064237759902e-32, 0.5912589143766227, -0.00015554210531018188
07:22:55 done sampling a new configuration.
07:22:55 HBMASTER: schedule new run for iteration 6
07:22:55 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
07:22:55 HBMASTER: submitting job (6, 0, 2) to dispatcher
07:22:55 DISPATCHER: trying to submit job (6, 0, 2)
07:22:55 DISPATCHER: trying to notify the job_runner thread.
07:22:55 HBMASTER: job (6, 0, 2) submitted to dispatcher
07:22:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:22:55 DISPATCHER: Trying to submit another job.
07:22:55 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
07:22:55 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
07:22:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:22:55 WORKER: start processing job (6, 0, 2)
07:22:55 WORKER: args: ()
07:22:55 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 710, 'last_n_outputs': 45, 'leak_rate': 0.9501655955494055, 'lr': 0.002028178629550587, 'optimizer': 'Adam', 'sparsity': 0.8716118424924504, 'steps_to_train': 96, 'weight_decay': 0.03072873422737541}, 'budget': 400.0, 'working_directory': '.'}
07:23:32 DISPATCHER: Starting worker discovery
07:23:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:23:32 DISPATCHER: Finished worker discovery
07:24:32 DISPATCHER: Starting worker discovery
07:24:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:24:32 DISPATCHER: Finished worker discovery
07:25:32 DISPATCHER: Starting worker discovery
07:25:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:25:32 DISPATCHER: Finished worker discovery
07:26:32 DISPATCHER: Starting worker discovery
07:26:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:26:32 DISPATCHER: Finished worker discovery
07:27:32 DISPATCHER: Starting worker discovery
07:27:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:27:32 DISPATCHER: Finished worker discovery
07:28:32 DISPATCHER: Starting worker discovery
07:28:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:28:32 DISPATCHER: Finished worker discovery
07:29:32 DISPATCHER: Starting worker discovery
07:29:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:29:32 DISPATCHER: Finished worker discovery
07:30:32 DISPATCHER: Starting worker discovery
07:30:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:30:32 DISPATCHER: Finished worker discovery
07:30:44 WORKER: done with job (6, 0, 2), trying to register it.
07:30:44 WORKER: registered result for job (6, 0, 2) with dispatcher
07:30:44 DISPATCHER: job (6, 0, 2) finished
07:30:44 DISPATCHER: register_result: lock acquired
07:30:44 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
07:30:44 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 710, 'last_n_outputs': 45, 'leak_rate': 0.9501655955494055, 'lr': 0.002028178629550587, 'optimizer': 'Adam', 'sparsity': 0.8716118424924504, 'steps_to_train': 96, 'weight_decay': 0.03072873422737541}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.32550764927274156, 'info': {'data03': 0.32550764927274156, 'config': "{'batch_size': 32, 'hidden_dim': 710, 'last_n_outputs': 45, 'leak_rate': 0.9501655955494055, 'lr': 0.002028178629550587, 'optimizer': 'Adam', 'sparsity': 0.8716118424924504, 'steps_to_train': 96, 'weight_decay': 0.03072873422737541}"}}
exception: None

07:30:44 job_callback for (6, 0, 2) started
07:30:44 DISPATCHER: Trying to submit another job.
07:30:44 job_callback for (6, 0, 2) got condition
07:30:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:30:44 done building a new model for budget 400.000000 based on 10/17 split
Best loss for this budget:-0.340020





07:30:44 HBMASTER: Trying to run another job!
07:30:44 job_callback for (6, 0, 2) finished
07:30:44 start sampling a new configuration.
07:30:44 best_vector: [0, 0.5299628687361407, 0.8229350945453918, 0.3794299386082288, 0.47071216522252085, 0, 0.419150930581062, 0.9560217555341946, 0.3792988638213361], 8.431938819013275e-33, 1.1859668594191985, -0.007429441015796894
07:30:44 done sampling a new configuration.
07:30:44 HBMASTER: schedule new run for iteration 6
07:30:44 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
07:30:44 HBMASTER: submitting job (6, 0, 3) to dispatcher
07:30:44 DISPATCHER: trying to submit job (6, 0, 3)
07:30:44 DISPATCHER: trying to notify the job_runner thread.
07:30:44 HBMASTER: job (6, 0, 3) submitted to dispatcher
07:30:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:30:44 DISPATCHER: Trying to submit another job.
07:30:44 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
07:30:44 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
07:30:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:30:44 WORKER: start processing job (6, 0, 3)
07:30:44 WORKER: args: ()
07:30:44 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 624, 'last_n_outputs': 43, 'leak_rate': 0.8448574846520572, 'lr': 0.008738247279596465, 'optimizer': 'Adam', 'sparsity': 0.8505962233394548, 'steps_to_train': 96, 'weight_decay': 0.031151516899655767}, 'budget': 400.0, 'working_directory': '.'}
07:31:32 DISPATCHER: Starting worker discovery
07:31:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:31:32 DISPATCHER: Finished worker discovery
07:32:32 DISPATCHER: Starting worker discovery
07:32:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:32:32 DISPATCHER: Finished worker discovery
07:33:32 DISPATCHER: Starting worker discovery
07:33:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:33:32 DISPATCHER: Finished worker discovery
07:34:32 DISPATCHER: Starting worker discovery
07:34:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:34:32 DISPATCHER: Finished worker discovery
07:35:32 DISPATCHER: Starting worker discovery
07:35:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:35:32 DISPATCHER: Finished worker discovery
07:36:32 DISPATCHER: Starting worker discovery
07:36:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:36:32 DISPATCHER: Finished worker discovery
07:37:32 DISPATCHER: Starting worker discovery
07:37:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:37:32 DISPATCHER: Finished worker discovery
07:38:10 WORKER: done with job (6, 0, 3), trying to register it.
07:38:10 WORKER: registered result for job (6, 0, 3) with dispatcher
07:38:10 DISPATCHER: job (6, 0, 3) finished
07:38:10 DISPATCHER: register_result: lock acquired
07:38:10 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
07:38:10 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 624, 'last_n_outputs': 43, 'leak_rate': 0.8448574846520572, 'lr': 0.008738247279596465, 'optimizer': 'Adam', 'sparsity': 0.8505962233394548, 'steps_to_train': 96, 'weight_decay': 0.031151516899655767}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.07368903760490214, 'info': {'data03': 0.07368903760490214, 'config': "{'batch_size': 16, 'hidden_dim': 624, 'last_n_outputs': 43, 'leak_rate': 0.8448574846520572, 'lr': 0.008738247279596465, 'optimizer': 'Adam', 'sparsity': 0.8505962233394548, 'steps_to_train': 96, 'weight_decay': 0.031151516899655767}"}}
exception: None

07:38:10 job_callback for (6, 0, 3) started
07:38:10 DISPATCHER: Trying to submit another job.
07:38:10 job_callback for (6, 0, 3) got condition
07:38:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:38:10 done building a new model for budget 400.000000 based on 10/18 split
Best loss for this budget:-0.340020





07:38:10 HBMASTER: Trying to run another job!
07:38:10 job_callback for (6, 0, 3) finished
07:38:10 start sampling a new configuration.
07:38:10 best_vector: [0, 0.7061230156684436, 0.6859544569204905, 0.11001127701690672, 0.1711210984679819, 0, 0.521916922026952, 0.808384731084651, 0.29005348221564586], 1.9222150461759858e-32, 0.5202331560089383, -0.017137630230239103
07:38:10 done sampling a new configuration.
07:38:10 HBMASTER: schedule new run for iteration 6
07:38:10 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
07:38:10 HBMASTER: submitting job (6, 0, 4) to dispatcher
07:38:10 DISPATCHER: trying to submit job (6, 0, 4)
07:38:10 DISPATCHER: trying to notify the job_runner thread.
07:38:10 HBMASTER: job (6, 0, 4) submitted to dispatcher
07:38:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:38:10 DISPATCHER: Trying to submit another job.
07:38:10 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
07:38:10 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
07:38:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:38:10 WORKER: start processing job (6, 0, 4)
07:38:10 WORKER: args: ()
07:38:10 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 765, 'last_n_outputs': 38, 'leak_rate': 0.7775028192542267, 'lr': 0.0021990859150374724, 'optimizer': 'Adam', 'sparsity': 0.8752600612864685, 'steps_to_train': 83, 'weight_decay': 0.02384340527526373}, 'budget': 400.0, 'working_directory': '.'}
07:38:32 DISPATCHER: Starting worker discovery
07:38:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:38:32 DISPATCHER: Finished worker discovery
07:39:32 DISPATCHER: Starting worker discovery
07:39:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:39:32 DISPATCHER: Finished worker discovery
07:40:32 DISPATCHER: Starting worker discovery
07:40:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:40:32 DISPATCHER: Finished worker discovery
07:41:32 DISPATCHER: Starting worker discovery
07:41:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:41:32 DISPATCHER: Finished worker discovery
07:42:32 DISPATCHER: Starting worker discovery
07:42:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:42:32 DISPATCHER: Finished worker discovery
07:43:32 DISPATCHER: Starting worker discovery
07:43:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:43:32 DISPATCHER: Finished worker discovery
07:44:32 DISPATCHER: Starting worker discovery
07:44:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:44:32 DISPATCHER: Finished worker discovery
07:45:32 DISPATCHER: Starting worker discovery
07:45:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:45:32 DISPATCHER: Finished worker discovery
07:45:39 WORKER: done with job (6, 0, 4), trying to register it.
07:45:39 WORKER: registered result for job (6, 0, 4) with dispatcher
07:45:39 DISPATCHER: job (6, 0, 4) finished
07:45:39 DISPATCHER: register_result: lock acquired
07:45:39 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
07:45:39 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 765, 'last_n_outputs': 38, 'leak_rate': 0.7775028192542267, 'lr': 0.0021990859150374724, 'optimizer': 'Adam', 'sparsity': 0.8752600612864685, 'steps_to_train': 83, 'weight_decay': 0.02384340527526373}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.2044686710612997, 'info': {'data03': 0.2044686710612997, 'config': "{'batch_size': 16, 'hidden_dim': 765, 'last_n_outputs': 38, 'leak_rate': 0.7775028192542267, 'lr': 0.0021990859150374724, 'optimizer': 'Adam', 'sparsity': 0.8752600612864685, 'steps_to_train': 83, 'weight_decay': 0.02384340527526373}"}}
exception: None

07:45:39 job_callback for (6, 0, 4) started
07:45:39 DISPATCHER: Trying to submit another job.
07:45:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:45:39 job_callback for (6, 0, 4) got condition
07:45:39 done building a new model for budget 400.000000 based on 10/19 split
Best loss for this budget:-0.340020





07:45:39 HBMASTER: Trying to run another job!
07:45:39 job_callback for (6, 0, 4) finished
07:45:39 start sampling a new configuration.
07:45:39 best_vector: [0, 0.6951274648254175, 0.8248511560666437, 0.1865659802902958, 0.6883924006216181, 0, 0.1346052519827713, 0.6280422595773167, 0.6618029528593915], 4.1886507248988257e-32, 0.2387403643029115, -0.01236649333344366
07:45:39 done sampling a new configuration.
07:45:39 HBMASTER: schedule new run for iteration 6
07:45:39 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
07:45:39 HBMASTER: submitting job (6, 0, 5) to dispatcher
07:45:39 DISPATCHER: trying to submit job (6, 0, 5)
07:45:39 DISPATCHER: trying to notify the job_runner thread.
07:45:39 HBMASTER: job (6, 0, 5) submitted to dispatcher
07:45:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:45:39 DISPATCHER: Trying to submit another job.
07:45:39 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
07:45:39 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
07:45:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:45:39 WORKER: start processing job (6, 0, 5)
07:45:39 WORKER: args: ()
07:45:39 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 756, 'last_n_outputs': 43, 'leak_rate': 0.796641495072574, 'lr': 0.023811392904423745, 'optimizer': 'Adam', 'sparsity': 0.7823052604758651, 'steps_to_train': 67, 'weight_decay': 0.07261485807764216}, 'budget': 400.0, 'working_directory': '.'}
07:46:32 DISPATCHER: Starting worker discovery
07:46:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:46:32 DISPATCHER: Finished worker discovery
07:47:32 DISPATCHER: Starting worker discovery
07:47:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:47:32 DISPATCHER: Finished worker discovery
07:48:32 DISPATCHER: Starting worker discovery
07:48:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:48:32 DISPATCHER: Finished worker discovery
07:49:32 DISPATCHER: Starting worker discovery
07:49:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:49:32 DISPATCHER: Finished worker discovery
07:50:32 DISPATCHER: Starting worker discovery
07:50:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:50:32 DISPATCHER: Finished worker discovery
07:51:32 DISPATCHER: Starting worker discovery
07:51:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:51:32 DISPATCHER: Finished worker discovery
07:52:32 DISPATCHER: Starting worker discovery
07:52:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:52:32 DISPATCHER: Finished worker discovery
07:53:18 WORKER: done with job (6, 0, 5), trying to register it.
07:53:18 WORKER: registered result for job (6, 0, 5) with dispatcher
07:53:18 DISPATCHER: job (6, 0, 5) finished
07:53:18 DISPATCHER: register_result: lock acquired
07:53:18 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
07:53:18 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 756, 'last_n_outputs': 43, 'leak_rate': 0.796641495072574, 'lr': 0.023811392904423745, 'optimizer': 'Adam', 'sparsity': 0.7823052604758651, 'steps_to_train': 67, 'weight_decay': 0.07261485807764216}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.1429154924874571, 'info': {'data03': 0.1429154924874571, 'config': "{'batch_size': 16, 'hidden_dim': 756, 'last_n_outputs': 43, 'leak_rate': 0.796641495072574, 'lr': 0.023811392904423745, 'optimizer': 'Adam', 'sparsity': 0.7823052604758651, 'steps_to_train': 67, 'weight_decay': 0.07261485807764216}"}}
exception: None

07:53:18 job_callback for (6, 0, 5) started
07:53:18 DISPATCHER: Trying to submit another job.
07:53:18 job_callback for (6, 0, 5) got condition
07:53:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:53:18 done building a new model for budget 400.000000 based on 10/20 split
Best loss for this budget:-0.340020





07:53:18 HBMASTER: Trying to run another job!
07:53:18 job_callback for (6, 0, 5) finished
07:53:18 ITERATION: Advancing config (6, 0, 0) to next budget 1200.000000
07:53:18 ITERATION: Advancing config (6, 0, 2) to next budget 1200.000000
07:53:18 HBMASTER: schedule new run for iteration 6
07:53:18 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
07:53:18 HBMASTER: submitting job (6, 0, 0) to dispatcher
07:53:18 DISPATCHER: trying to submit job (6, 0, 0)
07:53:18 DISPATCHER: trying to notify the job_runner thread.
07:53:18 HBMASTER: job (6, 0, 0) submitted to dispatcher
07:53:18 DISPATCHER: Trying to submit another job.
07:53:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:53:18 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
07:53:18 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
07:53:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:53:18 WORKER: start processing job (6, 0, 0)
07:53:18 WORKER: args: ()
07:53:18 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 768, 'last_n_outputs': 39, 'leak_rate': 0.8564412307419493, 'lr': 0.004689870927578098, 'optimizer': 'Adam', 'sparsity': 0.9418805164860987, 'steps_to_train': 97, 'weight_decay': 0.01568746578228537}, 'budget': 1200.0, 'working_directory': '.'}
07:53:32 DISPATCHER: Starting worker discovery
07:53:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:53:32 DISPATCHER: Finished worker discovery
07:54:32 DISPATCHER: Starting worker discovery
07:54:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:54:32 DISPATCHER: Finished worker discovery
07:55:32 DISPATCHER: Starting worker discovery
07:55:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:55:32 DISPATCHER: Finished worker discovery
07:56:32 DISPATCHER: Starting worker discovery
07:56:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:56:32 DISPATCHER: Finished worker discovery
07:57:32 DISPATCHER: Starting worker discovery
07:57:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:57:32 DISPATCHER: Finished worker discovery
07:58:32 DISPATCHER: Starting worker discovery
07:58:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:58:32 DISPATCHER: Finished worker discovery
07:59:32 DISPATCHER: Starting worker discovery
07:59:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:59:32 DISPATCHER: Finished worker discovery
08:00:32 DISPATCHER: Starting worker discovery
08:00:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:00:32 DISPATCHER: Finished worker discovery
08:01:32 DISPATCHER: Starting worker discovery
08:01:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:01:32 DISPATCHER: Finished worker discovery
08:02:32 DISPATCHER: Starting worker discovery
08:02:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:02:32 DISPATCHER: Finished worker discovery
08:03:32 DISPATCHER: Starting worker discovery
08:03:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:03:32 DISPATCHER: Finished worker discovery
08:04:32 DISPATCHER: Starting worker discovery
08:04:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:04:32 DISPATCHER: Finished worker discovery
08:05:32 DISPATCHER: Starting worker discovery
08:05:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:05:32 DISPATCHER: Finished worker discovery
08:06:32 DISPATCHER: Starting worker discovery
08:06:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:06:32 DISPATCHER: Finished worker discovery
08:07:32 DISPATCHER: Starting worker discovery
08:07:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:07:32 DISPATCHER: Finished worker discovery
08:08:32 DISPATCHER: Starting worker discovery
08:08:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:08:32 DISPATCHER: Finished worker discovery
08:09:32 DISPATCHER: Starting worker discovery
08:09:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:09:32 DISPATCHER: Finished worker discovery
08:10:32 DISPATCHER: Starting worker discovery
08:10:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:10:32 DISPATCHER: Finished worker discovery
08:11:32 DISPATCHER: Starting worker discovery
08:11:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:11:32 DISPATCHER: Finished worker discovery
08:12:32 DISPATCHER: Starting worker discovery
08:12:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:12:32 DISPATCHER: Finished worker discovery
08:13:32 DISPATCHER: Starting worker discovery
08:13:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:13:32 DISPATCHER: Finished worker discovery
08:14:32 DISPATCHER: Starting worker discovery
08:14:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:14:32 DISPATCHER: Finished worker discovery
08:14:36 WORKER: done with job (6, 0, 0), trying to register it.
08:14:36 WORKER: registered result for job (6, 0, 0) with dispatcher
08:14:36 DISPATCHER: job (6, 0, 0) finished
08:14:36 DISPATCHER: register_result: lock acquired
08:14:36 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
08:14:36 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 768, 'last_n_outputs': 39, 'leak_rate': 0.8564412307419493, 'lr': 0.004689870927578098, 'optimizer': 'Adam', 'sparsity': 0.9418805164860987, 'steps_to_train': 97, 'weight_decay': 0.01568746578228537}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.2872592112289193, 'info': {'data03': 0.2872592112289193, 'config': "{'batch_size': 128, 'hidden_dim': 768, 'last_n_outputs': 39, 'leak_rate': 0.8564412307419493, 'lr': 0.004689870927578098, 'optimizer': 'Adam', 'sparsity': 0.9418805164860987, 'steps_to_train': 97, 'weight_decay': 0.01568746578228537}"}}
exception: None

08:14:36 job_callback for (6, 0, 0) started
08:14:36 job_callback for (6, 0, 0) got condition
08:14:36 DISPATCHER: Trying to submit another job.
08:14:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:14:36 HBMASTER: Trying to run another job!
08:14:36 job_callback for (6, 0, 0) finished
08:14:36 HBMASTER: schedule new run for iteration 6
08:14:36 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
08:14:36 HBMASTER: submitting job (6, 0, 2) to dispatcher
08:14:36 DISPATCHER: trying to submit job (6, 0, 2)
08:14:36 DISPATCHER: trying to notify the job_runner thread.
08:14:36 HBMASTER: job (6, 0, 2) submitted to dispatcher
08:14:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:14:36 DISPATCHER: Trying to submit another job.
08:14:36 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
08:14:36 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
08:14:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:14:36 WORKER: start processing job (6, 0, 2)
08:14:36 WORKER: args: ()
08:14:36 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 710, 'last_n_outputs': 45, 'leak_rate': 0.9501655955494055, 'lr': 0.002028178629550587, 'optimizer': 'Adam', 'sparsity': 0.8716118424924504, 'steps_to_train': 96, 'weight_decay': 0.03072873422737541}, 'budget': 1200.0, 'working_directory': '.'}
08:15:32 DISPATCHER: Starting worker discovery
08:15:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:15:32 DISPATCHER: Finished worker discovery
08:16:32 DISPATCHER: Starting worker discovery
08:16:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:16:32 DISPATCHER: Finished worker discovery
08:17:32 DISPATCHER: Starting worker discovery
08:17:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:17:32 DISPATCHER: Finished worker discovery
08:18:32 DISPATCHER: Starting worker discovery
08:18:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:18:32 DISPATCHER: Finished worker discovery
08:19:32 DISPATCHER: Starting worker discovery
08:19:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:19:32 DISPATCHER: Finished worker discovery
08:20:32 DISPATCHER: Starting worker discovery
08:20:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:20:32 DISPATCHER: Finished worker discovery
08:21:32 DISPATCHER: Starting worker discovery
08:21:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:21:32 DISPATCHER: Finished worker discovery
08:22:32 DISPATCHER: Starting worker discovery
08:22:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:22:32 DISPATCHER: Finished worker discovery
08:23:32 DISPATCHER: Starting worker discovery
08:23:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:23:32 DISPATCHER: Finished worker discovery
08:24:32 DISPATCHER: Starting worker discovery
08:24:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:24:32 DISPATCHER: Finished worker discovery
08:25:32 DISPATCHER: Starting worker discovery
08:25:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:25:32 DISPATCHER: Finished worker discovery
08:26:32 DISPATCHER: Starting worker discovery
08:26:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:26:32 DISPATCHER: Finished worker discovery
08:27:32 DISPATCHER: Starting worker discovery
08:27:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:27:32 DISPATCHER: Finished worker discovery
08:28:32 DISPATCHER: Starting worker discovery
08:28:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:28:32 DISPATCHER: Finished worker discovery
08:29:32 DISPATCHER: Starting worker discovery
08:29:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:29:32 DISPATCHER: Finished worker discovery
08:30:32 DISPATCHER: Starting worker discovery
08:30:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:30:33 DISPATCHER: Finished worker discovery
08:31:33 DISPATCHER: Starting worker discovery
08:31:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:31:33 DISPATCHER: Finished worker discovery
08:32:33 DISPATCHER: Starting worker discovery
08:32:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:32:33 DISPATCHER: Finished worker discovery
08:33:33 DISPATCHER: Starting worker discovery
08:33:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:33:33 DISPATCHER: Finished worker discovery
08:34:33 DISPATCHER: Starting worker discovery
08:34:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:34:33 DISPATCHER: Finished worker discovery
08:35:31 WORKER: done with job (6, 0, 2), trying to register it.
08:35:31 WORKER: registered result for job (6, 0, 2) with dispatcher
08:35:31 DISPATCHER: job (6, 0, 2) finished
08:35:31 DISPATCHER: register_result: lock acquired
08:35:31 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
08:35:31 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 710, 'last_n_outputs': 45, 'leak_rate': 0.9501655955494055, 'lr': 0.002028178629550587, 'optimizer': 'Adam', 'sparsity': 0.8716118424924504, 'steps_to_train': 96, 'weight_decay': 0.03072873422737541}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.2538242163288814, 'info': {'data03': 0.2538242163288814, 'config': "{'batch_size': 32, 'hidden_dim': 710, 'last_n_outputs': 45, 'leak_rate': 0.9501655955494055, 'lr': 0.002028178629550587, 'optimizer': 'Adam', 'sparsity': 0.8716118424924504, 'steps_to_train': 96, 'weight_decay': 0.03072873422737541}"}}
exception: None

08:35:31 job_callback for (6, 0, 2) started
08:35:31 DISPATCHER: Trying to submit another job.
08:35:31 job_callback for (6, 0, 2) got condition
08:35:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:35:31 HBMASTER: Trying to run another job!
08:35:31 job_callback for (6, 0, 2) finished
08:35:31 start sampling a new configuration.
08:35:31 best_vector: [0, 0.6694943537633832, 0.7854862834440371, 0.9128612882755959, 0.3534149547980984, 0, 0.9238869735355977, 0.8600062909331061, 0.7715399692680311], 4.2500000037689485e-31, 0.023529411743839733, -0.0013307208203790254
08:35:31 done sampling a new configuration.
08:35:31 HBMASTER: schedule new run for iteration 7
08:35:31 HBMASTER: trying submitting job (7, 0, 0) to dispatcher
08:35:31 HBMASTER: submitting job (7, 0, 0) to dispatcher
08:35:31 DISPATCHER: trying to submit job (7, 0, 0)
08:35:31 DISPATCHER: trying to notify the job_runner thread.
08:35:31 HBMASTER: job (7, 0, 0) submitted to dispatcher
08:35:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:35:31 DISPATCHER: Trying to submit another job.
08:35:31 DISPATCHER: starting job (7, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
08:35:31 DISPATCHER: job (7, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
08:35:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:35:31 WORKER: start processing job (7, 0, 0)
08:35:31 WORKER: args: ()
08:35:31 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 736, 'last_n_outputs': 42, 'leak_rate': 0.9782153220688989, 'lr': 0.005091314318870356, 'optimizer': 'Adam', 'sparsity': 0.9717328736485434, 'steps_to_train': 88, 'weight_decay': 0.10087804169715262}, 'budget': 1200.0, 'working_directory': '.'}
08:35:33 DISPATCHER: Starting worker discovery
08:35:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:35:33 DISPATCHER: Finished worker discovery
08:36:33 DISPATCHER: Starting worker discovery
08:36:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:36:33 DISPATCHER: Finished worker discovery
08:37:33 DISPATCHER: Starting worker discovery
08:37:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:37:33 DISPATCHER: Finished worker discovery
08:38:33 DISPATCHER: Starting worker discovery
08:38:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:38:33 DISPATCHER: Finished worker discovery
08:39:33 DISPATCHER: Starting worker discovery
08:39:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:39:33 DISPATCHER: Finished worker discovery
08:40:33 DISPATCHER: Starting worker discovery
08:40:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:40:33 DISPATCHER: Finished worker discovery
08:41:33 DISPATCHER: Starting worker discovery
08:41:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:41:33 DISPATCHER: Finished worker discovery
08:42:33 DISPATCHER: Starting worker discovery
08:42:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:42:33 DISPATCHER: Finished worker discovery
08:43:33 DISPATCHER: Starting worker discovery
08:43:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:43:33 DISPATCHER: Finished worker discovery
08:44:33 DISPATCHER: Starting worker discovery
08:44:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:44:33 DISPATCHER: Finished worker discovery
08:45:33 DISPATCHER: Starting worker discovery
08:45:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:45:33 DISPATCHER: Finished worker discovery
08:46:33 DISPATCHER: Starting worker discovery
08:46:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:46:33 DISPATCHER: Finished worker discovery
08:47:33 DISPATCHER: Starting worker discovery
08:47:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:47:33 DISPATCHER: Finished worker discovery
08:48:33 DISPATCHER: Starting worker discovery
08:48:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:48:33 DISPATCHER: Finished worker discovery
08:49:33 DISPATCHER: Starting worker discovery
08:49:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:49:33 DISPATCHER: Finished worker discovery
08:50:33 DISPATCHER: Starting worker discovery
08:50:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:50:33 DISPATCHER: Finished worker discovery
08:51:33 DISPATCHER: Starting worker discovery
08:51:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:51:33 DISPATCHER: Finished worker discovery
08:52:33 DISPATCHER: Starting worker discovery
08:52:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:52:33 DISPATCHER: Finished worker discovery
08:53:33 DISPATCHER: Starting worker discovery
08:53:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:53:33 DISPATCHER: Finished worker discovery
08:54:33 DISPATCHER: Starting worker discovery
08:54:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:54:33 DISPATCHER: Finished worker discovery
08:55:33 DISPATCHER: Starting worker discovery
08:55:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:55:33 DISPATCHER: Finished worker discovery
08:56:33 DISPATCHER: Starting worker discovery
08:56:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:56:33 DISPATCHER: Finished worker discovery
08:56:51 WORKER: done with job (7, 0, 0), trying to register it.
08:56:51 WORKER: registered result for job (7, 0, 0) with dispatcher
08:56:51 DISPATCHER: job (7, 0, 0) finished
08:56:51 DISPATCHER: register_result: lock acquired
08:56:51 DISPATCHER: job (7, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
08:56:51 job_id: (7, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 736, 'last_n_outputs': 42, 'leak_rate': 0.9782153220688989, 'lr': 0.005091314318870356, 'optimizer': 'Adam', 'sparsity': 0.9717328736485434, 'steps_to_train': 88, 'weight_decay': 0.10087804169715262}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.13279618627415923, 'info': {'data03': 0.13279618627415923, 'config': "{'batch_size': 16, 'hidden_dim': 736, 'last_n_outputs': 42, 'leak_rate': 0.9782153220688989, 'lr': 0.005091314318870356, 'optimizer': 'Adam', 'sparsity': 0.9717328736485434, 'steps_to_train': 88, 'weight_decay': 0.10087804169715262}"}}
exception: None

08:56:51 job_callback for (7, 0, 0) started
08:56:51 job_callback for (7, 0, 0) got condition
08:56:51 DISPATCHER: Trying to submit another job.
08:56:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:56:51 HBMASTER: Trying to run another job!
08:56:51 job_callback for (7, 0, 0) finished
08:56:51 start sampling a new configuration.
08:56:51 best_vector: [0, 0.6726745351810247, 0.7754095605272843, 0.7224436417022609, 0.03828912103692464, 0, 0.40374815565879074, 0.7279712474527182, 0.5615047098851562], 1.4192617633312356e-32, 0.704591658731677, -0.016362884638844936
08:56:51 done sampling a new configuration.
08:56:51 HBMASTER: schedule new run for iteration 7
08:56:51 HBMASTER: trying submitting job (7, 0, 1) to dispatcher
08:56:51 HBMASTER: submitting job (7, 0, 1) to dispatcher
08:56:51 DISPATCHER: trying to submit job (7, 0, 1)
08:56:51 DISPATCHER: trying to notify the job_runner thread.
08:56:51 HBMASTER: job (7, 0, 1) submitted to dispatcher
08:56:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:56:51 DISPATCHER: Trying to submit another job.
08:56:51 DISPATCHER: starting job (7, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
08:56:51 DISPATCHER: job (7, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
08:56:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:56:51 WORKER: start processing job (7, 0, 1)
08:56:51 WORKER: args: ()
08:56:51 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 738, 'last_n_outputs': 41, 'leak_rate': 0.9306109104255652, 'lr': 0.0011928291454442379, 'optimizer': 'Adam', 'sparsity': 0.8468995573581097, 'steps_to_train': 76, 'weight_decay': 0.05376931085196245}, 'budget': 1200.0, 'working_directory': '.'}
08:57:33 DISPATCHER: Starting worker discovery
08:57:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:57:33 DISPATCHER: Finished worker discovery
08:58:33 DISPATCHER: Starting worker discovery
08:58:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:58:33 DISPATCHER: Finished worker discovery
08:59:33 DISPATCHER: Starting worker discovery
08:59:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:59:33 DISPATCHER: Finished worker discovery
09:00:33 DISPATCHER: Starting worker discovery
09:00:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:00:33 DISPATCHER: Finished worker discovery
09:01:33 DISPATCHER: Starting worker discovery
09:01:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:01:33 DISPATCHER: Finished worker discovery
09:02:33 DISPATCHER: Starting worker discovery
09:02:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:02:33 DISPATCHER: Finished worker discovery
09:03:33 DISPATCHER: Starting worker discovery
09:03:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:03:33 DISPATCHER: Finished worker discovery
09:04:33 DISPATCHER: Starting worker discovery
09:04:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:04:33 DISPATCHER: Finished worker discovery
09:05:33 DISPATCHER: Starting worker discovery
09:05:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:05:33 DISPATCHER: Finished worker discovery
09:06:33 DISPATCHER: Starting worker discovery
09:06:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:06:33 DISPATCHER: Finished worker discovery
09:07:33 DISPATCHER: Starting worker discovery
09:07:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:07:33 DISPATCHER: Finished worker discovery
09:08:33 DISPATCHER: Starting worker discovery
09:08:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:08:33 DISPATCHER: Finished worker discovery
09:09:33 DISPATCHER: Starting worker discovery
09:09:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:09:33 DISPATCHER: Finished worker discovery
09:10:33 DISPATCHER: Starting worker discovery
09:10:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:10:33 DISPATCHER: Finished worker discovery
09:11:33 DISPATCHER: Starting worker discovery
09:11:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:11:33 DISPATCHER: Finished worker discovery
09:12:33 DISPATCHER: Starting worker discovery
09:12:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:12:33 DISPATCHER: Finished worker discovery
09:13:33 DISPATCHER: Starting worker discovery
09:13:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:13:33 DISPATCHER: Finished worker discovery
09:14:33 DISPATCHER: Starting worker discovery
09:14:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:14:33 DISPATCHER: Finished worker discovery
09:15:33 DISPATCHER: Starting worker discovery
09:15:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:15:33 DISPATCHER: Finished worker discovery
09:16:33 DISPATCHER: Starting worker discovery
09:16:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:16:33 DISPATCHER: Finished worker discovery
09:17:33 DISPATCHER: Starting worker discovery
09:17:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:17:33 DISPATCHER: Finished worker discovery
09:17:47 WORKER: done with job (7, 0, 1), trying to register it.
09:17:47 WORKER: registered result for job (7, 0, 1) with dispatcher
09:17:47 DISPATCHER: job (7, 0, 1) finished
09:17:47 DISPATCHER: register_result: lock acquired
09:17:47 DISPATCHER: job (7, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
09:17:47 job_id: (7, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 738, 'last_n_outputs': 41, 'leak_rate': 0.9306109104255652, 'lr': 0.0011928291454442379, 'optimizer': 'Adam', 'sparsity': 0.8468995573581097, 'steps_to_train': 76, 'weight_decay': 0.05376931085196245}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.27341111756148584, 'info': {'data03': 0.27341111756148584, 'config': "{'batch_size': 16, 'hidden_dim': 738, 'last_n_outputs': 41, 'leak_rate': 0.9306109104255652, 'lr': 0.0011928291454442379, 'optimizer': 'Adam', 'sparsity': 0.8468995573581097, 'steps_to_train': 76, 'weight_decay': 0.05376931085196245}"}}
exception: None

09:17:47 job_callback for (7, 0, 1) started
09:17:47 DISPATCHER: Trying to submit another job.
09:17:47 job_callback for (7, 0, 1) got condition
09:17:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:17:47 HBMASTER: Trying to run another job!
09:17:47 job_callback for (7, 0, 1) finished
09:17:47 start sampling a new configuration.
09:17:47 best_vector: [0, 0.5138539043743489, 0.5584002438164688, 0.2101865261334085, 0.21876173073086036, 1, 0.5171540423239384, 0.9052533468375084, 0.378095788389315], 6.303178704584018e-32, 0.15865011081991773, -0.028450579097772776
09:17:47 done sampling a new configuration.
09:17:47 HBMASTER: schedule new run for iteration 7
09:17:47 HBMASTER: trying submitting job (7, 0, 2) to dispatcher
09:17:47 HBMASTER: submitting job (7, 0, 2) to dispatcher
09:17:47 DISPATCHER: trying to submit job (7, 0, 2)
09:17:47 DISPATCHER: trying to notify the job_runner thread.
09:17:47 HBMASTER: job (7, 0, 2) submitted to dispatcher
09:17:47 DISPATCHER: Trying to submit another job.
09:17:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:17:47 DISPATCHER: starting job (7, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
09:17:47 DISPATCHER: job (7, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
09:17:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:17:47 WORKER: start processing job (7, 0, 2)
09:17:47 WORKER: args: ()
09:17:47 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 611, 'last_n_outputs': 32, 'leak_rate': 0.8025466315333522, 'lr': 0.0027385675731986976, 'optimizer': 'SGD', 'sparsity': 0.8741169701577451, 'steps_to_train': 92, 'weight_decay': 0.031039446048085065}, 'budget': 1200.0, 'working_directory': '.'}
09:18:33 DISPATCHER: Starting worker discovery
09:18:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:18:33 DISPATCHER: Finished worker discovery
09:19:33 DISPATCHER: Starting worker discovery
09:19:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:19:33 DISPATCHER: Finished worker discovery
09:20:33 DISPATCHER: Starting worker discovery
09:20:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:20:33 DISPATCHER: Finished worker discovery
09:21:33 DISPATCHER: Starting worker discovery
09:21:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:21:33 DISPATCHER: Finished worker discovery
09:22:33 DISPATCHER: Starting worker discovery
09:22:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:22:33 DISPATCHER: Finished worker discovery
09:23:33 DISPATCHER: Starting worker discovery
09:23:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:23:33 DISPATCHER: Finished worker discovery
09:24:33 DISPATCHER: Starting worker discovery
09:24:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:24:33 DISPATCHER: Finished worker discovery
09:25:33 DISPATCHER: Starting worker discovery
09:25:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:25:33 DISPATCHER: Finished worker discovery
09:26:33 DISPATCHER: Starting worker discovery
09:26:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:26:33 DISPATCHER: Finished worker discovery
09:27:33 DISPATCHER: Starting worker discovery
09:27:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:27:33 DISPATCHER: Finished worker discovery
09:28:33 DISPATCHER: Starting worker discovery
09:28:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:28:33 DISPATCHER: Finished worker discovery
09:29:33 DISPATCHER: Starting worker discovery
09:29:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:29:33 DISPATCHER: Finished worker discovery
09:30:33 DISPATCHER: Starting worker discovery
09:30:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:30:33 DISPATCHER: Finished worker discovery
09:31:33 DISPATCHER: Starting worker discovery
09:31:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:31:33 DISPATCHER: Finished worker discovery
09:32:33 DISPATCHER: Starting worker discovery
09:32:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:32:33 DISPATCHER: Finished worker discovery
09:33:33 DISPATCHER: Starting worker discovery
09:33:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:33:33 DISPATCHER: Finished worker discovery
09:34:33 DISPATCHER: Starting worker discovery
09:34:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:34:33 DISPATCHER: Finished worker discovery
09:35:33 DISPATCHER: Starting worker discovery
09:35:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:35:33 DISPATCHER: Finished worker discovery
09:36:33 DISPATCHER: Starting worker discovery
09:36:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:36:33 DISPATCHER: Finished worker discovery
09:37:33 DISPATCHER: Starting worker discovery
09:37:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:37:33 DISPATCHER: Finished worker discovery
09:38:33 DISPATCHER: Starting worker discovery
09:38:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:38:33 DISPATCHER: Finished worker discovery
09:38:37 WORKER: done with job (7, 0, 2), trying to register it.
09:38:37 WORKER: registered result for job (7, 0, 2) with dispatcher
09:38:37 DISPATCHER: job (7, 0, 2) finished
09:38:37 DISPATCHER: register_result: lock acquired
09:38:37 DISPATCHER: job (7, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
09:38:37 job_id: (7, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 611, 'last_n_outputs': 32, 'leak_rate': 0.8025466315333522, 'lr': 0.0027385675731986976, 'optimizer': 'SGD', 'sparsity': 0.8741169701577451, 'steps_to_train': 92, 'weight_decay': 0.031039446048085065}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.2318111075930529, 'info': {'data03': 0.2318111075930529, 'config': "{'batch_size': 16, 'hidden_dim': 611, 'last_n_outputs': 32, 'leak_rate': 0.8025466315333522, 'lr': 0.0027385675731986976, 'optimizer': 'SGD', 'sparsity': 0.8741169701577451, 'steps_to_train': 92, 'weight_decay': 0.031039446048085065}"}}
exception: None

09:38:37 job_callback for (7, 0, 2) started
09:38:37 DISPATCHER: Trying to submit another job.
09:38:37 job_callback for (7, 0, 2) got condition
09:38:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:38:37 HBMASTER: Trying to run another job!
09:38:37 job_callback for (7, 0, 2) finished
09:38:37 start sampling a new configuration.
09:38:37 done sampling a new configuration.
09:38:38 HBMASTER: schedule new run for iteration 7
09:38:38 HBMASTER: trying submitting job (7, 0, 3) to dispatcher
09:38:38 HBMASTER: submitting job (7, 0, 3) to dispatcher
09:38:38 DISPATCHER: trying to submit job (7, 0, 3)
09:38:38 DISPATCHER: trying to notify the job_runner thread.
09:38:38 HBMASTER: job (7, 0, 3) submitted to dispatcher
09:38:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:38:38 DISPATCHER: Trying to submit another job.
09:38:38 DISPATCHER: starting job (7, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
09:38:38 DISPATCHER: job (7, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
09:38:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:38:38 WORKER: start processing job (7, 0, 3)
09:38:38 WORKER: args: ()
09:38:38 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 372, 'last_n_outputs': 13, 'leak_rate': 0.8604419303379559, 'lr': 0.0016614802278988238, 'optimizer': 'SGD', 'sparsity': 0.8851548008993325, 'steps_to_train': 79, 'weight_decay': 0.021946723358165544}, 'budget': 1200.0, 'working_directory': '.'}
09:39:33 DISPATCHER: Starting worker discovery
09:39:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:39:33 DISPATCHER: Finished worker discovery
09:40:33 DISPATCHER: Starting worker discovery
09:40:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:40:33 DISPATCHER: Finished worker discovery
09:41:33 DISPATCHER: Starting worker discovery
09:41:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:41:33 DISPATCHER: Finished worker discovery
09:42:33 DISPATCHER: Starting worker discovery
09:42:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:42:33 DISPATCHER: Finished worker discovery
09:43:33 DISPATCHER: Starting worker discovery
09:43:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:43:33 DISPATCHER: Finished worker discovery
09:44:33 DISPATCHER: Starting worker discovery
09:44:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:44:33 DISPATCHER: Finished worker discovery
09:45:33 DISPATCHER: Starting worker discovery
09:45:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:45:33 DISPATCHER: Finished worker discovery
09:46:33 DISPATCHER: Starting worker discovery
09:46:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:46:33 DISPATCHER: Finished worker discovery
09:47:33 DISPATCHER: Starting worker discovery
09:47:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:47:33 DISPATCHER: Finished worker discovery
09:48:33 DISPATCHER: Starting worker discovery
09:48:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:48:33 DISPATCHER: Finished worker discovery
09:49:33 DISPATCHER: Starting worker discovery
09:49:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:49:33 DISPATCHER: Finished worker discovery
09:50:33 DISPATCHER: Starting worker discovery
09:50:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:50:33 DISPATCHER: Finished worker discovery
09:51:33 DISPATCHER: Starting worker discovery
09:51:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:51:33 DISPATCHER: Finished worker discovery
09:52:33 DISPATCHER: Starting worker discovery
09:52:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:52:33 DISPATCHER: Finished worker discovery
09:53:33 DISPATCHER: Starting worker discovery
09:53:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:53:33 DISPATCHER: Finished worker discovery
09:54:33 DISPATCHER: Starting worker discovery
09:54:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:54:33 DISPATCHER: Finished worker discovery
09:55:33 DISPATCHER: Starting worker discovery
09:55:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:55:33 DISPATCHER: Finished worker discovery
09:56:33 DISPATCHER: Starting worker discovery
09:56:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:56:33 DISPATCHER: Finished worker discovery
09:57:33 DISPATCHER: Starting worker discovery
09:57:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:57:33 DISPATCHER: Finished worker discovery
09:58:33 DISPATCHER: Starting worker discovery
09:58:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:58:33 DISPATCHER: Finished worker discovery
09:59:33 DISPATCHER: Starting worker discovery
09:59:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:59:33 DISPATCHER: Finished worker discovery
09:59:42 WORKER: done with job (7, 0, 3), trying to register it.
09:59:42 WORKER: registered result for job (7, 0, 3) with dispatcher
09:59:42 DISPATCHER: job (7, 0, 3) finished
09:59:42 DISPATCHER: register_result: lock acquired
09:59:42 DISPATCHER: job (7, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
09:59:42 job_id: (7, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 372, 'last_n_outputs': 13, 'leak_rate': 0.8604419303379559, 'lr': 0.0016614802278988238, 'optimizer': 'SGD', 'sparsity': 0.8851548008993325, 'steps_to_train': 79, 'weight_decay': 0.021946723358165544}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0690180275467211, 'info': {'data03': 0.0690180275467211, 'config': "{'batch_size': 32, 'hidden_dim': 372, 'last_n_outputs': 13, 'leak_rate': 0.8604419303379559, 'lr': 0.0016614802278988238, 'optimizer': 'SGD', 'sparsity': 0.8851548008993325, 'steps_to_train': 79, 'weight_decay': 0.021946723358165544}"}}
exception: None

09:59:42 job_callback for (7, 0, 3) started
09:59:42 job_callback for (7, 0, 3) got condition
09:59:42 DISPATCHER: Trying to submit another job.
09:59:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:59:42 HBMASTER: Trying to run another job!
09:59:42 job_callback for (7, 0, 3) finished
09:59:42 start sampling a new configuration.
09:59:42 done sampling a new configuration.
09:59:42 HBMASTER: schedule new run for iteration 8
09:59:42 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
09:59:42 HBMASTER: submitting job (8, 0, 0) to dispatcher
09:59:42 DISPATCHER: trying to submit job (8, 0, 0)
09:59:42 DISPATCHER: trying to notify the job_runner thread.
09:59:42 HBMASTER: job (8, 0, 0) submitted to dispatcher
09:59:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:59:42 DISPATCHER: Trying to submit another job.
09:59:42 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
09:59:42 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
09:59:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:59:42 WORKER: start processing job (8, 0, 0)
09:59:42 WORKER: args: ()
09:59:42 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 846, 'last_n_outputs': 21, 'leak_rate': 0.9532259099746182, 'lr': 0.00651893458753199, 'optimizer': 'SGD', 'sparsity': 0.9192607974183713, 'steps_to_train': 71, 'weight_decay': 0.06620647634505833}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:00:33 DISPATCHER: Starting worker discovery
10:00:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:00:33 DISPATCHER: Finished worker discovery
10:01:28 WORKER: done with job (8, 0, 0), trying to register it.
10:01:28 WORKER: registered result for job (8, 0, 0) with dispatcher
10:01:28 DISPATCHER: job (8, 0, 0) finished
10:01:28 DISPATCHER: register_result: lock acquired
10:01:28 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:01:28 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 846, 'last_n_outputs': 21, 'leak_rate': 0.9532259099746182, 'lr': 0.00651893458753199, 'optimizer': 'SGD', 'sparsity': 0.9192607974183713, 'steps_to_train': 71, 'weight_decay': 0.06620647634505833}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.22020705859361636, 'info': {'data03': 0.22020705859361636, 'config': "{'batch_size': 128, 'hidden_dim': 846, 'last_n_outputs': 21, 'leak_rate': 0.9532259099746182, 'lr': 0.00651893458753199, 'optimizer': 'SGD', 'sparsity': 0.9192607974183713, 'steps_to_train': 71, 'weight_decay': 0.06620647634505833}"}}
exception: None

10:01:28 job_callback for (8, 0, 0) started
10:01:28 job_callback for (8, 0, 0) got condition
10:01:28 DISPATCHER: Trying to submit another job.
10:01:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:01:28 HBMASTER: Trying to run another job!
10:01:28 job_callback for (8, 0, 0) finished
10:01:28 start sampling a new configuration.
10:01:29 best_vector: [0, 0.8134261201016229, 0.8521529041356953, 0.2800374368197355, 0.062460919246011604, 0, 0.3806390230268465, 0.9776440336073948, 0.3014522821453567], 1.694704189914631e-32, 0.5900734806411105, -0.031591426024713806
10:01:29 done sampling a new configuration.
10:01:29 HBMASTER: schedule new run for iteration 8
10:01:29 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
10:01:29 HBMASTER: submitting job (8, 0, 1) to dispatcher
10:01:29 DISPATCHER: trying to submit job (8, 0, 1)
10:01:29 DISPATCHER: trying to notify the job_runner thread.
10:01:29 HBMASTER: job (8, 0, 1) submitted to dispatcher
10:01:29 DISPATCHER: Trying to submit another job.
10:01:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:01:29 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:01:29 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:01:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:01:29 WORKER: start processing job (8, 0, 1)
10:01:29 WORKER: args: ()
10:01:29 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 851, 'last_n_outputs': 44, 'leak_rate': 0.8200093592049339, 'lr': 0.0013332814552084276, 'optimizer': 'Adam', 'sparsity': 0.8413533655264431, 'steps_to_train': 98, 'weight_decay': 0.0246716651088002}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:01:33 DISPATCHER: Starting worker discovery
10:01:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:01:33 DISPATCHER: Finished worker discovery
10:02:33 DISPATCHER: Starting worker discovery
10:02:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:02:33 DISPATCHER: Finished worker discovery
10:02:51 WORKER: done with job (8, 0, 1), trying to register it.
10:02:51 WORKER: registered result for job (8, 0, 1) with dispatcher
10:02:51 DISPATCHER: job (8, 0, 1) finished
10:02:51 DISPATCHER: register_result: lock acquired
10:02:51 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:02:51 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 851, 'last_n_outputs': 44, 'leak_rate': 0.8200093592049339, 'lr': 0.0013332814552084276, 'optimizer': 'Adam', 'sparsity': 0.8413533655264431, 'steps_to_train': 98, 'weight_decay': 0.0246716651088002}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 851, 'last_n_outputs': 44, 'leak_rate': 0.8200093592049339, 'lr': 0.0013332814552084276, 'optimizer': 'Adam', 'sparsity': 0.8413533655264431, 'steps_to_train': 98, 'weight_decay': 0.0246716651088002}"}}
exception: None

10:02:51 job_callback for (8, 0, 1) started
10:02:51 job_callback for (8, 0, 1) got condition
10:02:51 DISPATCHER: Trying to submit another job.
10:02:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:02:51 HBMASTER: Trying to run another job!
10:02:51 job_callback for (8, 0, 1) finished
10:02:51 start sampling a new configuration.
10:02:51 best_vector: [0, 0.6431269397424185, 0.6462938351089421, 0.002278997560127838, 0.6133035784127913, 0, 0.25375323124768223, 0.7221698041691402, 0.6485498057364654], 6.413952649789677e-33, 1.5591010015217242, -0.06020976990054019
10:02:51 done sampling a new configuration.
10:02:51 HBMASTER: schedule new run for iteration 8
10:02:51 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
10:02:51 HBMASTER: submitting job (8, 0, 2) to dispatcher
10:02:51 DISPATCHER: trying to submit job (8, 0, 2)
10:02:51 DISPATCHER: trying to notify the job_runner thread.
10:02:51 HBMASTER: job (8, 0, 2) submitted to dispatcher
10:02:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:02:51 DISPATCHER: Trying to submit another job.
10:02:51 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:02:51 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:02:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:02:51 WORKER: start processing job (8, 0, 2)
10:02:51 WORKER: args: ()
10:02:51 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 715, 'last_n_outputs': 36, 'leak_rate': 0.750569749390032, 'lr': 0.016850281354685182, 'optimizer': 'Adam', 'sparsity': 0.8109007754994437, 'steps_to_train': 75, 'weight_decay': 0.0697883211531317}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:03:33 DISPATCHER: Starting worker discovery
10:03:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:03:33 DISPATCHER: Finished worker discovery
10:04:33 DISPATCHER: Starting worker discovery
10:04:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:04:33 DISPATCHER: Finished worker discovery
10:04:38 WORKER: done with job (8, 0, 2), trying to register it.
10:04:38 WORKER: registered result for job (8, 0, 2) with dispatcher
10:04:38 DISPATCHER: job (8, 0, 2) finished
10:04:38 DISPATCHER: register_result: lock acquired
10:04:38 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:04:38 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 715, 'last_n_outputs': 36, 'leak_rate': 0.750569749390032, 'lr': 0.016850281354685182, 'optimizer': 'Adam', 'sparsity': 0.8109007754994437, 'steps_to_train': 75, 'weight_decay': 0.0697883211531317}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.021889586565076845, 'info': {'data03': 0.021889586565076845, 'config': "{'batch_size': 16, 'hidden_dim': 715, 'last_n_outputs': 36, 'leak_rate': 0.750569749390032, 'lr': 0.016850281354685182, 'optimizer': 'Adam', 'sparsity': 0.8109007754994437, 'steps_to_train': 75, 'weight_decay': 0.0697883211531317}"}}
exception: None

10:04:38 job_callback for (8, 0, 2) started
10:04:38 DISPATCHER: Trying to submit another job.
10:04:38 job_callback for (8, 0, 2) got condition
10:04:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:04:38 HBMASTER: Trying to run another job!
10:04:38 job_callback for (8, 0, 2) finished
10:04:38 start sampling a new configuration.
10:04:38 best_vector: [0, 0.5208301951159513, 0.9671579196962299, 0.5124974728408173, 0.04963997924191317, 1, 0.8101357736799414, 0.5953951465982298, 0.31650887228430025], 6.915493603798251e-33, 1.4460283781489758, -0.0025038128279074047
10:04:38 done sampling a new configuration.
10:04:38 HBMASTER: schedule new run for iteration 8
10:04:38 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
10:04:38 HBMASTER: submitting job (8, 0, 3) to dispatcher
10:04:38 DISPATCHER: trying to submit job (8, 0, 3)
10:04:38 DISPATCHER: trying to notify the job_runner thread.
10:04:38 HBMASTER: job (8, 0, 3) submitted to dispatcher
10:04:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:04:38 DISPATCHER: Trying to submit another job.
10:04:38 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:04:38 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:04:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:04:38 WORKER: start processing job (8, 0, 3)
10:04:38 WORKER: args: ()
10:04:38 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 617, 'last_n_outputs': 49, 'leak_rate': 0.8781243682102043, 'lr': 0.0012568398970940235, 'optimizer': 'SGD', 'sparsity': 0.9444325856831859, 'steps_to_train': 64, 'weight_decay': 0.025809972198303208}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:05:33 DISPATCHER: Starting worker discovery
10:05:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:05:33 DISPATCHER: Finished worker discovery
10:06:25 WORKER: done with job (8, 0, 3), trying to register it.
10:06:25 WORKER: registered result for job (8, 0, 3) with dispatcher
10:06:25 DISPATCHER: job (8, 0, 3) finished
10:06:25 DISPATCHER: register_result: lock acquired
10:06:25 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:06:25 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 617, 'last_n_outputs': 49, 'leak_rate': 0.8781243682102043, 'lr': 0.0012568398970940235, 'optimizer': 'SGD', 'sparsity': 0.9444325856831859, 'steps_to_train': 64, 'weight_decay': 0.025809972198303208}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.23876756163902543, 'info': {'data03': 0.23876756163902543, 'config': "{'batch_size': 16, 'hidden_dim': 617, 'last_n_outputs': 49, 'leak_rate': 0.8781243682102043, 'lr': 0.0012568398970940235, 'optimizer': 'SGD', 'sparsity': 0.9444325856831859, 'steps_to_train': 64, 'weight_decay': 0.025809972198303208}"}}
exception: None

10:06:25 job_callback for (8, 0, 3) started
10:06:25 DISPATCHER: Trying to submit another job.
10:06:25 job_callback for (8, 0, 3) got condition
10:06:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:06:25 HBMASTER: Trying to run another job!
10:06:25 job_callback for (8, 0, 3) finished
10:06:25 start sampling a new configuration.
10:06:25 best_vector: [0, 0.6164520223913018, 0.9270956094081277, 0.6438603447897843, 0.25146864019575865, 0, 0.6514192787167651, 0.8614559998843256, 0.25955812246857524], 1.1312947363537413e-33, 8.839429441907285, -0.016362866166979052
10:06:25 done sampling a new configuration.
10:06:25 HBMASTER: schedule new run for iteration 8
10:06:25 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
10:06:25 HBMASTER: submitting job (8, 0, 4) to dispatcher
10:06:25 DISPATCHER: trying to submit job (8, 0, 4)
10:06:25 DISPATCHER: trying to notify the job_runner thread.
10:06:25 HBMASTER: job (8, 0, 4) submitted to dispatcher
10:06:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:06:25 DISPATCHER: Trying to submit another job.
10:06:25 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:06:25 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:06:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:06:25 WORKER: start processing job (8, 0, 4)
10:06:25 WORKER: args: ()
10:06:25 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 693, 'last_n_outputs': 48, 'leak_rate': 0.9109650861974461, 'lr': 0.0031837377019264066, 'optimizer': 'Adam', 'sparsity': 0.9063406268920235, 'steps_to_train': 88, 'weight_decay': 0.021761704208715215}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:06:33 DISPATCHER: Starting worker discovery
10:06:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:06:33 DISPATCHER: Finished worker discovery
10:07:33 DISPATCHER: Starting worker discovery
10:07:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:07:33 DISPATCHER: Finished worker discovery
10:07:52 WORKER: done with job (8, 0, 4), trying to register it.
10:07:52 WORKER: registered result for job (8, 0, 4) with dispatcher
10:07:52 DISPATCHER: job (8, 0, 4) finished
10:07:52 DISPATCHER: register_result: lock acquired
10:07:52 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:07:52 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 693, 'last_n_outputs': 48, 'leak_rate': 0.9109650861974461, 'lr': 0.0031837377019264066, 'optimizer': 'Adam', 'sparsity': 0.9063406268920235, 'steps_to_train': 88, 'weight_decay': 0.021761704208715215}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 693, 'last_n_outputs': 48, 'leak_rate': 0.9109650861974461, 'lr': 0.0031837377019264066, 'optimizer': 'Adam', 'sparsity': 0.9063406268920235, 'steps_to_train': 88, 'weight_decay': 0.021761704208715215}"}}
exception: None

10:07:52 job_callback for (8, 0, 4) started
10:07:52 DISPATCHER: Trying to submit another job.
10:07:52 job_callback for (8, 0, 4) got condition
10:07:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:07:52 HBMASTER: Trying to run another job!
10:07:52 job_callback for (8, 0, 4) finished
10:07:52 start sampling a new configuration.
10:07:52 done sampling a new configuration.
10:07:52 HBMASTER: schedule new run for iteration 8
10:07:52 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
10:07:52 HBMASTER: submitting job (8, 0, 5) to dispatcher
10:07:52 DISPATCHER: trying to submit job (8, 0, 5)
10:07:52 DISPATCHER: trying to notify the job_runner thread.
10:07:52 HBMASTER: job (8, 0, 5) submitted to dispatcher
10:07:52 DISPATCHER: Trying to submit another job.
10:07:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:07:52 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:07:52 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:07:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:07:52 WORKER: start processing job (8, 0, 5)
10:07:52 WORKER: args: ()
10:07:52 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 588, 'last_n_outputs': 20, 'leak_rate': 0.9307169931387157, 'lr': 0.005202668633003543, 'optimizer': 'SGD', 'sparsity': 0.9181493504473182, 'steps_to_train': 22, 'weight_decay': 0.057166848242246555}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:08:33 DISPATCHER: Starting worker discovery
10:08:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:08:33 DISPATCHER: Finished worker discovery
10:09:15 WORKER: done with job (8, 0, 5), trying to register it.
10:09:15 WORKER: registered result for job (8, 0, 5) with dispatcher
10:09:15 DISPATCHER: job (8, 0, 5) finished
10:09:15 DISPATCHER: register_result: lock acquired
10:09:15 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:09:15 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 588, 'last_n_outputs': 20, 'leak_rate': 0.9307169931387157, 'lr': 0.005202668633003543, 'optimizer': 'SGD', 'sparsity': 0.9181493504473182, 'steps_to_train': 22, 'weight_decay': 0.057166848242246555}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 588, 'last_n_outputs': 20, 'leak_rate': 0.9307169931387157, 'lr': 0.005202668633003543, 'optimizer': 'SGD', 'sparsity': 0.9181493504473182, 'steps_to_train': 22, 'weight_decay': 0.057166848242246555}"}}
exception: None

10:09:15 job_callback for (8, 0, 5) started
10:09:15 DISPATCHER: Trying to submit another job.
10:09:15 job_callback for (8, 0, 5) got condition
10:09:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:09:15 HBMASTER: Trying to run another job!
10:09:15 job_callback for (8, 0, 5) finished
10:09:15 start sampling a new configuration.
10:09:15 done sampling a new configuration.
10:09:15 HBMASTER: schedule new run for iteration 8
10:09:15 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
10:09:15 HBMASTER: submitting job (8, 0, 6) to dispatcher
10:09:15 DISPATCHER: trying to submit job (8, 0, 6)
10:09:15 DISPATCHER: trying to notify the job_runner thread.
10:09:15 HBMASTER: job (8, 0, 6) submitted to dispatcher
10:09:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:09:15 DISPATCHER: Trying to submit another job.
10:09:15 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:09:15 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:09:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:09:15 WORKER: start processing job (8, 0, 6)
10:09:15 WORKER: args: ()
10:09:15 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 559, 'last_n_outputs': 28, 'leak_rate': 0.9626426835679646, 'lr': 0.03205111275371613, 'optimizer': 'SGD', 'sparsity': 0.9830280930772746, 'steps_to_train': 56, 'weight_decay': 0.05520910901629069}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:09:33 DISPATCHER: Starting worker discovery
10:09:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:09:33 DISPATCHER: Finished worker discovery
10:10:33 DISPATCHER: Starting worker discovery
10:10:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:10:33 DISPATCHER: Finished worker discovery
10:10:41 WORKER: done with job (8, 0, 6), trying to register it.
10:10:41 WORKER: registered result for job (8, 0, 6) with dispatcher
10:10:41 DISPATCHER: job (8, 0, 6) finished
10:10:41 DISPATCHER: register_result: lock acquired
10:10:41 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:10:41 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 559, 'last_n_outputs': 28, 'leak_rate': 0.9626426835679646, 'lr': 0.03205111275371613, 'optimizer': 'SGD', 'sparsity': 0.9830280930772746, 'steps_to_train': 56, 'weight_decay': 0.05520910901629069}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 559, 'last_n_outputs': 28, 'leak_rate': 0.9626426835679646, 'lr': 0.03205111275371613, 'optimizer': 'SGD', 'sparsity': 0.9830280930772746, 'steps_to_train': 56, 'weight_decay': 0.05520910901629069}"}}
exception: None

10:10:41 job_callback for (8, 0, 6) started
10:10:41 job_callback for (8, 0, 6) got condition
10:10:41 DISPATCHER: Trying to submit another job.
10:10:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:10:41 HBMASTER: Trying to run another job!
10:10:41 job_callback for (8, 0, 6) finished
10:10:41 start sampling a new configuration.
10:10:41 best_vector: [0, 0.7718059705382427, 0.594508919605242, 0.28674892522450474, 0.4613257555114614, 1, 0.5717484656232275, 0.6290050704006845, 0.24927311850530248], 1.3836728821768113e-31, 0.07227141710161926, -0.01070472540731558
10:10:41 done sampling a new configuration.
10:10:41 HBMASTER: schedule new run for iteration 8
10:10:41 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
10:10:41 HBMASTER: submitting job (8, 0, 7) to dispatcher
10:10:41 DISPATCHER: trying to submit job (8, 0, 7)
10:10:41 DISPATCHER: trying to notify the job_runner thread.
10:10:41 HBMASTER: job (8, 0, 7) submitted to dispatcher
10:10:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:10:41 DISPATCHER: Trying to submit another job.
10:10:41 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:10:41 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:10:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:10:41 WORKER: start processing job (8, 0, 7)
10:10:41 WORKER: args: ()
10:10:41 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 818, 'last_n_outputs': 34, 'leak_rate': 0.8216872313061262, 'lr': 0.008368574968189506, 'optimizer': 'SGD', 'sparsity': 0.8872196317495746, 'steps_to_train': 67, 'weight_decay': 0.02110142595554022}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:11:33 DISPATCHER: Starting worker discovery
10:11:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:11:33 DISPATCHER: Finished worker discovery
10:12:20 WORKER: done with job (8, 0, 7), trying to register it.
10:12:20 WORKER: registered result for job (8, 0, 7) with dispatcher
10:12:20 DISPATCHER: job (8, 0, 7) finished
10:12:20 DISPATCHER: register_result: lock acquired
10:12:20 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:12:20 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 818, 'last_n_outputs': 34, 'leak_rate': 0.8216872313061262, 'lr': 0.008368574968189506, 'optimizer': 'SGD', 'sparsity': 0.8872196317495746, 'steps_to_train': 67, 'weight_decay': 0.02110142595554022}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.05157648291905685, 'info': {'data03': 0.05157648291905685, 'config': "{'batch_size': 16, 'hidden_dim': 818, 'last_n_outputs': 34, 'leak_rate': 0.8216872313061262, 'lr': 0.008368574968189506, 'optimizer': 'SGD', 'sparsity': 0.8872196317495746, 'steps_to_train': 67, 'weight_decay': 0.02110142595554022}"}}
exception: None

10:12:20 job_callback for (8, 0, 7) started
10:12:20 job_callback for (8, 0, 7) got condition
10:12:20 DISPATCHER: Trying to submit another job.
10:12:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:12:20 HBMASTER: Trying to run another job!
10:12:20 job_callback for (8, 0, 7) finished
10:12:20 start sampling a new configuration.
10:12:20 best_vector: [0, 0.3024252354250715, 0.9319570167226666, 0.6810741575219821, 0.1402832702916076, 0, 0.8154195586398688, 0.6444423443630396, 0.20184840612175833], 3.231208109314332e-33, 3.094817684807686, -0.000576067768367128
10:12:20 done sampling a new configuration.
10:12:20 HBMASTER: schedule new run for iteration 8
10:12:20 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
10:12:20 HBMASTER: submitting job (8, 0, 8) to dispatcher
10:12:20 DISPATCHER: trying to submit job (8, 0, 8)
10:12:20 DISPATCHER: trying to notify the job_runner thread.
10:12:20 HBMASTER: job (8, 0, 8) submitted to dispatcher
10:12:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:12:20 DISPATCHER: Trying to submit another job.
10:12:20 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:12:20 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:12:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:12:20 WORKER: start processing job (8, 0, 8)
10:12:20 WORKER: args: ()
10:12:20 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 442, 'last_n_outputs': 48, 'leak_rate': 0.9202685393804955, 'lr': 0.001907948028531219, 'optimizer': 'Adam', 'sparsity': 0.9457006940735685, 'steps_to_train': 68, 'weight_decay': 0.018306732302532536}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:12:33 DISPATCHER: Starting worker discovery
10:12:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:12:33 DISPATCHER: Finished worker discovery
10:13:33 DISPATCHER: Starting worker discovery
10:13:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:13:33 DISPATCHER: Finished worker discovery
10:13:59 WORKER: done with job (8, 0, 8), trying to register it.
10:13:59 WORKER: registered result for job (8, 0, 8) with dispatcher
10:13:59 DISPATCHER: job (8, 0, 8) finished
10:13:59 DISPATCHER: register_result: lock acquired
10:13:59 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:13:59 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 442, 'last_n_outputs': 48, 'leak_rate': 0.9202685393804955, 'lr': 0.001907948028531219, 'optimizer': 'Adam', 'sparsity': 0.9457006940735685, 'steps_to_train': 68, 'weight_decay': 0.018306732302532536}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.22668355708482382, 'info': {'data03': 0.22668355708482382, 'config': "{'batch_size': 16, 'hidden_dim': 442, 'last_n_outputs': 48, 'leak_rate': 0.9202685393804955, 'lr': 0.001907948028531219, 'optimizer': 'Adam', 'sparsity': 0.9457006940735685, 'steps_to_train': 68, 'weight_decay': 0.018306732302532536}"}}
exception: None

10:13:59 job_callback for (8, 0, 8) started
10:13:59 DISPATCHER: Trying to submit another job.
10:13:59 job_callback for (8, 0, 8) got condition
10:13:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:13:59 HBMASTER: Trying to run another job!
10:13:59 job_callback for (8, 0, 8) finished
10:13:59 start sampling a new configuration.
10:13:59 best_vector: [0, 0.5132709615180401, 0.8970818378858875, 0.3204477259841964, 0.1983601260867926, 1, 0.11822059131423568, 0.8650244207208103, 0.5894998609264478], 3.884454799824063e-32, 0.2574363846492158, -0.013503587921538681
10:13:59 done sampling a new configuration.
10:13:59 HBMASTER: schedule new run for iteration 8
10:13:59 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
10:13:59 HBMASTER: submitting job (8, 0, 9) to dispatcher
10:13:59 DISPATCHER: trying to submit job (8, 0, 9)
10:13:59 DISPATCHER: trying to notify the job_runner thread.
10:13:59 HBMASTER: job (8, 0, 9) submitted to dispatcher
10:13:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:13:59 DISPATCHER: Trying to submit another job.
10:13:59 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:13:59 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:13:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:13:59 WORKER: start processing job (8, 0, 9)
10:13:59 WORKER: args: ()
10:13:59 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 611, 'last_n_outputs': 46, 'leak_rate': 0.8301119314960491, 'lr': 0.0024929883681935076, 'optimizer': 'SGD', 'sparsity': 0.7783729419154166, 'steps_to_train': 88, 'weight_decay': 0.058473218829319204}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:14:33 DISPATCHER: Starting worker discovery
10:14:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:14:33 DISPATCHER: Finished worker discovery
10:15:22 WORKER: done with job (8, 0, 9), trying to register it.
10:15:22 WORKER: registered result for job (8, 0, 9) with dispatcher
10:15:22 DISPATCHER: job (8, 0, 9) finished
10:15:22 DISPATCHER: register_result: lock acquired
10:15:22 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:15:22 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 611, 'last_n_outputs': 46, 'leak_rate': 0.8301119314960491, 'lr': 0.0024929883681935076, 'optimizer': 'SGD', 'sparsity': 0.7783729419154166, 'steps_to_train': 88, 'weight_decay': 0.058473218829319204}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 611, 'last_n_outputs': 46, 'leak_rate': 0.8301119314960491, 'lr': 0.0024929883681935076, 'optimizer': 'SGD', 'sparsity': 0.7783729419154166, 'steps_to_train': 88, 'weight_decay': 0.058473218829319204}"}}
exception: None

10:15:22 job_callback for (8, 0, 9) started
10:15:22 DISPATCHER: Trying to submit another job.
10:15:22 job_callback for (8, 0, 9) got condition
10:15:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:15:22 HBMASTER: Trying to run another job!
10:15:22 job_callback for (8, 0, 9) finished
10:15:22 start sampling a new configuration.
10:15:22 best_vector: [0, 0.6499249021060072, 0.6053196248985894, 0.5164386399878628, 0.06439151986880393, 0, 0.5065791348403225, 0.9638953817421491, 0.10775555499158321], 2.002537317068124e-32, 0.4993664744605512, -0.015080572595905931
10:15:22 done sampling a new configuration.
10:15:22 HBMASTER: schedule new run for iteration 8
10:15:22 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
10:15:22 HBMASTER: submitting job (8, 0, 10) to dispatcher
10:15:22 DISPATCHER: trying to submit job (8, 0, 10)
10:15:22 DISPATCHER: trying to notify the job_runner thread.
10:15:22 HBMASTER: job (8, 0, 10) submitted to dispatcher
10:15:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:15:22 DISPATCHER: Trying to submit another job.
10:15:22 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:15:22 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:15:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:15:22 WORKER: start processing job (8, 0, 10)
10:15:22 WORKER: args: ()
10:15:22 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 720, 'last_n_outputs': 34, 'leak_rate': 0.8791096599969657, 'lr': 0.0013451881712326084, 'optimizer': 'Adam', 'sparsity': 0.8715789923616774, 'steps_to_train': 97, 'weight_decay': 0.013809985075759989}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:15:33 DISPATCHER: Starting worker discovery
10:15:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:15:33 DISPATCHER: Finished worker discovery
10:16:33 DISPATCHER: Starting worker discovery
10:16:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:16:33 DISPATCHER: Finished worker discovery
10:16:52 WORKER: done with job (8, 0, 10), trying to register it.
10:16:52 WORKER: registered result for job (8, 0, 10) with dispatcher
10:16:52 DISPATCHER: job (8, 0, 10) finished
10:16:52 DISPATCHER: register_result: lock acquired
10:16:52 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:16:52 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 720, 'last_n_outputs': 34, 'leak_rate': 0.8791096599969657, 'lr': 0.0013451881712326084, 'optimizer': 'Adam', 'sparsity': 0.8715789923616774, 'steps_to_train': 97, 'weight_decay': 0.013809985075759989}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 720, 'last_n_outputs': 34, 'leak_rate': 0.8791096599969657, 'lr': 0.0013451881712326084, 'optimizer': 'Adam', 'sparsity': 0.8715789923616774, 'steps_to_train': 97, 'weight_decay': 0.013809985075759989}"}}
exception: None

10:16:52 job_callback for (8, 0, 10) started
10:16:52 DISPATCHER: Trying to submit another job.
10:16:52 job_callback for (8, 0, 10) got condition
10:16:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:16:52 HBMASTER: Trying to run another job!
10:16:52 job_callback for (8, 0, 10) finished
10:16:52 start sampling a new configuration.
10:16:52 best_vector: [0, 0.6114875015815555, 0.9129651380010955, 0.828029331333195, 0.007976676708586518, 1, 0.8993371915381648, 0.5186262551764725, 0.11475866490449568], 8.00629994483599e-33, 1.2490164081911437, -6.623216016870883e-05
10:16:52 done sampling a new configuration.
10:16:52 HBMASTER: schedule new run for iteration 8
10:16:52 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
10:16:52 HBMASTER: submitting job (8, 0, 11) to dispatcher
10:16:52 DISPATCHER: trying to submit job (8, 0, 11)
10:16:52 DISPATCHER: trying to notify the job_runner thread.
10:16:52 HBMASTER: job (8, 0, 11) submitted to dispatcher
10:16:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:16:52 DISPATCHER: Trying to submit another job.
10:16:52 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:16:52 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:16:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:16:52 WORKER: start processing job (8, 0, 11)
10:16:52 WORKER: args: ()
10:16:52 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 689, 'last_n_outputs': 47, 'leak_rate': 0.9570073328332988, 'lr': 0.0010374169832344108, 'optimizer': 'SGD', 'sparsity': 0.9658409259691596, 'steps_to_train': 57, 'weight_decay': 0.014102771369775604}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:17:33 DISPATCHER: Starting worker discovery
10:17:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:17:33 DISPATCHER: Finished worker discovery
10:18:28 WORKER: done with job (8, 0, 11), trying to register it.
10:18:28 WORKER: registered result for job (8, 0, 11) with dispatcher
10:18:28 DISPATCHER: job (8, 0, 11) finished
10:18:28 DISPATCHER: register_result: lock acquired
10:18:28 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:18:28 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 689, 'last_n_outputs': 47, 'leak_rate': 0.9570073328332988, 'lr': 0.0010374169832344108, 'optimizer': 'SGD', 'sparsity': 0.9658409259691596, 'steps_to_train': 57, 'weight_decay': 0.014102771369775604}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 689, 'last_n_outputs': 47, 'leak_rate': 0.9570073328332988, 'lr': 0.0010374169832344108, 'optimizer': 'SGD', 'sparsity': 0.9658409259691596, 'steps_to_train': 57, 'weight_decay': 0.014102771369775604}"}}
exception: None

10:18:28 job_callback for (8, 0, 11) started
10:18:28 job_callback for (8, 0, 11) got condition
10:18:28 DISPATCHER: Trying to submit another job.
10:18:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:18:28 HBMASTER: Trying to run another job!
10:18:28 job_callback for (8, 0, 11) finished
10:18:28 start sampling a new configuration.
10:18:28 best_vector: [0, 0.3969802070804884, 0.922225443932755, 0.5439913794623588, 0.46610612060311524, 0, 0.6248784499412983, 0.7800670091602153, 0.3030791588412859], 2.863710896752269e-33, 3.4919726049654622, -0.022669491181194847
10:18:28 done sampling a new configuration.
10:18:28 HBMASTER: schedule new run for iteration 8
10:18:28 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
10:18:28 HBMASTER: submitting job (8, 0, 12) to dispatcher
10:18:28 DISPATCHER: trying to submit job (8, 0, 12)
10:18:28 DISPATCHER: trying to notify the job_runner thread.
10:18:28 HBMASTER: job (8, 0, 12) submitted to dispatcher
10:18:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:18:28 DISPATCHER: Trying to submit another job.
10:18:28 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:18:28 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:18:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:18:28 WORKER: start processing job (8, 0, 12)
10:18:28 WORKER: args: ()
10:18:28 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 517, 'last_n_outputs': 47, 'leak_rate': 0.8859978448655896, 'lr': 0.008554846890515114, 'optimizer': 'Adam', 'sparsity': 0.8999708279859115, 'steps_to_train': 80, 'weight_decay': 0.02479220057034827}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:18:33 DISPATCHER: Starting worker discovery
10:18:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:18:33 DISPATCHER: Finished worker discovery
10:19:33 DISPATCHER: Starting worker discovery
10:19:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:19:33 DISPATCHER: Finished worker discovery
10:20:22 WORKER: done with job (8, 0, 12), trying to register it.
10:20:22 WORKER: registered result for job (8, 0, 12) with dispatcher
10:20:22 DISPATCHER: job (8, 0, 12) finished
10:20:22 DISPATCHER: register_result: lock acquired
10:20:22 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:20:22 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 517, 'last_n_outputs': 47, 'leak_rate': 0.8859978448655896, 'lr': 0.008554846890515114, 'optimizer': 'Adam', 'sparsity': 0.8999708279859115, 'steps_to_train': 80, 'weight_decay': 0.02479220057034827}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.29411126263178666, 'info': {'data03': 0.29411126263178666, 'config': "{'batch_size': 16, 'hidden_dim': 517, 'last_n_outputs': 47, 'leak_rate': 0.8859978448655896, 'lr': 0.008554846890515114, 'optimizer': 'Adam', 'sparsity': 0.8999708279859115, 'steps_to_train': 80, 'weight_decay': 0.02479220057034827}"}}
exception: None

10:20:22 job_callback for (8, 0, 12) started
10:20:22 job_callback for (8, 0, 12) got condition
10:20:22 DISPATCHER: Trying to submit another job.
10:20:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:20:22 HBMASTER: Trying to run another job!
10:20:22 job_callback for (8, 0, 12) finished
10:20:22 start sampling a new configuration.
10:20:22 best_vector: [0, 0.4654716437474884, 0.6252147603434803, 0.11665394262606898, 0.5751399633618486, 0, 0.02875377052819028, 0.6858599834635818, 0.44717534456043556], 1.541212584823585e-32, 0.6488397576343858, -0.026440779745648325
10:20:22 done sampling a new configuration.
10:20:22 HBMASTER: schedule new run for iteration 8
10:20:22 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
10:20:22 HBMASTER: submitting job (8, 0, 13) to dispatcher
10:20:22 DISPATCHER: trying to submit job (8, 0, 13)
10:20:22 DISPATCHER: trying to notify the job_runner thread.
10:20:22 HBMASTER: job (8, 0, 13) submitted to dispatcher
10:20:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:20:22 DISPATCHER: Trying to submit another job.
10:20:22 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:20:22 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:20:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:20:22 WORKER: start processing job (8, 0, 13)
10:20:22 WORKER: args: ()
10:20:22 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 572, 'last_n_outputs': 35, 'leak_rate': 0.7791634856565173, 'lr': 0.014134482963859756, 'optimizer': 'Adam', 'sparsity': 0.7569009049267656, 'steps_to_train': 72, 'weight_decay': 0.03817583426749654}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:20:33 DISPATCHER: Starting worker discovery
10:20:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:20:33 DISPATCHER: Finished worker discovery
10:21:33 DISPATCHER: Starting worker discovery
10:21:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:21:33 DISPATCHER: Finished worker discovery
10:22:08 WORKER: done with job (8, 0, 13), trying to register it.
10:22:08 WORKER: registered result for job (8, 0, 13) with dispatcher
10:22:08 DISPATCHER: job (8, 0, 13) finished
10:22:08 DISPATCHER: register_result: lock acquired
10:22:08 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:22:08 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 572, 'last_n_outputs': 35, 'leak_rate': 0.7791634856565173, 'lr': 0.014134482963859756, 'optimizer': 'Adam', 'sparsity': 0.7569009049267656, 'steps_to_train': 72, 'weight_decay': 0.03817583426749654}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.12683975877585352, 'info': {'data03': 0.12683975877585352, 'config': "{'batch_size': 16, 'hidden_dim': 572, 'last_n_outputs': 35, 'leak_rate': 0.7791634856565173, 'lr': 0.014134482963859756, 'optimizer': 'Adam', 'sparsity': 0.7569009049267656, 'steps_to_train': 72, 'weight_decay': 0.03817583426749654}"}}
exception: None

10:22:08 job_callback for (8, 0, 13) started
10:22:08 job_callback for (8, 0, 13) got condition
10:22:08 DISPATCHER: Trying to submit another job.
10:22:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:22:08 HBMASTER: Trying to run another job!
10:22:08 job_callback for (8, 0, 13) finished
10:22:08 start sampling a new configuration.
10:22:08 best_vector: [0, 0.6928528127709097, 0.8401875065621647, 0.5593560584773535, 0.24475048213221465, 1, 0.34447369228227054, 0.9627410777255542, 0.3769466653723666], 3.1233769009934414e-33, 3.2016629170880195, -0.01903114793834893
10:22:08 done sampling a new configuration.
10:22:08 HBMASTER: schedule new run for iteration 8
10:22:08 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
10:22:08 HBMASTER: submitting job (8, 0, 14) to dispatcher
10:22:08 DISPATCHER: trying to submit job (8, 0, 14)
10:22:08 DISPATCHER: trying to notify the job_runner thread.
10:22:08 HBMASTER: job (8, 0, 14) submitted to dispatcher
10:22:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:22:08 DISPATCHER: Trying to submit another job.
10:22:08 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:22:08 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:22:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:22:08 WORKER: start processing job (8, 0, 14)
10:22:08 WORKER: args: ()
10:22:08 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 754, 'last_n_outputs': 44, 'leak_rate': 0.8898390146193383, 'lr': 0.0030867464991822845, 'optimizer': 'SGD', 'sparsity': 0.832673686147745, 'steps_to_train': 97, 'weight_decay': 0.030932777550915225}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:22:33 DISPATCHER: Starting worker discovery
10:22:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:22:33 DISPATCHER: Finished worker discovery
10:23:29 WORKER: done with job (8, 0, 14), trying to register it.
10:23:29 WORKER: registered result for job (8, 0, 14) with dispatcher
10:23:29 DISPATCHER: job (8, 0, 14) finished
10:23:29 DISPATCHER: register_result: lock acquired
10:23:29 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:23:29 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 754, 'last_n_outputs': 44, 'leak_rate': 0.8898390146193383, 'lr': 0.0030867464991822845, 'optimizer': 'SGD', 'sparsity': 0.832673686147745, 'steps_to_train': 97, 'weight_decay': 0.030932777550915225}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 754, 'last_n_outputs': 44, 'leak_rate': 0.8898390146193383, 'lr': 0.0030867464991822845, 'optimizer': 'SGD', 'sparsity': 0.832673686147745, 'steps_to_train': 97, 'weight_decay': 0.030932777550915225}"}}
exception: None

10:23:29 job_callback for (8, 0, 14) started
10:23:29 job_callback for (8, 0, 14) got condition
10:23:29 DISPATCHER: Trying to submit another job.
10:23:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:23:29 HBMASTER: Trying to run another job!
10:23:29 job_callback for (8, 0, 14) finished
10:23:29 start sampling a new configuration.
10:23:29 done sampling a new configuration.
10:23:29 HBMASTER: schedule new run for iteration 8
10:23:29 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
10:23:29 HBMASTER: submitting job (8, 0, 15) to dispatcher
10:23:29 DISPATCHER: trying to submit job (8, 0, 15)
10:23:29 DISPATCHER: trying to notify the job_runner thread.
10:23:29 HBMASTER: job (8, 0, 15) submitted to dispatcher
10:23:29 DISPATCHER: Trying to submit another job.
10:23:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:23:29 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:23:29 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:23:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:23:29 WORKER: start processing job (8, 0, 15)
10:23:29 WORKER: args: ()
10:23:29 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 450, 'last_n_outputs': 46, 'leak_rate': 0.9736113980452591, 'lr': 0.01138307173959682, 'optimizer': 'Adam', 'sparsity': 0.9019240329500808, 'steps_to_train': 35, 'weight_decay': 0.05150874348609912}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:23:33 DISPATCHER: Starting worker discovery
10:23:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:23:33 DISPATCHER: Finished worker discovery
10:24:33 DISPATCHER: Starting worker discovery
10:24:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:24:33 DISPATCHER: Finished worker discovery
10:25:04 WORKER: done with job (8, 0, 15), trying to register it.
10:25:04 WORKER: registered result for job (8, 0, 15) with dispatcher
10:25:04 DISPATCHER: job (8, 0, 15) finished
10:25:04 DISPATCHER: register_result: lock acquired
10:25:04 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:25:04 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 450, 'last_n_outputs': 46, 'leak_rate': 0.9736113980452591, 'lr': 0.01138307173959682, 'optimizer': 'Adam', 'sparsity': 0.9019240329500808, 'steps_to_train': 35, 'weight_decay': 0.05150874348609912}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2994730351893157, 'info': {'data03': 0.2994730351893157, 'config': "{'batch_size': 64, 'hidden_dim': 450, 'last_n_outputs': 46, 'leak_rate': 0.9736113980452591, 'lr': 0.01138307173959682, 'optimizer': 'Adam', 'sparsity': 0.9019240329500808, 'steps_to_train': 35, 'weight_decay': 0.05150874348609912}"}}
exception: None

10:25:04 job_callback for (8, 0, 15) started
10:25:04 DISPATCHER: Trying to submit another job.
10:25:04 job_callback for (8, 0, 15) got condition
10:25:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:25:04 HBMASTER: Trying to run another job!
10:25:04 job_callback for (8, 0, 15) finished
10:25:04 start sampling a new configuration.
10:25:04 best_vector: [0, 0.6500390065745435, 0.8027850937623145, 0.23530228350876892, 0.3537004283733198, 0, 0.6500197584419443, 0.879040624941079, 0.10587974216024115], 1.9310719160450924e-33, 5.178471043419437, -0.04356762234257039
10:25:04 done sampling a new configuration.
10:25:04 HBMASTER: schedule new run for iteration 8
10:25:04 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
10:25:04 HBMASTER: submitting job (8, 0, 16) to dispatcher
10:25:04 DISPATCHER: trying to submit job (8, 0, 16)
10:25:04 DISPATCHER: trying to notify the job_runner thread.
10:25:04 HBMASTER: job (8, 0, 16) submitted to dispatcher
10:25:04 DISPATCHER: Trying to submit another job.
10:25:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:25:04 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:25:04 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:25:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:25:04 WORKER: start processing job (8, 0, 16)
10:25:04 WORKER: args: ()
10:25:04 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 720, 'last_n_outputs': 42, 'leak_rate': 0.8088255708771922, 'lr': 0.0050980120392578295, 'optimizer': 'Adam', 'sparsity': 0.9060047420260666, 'steps_to_train': 89, 'weight_decay': 0.013732598427557847}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:25:33 DISPATCHER: Starting worker discovery
10:25:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:25:33 DISPATCHER: Finished worker discovery
10:26:32 WORKER: done with job (8, 0, 16), trying to register it.
10:26:32 WORKER: registered result for job (8, 0, 16) with dispatcher
10:26:32 DISPATCHER: job (8, 0, 16) finished
10:26:32 DISPATCHER: register_result: lock acquired
10:26:32 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:26:32 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 720, 'last_n_outputs': 42, 'leak_rate': 0.8088255708771922, 'lr': 0.0050980120392578295, 'optimizer': 'Adam', 'sparsity': 0.9060047420260666, 'steps_to_train': 89, 'weight_decay': 0.013732598427557847}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 720, 'last_n_outputs': 42, 'leak_rate': 0.8088255708771922, 'lr': 0.0050980120392578295, 'optimizer': 'Adam', 'sparsity': 0.9060047420260666, 'steps_to_train': 89, 'weight_decay': 0.013732598427557847}"}}
exception: None

10:26:32 job_callback for (8, 0, 16) started
10:26:32 DISPATCHER: Trying to submit another job.
10:26:32 job_callback for (8, 0, 16) got condition
10:26:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:26:32 HBMASTER: Trying to run another job!
10:26:32 job_callback for (8, 0, 16) finished
10:26:32 start sampling a new configuration.
10:26:32 done sampling a new configuration.
10:26:32 HBMASTER: schedule new run for iteration 8
10:26:32 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
10:26:32 HBMASTER: submitting job (8, 0, 17) to dispatcher
10:26:32 DISPATCHER: trying to submit job (8, 0, 17)
10:26:32 DISPATCHER: trying to notify the job_runner thread.
10:26:32 HBMASTER: job (8, 0, 17) submitted to dispatcher
10:26:32 DISPATCHER: Trying to submit another job.
10:26:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:26:32 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:26:32 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:26:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:26:32 WORKER: start processing job (8, 0, 17)
10:26:32 WORKER: args: ()
10:26:32 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 338, 'last_n_outputs': 26, 'leak_rate': 0.768849424374545, 'lr': 0.004610820621435558, 'optimizer': 'Adam', 'sparsity': 0.7697913500557674, 'steps_to_train': 20, 'weight_decay': 0.015357261509971576}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:26:33 DISPATCHER: Starting worker discovery
10:26:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:26:33 DISPATCHER: Finished worker discovery
10:27:33 DISPATCHER: Starting worker discovery
10:27:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:27:33 DISPATCHER: Finished worker discovery
10:27:57 WORKER: done with job (8, 0, 17), trying to register it.
10:27:57 WORKER: registered result for job (8, 0, 17) with dispatcher
10:27:57 DISPATCHER: job (8, 0, 17) finished
10:27:57 DISPATCHER: register_result: lock acquired
10:27:57 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:27:57 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 338, 'last_n_outputs': 26, 'leak_rate': 0.768849424374545, 'lr': 0.004610820621435558, 'optimizer': 'Adam', 'sparsity': 0.7697913500557674, 'steps_to_train': 20, 'weight_decay': 0.015357261509971576}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2479946350414277, 'info': {'data03': 0.2479946350414277, 'config': "{'batch_size': 16, 'hidden_dim': 338, 'last_n_outputs': 26, 'leak_rate': 0.768849424374545, 'lr': 0.004610820621435558, 'optimizer': 'Adam', 'sparsity': 0.7697913500557674, 'steps_to_train': 20, 'weight_decay': 0.015357261509971576}"}}
exception: None

10:27:57 job_callback for (8, 0, 17) started
10:27:57 job_callback for (8, 0, 17) got condition
10:27:57 DISPATCHER: Trying to submit another job.
10:27:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:27:57 HBMASTER: Trying to run another job!
10:27:57 job_callback for (8, 0, 17) finished
10:27:57 start sampling a new configuration.
10:27:57 done sampling a new configuration.
10:27:57 HBMASTER: schedule new run for iteration 8
10:27:57 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
10:27:57 HBMASTER: submitting job (8, 0, 18) to dispatcher
10:27:57 DISPATCHER: trying to submit job (8, 0, 18)
10:27:57 DISPATCHER: trying to notify the job_runner thread.
10:27:57 HBMASTER: job (8, 0, 18) submitted to dispatcher
10:27:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:27:57 DISPATCHER: Trying to submit another job.
10:27:57 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:27:57 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:27:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:27:57 WORKER: start processing job (8, 0, 18)
10:27:57 WORKER: args: ()
10:27:57 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 556, 'last_n_outputs': 28, 'leak_rate': 0.8050935102271035, 'lr': 0.02415475933062214, 'optimizer': 'Adam', 'sparsity': 0.8189626229439599, 'steps_to_train': 81, 'weight_decay': 0.020010469328429797}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:28:33 DISPATCHER: Starting worker discovery
10:28:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:28:33 DISPATCHER: Finished worker discovery
10:29:33 DISPATCHER: Starting worker discovery
10:29:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:29:33 DISPATCHER: Finished worker discovery
10:29:50 WORKER: done with job (8, 0, 18), trying to register it.
10:29:50 WORKER: registered result for job (8, 0, 18) with dispatcher
10:29:50 DISPATCHER: job (8, 0, 18) finished
10:29:50 DISPATCHER: register_result: lock acquired
10:29:50 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:29:50 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 556, 'last_n_outputs': 28, 'leak_rate': 0.8050935102271035, 'lr': 0.02415475933062214, 'optimizer': 'Adam', 'sparsity': 0.8189626229439599, 'steps_to_train': 81, 'weight_decay': 0.020010469328429797}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.27038833619678265, 'info': {'data03': 0.27038833619678265, 'config': "{'batch_size': 32, 'hidden_dim': 556, 'last_n_outputs': 28, 'leak_rate': 0.8050935102271035, 'lr': 0.02415475933062214, 'optimizer': 'Adam', 'sparsity': 0.8189626229439599, 'steps_to_train': 81, 'weight_decay': 0.020010469328429797}"}}
exception: None

10:29:50 job_callback for (8, 0, 18) started
10:29:50 DISPATCHER: Trying to submit another job.
10:29:50 job_callback for (8, 0, 18) got condition
10:29:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:29:50 HBMASTER: Trying to run another job!
10:29:50 job_callback for (8, 0, 18) finished
10:29:50 start sampling a new configuration.
10:29:50 best_vector: [0, 0.6150512754939506, 0.7917702894518002, 0.5240942644362004, 0.24576657166207516, 1, 0.641109025966935, 0.9188818821255986, 0.21860377096966743], 2.318984787846136e-33, 4.31223182334368, -0.019093696952243288
10:29:50 done sampling a new configuration.
10:29:50 HBMASTER: schedule new run for iteration 8
10:29:50 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
10:29:50 HBMASTER: submitting job (8, 0, 19) to dispatcher
10:29:50 DISPATCHER: trying to submit job (8, 0, 19)
10:29:50 DISPATCHER: trying to notify the job_runner thread.
10:29:50 HBMASTER: job (8, 0, 19) submitted to dispatcher
10:29:50 DISPATCHER: Trying to submit another job.
10:29:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:29:50 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:29:50 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:29:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:29:50 WORKER: start processing job (8, 0, 19)
10:29:50 WORKER: args: ()
10:29:50 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 692, 'last_n_outputs': 42, 'leak_rate': 0.8810235661090501, 'lr': 0.0031012240504203438, 'optimizer': 'SGD', 'sparsity': 0.9038661662320644, 'steps_to_train': 93, 'weight_decay': 0.01924908380024165}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:30:33 DISPATCHER: Starting worker discovery
10:30:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:30:33 DISPATCHER: Finished worker discovery
10:31:33 DISPATCHER: Starting worker discovery
10:31:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:31:33 DISPATCHER: Finished worker discovery
10:31:52 WORKER: done with job (8, 0, 19), trying to register it.
10:31:52 WORKER: registered result for job (8, 0, 19) with dispatcher
10:31:52 DISPATCHER: job (8, 0, 19) finished
10:31:52 DISPATCHER: register_result: lock acquired
10:31:52 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:31:52 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 692, 'last_n_outputs': 42, 'leak_rate': 0.8810235661090501, 'lr': 0.0031012240504203438, 'optimizer': 'SGD', 'sparsity': 0.9038661662320644, 'steps_to_train': 93, 'weight_decay': 0.01924908380024165}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.18717390109251705, 'info': {'data03': 0.18717390109251705, 'config': "{'batch_size': 16, 'hidden_dim': 692, 'last_n_outputs': 42, 'leak_rate': 0.8810235661090501, 'lr': 0.0031012240504203438, 'optimizer': 'SGD', 'sparsity': 0.9038661662320644, 'steps_to_train': 93, 'weight_decay': 0.01924908380024165}"}}
exception: None

10:31:52 job_callback for (8, 0, 19) started
10:31:52 DISPATCHER: Trying to submit another job.
10:31:52 job_callback for (8, 0, 19) got condition
10:31:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:31:52 HBMASTER: Trying to run another job!
10:31:52 job_callback for (8, 0, 19) finished
10:31:52 start sampling a new configuration.
10:31:52 best_vector: [0, 0.8548508188880195, 0.8741462790620825, 0.5017835792675328, 0.4389762639725713, 1, 0.8911985693237146, 0.7277822761113037, 0.5366000173930017], 1.0743494789049849e-31, 0.0930795816105608, -0.001444009366407258
10:31:52 done sampling a new configuration.
10:31:52 HBMASTER: schedule new run for iteration 8
10:31:52 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
10:31:52 HBMASTER: submitting job (8, 0, 20) to dispatcher
10:31:52 DISPATCHER: trying to submit job (8, 0, 20)
10:31:52 DISPATCHER: trying to notify the job_runner thread.
10:31:52 HBMASTER: job (8, 0, 20) submitted to dispatcher
10:31:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:31:52 DISPATCHER: Trying to submit another job.
10:31:52 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:31:52 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:31:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:31:52 WORKER: start processing job (8, 0, 20)
10:31:52 WORKER: args: ()
10:31:52 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 884, 'last_n_outputs': 45, 'leak_rate': 0.8754458948168832, 'lr': 0.007550096942184399, 'optimizer': 'SGD', 'sparsity': 0.9638876566376915, 'steps_to_train': 76, 'weight_decay': 0.049903696745414367}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:32:33 DISPATCHER: Starting worker discovery
10:32:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:32:33 DISPATCHER: Finished worker discovery
10:33:33 DISPATCHER: Starting worker discovery
10:33:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:33:33 DISPATCHER: Finished worker discovery
10:33:37 WORKER: done with job (8, 0, 20), trying to register it.
10:33:37 WORKER: registered result for job (8, 0, 20) with dispatcher
10:33:37 DISPATCHER: job (8, 0, 20) finished
10:33:37 DISPATCHER: register_result: lock acquired
10:33:37 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:33:37 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 884, 'last_n_outputs': 45, 'leak_rate': 0.8754458948168832, 'lr': 0.007550096942184399, 'optimizer': 'SGD', 'sparsity': 0.9638876566376915, 'steps_to_train': 76, 'weight_decay': 0.049903696745414367}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0696360208715324, 'info': {'data03': 0.0696360208715324, 'config': "{'batch_size': 16, 'hidden_dim': 884, 'last_n_outputs': 45, 'leak_rate': 0.8754458948168832, 'lr': 0.007550096942184399, 'optimizer': 'SGD', 'sparsity': 0.9638876566376915, 'steps_to_train': 76, 'weight_decay': 0.049903696745414367}"}}
exception: None

10:33:37 job_callback for (8, 0, 20) started
10:33:37 job_callback for (8, 0, 20) got condition
10:33:37 DISPATCHER: Trying to submit another job.
10:33:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:33:37 HBMASTER: Trying to run another job!
10:33:37 job_callback for (8, 0, 20) finished
10:33:37 start sampling a new configuration.
10:33:37 done sampling a new configuration.
10:33:37 HBMASTER: schedule new run for iteration 8
10:33:37 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
10:33:37 HBMASTER: submitting job (8, 0, 21) to dispatcher
10:33:37 DISPATCHER: trying to submit job (8, 0, 21)
10:33:37 DISPATCHER: trying to notify the job_runner thread.
10:33:37 HBMASTER: job (8, 0, 21) submitted to dispatcher
10:33:37 DISPATCHER: Trying to submit another job.
10:33:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:33:37 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:33:37 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:33:37 WORKER: start processing job (8, 0, 21)
10:33:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:33:37 WORKER: args: ()
10:33:37 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 449, 'last_n_outputs': 25, 'leak_rate': 0.8951226019781441, 'lr': 0.001292683893359265, 'optimizer': 'SGD', 'sparsity': 0.9042665406086626, 'steps_to_train': 97, 'weight_decay': 0.04808021653180191}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:34:33 DISPATCHER: Starting worker discovery
10:34:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:34:33 DISPATCHER: Finished worker discovery
10:35:06 WORKER: done with job (8, 0, 21), trying to register it.
10:35:06 WORKER: registered result for job (8, 0, 21) with dispatcher
10:35:06 DISPATCHER: job (8, 0, 21) finished
10:35:06 DISPATCHER: register_result: lock acquired
10:35:06 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:35:06 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 449, 'last_n_outputs': 25, 'leak_rate': 0.8951226019781441, 'lr': 0.001292683893359265, 'optimizer': 'SGD', 'sparsity': 0.9042665406086626, 'steps_to_train': 97, 'weight_decay': 0.04808021653180191}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 449, 'last_n_outputs': 25, 'leak_rate': 0.8951226019781441, 'lr': 0.001292683893359265, 'optimizer': 'SGD', 'sparsity': 0.9042665406086626, 'steps_to_train': 97, 'weight_decay': 0.04808021653180191}"}}
exception: None

10:35:06 job_callback for (8, 0, 21) started
10:35:06 DISPATCHER: Trying to submit another job.
10:35:06 job_callback for (8, 0, 21) got condition
10:35:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:35:06 HBMASTER: Trying to run another job!
10:35:06 job_callback for (8, 0, 21) finished
10:35:06 start sampling a new configuration.
10:35:06 best_vector: [0, 0.8330188989190933, 0.8308299738142005, 0.6974942296047368, 0.00915730012966616, 0, 0.9256690294485697, 0.8317969537869161, 0.5811187152317796], 3.0038207792862457e-32, 0.33290934229358904, -0.0017922712196867072
10:35:06 done sampling a new configuration.
10:35:06 HBMASTER: schedule new run for iteration 8
10:35:06 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
10:35:06 HBMASTER: submitting job (8, 0, 22) to dispatcher
10:35:06 DISPATCHER: trying to submit job (8, 0, 22)
10:35:06 DISPATCHER: trying to notify the job_runner thread.
10:35:06 HBMASTER: job (8, 0, 22) submitted to dispatcher
10:35:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:35:06 DISPATCHER: Trying to submit another job.
10:35:06 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:35:06 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:35:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:35:06 WORKER: start processing job (8, 0, 22)
10:35:06 WORKER: args: ()
10:35:06 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 867, 'last_n_outputs': 44, 'leak_rate': 0.9243735574011842, 'lr': 0.0010430727512892764, 'optimizer': 'Adam', 'sparsity': 0.9721605670676567, 'steps_to_train': 85, 'weight_decay': 0.057023369952818995}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:35:33 DISPATCHER: Starting worker discovery
10:35:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:35:33 DISPATCHER: Finished worker discovery
10:36:33 DISPATCHER: Starting worker discovery
10:36:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:36:33 DISPATCHER: Finished worker discovery
10:37:06 WORKER: done with job (8, 0, 22), trying to register it.
10:37:06 WORKER: registered result for job (8, 0, 22) with dispatcher
10:37:06 DISPATCHER: job (8, 0, 22) finished
10:37:06 DISPATCHER: register_result: lock acquired
10:37:06 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:37:06 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 867, 'last_n_outputs': 44, 'leak_rate': 0.9243735574011842, 'lr': 0.0010430727512892764, 'optimizer': 'Adam', 'sparsity': 0.9721605670676567, 'steps_to_train': 85, 'weight_decay': 0.057023369952818995}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.21977464712524084, 'info': {'data03': 0.21977464712524084, 'config': "{'batch_size': 16, 'hidden_dim': 867, 'last_n_outputs': 44, 'leak_rate': 0.9243735574011842, 'lr': 0.0010430727512892764, 'optimizer': 'Adam', 'sparsity': 0.9721605670676567, 'steps_to_train': 85, 'weight_decay': 0.057023369952818995}"}}
exception: None

10:37:06 job_callback for (8, 0, 22) started
10:37:06 DISPATCHER: Trying to submit another job.
10:37:06 job_callback for (8, 0, 22) got condition
10:37:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:37:06 HBMASTER: Trying to run another job!
10:37:06 job_callback for (8, 0, 22) finished
10:37:06 start sampling a new configuration.
10:37:06 best_vector: [0, 0.7896644257753029, 0.8446594246397343, 0.16429953360440208, 0.4415019740774105, 1, 0.6579455309732875, 0.8407815127947901, 0.25309349478739374], 1.4388715270589905e-32, 0.6949890808138859, -0.020194912198136704
10:37:06 done sampling a new configuration.
10:37:06 HBMASTER: schedule new run for iteration 8
10:37:06 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
10:37:06 HBMASTER: submitting job (8, 0, 23) to dispatcher
10:37:06 DISPATCHER: trying to submit job (8, 0, 23)
10:37:06 DISPATCHER: trying to notify the job_runner thread.
10:37:06 HBMASTER: job (8, 0, 23) submitted to dispatcher
10:37:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:37:06 DISPATCHER: Trying to submit another job.
10:37:06 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:37:06 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:37:06 WORKER: start processing job (8, 0, 23)
10:37:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:37:06 WORKER: args: ()
10:37:06 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 832, 'last_n_outputs': 44, 'leak_rate': 0.7910748834011005, 'lr': 0.0076384272761166995, 'optimizer': 'SGD', 'sparsity': 0.9079069274335889, 'steps_to_train': 86, 'weight_decay': 0.02134431533478605}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:37:33 DISPATCHER: Starting worker discovery
10:37:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:37:33 DISPATCHER: Finished worker discovery
10:38:33 DISPATCHER: Starting worker discovery
10:38:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:38:33 DISPATCHER: Finished worker discovery
10:39:01 WORKER: done with job (8, 0, 23), trying to register it.
10:39:01 WORKER: registered result for job (8, 0, 23) with dispatcher
10:39:01 DISPATCHER: job (8, 0, 23) finished
10:39:01 DISPATCHER: register_result: lock acquired
10:39:01 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:39:01 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 832, 'last_n_outputs': 44, 'leak_rate': 0.7910748834011005, 'lr': 0.0076384272761166995, 'optimizer': 'SGD', 'sparsity': 0.9079069274335889, 'steps_to_train': 86, 'weight_decay': 0.02134431533478605}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1726438169890921, 'info': {'data03': 0.1726438169890921, 'config': "{'batch_size': 16, 'hidden_dim': 832, 'last_n_outputs': 44, 'leak_rate': 0.7910748834011005, 'lr': 0.0076384272761166995, 'optimizer': 'SGD', 'sparsity': 0.9079069274335889, 'steps_to_train': 86, 'weight_decay': 0.02134431533478605}"}}
exception: None

10:39:01 job_callback for (8, 0, 23) started
10:39:01 DISPATCHER: Trying to submit another job.
10:39:01 job_callback for (8, 0, 23) got condition
10:39:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:39:01 HBMASTER: Trying to run another job!
10:39:01 job_callback for (8, 0, 23) finished
10:39:01 start sampling a new configuration.
10:39:01 best_vector: [0, 0.5819028520852304, 0.8582150372581138, 0.35854918796596014, 0.3557334446249778, 0, 0.2837814355731906, 0.8420639778970804, 0.6263658338481243], 2.3506044318064744e-33, 4.254224940908008, -0.06124857504801178
10:39:01 done sampling a new configuration.
10:39:01 HBMASTER: schedule new run for iteration 8
10:39:01 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
10:39:01 HBMASTER: submitting job (8, 0, 24) to dispatcher
10:39:01 DISPATCHER: trying to submit job (8, 0, 24)
10:39:01 DISPATCHER: trying to notify the job_runner thread.
10:39:01 HBMASTER: job (8, 0, 24) submitted to dispatcher
10:39:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:39:01 DISPATCHER: Trying to submit another job.
10:39:01 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:39:01 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:39:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:39:01 WORKER: start processing job (8, 0, 24)
10:39:01 WORKER: args: ()
10:39:01 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 666, 'last_n_outputs': 45, 'leak_rate': 0.83963729699149, 'lr': 0.005145965725110344, 'optimizer': 'Adam', 'sparsity': 0.8181075445375657, 'steps_to_train': 86, 'weight_decay': 0.06530113624438481}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:39:33 DISPATCHER: Starting worker discovery
10:39:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:39:33 DISPATCHER: Finished worker discovery
10:40:33 DISPATCHER: Starting worker discovery
10:40:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:40:33 DISPATCHER: Finished worker discovery
10:40:52 WORKER: done with job (8, 0, 24), trying to register it.
10:40:52 WORKER: registered result for job (8, 0, 24) with dispatcher
10:40:52 DISPATCHER: job (8, 0, 24) finished
10:40:52 DISPATCHER: register_result: lock acquired
10:40:52 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:40:52 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 666, 'last_n_outputs': 45, 'leak_rate': 0.83963729699149, 'lr': 0.005145965725110344, 'optimizer': 'Adam', 'sparsity': 0.8181075445375657, 'steps_to_train': 86, 'weight_decay': 0.06530113624438481}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2466590591251217, 'info': {'data03': 0.2466590591251217, 'config': "{'batch_size': 16, 'hidden_dim': 666, 'last_n_outputs': 45, 'leak_rate': 0.83963729699149, 'lr': 0.005145965725110344, 'optimizer': 'Adam', 'sparsity': 0.8181075445375657, 'steps_to_train': 86, 'weight_decay': 0.06530113624438481}"}}
exception: None

10:40:52 job_callback for (8, 0, 24) started
10:40:52 DISPATCHER: Trying to submit another job.
10:40:52 job_callback for (8, 0, 24) got condition
10:40:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:40:52 HBMASTER: Trying to run another job!
10:40:52 job_callback for (8, 0, 24) finished
10:40:52 start sampling a new configuration.
10:40:52 best_vector: [0, 0.44727879159285255, 0.9563310881261469, 0.30902056853842425, 0.16072119622545883, 0, 0.25003343640481057, 0.9790320811331246, 0.43256606533014935], 3.1838402170750414e-32, 0.31408611356718424, -0.024836686322643662
10:40:52 done sampling a new configuration.
10:40:52 HBMASTER: schedule new run for iteration 8
10:40:52 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
10:40:52 HBMASTER: submitting job (8, 0, 25) to dispatcher
10:40:52 DISPATCHER: trying to submit job (8, 0, 25)
10:40:52 DISPATCHER: trying to notify the job_runner thread.
10:40:52 HBMASTER: job (8, 0, 25) submitted to dispatcher
10:40:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:40:52 DISPATCHER: Trying to submit another job.
10:40:52 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:40:52 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:40:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:40:52 WORKER: start processing job (8, 0, 25)
10:40:52 WORKER: args: ()
10:40:52 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 558, 'last_n_outputs': 49, 'leak_rate': 0.827255142134606, 'lr': 0.0020962467025144407, 'optimizer': 'Adam', 'sparsity': 0.8100080247371545, 'steps_to_train': 99, 'weight_decay': 0.036541083953179426}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:41:33 DISPATCHER: Starting worker discovery
10:41:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:41:33 DISPATCHER: Finished worker discovery
10:42:15 WORKER: done with job (8, 0, 25), trying to register it.
10:42:15 WORKER: registered result for job (8, 0, 25) with dispatcher
10:42:15 DISPATCHER: job (8, 0, 25) finished
10:42:15 DISPATCHER: register_result: lock acquired
10:42:15 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:42:15 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 558, 'last_n_outputs': 49, 'leak_rate': 0.827255142134606, 'lr': 0.0020962467025144407, 'optimizer': 'Adam', 'sparsity': 0.8100080247371545, 'steps_to_train': 99, 'weight_decay': 0.036541083953179426}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 558, 'last_n_outputs': 49, 'leak_rate': 0.827255142134606, 'lr': 0.0020962467025144407, 'optimizer': 'Adam', 'sparsity': 0.8100080247371545, 'steps_to_train': 99, 'weight_decay': 0.036541083953179426}"}}
exception: None

10:42:15 job_callback for (8, 0, 25) started
10:42:15 job_callback for (8, 0, 25) got condition
10:42:15 DISPATCHER: Trying to submit another job.
10:42:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:42:15 HBMASTER: Trying to run another job!
10:42:15 job_callback for (8, 0, 25) finished
10:42:15 start sampling a new configuration.
10:42:15 done sampling a new configuration.
10:42:15 HBMASTER: schedule new run for iteration 8
10:42:15 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
10:42:15 HBMASTER: submitting job (8, 0, 26) to dispatcher
10:42:15 DISPATCHER: trying to submit job (8, 0, 26)
10:42:15 DISPATCHER: trying to notify the job_runner thread.
10:42:15 HBMASTER: job (8, 0, 26) submitted to dispatcher
10:42:15 DISPATCHER: Trying to submit another job.
10:42:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:42:15 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:42:15 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:42:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:42:15 WORKER: start processing job (8, 0, 26)
10:42:15 WORKER: args: ()
10:42:15 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 487, 'last_n_outputs': 34, 'leak_rate': 0.893819477387679, 'lr': 0.027959726581235387, 'optimizer': 'Adam', 'sparsity': 0.9588348452027601, 'steps_to_train': 33, 'weight_decay': 0.030042535759129605}, 'budget': 44.44444444444444, 'working_directory': '.'}
10:42:33 DISPATCHER: Starting worker discovery
10:42:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:42:33 DISPATCHER: Finished worker discovery
10:43:33 DISPATCHER: Starting worker discovery
10:43:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:43:33 DISPATCHER: Finished worker discovery
10:43:43 WORKER: done with job (8, 0, 26), trying to register it.
10:43:43 WORKER: registered result for job (8, 0, 26) with dispatcher
10:43:43 DISPATCHER: job (8, 0, 26) finished
10:43:43 DISPATCHER: register_result: lock acquired
10:43:43 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:43:43 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 487, 'last_n_outputs': 34, 'leak_rate': 0.893819477387679, 'lr': 0.027959726581235387, 'optimizer': 'Adam', 'sparsity': 0.9588348452027601, 'steps_to_train': 33, 'weight_decay': 0.030042535759129605}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.09472535968309315, 'info': {'data03': 0.09472535968309315, 'config': "{'batch_size': 64, 'hidden_dim': 487, 'last_n_outputs': 34, 'leak_rate': 0.893819477387679, 'lr': 0.027959726581235387, 'optimizer': 'Adam', 'sparsity': 0.9588348452027601, 'steps_to_train': 33, 'weight_decay': 0.030042535759129605}"}}
exception: None

10:43:43 job_callback for (8, 0, 26) started
10:43:43 DISPATCHER: Trying to submit another job.
10:43:43 job_callback for (8, 0, 26) got condition
10:43:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:43:43 HBMASTER: Trying to run another job!
10:43:43 job_callback for (8, 0, 26) finished
10:43:43 ITERATION: Advancing config (8, 0, 0) to next budget 133.333333
10:43:43 ITERATION: Advancing config (8, 0, 3) to next budget 133.333333
10:43:43 ITERATION: Advancing config (8, 0, 8) to next budget 133.333333
10:43:43 ITERATION: Advancing config (8, 0, 12) to next budget 133.333333
10:43:43 ITERATION: Advancing config (8, 0, 15) to next budget 133.333333
10:43:43 ITERATION: Advancing config (8, 0, 17) to next budget 133.333333
10:43:43 ITERATION: Advancing config (8, 0, 18) to next budget 133.333333
10:43:43 ITERATION: Advancing config (8, 0, 22) to next budget 133.333333
10:43:43 ITERATION: Advancing config (8, 0, 24) to next budget 133.333333
10:43:43 HBMASTER: schedule new run for iteration 8
10:43:43 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
10:43:43 HBMASTER: submitting job (8, 0, 0) to dispatcher
10:43:43 DISPATCHER: trying to submit job (8, 0, 0)
10:43:43 DISPATCHER: trying to notify the job_runner thread.
10:43:43 HBMASTER: job (8, 0, 0) submitted to dispatcher
10:43:43 DISPATCHER: Trying to submit another job.
10:43:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:43:43 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:43:43 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:43:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:43:43 WORKER: start processing job (8, 0, 0)
10:43:43 WORKER: args: ()
10:43:43 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 846, 'last_n_outputs': 21, 'leak_rate': 0.9532259099746182, 'lr': 0.00651893458753199, 'optimizer': 'SGD', 'sparsity': 0.9192607974183713, 'steps_to_train': 71, 'weight_decay': 0.06620647634505833}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:44:33 DISPATCHER: Starting worker discovery
10:44:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:44:33 DISPATCHER: Finished worker discovery
10:45:33 DISPATCHER: Starting worker discovery
10:45:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:45:33 DISPATCHER: Finished worker discovery
10:46:33 DISPATCHER: Starting worker discovery
10:46:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:46:33 DISPATCHER: Finished worker discovery
10:47:00 WORKER: done with job (8, 0, 0), trying to register it.
10:47:00 WORKER: registered result for job (8, 0, 0) with dispatcher
10:47:00 DISPATCHER: job (8, 0, 0) finished
10:47:00 DISPATCHER: register_result: lock acquired
10:47:00 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:47:00 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 846, 'last_n_outputs': 21, 'leak_rate': 0.9532259099746182, 'lr': 0.00651893458753199, 'optimizer': 'SGD', 'sparsity': 0.9192607974183713, 'steps_to_train': 71, 'weight_decay': 0.06620647634505833}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0499095659672334, 'info': {'data03': 0.0499095659672334, 'config': "{'batch_size': 128, 'hidden_dim': 846, 'last_n_outputs': 21, 'leak_rate': 0.9532259099746182, 'lr': 0.00651893458753199, 'optimizer': 'SGD', 'sparsity': 0.9192607974183713, 'steps_to_train': 71, 'weight_decay': 0.06620647634505833}"}}
exception: None

10:47:00 job_callback for (8, 0, 0) started
10:47:00 DISPATCHER: Trying to submit another job.
10:47:00 job_callback for (8, 0, 0) got condition
10:47:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:47:00 HBMASTER: Trying to run another job!
10:47:00 job_callback for (8, 0, 0) finished
10:47:00 HBMASTER: schedule new run for iteration 8
10:47:00 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
10:47:00 HBMASTER: submitting job (8, 0, 3) to dispatcher
10:47:00 DISPATCHER: trying to submit job (8, 0, 3)
10:47:00 DISPATCHER: trying to notify the job_runner thread.
10:47:00 HBMASTER: job (8, 0, 3) submitted to dispatcher
10:47:00 DISPATCHER: Trying to submit another job.
10:47:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:47:00 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:47:00 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:47:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:47:00 WORKER: start processing job (8, 0, 3)
10:47:00 WORKER: args: ()
10:47:00 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 617, 'last_n_outputs': 49, 'leak_rate': 0.8781243682102043, 'lr': 0.0012568398970940235, 'optimizer': 'SGD', 'sparsity': 0.9444325856831859, 'steps_to_train': 64, 'weight_decay': 0.025809972198303208}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:47:33 DISPATCHER: Starting worker discovery
10:47:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:47:33 DISPATCHER: Finished worker discovery
10:48:33 DISPATCHER: Starting worker discovery
10:48:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:48:33 DISPATCHER: Finished worker discovery
10:49:33 DISPATCHER: Starting worker discovery
10:49:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:49:33 DISPATCHER: Finished worker discovery
10:50:10 WORKER: done with job (8, 0, 3), trying to register it.
10:50:10 WORKER: registered result for job (8, 0, 3) with dispatcher
10:50:10 DISPATCHER: job (8, 0, 3) finished
10:50:10 DISPATCHER: register_result: lock acquired
10:50:10 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:50:10 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 617, 'last_n_outputs': 49, 'leak_rate': 0.8781243682102043, 'lr': 0.0012568398970940235, 'optimizer': 'SGD', 'sparsity': 0.9444325856831859, 'steps_to_train': 64, 'weight_decay': 0.025809972198303208}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2647286067076878, 'info': {'data03': 0.2647286067076878, 'config': "{'batch_size': 16, 'hidden_dim': 617, 'last_n_outputs': 49, 'leak_rate': 0.8781243682102043, 'lr': 0.0012568398970940235, 'optimizer': 'SGD', 'sparsity': 0.9444325856831859, 'steps_to_train': 64, 'weight_decay': 0.025809972198303208}"}}
exception: None

10:50:10 job_callback for (8, 0, 3) started
10:50:10 job_callback for (8, 0, 3) got condition
10:50:10 DISPATCHER: Trying to submit another job.
10:50:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:50:10 HBMASTER: Trying to run another job!
10:50:10 job_callback for (8, 0, 3) finished
10:50:10 HBMASTER: schedule new run for iteration 8
10:50:10 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
10:50:10 HBMASTER: submitting job (8, 0, 8) to dispatcher
10:50:10 DISPATCHER: trying to submit job (8, 0, 8)
10:50:10 DISPATCHER: trying to notify the job_runner thread.
10:50:10 HBMASTER: job (8, 0, 8) submitted to dispatcher
10:50:10 DISPATCHER: Trying to submit another job.
10:50:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:50:10 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:50:10 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:50:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:50:10 WORKER: start processing job (8, 0, 8)
10:50:10 WORKER: args: ()
10:50:10 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 442, 'last_n_outputs': 48, 'leak_rate': 0.9202685393804955, 'lr': 0.001907948028531219, 'optimizer': 'Adam', 'sparsity': 0.9457006940735685, 'steps_to_train': 68, 'weight_decay': 0.018306732302532536}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:50:33 DISPATCHER: Starting worker discovery
10:50:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:50:33 DISPATCHER: Finished worker discovery
10:51:33 DISPATCHER: Starting worker discovery
10:51:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:51:33 DISPATCHER: Finished worker discovery
10:52:33 DISPATCHER: Starting worker discovery
10:52:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:52:33 DISPATCHER: Finished worker discovery
10:53:29 WORKER: done with job (8, 0, 8), trying to register it.
10:53:29 WORKER: registered result for job (8, 0, 8) with dispatcher
10:53:29 DISPATCHER: job (8, 0, 8) finished
10:53:29 DISPATCHER: register_result: lock acquired
10:53:29 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:53:29 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 442, 'last_n_outputs': 48, 'leak_rate': 0.9202685393804955, 'lr': 0.001907948028531219, 'optimizer': 'Adam', 'sparsity': 0.9457006940735685, 'steps_to_train': 68, 'weight_decay': 0.018306732302532536}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2818839174393951, 'info': {'data03': 0.2818839174393951, 'config': "{'batch_size': 16, 'hidden_dim': 442, 'last_n_outputs': 48, 'leak_rate': 0.9202685393804955, 'lr': 0.001907948028531219, 'optimizer': 'Adam', 'sparsity': 0.9457006940735685, 'steps_to_train': 68, 'weight_decay': 0.018306732302532536}"}}
exception: None

10:53:29 job_callback for (8, 0, 8) started
10:53:29 job_callback for (8, 0, 8) got condition
10:53:29 DISPATCHER: Trying to submit another job.
10:53:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:53:29 HBMASTER: Trying to run another job!
10:53:29 job_callback for (8, 0, 8) finished
10:53:29 HBMASTER: schedule new run for iteration 8
10:53:29 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
10:53:29 HBMASTER: submitting job (8, 0, 12) to dispatcher
10:53:29 DISPATCHER: trying to submit job (8, 0, 12)
10:53:29 DISPATCHER: trying to notify the job_runner thread.
10:53:29 HBMASTER: job (8, 0, 12) submitted to dispatcher
10:53:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:53:29 DISPATCHER: Trying to submit another job.
10:53:29 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:53:29 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:53:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:53:29 WORKER: start processing job (8, 0, 12)
10:53:29 WORKER: args: ()
10:53:29 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 517, 'last_n_outputs': 47, 'leak_rate': 0.8859978448655896, 'lr': 0.008554846890515114, 'optimizer': 'Adam', 'sparsity': 0.8999708279859115, 'steps_to_train': 80, 'weight_decay': 0.02479220057034827}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:53:33 DISPATCHER: Starting worker discovery
10:53:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:53:33 DISPATCHER: Finished worker discovery
10:54:33 DISPATCHER: Starting worker discovery
10:54:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:54:34 DISPATCHER: Finished worker discovery
10:55:34 DISPATCHER: Starting worker discovery
10:55:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:55:34 DISPATCHER: Finished worker discovery
10:56:34 DISPATCHER: Starting worker discovery
10:56:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:56:34 DISPATCHER: Finished worker discovery
10:56:37 WORKER: done with job (8, 0, 12), trying to register it.
10:56:37 WORKER: registered result for job (8, 0, 12) with dispatcher
10:56:37 DISPATCHER: job (8, 0, 12) finished
10:56:37 DISPATCHER: register_result: lock acquired
10:56:37 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:56:37 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 517, 'last_n_outputs': 47, 'leak_rate': 0.8859978448655896, 'lr': 0.008554846890515114, 'optimizer': 'Adam', 'sparsity': 0.8999708279859115, 'steps_to_train': 80, 'weight_decay': 0.02479220057034827}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.19418100243614786, 'info': {'data03': 0.19418100243614786, 'config': "{'batch_size': 16, 'hidden_dim': 517, 'last_n_outputs': 47, 'leak_rate': 0.8859978448655896, 'lr': 0.008554846890515114, 'optimizer': 'Adam', 'sparsity': 0.8999708279859115, 'steps_to_train': 80, 'weight_decay': 0.02479220057034827}"}}
exception: None

10:56:37 job_callback for (8, 0, 12) started
10:56:37 DISPATCHER: Trying to submit another job.
10:56:37 job_callback for (8, 0, 12) got condition
10:56:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:56:37 HBMASTER: Trying to run another job!
10:56:37 job_callback for (8, 0, 12) finished
10:56:37 HBMASTER: schedule new run for iteration 8
10:56:37 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
10:56:37 HBMASTER: submitting job (8, 0, 15) to dispatcher
10:56:37 DISPATCHER: trying to submit job (8, 0, 15)
10:56:37 DISPATCHER: trying to notify the job_runner thread.
10:56:37 HBMASTER: job (8, 0, 15) submitted to dispatcher
10:56:37 DISPATCHER: Trying to submit another job.
10:56:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:56:37 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:56:37 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:56:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:56:37 WORKER: start processing job (8, 0, 15)
10:56:37 WORKER: args: ()
10:56:37 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 450, 'last_n_outputs': 46, 'leak_rate': 0.9736113980452591, 'lr': 0.01138307173959682, 'optimizer': 'Adam', 'sparsity': 0.9019240329500808, 'steps_to_train': 35, 'weight_decay': 0.05150874348609912}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:57:34 DISPATCHER: Starting worker discovery
10:57:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:57:34 DISPATCHER: Finished worker discovery
10:58:34 DISPATCHER: Starting worker discovery
10:58:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:58:34 DISPATCHER: Finished worker discovery
10:59:33 WORKER: done with job (8, 0, 15), trying to register it.
10:59:33 WORKER: registered result for job (8, 0, 15) with dispatcher
10:59:33 DISPATCHER: job (8, 0, 15) finished
10:59:33 DISPATCHER: register_result: lock acquired
10:59:33 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:59:33 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 450, 'last_n_outputs': 46, 'leak_rate': 0.9736113980452591, 'lr': 0.01138307173959682, 'optimizer': 'Adam', 'sparsity': 0.9019240329500808, 'steps_to_train': 35, 'weight_decay': 0.05150874348609912}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2774651242918782, 'info': {'data03': 0.2774651242918782, 'config': "{'batch_size': 64, 'hidden_dim': 450, 'last_n_outputs': 46, 'leak_rate': 0.9736113980452591, 'lr': 0.01138307173959682, 'optimizer': 'Adam', 'sparsity': 0.9019240329500808, 'steps_to_train': 35, 'weight_decay': 0.05150874348609912}"}}
exception: None

10:59:33 job_callback for (8, 0, 15) started
10:59:33 job_callback for (8, 0, 15) got condition
10:59:33 DISPATCHER: Trying to submit another job.
10:59:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:59:33 HBMASTER: Trying to run another job!
10:59:33 job_callback for (8, 0, 15) finished
10:59:33 HBMASTER: schedule new run for iteration 8
10:59:33 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
10:59:33 HBMASTER: submitting job (8, 0, 17) to dispatcher
10:59:33 DISPATCHER: trying to submit job (8, 0, 17)
10:59:33 DISPATCHER: trying to notify the job_runner thread.
10:59:33 HBMASTER: job (8, 0, 17) submitted to dispatcher
10:59:33 DISPATCHER: Trying to submit another job.
10:59:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:59:33 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:59:33 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:59:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:59:33 WORKER: start processing job (8, 0, 17)
10:59:33 WORKER: args: ()
10:59:33 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 338, 'last_n_outputs': 26, 'leak_rate': 0.768849424374545, 'lr': 0.004610820621435558, 'optimizer': 'Adam', 'sparsity': 0.7697913500557674, 'steps_to_train': 20, 'weight_decay': 0.015357261509971576}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:59:34 DISPATCHER: Starting worker discovery
10:59:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:59:34 DISPATCHER: Finished worker discovery
11:00:34 DISPATCHER: Starting worker discovery
11:00:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:00:34 DISPATCHER: Finished worker discovery
11:01:34 DISPATCHER: Starting worker discovery
11:01:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:01:34 DISPATCHER: Finished worker discovery
11:02:29 WORKER: done with job (8, 0, 17), trying to register it.
11:02:29 WORKER: registered result for job (8, 0, 17) with dispatcher
11:02:29 DISPATCHER: job (8, 0, 17) finished
11:02:29 DISPATCHER: register_result: lock acquired
11:02:29 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
11:02:29 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 338, 'last_n_outputs': 26, 'leak_rate': 0.768849424374545, 'lr': 0.004610820621435558, 'optimizer': 'Adam', 'sparsity': 0.7697913500557674, 'steps_to_train': 20, 'weight_decay': 0.015357261509971576}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.17533245128986683, 'info': {'data03': 0.17533245128986683, 'config': "{'batch_size': 16, 'hidden_dim': 338, 'last_n_outputs': 26, 'leak_rate': 0.768849424374545, 'lr': 0.004610820621435558, 'optimizer': 'Adam', 'sparsity': 0.7697913500557674, 'steps_to_train': 20, 'weight_decay': 0.015357261509971576}"}}
exception: None

11:02:29 job_callback for (8, 0, 17) started
11:02:29 job_callback for (8, 0, 17) got condition
11:02:29 DISPATCHER: Trying to submit another job.
11:02:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:02:29 HBMASTER: Trying to run another job!
11:02:29 job_callback for (8, 0, 17) finished
11:02:29 HBMASTER: schedule new run for iteration 8
11:02:29 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
11:02:29 HBMASTER: submitting job (8, 0, 18) to dispatcher
11:02:29 DISPATCHER: trying to submit job (8, 0, 18)
11:02:29 DISPATCHER: trying to notify the job_runner thread.
11:02:29 HBMASTER: job (8, 0, 18) submitted to dispatcher
11:02:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:02:29 DISPATCHER: Trying to submit another job.
11:02:29 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpui.1576139975513683776
11:02:29 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
11:02:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:02:29 WORKER: start processing job (8, 0, 18)
11:02:29 WORKER: args: ()
11:02:29 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 556, 'last_n_outputs': 28, 'leak_rate': 0.8050935102271035, 'lr': 0.02415475933062214, 'optimizer': 'Adam', 'sparsity': 0.8189626229439599, 'steps_to_train': 81, 'weight_decay': 0.020010469328429797}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:02:34 DISPATCHER: Starting worker discovery
11:02:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:02:34 DISPATCHER: Finished worker discovery
11:03:34 DISPATCHER: Starting worker discovery
11:03:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:03:34 DISPATCHER: Finished worker discovery
11:04:34 DISPATCHER: Starting worker discovery
11:04:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:04:34 DISPATCHER: Finished worker discovery
11:05:34 DISPATCHER: Starting worker discovery
11:05:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:05:34 DISPATCHER: Finished worker discovery
11:05:44 WORKER: done with job (8, 0, 18), trying to register it.
11:05:44 WORKER: registered result for job (8, 0, 18) with dispatcher
11:05:44 DISPATCHER: job (8, 0, 18) finished
11:05:44 DISPATCHER: register_result: lock acquired
11:05:44 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
11:05:44 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 556, 'last_n_outputs': 28, 'leak_rate': 0.8050935102271035, 'lr': 0.02415475933062214, 'optimizer': 'Adam', 'sparsity': 0.8189626229439599, 'steps_to_train': 81, 'weight_decay': 0.020010469328429797}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.25918833053234047, 'info': {'data03': 0.25918833053234047, 'config': "{'batch_size': 32, 'hidden_dim': 556, 'last_n_outputs': 28, 'leak_rate': 0.8050935102271035, 'lr': 0.02415475933062214, 'optimizer': 'Adam', 'sparsity': 0.8189626229439599, 'steps_to_train': 81, 'weight_decay': 0.020010469328429797}"}}
exception: None

11:05:44 job_callback for (8, 0, 18) started
11:05:44 DISPATCHER: Trying to submit another job.
11:05:44 job_callback for (8, 0, 18) got condition
11:05:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:05:44 HBMASTER: Trying to run another job!
11:05:44 job_callback for (8, 0, 18) finished
11:05:44 HBMASTER: schedule new run for iteration 8
11:05:44 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
11:05:44 HBMASTER: submitting job (8, 0, 22) to dispatcher
11:05:44 DISPATCHER: trying to submit job (8, 0, 22)
11:05:44 DISPATCHER: trying to notify the job_runner thread.
11:05:44 HBMASTER: job (8, 0, 22) submitted to dispatcher
11:05:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:05:44 DISPATCHER: Trying to submit another job.
11:05:44 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776
11:05:44 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
11:05:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:05:44 WORKER: start processing job (8, 0, 22)
11:05:44 WORKER: args: ()
11:05:44 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 867, 'last_n_outputs': 44, 'leak_rate': 0.9243735574011842, 'lr': 0.0010430727512892764, 'optimizer': 'Adam', 'sparsity': 0.9721605670676567, 'steps_to_train': 85, 'weight_decay': 0.057023369952818995}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:06:34 DISPATCHER: Starting worker discovery
11:06:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:06:34 DISPATCHER: Finished worker discovery
11:07:34 DISPATCHER: Starting worker discovery
11:07:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:07:34 DISPATCHER: Finished worker discovery
11:08:34 DISPATCHER: Starting worker discovery
11:08:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:08:34 DISPATCHER: Finished worker discovery
11:08:36 WORKER: done with job (8, 0, 22), trying to register it.
11:08:36 WORKER: registered result for job (8, 0, 22) with dispatcher
11:08:36 DISPATCHER: job (8, 0, 22) finished
11:08:36 DISPATCHER: register_result: lock acquired
11:08:36 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
11:08:36 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 867, 'last_n_outputs': 44, 'leak_rate': 0.9243735574011842, 'lr': 0.0010430727512892764, 'optimizer': 'Adam', 'sparsity': 0.9721605670676567, 'steps_to_train': 85, 'weight_decay': 0.057023369952818995}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.34083334552540684, 'info': {'data03': 0.34083334552540684, 'config': "{'batch_size': 16, 'hidden_dim': 867, 'last_n_outputs': 44, 'leak_rate': 0.9243735574011842, 'lr': 0.0010430727512892764, 'optimizer': 'Adam', 'sparsity': 0.9721605670676567, 'steps_to_train': 85, 'weight_decay': 0.057023369952818995}"}}
exception: None

11:08:36 job_callback for (8, 0, 22) started
11:08:36 job_callback for (8, 0, 22) got condition
11:08:36 DISPATCHER: Trying to submit another job.
11:08:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:08:36 HBMASTER: Trying to run another job!
11:08:36 job_callback for (8, 0, 22) finished
11:08:36 HBMASTER: schedule new run for iteration 8
11:08:36 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
11:08:36 HBMASTER: submitting job (8, 0, 24) to dispatcher
11:08:36 DISPATCHER: trying to submit job (8, 0, 24)
11:08:36 DISPATCHER: trying to notify the job_runner thread.
11:08:36 HBMASTER: job (8, 0, 24) submitted to dispatcher
11:08:36 DISPATCHER: Trying to submit another job.
11:08:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:08:36 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776
11:08:36 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
11:08:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:08:36 WORKER: start processing job (8, 0, 24)
11:08:36 WORKER: args: ()
11:08:36 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 666, 'last_n_outputs': 45, 'leak_rate': 0.83963729699149, 'lr': 0.005145965725110344, 'optimizer': 'Adam', 'sparsity': 0.8181075445375657, 'steps_to_train': 86, 'weight_decay': 0.06530113624438481}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:09:34 DISPATCHER: Starting worker discovery
11:09:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:09:34 DISPATCHER: Finished worker discovery
11:10:34 DISPATCHER: Starting worker discovery
11:10:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:10:34 DISPATCHER: Finished worker discovery
11:11:34 DISPATCHER: Starting worker discovery
11:11:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:11:34 DISPATCHER: Finished worker discovery
11:11:47 WORKER: done with job (8, 0, 24), trying to register it.
11:11:47 WORKER: registered result for job (8, 0, 24) with dispatcher
11:11:47 DISPATCHER: job (8, 0, 24) finished
11:11:47 DISPATCHER: register_result: lock acquired
11:11:47 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
11:11:47 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 666, 'last_n_outputs': 45, 'leak_rate': 0.83963729699149, 'lr': 0.005145965725110344, 'optimizer': 'Adam', 'sparsity': 0.8181075445375657, 'steps_to_train': 86, 'weight_decay': 0.06530113624438481}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2697893454274596, 'info': {'data03': 0.2697893454274596, 'config': "{'batch_size': 16, 'hidden_dim': 666, 'last_n_outputs': 45, 'leak_rate': 0.83963729699149, 'lr': 0.005145965725110344, 'optimizer': 'Adam', 'sparsity': 0.8181075445375657, 'steps_to_train': 86, 'weight_decay': 0.06530113624438481}"}}
exception: None

11:11:47 job_callback for (8, 0, 24) started
11:11:47 DISPATCHER: Trying to submit another job.
11:11:47 job_callback for (8, 0, 24) got condition
11:11:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:11:47 HBMASTER: Trying to run another job!
11:11:47 job_callback for (8, 0, 24) finished
11:11:47 ITERATION: Advancing config (8, 0, 8) to next budget 400.000000
11:11:47 ITERATION: Advancing config (8, 0, 15) to next budget 400.000000
11:11:47 ITERATION: Advancing config (8, 0, 22) to next budget 400.000000
11:11:47 HBMASTER: schedule new run for iteration 8
11:11:47 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
11:11:47 HBMASTER: submitting job (8, 0, 8) to dispatcher
11:11:47 DISPATCHER: trying to submit job (8, 0, 8)
11:11:47 DISPATCHER: trying to notify the job_runner thread.
11:11:47 HBMASTER: job (8, 0, 8) submitted to dispatcher
11:11:47 DISPATCHER: Trying to submit another job.
11:11:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:11:47 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776
11:11:47 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
11:11:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:11:47 WORKER: start processing job (8, 0, 8)
11:11:47 WORKER: args: ()
11:11:47 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 442, 'last_n_outputs': 48, 'leak_rate': 0.9202685393804955, 'lr': 0.001907948028531219, 'optimizer': 'Adam', 'sparsity': 0.9457006940735685, 'steps_to_train': 68, 'weight_decay': 0.018306732302532536}, 'budget': 400.0, 'working_directory': '.'}
11:12:34 DISPATCHER: Starting worker discovery
11:12:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:12:34 DISPATCHER: Finished worker discovery
11:13:34 DISPATCHER: Starting worker discovery
11:13:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:13:34 DISPATCHER: Finished worker discovery
11:14:34 DISPATCHER: Starting worker discovery
11:14:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:14:34 DISPATCHER: Finished worker discovery
11:15:34 DISPATCHER: Starting worker discovery
11:15:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:15:34 DISPATCHER: Finished worker discovery
11:16:34 DISPATCHER: Starting worker discovery
11:16:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:16:34 DISPATCHER: Finished worker discovery
11:17:34 DISPATCHER: Starting worker discovery
11:17:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:17:34 DISPATCHER: Finished worker discovery
11:18:34 DISPATCHER: Starting worker discovery
11:18:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:18:34 DISPATCHER: Finished worker discovery
11:19:23 WORKER: done with job (8, 0, 8), trying to register it.
11:19:23 WORKER: registered result for job (8, 0, 8) with dispatcher
11:19:23 DISPATCHER: job (8, 0, 8) finished
11:19:23 DISPATCHER: register_result: lock acquired
11:19:23 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
11:19:23 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 442, 'last_n_outputs': 48, 'leak_rate': 0.9202685393804955, 'lr': 0.001907948028531219, 'optimizer': 'Adam', 'sparsity': 0.9457006940735685, 'steps_to_train': 68, 'weight_decay': 0.018306732302532536}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.2472744586479778, 'info': {'data03': 0.2472744586479778, 'config': "{'batch_size': 16, 'hidden_dim': 442, 'last_n_outputs': 48, 'leak_rate': 0.9202685393804955, 'lr': 0.001907948028531219, 'optimizer': 'Adam', 'sparsity': 0.9457006940735685, 'steps_to_train': 68, 'weight_decay': 0.018306732302532536}"}}
exception: None

11:19:23 job_callback for (8, 0, 8) started
11:19:23 job_callback for (8, 0, 8) got condition
11:19:23 DISPATCHER: Trying to submit another job.
11:19:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:19:23 done building a new model for budget 400.000000 based on 10/21 split
Best loss for this budget:-0.340020





11:19:23 HBMASTER: Trying to run another job!
11:19:23 job_callback for (8, 0, 8) finished
11:19:23 HBMASTER: schedule new run for iteration 8
11:19:23 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
11:19:23 HBMASTER: submitting job (8, 0, 15) to dispatcher
11:19:23 DISPATCHER: trying to submit job (8, 0, 15)
11:19:23 DISPATCHER: trying to notify the job_runner thread.
11:19:23 HBMASTER: job (8, 0, 15) submitted to dispatcher
11:19:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:19:23 DISPATCHER: Trying to submit another job.
11:19:23 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776
11:19:23 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
11:19:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:19:23 WORKER: start processing job (8, 0, 15)
11:19:23 WORKER: args: ()
11:19:23 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 450, 'last_n_outputs': 46, 'leak_rate': 0.9736113980452591, 'lr': 0.01138307173959682, 'optimizer': 'Adam', 'sparsity': 0.9019240329500808, 'steps_to_train': 35, 'weight_decay': 0.05150874348609912}, 'budget': 400.0, 'working_directory': '.'}
11:19:34 DISPATCHER: Starting worker discovery
11:19:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:19:34 DISPATCHER: Finished worker discovery
11:20:34 DISPATCHER: Starting worker discovery
11:20:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:20:34 DISPATCHER: Finished worker discovery
11:21:34 DISPATCHER: Starting worker discovery
11:21:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:21:34 DISPATCHER: Finished worker discovery
11:22:34 DISPATCHER: Starting worker discovery
11:22:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:22:34 DISPATCHER: Finished worker discovery
11:23:34 DISPATCHER: Starting worker discovery
11:23:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:23:34 DISPATCHER: Finished worker discovery
11:24:34 DISPATCHER: Starting worker discovery
11:24:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:24:34 DISPATCHER: Finished worker discovery
11:25:34 DISPATCHER: Starting worker discovery
11:25:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:25:34 DISPATCHER: Finished worker discovery
11:26:34 DISPATCHER: Starting worker discovery
11:26:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:26:34 DISPATCHER: Finished worker discovery
11:26:54 WORKER: done with job (8, 0, 15), trying to register it.
11:26:54 WORKER: registered result for job (8, 0, 15) with dispatcher
11:26:54 DISPATCHER: job (8, 0, 15) finished
11:26:54 DISPATCHER: register_result: lock acquired
11:26:54 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
11:26:54 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 450, 'last_n_outputs': 46, 'leak_rate': 0.9736113980452591, 'lr': 0.01138307173959682, 'optimizer': 'Adam', 'sparsity': 0.9019240329500808, 'steps_to_train': 35, 'weight_decay': 0.05150874348609912}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.22052192024328665, 'info': {'data03': 0.22052192024328665, 'config': "{'batch_size': 64, 'hidden_dim': 450, 'last_n_outputs': 46, 'leak_rate': 0.9736113980452591, 'lr': 0.01138307173959682, 'optimizer': 'Adam', 'sparsity': 0.9019240329500808, 'steps_to_train': 35, 'weight_decay': 0.05150874348609912}"}}
exception: None

11:26:54 job_callback for (8, 0, 15) started
11:26:54 DISPATCHER: Trying to submit another job.
11:26:54 job_callback for (8, 0, 15) got condition
11:26:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:26:54 done building a new model for budget 400.000000 based on 10/22 split
Best loss for this budget:-0.340020





11:26:54 HBMASTER: Trying to run another job!
11:26:54 job_callback for (8, 0, 15) finished
11:26:54 HBMASTER: schedule new run for iteration 8
11:26:54 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
11:26:54 HBMASTER: submitting job (8, 0, 22) to dispatcher
11:26:54 DISPATCHER: trying to submit job (8, 0, 22)
11:26:54 DISPATCHER: trying to notify the job_runner thread.
11:26:54 HBMASTER: job (8, 0, 22) submitted to dispatcher
11:26:54 DISPATCHER: Trying to submit another job.
11:26:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:26:54 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776
11:26:54 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
11:26:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:26:54 WORKER: start processing job (8, 0, 22)
11:26:54 WORKER: args: ()
11:26:54 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 867, 'last_n_outputs': 44, 'leak_rate': 0.9243735574011842, 'lr': 0.0010430727512892764, 'optimizer': 'Adam', 'sparsity': 0.9721605670676567, 'steps_to_train': 85, 'weight_decay': 0.057023369952818995}, 'budget': 400.0, 'working_directory': '.'}
11:27:34 DISPATCHER: Starting worker discovery
11:27:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:27:34 DISPATCHER: Finished worker discovery
11:28:34 DISPATCHER: Starting worker discovery
11:28:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:28:34 DISPATCHER: Finished worker discovery
11:29:34 DISPATCHER: Starting worker discovery
11:29:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:29:34 DISPATCHER: Finished worker discovery
11:30:34 DISPATCHER: Starting worker discovery
11:30:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:30:34 DISPATCHER: Finished worker discovery
11:31:34 DISPATCHER: Starting worker discovery
11:31:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:31:34 DISPATCHER: Finished worker discovery
11:32:34 DISPATCHER: Starting worker discovery
11:32:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:32:34 DISPATCHER: Finished worker discovery
11:33:34 DISPATCHER: Starting worker discovery
11:33:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:33:34 DISPATCHER: Finished worker discovery
11:34:23 WORKER: done with job (8, 0, 22), trying to register it.
11:34:23 WORKER: registered result for job (8, 0, 22) with dispatcher
11:34:23 DISPATCHER: job (8, 0, 22) finished
11:34:23 DISPATCHER: register_result: lock acquired
11:34:23 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
11:34:23 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 867, 'last_n_outputs': 44, 'leak_rate': 0.9243735574011842, 'lr': 0.0010430727512892764, 'optimizer': 'Adam', 'sparsity': 0.9721605670676567, 'steps_to_train': 85, 'weight_decay': 0.057023369952818995}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.29848105161544464, 'info': {'data03': 0.29848105161544464, 'config': "{'batch_size': 16, 'hidden_dim': 867, 'last_n_outputs': 44, 'leak_rate': 0.9243735574011842, 'lr': 0.0010430727512892764, 'optimizer': 'Adam', 'sparsity': 0.9721605670676567, 'steps_to_train': 85, 'weight_decay': 0.057023369952818995}"}}
exception: None

11:34:23 job_callback for (8, 0, 22) started
11:34:23 job_callback for (8, 0, 22) got condition
11:34:23 DISPATCHER: Trying to submit another job.
11:34:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:34:23 done building a new model for budget 400.000000 based on 10/22 split
Best loss for this budget:-0.340020





11:34:23 HBMASTER: Trying to run another job!
11:34:23 job_callback for (8, 0, 22) finished
11:34:23 ITERATION: Advancing config (8, 0, 22) to next budget 1200.000000
11:34:23 HBMASTER: schedule new run for iteration 8
11:34:23 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
11:34:23 HBMASTER: submitting job (8, 0, 22) to dispatcher
11:34:23 DISPATCHER: trying to submit job (8, 0, 22)
11:34:23 DISPATCHER: trying to notify the job_runner thread.
11:34:23 HBMASTER: job (8, 0, 22) submitted to dispatcher
11:34:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:34:23 DISPATCHER: Trying to submit another job.
11:34:23 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776
11:34:23 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
11:34:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:34:23 WORKER: start processing job (8, 0, 22)
11:34:23 WORKER: args: ()
11:34:23 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 867, 'last_n_outputs': 44, 'leak_rate': 0.9243735574011842, 'lr': 0.0010430727512892764, 'optimizer': 'Adam', 'sparsity': 0.9721605670676567, 'steps_to_train': 85, 'weight_decay': 0.057023369952818995}, 'budget': 1200.0, 'working_directory': '.'}
11:34:34 DISPATCHER: Starting worker discovery
11:34:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:34:34 DISPATCHER: Finished worker discovery
11:35:34 DISPATCHER: Starting worker discovery
11:35:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:35:34 DISPATCHER: Finished worker discovery
11:36:34 DISPATCHER: Starting worker discovery
11:36:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:36:34 DISPATCHER: Finished worker discovery
11:37:34 DISPATCHER: Starting worker discovery
11:37:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:37:34 DISPATCHER: Finished worker discovery
11:38:34 DISPATCHER: Starting worker discovery
11:38:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:38:34 DISPATCHER: Finished worker discovery
11:39:34 DISPATCHER: Starting worker discovery
11:39:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:39:34 DISPATCHER: Finished worker discovery
11:40:34 DISPATCHER: Starting worker discovery
11:40:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:40:34 DISPATCHER: Finished worker discovery
11:41:34 DISPATCHER: Starting worker discovery
11:41:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:41:34 DISPATCHER: Finished worker discovery
11:42:34 DISPATCHER: Starting worker discovery
11:42:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:42:34 DISPATCHER: Finished worker discovery
11:43:34 DISPATCHER: Starting worker discovery
11:43:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:43:34 DISPATCHER: Finished worker discovery
11:44:34 DISPATCHER: Starting worker discovery
11:44:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:44:34 DISPATCHER: Finished worker discovery
11:45:34 DISPATCHER: Starting worker discovery
11:45:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:45:34 DISPATCHER: Finished worker discovery
11:46:34 DISPATCHER: Starting worker discovery
11:46:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:46:34 DISPATCHER: Finished worker discovery
11:47:34 DISPATCHER: Starting worker discovery
11:47:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:47:34 DISPATCHER: Finished worker discovery
11:48:34 DISPATCHER: Starting worker discovery
11:48:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:48:34 DISPATCHER: Finished worker discovery
11:49:34 DISPATCHER: Starting worker discovery
11:49:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:49:34 DISPATCHER: Finished worker discovery
11:50:34 DISPATCHER: Starting worker discovery
11:50:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:50:34 DISPATCHER: Finished worker discovery
11:51:34 DISPATCHER: Starting worker discovery
11:51:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:51:34 DISPATCHER: Finished worker discovery
11:52:34 DISPATCHER: Starting worker discovery
11:52:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:52:34 DISPATCHER: Finished worker discovery
11:53:34 DISPATCHER: Starting worker discovery
11:53:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:53:34 DISPATCHER: Finished worker discovery
11:54:34 DISPATCHER: Starting worker discovery
11:54:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:54:34 DISPATCHER: Finished worker discovery
11:55:34 DISPATCHER: Starting worker discovery
11:55:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:55:34 DISPATCHER: Finished worker discovery
11:55:38 WORKER: done with job (8, 0, 22), trying to register it.
11:55:38 WORKER: registered result for job (8, 0, 22) with dispatcher
11:55:38 DISPATCHER: job (8, 0, 22) finished
11:55:38 DISPATCHER: register_result: lock acquired
11:55:38 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
11:55:38 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 867, 'last_n_outputs': 44, 'leak_rate': 0.9243735574011842, 'lr': 0.0010430727512892764, 'optimizer': 'Adam', 'sparsity': 0.9721605670676567, 'steps_to_train': 85, 'weight_decay': 0.057023369952818995}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.2879465947431026, 'info': {'data03': 0.2879465947431026, 'config': "{'batch_size': 16, 'hidden_dim': 867, 'last_n_outputs': 44, 'leak_rate': 0.9243735574011842, 'lr': 0.0010430727512892764, 'optimizer': 'Adam', 'sparsity': 0.9721605670676567, 'steps_to_train': 85, 'weight_decay': 0.057023369952818995}"}}
exception: None

11:55:38 job_callback for (8, 0, 22) started
11:55:38 job_callback for (8, 0, 22) got condition
11:55:38 DISPATCHER: Trying to submit another job.
11:55:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:55:38 HBMASTER: Trying to run another job!
11:55:38 job_callback for (8, 0, 22) finished
11:55:38 start sampling a new configuration.
11:55:38 done sampling a new configuration.
11:55:38 HBMASTER: schedule new run for iteration 9
11:55:38 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
11:55:38 HBMASTER: submitting job (9, 0, 0) to dispatcher
11:55:38 DISPATCHER: trying to submit job (9, 0, 0)
11:55:38 DISPATCHER: trying to notify the job_runner thread.
11:55:38 HBMASTER: job (9, 0, 0) submitted to dispatcher
11:55:38 DISPATCHER: Trying to submit another job.
11:55:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:55:38 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
11:55:38 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
11:55:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:55:38 WORKER: start processing job (9, 0, 0)
11:55:38 WORKER: args: ()
11:55:38 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 853, 'last_n_outputs': 29, 'leak_rate': 0.7727120557385249, 'lr': 0.014784413387465905, 'optimizer': 'SGD', 'sparsity': 0.8160510503273987, 'steps_to_train': 72, 'weight_decay': 0.17628126687245121}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:56:34 DISPATCHER: Starting worker discovery
11:56:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:56:34 DISPATCHER: Finished worker discovery
11:57:34 DISPATCHER: Starting worker discovery
11:57:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:57:34 DISPATCHER: Finished worker discovery
11:58:34 DISPATCHER: Starting worker discovery
11:58:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:58:34 DISPATCHER: Finished worker discovery
11:58:44 WORKER: done with job (9, 0, 0), trying to register it.
11:58:44 WORKER: registered result for job (9, 0, 0) with dispatcher
11:58:44 DISPATCHER: job (9, 0, 0) finished
11:58:44 DISPATCHER: register_result: lock acquired
11:58:44 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
11:58:44 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 853, 'last_n_outputs': 29, 'leak_rate': 0.7727120557385249, 'lr': 0.014784413387465905, 'optimizer': 'SGD', 'sparsity': 0.8160510503273987, 'steps_to_train': 72, 'weight_decay': 0.17628126687245121}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.17119565728028815, 'info': {'data03': 0.17119565728028815, 'config': "{'batch_size': 128, 'hidden_dim': 853, 'last_n_outputs': 29, 'leak_rate': 0.7727120557385249, 'lr': 0.014784413387465905, 'optimizer': 'SGD', 'sparsity': 0.8160510503273987, 'steps_to_train': 72, 'weight_decay': 0.17628126687245121}"}}
exception: None

11:58:44 DISPATCHER: Trying to submit another job.
11:58:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:58:44 job_callback for (9, 0, 0) started
11:58:44 job_callback for (9, 0, 0) got condition
11:58:44 HBMASTER: Trying to run another job!
11:58:44 job_callback for (9, 0, 0) finished
11:58:44 start sampling a new configuration.
11:58:44 done sampling a new configuration.
11:58:44 HBMASTER: schedule new run for iteration 9
11:58:44 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
11:58:44 HBMASTER: submitting job (9, 0, 1) to dispatcher
11:58:44 DISPATCHER: trying to submit job (9, 0, 1)
11:58:44 DISPATCHER: trying to notify the job_runner thread.
11:58:44 HBMASTER: job (9, 0, 1) submitted to dispatcher
11:58:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:58:44 DISPATCHER: Trying to submit another job.
11:58:44 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
11:58:44 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
11:58:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:58:44 WORKER: start processing job (9, 0, 1)
11:58:44 WORKER: args: ()
11:58:44 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 785, 'last_n_outputs': 20, 'leak_rate': 0.9479132180823372, 'lr': 0.014294123072044411, 'optimizer': 'Adam', 'sparsity': 0.7930949216704407, 'steps_to_train': 77, 'weight_decay': 0.06218301187719215}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:59:34 DISPATCHER: Starting worker discovery
11:59:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:59:34 DISPATCHER: Finished worker discovery
12:00:34 DISPATCHER: Starting worker discovery
12:00:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:00:34 DISPATCHER: Finished worker discovery
12:01:34 DISPATCHER: Starting worker discovery
12:01:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:01:34 DISPATCHER: Finished worker discovery
12:01:46 WORKER: done with job (9, 0, 1), trying to register it.
12:01:46 WORKER: registered result for job (9, 0, 1) with dispatcher
12:01:46 DISPATCHER: job (9, 0, 1) finished
12:01:46 DISPATCHER: register_result: lock acquired
12:01:46 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
12:01:46 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 785, 'last_n_outputs': 20, 'leak_rate': 0.9479132180823372, 'lr': 0.014294123072044411, 'optimizer': 'Adam', 'sparsity': 0.7930949216704407, 'steps_to_train': 77, 'weight_decay': 0.06218301187719215}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.007437207972557226, 'info': {'data03': 0.007437207972557226, 'config': "{'batch_size': 64, 'hidden_dim': 785, 'last_n_outputs': 20, 'leak_rate': 0.9479132180823372, 'lr': 0.014294123072044411, 'optimizer': 'Adam', 'sparsity': 0.7930949216704407, 'steps_to_train': 77, 'weight_decay': 0.06218301187719215}"}}
exception: None

12:01:46 job_callback for (9, 0, 1) started
12:01:46 job_callback for (9, 0, 1) got condition
12:01:46 DISPATCHER: Trying to submit another job.
12:01:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:01:46 HBMASTER: Trying to run another job!
12:01:46 job_callback for (9, 0, 1) finished
12:01:46 start sampling a new configuration.
12:01:46 done sampling a new configuration.
12:01:46 HBMASTER: schedule new run for iteration 9
12:01:46 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
12:01:46 HBMASTER: submitting job (9, 0, 2) to dispatcher
12:01:46 DISPATCHER: trying to submit job (9, 0, 2)
12:01:46 DISPATCHER: trying to notify the job_runner thread.
12:01:46 HBMASTER: job (9, 0, 2) submitted to dispatcher
12:01:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:01:46 DISPATCHER: Trying to submit another job.
12:01:46 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
12:01:46 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
12:01:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:01:46 WORKER: start processing job (9, 0, 2)
12:01:46 WORKER: args: ()
12:01:46 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 842, 'last_n_outputs': 21, 'leak_rate': 0.798569941347733, 'lr': 0.03019814277765556, 'optimizer': 'Adam', 'sparsity': 0.848515677392304, 'steps_to_train': 65, 'weight_decay': 0.08603499073263873}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:02:34 DISPATCHER: Starting worker discovery
12:02:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:02:34 DISPATCHER: Finished worker discovery
12:03:34 DISPATCHER: Starting worker discovery
12:03:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:03:34 DISPATCHER: Finished worker discovery
12:04:34 DISPATCHER: Starting worker discovery
12:04:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:04:34 DISPATCHER: Finished worker discovery
12:04:58 WORKER: done with job (9, 0, 2), trying to register it.
12:04:58 WORKER: registered result for job (9, 0, 2) with dispatcher
12:04:58 DISPATCHER: job (9, 0, 2) finished
12:04:58 DISPATCHER: register_result: lock acquired
12:04:58 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
12:04:58 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 842, 'last_n_outputs': 21, 'leak_rate': 0.798569941347733, 'lr': 0.03019814277765556, 'optimizer': 'Adam', 'sparsity': 0.848515677392304, 'steps_to_train': 65, 'weight_decay': 0.08603499073263873}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.05082618740261902, 'info': {'data03': 0.05082618740261902, 'config': "{'batch_size': 16, 'hidden_dim': 842, 'last_n_outputs': 21, 'leak_rate': 0.798569941347733, 'lr': 0.03019814277765556, 'optimizer': 'Adam', 'sparsity': 0.848515677392304, 'steps_to_train': 65, 'weight_decay': 0.08603499073263873}"}}
exception: None

12:04:58 job_callback for (9, 0, 2) started
12:04:58 DISPATCHER: Trying to submit another job.
12:04:58 job_callback for (9, 0, 2) got condition
12:04:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:04:58 HBMASTER: Trying to run another job!
12:04:58 job_callback for (9, 0, 2) finished
12:04:58 start sampling a new configuration.
12:04:58 best_vector: [0, 0.9676253060797271, 0.9140640098572455, 0.006175305380269891, 0.3967115707652716, 0, 0.6963662952607734, 0.5123439398180971, 0.02695265360591642], 6.49046054424568e-29, 0.0001540722716335717, -0.0008728601970672764
12:04:58 done sampling a new configuration.
12:04:58 HBMASTER: schedule new run for iteration 9
12:04:58 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
12:04:58 HBMASTER: submitting job (9, 0, 3) to dispatcher
12:04:58 DISPATCHER: trying to submit job (9, 0, 3)
12:04:58 DISPATCHER: trying to notify the job_runner thread.
12:04:58 HBMASTER: job (9, 0, 3) submitted to dispatcher
12:04:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:04:58 DISPATCHER: Trying to submit another job.
12:04:58 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
12:04:58 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
12:04:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:04:58 WORKER: start processing job (9, 0, 3)
12:04:58 WORKER: args: ()
12:04:58 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 975, 'last_n_outputs': 47, 'leak_rate': 0.7515438263450674, 'lr': 0.006214742537535165, 'optimizer': 'Adam', 'sparsity': 0.9171279108625856, 'steps_to_train': 56, 'weight_decay': 0.0108409217779146}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:05:34 DISPATCHER: Starting worker discovery
12:05:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:05:34 DISPATCHER: Finished worker discovery
12:06:34 DISPATCHER: Starting worker discovery
12:06:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:06:34 DISPATCHER: Finished worker discovery
12:07:34 DISPATCHER: Starting worker discovery
12:07:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:07:34 DISPATCHER: Finished worker discovery
12:07:49 WORKER: done with job (9, 0, 3), trying to register it.
12:07:49 WORKER: registered result for job (9, 0, 3) with dispatcher
12:07:49 DISPATCHER: job (9, 0, 3) finished
12:07:49 DISPATCHER: register_result: lock acquired
12:07:49 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
12:07:49 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 975, 'last_n_outputs': 47, 'leak_rate': 0.7515438263450674, 'lr': 0.006214742537535165, 'optimizer': 'Adam', 'sparsity': 0.9171279108625856, 'steps_to_train': 56, 'weight_decay': 0.0108409217779146}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2820269225635014, 'info': {'data03': 0.2820269225635014, 'config': "{'batch_size': 16, 'hidden_dim': 975, 'last_n_outputs': 47, 'leak_rate': 0.7515438263450674, 'lr': 0.006214742537535165, 'optimizer': 'Adam', 'sparsity': 0.9171279108625856, 'steps_to_train': 56, 'weight_decay': 0.0108409217779146}"}}
exception: None

12:07:49 job_callback for (9, 0, 3) started
12:07:49 DISPATCHER: Trying to submit another job.
12:07:49 job_callback for (9, 0, 3) got condition
12:07:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:07:49 HBMASTER: Trying to run another job!
12:07:49 job_callback for (9, 0, 3) finished
12:07:49 start sampling a new configuration.
12:07:49 best_vector: [0, 0.6197546266590781, 0.9153848955059268, 0.9717091695661482, 0.2516843727202943, 1, 0.7845933257846717, 0.8349929895480271, 0.7497039905496445], 1.769286946853513e-31, 0.0565199444769766, -0.0037408045143143237
12:07:49 done sampling a new configuration.
12:07:49 HBMASTER: schedule new run for iteration 9
12:07:49 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
12:07:49 HBMASTER: submitting job (9, 0, 4) to dispatcher
12:07:49 DISPATCHER: trying to submit job (9, 0, 4)
12:07:49 DISPATCHER: trying to notify the job_runner thread.
12:07:49 HBMASTER: job (9, 0, 4) submitted to dispatcher
12:07:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:07:49 DISPATCHER: Trying to submit another job.
12:07:49 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
12:07:49 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
12:07:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:07:49 WORKER: start processing job (9, 0, 4)
12:07:49 WORKER: args: ()
12:07:49 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 696, 'last_n_outputs': 47, 'leak_rate': 0.9929272923915371, 'lr': 0.0031869022692605944, 'optimizer': 'SGD', 'sparsity': 0.9383023981883212, 'steps_to_train': 85, 'weight_decay': 0.0944903330118164}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:08:34 DISPATCHER: Starting worker discovery
12:08:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:08:34 DISPATCHER: Finished worker discovery
12:09:34 DISPATCHER: Starting worker discovery
12:09:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:09:34 DISPATCHER: Finished worker discovery
12:10:34 DISPATCHER: Starting worker discovery
12:10:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:10:34 DISPATCHER: Finished worker discovery
12:11:07 WORKER: done with job (9, 0, 4), trying to register it.
12:11:07 WORKER: registered result for job (9, 0, 4) with dispatcher
12:11:07 DISPATCHER: job (9, 0, 4) finished
12:11:07 DISPATCHER: register_result: lock acquired
12:11:07 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
12:11:07 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 696, 'last_n_outputs': 47, 'leak_rate': 0.9929272923915371, 'lr': 0.0031869022692605944, 'optimizer': 'SGD', 'sparsity': 0.9383023981883212, 'steps_to_train': 85, 'weight_decay': 0.0944903330118164}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1854078929702912, 'info': {'data03': 0.1854078929702912, 'config': "{'batch_size': 16, 'hidden_dim': 696, 'last_n_outputs': 47, 'leak_rate': 0.9929272923915371, 'lr': 0.0031869022692605944, 'optimizer': 'SGD', 'sparsity': 0.9383023981883212, 'steps_to_train': 85, 'weight_decay': 0.0944903330118164}"}}
exception: None

12:11:07 job_callback for (9, 0, 4) started
12:11:07 job_callback for (9, 0, 4) got condition
12:11:07 DISPATCHER: Trying to submit another job.
12:11:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:11:07 HBMASTER: Trying to run another job!
12:11:07 job_callback for (9, 0, 4) finished
12:11:07 start sampling a new configuration.
12:11:08 best_vector: [0, 0.8211292699411585, 0.6581208437781665, 0.1267151002348803, 0.032329310898334476, 0, 0.5458417154625079, 0.8843803421861187, 0.4728851466901514], 3.110228721344802e-30, 0.003215197625619056, -0.005212130366479281
12:11:08 done sampling a new configuration.
12:11:08 HBMASTER: schedule new run for iteration 9
12:11:08 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
12:11:08 HBMASTER: submitting job (9, 0, 5) to dispatcher
12:11:08 DISPATCHER: trying to submit job (9, 0, 5)
12:11:08 DISPATCHER: trying to notify the job_runner thread.
12:11:08 HBMASTER: job (9, 0, 5) submitted to dispatcher
12:11:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:11:08 DISPATCHER: Trying to submit another job.
12:11:08 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
12:11:08 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
12:11:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:11:08 WORKER: start processing job (9, 0, 5)
12:11:08 WORKER: args: ()
12:11:08 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 857, 'last_n_outputs': 36, 'leak_rate': 0.7816787750587201, 'lr': 0.0011605360131369774, 'optimizer': 'Adam', 'sparsity': 0.8810020117110019, 'steps_to_train': 90, 'weight_decay': 0.041232318918715136}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:11:34 DISPATCHER: Starting worker discovery
12:11:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:11:34 DISPATCHER: Finished worker discovery
12:12:34 DISPATCHER: Starting worker discovery
12:12:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:12:34 DISPATCHER: Finished worker discovery
12:13:34 DISPATCHER: Starting worker discovery
12:13:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:13:34 DISPATCHER: Finished worker discovery
12:14:34 DISPATCHER: Starting worker discovery
12:14:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:14:34 DISPATCHER: Finished worker discovery
12:14:36 WORKER: done with job (9, 0, 5), trying to register it.
12:14:36 WORKER: registered result for job (9, 0, 5) with dispatcher
12:14:36 DISPATCHER: job (9, 0, 5) finished
12:14:36 DISPATCHER: register_result: lock acquired
12:14:36 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
12:14:36 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 857, 'last_n_outputs': 36, 'leak_rate': 0.7816787750587201, 'lr': 0.0011605360131369774, 'optimizer': 'Adam', 'sparsity': 0.8810020117110019, 'steps_to_train': 90, 'weight_decay': 0.041232318918715136}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1967140734303051, 'info': {'data03': 0.1967140734303051, 'config': "{'batch_size': 16, 'hidden_dim': 857, 'last_n_outputs': 36, 'leak_rate': 0.7816787750587201, 'lr': 0.0011605360131369774, 'optimizer': 'Adam', 'sparsity': 0.8810020117110019, 'steps_to_train': 90, 'weight_decay': 0.041232318918715136}"}}
exception: None

12:14:36 job_callback for (9, 0, 5) started
12:14:36 DISPATCHER: Trying to submit another job.
12:14:36 job_callback for (9, 0, 5) got condition
12:14:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:14:36 HBMASTER: Trying to run another job!
12:14:36 job_callback for (9, 0, 5) finished
12:14:36 start sampling a new configuration.
12:14:36 best_vector: [0, 0.9273722049182545, 0.9670108953117504, 0.4079421016312488, 0.4801362938644453, 0, 0.8266517905649543, 0.9989077974704237, 0.2088871458765936], 2.1064717266826756e-31, 0.04747274731167767, -0.000643901649746702
12:14:36 done sampling a new configuration.
12:14:36 HBMASTER: schedule new run for iteration 9
12:14:36 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
12:14:36 HBMASTER: submitting job (9, 0, 6) to dispatcher
12:14:36 DISPATCHER: trying to submit job (9, 0, 6)
12:14:36 DISPATCHER: trying to notify the job_runner thread.
12:14:36 HBMASTER: job (9, 0, 6) submitted to dispatcher
12:14:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:14:36 DISPATCHER: Trying to submit another job.
12:14:36 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776
12:14:36 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
12:14:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:14:36 WORKER: start processing job (9, 0, 6)
12:14:36 WORKER: args: ()
12:14:36 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 942, 'last_n_outputs': 49, 'leak_rate': 0.8519855254078121, 'lr': 0.009125834485156789, 'optimizer': 'Adam', 'sparsity': 0.948396429735589, 'steps_to_train': 100, 'weight_decay': 0.01869684994304224}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:15:34 DISPATCHER: Starting worker discovery
12:15:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:15:34 DISPATCHER: Finished worker discovery
12:16:34 DISPATCHER: Starting worker discovery
12:16:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:16:34 DISPATCHER: Finished worker discovery
12:17:34 DISPATCHER: Starting worker discovery
12:17:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:17:34 DISPATCHER: Finished worker discovery
12:17:48 WORKER: done with job (9, 0, 6), trying to register it.
12:17:48 WORKER: registered result for job (9, 0, 6) with dispatcher
12:17:48 DISPATCHER: job (9, 0, 6) finished
12:17:48 DISPATCHER: register_result: lock acquired
12:17:48 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
12:17:48 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 942, 'last_n_outputs': 49, 'leak_rate': 0.8519855254078121, 'lr': 0.009125834485156789, 'optimizer': 'Adam', 'sparsity': 0.948396429735589, 'steps_to_train': 100, 'weight_decay': 0.01869684994304224}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.13024396222758944, 'info': {'data03': 0.13024396222758944, 'config': "{'batch_size': 16, 'hidden_dim': 942, 'last_n_outputs': 49, 'leak_rate': 0.8519855254078121, 'lr': 0.009125834485156789, 'optimizer': 'Adam', 'sparsity': 0.948396429735589, 'steps_to_train': 100, 'weight_decay': 0.01869684994304224}"}}
exception: None

12:17:48 job_callback for (9, 0, 6) started
12:17:48 DISPATCHER: Trying to submit another job.
12:17:48 job_callback for (9, 0, 6) got condition
12:17:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:17:48 HBMASTER: Trying to run another job!
12:17:48 job_callback for (9, 0, 6) finished
12:17:48 start sampling a new configuration.
12:17:49 best_vector: [0, 0.850599817308773, 0.8805752226103396, 0.832955417799057, 0.11078597359912425, 1, 0.7130019191040631, 0.84920966642031, 0.47343027560368345], 3.0233818746958305e-33, 3.307554392547934, -0.0005001358122778822
12:17:49 done sampling a new configuration.
12:17:49 HBMASTER: schedule new run for iteration 9
12:17:49 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
12:17:49 HBMASTER: submitting job (9, 0, 7) to dispatcher
12:17:49 DISPATCHER: trying to submit job (9, 0, 7)
12:17:49 DISPATCHER: trying to notify the job_runner thread.
12:17:49 HBMASTER: job (9, 0, 7) submitted to dispatcher
12:17:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:17:49 DISPATCHER: Trying to submit another job.
12:17:49 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776
12:17:49 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
12:17:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:17:49 WORKER: start processing job (9, 0, 7)
12:17:49 WORKER: args: ()
12:17:49 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 881, 'last_n_outputs': 46, 'leak_rate': 0.9582388544497642, 'lr': 0.0016656047365830244, 'optimizer': 'SGD', 'sparsity': 0.9211204605849751, 'steps_to_train': 87, 'weight_decay': 0.04129970879185937}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:18:34 DISPATCHER: Starting worker discovery
12:18:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:18:34 DISPATCHER: Finished worker discovery
12:19:34 DISPATCHER: Starting worker discovery
12:19:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:19:34 DISPATCHER: Finished worker discovery
12:20:34 DISPATCHER: Starting worker discovery
12:20:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:20:34 DISPATCHER: Finished worker discovery
12:21:10 WORKER: done with job (9, 0, 7), trying to register it.
12:21:10 WORKER: registered result for job (9, 0, 7) with dispatcher
12:21:10 DISPATCHER: job (9, 0, 7) finished
12:21:10 DISPATCHER: register_result: lock acquired
12:21:10 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
12:21:10 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 881, 'last_n_outputs': 46, 'leak_rate': 0.9582388544497642, 'lr': 0.0016656047365830244, 'optimizer': 'SGD', 'sparsity': 0.9211204605849751, 'steps_to_train': 87, 'weight_decay': 0.04129970879185937}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.02821071145167867, 'info': {'data03': 0.02821071145167867, 'config': "{'batch_size': 16, 'hidden_dim': 881, 'last_n_outputs': 46, 'leak_rate': 0.9582388544497642, 'lr': 0.0016656047365830244, 'optimizer': 'SGD', 'sparsity': 0.9211204605849751, 'steps_to_train': 87, 'weight_decay': 0.04129970879185937}"}}
exception: None

12:21:10 job_callback for (9, 0, 7) started
12:21:10 job_callback for (9, 0, 7) got condition
12:21:10 DISPATCHER: Trying to submit another job.
12:21:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:21:10 HBMASTER: Trying to run another job!
12:21:10 job_callback for (9, 0, 7) finished
12:21:10 start sampling a new configuration.
12:21:10 best_vector: [2, 0.00937584081200582, 0.8443680578237375, 0.5600196853274183, 0.4612737871935372, 1, 0.7139258417383814, 0.45418980612544335, 0.29953959361824817], 1.3729957083694178e-30, 0.007283343960248857, -0.00034798688456838013
12:21:10 done sampling a new configuration.
12:21:10 HBMASTER: schedule new run for iteration 9
12:21:10 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
12:21:10 HBMASTER: submitting job (9, 0, 8) to dispatcher
12:21:10 DISPATCHER: trying to submit job (9, 0, 8)
12:21:10 DISPATCHER: trying to notify the job_runner thread.
12:21:10 HBMASTER: job (9, 0, 8) submitted to dispatcher
12:21:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:21:10 DISPATCHER: Trying to submit another job.
12:21:10 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776
12:21:10 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
12:21:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:21:10 WORKER: start processing job (9, 0, 8)
12:21:10 WORKER: args: ()
12:21:10 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 207, 'last_n_outputs': 44, 'leak_rate': 0.8900049213318546, 'lr': 0.00836657241579281, 'optimizer': 'SGD', 'sparsity': 0.9213422020172115, 'steps_to_train': 51, 'weight_decay': 0.024530703102012778}, 'budget': 133.33333333333331, 'working_directory': '.'}
12:21:34 DISPATCHER: Starting worker discovery
12:21:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:21:34 DISPATCHER: Finished worker discovery
12:22:34 DISPATCHER: Starting worker discovery
12:22:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:22:34 DISPATCHER: Finished worker discovery
12:23:34 DISPATCHER: Starting worker discovery
12:23:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:23:34 DISPATCHER: Finished worker discovery
12:24:08 WORKER: done with job (9, 0, 8), trying to register it.
12:24:08 WORKER: registered result for job (9, 0, 8) with dispatcher
12:24:08 DISPATCHER: job (9, 0, 8) finished
12:24:08 DISPATCHER: register_result: lock acquired
12:24:08 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
12:24:08 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 207, 'last_n_outputs': 44, 'leak_rate': 0.8900049213318546, 'lr': 0.00836657241579281, 'optimizer': 'SGD', 'sparsity': 0.9213422020172115, 'steps_to_train': 51, 'weight_decay': 0.024530703102012778}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.011671748151643957, 'info': {'data03': 0.011671748151643957, 'config': "{'batch_size': 64, 'hidden_dim': 207, 'last_n_outputs': 44, 'leak_rate': 0.8900049213318546, 'lr': 0.00836657241579281, 'optimizer': 'SGD', 'sparsity': 0.9213422020172115, 'steps_to_train': 51, 'weight_decay': 0.024530703102012778}"}}
exception: None

12:24:08 job_callback for (9, 0, 8) started
12:24:08 DISPATCHER: Trying to submit another job.
12:24:08 job_callback for (9, 0, 8) got condition
12:24:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:24:08 HBMASTER: Trying to run another job!
12:24:08 job_callback for (9, 0, 8) finished
12:24:08 ITERATION: Advancing config (9, 0, 3) to next budget 400.000000
12:24:08 ITERATION: Advancing config (9, 0, 4) to next budget 400.000000
12:24:08 ITERATION: Advancing config (9, 0, 5) to next budget 400.000000
12:24:08 HBMASTER: schedule new run for iteration 9
12:24:08 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
12:24:08 HBMASTER: submitting job (9, 0, 3) to dispatcher
12:24:08 DISPATCHER: trying to submit job (9, 0, 3)
12:24:08 DISPATCHER: trying to notify the job_runner thread.
12:24:08 HBMASTER: job (9, 0, 3) submitted to dispatcher
12:24:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:24:08 DISPATCHER: Trying to submit another job.
12:24:08 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
12:24:08 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
12:24:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:24:08 WORKER: start processing job (9, 0, 3)
12:24:08 WORKER: args: ()
12:24:08 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 975, 'last_n_outputs': 47, 'leak_rate': 0.7515438263450674, 'lr': 0.006214742537535165, 'optimizer': 'Adam', 'sparsity': 0.9171279108625856, 'steps_to_train': 56, 'weight_decay': 0.0108409217779146}, 'budget': 400.0, 'working_directory': '.'}
12:24:34 DISPATCHER: Starting worker discovery
12:24:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:24:34 DISPATCHER: Finished worker discovery
12:25:34 DISPATCHER: Starting worker discovery
12:25:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:25:34 DISPATCHER: Finished worker discovery
12:26:34 DISPATCHER: Starting worker discovery
12:26:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:26:34 DISPATCHER: Finished worker discovery
12:27:34 DISPATCHER: Starting worker discovery
12:27:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:27:34 DISPATCHER: Finished worker discovery
12:28:34 DISPATCHER: Starting worker discovery
12:28:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:28:34 DISPATCHER: Finished worker discovery
12:29:34 DISPATCHER: Starting worker discovery
12:29:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:29:34 DISPATCHER: Finished worker discovery
12:30:34 DISPATCHER: Starting worker discovery
12:30:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:30:34 DISPATCHER: Finished worker discovery
12:31:34 DISPATCHER: Starting worker discovery
12:31:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:31:34 DISPATCHER: Finished worker discovery
12:31:38 WORKER: done with job (9, 0, 3), trying to register it.
12:31:38 WORKER: registered result for job (9, 0, 3) with dispatcher
12:31:38 DISPATCHER: job (9, 0, 3) finished
12:31:38 DISPATCHER: register_result: lock acquired
12:31:38 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
12:31:38 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 975, 'last_n_outputs': 47, 'leak_rate': 0.7515438263450674, 'lr': 0.006214742537535165, 'optimizer': 'Adam', 'sparsity': 0.9171279108625856, 'steps_to_train': 56, 'weight_decay': 0.0108409217779146}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.21356332911640113, 'info': {'data03': 0.21356332911640113, 'config': "{'batch_size': 16, 'hidden_dim': 975, 'last_n_outputs': 47, 'leak_rate': 0.7515438263450674, 'lr': 0.006214742537535165, 'optimizer': 'Adam', 'sparsity': 0.9171279108625856, 'steps_to_train': 56, 'weight_decay': 0.0108409217779146}"}}
exception: None

12:31:38 job_callback for (9, 0, 3) started
12:31:38 DISPATCHER: Trying to submit another job.
12:31:38 job_callback for (9, 0, 3) got condition
12:31:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:31:38 done building a new model for budget 400.000000 based on 10/23 split
Best loss for this budget:-0.340020





12:31:38 HBMASTER: Trying to run another job!
12:31:38 job_callback for (9, 0, 3) finished
12:31:38 HBMASTER: schedule new run for iteration 9
12:31:38 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
12:31:38 HBMASTER: submitting job (9, 0, 4) to dispatcher
12:31:38 DISPATCHER: trying to submit job (9, 0, 4)
12:31:38 DISPATCHER: trying to notify the job_runner thread.
12:31:38 HBMASTER: job (9, 0, 4) submitted to dispatcher
12:31:38 DISPATCHER: Trying to submit another job.
12:31:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:31:38 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
12:31:38 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
12:31:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:31:38 WORKER: start processing job (9, 0, 4)
12:31:38 WORKER: args: ()
12:31:38 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 696, 'last_n_outputs': 47, 'leak_rate': 0.9929272923915371, 'lr': 0.0031869022692605944, 'optimizer': 'SGD', 'sparsity': 0.9383023981883212, 'steps_to_train': 85, 'weight_decay': 0.0944903330118164}, 'budget': 400.0, 'working_directory': '.'}
12:32:34 DISPATCHER: Starting worker discovery
12:32:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:32:34 DISPATCHER: Finished worker discovery
12:33:34 DISPATCHER: Starting worker discovery
12:33:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:33:34 DISPATCHER: Finished worker discovery
12:34:34 DISPATCHER: Starting worker discovery
12:34:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:34:34 DISPATCHER: Finished worker discovery
12:35:34 DISPATCHER: Starting worker discovery
12:35:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:35:34 DISPATCHER: Finished worker discovery
12:36:34 DISPATCHER: Starting worker discovery
12:36:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:36:34 DISPATCHER: Finished worker discovery
12:37:34 DISPATCHER: Starting worker discovery
12:37:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:37:34 DISPATCHER: Finished worker discovery
12:38:34 DISPATCHER: Starting worker discovery
12:38:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:38:34 DISPATCHER: Finished worker discovery
12:39:14 WORKER: done with job (9, 0, 4), trying to register it.
12:39:14 WORKER: registered result for job (9, 0, 4) with dispatcher
12:39:14 DISPATCHER: job (9, 0, 4) finished
12:39:14 DISPATCHER: register_result: lock acquired
12:39:14 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
12:39:14 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 696, 'last_n_outputs': 47, 'leak_rate': 0.9929272923915371, 'lr': 0.0031869022692605944, 'optimizer': 'SGD', 'sparsity': 0.9383023981883212, 'steps_to_train': 85, 'weight_decay': 0.0944903330118164}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.17836586681339156, 'info': {'data03': 0.17836586681339156, 'config': "{'batch_size': 16, 'hidden_dim': 696, 'last_n_outputs': 47, 'leak_rate': 0.9929272923915371, 'lr': 0.0031869022692605944, 'optimizer': 'SGD', 'sparsity': 0.9383023981883212, 'steps_to_train': 85, 'weight_decay': 0.0944903330118164}"}}
exception: None

12:39:14 job_callback for (9, 0, 4) started
12:39:14 DISPATCHER: Trying to submit another job.
12:39:14 job_callback for (9, 0, 4) got condition
12:39:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:39:14 done building a new model for budget 400.000000 based on 10/24 split
Best loss for this budget:-0.340020





12:39:14 HBMASTER: Trying to run another job!
12:39:14 job_callback for (9, 0, 4) finished
12:39:14 HBMASTER: schedule new run for iteration 9
12:39:14 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
12:39:14 HBMASTER: submitting job (9, 0, 5) to dispatcher
12:39:14 DISPATCHER: trying to submit job (9, 0, 5)
12:39:14 DISPATCHER: trying to notify the job_runner thread.
12:39:14 HBMASTER: job (9, 0, 5) submitted to dispatcher
12:39:14 DISPATCHER: Trying to submit another job.
12:39:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:39:14 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
12:39:14 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
12:39:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:39:14 WORKER: start processing job (9, 0, 5)
12:39:14 WORKER: args: ()
12:39:14 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 857, 'last_n_outputs': 36, 'leak_rate': 0.7816787750587201, 'lr': 0.0011605360131369774, 'optimizer': 'Adam', 'sparsity': 0.8810020117110019, 'steps_to_train': 90, 'weight_decay': 0.041232318918715136}, 'budget': 400.0, 'working_directory': '.'}
12:39:34 DISPATCHER: Starting worker discovery
12:39:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:39:34 DISPATCHER: Finished worker discovery
12:40:34 DISPATCHER: Starting worker discovery
12:40:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:40:34 DISPATCHER: Finished worker discovery
12:41:34 DISPATCHER: Starting worker discovery
12:41:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:41:34 DISPATCHER: Finished worker discovery
12:42:34 DISPATCHER: Starting worker discovery
12:42:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:42:34 DISPATCHER: Finished worker discovery
12:43:34 DISPATCHER: Starting worker discovery
12:43:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:43:34 DISPATCHER: Finished worker discovery
12:44:34 DISPATCHER: Starting worker discovery
12:44:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:44:34 DISPATCHER: Finished worker discovery
12:45:34 DISPATCHER: Starting worker discovery
12:45:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:45:34 DISPATCHER: Finished worker discovery
12:46:34 DISPATCHER: Starting worker discovery
12:46:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:46:34 DISPATCHER: Finished worker discovery
12:47:03 WORKER: done with job (9, 0, 5), trying to register it.
12:47:03 WORKER: registered result for job (9, 0, 5) with dispatcher
12:47:03 DISPATCHER: job (9, 0, 5) finished
12:47:03 DISPATCHER: register_result: lock acquired
12:47:03 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
12:47:03 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 857, 'last_n_outputs': 36, 'leak_rate': 0.7816787750587201, 'lr': 0.0011605360131369774, 'optimizer': 'Adam', 'sparsity': 0.8810020117110019, 'steps_to_train': 90, 'weight_decay': 0.041232318918715136}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.26347822112342734, 'info': {'data03': 0.26347822112342734, 'config': "{'batch_size': 16, 'hidden_dim': 857, 'last_n_outputs': 36, 'leak_rate': 0.7816787750587201, 'lr': 0.0011605360131369774, 'optimizer': 'Adam', 'sparsity': 0.8810020117110019, 'steps_to_train': 90, 'weight_decay': 0.041232318918715136}"}}
exception: None

12:47:03 job_callback for (9, 0, 5) started
12:47:03 DISPATCHER: Trying to submit another job.
12:47:03 job_callback for (9, 0, 5) got condition
12:47:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:47:03 done building a new model for budget 400.000000 based on 10/25 split
Best loss for this budget:-0.340020





12:47:03 HBMASTER: Trying to run another job!
12:47:03 job_callback for (9, 0, 5) finished
12:47:03 ITERATION: Advancing config (9, 0, 5) to next budget 1200.000000
12:47:03 HBMASTER: schedule new run for iteration 9
12:47:03 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
12:47:03 HBMASTER: submitting job (9, 0, 5) to dispatcher
12:47:03 DISPATCHER: trying to submit job (9, 0, 5)
12:47:03 DISPATCHER: trying to notify the job_runner thread.
12:47:03 HBMASTER: job (9, 0, 5) submitted to dispatcher
12:47:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:47:03 DISPATCHER: Trying to submit another job.
12:47:03 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
12:47:03 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
12:47:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:47:03 WORKER: start processing job (9, 0, 5)
12:47:03 WORKER: args: ()
12:47:03 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 857, 'last_n_outputs': 36, 'leak_rate': 0.7816787750587201, 'lr': 0.0011605360131369774, 'optimizer': 'Adam', 'sparsity': 0.8810020117110019, 'steps_to_train': 90, 'weight_decay': 0.041232318918715136}, 'budget': 1200.0, 'working_directory': '.'}
12:47:34 DISPATCHER: Starting worker discovery
12:47:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:47:34 DISPATCHER: Finished worker discovery
12:48:34 DISPATCHER: Starting worker discovery
12:48:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:48:34 DISPATCHER: Finished worker discovery
12:49:34 DISPATCHER: Starting worker discovery
12:49:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:49:34 DISPATCHER: Finished worker discovery
12:50:34 DISPATCHER: Starting worker discovery
12:50:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:50:34 DISPATCHER: Finished worker discovery
12:51:34 DISPATCHER: Starting worker discovery
12:51:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:51:34 DISPATCHER: Finished worker discovery
12:52:34 DISPATCHER: Starting worker discovery
12:52:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:52:34 DISPATCHER: Finished worker discovery
12:53:34 DISPATCHER: Starting worker discovery
12:53:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:53:34 DISPATCHER: Finished worker discovery
12:54:34 DISPATCHER: Starting worker discovery
12:54:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:54:34 DISPATCHER: Finished worker discovery
12:55:34 DISPATCHER: Starting worker discovery
12:55:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:55:34 DISPATCHER: Finished worker discovery
12:56:34 DISPATCHER: Starting worker discovery
12:56:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:56:34 DISPATCHER: Finished worker discovery
12:57:34 DISPATCHER: Starting worker discovery
12:57:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:57:34 DISPATCHER: Finished worker discovery
12:58:34 DISPATCHER: Starting worker discovery
12:58:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:58:34 DISPATCHER: Finished worker discovery
12:59:34 DISPATCHER: Starting worker discovery
12:59:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:59:34 DISPATCHER: Finished worker discovery
13:00:34 DISPATCHER: Starting worker discovery
13:00:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:00:34 DISPATCHER: Finished worker discovery
13:01:34 DISPATCHER: Starting worker discovery
13:01:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:01:34 DISPATCHER: Finished worker discovery
13:02:34 DISPATCHER: Starting worker discovery
13:02:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:02:34 DISPATCHER: Finished worker discovery
13:03:34 DISPATCHER: Starting worker discovery
13:03:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:03:35 DISPATCHER: Finished worker discovery
13:04:35 DISPATCHER: Starting worker discovery
13:04:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:04:35 DISPATCHER: Finished worker discovery
13:05:35 DISPATCHER: Starting worker discovery
13:05:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:05:35 DISPATCHER: Finished worker discovery
13:06:35 DISPATCHER: Starting worker discovery
13:06:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:06:35 DISPATCHER: Finished worker discovery
13:07:35 DISPATCHER: Starting worker discovery
13:07:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:07:35 DISPATCHER: Finished worker discovery
13:08:24 WORKER: done with job (9, 0, 5), trying to register it.
13:08:24 WORKER: registered result for job (9, 0, 5) with dispatcher
13:08:24 DISPATCHER: job (9, 0, 5) finished
13:08:24 DISPATCHER: register_result: lock acquired
13:08:24 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
13:08:24 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 857, 'last_n_outputs': 36, 'leak_rate': 0.7816787750587201, 'lr': 0.0011605360131369774, 'optimizer': 'Adam', 'sparsity': 0.8810020117110019, 'steps_to_train': 90, 'weight_decay': 0.041232318918715136}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.29769320346382977, 'info': {'data03': 0.29769320346382977, 'config': "{'batch_size': 16, 'hidden_dim': 857, 'last_n_outputs': 36, 'leak_rate': 0.7816787750587201, 'lr': 0.0011605360131369774, 'optimizer': 'Adam', 'sparsity': 0.8810020117110019, 'steps_to_train': 90, 'weight_decay': 0.041232318918715136}"}}
exception: None

13:08:24 job_callback for (9, 0, 5) started
13:08:24 job_callback for (9, 0, 5) got condition
13:08:24 DISPATCHER: Trying to submit another job.
13:08:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:08:24 HBMASTER: Trying to run another job!
13:08:24 job_callback for (9, 0, 5) finished
13:08:24 HBMASTER: shutdown initiated, shutdown_workers = True
13:08:24 WORKER: shutting down now!
13:08:24 DISPATCHER: Dispatcher shutting down
13:08:24 DISPATCHER: discover_workers shutting down
13:08:24 DISPATCHER: Trying to submit another job.
13:08:24 DISPATCHER: 'discover_worker' thread exited
13:08:24 DISPATCHER: job_runner shutting down
13:08:24 DISPATCHER: 'job_runner' thread exited
13:08:24 DISPATCHER: shut down complete
13:08:24 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7f4dcac88208; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:31890>
13:08:24 WORKER: No dispatcher found. Waiting for one to initiate contact.
13:08:24 WORKER: start listening for jobs
13:08:24 wait_for_workers trying to get the condition
13:08:24 DISPATCHER: started the 'discover_worker' thread
13:08:24 DISPATCHER: started the 'job_runner' thread
13:08:24 DISPATCHER: Pyro daemon running on localhost:38257
13:08:24 DISPATCHER: Starting worker discovery
13:08:24 DISPATCHER: Found 1 potential workers, 0 currently in the pool.
13:08:24 DISPATCHER: discovered new worker, hpbandster.run_0.worker.metagpui.1576139975513683776
13:08:24 HBMASTER: number of workers changed to 1
13:08:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:08:24 HBMASTER: only 1 worker(s) available, waiting for at least 1.
13:08:24 adjust_queue_size: lock accquired
13:08:24 HBMASTER: adjusted queue size to (0, 1)
13:08:24 DISPATCHER: Finished worker discovery
13:08:24 DISPATCHER: A new worker triggered discover_worker
13:08:24 DISPATCHER: Trying to submit another job.
13:08:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:08:24 Enough workers to start this run!
13:08:24 DISPATCHER: Starting worker discovery
13:08:24 HBMASTER: starting run at 1583842104.891067
13:08:24 start sampling a new configuration.
13:08:24 done sampling a new configuration.
13:08:24 HBMASTER: schedule new run for iteration 0
13:08:24 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
13:08:24 HBMASTER: submitting job (0, 0, 0) to dispatcher
13:08:24 DISPATCHER: trying to submit job (0, 0, 0)
13:08:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:08:24 DISPATCHER: Finished worker discovery
13:08:24 DISPATCHER: trying to notify the job_runner thread.
13:08:24 HBMASTER: job (0, 0, 0) submitted to dispatcher
13:08:24 DISPATCHER: Trying to submit another job.
13:08:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:08:24 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
13:08:24 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
13:08:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:08:24 WORKER: start processing job (0, 0, 0)
13:08:24 WORKER: args: ()
13:08:24 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.017286459844432688, 'num_filters_1': 17, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.02123635748911129}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:09:24 DISPATCHER: Starting worker discovery
13:09:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:09:24 DISPATCHER: Finished worker discovery
13:09:49 WORKER: done with job (0, 0, 0), trying to register it.
13:09:49 WORKER: registered result for job (0, 0, 0) with dispatcher
13:09:49 DISPATCHER: job (0, 0, 0) finished
13:09:49 DISPATCHER: register_result: lock acquired
13:09:49 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
13:09:49 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.017286459844432688, 'num_filters_1': 17, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.02123635748911129}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3597212641740697, 'info': {'data03': 0.3597212641740697, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.017286459844432688, 'num_filters_1': 17, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.02123635748911129}"}}
exception: None

13:09:49 job_callback for (0, 0, 0) started
13:09:49 DISPATCHER: Trying to submit another job.
13:09:49 job_callback for (0, 0, 0) got condition
13:09:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:09:49 Only 1 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
13:09:49 HBMASTER: Trying to run another job!
13:09:49 job_callback for (0, 0, 0) finished
13:09:49 start sampling a new configuration.
13:09:49 done sampling a new configuration.
13:09:49 HBMASTER: schedule new run for iteration 0
13:09:49 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
13:09:49 HBMASTER: submitting job (0, 0, 1) to dispatcher
13:09:49 DISPATCHER: trying to submit job (0, 0, 1)
13:09:49 DISPATCHER: trying to notify the job_runner thread.
13:09:49 HBMASTER: job (0, 0, 1) submitted to dispatcher
13:09:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:09:49 DISPATCHER: Trying to submit another job.
13:09:49 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
13:09:49 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
13:09:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:09:49 WORKER: start processing job (0, 0, 1)
13:09:49 WORKER: args: ()
13:09:49 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.07621856837086101, 'num_filters_1': 51, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.08307313225094817, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 49, 'num_filters_3': 69, 'num_filters_4': 27, 'num_filters_5': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:10:24 DISPATCHER: Starting worker discovery
13:10:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:10:24 DISPATCHER: Finished worker discovery
13:11:11 WORKER: done with job (0, 0, 1), trying to register it.
13:11:11 WORKER: registered result for job (0, 0, 1) with dispatcher
13:11:11 DISPATCHER: job (0, 0, 1) finished
13:11:11 DISPATCHER: register_result: lock acquired
13:11:11 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
13:11:11 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.07621856837086101, 'num_filters_1': 51, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.08307313225094817, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 49, 'num_filters_3': 69, 'num_filters_4': 27, 'num_filters_5': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.23275250428147398, 'info': {'data03': 0.23275250428147398, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.07621856837086101, 'num_filters_1': 51, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.08307313225094817, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 49, 'num_filters_3': 69, 'num_filters_4': 27, 'num_filters_5': 16}"}}
exception: None

13:11:11 job_callback for (0, 0, 1) started
13:11:11 DISPATCHER: Trying to submit another job.
13:11:11 job_callback for (0, 0, 1) got condition
13:11:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:11:11 Only 2 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
13:11:11 HBMASTER: Trying to run another job!
13:11:11 job_callback for (0, 0, 1) finished
13:11:11 start sampling a new configuration.
13:11:11 done sampling a new configuration.
13:11:11 HBMASTER: schedule new run for iteration 0
13:11:11 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
13:11:11 HBMASTER: submitting job (0, 0, 2) to dispatcher
13:11:11 DISPATCHER: trying to submit job (0, 0, 2)
13:11:11 DISPATCHER: trying to notify the job_runner thread.
13:11:11 HBMASTER: job (0, 0, 2) submitted to dispatcher
13:11:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:11:11 DISPATCHER: Trying to submit another job.
13:11:11 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
13:11:11 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
13:11:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:11:11 WORKER: start processing job (0, 0, 2)
13:11:11 WORKER: args: ()
13:11:11 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0039275844428912285, 'num_filters_1': 54, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.026147647136185836, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 103, 'num_filters_3': 24, 'num_filters_4': 57, 'num_filters_5': 77}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:11:24 DISPATCHER: Starting worker discovery
13:11:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:11:24 DISPATCHER: Finished worker discovery
13:12:24 DISPATCHER: Starting worker discovery
13:12:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:12:24 DISPATCHER: Finished worker discovery
13:12:36 WORKER: done with job (0, 0, 2), trying to register it.
13:12:36 WORKER: registered result for job (0, 0, 2) with dispatcher
13:12:36 DISPATCHER: job (0, 0, 2) finished
13:12:36 DISPATCHER: register_result: lock acquired
13:12:36 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
13:12:36 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0039275844428912285, 'num_filters_1': 54, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.026147647136185836, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 103, 'num_filters_3': 24, 'num_filters_4': 57, 'num_filters_5': 77}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.466953891474412, 'info': {'data03': 0.466953891474412, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0039275844428912285, 'num_filters_1': 54, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.026147647136185836, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 103, 'num_filters_3': 24, 'num_filters_4': 57, 'num_filters_5': 77}"}}
exception: None

13:12:36 job_callback for (0, 0, 2) started
13:12:36 DISPATCHER: Trying to submit another job.
13:12:36 job_callback for (0, 0, 2) got condition
13:12:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:12:36 Only 3 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
13:12:36 HBMASTER: Trying to run another job!
13:12:36 job_callback for (0, 0, 2) finished
13:12:36 start sampling a new configuration.
13:12:36 done sampling a new configuration.
13:12:36 HBMASTER: schedule new run for iteration 0
13:12:36 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
13:12:36 HBMASTER: submitting job (0, 0, 3) to dispatcher
13:12:36 DISPATCHER: trying to submit job (0, 0, 3)
13:12:36 DISPATCHER: trying to notify the job_runner thread.
13:12:36 HBMASTER: job (0, 0, 3) submitted to dispatcher
13:12:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:12:36 DISPATCHER: Trying to submit another job.
13:12:36 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
13:12:36 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
13:12:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:12:36 WORKER: start processing job (0, 0, 3)
13:12:36 WORKER: args: ()
13:12:36 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.016661458032665832, 'num_filters_1': 103, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.03229017314884223, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 77, 'num_filters_3': 21, 'num_filters_4': 81, 'num_filters_5': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:13:24 DISPATCHER: Starting worker discovery
13:13:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:13:24 DISPATCHER: Finished worker discovery
13:14:00 WORKER: done with job (0, 0, 3), trying to register it.
13:14:00 WORKER: registered result for job (0, 0, 3) with dispatcher
13:14:00 DISPATCHER: job (0, 0, 3) finished
13:14:00 DISPATCHER: register_result: lock acquired
13:14:00 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
13:14:00 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.016661458032665832, 'num_filters_1': 103, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.03229017314884223, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 77, 'num_filters_3': 21, 'num_filters_4': 81, 'num_filters_5': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.016661458032665832, 'num_filters_1': 103, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.03229017314884223, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 77, 'num_filters_3': 21, 'num_filters_4': 81, 'num_filters_5': 17}"}}
exception: None

13:14:00 job_callback for (0, 0, 3) started
13:14:00 DISPATCHER: Trying to submit another job.
13:14:00 job_callback for (0, 0, 3) got condition
13:14:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:14:00 Only 4 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
13:14:00 HBMASTER: Trying to run another job!
13:14:00 job_callback for (0, 0, 3) finished
13:14:00 start sampling a new configuration.
13:14:00 done sampling a new configuration.
13:14:00 HBMASTER: schedule new run for iteration 0
13:14:00 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
13:14:00 HBMASTER: submitting job (0, 0, 4) to dispatcher
13:14:00 DISPATCHER: trying to submit job (0, 0, 4)
13:14:00 DISPATCHER: trying to notify the job_runner thread.
13:14:00 HBMASTER: job (0, 0, 4) submitted to dispatcher
13:14:00 DISPATCHER: Trying to submit another job.
13:14:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:14:00 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
13:14:00 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
13:14:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:14:00 WORKER: start processing job (0, 0, 4)
13:14:00 WORKER: args: ()
13:14:00 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001381073182769778, 'num_filters_1': 46, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.062141503363574865, 'kernel_size_2': 5, 'num_filters_2': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:14:24 DISPATCHER: Starting worker discovery
13:14:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:14:24 DISPATCHER: Finished worker discovery
13:15:23 WORKER: done with job (0, 0, 4), trying to register it.
13:15:23 WORKER: registered result for job (0, 0, 4) with dispatcher
13:15:23 DISPATCHER: job (0, 0, 4) finished
13:15:23 DISPATCHER: register_result: lock acquired
13:15:23 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
13:15:23 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001381073182769778, 'num_filters_1': 46, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.062141503363574865, 'kernel_size_2': 5, 'num_filters_2': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.41832987625060974, 'info': {'data03': 0.41832987625060974, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001381073182769778, 'num_filters_1': 46, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.062141503363574865, 'kernel_size_2': 5, 'num_filters_2': 24}"}}
exception: None

13:15:23 job_callback for (0, 0, 4) started
13:15:23 DISPATCHER: Trying to submit another job.
13:15:23 job_callback for (0, 0, 4) got condition
13:15:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:15:23 Only 5 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
13:15:23 HBMASTER: Trying to run another job!
13:15:23 job_callback for (0, 0, 4) finished
13:15:23 start sampling a new configuration.
13:15:23 done sampling a new configuration.
13:15:23 HBMASTER: schedule new run for iteration 0
13:15:23 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
13:15:23 HBMASTER: submitting job (0, 0, 5) to dispatcher
13:15:23 DISPATCHER: trying to submit job (0, 0, 5)
13:15:23 DISPATCHER: trying to notify the job_runner thread.
13:15:23 HBMASTER: job (0, 0, 5) submitted to dispatcher
13:15:23 DISPATCHER: Trying to submit another job.
13:15:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:15:23 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
13:15:23 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
13:15:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:15:23 WORKER: start processing job (0, 0, 5)
13:15:23 WORKER: args: ()
13:15:23 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0038540822542164864, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.05971561705065691, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 44, 'num_filters_3': 128, 'num_filters_4': 91, 'num_filters_5': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:15:24 DISPATCHER: Starting worker discovery
13:15:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:15:24 DISPATCHER: Finished worker discovery
13:16:24 DISPATCHER: Starting worker discovery
13:16:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:16:24 DISPATCHER: Finished worker discovery
13:16:47 WORKER: done with job (0, 0, 5), trying to register it.
13:16:47 WORKER: registered result for job (0, 0, 5) with dispatcher
13:16:47 DISPATCHER: job (0, 0, 5) finished
13:16:47 DISPATCHER: register_result: lock acquired
13:16:47 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
13:16:47 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0038540822542164864, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.05971561705065691, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 44, 'num_filters_3': 128, 'num_filters_4': 91, 'num_filters_5': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4582083044668962, 'info': {'data03': 0.4582083044668962, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0038540822542164864, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.05971561705065691, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 44, 'num_filters_3': 128, 'num_filters_4': 91, 'num_filters_5': 44}"}}
exception: None

13:16:47 job_callback for (0, 0, 5) started
13:16:47 DISPATCHER: Trying to submit another job.
13:16:47 job_callback for (0, 0, 5) got condition
13:16:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:16:47 Only 6 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
13:16:47 HBMASTER: Trying to run another job!
13:16:47 job_callback for (0, 0, 5) finished
13:16:47 start sampling a new configuration.
13:16:47 done sampling a new configuration.
13:16:47 HBMASTER: schedule new run for iteration 0
13:16:47 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
13:16:47 HBMASTER: submitting job (0, 0, 6) to dispatcher
13:16:47 DISPATCHER: trying to submit job (0, 0, 6)
13:16:47 DISPATCHER: trying to notify the job_runner thread.
13:16:47 HBMASTER: job (0, 0, 6) submitted to dispatcher
13:16:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:16:47 DISPATCHER: Trying to submit another job.
13:16:47 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776
13:16:47 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
13:16:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:16:47 WORKER: start processing job (0, 0, 6)
13:16:47 WORKER: args: ()
13:16:47 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.07157651034458286, 'num_filters_1': 27, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.16895254622517838, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 19, 'num_filters_3': 20, 'num_filters_4': 52, 'num_filters_5': 89}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:17:24 DISPATCHER: Starting worker discovery
13:17:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:17:24 DISPATCHER: Finished worker discovery
13:18:07 WORKER: done with job (0, 0, 6), trying to register it.
13:18:07 WORKER: registered result for job (0, 0, 6) with dispatcher
13:18:07 DISPATCHER: job (0, 0, 6) finished
13:18:07 DISPATCHER: register_result: lock acquired
13:18:07 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
13:18:07 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.07157651034458286, 'num_filters_1': 27, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.16895254622517838, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 19, 'num_filters_3': 20, 'num_filters_4': 52, 'num_filters_5': 89}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.07157651034458286, 'num_filters_1': 27, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.16895254622517838, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 19, 'num_filters_3': 20, 'num_filters_4': 52, 'num_filters_5': 89}"}}
exception: None

13:18:07 job_callback for (0, 0, 6) started
13:18:07 DISPATCHER: Trying to submit another job.
13:18:07 job_callback for (0, 0, 6) got condition
13:18:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:18:07 Only 7 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
13:18:07 HBMASTER: Trying to run another job!
13:18:07 job_callback for (0, 0, 6) finished
13:18:07 start sampling a new configuration.
13:18:07 done sampling a new configuration.
13:18:07 HBMASTER: schedule new run for iteration 0
13:18:07 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
13:18:07 HBMASTER: submitting job (0, 0, 7) to dispatcher
13:18:07 DISPATCHER: trying to submit job (0, 0, 7)
13:18:07 DISPATCHER: trying to notify the job_runner thread.
13:18:07 HBMASTER: job (0, 0, 7) submitted to dispatcher
13:18:07 DISPATCHER: Trying to submit another job.
13:18:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:18:07 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776
13:18:07 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
13:18:07 WORKER: start processing job (0, 0, 7)
13:18:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:18:07 WORKER: args: ()
13:18:07 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.005278480093278599, 'num_filters_1': 116, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.0727341157831343, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 35, 'num_filters_3': 99, 'num_filters_4': 32}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:18:24 DISPATCHER: Starting worker discovery
13:18:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:18:24 DISPATCHER: Finished worker discovery
13:19:24 DISPATCHER: Starting worker discovery
13:19:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:19:24 DISPATCHER: Finished worker discovery
13:19:31 WORKER: done with job (0, 0, 7), trying to register it.
13:19:31 WORKER: registered result for job (0, 0, 7) with dispatcher
13:19:31 DISPATCHER: job (0, 0, 7) finished
13:19:31 DISPATCHER: register_result: lock acquired
13:19:31 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
13:19:31 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.005278480093278599, 'num_filters_1': 116, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.0727341157831343, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 35, 'num_filters_3': 99, 'num_filters_4': 32}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4479572036020516, 'info': {'data03': 0.4479572036020516, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.005278480093278599, 'num_filters_1': 116, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.0727341157831343, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 35, 'num_filters_3': 99, 'num_filters_4': 32}"}}
exception: None

13:19:32 job_callback for (0, 0, 7) started
13:19:32 job_callback for (0, 0, 7) got condition
13:19:32 DISPATCHER: Trying to submit another job.
13:19:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:19:32 Only 8 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
13:19:32 HBMASTER: Trying to run another job!
13:19:32 job_callback for (0, 0, 7) finished
13:19:32 start sampling a new configuration.
13:19:32 done sampling a new configuration.
13:19:32 HBMASTER: schedule new run for iteration 0
13:19:32 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
13:19:32 HBMASTER: submitting job (0, 0, 8) to dispatcher
13:19:32 DISPATCHER: trying to submit job (0, 0, 8)
13:19:32 DISPATCHER: trying to notify the job_runner thread.
13:19:32 HBMASTER: job (0, 0, 8) submitted to dispatcher
13:19:32 DISPATCHER: Trying to submit another job.
13:19:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:19:32 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776
13:19:32 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
13:19:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:19:32 WORKER: start processing job (0, 0, 8)
13:19:32 WORKER: args: ()
13:19:32 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.007014021020885936, 'num_filters_1': 86, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.014727459589957796, 'kernel_size_2': 3, 'num_filters_2': 86}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:20:24 DISPATCHER: Starting worker discovery
13:20:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:20:24 DISPATCHER: Finished worker discovery
13:20:55 WORKER: done with job (0, 0, 8), trying to register it.
13:20:55 WORKER: registered result for job (0, 0, 8) with dispatcher
13:20:55 DISPATCHER: job (0, 0, 8) finished
13:20:55 DISPATCHER: register_result: lock acquired
13:20:55 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
13:20:55 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.007014021020885936, 'num_filters_1': 86, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.014727459589957796, 'kernel_size_2': 3, 'num_filters_2': 86}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3985081313840776, 'info': {'data03': 0.3985081313840776, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.007014021020885936, 'num_filters_1': 86, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.014727459589957796, 'kernel_size_2': 3, 'num_filters_2': 86}"}}
exception: None

13:20:55 job_callback for (0, 0, 8) started
13:20:55 job_callback for (0, 0, 8) got condition
13:20:55 DISPATCHER: Trying to submit another job.
13:20:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:20:55 Only 9 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
13:20:55 HBMASTER: Trying to run another job!
13:20:55 job_callback for (0, 0, 8) finished
13:20:55 start sampling a new configuration.
13:20:55 done sampling a new configuration.
13:20:55 HBMASTER: schedule new run for iteration 0
13:20:55 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
13:20:55 HBMASTER: submitting job (0, 0, 9) to dispatcher
13:20:55 DISPATCHER: trying to submit job (0, 0, 9)
13:20:55 DISPATCHER: trying to notify the job_runner thread.
13:20:55 HBMASTER: job (0, 0, 9) submitted to dispatcher
13:20:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:20:55 DISPATCHER: Trying to submit another job.
13:20:55 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpui.1576139975513683776
13:20:55 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
13:20:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:20:55 WORKER: start processing job (0, 0, 9)
13:20:55 WORKER: args: ()
13:20:55 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.03640395037558, 'num_filters_1': 40, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.13996894611683133, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 23, 'num_filters_3': 63, 'num_filters_4': 94, 'num_filters_5': 50}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:21:24 DISPATCHER: Starting worker discovery
13:21:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:21:24 DISPATCHER: Finished worker discovery
13:22:17 WORKER: done with job (0, 0, 9), trying to register it.
13:22:17 WORKER: registered result for job (0, 0, 9) with dispatcher
13:22:17 DISPATCHER: job (0, 0, 9) finished
13:22:17 DISPATCHER: register_result: lock acquired
13:22:17 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
13:22:17 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.03640395037558, 'num_filters_1': 40, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.13996894611683133, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 23, 'num_filters_3': 63, 'num_filters_4': 94, 'num_filters_5': 50}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.03640395037558, 'num_filters_1': 40, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.13996894611683133, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 23, 'num_filters_3': 63, 'num_filters_4': 94, 'num_filters_5': 50}"}}
exception: None

13:22:17 job_callback for (0, 0, 9) started
13:22:17 job_callback for (0, 0, 9) got condition
13:22:17 DISPATCHER: Trying to submit another job.
13:22:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:22:17 Only 10 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
13:22:17 HBMASTER: Trying to run another job!
13:22:17 job_callback for (0, 0, 9) finished
13:22:17 start sampling a new configuration.
13:22:17 done sampling a new configuration.
13:22:17 HBMASTER: schedule new run for iteration 0
13:22:17 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
13:22:17 HBMASTER: submitting job (0, 0, 10) to dispatcher
13:22:17 DISPATCHER: trying to submit job (0, 0, 10)
13:22:17 DISPATCHER: trying to notify the job_runner thread.
13:22:17 HBMASTER: job (0, 0, 10) submitted to dispatcher
13:22:17 DISPATCHER: Trying to submit another job.
13:22:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:22:17 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpui.1576139975513683776
13:22:17 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
13:22:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:22:17 WORKER: start processing job (0, 0, 10)
13:22:17 WORKER: args: ()
13:22:17 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.003893050798529051, 'num_filters_1': 44, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.0160053311637959, 'kernel_size_2': 7, 'num_filters_2': 79}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:22:24 DISPATCHER: Starting worker discovery
13:22:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:22:24 DISPATCHER: Finished worker discovery
13:23:24 DISPATCHER: Starting worker discovery
13:23:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:23:24 DISPATCHER: Finished worker discovery
13:23:43 WORKER: done with job (0, 0, 10), trying to register it.
13:23:43 WORKER: registered result for job (0, 0, 10) with dispatcher
13:23:43 DISPATCHER: job (0, 0, 10) finished
13:23:43 DISPATCHER: register_result: lock acquired
13:23:43 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
13:23:43 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.003893050798529051, 'num_filters_1': 44, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.0160053311637959, 'kernel_size_2': 7, 'num_filters_2': 79}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3977756630394955, 'info': {'data03': 0.3977756630394955, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.003893050798529051, 'num_filters_1': 44, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.0160053311637959, 'kernel_size_2': 7, 'num_filters_2': 79}"}}
exception: None

13:23:43 job_callback for (0, 0, 10) started
13:23:43 DISPATCHER: Trying to submit another job.
13:23:43 job_callback for (0, 0, 10) got condition
13:23:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:23:43 Only 11 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
13:23:43 HBMASTER: Trying to run another job!
13:23:43 job_callback for (0, 0, 10) finished
13:23:43 start sampling a new configuration.
13:23:43 done sampling a new configuration.
13:23:43 HBMASTER: schedule new run for iteration 0
13:23:43 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
13:23:43 HBMASTER: submitting job (0, 0, 11) to dispatcher
13:23:43 DISPATCHER: trying to submit job (0, 0, 11)
13:23:43 DISPATCHER: trying to notify the job_runner thread.
13:23:43 HBMASTER: job (0, 0, 11) submitted to dispatcher
13:23:43 DISPATCHER: Trying to submit another job.
13:23:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:23:43 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776
13:23:43 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
13:23:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:23:43 WORKER: start processing job (0, 0, 11)
13:23:43 WORKER: args: ()
13:23:43 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.00241495915478618, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.09574767090125094, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 38, 'num_filters_3': 85, 'num_filters_4': 106}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:24:24 DISPATCHER: Starting worker discovery
13:24:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:24:25 DISPATCHER: Finished worker discovery
13:25:06 WORKER: done with job (0, 0, 11), trying to register it.
13:25:06 WORKER: registered result for job (0, 0, 11) with dispatcher
13:25:06 DISPATCHER: job (0, 0, 11) finished
13:25:06 DISPATCHER: register_result: lock acquired
13:25:06 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
13:25:06 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.00241495915478618, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.09574767090125094, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 38, 'num_filters_3': 85, 'num_filters_4': 106}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2625823574145597, 'info': {'data03': 0.2625823574145597, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.00241495915478618, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.09574767090125094, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 38, 'num_filters_3': 85, 'num_filters_4': 106}"}}
exception: None

13:25:06 job_callback for (0, 0, 11) started
13:25:06 DISPATCHER: Trying to submit another job.
13:25:06 job_callback for (0, 0, 11) got condition
13:25:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:25:06 Only 12 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
13:25:06 HBMASTER: Trying to run another job!
13:25:06 job_callback for (0, 0, 11) finished
13:25:06 start sampling a new configuration.
13:25:06 done sampling a new configuration.
13:25:06 HBMASTER: schedule new run for iteration 0
13:25:06 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
13:25:06 HBMASTER: submitting job (0, 0, 12) to dispatcher
13:25:06 DISPATCHER: trying to submit job (0, 0, 12)
13:25:06 DISPATCHER: trying to notify the job_runner thread.
13:25:06 HBMASTER: job (0, 0, 12) submitted to dispatcher
13:25:06 DISPATCHER: Trying to submit another job.
13:25:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:25:06 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpui.1576139975513683776
13:25:06 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
13:25:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:25:06 WORKER: start processing job (0, 0, 12)
13:25:06 WORKER: args: ()
13:25:06 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0018274739597490233, 'num_filters_1': 126, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.020921760308598235, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 46, 'num_filters_3': 29, 'num_filters_4': 66}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:25:25 DISPATCHER: Starting worker discovery
13:25:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:25:25 DISPATCHER: Finished worker discovery
13:26:25 DISPATCHER: Starting worker discovery
13:26:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:26:25 DISPATCHER: Finished worker discovery
13:26:30 WORKER: done with job (0, 0, 12), trying to register it.
13:26:30 WORKER: registered result for job (0, 0, 12) with dispatcher
13:26:30 DISPATCHER: job (0, 0, 12) finished
13:26:30 DISPATCHER: register_result: lock acquired
13:26:30 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
13:26:30 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0018274739597490233, 'num_filters_1': 126, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.020921760308598235, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 46, 'num_filters_3': 29, 'num_filters_4': 66}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.34293258317337033, 'info': {'data03': 0.34293258317337033, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0018274739597490233, 'num_filters_1': 126, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.020921760308598235, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 46, 'num_filters_3': 29, 'num_filters_4': 66}"}}
exception: None

13:26:30 job_callback for (0, 0, 12) started
13:26:30 job_callback for (0, 0, 12) got condition
13:26:30 DISPATCHER: Trying to submit another job.
13:26:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:26:30 Only 13 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
13:26:30 HBMASTER: Trying to run another job!
13:26:30 job_callback for (0, 0, 12) finished
13:26:30 start sampling a new configuration.
13:26:30 done sampling a new configuration.
13:26:30 HBMASTER: schedule new run for iteration 0
13:26:30 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
13:26:30 HBMASTER: submitting job (0, 0, 13) to dispatcher
13:26:30 DISPATCHER: trying to submit job (0, 0, 13)
13:26:30 DISPATCHER: trying to notify the job_runner thread.
13:26:30 HBMASTER: job (0, 0, 13) submitted to dispatcher
13:26:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:26:30 DISPATCHER: Trying to submit another job.
13:26:30 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpui.1576139975513683776
13:26:30 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
13:26:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:26:30 WORKER: start processing job (0, 0, 13)
13:26:30 WORKER: args: ()
13:26:30 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002922779734733952, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.02009746935857763, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 77, 'num_filters_3': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:27:25 DISPATCHER: Starting worker discovery
13:27:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:27:25 DISPATCHER: Finished worker discovery
13:27:53 WORKER: done with job (0, 0, 13), trying to register it.
13:27:53 WORKER: registered result for job (0, 0, 13) with dispatcher
13:27:53 DISPATCHER: job (0, 0, 13) finished
13:27:53 DISPATCHER: register_result: lock acquired
13:27:53 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
13:27:53 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002922779734733952, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.02009746935857763, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 77, 'num_filters_3': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3189287247060368, 'info': {'data03': 0.3189287247060368, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002922779734733952, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.02009746935857763, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 77, 'num_filters_3': 24}"}}
exception: None

13:27:53 job_callback for (0, 0, 13) started
13:27:53 DISPATCHER: Trying to submit another job.
13:27:53 job_callback for (0, 0, 13) got condition
13:27:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:27:53 Only 14 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
13:27:53 HBMASTER: Trying to run another job!
13:27:53 job_callback for (0, 0, 13) finished
13:27:53 start sampling a new configuration.
13:27:53 done sampling a new configuration.
13:27:53 HBMASTER: schedule new run for iteration 0
13:27:53 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
13:27:53 HBMASTER: submitting job (0, 0, 14) to dispatcher
13:27:53 DISPATCHER: trying to submit job (0, 0, 14)
13:27:53 DISPATCHER: trying to notify the job_runner thread.
13:27:53 HBMASTER: job (0, 0, 14) submitted to dispatcher
13:27:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:27:53 DISPATCHER: Trying to submit another job.
13:27:53 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776
13:27:53 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
13:27:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:27:53 WORKER: start processing job (0, 0, 14)
13:27:53 WORKER: args: ()
13:27:53 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007071038978983309, 'num_filters_1': 73, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.014858393982464933}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:28:25 DISPATCHER: Starting worker discovery
13:28:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:28:25 DISPATCHER: Finished worker discovery
13:29:16 WORKER: done with job (0, 0, 14), trying to register it.
13:29:16 WORKER: registered result for job (0, 0, 14) with dispatcher
13:29:16 DISPATCHER: job (0, 0, 14) finished
13:29:16 DISPATCHER: register_result: lock acquired
13:29:16 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
13:29:16 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007071038978983309, 'num_filters_1': 73, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.014858393982464933}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4012898888181067, 'info': {'data03': 0.4012898888181067, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007071038978983309, 'num_filters_1': 73, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.014858393982464933}"}}
exception: None

13:29:16 job_callback for (0, 0, 14) started
13:29:16 job_callback for (0, 0, 14) got condition
13:29:16 DISPATCHER: Trying to submit another job.
13:29:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:29:16 Only 15 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
13:29:16 HBMASTER: Trying to run another job!
13:29:16 job_callback for (0, 0, 14) finished
13:29:16 start sampling a new configuration.
13:29:16 done sampling a new configuration.
13:29:16 HBMASTER: schedule new run for iteration 0
13:29:16 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
13:29:16 HBMASTER: submitting job (0, 0, 15) to dispatcher
13:29:16 DISPATCHER: trying to submit job (0, 0, 15)
13:29:16 DISPATCHER: trying to notify the job_runner thread.
13:29:16 HBMASTER: job (0, 0, 15) submitted to dispatcher
13:29:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:29:16 DISPATCHER: Trying to submit another job.
13:29:16 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776
13:29:16 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
13:29:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:29:16 WORKER: start processing job (0, 0, 15)
13:29:16 WORKER: args: ()
13:29:16 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.015808612357417942, 'num_filters_1': 67, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.011890349289815265}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:29:25 DISPATCHER: Starting worker discovery
13:29:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:29:25 DISPATCHER: Finished worker discovery
13:30:25 DISPATCHER: Starting worker discovery
13:30:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:30:25 DISPATCHER: Finished worker discovery
13:30:40 WORKER: done with job (0, 0, 15), trying to register it.
13:30:40 WORKER: registered result for job (0, 0, 15) with dispatcher
13:30:40 DISPATCHER: job (0, 0, 15) finished
13:30:40 DISPATCHER: register_result: lock acquired
13:30:40 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
13:30:40 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.015808612357417942, 'num_filters_1': 67, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.011890349289815265}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3530777544335633, 'info': {'data03': 0.3530777544335633, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.015808612357417942, 'num_filters_1': 67, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.011890349289815265}"}}
exception: None

13:30:40 job_callback for (0, 0, 15) started
13:30:40 job_callback for (0, 0, 15) got condition
13:30:40 DISPATCHER: Trying to submit another job.
13:30:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:30:40 Only 16 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
13:30:40 HBMASTER: Trying to run another job!
13:30:40 job_callback for (0, 0, 15) finished
13:30:40 start sampling a new configuration.
13:30:40 done sampling a new configuration.
13:30:40 HBMASTER: schedule new run for iteration 0
13:30:40 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
13:30:40 HBMASTER: submitting job (0, 0, 16) to dispatcher
13:30:40 DISPATCHER: trying to submit job (0, 0, 16)
13:30:40 DISPATCHER: trying to notify the job_runner thread.
13:30:40 HBMASTER: job (0, 0, 16) submitted to dispatcher
13:30:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:30:40 DISPATCHER: Trying to submit another job.
13:30:40 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpui.1576139975513683776
13:30:40 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
13:30:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:30:40 WORKER: start processing job (0, 0, 16)
13:30:40 WORKER: args: ()
13:30:40 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.021694210313209478, 'num_filters_1': 120, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.18573122263686664, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 72, 'num_filters_3': 85, 'num_filters_4': 34, 'num_filters_5': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:31:25 DISPATCHER: Starting worker discovery
13:31:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:31:25 DISPATCHER: Finished worker discovery
13:32:10 WORKER: done with job (0, 0, 16), trying to register it.
13:32:10 WORKER: registered result for job (0, 0, 16) with dispatcher
13:32:10 DISPATCHER: job (0, 0, 16) finished
13:32:10 DISPATCHER: register_result: lock acquired
13:32:10 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
13:32:10 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.021694210313209478, 'num_filters_1': 120, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.18573122263686664, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 72, 'num_filters_3': 85, 'num_filters_4': 34, 'num_filters_5': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.021694210313209478, 'num_filters_1': 120, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.18573122263686664, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 72, 'num_filters_3': 85, 'num_filters_4': 34, 'num_filters_5': 21}"}}
exception: None

13:32:10 job_callback for (0, 0, 16) started
13:32:10 job_callback for (0, 0, 16) got condition
13:32:10 DISPATCHER: Trying to submit another job.
13:32:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:32:10 HBMASTER: Trying to run another job!
13:32:10 job_callback for (0, 0, 16) finished
13:32:10 start sampling a new configuration.
13:32:10 done sampling a new configuration.
13:32:10 HBMASTER: schedule new run for iteration 0
13:32:10 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
13:32:10 HBMASTER: submitting job (0, 0, 17) to dispatcher
13:32:10 DISPATCHER: trying to submit job (0, 0, 17)
13:32:10 DISPATCHER: trying to notify the job_runner thread.
13:32:10 HBMASTER: job (0, 0, 17) submitted to dispatcher
13:32:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:32:10 DISPATCHER: Trying to submit another job.
13:32:10 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpui.1576139975513683776
13:32:10 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
13:32:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:32:10 WORKER: start processing job (0, 0, 17)
13:32:10 WORKER: args: ()
13:32:10 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.002374464185207884, 'num_filters_1': 83, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.04695204309230213, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 122, 'num_filters_3': 96}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:32:25 DISPATCHER: Starting worker discovery
13:32:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:32:25 DISPATCHER: Finished worker discovery
13:33:25 DISPATCHER: Starting worker discovery
13:33:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:33:25 DISPATCHER: Finished worker discovery
13:33:33 WORKER: done with job (0, 0, 17), trying to register it.
13:33:33 WORKER: registered result for job (0, 0, 17) with dispatcher
13:33:33 DISPATCHER: job (0, 0, 17) finished
13:33:33 DISPATCHER: register_result: lock acquired
13:33:33 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
13:33:33 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.002374464185207884, 'num_filters_1': 83, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.04695204309230213, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 122, 'num_filters_3': 96}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.28326735166503475, 'info': {'data03': 0.28326735166503475, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.002374464185207884, 'num_filters_1': 83, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.04695204309230213, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 122, 'num_filters_3': 96}"}}
exception: None

13:33:33 job_callback for (0, 0, 17) started
13:33:33 DISPATCHER: Trying to submit another job.
13:33:33 job_callback for (0, 0, 17) got condition
13:33:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:33:33 HBMASTER: Trying to run another job!
13:33:33 job_callback for (0, 0, 17) finished
13:33:33 start sampling a new configuration.
13:33:33 done sampling a new configuration.
13:33:33 HBMASTER: schedule new run for iteration 0
13:33:33 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
13:33:33 HBMASTER: submitting job (0, 0, 18) to dispatcher
13:33:33 DISPATCHER: trying to submit job (0, 0, 18)
13:33:33 DISPATCHER: trying to notify the job_runner thread.
13:33:33 HBMASTER: job (0, 0, 18) submitted to dispatcher
13:33:33 DISPATCHER: Trying to submit another job.
13:33:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:33:33 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpui.1576139975513683776
13:33:33 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
13:33:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:33:33 WORKER: start processing job (0, 0, 18)
13:33:33 WORKER: args: ()
13:33:33 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.05323888871184073, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.02779432533340604, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 42, 'num_filters_3': 85}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:34:25 DISPATCHER: Starting worker discovery
13:34:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:34:25 DISPATCHER: Finished worker discovery
13:34:56 WORKER: done with job (0, 0, 18), trying to register it.
13:34:56 WORKER: registered result for job (0, 0, 18) with dispatcher
13:34:56 DISPATCHER: job (0, 0, 18) finished
13:34:56 DISPATCHER: register_result: lock acquired
13:34:56 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
13:34:56 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.05323888871184073, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.02779432533340604, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 42, 'num_filters_3': 85}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2960541540416937, 'info': {'data03': 0.2960541540416937, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.05323888871184073, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.02779432533340604, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 42, 'num_filters_3': 85}"}}
exception: None

13:34:56 job_callback for (0, 0, 18) started
13:34:56 job_callback for (0, 0, 18) got condition
13:34:56 DISPATCHER: Trying to submit another job.
13:34:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:34:56 HBMASTER: Trying to run another job!
13:34:56 job_callback for (0, 0, 18) finished
13:34:56 start sampling a new configuration.
13:34:56 done sampling a new configuration.
13:34:56 HBMASTER: schedule new run for iteration 0
13:34:56 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
13:34:56 HBMASTER: submitting job (0, 0, 19) to dispatcher
13:34:56 DISPATCHER: trying to submit job (0, 0, 19)
13:34:56 DISPATCHER: trying to notify the job_runner thread.
13:34:56 HBMASTER: job (0, 0, 19) submitted to dispatcher
13:34:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:34:56 DISPATCHER: Trying to submit another job.
13:34:56 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpui.1576139975513683776
13:34:56 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
13:34:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:34:56 WORKER: start processing job (0, 0, 19)
13:34:56 WORKER: args: ()
13:34:56 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.02751227892087302, 'num_filters_1': 33, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.11798070829511144, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 24, 'num_filters_3': 16, 'num_filters_4': 70, 'num_filters_5': 96}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:35:25 DISPATCHER: Starting worker discovery
13:35:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:35:25 DISPATCHER: Finished worker discovery
13:36:16 WORKER: done with job (0, 0, 19), trying to register it.
13:36:16 WORKER: registered result for job (0, 0, 19) with dispatcher
13:36:16 DISPATCHER: job (0, 0, 19) finished
13:36:16 DISPATCHER: register_result: lock acquired
13:36:16 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
13:36:16 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.02751227892087302, 'num_filters_1': 33, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.11798070829511144, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 24, 'num_filters_3': 16, 'num_filters_4': 70, 'num_filters_5': 96}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2795699238904621, 'info': {'data03': 0.2795699238904621, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.02751227892087302, 'num_filters_1': 33, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.11798070829511144, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 24, 'num_filters_3': 16, 'num_filters_4': 70, 'num_filters_5': 96}"}}
exception: None

13:36:16 job_callback for (0, 0, 19) started
13:36:16 job_callback for (0, 0, 19) got condition
13:36:16 DISPATCHER: Trying to submit another job.
13:36:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:36:16 HBMASTER: Trying to run another job!
13:36:16 job_callback for (0, 0, 19) finished
13:36:16 start sampling a new configuration.
13:36:16 done sampling a new configuration.
13:36:16 HBMASTER: schedule new run for iteration 0
13:36:16 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
13:36:16 HBMASTER: submitting job (0, 0, 20) to dispatcher
13:36:16 DISPATCHER: trying to submit job (0, 0, 20)
13:36:16 DISPATCHER: trying to notify the job_runner thread.
13:36:16 HBMASTER: job (0, 0, 20) submitted to dispatcher
13:36:16 DISPATCHER: Trying to submit another job.
13:36:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:36:16 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpui.1576139975513683776
13:36:16 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
13:36:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:36:16 WORKER: start processing job (0, 0, 20)
13:36:16 WORKER: args: ()
13:36:16 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0036585860970145094, 'num_filters_1': 18, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.01745051445842373, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 60, 'num_filters_3': 125}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:36:25 DISPATCHER: Starting worker discovery
13:36:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:36:25 DISPATCHER: Finished worker discovery
13:37:25 DISPATCHER: Starting worker discovery
13:37:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:37:25 DISPATCHER: Finished worker discovery
13:37:40 WORKER: done with job (0, 0, 20), trying to register it.
13:37:40 WORKER: registered result for job (0, 0, 20) with dispatcher
13:37:40 DISPATCHER: job (0, 0, 20) finished
13:37:40 DISPATCHER: register_result: lock acquired
13:37:40 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
13:37:40 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0036585860970145094, 'num_filters_1': 18, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.01745051445842373, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 60, 'num_filters_3': 125}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.31352974822491925, 'info': {'data03': 0.31352974822491925, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0036585860970145094, 'num_filters_1': 18, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.01745051445842373, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 60, 'num_filters_3': 125}"}}
exception: None

13:37:40 job_callback for (0, 0, 20) started
13:37:40 DISPATCHER: Trying to submit another job.
13:37:40 job_callback for (0, 0, 20) got condition
13:37:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:37:40 HBMASTER: Trying to run another job!
13:37:40 job_callback for (0, 0, 20) finished
13:37:40 start sampling a new configuration.
13:37:40 done sampling a new configuration.
13:37:40 HBMASTER: schedule new run for iteration 0
13:37:40 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
13:37:40 HBMASTER: submitting job (0, 0, 21) to dispatcher
13:37:40 DISPATCHER: trying to submit job (0, 0, 21)
13:37:40 DISPATCHER: trying to notify the job_runner thread.
13:37:40 HBMASTER: job (0, 0, 21) submitted to dispatcher
13:37:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:37:40 DISPATCHER: Trying to submit another job.
13:37:40 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776
13:37:40 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
13:37:40 WORKER: start processing job (0, 0, 21)
13:37:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:37:40 WORKER: args: ()
13:37:40 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.05031660997935461, 'num_filters_1': 44, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.056689482743911196, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 50, 'num_filters_3': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:38:25 DISPATCHER: Starting worker discovery
13:38:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:38:25 DISPATCHER: Finished worker discovery
13:39:03 WORKER: done with job (0, 0, 21), trying to register it.
13:39:03 WORKER: registered result for job (0, 0, 21) with dispatcher
13:39:03 DISPATCHER: job (0, 0, 21) finished
13:39:03 DISPATCHER: register_result: lock acquired
13:39:03 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
13:39:03 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.05031660997935461, 'num_filters_1': 44, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.056689482743911196, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 50, 'num_filters_3': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.05031660997935461, 'num_filters_1': 44, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.056689482743911196, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 50, 'num_filters_3': 23}"}}
exception: None

13:39:03 job_callback for (0, 0, 21) started
13:39:03 job_callback for (0, 0, 21) got condition
13:39:03 DISPATCHER: Trying to submit another job.
13:39:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:39:03 HBMASTER: Trying to run another job!
13:39:03 job_callback for (0, 0, 21) finished
13:39:03 start sampling a new configuration.
13:39:03 done sampling a new configuration.
13:39:03 HBMASTER: schedule new run for iteration 0
13:39:03 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
13:39:03 HBMASTER: submitting job (0, 0, 22) to dispatcher
13:39:03 DISPATCHER: trying to submit job (0, 0, 22)
13:39:03 DISPATCHER: trying to notify the job_runner thread.
13:39:03 HBMASTER: job (0, 0, 22) submitted to dispatcher
13:39:03 DISPATCHER: Trying to submit another job.
13:39:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:39:03 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776
13:39:03 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
13:39:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:39:03 WORKER: start processing job (0, 0, 22)
13:39:03 WORKER: args: ()
13:39:03 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.004993752972911515, 'num_filters_1': 94, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.17916370951823757}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:39:25 DISPATCHER: Starting worker discovery
13:39:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:39:25 DISPATCHER: Finished worker discovery
13:40:25 DISPATCHER: Starting worker discovery
13:40:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:40:25 DISPATCHER: Finished worker discovery
13:40:26 WORKER: done with job (0, 0, 22), trying to register it.
13:40:26 WORKER: registered result for job (0, 0, 22) with dispatcher
13:40:26 DISPATCHER: job (0, 0, 22) finished
13:40:26 DISPATCHER: register_result: lock acquired
13:40:26 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
13:40:26 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.004993752972911515, 'num_filters_1': 94, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.17916370951823757}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.33958895689399693, 'info': {'data03': 0.33958895689399693, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.004993752972911515, 'num_filters_1': 94, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.17916370951823757}"}}
exception: None

13:40:26 job_callback for (0, 0, 22) started
13:40:26 job_callback for (0, 0, 22) got condition
13:40:26 DISPATCHER: Trying to submit another job.
13:40:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:40:26 HBMASTER: Trying to run another job!
13:40:26 job_callback for (0, 0, 22) finished
13:40:26 start sampling a new configuration.
13:40:26 done sampling a new configuration.
13:40:26 HBMASTER: schedule new run for iteration 0
13:40:26 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
13:40:26 HBMASTER: submitting job (0, 0, 23) to dispatcher
13:40:26 DISPATCHER: trying to submit job (0, 0, 23)
13:40:26 DISPATCHER: trying to notify the job_runner thread.
13:40:26 HBMASTER: job (0, 0, 23) submitted to dispatcher
13:40:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:40:26 DISPATCHER: Trying to submit another job.
13:40:26 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpui.1576139975513683776
13:40:26 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
13:40:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:40:26 WORKER: start processing job (0, 0, 23)
13:40:26 WORKER: args: ()
13:40:26 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.024599500285180043, 'num_filters_1': 105, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.1959616102392119}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:41:25 DISPATCHER: Starting worker discovery
13:41:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:41:25 DISPATCHER: Finished worker discovery
13:41:49 WORKER: done with job (0, 0, 23), trying to register it.
13:41:49 WORKER: registered result for job (0, 0, 23) with dispatcher
13:41:49 DISPATCHER: job (0, 0, 23) finished
13:41:49 DISPATCHER: register_result: lock acquired
13:41:49 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
13:41:49 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.024599500285180043, 'num_filters_1': 105, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.1959616102392119}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.28819792705777564, 'info': {'data03': 0.28819792705777564, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.024599500285180043, 'num_filters_1': 105, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.1959616102392119}"}}
exception: None

13:41:49 job_callback for (0, 0, 23) started
13:41:49 job_callback for (0, 0, 23) got condition
13:41:49 DISPATCHER: Trying to submit another job.
13:41:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:41:49 HBMASTER: Trying to run another job!
13:41:49 job_callback for (0, 0, 23) finished
13:41:49 start sampling a new configuration.
13:41:49 done sampling a new configuration.
13:41:49 HBMASTER: schedule new run for iteration 0
13:41:49 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
13:41:49 HBMASTER: submitting job (0, 0, 24) to dispatcher
13:41:49 DISPATCHER: trying to submit job (0, 0, 24)
13:41:49 DISPATCHER: trying to notify the job_runner thread.
13:41:49 HBMASTER: job (0, 0, 24) submitted to dispatcher
13:41:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:41:49 DISPATCHER: Trying to submit another job.
13:41:49 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776
13:41:49 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
13:41:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:41:49 WORKER: start processing job (0, 0, 24)
13:41:49 WORKER: args: ()
13:41:49 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004833352434204842, 'num_filters_1': 30, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.1301519786004452}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:42:25 DISPATCHER: Starting worker discovery
13:42:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:42:25 DISPATCHER: Finished worker discovery
13:43:12 WORKER: done with job (0, 0, 24), trying to register it.
13:43:12 WORKER: registered result for job (0, 0, 24) with dispatcher
13:43:12 DISPATCHER: job (0, 0, 24) finished
13:43:12 DISPATCHER: register_result: lock acquired
13:43:12 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
13:43:12 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004833352434204842, 'num_filters_1': 30, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.1301519786004452}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3228627890253199, 'info': {'data03': 0.3228627890253199, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004833352434204842, 'num_filters_1': 30, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.1301519786004452}"}}
exception: None

13:43:12 job_callback for (0, 0, 24) started
13:43:12 job_callback for (0, 0, 24) got condition
13:43:12 DISPATCHER: Trying to submit another job.
13:43:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:43:12 HBMASTER: Trying to run another job!
13:43:12 job_callback for (0, 0, 24) finished
13:43:12 start sampling a new configuration.
13:43:12 done sampling a new configuration.
13:43:12 HBMASTER: schedule new run for iteration 0
13:43:12 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
13:43:12 HBMASTER: submitting job (0, 0, 25) to dispatcher
13:43:12 DISPATCHER: trying to submit job (0, 0, 25)
13:43:12 DISPATCHER: trying to notify the job_runner thread.
13:43:12 HBMASTER: job (0, 0, 25) submitted to dispatcher
13:43:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:43:12 DISPATCHER: Trying to submit another job.
13:43:12 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpui.1576139975513683776
13:43:12 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
13:43:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:43:12 WORKER: start processing job (0, 0, 25)
13:43:12 WORKER: args: ()
13:43:12 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.09591261273903474, 'num_filters_1': 71, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.07236430352616224, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 44, 'num_filters_3': 64, 'num_filters_4': 96}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:43:25 DISPATCHER: Starting worker discovery
13:43:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:43:25 DISPATCHER: Finished worker discovery
13:44:25 DISPATCHER: Starting worker discovery
13:44:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:44:25 DISPATCHER: Finished worker discovery
13:44:36 WORKER: done with job (0, 0, 25), trying to register it.
13:44:36 WORKER: registered result for job (0, 0, 25) with dispatcher
13:44:36 DISPATCHER: job (0, 0, 25) finished
13:44:36 DISPATCHER: register_result: lock acquired
13:44:36 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
13:44:36 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.09591261273903474, 'num_filters_1': 71, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.07236430352616224, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 44, 'num_filters_3': 64, 'num_filters_4': 96}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.09591261273903474, 'num_filters_1': 71, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.07236430352616224, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 44, 'num_filters_3': 64, 'num_filters_4': 96}"}}
exception: None

13:44:36 job_callback for (0, 0, 25) started
13:44:36 job_callback for (0, 0, 25) got condition
13:44:36 DISPATCHER: Trying to submit another job.
13:44:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:44:36 HBMASTER: Trying to run another job!
13:44:36 job_callback for (0, 0, 25) finished
13:44:36 start sampling a new configuration.
13:44:36 done sampling a new configuration.
13:44:36 HBMASTER: schedule new run for iteration 0
13:44:36 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
13:44:36 HBMASTER: submitting job (0, 0, 26) to dispatcher
13:44:36 DISPATCHER: trying to submit job (0, 0, 26)
13:44:36 DISPATCHER: trying to notify the job_runner thread.
13:44:36 HBMASTER: job (0, 0, 26) submitted to dispatcher
13:44:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:44:36 DISPATCHER: Trying to submit another job.
13:44:36 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpui.1576139975513683776
13:44:36 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
13:44:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:44:36 WORKER: start processing job (0, 0, 26)
13:44:36 WORKER: args: ()
13:44:36 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0014536242876948048, 'num_filters_1': 47, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.048248131741734424}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:45:25 DISPATCHER: Starting worker discovery
13:45:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:45:25 DISPATCHER: Finished worker discovery
13:45:59 WORKER: done with job (0, 0, 26), trying to register it.
13:45:59 WORKER: registered result for job (0, 0, 26) with dispatcher
13:45:59 DISPATCHER: job (0, 0, 26) finished
13:45:59 DISPATCHER: register_result: lock acquired
13:45:59 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
13:45:59 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0014536242876948048, 'num_filters_1': 47, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.048248131741734424}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3234695088329764, 'info': {'data03': 0.3234695088329764, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0014536242876948048, 'num_filters_1': 47, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.048248131741734424}"}}
exception: None

13:45:59 job_callback for (0, 0, 26) started
13:45:59 job_callback for (0, 0, 26) got condition
13:45:59 DISPATCHER: Trying to submit another job.
13:45:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:45:59 HBMASTER: Trying to run another job!
13:45:59 job_callback for (0, 0, 26) finished
13:45:59 ITERATION: Advancing config (0, 0, 0) to next budget 133.333333
13:45:59 ITERATION: Advancing config (0, 0, 2) to next budget 133.333333
13:45:59 ITERATION: Advancing config (0, 0, 4) to next budget 133.333333
13:45:59 ITERATION: Advancing config (0, 0, 5) to next budget 133.333333
13:45:59 ITERATION: Advancing config (0, 0, 7) to next budget 133.333333
13:45:59 ITERATION: Advancing config (0, 0, 8) to next budget 133.333333
13:45:59 ITERATION: Advancing config (0, 0, 10) to next budget 133.333333
13:45:59 ITERATION: Advancing config (0, 0, 14) to next budget 133.333333
13:45:59 ITERATION: Advancing config (0, 0, 15) to next budget 133.333333
13:45:59 HBMASTER: schedule new run for iteration 0
13:45:59 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
13:45:59 HBMASTER: submitting job (0, 0, 0) to dispatcher
13:45:59 DISPATCHER: trying to submit job (0, 0, 0)
13:45:59 DISPATCHER: trying to notify the job_runner thread.
13:45:59 HBMASTER: job (0, 0, 0) submitted to dispatcher
13:45:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:45:59 DISPATCHER: Trying to submit another job.
13:45:59 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
13:45:59 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
13:45:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:45:59 WORKER: start processing job (0, 0, 0)
13:45:59 WORKER: args: ()
13:45:59 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.017286459844432688, 'num_filters_1': 17, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.02123635748911129}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:46:25 DISPATCHER: Starting worker discovery
13:46:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:46:25 DISPATCHER: Finished worker discovery
13:47:25 DISPATCHER: Starting worker discovery
13:47:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:47:25 DISPATCHER: Finished worker discovery
13:48:25 DISPATCHER: Starting worker discovery
13:48:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:48:25 DISPATCHER: Finished worker discovery
13:48:50 WORKER: done with job (0, 0, 0), trying to register it.
13:48:50 WORKER: registered result for job (0, 0, 0) with dispatcher
13:48:50 DISPATCHER: job (0, 0, 0) finished
13:48:50 DISPATCHER: register_result: lock acquired
13:48:50 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
13:48:50 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.017286459844432688, 'num_filters_1': 17, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.02123635748911129}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.37182778107934844, 'info': {'data03': 0.37182778107934844, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.017286459844432688, 'num_filters_1': 17, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.02123635748911129}"}}
exception: None

13:48:50 job_callback for (0, 0, 0) started
13:48:50 DISPATCHER: Trying to submit another job.
13:48:50 job_callback for (0, 0, 0) got condition
13:48:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:48:50 Only 1 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
13:48:50 HBMASTER: Trying to run another job!
13:48:50 job_callback for (0, 0, 0) finished
13:48:50 HBMASTER: schedule new run for iteration 0
13:48:50 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
13:48:50 HBMASTER: submitting job (0, 0, 2) to dispatcher
13:48:50 DISPATCHER: trying to submit job (0, 0, 2)
13:48:50 DISPATCHER: trying to notify the job_runner thread.
13:48:50 HBMASTER: job (0, 0, 2) submitted to dispatcher
13:48:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:48:50 DISPATCHER: Trying to submit another job.
13:48:50 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
13:48:50 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
13:48:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:48:50 WORKER: start processing job (0, 0, 2)
13:48:50 WORKER: args: ()
13:48:50 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0039275844428912285, 'num_filters_1': 54, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.026147647136185836, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 103, 'num_filters_3': 24, 'num_filters_4': 57, 'num_filters_5': 77}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:49:25 DISPATCHER: Starting worker discovery
13:49:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:49:25 DISPATCHER: Finished worker discovery
13:50:25 DISPATCHER: Starting worker discovery
13:50:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:50:25 DISPATCHER: Finished worker discovery
13:51:25 DISPATCHER: Starting worker discovery
13:51:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:51:25 DISPATCHER: Finished worker discovery
13:51:43 WORKER: done with job (0, 0, 2), trying to register it.
13:51:43 WORKER: registered result for job (0, 0, 2) with dispatcher
13:51:43 DISPATCHER: job (0, 0, 2) finished
13:51:43 DISPATCHER: register_result: lock acquired
13:51:43 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
13:51:43 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0039275844428912285, 'num_filters_1': 54, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.026147647136185836, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 103, 'num_filters_3': 24, 'num_filters_4': 57, 'num_filters_5': 77}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4332421321865983, 'info': {'data03': 0.4332421321865983, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0039275844428912285, 'num_filters_1': 54, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.026147647136185836, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 103, 'num_filters_3': 24, 'num_filters_4': 57, 'num_filters_5': 77}"}}
exception: None

13:51:43 job_callback for (0, 0, 2) started
13:51:43 job_callback for (0, 0, 2) got condition
13:51:43 DISPATCHER: Trying to submit another job.
13:51:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:51:43 Only 2 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
13:51:43 HBMASTER: Trying to run another job!
13:51:43 job_callback for (0, 0, 2) finished
13:51:43 HBMASTER: schedule new run for iteration 0
13:51:43 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
13:51:43 HBMASTER: submitting job (0, 0, 4) to dispatcher
13:51:43 DISPATCHER: trying to submit job (0, 0, 4)
13:51:43 DISPATCHER: trying to notify the job_runner thread.
13:51:43 HBMASTER: job (0, 0, 4) submitted to dispatcher
13:51:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:51:43 DISPATCHER: Trying to submit another job.
13:51:43 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
13:51:43 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
13:51:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:51:43 WORKER: start processing job (0, 0, 4)
13:51:43 WORKER: args: ()
13:51:43 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001381073182769778, 'num_filters_1': 46, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.062141503363574865, 'kernel_size_2': 5, 'num_filters_2': 24}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:52:25 DISPATCHER: Starting worker discovery
13:52:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:52:25 DISPATCHER: Finished worker discovery
13:53:25 DISPATCHER: Starting worker discovery
13:53:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:53:25 DISPATCHER: Finished worker discovery
13:54:25 DISPATCHER: Starting worker discovery
13:54:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:54:25 DISPATCHER: Finished worker discovery
13:54:37 WORKER: done with job (0, 0, 4), trying to register it.
13:54:37 WORKER: registered result for job (0, 0, 4) with dispatcher
13:54:37 DISPATCHER: job (0, 0, 4) finished
13:54:37 DISPATCHER: register_result: lock acquired
13:54:37 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
13:54:37 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001381073182769778, 'num_filters_1': 46, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.062141503363574865, 'kernel_size_2': 5, 'num_filters_2': 24}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.33585216233404513, 'info': {'data03': 0.33585216233404513, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001381073182769778, 'num_filters_1': 46, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.062141503363574865, 'kernel_size_2': 5, 'num_filters_2': 24}"}}
exception: None

13:54:37 job_callback for (0, 0, 4) started
13:54:37 DISPATCHER: Trying to submit another job.
13:54:37 job_callback for (0, 0, 4) got condition
13:54:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:54:37 Only 3 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
13:54:37 HBMASTER: Trying to run another job!
13:54:37 job_callback for (0, 0, 4) finished
13:54:37 HBMASTER: schedule new run for iteration 0
13:54:37 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
13:54:37 HBMASTER: submitting job (0, 0, 5) to dispatcher
13:54:37 DISPATCHER: trying to submit job (0, 0, 5)
13:54:37 DISPATCHER: trying to notify the job_runner thread.
13:54:37 HBMASTER: job (0, 0, 5) submitted to dispatcher
13:54:37 DISPATCHER: Trying to submit another job.
13:54:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:54:37 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
13:54:37 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
13:54:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:54:37 WORKER: start processing job (0, 0, 5)
13:54:37 WORKER: args: ()
13:54:37 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0038540822542164864, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.05971561705065691, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 44, 'num_filters_3': 128, 'num_filters_4': 91, 'num_filters_5': 44}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:55:25 DISPATCHER: Starting worker discovery
13:55:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:55:25 DISPATCHER: Finished worker discovery
13:56:25 DISPATCHER: Starting worker discovery
13:56:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:56:25 DISPATCHER: Finished worker discovery
13:57:25 DISPATCHER: Starting worker discovery
13:57:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:57:25 DISPATCHER: Finished worker discovery
13:57:29 WORKER: done with job (0, 0, 5), trying to register it.
13:57:29 WORKER: registered result for job (0, 0, 5) with dispatcher
13:57:29 DISPATCHER: job (0, 0, 5) finished
13:57:29 DISPATCHER: register_result: lock acquired
13:57:29 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
13:57:29 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0038540822542164864, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.05971561705065691, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 44, 'num_filters_3': 128, 'num_filters_4': 91, 'num_filters_5': 44}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4171528218627616, 'info': {'data03': 0.4171528218627616, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0038540822542164864, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.05971561705065691, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 44, 'num_filters_3': 128, 'num_filters_4': 91, 'num_filters_5': 44}"}}
exception: None

13:57:29 job_callback for (0, 0, 5) started
13:57:29 DISPATCHER: Trying to submit another job.
13:57:29 job_callback for (0, 0, 5) got condition
13:57:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:57:29 Only 4 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
13:57:29 HBMASTER: Trying to run another job!
13:57:29 job_callback for (0, 0, 5) finished
13:57:29 HBMASTER: schedule new run for iteration 0
13:57:29 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
13:57:29 HBMASTER: submitting job (0, 0, 7) to dispatcher
13:57:29 DISPATCHER: trying to submit job (0, 0, 7)
13:57:29 DISPATCHER: trying to notify the job_runner thread.
13:57:29 HBMASTER: job (0, 0, 7) submitted to dispatcher
13:57:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:57:29 DISPATCHER: Trying to submit another job.
13:57:29 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776
13:57:29 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
13:57:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:57:29 WORKER: start processing job (0, 0, 7)
13:57:29 WORKER: args: ()
13:57:29 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.005278480093278599, 'num_filters_1': 116, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.0727341157831343, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 35, 'num_filters_3': 99, 'num_filters_4': 32}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:58:25 DISPATCHER: Starting worker discovery
13:58:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:58:25 DISPATCHER: Finished worker discovery
13:59:25 DISPATCHER: Starting worker discovery
13:59:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:59:25 DISPATCHER: Finished worker discovery
14:00:20 WORKER: done with job (0, 0, 7), trying to register it.
14:00:20 WORKER: registered result for job (0, 0, 7) with dispatcher
14:00:20 DISPATCHER: job (0, 0, 7) finished
14:00:20 DISPATCHER: register_result: lock acquired
14:00:20 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
14:00:20 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.005278480093278599, 'num_filters_1': 116, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.0727341157831343, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 35, 'num_filters_3': 99, 'num_filters_4': 32}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.32391665972005246, 'info': {'data03': 0.32391665972005246, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.005278480093278599, 'num_filters_1': 116, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.0727341157831343, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 35, 'num_filters_3': 99, 'num_filters_4': 32}"}}
exception: None

14:00:20 job_callback for (0, 0, 7) started
14:00:20 DISPATCHER: Trying to submit another job.
14:00:20 job_callback for (0, 0, 7) got condition
14:00:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:00:20 Only 5 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
14:00:20 HBMASTER: Trying to run another job!
14:00:20 job_callback for (0, 0, 7) finished
14:00:20 HBMASTER: schedule new run for iteration 0
14:00:20 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
14:00:20 HBMASTER: submitting job (0, 0, 8) to dispatcher
14:00:20 DISPATCHER: trying to submit job (0, 0, 8)
14:00:20 DISPATCHER: trying to notify the job_runner thread.
14:00:20 HBMASTER: job (0, 0, 8) submitted to dispatcher
14:00:20 DISPATCHER: Trying to submit another job.
14:00:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:00:20 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776
14:00:20 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
14:00:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:00:20 WORKER: start processing job (0, 0, 8)
14:00:20 WORKER: args: ()
14:00:20 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.007014021020885936, 'num_filters_1': 86, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.014727459589957796, 'kernel_size_2': 3, 'num_filters_2': 86}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:00:25 DISPATCHER: Starting worker discovery
14:00:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:00:25 DISPATCHER: Finished worker discovery
14:01:25 DISPATCHER: Starting worker discovery
14:01:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:01:25 DISPATCHER: Finished worker discovery
14:02:25 DISPATCHER: Starting worker discovery
14:02:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:02:25 DISPATCHER: Finished worker discovery
14:03:14 WORKER: done with job (0, 0, 8), trying to register it.
14:03:14 WORKER: registered result for job (0, 0, 8) with dispatcher
14:03:14 DISPATCHER: job (0, 0, 8) finished
14:03:14 DISPATCHER: register_result: lock acquired
14:03:14 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
14:03:14 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.007014021020885936, 'num_filters_1': 86, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.014727459589957796, 'kernel_size_2': 3, 'num_filters_2': 86}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.33577023112428744, 'info': {'data03': 0.33577023112428744, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.007014021020885936, 'num_filters_1': 86, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.014727459589957796, 'kernel_size_2': 3, 'num_filters_2': 86}"}}
exception: None

14:03:14 job_callback for (0, 0, 8) started
14:03:14 DISPATCHER: Trying to submit another job.
14:03:14 job_callback for (0, 0, 8) got condition
14:03:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:03:14 Only 6 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
14:03:14 HBMASTER: Trying to run another job!
14:03:14 job_callback for (0, 0, 8) finished
14:03:14 HBMASTER: schedule new run for iteration 0
14:03:14 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
14:03:14 HBMASTER: submitting job (0, 0, 10) to dispatcher
14:03:14 DISPATCHER: trying to submit job (0, 0, 10)
14:03:14 DISPATCHER: trying to notify the job_runner thread.
14:03:14 HBMASTER: job (0, 0, 10) submitted to dispatcher
14:03:14 DISPATCHER: Trying to submit another job.
14:03:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:03:14 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpui.1576139975513683776
14:03:14 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
14:03:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:03:14 WORKER: start processing job (0, 0, 10)
14:03:14 WORKER: args: ()
14:03:14 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.003893050798529051, 'num_filters_1': 44, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.0160053311637959, 'kernel_size_2': 7, 'num_filters_2': 79}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:03:25 DISPATCHER: Starting worker discovery
14:03:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:03:25 DISPATCHER: Finished worker discovery
14:04:25 DISPATCHER: Starting worker discovery
14:04:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:04:25 DISPATCHER: Finished worker discovery
14:05:25 DISPATCHER: Starting worker discovery
14:05:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:05:25 DISPATCHER: Finished worker discovery
14:06:12 WORKER: done with job (0, 0, 10), trying to register it.
14:06:12 WORKER: registered result for job (0, 0, 10) with dispatcher
14:06:12 DISPATCHER: job (0, 0, 10) finished
14:06:12 DISPATCHER: register_result: lock acquired
14:06:12 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
14:06:12 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.003893050798529051, 'num_filters_1': 44, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.0160053311637959, 'kernel_size_2': 7, 'num_filters_2': 79}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.43255840732959305, 'info': {'data03': 0.43255840732959305, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.003893050798529051, 'num_filters_1': 44, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.0160053311637959, 'kernel_size_2': 7, 'num_filters_2': 79}"}}
exception: None

14:06:12 job_callback for (0, 0, 10) started
14:06:12 DISPATCHER: Trying to submit another job.
14:06:12 job_callback for (0, 0, 10) got condition
14:06:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:06:12 Only 7 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
14:06:12 HBMASTER: Trying to run another job!
14:06:12 job_callback for (0, 0, 10) finished
14:06:12 HBMASTER: schedule new run for iteration 0
14:06:12 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
14:06:12 HBMASTER: submitting job (0, 0, 14) to dispatcher
14:06:12 DISPATCHER: trying to submit job (0, 0, 14)
14:06:12 DISPATCHER: trying to notify the job_runner thread.
14:06:12 HBMASTER: job (0, 0, 14) submitted to dispatcher
14:06:12 DISPATCHER: Trying to submit another job.
14:06:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:06:12 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776
14:06:12 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
14:06:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:06:12 WORKER: start processing job (0, 0, 14)
14:06:12 WORKER: args: ()
14:06:12 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007071038978983309, 'num_filters_1': 73, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.014858393982464933}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:06:25 DISPATCHER: Starting worker discovery
14:06:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:06:25 DISPATCHER: Finished worker discovery
14:07:25 DISPATCHER: Starting worker discovery
14:07:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:07:25 DISPATCHER: Finished worker discovery
14:08:25 DISPATCHER: Starting worker discovery
14:08:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:08:25 DISPATCHER: Finished worker discovery
14:09:06 WORKER: done with job (0, 0, 14), trying to register it.
14:09:06 WORKER: registered result for job (0, 0, 14) with dispatcher
14:09:06 DISPATCHER: job (0, 0, 14) finished
14:09:06 DISPATCHER: register_result: lock acquired
14:09:06 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
14:09:06 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007071038978983309, 'num_filters_1': 73, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.014858393982464933}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.25407917777016836, 'info': {'data03': 0.25407917777016836, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.007071038978983309, 'num_filters_1': 73, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.014858393982464933}"}}
exception: None

14:09:06 job_callback for (0, 0, 14) started
14:09:06 DISPATCHER: Trying to submit another job.
14:09:06 job_callback for (0, 0, 14) got condition
14:09:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:09:06 Only 8 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
14:09:06 HBMASTER: Trying to run another job!
14:09:06 job_callback for (0, 0, 14) finished
14:09:06 HBMASTER: schedule new run for iteration 0
14:09:06 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
14:09:06 HBMASTER: submitting job (0, 0, 15) to dispatcher
14:09:06 DISPATCHER: trying to submit job (0, 0, 15)
14:09:06 DISPATCHER: trying to notify the job_runner thread.
14:09:06 HBMASTER: job (0, 0, 15) submitted to dispatcher
14:09:06 DISPATCHER: Trying to submit another job.
14:09:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:09:06 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776
14:09:06 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
14:09:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:09:06 WORKER: start processing job (0, 0, 15)
14:09:06 WORKER: args: ()
14:09:06 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.015808612357417942, 'num_filters_1': 67, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.011890349289815265}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:09:25 DISPATCHER: Starting worker discovery
14:09:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:09:25 DISPATCHER: Finished worker discovery
14:10:25 DISPATCHER: Starting worker discovery
14:10:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:10:25 DISPATCHER: Finished worker discovery
14:11:25 DISPATCHER: Starting worker discovery
14:11:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:11:25 DISPATCHER: Finished worker discovery
14:11:58 WORKER: done with job (0, 0, 15), trying to register it.
14:11:58 WORKER: registered result for job (0, 0, 15) with dispatcher
14:11:58 DISPATCHER: job (0, 0, 15) finished
14:11:58 DISPATCHER: register_result: lock acquired
14:11:58 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
14:11:58 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.015808612357417942, 'num_filters_1': 67, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.011890349289815265}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.38661941849148074, 'info': {'data03': 0.38661941849148074, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.015808612357417942, 'num_filters_1': 67, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.011890349289815265}"}}
exception: None

14:11:58 job_callback for (0, 0, 15) started
14:11:58 job_callback for (0, 0, 15) got condition
14:11:58 DISPATCHER: Trying to submit another job.
14:11:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:11:58 Only 9 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
14:11:58 HBMASTER: Trying to run another job!
14:11:58 job_callback for (0, 0, 15) finished
14:11:58 ITERATION: Advancing config (0, 0, 2) to next budget 400.000000
14:11:58 ITERATION: Advancing config (0, 0, 5) to next budget 400.000000
14:11:58 ITERATION: Advancing config (0, 0, 10) to next budget 400.000000
14:11:58 HBMASTER: schedule new run for iteration 0
14:11:58 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
14:11:58 HBMASTER: submitting job (0, 0, 2) to dispatcher
14:11:58 DISPATCHER: trying to submit job (0, 0, 2)
14:11:58 DISPATCHER: trying to notify the job_runner thread.
14:11:58 HBMASTER: job (0, 0, 2) submitted to dispatcher
14:11:58 DISPATCHER: Trying to submit another job.
14:11:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:11:58 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
14:11:58 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
14:11:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:11:58 WORKER: start processing job (0, 0, 2)
14:11:58 WORKER: args: ()
14:11:58 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0039275844428912285, 'num_filters_1': 54, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.026147647136185836, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 103, 'num_filters_3': 24, 'num_filters_4': 57, 'num_filters_5': 77}, 'budget': 400.0, 'working_directory': '.'}
14:12:25 DISPATCHER: Starting worker discovery
14:12:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:12:25 DISPATCHER: Finished worker discovery
14:13:25 DISPATCHER: Starting worker discovery
14:13:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:13:25 DISPATCHER: Finished worker discovery
14:14:25 DISPATCHER: Starting worker discovery
14:14:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:14:25 DISPATCHER: Finished worker discovery
14:15:25 DISPATCHER: Starting worker discovery
14:15:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:15:25 DISPATCHER: Finished worker discovery
14:16:25 DISPATCHER: Starting worker discovery
14:16:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:16:25 DISPATCHER: Finished worker discovery
14:17:25 DISPATCHER: Starting worker discovery
14:17:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:17:25 DISPATCHER: Finished worker discovery
14:18:25 DISPATCHER: Starting worker discovery
14:18:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:18:25 DISPATCHER: Finished worker discovery
14:19:16 WORKER: done with job (0, 0, 2), trying to register it.
14:19:16 WORKER: registered result for job (0, 0, 2) with dispatcher
14:19:16 DISPATCHER: job (0, 0, 2) finished
14:19:16 DISPATCHER: register_result: lock acquired
14:19:16 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
14:19:16 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0039275844428912285, 'num_filters_1': 54, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.026147647136185836, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 103, 'num_filters_3': 24, 'num_filters_4': 57, 'num_filters_5': 77}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3938389471039206, 'info': {'data03': 0.3938389471039206, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0039275844428912285, 'num_filters_1': 54, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.026147647136185836, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 103, 'num_filters_3': 24, 'num_filters_4': 57, 'num_filters_5': 77}"}}
exception: None

14:19:16 job_callback for (0, 0, 2) started
14:19:16 job_callback for (0, 0, 2) got condition
14:19:16 DISPATCHER: Trying to submit another job.
14:19:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:19:16 Only 1 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
14:19:16 HBMASTER: Trying to run another job!
14:19:16 job_callback for (0, 0, 2) finished
14:19:16 HBMASTER: schedule new run for iteration 0
14:19:16 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
14:19:16 HBMASTER: submitting job (0, 0, 5) to dispatcher
14:19:16 DISPATCHER: trying to submit job (0, 0, 5)
14:19:16 DISPATCHER: trying to notify the job_runner thread.
14:19:16 HBMASTER: job (0, 0, 5) submitted to dispatcher
14:19:16 DISPATCHER: Trying to submit another job.
14:19:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:19:16 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
14:19:16 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
14:19:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:19:16 WORKER: start processing job (0, 0, 5)
14:19:16 WORKER: args: ()
14:19:16 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0038540822542164864, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.05971561705065691, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 44, 'num_filters_3': 128, 'num_filters_4': 91, 'num_filters_5': 44}, 'budget': 400.0, 'working_directory': '.'}
14:19:25 DISPATCHER: Starting worker discovery
14:19:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:19:25 DISPATCHER: Finished worker discovery
14:20:25 DISPATCHER: Starting worker discovery
14:20:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:20:25 DISPATCHER: Finished worker discovery
14:21:25 DISPATCHER: Starting worker discovery
14:21:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:21:25 DISPATCHER: Finished worker discovery
14:22:25 DISPATCHER: Starting worker discovery
14:22:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:22:25 DISPATCHER: Finished worker discovery
14:23:25 DISPATCHER: Starting worker discovery
14:23:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:23:25 DISPATCHER: Finished worker discovery
14:24:25 DISPATCHER: Starting worker discovery
14:24:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:24:25 DISPATCHER: Finished worker discovery
14:25:25 DISPATCHER: Starting worker discovery
14:25:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:25:25 DISPATCHER: Finished worker discovery
14:26:25 DISPATCHER: Starting worker discovery
14:26:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:26:25 DISPATCHER: Finished worker discovery
14:26:34 WORKER: done with job (0, 0, 5), trying to register it.
14:26:34 WORKER: registered result for job (0, 0, 5) with dispatcher
14:26:34 DISPATCHER: job (0, 0, 5) finished
14:26:34 DISPATCHER: register_result: lock acquired
14:26:34 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
14:26:34 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0038540822542164864, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.05971561705065691, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 44, 'num_filters_3': 128, 'num_filters_4': 91, 'num_filters_5': 44}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.46922825665941387, 'info': {'data03': 0.46922825665941387, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0038540822542164864, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.05971561705065691, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 44, 'num_filters_3': 128, 'num_filters_4': 91, 'num_filters_5': 44}"}}
exception: None

14:26:34 job_callback for (0, 0, 5) started
14:26:34 job_callback for (0, 0, 5) got condition
14:26:34 DISPATCHER: Trying to submit another job.
14:26:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:26:34 Only 2 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
14:26:34 HBMASTER: Trying to run another job!
14:26:34 job_callback for (0, 0, 5) finished
14:26:34 HBMASTER: schedule new run for iteration 0
14:26:34 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
14:26:34 HBMASTER: submitting job (0, 0, 10) to dispatcher
14:26:34 DISPATCHER: trying to submit job (0, 0, 10)
14:26:34 DISPATCHER: trying to notify the job_runner thread.
14:26:34 HBMASTER: job (0, 0, 10) submitted to dispatcher
14:26:34 DISPATCHER: Trying to submit another job.
14:26:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:26:34 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpui.1576139975513683776
14:26:34 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
14:26:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:26:34 WORKER: start processing job (0, 0, 10)
14:26:34 WORKER: args: ()
14:26:34 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.003893050798529051, 'num_filters_1': 44, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.0160053311637959, 'kernel_size_2': 7, 'num_filters_2': 79}, 'budget': 400.0, 'working_directory': '.'}
14:27:25 DISPATCHER: Starting worker discovery
14:27:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:27:25 DISPATCHER: Finished worker discovery
14:28:25 DISPATCHER: Starting worker discovery
14:28:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:28:25 DISPATCHER: Finished worker discovery
14:29:25 DISPATCHER: Starting worker discovery
14:29:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:29:25 DISPATCHER: Finished worker discovery
14:30:25 DISPATCHER: Starting worker discovery
14:30:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:30:25 DISPATCHER: Finished worker discovery
14:31:25 DISPATCHER: Starting worker discovery
14:31:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:31:25 DISPATCHER: Finished worker discovery
14:32:25 DISPATCHER: Starting worker discovery
14:32:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:32:25 DISPATCHER: Finished worker discovery
14:33:25 DISPATCHER: Starting worker discovery
14:33:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:33:25 DISPATCHER: Finished worker discovery
14:33:55 WORKER: done with job (0, 0, 10), trying to register it.
14:33:55 WORKER: registered result for job (0, 0, 10) with dispatcher
14:33:55 DISPATCHER: job (0, 0, 10) finished
14:33:55 DISPATCHER: register_result: lock acquired
14:33:55 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
14:33:55 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.003893050798529051, 'num_filters_1': 44, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.0160053311637959, 'kernel_size_2': 7, 'num_filters_2': 79}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.38122674646124, 'info': {'data03': 0.38122674646124, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.003893050798529051, 'num_filters_1': 44, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.0160053311637959, 'kernel_size_2': 7, 'num_filters_2': 79}"}}
exception: None

14:33:55 job_callback for (0, 0, 10) started
14:33:55 DISPATCHER: Trying to submit another job.
14:33:55 job_callback for (0, 0, 10) got condition
14:33:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:33:55 Only 3 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
14:33:55 HBMASTER: Trying to run another job!
14:33:55 job_callback for (0, 0, 10) finished
14:33:55 ITERATION: Advancing config (0, 0, 5) to next budget 1200.000000
14:33:55 HBMASTER: schedule new run for iteration 0
14:33:55 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
14:33:55 HBMASTER: submitting job (0, 0, 5) to dispatcher
14:33:55 DISPATCHER: trying to submit job (0, 0, 5)
14:33:55 DISPATCHER: trying to notify the job_runner thread.
14:33:55 HBMASTER: job (0, 0, 5) submitted to dispatcher
14:33:55 DISPATCHER: Trying to submit another job.
14:33:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:33:55 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
14:33:55 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
14:33:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:33:55 WORKER: start processing job (0, 0, 5)
14:33:55 WORKER: args: ()
14:33:55 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0038540822542164864, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.05971561705065691, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 44, 'num_filters_3': 128, 'num_filters_4': 91, 'num_filters_5': 44}, 'budget': 1200.0, 'working_directory': '.'}
14:34:25 DISPATCHER: Starting worker discovery
14:34:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:34:25 DISPATCHER: Finished worker discovery
14:35:25 DISPATCHER: Starting worker discovery
14:35:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:35:25 DISPATCHER: Finished worker discovery
14:36:25 DISPATCHER: Starting worker discovery
14:36:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:36:25 DISPATCHER: Finished worker discovery
14:37:25 DISPATCHER: Starting worker discovery
14:37:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:37:25 DISPATCHER: Finished worker discovery
14:38:25 DISPATCHER: Starting worker discovery
14:38:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:38:25 DISPATCHER: Finished worker discovery
14:39:25 DISPATCHER: Starting worker discovery
14:39:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:39:25 DISPATCHER: Finished worker discovery
14:40:25 DISPATCHER: Starting worker discovery
14:40:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:40:25 DISPATCHER: Finished worker discovery
14:41:25 DISPATCHER: Starting worker discovery
14:41:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:41:25 DISPATCHER: Finished worker discovery
14:42:25 DISPATCHER: Starting worker discovery
14:42:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:42:25 DISPATCHER: Finished worker discovery
14:43:25 DISPATCHER: Starting worker discovery
14:43:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:43:25 DISPATCHER: Finished worker discovery
14:44:25 DISPATCHER: Starting worker discovery
14:44:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:44:25 DISPATCHER: Finished worker discovery
14:45:25 DISPATCHER: Starting worker discovery
14:45:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:45:25 DISPATCHER: Finished worker discovery
14:46:25 DISPATCHER: Starting worker discovery
14:46:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:46:25 DISPATCHER: Finished worker discovery
14:47:25 DISPATCHER: Starting worker discovery
14:47:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:47:25 DISPATCHER: Finished worker discovery
14:48:25 DISPATCHER: Starting worker discovery
14:48:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:48:25 DISPATCHER: Finished worker discovery
14:49:25 DISPATCHER: Starting worker discovery
14:49:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:49:25 DISPATCHER: Finished worker discovery
14:50:25 DISPATCHER: Starting worker discovery
14:50:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:50:25 DISPATCHER: Finished worker discovery
14:51:25 DISPATCHER: Starting worker discovery
14:51:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:51:25 DISPATCHER: Finished worker discovery
14:52:25 DISPATCHER: Starting worker discovery
14:52:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:52:25 DISPATCHER: Finished worker discovery
14:53:25 DISPATCHER: Starting worker discovery
14:53:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:53:25 DISPATCHER: Finished worker discovery
14:54:25 DISPATCHER: Starting worker discovery
14:54:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:54:25 DISPATCHER: Finished worker discovery
14:54:36 WORKER: done with job (0, 0, 5), trying to register it.
14:54:36 WORKER: registered result for job (0, 0, 5) with dispatcher
14:54:36 DISPATCHER: job (0, 0, 5) finished
14:54:36 DISPATCHER: register_result: lock acquired
14:54:36 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
14:54:36 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0038540822542164864, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.05971561705065691, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 44, 'num_filters_3': 128, 'num_filters_4': 91, 'num_filters_5': 44}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.3954147183018094, 'info': {'data03': 0.3954147183018094, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0038540822542164864, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.05971561705065691, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 44, 'num_filters_3': 128, 'num_filters_4': 91, 'num_filters_5': 44}"}}
exception: None

14:54:36 job_callback for (0, 0, 5) started
14:54:36 job_callback for (0, 0, 5) got condition
14:54:36 DISPATCHER: Trying to submit another job.
14:54:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:54:36 Only 1 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
14:54:36 HBMASTER: Trying to run another job!
14:54:36 job_callback for (0, 0, 5) finished
14:54:36 start sampling a new configuration.
14:54:36 done sampling a new configuration.
14:54:36 HBMASTER: schedule new run for iteration 1
14:54:36 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
14:54:36 HBMASTER: submitting job (1, 0, 0) to dispatcher
14:54:36 DISPATCHER: trying to submit job (1, 0, 0)
14:54:36 DISPATCHER: trying to notify the job_runner thread.
14:54:36 HBMASTER: job (1, 0, 0) submitted to dispatcher
14:54:36 DISPATCHER: Trying to submit another job.
14:54:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:54:36 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
14:54:36 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
14:54:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:54:36 WORKER: start processing job (1, 0, 0)
14:54:36 WORKER: args: ()
14:54:36 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.015671595687602336, 'num_filters_1': 35, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.05677530345840621}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:55:25 DISPATCHER: Starting worker discovery
14:55:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:55:25 DISPATCHER: Finished worker discovery
14:56:25 DISPATCHER: Starting worker discovery
14:56:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:56:25 DISPATCHER: Finished worker discovery
14:57:25 DISPATCHER: Starting worker discovery
14:57:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:57:25 DISPATCHER: Finished worker discovery
14:57:29 WORKER: done with job (1, 0, 0), trying to register it.
14:57:29 WORKER: registered result for job (1, 0, 0) with dispatcher
14:57:29 DISPATCHER: job (1, 0, 0) finished
14:57:29 DISPATCHER: register_result: lock acquired
14:57:29 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
14:57:29 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.015671595687602336, 'num_filters_1': 35, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.05677530345840621}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.25641870130651967, 'info': {'data03': 0.25641870130651967, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.015671595687602336, 'num_filters_1': 35, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.05677530345840621}"}}
exception: None

14:57:29 job_callback for (1, 0, 0) started
14:57:29 job_callback for (1, 0, 0) got condition
14:57:29 DISPATCHER: Trying to submit another job.
14:57:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:57:29 Only 10 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
14:57:29 HBMASTER: Trying to run another job!
14:57:29 job_callback for (1, 0, 0) finished
14:57:29 start sampling a new configuration.
14:57:29 done sampling a new configuration.
14:57:29 HBMASTER: schedule new run for iteration 1
14:57:29 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
14:57:29 HBMASTER: submitting job (1, 0, 1) to dispatcher
14:57:29 DISPATCHER: trying to submit job (1, 0, 1)
14:57:29 DISPATCHER: trying to notify the job_runner thread.
14:57:29 HBMASTER: job (1, 0, 1) submitted to dispatcher
14:57:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:57:29 DISPATCHER: Trying to submit another job.
14:57:29 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
14:57:29 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
14:57:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:57:29 WORKER: start processing job (1, 0, 1)
14:57:29 WORKER: args: ()
14:57:29 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.018168673085871615, 'num_filters_1': 84, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.024651287135157338}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:58:25 DISPATCHER: Starting worker discovery
14:58:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:58:25 DISPATCHER: Finished worker discovery
14:59:25 DISPATCHER: Starting worker discovery
14:59:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:59:25 DISPATCHER: Finished worker discovery
15:00:21 WORKER: done with job (1, 0, 1), trying to register it.
15:00:21 WORKER: registered result for job (1, 0, 1) with dispatcher
15:00:21 DISPATCHER: job (1, 0, 1) finished
15:00:21 DISPATCHER: register_result: lock acquired
15:00:21 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:00:21 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.018168673085871615, 'num_filters_1': 84, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.024651287135157338}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1882397772771774, 'info': {'data03': 0.1882397772771774, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.018168673085871615, 'num_filters_1': 84, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.024651287135157338}"}}
exception: None

15:00:21 job_callback for (1, 0, 1) started
15:00:21 job_callback for (1, 0, 1) got condition
15:00:21 DISPATCHER: Trying to submit another job.
15:00:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:00:21 Only 11 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
15:00:21 HBMASTER: Trying to run another job!
15:00:21 job_callback for (1, 0, 1) finished
15:00:21 start sampling a new configuration.
15:00:21 done sampling a new configuration.
15:00:21 HBMASTER: schedule new run for iteration 1
15:00:21 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
15:00:21 HBMASTER: submitting job (1, 0, 2) to dispatcher
15:00:21 DISPATCHER: trying to submit job (1, 0, 2)
15:00:21 DISPATCHER: trying to notify the job_runner thread.
15:00:21 HBMASTER: job (1, 0, 2) submitted to dispatcher
15:00:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:00:21 DISPATCHER: Trying to submit another job.
15:00:21 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:00:21 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:00:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:00:21 WORKER: start processing job (1, 0, 2)
15:00:21 WORKER: args: ()
15:00:21 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.023461373575956908, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.022938797666054354, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 27, 'num_filters_3': 99, 'num_filters_4': 16, 'num_filters_5': 51}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:00:25 DISPATCHER: Starting worker discovery
15:00:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:00:25 DISPATCHER: Finished worker discovery
15:01:25 DISPATCHER: Starting worker discovery
15:01:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:01:25 DISPATCHER: Finished worker discovery
15:02:25 DISPATCHER: Starting worker discovery
15:02:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:02:25 DISPATCHER: Finished worker discovery
15:03:15 WORKER: done with job (1, 0, 2), trying to register it.
15:03:15 WORKER: registered result for job (1, 0, 2) with dispatcher
15:03:15 DISPATCHER: job (1, 0, 2) finished
15:03:15 DISPATCHER: register_result: lock acquired
15:03:15 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:03:15 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.023461373575956908, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.022938797666054354, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 27, 'num_filters_3': 99, 'num_filters_4': 16, 'num_filters_5': 51}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.29996875894294356, 'info': {'data03': 0.29996875894294356, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.023461373575956908, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.022938797666054354, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 27, 'num_filters_3': 99, 'num_filters_4': 16, 'num_filters_5': 51}"}}
exception: None

15:03:15 job_callback for (1, 0, 2) started
15:03:15 DISPATCHER: Trying to submit another job.
15:03:15 job_callback for (1, 0, 2) got condition
15:03:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:03:15 Only 12 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
15:03:15 HBMASTER: Trying to run another job!
15:03:15 job_callback for (1, 0, 2) finished
15:03:15 start sampling a new configuration.
15:03:15 done sampling a new configuration.
15:03:15 HBMASTER: schedule new run for iteration 1
15:03:15 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
15:03:15 HBMASTER: submitting job (1, 0, 3) to dispatcher
15:03:15 DISPATCHER: trying to submit job (1, 0, 3)
15:03:15 DISPATCHER: trying to notify the job_runner thread.
15:03:15 HBMASTER: job (1, 0, 3) submitted to dispatcher
15:03:15 DISPATCHER: Trying to submit another job.
15:03:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:03:15 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:03:15 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:03:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:03:15 WORKER: start processing job (1, 0, 3)
15:03:15 WORKER: args: ()
15:03:15 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.01053818645767753, 'num_filters_1': 36, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.08819263383881633, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 47, 'num_filters_3': 21}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:03:25 DISPATCHER: Starting worker discovery
15:03:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:03:25 DISPATCHER: Finished worker discovery
15:04:25 DISPATCHER: Starting worker discovery
15:04:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:04:25 DISPATCHER: Finished worker discovery
15:05:25 DISPATCHER: Starting worker discovery
15:05:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:05:25 DISPATCHER: Finished worker discovery
15:06:07 WORKER: done with job (1, 0, 3), trying to register it.
15:06:07 WORKER: registered result for job (1, 0, 3) with dispatcher
15:06:07 DISPATCHER: job (1, 0, 3) finished
15:06:07 DISPATCHER: register_result: lock acquired
15:06:07 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:06:07 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.01053818645767753, 'num_filters_1': 36, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.08819263383881633, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 47, 'num_filters_3': 21}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.28941109750543054, 'info': {'data03': 0.28941109750543054, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.01053818645767753, 'num_filters_1': 36, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.08819263383881633, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 47, 'num_filters_3': 21}"}}
exception: None

15:06:07 job_callback for (1, 0, 3) started
15:06:07 DISPATCHER: Trying to submit another job.
15:06:07 job_callback for (1, 0, 3) got condition
15:06:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:06:07 Only 13 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
15:06:07 HBMASTER: Trying to run another job!
15:06:07 job_callback for (1, 0, 3) finished
15:06:07 start sampling a new configuration.
15:06:07 done sampling a new configuration.
15:06:07 HBMASTER: schedule new run for iteration 1
15:06:07 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
15:06:07 HBMASTER: submitting job (1, 0, 4) to dispatcher
15:06:07 DISPATCHER: trying to submit job (1, 0, 4)
15:06:07 DISPATCHER: trying to notify the job_runner thread.
15:06:07 HBMASTER: job (1, 0, 4) submitted to dispatcher
15:06:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:06:07 DISPATCHER: Trying to submit another job.
15:06:07 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:06:07 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:06:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:06:07 WORKER: start processing job (1, 0, 4)
15:06:07 WORKER: args: ()
15:06:07 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.03114027228882926, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.01651783933465819, 'kernel_size_2': 7, 'num_filters_2': 39}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:06:25 DISPATCHER: Starting worker discovery
15:06:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:06:25 DISPATCHER: Finished worker discovery
15:07:25 DISPATCHER: Starting worker discovery
15:07:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:07:25 DISPATCHER: Finished worker discovery
15:08:25 DISPATCHER: Starting worker discovery
15:08:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:08:25 DISPATCHER: Finished worker discovery
15:08:57 WORKER: done with job (1, 0, 4), trying to register it.
15:08:57 WORKER: registered result for job (1, 0, 4) with dispatcher
15:08:57 DISPATCHER: job (1, 0, 4) finished
15:08:57 DISPATCHER: register_result: lock acquired
15:08:57 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:08:57 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.03114027228882926, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.01651783933465819, 'kernel_size_2': 7, 'num_filters_2': 39}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.006956243826476257, 'info': {'data03': 0.006956243826476257, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.03114027228882926, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.01651783933465819, 'kernel_size_2': 7, 'num_filters_2': 39}"}}
exception: None

15:08:57 job_callback for (1, 0, 4) started
15:08:57 DISPATCHER: Trying to submit another job.
15:08:57 job_callback for (1, 0, 4) got condition
15:08:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:08:57 Only 14 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
15:08:57 HBMASTER: Trying to run another job!
15:08:57 job_callback for (1, 0, 4) finished
15:08:57 start sampling a new configuration.
15:08:57 done sampling a new configuration.
15:08:57 HBMASTER: schedule new run for iteration 1
15:08:57 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
15:08:57 HBMASTER: submitting job (1, 0, 5) to dispatcher
15:08:57 DISPATCHER: trying to submit job (1, 0, 5)
15:08:57 DISPATCHER: trying to notify the job_runner thread.
15:08:57 HBMASTER: job (1, 0, 5) submitted to dispatcher
15:08:57 DISPATCHER: Trying to submit another job.
15:08:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:08:57 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:08:57 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:08:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:08:57 WORKER: start processing job (1, 0, 5)
15:08:57 WORKER: args: ()
15:08:57 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.07001377591962579, 'num_filters_1': 51, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.01667933444266714, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 125, 'num_filters_3': 41, 'num_filters_4': 49, 'num_filters_5': 65}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:09:25 DISPATCHER: Starting worker discovery
15:09:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:09:25 DISPATCHER: Finished worker discovery
15:10:25 DISPATCHER: Starting worker discovery
15:10:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:10:25 DISPATCHER: Finished worker discovery
15:11:25 DISPATCHER: Starting worker discovery
15:11:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:11:25 DISPATCHER: Finished worker discovery
15:11:50 WORKER: done with job (1, 0, 5), trying to register it.
15:11:50 WORKER: registered result for job (1, 0, 5) with dispatcher
15:11:50 DISPATCHER: job (1, 0, 5) finished
15:11:50 DISPATCHER: register_result: lock acquired
15:11:50 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:11:50 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.07001377591962579, 'num_filters_1': 51, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.01667933444266714, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 125, 'num_filters_3': 41, 'num_filters_4': 49, 'num_filters_5': 65}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.07001377591962579, 'num_filters_1': 51, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.01667933444266714, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 125, 'num_filters_3': 41, 'num_filters_4': 49, 'num_filters_5': 65}"}}
exception: None

15:11:50 job_callback for (1, 0, 5) started
15:11:50 DISPATCHER: Trying to submit another job.
15:11:50 job_callback for (1, 0, 5) got condition
15:11:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:11:50 Only 15 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
15:11:50 HBMASTER: Trying to run another job!
15:11:50 job_callback for (1, 0, 5) finished
15:11:50 start sampling a new configuration.
15:11:50 done sampling a new configuration.
15:11:50 HBMASTER: schedule new run for iteration 1
15:11:50 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
15:11:50 HBMASTER: submitting job (1, 0, 6) to dispatcher
15:11:50 DISPATCHER: trying to submit job (1, 0, 6)
15:11:50 DISPATCHER: trying to notify the job_runner thread.
15:11:50 HBMASTER: job (1, 0, 6) submitted to dispatcher
15:11:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:11:50 DISPATCHER: Trying to submit another job.
15:11:50 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:11:50 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:11:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:11:50 WORKER: start processing job (1, 0, 6)
15:11:50 WORKER: args: ()
15:11:50 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.042891421847828036, 'num_filters_1': 28, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.017818602854429502, 'kernel_size_2': 3, 'num_filters_2': 41}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:12:25 DISPATCHER: Starting worker discovery
15:12:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:12:25 DISPATCHER: Finished worker discovery
15:13:25 DISPATCHER: Starting worker discovery
15:13:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:13:25 DISPATCHER: Finished worker discovery
15:14:25 DISPATCHER: Starting worker discovery
15:14:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:14:25 DISPATCHER: Finished worker discovery
15:14:39 WORKER: done with job (1, 0, 6), trying to register it.
15:14:39 WORKER: registered result for job (1, 0, 6) with dispatcher
15:14:39 DISPATCHER: job (1, 0, 6) finished
15:14:39 DISPATCHER: register_result: lock acquired
15:14:39 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:14:39 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.042891421847828036, 'num_filters_1': 28, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.017818602854429502, 'kernel_size_2': 3, 'num_filters_2': 41}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3114091635849952, 'info': {'data03': 0.3114091635849952, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.042891421847828036, 'num_filters_1': 28, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.017818602854429502, 'kernel_size_2': 3, 'num_filters_2': 41}"}}
exception: None

15:14:39 job_callback for (1, 0, 6) started
15:14:39 DISPATCHER: Trying to submit another job.
15:14:39 job_callback for (1, 0, 6) got condition
15:14:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:14:39 Only 16 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
15:14:39 HBMASTER: Trying to run another job!
15:14:39 job_callback for (1, 0, 6) finished
15:14:39 start sampling a new configuration.
15:14:39 done sampling a new configuration.
15:14:39 HBMASTER: schedule new run for iteration 1
15:14:39 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
15:14:39 HBMASTER: submitting job (1, 0, 7) to dispatcher
15:14:39 DISPATCHER: trying to submit job (1, 0, 7)
15:14:39 DISPATCHER: trying to notify the job_runner thread.
15:14:39 HBMASTER: job (1, 0, 7) submitted to dispatcher
15:14:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:14:39 DISPATCHER: Trying to submit another job.
15:14:39 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:14:40 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:14:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:14:40 WORKER: start processing job (1, 0, 7)
15:14:40 WORKER: args: ()
15:14:40 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.018242975399712286, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.15400864998731315}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:15:25 DISPATCHER: Starting worker discovery
15:15:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:15:25 DISPATCHER: Finished worker discovery
15:16:25 DISPATCHER: Starting worker discovery
15:16:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:16:25 DISPATCHER: Finished worker discovery
15:17:25 DISPATCHER: Starting worker discovery
15:17:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:17:25 DISPATCHER: Finished worker discovery
15:17:33 WORKER: done with job (1, 0, 7), trying to register it.
15:17:33 WORKER: registered result for job (1, 0, 7) with dispatcher
15:17:33 DISPATCHER: job (1, 0, 7) finished
15:17:33 DISPATCHER: register_result: lock acquired
15:17:33 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:17:33 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.018242975399712286, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.15400864998731315}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.34991927377289894, 'info': {'data03': 0.34991927377289894, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.018242975399712286, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.15400864998731315}"}}
exception: None

15:17:33 job_callback for (1, 0, 7) started
15:17:33 DISPATCHER: Trying to submit another job.
15:17:33 job_callback for (1, 0, 7) got condition
15:17:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:17:33 HBMASTER: Trying to run another job!
15:17:33 job_callback for (1, 0, 7) finished
15:17:33 start sampling a new configuration.
15:17:33 done sampling a new configuration.
15:17:33 HBMASTER: schedule new run for iteration 1
15:17:33 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
15:17:33 HBMASTER: submitting job (1, 0, 8) to dispatcher
15:17:33 DISPATCHER: trying to submit job (1, 0, 8)
15:17:33 DISPATCHER: trying to notify the job_runner thread.
15:17:33 HBMASTER: job (1, 0, 8) submitted to dispatcher
15:17:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:17:33 DISPATCHER: Trying to submit another job.
15:17:33 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:17:33 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:17:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:17:33 WORKER: start processing job (1, 0, 8)
15:17:33 WORKER: args: ()
15:17:33 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.029022670666296553, 'num_filters_1': 115, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.04192265659673642, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 20, 'num_filters_3': 115, 'num_filters_4': 29}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:18:25 DISPATCHER: Starting worker discovery
15:18:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:18:25 DISPATCHER: Finished worker discovery
15:19:25 DISPATCHER: Starting worker discovery
15:19:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:19:25 DISPATCHER: Finished worker discovery
15:20:25 DISPATCHER: Starting worker discovery
15:20:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:20:25 DISPATCHER: Finished worker discovery
15:20:27 WORKER: done with job (1, 0, 8), trying to register it.
15:20:27 WORKER: registered result for job (1, 0, 8) with dispatcher
15:20:27 DISPATCHER: job (1, 0, 8) finished
15:20:27 DISPATCHER: register_result: lock acquired
15:20:27 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:20:27 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.029022670666296553, 'num_filters_1': 115, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.04192265659673642, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 20, 'num_filters_3': 115, 'num_filters_4': 29}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.029022670666296553, 'num_filters_1': 115, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.04192265659673642, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 20, 'num_filters_3': 115, 'num_filters_4': 29}"}}
exception: None

15:20:27 job_callback for (1, 0, 8) started
15:20:27 DISPATCHER: Trying to submit another job.
15:20:27 job_callback for (1, 0, 8) got condition
15:20:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:20:27 HBMASTER: Trying to run another job!
15:20:27 job_callback for (1, 0, 8) finished
15:20:27 ITERATION: Advancing config (1, 0, 2) to next budget 400.000000
15:20:27 ITERATION: Advancing config (1, 0, 6) to next budget 400.000000
15:20:27 ITERATION: Advancing config (1, 0, 7) to next budget 400.000000
15:20:27 HBMASTER: schedule new run for iteration 1
15:20:27 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
15:20:27 HBMASTER: submitting job (1, 0, 2) to dispatcher
15:20:27 DISPATCHER: trying to submit job (1, 0, 2)
15:20:27 DISPATCHER: trying to notify the job_runner thread.
15:20:27 HBMASTER: job (1, 0, 2) submitted to dispatcher
15:20:27 DISPATCHER: Trying to submit another job.
15:20:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:20:27 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:20:27 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:20:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:20:27 WORKER: start processing job (1, 0, 2)
15:20:27 WORKER: args: ()
15:20:27 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.023461373575956908, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.022938797666054354, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 27, 'num_filters_3': 99, 'num_filters_4': 16, 'num_filters_5': 51}, 'budget': 400.0, 'working_directory': '.'}
15:21:25 DISPATCHER: Starting worker discovery
15:21:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:21:25 DISPATCHER: Finished worker discovery
15:22:25 DISPATCHER: Starting worker discovery
15:22:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:22:25 DISPATCHER: Finished worker discovery
15:23:25 DISPATCHER: Starting worker discovery
15:23:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:23:25 DISPATCHER: Finished worker discovery
15:24:25 DISPATCHER: Starting worker discovery
15:24:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:24:25 DISPATCHER: Finished worker discovery
15:25:25 DISPATCHER: Starting worker discovery
15:25:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:25:25 DISPATCHER: Finished worker discovery
15:26:25 DISPATCHER: Starting worker discovery
15:26:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:26:25 DISPATCHER: Finished worker discovery
15:27:25 DISPATCHER: Starting worker discovery
15:27:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:27:25 DISPATCHER: Finished worker discovery
15:27:46 WORKER: done with job (1, 0, 2), trying to register it.
15:27:46 WORKER: registered result for job (1, 0, 2) with dispatcher
15:27:46 DISPATCHER: job (1, 0, 2) finished
15:27:46 DISPATCHER: register_result: lock acquired
15:27:46 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:27:46 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.023461373575956908, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.022938797666054354, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 27, 'num_filters_3': 99, 'num_filters_4': 16, 'num_filters_5': 51}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3318832988065023, 'info': {'data03': 0.3318832988065023, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.023461373575956908, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.022938797666054354, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 27, 'num_filters_3': 99, 'num_filters_4': 16, 'num_filters_5': 51}"}}
exception: None

15:27:46 job_callback for (1, 0, 2) started
15:27:46 DISPATCHER: Trying to submit another job.
15:27:46 job_callback for (1, 0, 2) got condition
15:27:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:27:46 Only 4 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
15:27:46 HBMASTER: Trying to run another job!
15:27:46 job_callback for (1, 0, 2) finished
15:27:46 HBMASTER: schedule new run for iteration 1
15:27:46 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
15:27:46 HBMASTER: submitting job (1, 0, 6) to dispatcher
15:27:46 DISPATCHER: trying to submit job (1, 0, 6)
15:27:46 DISPATCHER: trying to notify the job_runner thread.
15:27:46 HBMASTER: job (1, 0, 6) submitted to dispatcher
15:27:46 DISPATCHER: Trying to submit another job.
15:27:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:27:46 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:27:46 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:27:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:27:46 WORKER: start processing job (1, 0, 6)
15:27:46 WORKER: args: ()
15:27:46 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.042891421847828036, 'num_filters_1': 28, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.017818602854429502, 'kernel_size_2': 3, 'num_filters_2': 41}, 'budget': 400.0, 'working_directory': '.'}
15:28:25 DISPATCHER: Starting worker discovery
15:28:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:28:25 DISPATCHER: Finished worker discovery
15:29:25 DISPATCHER: Starting worker discovery
15:29:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:29:25 DISPATCHER: Finished worker discovery
15:30:25 DISPATCHER: Starting worker discovery
15:30:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:30:25 DISPATCHER: Finished worker discovery
15:31:25 DISPATCHER: Starting worker discovery
15:31:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:31:25 DISPATCHER: Finished worker discovery
15:32:25 DISPATCHER: Starting worker discovery
15:32:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:32:25 DISPATCHER: Finished worker discovery
15:33:25 DISPATCHER: Starting worker discovery
15:33:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:33:25 DISPATCHER: Finished worker discovery
15:34:25 DISPATCHER: Starting worker discovery
15:34:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:34:25 DISPATCHER: Finished worker discovery
15:35:04 WORKER: done with job (1, 0, 6), trying to register it.
15:35:04 WORKER: registered result for job (1, 0, 6) with dispatcher
15:35:04 DISPATCHER: job (1, 0, 6) finished
15:35:04 DISPATCHER: register_result: lock acquired
15:35:04 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:35:04 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.042891421847828036, 'num_filters_1': 28, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.017818602854429502, 'kernel_size_2': 3, 'num_filters_2': 41}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.318958359968772, 'info': {'data03': 0.318958359968772, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.042891421847828036, 'num_filters_1': 28, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.017818602854429502, 'kernel_size_2': 3, 'num_filters_2': 41}"}}
exception: None

15:35:04 job_callback for (1, 0, 6) started
15:35:04 job_callback for (1, 0, 6) got condition
15:35:04 DISPATCHER: Trying to submit another job.
15:35:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:35:04 Only 5 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
15:35:04 HBMASTER: Trying to run another job!
15:35:04 job_callback for (1, 0, 6) finished
15:35:04 HBMASTER: schedule new run for iteration 1
15:35:04 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
15:35:04 HBMASTER: submitting job (1, 0, 7) to dispatcher
15:35:04 DISPATCHER: trying to submit job (1, 0, 7)
15:35:04 DISPATCHER: trying to notify the job_runner thread.
15:35:04 HBMASTER: job (1, 0, 7) submitted to dispatcher
15:35:04 DISPATCHER: Trying to submit another job.
15:35:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:35:04 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:35:04 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:35:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:35:04 WORKER: start processing job (1, 0, 7)
15:35:04 WORKER: args: ()
15:35:04 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.018242975399712286, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.15400864998731315}, 'budget': 400.0, 'working_directory': '.'}
15:35:25 DISPATCHER: Starting worker discovery
15:35:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:35:25 DISPATCHER: Finished worker discovery
15:36:25 DISPATCHER: Starting worker discovery
15:36:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:36:25 DISPATCHER: Finished worker discovery
15:37:25 DISPATCHER: Starting worker discovery
15:37:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:37:25 DISPATCHER: Finished worker discovery
15:38:25 DISPATCHER: Starting worker discovery
15:38:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:38:25 DISPATCHER: Finished worker discovery
15:39:25 DISPATCHER: Starting worker discovery
15:39:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:39:25 DISPATCHER: Finished worker discovery
15:40:25 DISPATCHER: Starting worker discovery
15:40:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:40:26 DISPATCHER: Finished worker discovery
15:41:26 DISPATCHER: Starting worker discovery
15:41:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:41:26 DISPATCHER: Finished worker discovery
15:42:23 WORKER: done with job (1, 0, 7), trying to register it.
15:42:23 WORKER: registered result for job (1, 0, 7) with dispatcher
15:42:23 DISPATCHER: job (1, 0, 7) finished
15:42:23 DISPATCHER: register_result: lock acquired
15:42:23 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:42:23 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.018242975399712286, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.15400864998731315}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3433646917605948, 'info': {'data03': 0.3433646917605948, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.018242975399712286, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.15400864998731315}"}}
exception: None

15:42:23 job_callback for (1, 0, 7) started
15:42:23 job_callback for (1, 0, 7) got condition
15:42:23 DISPATCHER: Trying to submit another job.
15:42:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:42:23 Only 6 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
15:42:23 HBMASTER: Trying to run another job!
15:42:23 job_callback for (1, 0, 7) finished
15:42:23 ITERATION: Advancing config (1, 0, 7) to next budget 1200.000000
15:42:23 HBMASTER: schedule new run for iteration 1
15:42:23 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
15:42:23 HBMASTER: submitting job (1, 0, 7) to dispatcher
15:42:23 DISPATCHER: trying to submit job (1, 0, 7)
15:42:23 DISPATCHER: trying to notify the job_runner thread.
15:42:23 HBMASTER: job (1, 0, 7) submitted to dispatcher
15:42:23 DISPATCHER: Trying to submit another job.
15:42:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:42:23 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:42:23 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:42:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:42:23 WORKER: start processing job (1, 0, 7)
15:42:23 WORKER: args: ()
15:42:23 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.018242975399712286, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.15400864998731315}, 'budget': 1200.0, 'working_directory': '.'}
15:42:26 DISPATCHER: Starting worker discovery
15:42:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:42:26 DISPATCHER: Finished worker discovery
15:43:26 DISPATCHER: Starting worker discovery
15:43:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:43:26 DISPATCHER: Finished worker discovery
15:44:26 DISPATCHER: Starting worker discovery
15:44:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:44:26 DISPATCHER: Finished worker discovery
15:45:26 DISPATCHER: Starting worker discovery
15:45:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:45:26 DISPATCHER: Finished worker discovery
15:46:26 DISPATCHER: Starting worker discovery
15:46:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:46:26 DISPATCHER: Finished worker discovery
15:47:26 DISPATCHER: Starting worker discovery
15:47:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:47:26 DISPATCHER: Finished worker discovery
15:48:26 DISPATCHER: Starting worker discovery
15:48:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:48:26 DISPATCHER: Finished worker discovery
15:49:26 DISPATCHER: Starting worker discovery
15:49:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:49:26 DISPATCHER: Finished worker discovery
15:50:26 DISPATCHER: Starting worker discovery
15:50:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:50:26 DISPATCHER: Finished worker discovery
15:51:26 DISPATCHER: Starting worker discovery
15:51:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:51:26 DISPATCHER: Finished worker discovery
15:52:26 DISPATCHER: Starting worker discovery
15:52:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:52:26 DISPATCHER: Finished worker discovery
15:53:26 DISPATCHER: Starting worker discovery
15:53:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:53:26 DISPATCHER: Finished worker discovery
15:54:26 DISPATCHER: Starting worker discovery
15:54:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:54:26 DISPATCHER: Finished worker discovery
15:55:26 DISPATCHER: Starting worker discovery
15:55:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:55:26 DISPATCHER: Finished worker discovery
15:56:26 DISPATCHER: Starting worker discovery
15:56:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:56:26 DISPATCHER: Finished worker discovery
15:57:26 DISPATCHER: Starting worker discovery
15:57:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:57:26 DISPATCHER: Finished worker discovery
15:58:26 DISPATCHER: Starting worker discovery
15:58:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:58:26 DISPATCHER: Finished worker discovery
15:59:26 DISPATCHER: Starting worker discovery
15:59:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:59:26 DISPATCHER: Finished worker discovery
16:00:26 DISPATCHER: Starting worker discovery
16:00:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:00:26 DISPATCHER: Finished worker discovery
16:01:26 DISPATCHER: Starting worker discovery
16:01:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:01:26 DISPATCHER: Finished worker discovery
16:02:26 DISPATCHER: Starting worker discovery
16:02:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:02:26 DISPATCHER: Finished worker discovery
16:03:11 WORKER: done with job (1, 0, 7), trying to register it.
16:03:11 WORKER: registered result for job (1, 0, 7) with dispatcher
16:03:11 DISPATCHER: job (1, 0, 7) finished
16:03:11 DISPATCHER: register_result: lock acquired
16:03:11 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
16:03:11 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.018242975399712286, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.15400864998731315}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.33941004328661695, 'info': {'data03': 0.33941004328661695, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.018242975399712286, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.15400864998731315}"}}
exception: None

16:03:11 job_callback for (1, 0, 7) started
16:03:11 job_callback for (1, 0, 7) got condition
16:03:11 DISPATCHER: Trying to submit another job.
16:03:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:03:11 Only 2 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
16:03:11 HBMASTER: Trying to run another job!
16:03:11 job_callback for (1, 0, 7) finished
16:03:11 start sampling a new configuration.
16:03:11 done sampling a new configuration.
16:03:11 HBMASTER: schedule new run for iteration 2
16:03:11 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
16:03:11 HBMASTER: submitting job (2, 0, 0) to dispatcher
16:03:11 DISPATCHER: trying to submit job (2, 0, 0)
16:03:11 DISPATCHER: trying to notify the job_runner thread.
16:03:11 HBMASTER: job (2, 0, 0) submitted to dispatcher
16:03:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:03:11 DISPATCHER: Trying to submit another job.
16:03:11 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
16:03:11 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
16:03:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:03:11 WORKER: start processing job (2, 0, 0)
16:03:11 WORKER: args: ()
16:03:11 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001728727487441666, 'num_filters_1': 53, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.014408781415555209, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 87, 'num_filters_3': 39, 'num_filters_4': 74}, 'budget': 400.0, 'working_directory': '.'}
16:03:26 DISPATCHER: Starting worker discovery
16:03:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:03:26 DISPATCHER: Finished worker discovery
16:04:26 DISPATCHER: Starting worker discovery
16:04:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:04:26 DISPATCHER: Finished worker discovery
16:05:26 DISPATCHER: Starting worker discovery
16:05:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:05:26 DISPATCHER: Finished worker discovery
16:06:26 DISPATCHER: Starting worker discovery
16:06:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:06:26 DISPATCHER: Finished worker discovery
16:07:26 DISPATCHER: Starting worker discovery
16:07:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:07:26 DISPATCHER: Finished worker discovery
16:08:26 DISPATCHER: Starting worker discovery
16:08:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:08:26 DISPATCHER: Finished worker discovery
16:09:26 DISPATCHER: Starting worker discovery
16:09:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:09:26 DISPATCHER: Finished worker discovery
16:10:26 DISPATCHER: Starting worker discovery
16:10:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:10:26 DISPATCHER: Finished worker discovery
16:10:27 WORKER: done with job (2, 0, 0), trying to register it.
16:10:27 WORKER: registered result for job (2, 0, 0) with dispatcher
16:10:27 DISPATCHER: job (2, 0, 0) finished
16:10:27 DISPATCHER: register_result: lock acquired
16:10:27 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
16:10:27 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001728727487441666, 'num_filters_1': 53, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.014408781415555209, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 87, 'num_filters_3': 39, 'num_filters_4': 74}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.38336411237844686, 'info': {'data03': 0.38336411237844686, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001728727487441666, 'num_filters_1': 53, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.014408781415555209, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 87, 'num_filters_3': 39, 'num_filters_4': 74}"}}
exception: None

16:10:27 job_callback for (2, 0, 0) started
16:10:27 job_callback for (2, 0, 0) got condition
16:10:27 DISPATCHER: Trying to submit another job.
16:10:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:10:27 Only 7 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
16:10:27 HBMASTER: Trying to run another job!
16:10:27 job_callback for (2, 0, 0) finished
16:10:27 start sampling a new configuration.
16:10:27 done sampling a new configuration.
16:10:27 HBMASTER: schedule new run for iteration 2
16:10:27 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
16:10:27 HBMASTER: submitting job (2, 0, 1) to dispatcher
16:10:27 DISPATCHER: trying to submit job (2, 0, 1)
16:10:27 DISPATCHER: trying to notify the job_runner thread.
16:10:27 HBMASTER: job (2, 0, 1) submitted to dispatcher
16:10:27 DISPATCHER: Trying to submit another job.
16:10:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:10:27 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
16:10:27 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
16:10:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:10:27 WORKER: start processing job (2, 0, 1)
16:10:27 WORKER: args: ()
16:10:27 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.05440359744767401, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.028550745535796306, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 21, 'num_filters_3': 56, 'num_filters_4': 20, 'num_filters_5': 32}, 'budget': 400.0, 'working_directory': '.'}
16:11:26 DISPATCHER: Starting worker discovery
16:11:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:11:26 DISPATCHER: Finished worker discovery
16:12:26 DISPATCHER: Starting worker discovery
16:12:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:12:26 DISPATCHER: Finished worker discovery
16:13:26 DISPATCHER: Starting worker discovery
16:13:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:13:26 DISPATCHER: Finished worker discovery
16:14:26 DISPATCHER: Starting worker discovery
16:14:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:14:26 DISPATCHER: Finished worker discovery
16:15:26 DISPATCHER: Starting worker discovery
16:15:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:15:26 DISPATCHER: Finished worker discovery
16:16:26 DISPATCHER: Starting worker discovery
16:16:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:16:26 DISPATCHER: Finished worker discovery
16:17:26 DISPATCHER: Starting worker discovery
16:17:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:17:26 DISPATCHER: Finished worker discovery
16:17:45 WORKER: done with job (2, 0, 1), trying to register it.
16:17:45 WORKER: registered result for job (2, 0, 1) with dispatcher
16:17:45 DISPATCHER: job (2, 0, 1) finished
16:17:45 DISPATCHER: register_result: lock acquired
16:17:45 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
16:17:45 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.05440359744767401, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.028550745535796306, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 21, 'num_filters_3': 56, 'num_filters_4': 20, 'num_filters_5': 32}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.05440359744767401, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.028550745535796306, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 21, 'num_filters_3': 56, 'num_filters_4': 20, 'num_filters_5': 32}"}}
exception: None

16:17:45 job_callback for (2, 0, 1) started
16:17:45 job_callback for (2, 0, 1) got condition
16:17:45 DISPATCHER: Trying to submit another job.
16:17:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:17:45 Only 8 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
16:17:45 HBMASTER: Trying to run another job!
16:17:45 job_callback for (2, 0, 1) finished
16:17:45 start sampling a new configuration.
16:17:45 done sampling a new configuration.
16:17:45 HBMASTER: schedule new run for iteration 2
16:17:45 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
16:17:45 HBMASTER: submitting job (2, 0, 2) to dispatcher
16:17:45 DISPATCHER: trying to submit job (2, 0, 2)
16:17:45 DISPATCHER: trying to notify the job_runner thread.
16:17:45 HBMASTER: job (2, 0, 2) submitted to dispatcher
16:17:45 DISPATCHER: Trying to submit another job.
16:17:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:17:45 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
16:17:45 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
16:17:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:17:45 WORKER: start processing job (2, 0, 2)
16:17:45 WORKER: args: ()
16:17:45 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.018134979308275987, 'num_filters_1': 52, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.19327482374574936, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 59, 'num_filters_3': 37, 'num_filters_4': 31}, 'budget': 400.0, 'working_directory': '.'}
16:18:26 DISPATCHER: Starting worker discovery
16:18:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:18:26 DISPATCHER: Finished worker discovery
16:19:26 DISPATCHER: Starting worker discovery
16:19:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:19:26 DISPATCHER: Finished worker discovery
16:20:26 DISPATCHER: Starting worker discovery
16:20:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:20:26 DISPATCHER: Finished worker discovery
16:21:26 DISPATCHER: Starting worker discovery
16:21:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:21:26 DISPATCHER: Finished worker discovery
16:22:26 DISPATCHER: Starting worker discovery
16:22:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:22:26 DISPATCHER: Finished worker discovery
16:23:26 DISPATCHER: Starting worker discovery
16:23:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:23:26 DISPATCHER: Finished worker discovery
16:24:26 DISPATCHER: Starting worker discovery
16:24:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:24:26 DISPATCHER: Finished worker discovery
16:25:03 WORKER: done with job (2, 0, 2), trying to register it.
16:25:03 WORKER: registered result for job (2, 0, 2) with dispatcher
16:25:03 DISPATCHER: job (2, 0, 2) finished
16:25:03 DISPATCHER: register_result: lock acquired
16:25:03 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
16:25:03 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.018134979308275987, 'num_filters_1': 52, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.19327482374574936, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 59, 'num_filters_3': 37, 'num_filters_4': 31}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.018134979308275987, 'num_filters_1': 52, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.19327482374574936, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 59, 'num_filters_3': 37, 'num_filters_4': 31}"}}
exception: None

16:25:03 job_callback for (2, 0, 2) started
16:25:03 job_callback for (2, 0, 2) got condition
16:25:03 DISPATCHER: Trying to submit another job.
16:25:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:25:03 Only 9 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
16:25:03 HBMASTER: Trying to run another job!
16:25:03 job_callback for (2, 0, 2) finished
16:25:03 start sampling a new configuration.
16:25:03 done sampling a new configuration.
16:25:03 HBMASTER: schedule new run for iteration 2
16:25:03 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
16:25:03 HBMASTER: submitting job (2, 0, 3) to dispatcher
16:25:03 DISPATCHER: trying to submit job (2, 0, 3)
16:25:03 DISPATCHER: trying to notify the job_runner thread.
16:25:03 HBMASTER: job (2, 0, 3) submitted to dispatcher
16:25:03 DISPATCHER: Trying to submit another job.
16:25:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:25:03 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
16:25:03 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
16:25:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:25:03 WORKER: start processing job (2, 0, 3)
16:25:03 WORKER: args: ()
16:25:03 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0016153694018003492, 'num_filters_1': 71, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.019575680695322253, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 25, 'num_filters_3': 16}, 'budget': 400.0, 'working_directory': '.'}
16:25:26 DISPATCHER: Starting worker discovery
16:25:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:25:26 DISPATCHER: Finished worker discovery
16:26:26 DISPATCHER: Starting worker discovery
16:26:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:26:26 DISPATCHER: Finished worker discovery
16:27:26 DISPATCHER: Starting worker discovery
16:27:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:27:26 DISPATCHER: Finished worker discovery
16:28:26 DISPATCHER: Starting worker discovery
16:28:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:28:26 DISPATCHER: Finished worker discovery
16:29:26 DISPATCHER: Starting worker discovery
16:29:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:29:26 DISPATCHER: Finished worker discovery
16:30:26 DISPATCHER: Starting worker discovery
16:30:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:30:26 DISPATCHER: Finished worker discovery
16:31:26 DISPATCHER: Starting worker discovery
16:31:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:31:26 DISPATCHER: Finished worker discovery
16:32:24 WORKER: done with job (2, 0, 3), trying to register it.
16:32:24 WORKER: registered result for job (2, 0, 3) with dispatcher
16:32:24 DISPATCHER: job (2, 0, 3) finished
16:32:24 DISPATCHER: register_result: lock acquired
16:32:24 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
16:32:24 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0016153694018003492, 'num_filters_1': 71, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.019575680695322253, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 25, 'num_filters_3': 16}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4038238718400887, 'info': {'data03': 0.4038238718400887, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0016153694018003492, 'num_filters_1': 71, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.019575680695322253, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 25, 'num_filters_3': 16}"}}
exception: None

16:32:24 job_callback for (2, 0, 3) started
16:32:24 job_callback for (2, 0, 3) got condition
16:32:24 DISPATCHER: Trying to submit another job.
16:32:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:32:24 Only 10 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
16:32:24 HBMASTER: Trying to run another job!
16:32:24 job_callback for (2, 0, 3) finished
16:32:24 start sampling a new configuration.
16:32:24 done sampling a new configuration.
16:32:24 HBMASTER: schedule new run for iteration 2
16:32:24 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
16:32:24 HBMASTER: submitting job (2, 0, 4) to dispatcher
16:32:24 DISPATCHER: trying to submit job (2, 0, 4)
16:32:24 DISPATCHER: trying to notify the job_runner thread.
16:32:24 HBMASTER: job (2, 0, 4) submitted to dispatcher
16:32:24 DISPATCHER: Trying to submit another job.
16:32:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:32:24 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
16:32:24 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
16:32:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:32:24 WORKER: start processing job (2, 0, 4)
16:32:24 WORKER: args: ()
16:32:24 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.002681563469045763, 'num_filters_1': 38, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.19016667288500666, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 54, 'num_filters_3': 56, 'num_filters_4': 66, 'num_filters_5': 30}, 'budget': 400.0, 'working_directory': '.'}
16:32:26 DISPATCHER: Starting worker discovery
16:32:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:32:26 DISPATCHER: Finished worker discovery
16:33:26 DISPATCHER: Starting worker discovery
16:33:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:33:26 DISPATCHER: Finished worker discovery
16:34:26 DISPATCHER: Starting worker discovery
16:34:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:34:26 DISPATCHER: Finished worker discovery
16:35:26 DISPATCHER: Starting worker discovery
16:35:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:35:26 DISPATCHER: Finished worker discovery
16:36:26 DISPATCHER: Starting worker discovery
16:36:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:36:26 DISPATCHER: Finished worker discovery
16:37:26 DISPATCHER: Starting worker discovery
16:37:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:37:26 DISPATCHER: Finished worker discovery
16:38:26 DISPATCHER: Starting worker discovery
16:38:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:38:26 DISPATCHER: Finished worker discovery
16:39:26 DISPATCHER: Starting worker discovery
16:39:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:39:26 DISPATCHER: Finished worker discovery
16:39:46 WORKER: done with job (2, 0, 4), trying to register it.
16:39:46 WORKER: registered result for job (2, 0, 4) with dispatcher
16:39:46 DISPATCHER: job (2, 0, 4) finished
16:39:46 DISPATCHER: register_result: lock acquired
16:39:46 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
16:39:46 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.002681563469045763, 'num_filters_1': 38, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.19016667288500666, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 54, 'num_filters_3': 56, 'num_filters_4': 66, 'num_filters_5': 30}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.27269722774407945, 'info': {'data03': 0.27269722774407945, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.002681563469045763, 'num_filters_1': 38, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.19016667288500666, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 54, 'num_filters_3': 56, 'num_filters_4': 66, 'num_filters_5': 30}"}}
exception: None

16:39:46 job_callback for (2, 0, 4) started
16:39:46 job_callback for (2, 0, 4) got condition
16:39:46 DISPATCHER: Trying to submit another job.
16:39:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:39:46 Only 11 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
16:39:46 HBMASTER: Trying to run another job!
16:39:46 job_callback for (2, 0, 4) finished
16:39:46 start sampling a new configuration.
16:39:46 done sampling a new configuration.
16:39:46 HBMASTER: schedule new run for iteration 2
16:39:46 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
16:39:46 HBMASTER: submitting job (2, 0, 5) to dispatcher
16:39:46 DISPATCHER: trying to submit job (2, 0, 5)
16:39:46 DISPATCHER: trying to notify the job_runner thread.
16:39:46 HBMASTER: job (2, 0, 5) submitted to dispatcher
16:39:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:39:46 DISPATCHER: Trying to submit another job.
16:39:46 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
16:39:46 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
16:39:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:39:46 WORKER: start processing job (2, 0, 5)
16:39:46 WORKER: args: ()
16:39:46 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.019474674283533798, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.03097264263978402, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 109, 'num_filters_3': 17}, 'budget': 400.0, 'working_directory': '.'}
16:40:26 DISPATCHER: Starting worker discovery
16:40:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:40:26 DISPATCHER: Finished worker discovery
16:41:26 DISPATCHER: Starting worker discovery
16:41:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:41:26 DISPATCHER: Finished worker discovery
16:42:26 DISPATCHER: Starting worker discovery
16:42:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:42:26 DISPATCHER: Finished worker discovery
16:43:26 DISPATCHER: Starting worker discovery
16:43:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:43:26 DISPATCHER: Finished worker discovery
16:44:26 DISPATCHER: Starting worker discovery
16:44:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:44:26 DISPATCHER: Finished worker discovery
16:45:26 DISPATCHER: Starting worker discovery
16:45:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:45:26 DISPATCHER: Finished worker discovery
16:46:26 DISPATCHER: Starting worker discovery
16:46:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:46:26 DISPATCHER: Finished worker discovery
16:47:06 WORKER: done with job (2, 0, 5), trying to register it.
16:47:06 WORKER: registered result for job (2, 0, 5) with dispatcher
16:47:06 DISPATCHER: job (2, 0, 5) finished
16:47:06 DISPATCHER: register_result: lock acquired
16:47:06 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
16:47:06 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.019474674283533798, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.03097264263978402, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 109, 'num_filters_3': 17}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3008912276560081, 'info': {'data03': 0.3008912276560081, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.019474674283533798, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.03097264263978402, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 109, 'num_filters_3': 17}"}}
exception: None

16:47:06 job_callback for (2, 0, 5) started
16:47:06 DISPATCHER: Trying to submit another job.
16:47:06 job_callback for (2, 0, 5) got condition
16:47:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:47:06 Only 12 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
16:47:06 HBMASTER: Trying to run another job!
16:47:06 job_callback for (2, 0, 5) finished
16:47:06 ITERATION: Advancing config (2, 0, 0) to next budget 1200.000000
16:47:06 ITERATION: Advancing config (2, 0, 3) to next budget 1200.000000
16:47:06 HBMASTER: schedule new run for iteration 2
16:47:06 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
16:47:06 HBMASTER: submitting job (2, 0, 0) to dispatcher
16:47:06 DISPATCHER: trying to submit job (2, 0, 0)
16:47:06 DISPATCHER: trying to notify the job_runner thread.
16:47:06 HBMASTER: job (2, 0, 0) submitted to dispatcher
16:47:06 DISPATCHER: Trying to submit another job.
16:47:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:47:06 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
16:47:06 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
16:47:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:47:06 WORKER: start processing job (2, 0, 0)
16:47:06 WORKER: args: ()
16:47:06 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001728727487441666, 'num_filters_1': 53, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.014408781415555209, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 87, 'num_filters_3': 39, 'num_filters_4': 74}, 'budget': 1200.0, 'working_directory': '.'}
16:47:26 DISPATCHER: Starting worker discovery
16:47:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:47:26 DISPATCHER: Finished worker discovery
16:48:26 DISPATCHER: Starting worker discovery
16:48:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:48:26 DISPATCHER: Finished worker discovery
16:49:26 DISPATCHER: Starting worker discovery
16:49:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:49:26 DISPATCHER: Finished worker discovery
16:50:26 DISPATCHER: Starting worker discovery
16:50:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:50:26 DISPATCHER: Finished worker discovery
16:51:26 DISPATCHER: Starting worker discovery
16:51:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:51:26 DISPATCHER: Finished worker discovery
16:52:26 DISPATCHER: Starting worker discovery
16:52:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:52:26 DISPATCHER: Finished worker discovery
16:53:26 DISPATCHER: Starting worker discovery
16:53:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:53:26 DISPATCHER: Finished worker discovery
16:54:26 DISPATCHER: Starting worker discovery
16:54:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:54:26 DISPATCHER: Finished worker discovery
16:55:26 DISPATCHER: Starting worker discovery
16:55:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:55:26 DISPATCHER: Finished worker discovery
16:56:26 DISPATCHER: Starting worker discovery
16:56:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:56:26 DISPATCHER: Finished worker discovery
16:57:26 DISPATCHER: Starting worker discovery
16:57:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:57:26 DISPATCHER: Finished worker discovery
16:58:26 DISPATCHER: Starting worker discovery
16:58:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:58:26 DISPATCHER: Finished worker discovery
16:59:26 DISPATCHER: Starting worker discovery
16:59:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:59:26 DISPATCHER: Finished worker discovery
17:00:26 DISPATCHER: Starting worker discovery
17:00:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:00:26 DISPATCHER: Finished worker discovery
17:01:26 DISPATCHER: Starting worker discovery
17:01:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:01:26 DISPATCHER: Finished worker discovery
17:02:26 DISPATCHER: Starting worker discovery
17:02:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:02:26 DISPATCHER: Finished worker discovery
17:03:26 DISPATCHER: Starting worker discovery
17:03:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:03:26 DISPATCHER: Finished worker discovery
17:04:26 DISPATCHER: Starting worker discovery
17:04:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:04:26 DISPATCHER: Finished worker discovery
17:05:26 DISPATCHER: Starting worker discovery
17:05:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:05:26 DISPATCHER: Finished worker discovery
17:06:26 DISPATCHER: Starting worker discovery
17:06:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:06:26 DISPATCHER: Finished worker discovery
17:07:26 DISPATCHER: Starting worker discovery
17:07:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:07:26 DISPATCHER: Finished worker discovery
17:07:46 WORKER: done with job (2, 0, 0), trying to register it.
17:07:46 WORKER: registered result for job (2, 0, 0) with dispatcher
17:07:46 DISPATCHER: job (2, 0, 0) finished
17:07:46 DISPATCHER: register_result: lock acquired
17:07:46 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
17:07:46 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001728727487441666, 'num_filters_1': 53, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.014408781415555209, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 87, 'num_filters_3': 39, 'num_filters_4': 74}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.3543051495358823, 'info': {'data03': 0.3543051495358823, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001728727487441666, 'num_filters_1': 53, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.014408781415555209, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 87, 'num_filters_3': 39, 'num_filters_4': 74}"}}
exception: None

17:07:46 job_callback for (2, 0, 0) started
17:07:46 DISPATCHER: Trying to submit another job.
17:07:46 job_callback for (2, 0, 0) got condition
17:07:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:07:46 Only 3 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
17:07:46 HBMASTER: Trying to run another job!
17:07:46 job_callback for (2, 0, 0) finished
17:07:46 HBMASTER: schedule new run for iteration 2
17:07:46 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
17:07:46 HBMASTER: submitting job (2, 0, 3) to dispatcher
17:07:46 DISPATCHER: trying to submit job (2, 0, 3)
17:07:46 DISPATCHER: trying to notify the job_runner thread.
17:07:46 HBMASTER: job (2, 0, 3) submitted to dispatcher
17:07:46 DISPATCHER: Trying to submit another job.
17:07:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:07:46 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
17:07:46 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
17:07:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:07:46 WORKER: start processing job (2, 0, 3)
17:07:46 WORKER: args: ()
17:07:46 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0016153694018003492, 'num_filters_1': 71, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.019575680695322253, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 25, 'num_filters_3': 16}, 'budget': 1200.0, 'working_directory': '.'}
17:08:26 DISPATCHER: Starting worker discovery
17:08:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:08:26 DISPATCHER: Finished worker discovery
17:09:26 DISPATCHER: Starting worker discovery
17:09:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:09:26 DISPATCHER: Finished worker discovery
17:10:26 DISPATCHER: Starting worker discovery
17:10:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:10:26 DISPATCHER: Finished worker discovery
17:11:26 DISPATCHER: Starting worker discovery
17:11:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:11:26 DISPATCHER: Finished worker discovery
17:12:26 DISPATCHER: Starting worker discovery
17:12:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:12:26 DISPATCHER: Finished worker discovery
17:13:26 DISPATCHER: Starting worker discovery
17:13:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:13:26 DISPATCHER: Finished worker discovery
17:14:26 DISPATCHER: Starting worker discovery
17:14:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:14:26 DISPATCHER: Finished worker discovery
17:15:26 DISPATCHER: Starting worker discovery
17:15:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:15:26 DISPATCHER: Finished worker discovery
17:16:26 DISPATCHER: Starting worker discovery
17:16:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:16:26 DISPATCHER: Finished worker discovery
17:17:26 DISPATCHER: Starting worker discovery
17:17:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:17:26 DISPATCHER: Finished worker discovery
17:18:26 DISPATCHER: Starting worker discovery
17:18:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:18:26 DISPATCHER: Finished worker discovery
17:19:26 DISPATCHER: Starting worker discovery
17:19:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:19:26 DISPATCHER: Finished worker discovery
17:20:26 DISPATCHER: Starting worker discovery
17:20:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:20:26 DISPATCHER: Finished worker discovery
17:21:26 DISPATCHER: Starting worker discovery
17:21:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:21:26 DISPATCHER: Finished worker discovery
17:22:26 DISPATCHER: Starting worker discovery
17:22:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:22:26 DISPATCHER: Finished worker discovery
17:23:26 DISPATCHER: Starting worker discovery
17:23:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:23:26 DISPATCHER: Finished worker discovery
17:24:26 DISPATCHER: Starting worker discovery
17:24:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:24:26 DISPATCHER: Finished worker discovery
17:25:26 DISPATCHER: Starting worker discovery
17:25:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:25:26 DISPATCHER: Finished worker discovery
17:26:26 DISPATCHER: Starting worker discovery
17:26:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:26:26 DISPATCHER: Finished worker discovery
17:27:26 DISPATCHER: Starting worker discovery
17:27:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:27:26 DISPATCHER: Finished worker discovery
17:28:24 WORKER: done with job (2, 0, 3), trying to register it.
17:28:24 WORKER: registered result for job (2, 0, 3) with dispatcher
17:28:24 DISPATCHER: job (2, 0, 3) finished
17:28:24 DISPATCHER: register_result: lock acquired
17:28:24 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
17:28:24 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0016153694018003492, 'num_filters_1': 71, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.019575680695322253, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 25, 'num_filters_3': 16}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.31744590364164854, 'info': {'data03': 0.31744590364164854, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0016153694018003492, 'num_filters_1': 71, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.019575680695322253, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 25, 'num_filters_3': 16}"}}
exception: None

17:28:24 job_callback for (2, 0, 3) started
17:28:24 DISPATCHER: Trying to submit another job.
17:28:24 job_callback for (2, 0, 3) got condition
17:28:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:28:24 Only 4 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
17:28:24 HBMASTER: Trying to run another job!
17:28:24 job_callback for (2, 0, 3) finished
17:28:24 start sampling a new configuration.
17:28:24 done sampling a new configuration.
17:28:24 HBMASTER: schedule new run for iteration 3
17:28:24 HBMASTER: trying submitting job (3, 0, 0) to dispatcher
17:28:24 HBMASTER: submitting job (3, 0, 0) to dispatcher
17:28:24 DISPATCHER: trying to submit job (3, 0, 0)
17:28:24 DISPATCHER: trying to notify the job_runner thread.
17:28:24 HBMASTER: job (3, 0, 0) submitted to dispatcher
17:28:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:28:24 DISPATCHER: Trying to submit another job.
17:28:24 DISPATCHER: starting job (3, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
17:28:24 DISPATCHER: job (3, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
17:28:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:28:24 WORKER: start processing job (3, 0, 0)
17:28:24 WORKER: args: ()
17:28:24 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0064988069651270046, 'num_filters_1': 21, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.0166035077143704, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 39, 'num_filters_3': 26, 'num_filters_4': 117}, 'budget': 1200.0, 'working_directory': '.'}
17:28:26 DISPATCHER: Starting worker discovery
17:28:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:28:26 DISPATCHER: Finished worker discovery
17:29:26 DISPATCHER: Starting worker discovery
17:29:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:29:26 DISPATCHER: Finished worker discovery
17:30:26 DISPATCHER: Starting worker discovery
17:30:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:30:26 DISPATCHER: Finished worker discovery
17:31:26 DISPATCHER: Starting worker discovery
17:31:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:31:26 DISPATCHER: Finished worker discovery
17:32:26 DISPATCHER: Starting worker discovery
17:32:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:32:26 DISPATCHER: Finished worker discovery
17:33:26 DISPATCHER: Starting worker discovery
17:33:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:33:26 DISPATCHER: Finished worker discovery
17:34:26 DISPATCHER: Starting worker discovery
17:34:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:34:26 DISPATCHER: Finished worker discovery
17:35:26 DISPATCHER: Starting worker discovery
17:35:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:35:26 DISPATCHER: Finished worker discovery
17:36:26 DISPATCHER: Starting worker discovery
17:36:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:36:26 DISPATCHER: Finished worker discovery
17:37:26 DISPATCHER: Starting worker discovery
17:37:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:37:26 DISPATCHER: Finished worker discovery
17:38:26 DISPATCHER: Starting worker discovery
17:38:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:38:26 DISPATCHER: Finished worker discovery
17:39:26 DISPATCHER: Starting worker discovery
17:39:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:39:26 DISPATCHER: Finished worker discovery
17:40:26 DISPATCHER: Starting worker discovery
17:40:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:40:26 DISPATCHER: Finished worker discovery
17:41:26 DISPATCHER: Starting worker discovery
17:41:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:41:26 DISPATCHER: Finished worker discovery
17:42:26 DISPATCHER: Starting worker discovery
17:42:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:42:26 DISPATCHER: Finished worker discovery
17:43:26 DISPATCHER: Starting worker discovery
17:43:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:43:26 DISPATCHER: Finished worker discovery
17:44:26 DISPATCHER: Starting worker discovery
17:44:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:44:26 DISPATCHER: Finished worker discovery
17:45:26 DISPATCHER: Starting worker discovery
17:45:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:45:26 DISPATCHER: Finished worker discovery
17:46:26 DISPATCHER: Starting worker discovery
17:46:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:46:26 DISPATCHER: Finished worker discovery
17:47:26 DISPATCHER: Starting worker discovery
17:47:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:47:26 DISPATCHER: Finished worker discovery
17:48:26 DISPATCHER: Starting worker discovery
17:48:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:48:26 DISPATCHER: Finished worker discovery
17:49:06 WORKER: done with job (3, 0, 0), trying to register it.
17:49:06 WORKER: registered result for job (3, 0, 0) with dispatcher
17:49:06 DISPATCHER: job (3, 0, 0) finished
17:49:06 DISPATCHER: register_result: lock acquired
17:49:06 DISPATCHER: job (3, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
17:49:06 job_id: (3, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0064988069651270046, 'num_filters_1': 21, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.0166035077143704, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 39, 'num_filters_3': 26, 'num_filters_4': 117}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.3192861800062189, 'info': {'data03': 0.3192861800062189, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0064988069651270046, 'num_filters_1': 21, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.0166035077143704, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 39, 'num_filters_3': 26, 'num_filters_4': 117}"}}
exception: None

17:49:06 job_callback for (3, 0, 0) started
17:49:06 DISPATCHER: Trying to submit another job.
17:49:06 job_callback for (3, 0, 0) got condition
17:49:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:49:06 Only 5 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
17:49:06 HBMASTER: Trying to run another job!
17:49:06 job_callback for (3, 0, 0) finished
17:49:06 start sampling a new configuration.
17:49:06 done sampling a new configuration.
17:49:06 HBMASTER: schedule new run for iteration 3
17:49:06 HBMASTER: trying submitting job (3, 0, 1) to dispatcher
17:49:06 HBMASTER: submitting job (3, 0, 1) to dispatcher
17:49:06 DISPATCHER: trying to submit job (3, 0, 1)
17:49:06 DISPATCHER: trying to notify the job_runner thread.
17:49:06 HBMASTER: job (3, 0, 1) submitted to dispatcher
17:49:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:49:06 DISPATCHER: Trying to submit another job.
17:49:06 DISPATCHER: starting job (3, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
17:49:06 DISPATCHER: job (3, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
17:49:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:49:06 WORKER: start processing job (3, 0, 1)
17:49:06 WORKER: args: ()
17:49:06 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.017602505471168907, 'num_filters_1': 111, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.09851027974748842, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 65, 'num_filters_3': 120, 'num_filters_4': 122, 'num_filters_5': 31}, 'budget': 1200.0, 'working_directory': '.'}
17:49:26 DISPATCHER: Starting worker discovery
17:49:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:49:26 DISPATCHER: Finished worker discovery
17:50:26 DISPATCHER: Starting worker discovery
17:50:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:50:26 DISPATCHER: Finished worker discovery
17:51:26 DISPATCHER: Starting worker discovery
17:51:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:51:26 DISPATCHER: Finished worker discovery
17:52:26 DISPATCHER: Starting worker discovery
17:52:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:52:26 DISPATCHER: Finished worker discovery
17:53:26 DISPATCHER: Starting worker discovery
17:53:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:53:26 DISPATCHER: Finished worker discovery
17:54:26 DISPATCHER: Starting worker discovery
17:54:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:54:27 DISPATCHER: Finished worker discovery
17:55:27 DISPATCHER: Starting worker discovery
17:55:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:55:27 DISPATCHER: Finished worker discovery
17:56:27 DISPATCHER: Starting worker discovery
17:56:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:56:27 DISPATCHER: Finished worker discovery
17:57:27 DISPATCHER: Starting worker discovery
17:57:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:57:27 DISPATCHER: Finished worker discovery
17:58:27 DISPATCHER: Starting worker discovery
17:58:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:58:27 DISPATCHER: Finished worker discovery
17:59:27 DISPATCHER: Starting worker discovery
17:59:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:59:27 DISPATCHER: Finished worker discovery
18:00:27 DISPATCHER: Starting worker discovery
18:00:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:00:27 DISPATCHER: Finished worker discovery
18:01:27 DISPATCHER: Starting worker discovery
18:01:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:01:27 DISPATCHER: Finished worker discovery
18:02:27 DISPATCHER: Starting worker discovery
18:02:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:02:27 DISPATCHER: Finished worker discovery
18:03:27 DISPATCHER: Starting worker discovery
18:03:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:03:27 DISPATCHER: Finished worker discovery
18:04:27 DISPATCHER: Starting worker discovery
18:04:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:04:27 DISPATCHER: Finished worker discovery
18:05:27 DISPATCHER: Starting worker discovery
18:05:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:05:27 DISPATCHER: Finished worker discovery
18:06:27 DISPATCHER: Starting worker discovery
18:06:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:06:27 DISPATCHER: Finished worker discovery
18:07:27 DISPATCHER: Starting worker discovery
18:07:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:07:27 DISPATCHER: Finished worker discovery
18:08:27 DISPATCHER: Starting worker discovery
18:08:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:08:27 DISPATCHER: Finished worker discovery
18:09:27 DISPATCHER: Starting worker discovery
18:09:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:09:27 DISPATCHER: Finished worker discovery
18:09:43 WORKER: done with job (3, 0, 1), trying to register it.
18:09:44 WORKER: registered result for job (3, 0, 1) with dispatcher
18:09:44 DISPATCHER: job (3, 0, 1) finished
18:09:44 DISPATCHER: register_result: lock acquired
18:09:44 DISPATCHER: job (3, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:09:44 job_id: (3, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.017602505471168907, 'num_filters_1': 111, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.09851027974748842, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 65, 'num_filters_3': 120, 'num_filters_4': 122, 'num_filters_5': 31}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.017602505471168907, 'num_filters_1': 111, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.09851027974748842, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 65, 'num_filters_3': 120, 'num_filters_4': 122, 'num_filters_5': 31}"}}
exception: None

18:09:44 job_callback for (3, 0, 1) started
18:09:44 DISPATCHER: Trying to submit another job.
18:09:44 job_callback for (3, 0, 1) got condition
18:09:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:09:44 Only 6 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
18:09:44 HBMASTER: Trying to run another job!
18:09:44 job_callback for (3, 0, 1) finished
18:09:44 start sampling a new configuration.
18:09:44 done sampling a new configuration.
18:09:44 HBMASTER: schedule new run for iteration 3
18:09:44 HBMASTER: trying submitting job (3, 0, 2) to dispatcher
18:09:44 HBMASTER: submitting job (3, 0, 2) to dispatcher
18:09:44 DISPATCHER: trying to submit job (3, 0, 2)
18:09:44 DISPATCHER: trying to notify the job_runner thread.
18:09:44 HBMASTER: job (3, 0, 2) submitted to dispatcher
18:09:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:09:44 DISPATCHER: Trying to submit another job.
18:09:44 DISPATCHER: starting job (3, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:09:44 DISPATCHER: job (3, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:09:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:09:44 WORKER: start processing job (3, 0, 2)
18:09:44 WORKER: args: ()
18:09:44 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.07398210593246245, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.087637211198372, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 16, 'num_filters_3': 20}, 'budget': 1200.0, 'working_directory': '.'}
18:10:27 DISPATCHER: Starting worker discovery
18:10:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:10:27 DISPATCHER: Finished worker discovery
18:11:27 DISPATCHER: Starting worker discovery
18:11:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:11:27 DISPATCHER: Finished worker discovery
18:12:27 DISPATCHER: Starting worker discovery
18:12:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:12:27 DISPATCHER: Finished worker discovery
18:13:27 DISPATCHER: Starting worker discovery
18:13:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:13:27 DISPATCHER: Finished worker discovery
18:14:27 DISPATCHER: Starting worker discovery
18:14:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:14:27 DISPATCHER: Finished worker discovery
18:15:27 DISPATCHER: Starting worker discovery
18:15:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:15:27 DISPATCHER: Finished worker discovery
18:16:27 DISPATCHER: Starting worker discovery
18:16:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:16:27 DISPATCHER: Finished worker discovery
18:17:27 DISPATCHER: Starting worker discovery
18:17:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:17:27 DISPATCHER: Finished worker discovery
18:18:27 DISPATCHER: Starting worker discovery
18:18:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:18:27 DISPATCHER: Finished worker discovery
18:19:27 DISPATCHER: Starting worker discovery
18:19:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:19:27 DISPATCHER: Finished worker discovery
18:20:27 DISPATCHER: Starting worker discovery
18:20:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:20:27 DISPATCHER: Finished worker discovery
18:21:27 DISPATCHER: Starting worker discovery
18:21:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:21:27 DISPATCHER: Finished worker discovery
18:22:27 DISPATCHER: Starting worker discovery
18:22:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:22:27 DISPATCHER: Finished worker discovery
18:23:27 DISPATCHER: Starting worker discovery
18:23:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:23:27 DISPATCHER: Finished worker discovery
18:24:27 DISPATCHER: Starting worker discovery
18:24:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:24:27 DISPATCHER: Finished worker discovery
18:25:27 DISPATCHER: Starting worker discovery
18:25:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:25:27 DISPATCHER: Finished worker discovery
18:26:27 DISPATCHER: Starting worker discovery
18:26:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:26:27 DISPATCHER: Finished worker discovery
18:27:27 DISPATCHER: Starting worker discovery
18:27:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:27:27 DISPATCHER: Finished worker discovery
18:28:27 DISPATCHER: Starting worker discovery
18:28:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:28:27 DISPATCHER: Finished worker discovery
18:29:27 DISPATCHER: Starting worker discovery
18:29:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:29:27 DISPATCHER: Finished worker discovery
18:30:27 DISPATCHER: Starting worker discovery
18:30:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:30:27 DISPATCHER: Finished worker discovery
18:30:28 WORKER: done with job (3, 0, 2), trying to register it.
18:30:28 WORKER: registered result for job (3, 0, 2) with dispatcher
18:30:28 DISPATCHER: job (3, 0, 2) finished
18:30:28 DISPATCHER: register_result: lock acquired
18:30:28 DISPATCHER: job (3, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:30:28 job_id: (3, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.07398210593246245, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.087637211198372, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 16, 'num_filters_3': 20}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.2679463255261716, 'info': {'data03': 0.2679463255261716, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.07398210593246245, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.087637211198372, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 16, 'num_filters_3': 20}"}}
exception: None

18:30:28 job_callback for (3, 0, 2) started
18:30:28 DISPATCHER: Trying to submit another job.
18:30:28 job_callback for (3, 0, 2) got condition
18:30:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:30:29 Only 7 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
18:30:29 HBMASTER: Trying to run another job!
18:30:29 job_callback for (3, 0, 2) finished
18:30:29 start sampling a new configuration.
18:30:29 done sampling a new configuration.
18:30:29 HBMASTER: schedule new run for iteration 3
18:30:29 HBMASTER: trying submitting job (3, 0, 3) to dispatcher
18:30:29 HBMASTER: submitting job (3, 0, 3) to dispatcher
18:30:29 DISPATCHER: trying to submit job (3, 0, 3)
18:30:29 DISPATCHER: trying to notify the job_runner thread.
18:30:29 HBMASTER: job (3, 0, 3) submitted to dispatcher
18:30:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:30:29 DISPATCHER: Trying to submit another job.
18:30:29 DISPATCHER: starting job (3, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:30:29 DISPATCHER: job (3, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:30:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:30:29 WORKER: start processing job (3, 0, 3)
18:30:29 WORKER: args: ()
18:30:29 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.00364689917576309, 'num_filters_1': 32, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.052369488133380535, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 20, 'num_filters_3': 77, 'num_filters_4': 26, 'num_filters_5': 59}, 'budget': 1200.0, 'working_directory': '.'}
18:31:27 DISPATCHER: Starting worker discovery
18:31:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:31:27 DISPATCHER: Finished worker discovery
18:32:27 DISPATCHER: Starting worker discovery
18:32:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:32:27 DISPATCHER: Finished worker discovery
18:33:27 DISPATCHER: Starting worker discovery
18:33:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:33:27 DISPATCHER: Finished worker discovery
18:34:27 DISPATCHER: Starting worker discovery
18:34:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:34:27 DISPATCHER: Finished worker discovery
18:35:27 DISPATCHER: Starting worker discovery
18:35:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:35:27 DISPATCHER: Finished worker discovery
18:36:27 DISPATCHER: Starting worker discovery
18:36:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:36:27 DISPATCHER: Finished worker discovery
18:37:27 DISPATCHER: Starting worker discovery
18:37:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:37:27 DISPATCHER: Finished worker discovery
18:38:27 DISPATCHER: Starting worker discovery
18:38:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:38:27 DISPATCHER: Finished worker discovery
18:39:27 DISPATCHER: Starting worker discovery
18:39:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:39:27 DISPATCHER: Finished worker discovery
18:40:27 DISPATCHER: Starting worker discovery
18:40:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:40:27 DISPATCHER: Finished worker discovery
18:41:27 DISPATCHER: Starting worker discovery
18:41:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:41:27 DISPATCHER: Finished worker discovery
18:42:27 DISPATCHER: Starting worker discovery
18:42:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:42:27 DISPATCHER: Finished worker discovery
18:43:27 DISPATCHER: Starting worker discovery
18:43:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:43:27 DISPATCHER: Finished worker discovery
18:44:27 DISPATCHER: Starting worker discovery
18:44:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:44:27 DISPATCHER: Finished worker discovery
18:45:27 DISPATCHER: Starting worker discovery
18:45:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:45:27 DISPATCHER: Finished worker discovery
18:46:27 DISPATCHER: Starting worker discovery
18:46:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:46:27 DISPATCHER: Finished worker discovery
18:47:27 DISPATCHER: Starting worker discovery
18:47:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:47:27 DISPATCHER: Finished worker discovery
18:48:27 DISPATCHER: Starting worker discovery
18:48:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:48:27 DISPATCHER: Finished worker discovery
18:49:27 DISPATCHER: Starting worker discovery
18:49:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:49:27 DISPATCHER: Finished worker discovery
18:50:27 DISPATCHER: Starting worker discovery
18:50:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:50:27 DISPATCHER: Finished worker discovery
18:51:11 WORKER: done with job (3, 0, 3), trying to register it.
18:51:11 WORKER: registered result for job (3, 0, 3) with dispatcher
18:51:11 DISPATCHER: job (3, 0, 3) finished
18:51:11 DISPATCHER: register_result: lock acquired
18:51:11 DISPATCHER: job (3, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:51:11 job_id: (3, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.00364689917576309, 'num_filters_1': 32, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.052369488133380535, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 20, 'num_filters_3': 77, 'num_filters_4': 26, 'num_filters_5': 59}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.37561552373820173, 'info': {'data03': 0.37561552373820173, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.00364689917576309, 'num_filters_1': 32, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.052369488133380535, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 20, 'num_filters_3': 77, 'num_filters_4': 26, 'num_filters_5': 59}"}}
exception: None

18:51:11 job_callback for (3, 0, 3) started
18:51:11 DISPATCHER: Trying to submit another job.
18:51:11 job_callback for (3, 0, 3) got condition
18:51:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:51:11 Only 8 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
18:51:11 HBMASTER: Trying to run another job!
18:51:11 job_callback for (3, 0, 3) finished
18:51:11 start sampling a new configuration.
18:51:11 done sampling a new configuration.
18:51:11 HBMASTER: schedule new run for iteration 4
18:51:11 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
18:51:11 HBMASTER: submitting job (4, 0, 0) to dispatcher
18:51:11 DISPATCHER: trying to submit job (4, 0, 0)
18:51:11 DISPATCHER: trying to notify the job_runner thread.
18:51:11 HBMASTER: job (4, 0, 0) submitted to dispatcher
18:51:11 DISPATCHER: Trying to submit another job.
18:51:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:51:11 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:51:11 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:51:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:51:11 WORKER: start processing job (4, 0, 0)
18:51:11 WORKER: args: ()
18:51:11 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.007579108340660349, 'num_filters_1': 41, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.013924450357388884, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 66, 'num_filters_3': 37, 'num_filters_4': 32}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:51:27 DISPATCHER: Starting worker discovery
18:51:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:51:27 DISPATCHER: Finished worker discovery
18:52:27 DISPATCHER: Starting worker discovery
18:52:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:52:27 DISPATCHER: Finished worker discovery
18:52:35 WORKER: done with job (4, 0, 0), trying to register it.
18:52:35 WORKER: registered result for job (4, 0, 0) with dispatcher
18:52:35 DISPATCHER: job (4, 0, 0) finished
18:52:35 DISPATCHER: register_result: lock acquired
18:52:35 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:52:35 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.007579108340660349, 'num_filters_1': 41, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.013924450357388884, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 66, 'num_filters_3': 37, 'num_filters_4': 32}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.31563913675624783, 'info': {'data03': 0.31563913675624783, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.007579108340660349, 'num_filters_1': 41, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.013924450357388884, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 66, 'num_filters_3': 37, 'num_filters_4': 32}"}}
exception: None

18:52:35 job_callback for (4, 0, 0) started
18:52:35 DISPATCHER: Trying to submit another job.
18:52:35 job_callback for (4, 0, 0) got condition
18:52:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:52:35 HBMASTER: Trying to run another job!
18:52:35 job_callback for (4, 0, 0) finished
18:52:35 start sampling a new configuration.
18:52:35 done sampling a new configuration.
18:52:35 HBMASTER: schedule new run for iteration 4
18:52:35 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
18:52:35 HBMASTER: submitting job (4, 0, 1) to dispatcher
18:52:35 DISPATCHER: trying to submit job (4, 0, 1)
18:52:35 DISPATCHER: trying to notify the job_runner thread.
18:52:35 HBMASTER: job (4, 0, 1) submitted to dispatcher
18:52:35 DISPATCHER: Trying to submit another job.
18:52:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:52:35 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:52:35 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:52:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:52:35 WORKER: start processing job (4, 0, 1)
18:52:35 WORKER: args: ()
18:52:35 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.013653075898485925, 'num_filters_1': 47, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.09123524303481256, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 82, 'num_filters_3': 44, 'num_filters_4': 53, 'num_filters_5': 30}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:53:27 DISPATCHER: Starting worker discovery
18:53:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:53:27 DISPATCHER: Finished worker discovery
18:54:03 WORKER: done with job (4, 0, 1), trying to register it.
18:54:03 WORKER: registered result for job (4, 0, 1) with dispatcher
18:54:03 DISPATCHER: job (4, 0, 1) finished
18:54:03 DISPATCHER: register_result: lock acquired
18:54:03 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:54:03 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.013653075898485925, 'num_filters_1': 47, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.09123524303481256, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 82, 'num_filters_3': 44, 'num_filters_4': 53, 'num_filters_5': 30}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.013653075898485925, 'num_filters_1': 47, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.09123524303481256, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 82, 'num_filters_3': 44, 'num_filters_4': 53, 'num_filters_5': 30}"}}
exception: None

18:54:03 job_callback for (4, 0, 1) started
18:54:03 job_callback for (4, 0, 1) got condition
18:54:03 DISPATCHER: Trying to submit another job.
18:54:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:54:03 HBMASTER: Trying to run another job!
18:54:03 job_callback for (4, 0, 1) finished
18:54:03 start sampling a new configuration.
18:54:03 done sampling a new configuration.
18:54:03 HBMASTER: schedule new run for iteration 4
18:54:03 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
18:54:03 HBMASTER: submitting job (4, 0, 2) to dispatcher
18:54:03 DISPATCHER: trying to submit job (4, 0, 2)
18:54:03 DISPATCHER: trying to notify the job_runner thread.
18:54:03 HBMASTER: job (4, 0, 2) submitted to dispatcher
18:54:03 DISPATCHER: Trying to submit another job.
18:54:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:54:03 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:54:03 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:54:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:54:03 WORKER: start processing job (4, 0, 2)
18:54:03 WORKER: args: ()
18:54:03 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004508643708707877, 'num_filters_1': 127, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.058182601930580856, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 93, 'num_filters_3': 115}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:54:27 DISPATCHER: Starting worker discovery
18:54:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:54:27 DISPATCHER: Finished worker discovery
18:55:27 DISPATCHER: Starting worker discovery
18:55:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:55:27 DISPATCHER: Finished worker discovery
18:55:29 WORKER: done with job (4, 0, 2), trying to register it.
18:55:29 WORKER: registered result for job (4, 0, 2) with dispatcher
18:55:29 DISPATCHER: job (4, 0, 2) finished
18:55:29 DISPATCHER: register_result: lock acquired
18:55:29 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:55:29 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004508643708707877, 'num_filters_1': 127, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.058182601930580856, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 93, 'num_filters_3': 115}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.45829833719335483, 'info': {'data03': 0.45829833719335483, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004508643708707877, 'num_filters_1': 127, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.058182601930580856, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 93, 'num_filters_3': 115}"}}
exception: None

18:55:29 job_callback for (4, 0, 2) started
18:55:29 job_callback for (4, 0, 2) got condition
18:55:29 DISPATCHER: Trying to submit another job.
18:55:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:55:29 HBMASTER: Trying to run another job!
18:55:29 job_callback for (4, 0, 2) finished
18:55:29 start sampling a new configuration.
18:55:29 done sampling a new configuration.
18:55:29 HBMASTER: schedule new run for iteration 4
18:55:29 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
18:55:29 HBMASTER: submitting job (4, 0, 3) to dispatcher
18:55:29 DISPATCHER: trying to submit job (4, 0, 3)
18:55:29 DISPATCHER: trying to notify the job_runner thread.
18:55:29 HBMASTER: job (4, 0, 3) submitted to dispatcher
18:55:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:55:29 DISPATCHER: Trying to submit another job.
18:55:29 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:55:29 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:55:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:55:29 WORKER: start processing job (4, 0, 3)
18:55:29 WORKER: args: ()
18:55:29 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.034488500318623785, 'num_filters_1': 105, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.08780849786581979, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 97, 'num_filters_3': 33, 'num_filters_4': 40}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:56:27 DISPATCHER: Starting worker discovery
18:56:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:56:27 DISPATCHER: Finished worker discovery
18:56:57 WORKER: done with job (4, 0, 3), trying to register it.
18:56:57 WORKER: registered result for job (4, 0, 3) with dispatcher
18:56:57 DISPATCHER: job (4, 0, 3) finished
18:56:57 DISPATCHER: register_result: lock acquired
18:56:57 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:56:57 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.034488500318623785, 'num_filters_1': 105, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.08780849786581979, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 97, 'num_filters_3': 33, 'num_filters_4': 40}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.005852434779626791, 'info': {'data03': 0.005852434779626791, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.034488500318623785, 'num_filters_1': 105, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.08780849786581979, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 97, 'num_filters_3': 33, 'num_filters_4': 40}"}}
exception: None

18:56:57 job_callback for (4, 0, 3) started
18:56:57 DISPATCHER: Trying to submit another job.
18:56:57 job_callback for (4, 0, 3) got condition
18:56:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:56:57 HBMASTER: Trying to run another job!
18:56:57 job_callback for (4, 0, 3) finished
18:56:57 start sampling a new configuration.
18:56:57 done sampling a new configuration.
18:56:57 HBMASTER: schedule new run for iteration 4
18:56:57 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
18:56:57 HBMASTER: submitting job (4, 0, 4) to dispatcher
18:56:57 DISPATCHER: trying to submit job (4, 0, 4)
18:56:57 DISPATCHER: trying to notify the job_runner thread.
18:56:57 HBMASTER: job (4, 0, 4) submitted to dispatcher
18:56:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:56:57 DISPATCHER: Trying to submit another job.
18:56:57 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:56:57 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:56:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:56:57 WORKER: start processing job (4, 0, 4)
18:56:57 WORKER: args: ()
18:56:57 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.008735864276808156, 'num_filters_1': 50, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.021671431450989022, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 74, 'num_filters_3': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:57:27 DISPATCHER: Starting worker discovery
18:57:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:57:27 DISPATCHER: Finished worker discovery
18:58:22 WORKER: done with job (4, 0, 4), trying to register it.
18:58:22 WORKER: registered result for job (4, 0, 4) with dispatcher
18:58:22 DISPATCHER: job (4, 0, 4) finished
18:58:22 DISPATCHER: register_result: lock acquired
18:58:22 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:58:22 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.008735864276808156, 'num_filters_1': 50, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.021671431450989022, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 74, 'num_filters_3': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.32117634979407467, 'info': {'data03': 0.32117634979407467, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.008735864276808156, 'num_filters_1': 50, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.021671431450989022, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 74, 'num_filters_3': 44}"}}
exception: None

18:58:22 job_callback for (4, 0, 4) started
18:58:22 job_callback for (4, 0, 4) got condition
18:58:22 DISPATCHER: Trying to submit another job.
18:58:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:58:22 HBMASTER: Trying to run another job!
18:58:22 job_callback for (4, 0, 4) finished
18:58:22 start sampling a new configuration.
18:58:22 done sampling a new configuration.
18:58:22 HBMASTER: schedule new run for iteration 4
18:58:22 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
18:58:22 HBMASTER: submitting job (4, 0, 5) to dispatcher
18:58:22 DISPATCHER: trying to submit job (4, 0, 5)
18:58:22 DISPATCHER: trying to notify the job_runner thread.
18:58:22 HBMASTER: job (4, 0, 5) submitted to dispatcher
18:58:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:58:22 DISPATCHER: Trying to submit another job.
18:58:22 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:58:22 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:58:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:58:22 WORKER: start processing job (4, 0, 5)
18:58:22 WORKER: args: ()
18:58:22 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.055632181902124066, 'num_filters_1': 95, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.18656043062398547}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:58:27 DISPATCHER: Starting worker discovery
18:58:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:58:27 DISPATCHER: Finished worker discovery
18:59:27 DISPATCHER: Starting worker discovery
18:59:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:59:27 DISPATCHER: Finished worker discovery
18:59:44 WORKER: done with job (4, 0, 5), trying to register it.
18:59:44 WORKER: registered result for job (4, 0, 5) with dispatcher
18:59:44 DISPATCHER: job (4, 0, 5) finished
18:59:44 DISPATCHER: register_result: lock acquired
18:59:44 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:59:44 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.055632181902124066, 'num_filters_1': 95, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.18656043062398547}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.34637555162203426, 'info': {'data03': 0.34637555162203426, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.055632181902124066, 'num_filters_1': 95, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.18656043062398547}"}}
exception: None

18:59:44 job_callback for (4, 0, 5) started
18:59:44 job_callback for (4, 0, 5) got condition
18:59:44 DISPATCHER: Trying to submit another job.
18:59:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:59:44 HBMASTER: Trying to run another job!
18:59:44 job_callback for (4, 0, 5) finished
18:59:44 start sampling a new configuration.
18:59:44 done sampling a new configuration.
18:59:44 HBMASTER: schedule new run for iteration 4
18:59:44 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
18:59:44 HBMASTER: submitting job (4, 0, 6) to dispatcher
18:59:44 DISPATCHER: trying to submit job (4, 0, 6)
18:59:44 DISPATCHER: trying to notify the job_runner thread.
18:59:44 HBMASTER: job (4, 0, 6) submitted to dispatcher
18:59:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:59:44 DISPATCHER: Trying to submit another job.
18:59:44 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:59:44 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:59:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:59:44 WORKER: start processing job (4, 0, 6)
18:59:44 WORKER: args: ()
18:59:44 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0035235188082819234, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.014537581369304239, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 79, 'num_filters_3': 53, 'num_filters_4': 27, 'num_filters_5': 28}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:00:27 DISPATCHER: Starting worker discovery
19:00:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:00:27 DISPATCHER: Finished worker discovery
19:01:08 WORKER: done with job (4, 0, 6), trying to register it.
19:01:08 WORKER: registered result for job (4, 0, 6) with dispatcher
19:01:08 DISPATCHER: job (4, 0, 6) finished
19:01:08 DISPATCHER: register_result: lock acquired
19:01:08 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:01:08 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0035235188082819234, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.014537581369304239, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 79, 'num_filters_3': 53, 'num_filters_4': 27, 'num_filters_5': 28}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.28768537098841035, 'info': {'data03': 0.28768537098841035, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0035235188082819234, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.014537581369304239, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 79, 'num_filters_3': 53, 'num_filters_4': 27, 'num_filters_5': 28}"}}
exception: None

19:01:08 job_callback for (4, 0, 6) started
19:01:08 job_callback for (4, 0, 6) got condition
19:01:08 DISPATCHER: Trying to submit another job.
19:01:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:01:08 done building a new model for budget 44.444444 based on 17/28 split
Best loss for this budget:-0.466954





19:01:08 HBMASTER: Trying to run another job!
19:01:08 job_callback for (4, 0, 6) finished
19:01:08 start sampling a new configuration.
19:01:08 best_vector: [0, 1, 0.27277573128286603, 0.7455795694223021, 0.14964029983430815, 0, 0.4998664532188569, 0.7182919032947652, 0, 2, 2, 2, 0.7316429063680888, 0.40361025035254705, 0.9351790026369065, 0.2548962608631892], 7.140186129411614e-29, 0.00014005237144741001, -5.030609452655889e-07
19:01:08 done sampling a new configuration.
19:01:08 HBMASTER: schedule new run for iteration 4
19:01:08 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
19:01:08 HBMASTER: submitting job (4, 0, 7) to dispatcher
19:01:08 DISPATCHER: trying to submit job (4, 0, 7)
19:01:08 DISPATCHER: trying to notify the job_runner thread.
19:01:08 HBMASTER: job (4, 0, 7) submitted to dispatcher
19:01:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:01:08 DISPATCHER: Trying to submit another job.
19:01:08 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:01:08 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:01:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:01:08 WORKER: start processing job (4, 0, 7)
19:01:08 WORKER: args: ()
19:01:08 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0035119753788313023, 'num_filters_1': 75, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.08600413096070521}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:01:27 DISPATCHER: Starting worker discovery
19:01:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:01:27 DISPATCHER: Finished worker discovery
19:02:27 DISPATCHER: Starting worker discovery
19:02:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:02:27 DISPATCHER: Finished worker discovery
19:02:34 WORKER: done with job (4, 0, 7), trying to register it.
19:02:34 WORKER: registered result for job (4, 0, 7) with dispatcher
19:02:34 DISPATCHER: job (4, 0, 7) finished
19:02:34 DISPATCHER: register_result: lock acquired
19:02:34 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:02:34 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0035119753788313023, 'num_filters_1': 75, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.08600413096070521}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.29587017253871334, 'info': {'data03': 0.29587017253871334, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0035119753788313023, 'num_filters_1': 75, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.08600413096070521}"}}
exception: None

19:02:34 job_callback for (4, 0, 7) started
19:02:34 DISPATCHER: Trying to submit another job.
19:02:34 job_callback for (4, 0, 7) got condition
19:02:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:02:34 done building a new model for budget 44.444444 based on 17/29 split
Best loss for this budget:-0.466954





19:02:34 HBMASTER: Trying to run another job!
19:02:34 job_callback for (4, 0, 7) finished
19:02:34 start sampling a new configuration.
19:02:35 best_vector: [0, 1, 0.4834666319668324, 0.06423624049457255, 0.18228979387606825, 0, 0.6199320149134112, 0.6690577296517219, 1, 1, 0, 2, 0.7246582193542819, 0.20410677053092285, 0.8806380130019508, 0.6497794584032563], 2.5163930953970735e-30, 0.003973941916424649, -4.1767744898909787e-07
19:02:35 done sampling a new configuration.
19:02:35 HBMASTER: schedule new run for iteration 4
19:02:35 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
19:02:35 HBMASTER: submitting job (4, 0, 8) to dispatcher
19:02:35 DISPATCHER: trying to submit job (4, 0, 8)
19:02:35 DISPATCHER: trying to notify the job_runner thread.
19:02:35 HBMASTER: job (4, 0, 8) submitted to dispatcher
19:02:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:02:35 DISPATCHER: Trying to submit another job.
19:02:35 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:02:35 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:02:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:02:35 WORKER: start processing job (4, 0, 8)
19:02:35 WORKER: args: ()
19:02:35 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.009266874125796238, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.07421029792409578}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:03:27 DISPATCHER: Starting worker discovery
19:03:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:03:27 DISPATCHER: Finished worker discovery
19:04:00 WORKER: done with job (4, 0, 8), trying to register it.
19:04:00 WORKER: registered result for job (4, 0, 8) with dispatcher
19:04:00 DISPATCHER: job (4, 0, 8) finished
19:04:00 DISPATCHER: register_result: lock acquired
19:04:00 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:04:00 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.009266874125796238, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.07421029792409578}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.25749817481478143, 'info': {'data03': 0.25749817481478143, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.009266874125796238, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.07421029792409578}"}}
exception: None

19:04:00 job_callback for (4, 0, 8) started
19:04:00 DISPATCHER: Trying to submit another job.
19:04:00 job_callback for (4, 0, 8) got condition
19:04:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:04:00 done building a new model for budget 44.444444 based on 17/30 split
Best loss for this budget:-0.466954





19:04:00 HBMASTER: Trying to run another job!
19:04:00 job_callback for (4, 0, 8) finished
19:04:00 start sampling a new configuration.
19:04:00 best_vector: [0, 1, 0.24246844780973673, 0.3992638453045201, 0.18279109137383287, 1, 0.5455693066530818, 0.851678385732279, 0, 1, 0, 0, 0.27444316046184103, 0.41175269136901566, 0.9499010988525806, 0.5454830932246095], 8.979446208655241e-30, 0.0011136544245190815, -6.8772287973875686e-06
19:04:00 done sampling a new configuration.
19:04:00 HBMASTER: schedule new run for iteration 4
19:04:00 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
19:04:00 HBMASTER: submitting job (4, 0, 9) to dispatcher
19:04:00 DISPATCHER: trying to submit job (4, 0, 9)
19:04:00 DISPATCHER: trying to notify the job_runner thread.
19:04:00 HBMASTER: job (4, 0, 9) submitted to dispatcher
19:04:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:04:00 DISPATCHER: Trying to submit another job.
19:04:00 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:04:00 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:04:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:04:00 WORKER: start processing job (4, 0, 9)
19:04:00 WORKER: args: ()
19:04:00 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0030544772556317288, 'num_filters_1': 36, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.12825051758851103}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:04:27 DISPATCHER: Starting worker discovery
19:04:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:04:27 DISPATCHER: Finished worker discovery
19:05:25 WORKER: done with job (4, 0, 9), trying to register it.
19:05:25 WORKER: registered result for job (4, 0, 9) with dispatcher
19:05:25 DISPATCHER: job (4, 0, 9) finished
19:05:25 DISPATCHER: register_result: lock acquired
19:05:25 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:05:25 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0030544772556317288, 'num_filters_1': 36, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.12825051758851103}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2200975855273133, 'info': {'data03': 0.2200975855273133, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0030544772556317288, 'num_filters_1': 36, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.12825051758851103}"}}
exception: None

19:05:25 job_callback for (4, 0, 9) started
19:05:25 job_callback for (4, 0, 9) got condition
19:05:25 DISPATCHER: Trying to submit another job.
19:05:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:05:25 done building a new model for budget 44.444444 based on 17/31 split
Best loss for this budget:-0.466954





19:05:25 HBMASTER: Trying to run another job!
19:05:25 job_callback for (4, 0, 9) finished
19:05:25 start sampling a new configuration.
19:05:25 done sampling a new configuration.
19:05:25 HBMASTER: schedule new run for iteration 4
19:05:25 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
19:05:25 HBMASTER: submitting job (4, 0, 10) to dispatcher
19:05:25 DISPATCHER: trying to submit job (4, 0, 10)
19:05:25 DISPATCHER: trying to notify the job_runner thread.
19:05:25 HBMASTER: job (4, 0, 10) submitted to dispatcher
19:05:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:05:25 DISPATCHER: Trying to submit another job.
19:05:25 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:05:25 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:05:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:05:25 WORKER: start processing job (4, 0, 10)
19:05:25 WORKER: args: ()
19:05:25 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.007767276183390426, 'num_filters_1': 44, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 10, 'weight_decay': 0.10630255050804786}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:05:27 DISPATCHER: Starting worker discovery
19:05:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:05:27 DISPATCHER: Finished worker discovery
19:06:27 DISPATCHER: Starting worker discovery
19:06:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:06:27 DISPATCHER: Finished worker discovery
19:06:50 WORKER: done with job (4, 0, 10), trying to register it.
19:06:50 WORKER: registered result for job (4, 0, 10) with dispatcher
19:06:50 DISPATCHER: job (4, 0, 10) finished
19:06:50 DISPATCHER: register_result: lock acquired
19:06:50 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:06:50 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.007767276183390426, 'num_filters_1': 44, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 10, 'weight_decay': 0.10630255050804786}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2082275771661642, 'info': {'data03': 0.2082275771661642, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.007767276183390426, 'num_filters_1': 44, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 10, 'weight_decay': 0.10630255050804786}"}}
exception: None

19:06:50 job_callback for (4, 0, 10) started
19:06:50 job_callback for (4, 0, 10) got condition
19:06:50 DISPATCHER: Trying to submit another job.
19:06:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:06:50 done building a new model for budget 44.444444 based on 17/32 split
Best loss for this budget:-0.466954





19:06:50 HBMASTER: Trying to run another job!
19:06:50 job_callback for (4, 0, 10) finished
19:06:50 start sampling a new configuration.
19:06:50 best_vector: [1, 1, 0.12309878864969206, 0.4701835495251216, 0.9263938235850196, 1, 0.549129046951115, 0.7560600841181722, 2, 2, 2, 1, 0.27310298543985845, 0.8842118515871719, 0.5650465560702164, 0.8438130917587152], 2.252565658956691e-28, 4.439382248520848e-05, -7.71966225005614e-07
19:06:50 done sampling a new configuration.
19:06:50 HBMASTER: schedule new run for iteration 4
19:06:50 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
19:06:50 HBMASTER: submitting job (4, 0, 11) to dispatcher
19:06:50 DISPATCHER: trying to submit job (4, 0, 11)
19:06:50 DISPATCHER: trying to notify the job_runner thread.
19:06:50 HBMASTER: job (4, 0, 11) submitted to dispatcher
19:06:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:06:50 DISPATCHER: Trying to submit another job.
19:06:50 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:06:50 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:06:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:06:50 WORKER: start processing job (4, 0, 11)
19:06:50 WORKER: args: ()
19:06:50 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0017627778195941665, 'num_filters_1': 42, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.09630677676626977, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 28, 'num_filters_3': 101, 'num_filters_4': 51, 'num_filters_5': 92}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:07:27 DISPATCHER: Starting worker discovery
19:07:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:07:27 DISPATCHER: Finished worker discovery
19:08:15 WORKER: done with job (4, 0, 11), trying to register it.
19:08:15 WORKER: registered result for job (4, 0, 11) with dispatcher
19:08:15 DISPATCHER: job (4, 0, 11) finished
19:08:15 DISPATCHER: register_result: lock acquired
19:08:15 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:08:15 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0017627778195941665, 'num_filters_1': 42, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.09630677676626977, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 28, 'num_filters_3': 101, 'num_filters_4': 51, 'num_filters_5': 92}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4648101714662342, 'info': {'data03': 0.4648101714662342, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0017627778195941665, 'num_filters_1': 42, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.09630677676626977, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 28, 'num_filters_3': 101, 'num_filters_4': 51, 'num_filters_5': 92}"}}
exception: None

19:08:15 job_callback for (4, 0, 11) started
19:08:15 DISPATCHER: Trying to submit another job.
19:08:15 job_callback for (4, 0, 11) got condition
19:08:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:08:15 done building a new model for budget 44.444444 based on 17/33 split
Best loss for this budget:-0.466954





19:08:15 HBMASTER: Trying to run another job!
19:08:15 job_callback for (4, 0, 11) finished
19:08:15 start sampling a new configuration.
19:08:15 done sampling a new configuration.
19:08:15 HBMASTER: schedule new run for iteration 4
19:08:15 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
19:08:15 HBMASTER: submitting job (4, 0, 12) to dispatcher
19:08:15 DISPATCHER: trying to submit job (4, 0, 12)
19:08:15 DISPATCHER: trying to notify the job_runner thread.
19:08:15 HBMASTER: job (4, 0, 12) submitted to dispatcher
19:08:15 DISPATCHER: Trying to submit another job.
19:08:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:08:15 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:08:15 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:08:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:08:15 WORKER: start processing job (4, 0, 12)
19:08:15 WORKER: args: ()
19:08:15 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.018291278786568246, 'num_filters_1': 90, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.08154934770016298, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 41, 'num_filters_3': 44, 'num_filters_4': 71}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:08:27 DISPATCHER: Starting worker discovery
19:08:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:08:27 DISPATCHER: Finished worker discovery
19:09:27 DISPATCHER: Starting worker discovery
19:09:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:09:27 DISPATCHER: Finished worker discovery
19:09:40 WORKER: done with job (4, 0, 12), trying to register it.
19:09:40 WORKER: registered result for job (4, 0, 12) with dispatcher
19:09:40 DISPATCHER: job (4, 0, 12) finished
19:09:40 DISPATCHER: register_result: lock acquired
19:09:40 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:09:40 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.018291278786568246, 'num_filters_1': 90, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.08154934770016298, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 41, 'num_filters_3': 44, 'num_filters_4': 71}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.018291278786568246, 'num_filters_1': 90, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.08154934770016298, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 41, 'num_filters_3': 44, 'num_filters_4': 71}"}}
exception: None

19:09:40 job_callback for (4, 0, 12) started
19:09:40 DISPATCHER: Trying to submit another job.
19:09:40 job_callback for (4, 0, 12) got condition
19:09:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:09:40 done building a new model for budget 44.444444 based on 17/34 split
Best loss for this budget:-0.466954





19:09:40 HBMASTER: Trying to run another job!
19:09:40 job_callback for (4, 0, 12) finished
19:09:40 start sampling a new configuration.
19:09:40 best_vector: [2, 2, 0.2455727177630769, 0.9810759847798047, 0.10719607042493307, 0, 0.49499874359285756, 0.1503073295467356, 0, 0, 2, 2, 0.4990408751944354, 0.5002247882579207, 0.23281053456716977, 0.7511737309952179], 0.0017492267774204208, 0.0010324679939528003, 1.8060206618517834e-06
19:09:40 done sampling a new configuration.
19:09:40 HBMASTER: schedule new run for iteration 4
19:09:40 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
19:09:40 HBMASTER: submitting job (4, 0, 13) to dispatcher
19:09:40 DISPATCHER: trying to submit job (4, 0, 13)
19:09:40 DISPATCHER: trying to notify the job_runner thread.
19:09:40 HBMASTER: job (4, 0, 13) submitted to dispatcher
19:09:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:09:40 DISPATCHER: Trying to submit another job.
19:09:40 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:09:40 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:09:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:09:40 WORKER: start processing job (4, 0, 13)
19:09:40 WORKER: args: ()
19:09:40 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003098456729484919, 'num_filters_1': 123, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.015687521871165597}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:10:27 DISPATCHER: Starting worker discovery
19:10:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:10:27 DISPATCHER: Finished worker discovery
19:11:01 WORKER: done with job (4, 0, 13), trying to register it.
19:11:01 WORKER: registered result for job (4, 0, 13) with dispatcher
19:11:01 DISPATCHER: job (4, 0, 13) finished
19:11:01 DISPATCHER: register_result: lock acquired
19:11:01 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:11:01 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003098456729484919, 'num_filters_1': 123, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.015687521871165597}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3992745216322992, 'info': {'data03': 0.3992745216322992, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003098456729484919, 'num_filters_1': 123, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.015687521871165597}"}}
exception: None

19:11:01 job_callback for (4, 0, 13) started
19:11:01 DISPATCHER: Trying to submit another job.
19:11:01 job_callback for (4, 0, 13) got condition
19:11:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:11:01 done building a new model for budget 44.444444 based on 17/34 split
Best loss for this budget:-0.466954





19:11:01 HBMASTER: Trying to run another job!
19:11:01 job_callback for (4, 0, 13) finished
19:11:01 start sampling a new configuration.
19:11:01 best_vector: [0, 2, 0.6176165567949699, 0.7835302227549181, 0.9895320424153684, 1, 0.9501853854469738, 0.056036507528234414, 2, 2, 2, 2, 0.2134009887036013, 0.06995822483507974, 0.4248772264004489, 0.6919059982470938], 2.4811818218901727e-26, 4.0303374431390793e-07, -2.576609139269132e-07
19:11:01 done sampling a new configuration.
19:11:01 HBMASTER: schedule new run for iteration 4
19:11:01 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
19:11:01 HBMASTER: submitting job (4, 0, 14) to dispatcher
19:11:01 DISPATCHER: trying to submit job (4, 0, 14)
19:11:01 DISPATCHER: trying to notify the job_runner thread.
19:11:01 HBMASTER: job (4, 0, 14) submitted to dispatcher
19:11:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:11:01 DISPATCHER: Trying to submit another job.
19:11:01 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:11:01 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:11:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:11:01 WORKER: start processing job (4, 0, 14)
19:11:01 WORKER: args: ()
19:11:01 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.017188307458463687, 'num_filters_1': 81, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.01182783281362458, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 24, 'num_filters_3': 18, 'num_filters_4': 38, 'num_filters_5': 67}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:11:27 DISPATCHER: Starting worker discovery
19:11:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:11:27 DISPATCHER: Finished worker discovery
19:12:25 WORKER: done with job (4, 0, 14), trying to register it.
19:12:25 WORKER: registered result for job (4, 0, 14) with dispatcher
19:12:25 DISPATCHER: job (4, 0, 14) finished
19:12:25 DISPATCHER: register_result: lock acquired
19:12:25 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:12:25 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.017188307458463687, 'num_filters_1': 81, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.01182783281362458, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 24, 'num_filters_3': 18, 'num_filters_4': 38, 'num_filters_5': 67}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3483786808305903, 'info': {'data03': 0.3483786808305903, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.017188307458463687, 'num_filters_1': 81, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.01182783281362458, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 24, 'num_filters_3': 18, 'num_filters_4': 38, 'num_filters_5': 67}"}}
exception: None

19:12:25 job_callback for (4, 0, 14) started
19:12:25 DISPATCHER: Trying to submit another job.
19:12:25 job_callback for (4, 0, 14) got condition
19:12:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:12:25 done building a new model for budget 44.444444 based on 17/35 split
Best loss for this budget:-0.466954





19:12:25 HBMASTER: Trying to run another job!
19:12:25 job_callback for (4, 0, 14) finished
19:12:25 start sampling a new configuration.
19:12:25 best_vector: [1, 1, 0.15989532094574105, 0.7950948311528658, 0.04020005938695603, 0, 0.4743547268791085, 0.1232143042080284, 2, 1, 1, 2, 0.34214484749933927, 0.1062609777109777, 0.4640527232444791, 0.9391208926433168], 0.00014302012744560173, 0.000331342750102675, 4.738868234786074e-08
19:12:25 done sampling a new configuration.
19:12:25 HBMASTER: schedule new run for iteration 4
19:12:25 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
19:12:25 HBMASTER: submitting job (4, 0, 15) to dispatcher
19:12:25 DISPATCHER: trying to submit job (4, 0, 15)
19:12:25 DISPATCHER: trying to notify the job_runner thread.
19:12:25 HBMASTER: job (4, 0, 15) submitted to dispatcher
19:12:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:12:25 DISPATCHER: Trying to submit another job.
19:12:25 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:12:25 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:12:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:12:25 WORKER: start processing job (4, 0, 15)
19:12:25 WORKER: args: ()
19:12:25 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.002088289197330835, 'num_filters_1': 83, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 53, 'weight_decay': 0.014464569271193353}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:12:27 DISPATCHER: Starting worker discovery
19:12:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:12:27 DISPATCHER: Finished worker discovery
19:13:27 DISPATCHER: Starting worker discovery
19:13:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:13:27 DISPATCHER: Finished worker discovery
19:13:53 WORKER: done with job (4, 0, 15), trying to register it.
19:13:53 WORKER: registered result for job (4, 0, 15) with dispatcher
19:13:53 DISPATCHER: job (4, 0, 15) finished
19:13:53 DISPATCHER: register_result: lock acquired
19:13:53 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:13:53 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.002088289197330835, 'num_filters_1': 83, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 53, 'weight_decay': 0.014464569271193353}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3451630775589808, 'info': {'data03': 0.3451630775589808, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.002088289197330835, 'num_filters_1': 83, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 53, 'weight_decay': 0.014464569271193353}"}}
exception: None

19:13:53 job_callback for (4, 0, 15) started
19:13:53 job_callback for (4, 0, 15) got condition
19:13:53 DISPATCHER: Trying to submit another job.
19:13:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:13:53 done building a new model for budget 44.444444 based on 17/36 split
Best loss for this budget:-0.466954





19:13:53 HBMASTER: Trying to run another job!
19:13:53 job_callback for (4, 0, 15) finished
19:13:53 start sampling a new configuration.
19:13:53 best_vector: [2, 2, 0.30777788543368895, 0.10094453425750838, 0.031604837241028694, 1, 0.23434544238684257, 0.9934967466340949, 2, 2, 2, 0, 0.5917925031050428, 0.9954008024020939, 0.1277995788172691, 0.2500524401327058], 3.231143307381946e-20, 3.094879752672611e-13, -1.3742508592859508e-06
19:13:53 done sampling a new configuration.
19:13:53 HBMASTER: schedule new run for iteration 4
19:13:53 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
19:13:53 HBMASTER: submitting job (4, 0, 16) to dispatcher
19:13:53 DISPATCHER: trying to submit job (4, 0, 16)
19:13:53 DISPATCHER: trying to notify the job_runner thread.
19:13:53 HBMASTER: job (4, 0, 16) submitted to dispatcher
19:13:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:13:53 DISPATCHER: Trying to submit another job.
19:13:53 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:13:53 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:13:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:13:53 WORKER: start processing job (4, 0, 16)
19:13:53 WORKER: args: ()
19:13:53 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004126252218769469, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.19614130837438107}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:14:27 DISPATCHER: Starting worker discovery
19:14:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:14:27 DISPATCHER: Finished worker discovery
19:15:18 WORKER: done with job (4, 0, 16), trying to register it.
19:15:18 WORKER: registered result for job (4, 0, 16) with dispatcher
19:15:18 DISPATCHER: job (4, 0, 16) finished
19:15:18 DISPATCHER: register_result: lock acquired
19:15:18 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:15:18 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004126252218769469, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.19614130837438107}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3278931207825005, 'info': {'data03': 0.3278931207825005, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.004126252218769469, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.19614130837438107}"}}
exception: None

19:15:18 job_callback for (4, 0, 16) started
19:15:18 DISPATCHER: Trying to submit another job.
19:15:18 job_callback for (4, 0, 16) got condition
19:15:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:15:18 done building a new model for budget 44.444444 based on 17/37 split
Best loss for this budget:-0.466954





19:15:18 HBMASTER: Trying to run another job!
19:15:18 job_callback for (4, 0, 16) finished
19:15:18 start sampling a new configuration.
19:15:18 done sampling a new configuration.
19:15:18 HBMASTER: schedule new run for iteration 4
19:15:18 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
19:15:18 HBMASTER: submitting job (4, 0, 17) to dispatcher
19:15:18 DISPATCHER: trying to submit job (4, 0, 17)
19:15:18 DISPATCHER: trying to notify the job_runner thread.
19:15:18 HBMASTER: job (4, 0, 17) submitted to dispatcher
19:15:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:15:18 DISPATCHER: Trying to submit another job.
19:15:18 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:15:18 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:15:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:15:18 WORKER: start processing job (4, 0, 17)
19:15:18 WORKER: args: ()
19:15:18 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.003793939762748174, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.011416044643944379, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 58, 'num_filters_3': 94, 'num_filters_4': 41, 'num_filters_5': 54}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:15:27 DISPATCHER: Starting worker discovery
19:15:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:15:27 DISPATCHER: Finished worker discovery
19:16:27 DISPATCHER: Starting worker discovery
19:16:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:16:27 DISPATCHER: Finished worker discovery
19:16:42 WORKER: done with job (4, 0, 17), trying to register it.
19:16:42 WORKER: registered result for job (4, 0, 17) with dispatcher
19:16:42 DISPATCHER: job (4, 0, 17) finished
19:16:42 DISPATCHER: register_result: lock acquired
19:16:42 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:16:42 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.003793939762748174, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.011416044643944379, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 58, 'num_filters_3': 94, 'num_filters_4': 41, 'num_filters_5': 54}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.24412695360024084, 'info': {'data03': 0.24412695360024084, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.003793939762748174, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.011416044643944379, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 58, 'num_filters_3': 94, 'num_filters_4': 41, 'num_filters_5': 54}"}}
exception: None

19:16:42 job_callback for (4, 0, 17) started
19:16:42 DISPATCHER: Trying to submit another job.
19:16:42 job_callback for (4, 0, 17) got condition
19:16:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:16:42 done building a new model for budget 44.444444 based on 17/38 split
Best loss for this budget:-0.466954





19:16:42 HBMASTER: Trying to run another job!
19:16:42 job_callback for (4, 0, 17) finished
19:16:42 start sampling a new configuration.
19:16:42 done sampling a new configuration.
19:16:42 HBMASTER: schedule new run for iteration 4
19:16:42 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
19:16:42 HBMASTER: submitting job (4, 0, 18) to dispatcher
19:16:42 DISPATCHER: trying to submit job (4, 0, 18)
19:16:42 DISPATCHER: trying to notify the job_runner thread.
19:16:42 HBMASTER: job (4, 0, 18) submitted to dispatcher
19:16:42 DISPATCHER: Trying to submit another job.
19:16:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:16:42 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:16:42 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:16:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:16:42 WORKER: start processing job (4, 0, 18)
19:16:42 WORKER: args: ()
19:16:42 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.04885532002501979, 'num_filters_1': 74, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.014371283900190157, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 53, 'num_filters_3': 16, 'num_filters_4': 87, 'num_filters_5': 47}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:17:27 DISPATCHER: Starting worker discovery
19:17:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:17:27 DISPATCHER: Finished worker discovery
19:18:05 WORKER: done with job (4, 0, 18), trying to register it.
19:18:05 WORKER: registered result for job (4, 0, 18) with dispatcher
19:18:05 DISPATCHER: job (4, 0, 18) finished
19:18:05 DISPATCHER: register_result: lock acquired
19:18:05 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:18:05 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.04885532002501979, 'num_filters_1': 74, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.014371283900190157, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 53, 'num_filters_3': 16, 'num_filters_4': 87, 'num_filters_5': 47}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.04885532002501979, 'num_filters_1': 74, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.014371283900190157, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 53, 'num_filters_3': 16, 'num_filters_4': 87, 'num_filters_5': 47}"}}
exception: None

19:18:05 job_callback for (4, 0, 18) started
19:18:05 DISPATCHER: Trying to submit another job.
19:18:05 job_callback for (4, 0, 18) got condition
19:18:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:18:05 done building a new model for budget 44.444444 based on 17/39 split
Best loss for this budget:-0.466954





19:18:05 HBMASTER: Trying to run another job!
19:18:05 job_callback for (4, 0, 18) finished
19:18:05 start sampling a new configuration.
19:18:05 done sampling a new configuration.
19:18:05 HBMASTER: schedule new run for iteration 4
19:18:05 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
19:18:05 HBMASTER: submitting job (4, 0, 19) to dispatcher
19:18:05 DISPATCHER: trying to submit job (4, 0, 19)
19:18:05 DISPATCHER: trying to notify the job_runner thread.
19:18:05 HBMASTER: job (4, 0, 19) submitted to dispatcher
19:18:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:18:05 DISPATCHER: Trying to submit another job.
19:18:05 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:18:05 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:18:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:18:05 WORKER: start processing job (4, 0, 19)
19:18:05 WORKER: args: ()
19:18:05 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.05052644262248808, 'num_filters_1': 37, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.0572100612728475, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 24, 'num_filters_3': 17, 'num_filters_4': 61, 'num_filters_5': 33}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:18:27 DISPATCHER: Starting worker discovery
19:18:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:18:27 DISPATCHER: Finished worker discovery
19:19:27 DISPATCHER: Starting worker discovery
19:19:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:19:27 DISPATCHER: Finished worker discovery
19:19:29 WORKER: done with job (4, 0, 19), trying to register it.
19:19:29 WORKER: registered result for job (4, 0, 19) with dispatcher
19:19:29 DISPATCHER: job (4, 0, 19) finished
19:19:29 DISPATCHER: register_result: lock acquired
19:19:29 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:19:29 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.05052644262248808, 'num_filters_1': 37, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.0572100612728475, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 24, 'num_filters_3': 17, 'num_filters_4': 61, 'num_filters_5': 33}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3059918595512249, 'info': {'data03': 0.3059918595512249, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.05052644262248808, 'num_filters_1': 37, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.0572100612728475, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 24, 'num_filters_3': 17, 'num_filters_4': 61, 'num_filters_5': 33}"}}
exception: None

19:19:29 job_callback for (4, 0, 19) started
19:19:29 DISPATCHER: Trying to submit another job.
19:19:29 job_callback for (4, 0, 19) got condition
19:19:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:19:29 done building a new model for budget 44.444444 based on 17/39 split
Best loss for this budget:-0.466954





19:19:29 HBMASTER: Trying to run another job!
19:19:29 job_callback for (4, 0, 19) finished
19:19:29 start sampling a new configuration.
19:19:29 done sampling a new configuration.
19:19:29 HBMASTER: schedule new run for iteration 4
19:19:29 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
19:19:29 HBMASTER: submitting job (4, 0, 20) to dispatcher
19:19:29 DISPATCHER: trying to submit job (4, 0, 20)
19:19:29 DISPATCHER: trying to notify the job_runner thread.
19:19:29 HBMASTER: job (4, 0, 20) submitted to dispatcher
19:19:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:19:29 DISPATCHER: Trying to submit another job.
19:19:29 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:19:29 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:19:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:19:29 WORKER: start processing job (4, 0, 20)
19:19:29 WORKER: args: ()
19:19:29 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.01244968541077741, 'num_filters_1': 41, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.04416087202766}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:20:27 DISPATCHER: Starting worker discovery
19:20:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:20:27 DISPATCHER: Finished worker discovery
19:20:54 WORKER: done with job (4, 0, 20), trying to register it.
19:20:54 WORKER: registered result for job (4, 0, 20) with dispatcher
19:20:54 DISPATCHER: job (4, 0, 20) finished
19:20:54 DISPATCHER: register_result: lock acquired
19:20:54 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:20:54 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.01244968541077741, 'num_filters_1': 41, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.04416087202766}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3471740068611024, 'info': {'data03': 0.3471740068611024, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.01244968541077741, 'num_filters_1': 41, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.04416087202766}"}}
exception: None

19:20:54 job_callback for (4, 0, 20) started
19:20:54 DISPATCHER: Trying to submit another job.
19:20:54 job_callback for (4, 0, 20) got condition
19:20:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:20:54 done building a new model for budget 44.444444 based on 17/40 split
Best loss for this budget:-0.466954





19:20:54 HBMASTER: Trying to run another job!
19:20:54 job_callback for (4, 0, 20) finished
19:20:54 start sampling a new configuration.
19:20:54 done sampling a new configuration.
19:20:54 HBMASTER: schedule new run for iteration 4
19:20:54 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
19:20:54 HBMASTER: submitting job (4, 0, 21) to dispatcher
19:20:54 DISPATCHER: trying to submit job (4, 0, 21)
19:20:54 DISPATCHER: trying to notify the job_runner thread.
19:20:54 HBMASTER: job (4, 0, 21) submitted to dispatcher
19:20:54 DISPATCHER: Trying to submit another job.
19:20:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:20:54 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:20:54 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:20:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:20:54 WORKER: start processing job (4, 0, 21)
19:20:54 WORKER: args: ()
19:20:54 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.039845464962606394, 'num_filters_1': 105, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.03051029650491162}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:21:27 DISPATCHER: Starting worker discovery
19:21:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:21:27 DISPATCHER: Finished worker discovery
19:22:20 WORKER: done with job (4, 0, 21), trying to register it.
19:22:20 WORKER: registered result for job (4, 0, 21) with dispatcher
19:22:20 DISPATCHER: job (4, 0, 21) finished
19:22:20 DISPATCHER: register_result: lock acquired
19:22:20 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:22:20 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.039845464962606394, 'num_filters_1': 105, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.03051029650491162}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.33266560351777125, 'info': {'data03': 0.33266560351777125, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.039845464962606394, 'num_filters_1': 105, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.03051029650491162}"}}
exception: None

19:22:20 job_callback for (4, 0, 21) started
19:22:20 DISPATCHER: Trying to submit another job.
19:22:20 job_callback for (4, 0, 21) got condition
19:22:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:22:20 done building a new model for budget 44.444444 based on 17/41 split
Best loss for this budget:-0.466954





19:22:20 HBMASTER: Trying to run another job!
19:22:20 job_callback for (4, 0, 21) finished
19:22:20 start sampling a new configuration.
19:22:20 best_vector: [3, 1, 0.8311378214982154, 0.6029595496390425, 0.4208510191929714, 1, 0.8977661851309964, 0.10354488230154879, 2, 0, 0, 2, 0.09871616946608847, 0.06634558909266297, 0.015290176712625114, 0.9223567348115725], 0.00019982279663219077, 2.2845579082500175e-05, 4.565067502947064e-09
19:22:20 done sampling a new configuration.
19:22:20 HBMASTER: schedule new run for iteration 4
19:22:20 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
19:22:20 HBMASTER: submitting job (4, 0, 22) to dispatcher
19:22:20 DISPATCHER: trying to submit job (4, 0, 22)
19:22:20 DISPATCHER: trying to notify the job_runner thread.
19:22:20 HBMASTER: job (4, 0, 22) submitted to dispatcher
19:22:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:22:20 DISPATCHER: Trying to submit another job.
19:22:20 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:22:20 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:22:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:22:20 WORKER: start processing job (4, 0, 22)
19:22:20 WORKER: args: ()
19:22:20 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.04594895544012547, 'num_filters_1': 55, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.013636879337500168, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 19, 'num_filters_3': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:22:27 DISPATCHER: Starting worker discovery
19:22:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:22:27 DISPATCHER: Finished worker discovery
19:23:27 DISPATCHER: Starting worker discovery
19:23:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:23:27 DISPATCHER: Finished worker discovery
19:23:44 WORKER: done with job (4, 0, 22), trying to register it.
19:23:44 WORKER: registered result for job (4, 0, 22) with dispatcher
19:23:44 DISPATCHER: job (4, 0, 22) finished
19:23:44 DISPATCHER: register_result: lock acquired
19:23:44 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:23:44 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.04594895544012547, 'num_filters_1': 55, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.013636879337500168, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 19, 'num_filters_3': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2568179343078005, 'info': {'data03': 0.2568179343078005, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.04594895544012547, 'num_filters_1': 55, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.013636879337500168, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 19, 'num_filters_3': 18}"}}
exception: None

19:23:44 job_callback for (4, 0, 22) started
19:23:44 job_callback for (4, 0, 22) got condition
19:23:44 DISPATCHER: Trying to submit another job.
19:23:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:23:44 done building a new model for budget 44.444444 based on 17/42 split
Best loss for this budget:-0.466954





19:23:44 HBMASTER: Trying to run another job!
19:23:44 job_callback for (4, 0, 22) finished
19:23:44 start sampling a new configuration.
19:23:44 best_vector: [0, 2, 0.2918884507657535, 0.011720600443966167, 0.11161782061088199, 0, 0.9116572708628932, 0.24183520034419798, 0, 1, 0, 0, 0.3197578743361431, 0.9601225678203293, 0.7311774607434144, 0.6295278045833032], 2.6584107418389278e-28, 3.76164594982136e-05, -3.645648058347031e-06
19:23:44 done sampling a new configuration.
19:23:44 HBMASTER: schedule new run for iteration 4
19:23:44 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
19:23:44 HBMASTER: submitting job (4, 0, 23) to dispatcher
19:23:44 DISPATCHER: trying to submit job (4, 0, 23)
19:23:44 DISPATCHER: trying to notify the job_runner thread.
19:23:44 HBMASTER: job (4, 0, 23) submitted to dispatcher
19:23:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:23:44 DISPATCHER: Trying to submit another job.
19:23:44 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:23:44 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:23:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:23:44 WORKER: start processing job (4, 0, 23)
19:23:44 WORKER: args: ()
19:23:44 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.003835101844691785, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.020636443351973933}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:24:27 DISPATCHER: Starting worker discovery
19:24:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:24:27 DISPATCHER: Finished worker discovery
19:25:07 WORKER: done with job (4, 0, 23), trying to register it.
19:25:07 WORKER: registered result for job (4, 0, 23) with dispatcher
19:25:07 DISPATCHER: job (4, 0, 23) finished
19:25:07 DISPATCHER: register_result: lock acquired
19:25:07 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:25:07 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.003835101844691785, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.020636443351973933}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.27575529625989254, 'info': {'data03': 0.27575529625989254, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.003835101844691785, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.020636443351973933}"}}
exception: None

19:25:07 job_callback for (4, 0, 23) started
19:25:07 job_callback for (4, 0, 23) got condition
19:25:07 DISPATCHER: Trying to submit another job.
19:25:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:25:07 done building a new model for budget 44.444444 based on 17/43 split
Best loss for this budget:-0.466954





19:25:07 HBMASTER: Trying to run another job!
19:25:07 job_callback for (4, 0, 23) finished
19:25:07 start sampling a new configuration.
19:25:07 done sampling a new configuration.
19:25:07 HBMASTER: schedule new run for iteration 4
19:25:07 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
19:25:07 HBMASTER: submitting job (4, 0, 24) to dispatcher
19:25:07 DISPATCHER: trying to submit job (4, 0, 24)
19:25:07 DISPATCHER: trying to notify the job_runner thread.
19:25:07 HBMASTER: job (4, 0, 24) submitted to dispatcher
19:25:07 DISPATCHER: Trying to submit another job.
19:25:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:25:07 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:25:07 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:25:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:25:07 WORKER: start processing job (4, 0, 24)
19:25:07 WORKER: args: ()
19:25:07 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0010147815284980858, 'num_filters_1': 68, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.04358194817892175}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:25:27 DISPATCHER: Starting worker discovery
19:25:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:25:27 DISPATCHER: Finished worker discovery
19:26:27 DISPATCHER: Starting worker discovery
19:26:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:26:27 DISPATCHER: Finished worker discovery
19:26:31 WORKER: done with job (4, 0, 24), trying to register it.
19:26:31 WORKER: registered result for job (4, 0, 24) with dispatcher
19:26:31 DISPATCHER: job (4, 0, 24) finished
19:26:31 DISPATCHER: register_result: lock acquired
19:26:31 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:26:31 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0010147815284980858, 'num_filters_1': 68, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.04358194817892175}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3648293769457315, 'info': {'data03': 0.3648293769457315, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0010147815284980858, 'num_filters_1': 68, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.04358194817892175}"}}
exception: None

19:26:31 job_callback for (4, 0, 24) started
19:26:31 job_callback for (4, 0, 24) got condition
19:26:31 DISPATCHER: Trying to submit another job.
19:26:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:26:31 done building a new model for budget 44.444444 based on 17/44 split
Best loss for this budget:-0.466954





19:26:31 HBMASTER: Trying to run another job!
19:26:31 job_callback for (4, 0, 24) finished
19:26:31 start sampling a new configuration.
19:26:31 done sampling a new configuration.
19:26:31 HBMASTER: schedule new run for iteration 4
19:26:31 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
19:26:31 HBMASTER: submitting job (4, 0, 25) to dispatcher
19:26:31 DISPATCHER: trying to submit job (4, 0, 25)
19:26:31 DISPATCHER: trying to notify the job_runner thread.
19:26:31 HBMASTER: job (4, 0, 25) submitted to dispatcher
19:26:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:26:31 DISPATCHER: Trying to submit another job.
19:26:31 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:26:31 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:26:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:26:31 WORKER: start processing job (4, 0, 25)
19:26:31 WORKER: args: ()
19:26:31 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0374478593038737, 'num_filters_1': 70, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.1901493750442296, 'kernel_size_2': 3, 'num_filters_2': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:27:27 DISPATCHER: Starting worker discovery
19:27:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:27:27 DISPATCHER: Finished worker discovery
19:27:55 WORKER: done with job (4, 0, 25), trying to register it.
19:27:55 WORKER: registered result for job (4, 0, 25) with dispatcher
19:27:55 DISPATCHER: job (4, 0, 25) finished
19:27:55 DISPATCHER: register_result: lock acquired
19:27:55 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:27:55 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0374478593038737, 'num_filters_1': 70, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.1901493750442296, 'kernel_size_2': 3, 'num_filters_2': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.24413357560645657, 'info': {'data03': 0.24413357560645657, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0374478593038737, 'num_filters_1': 70, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.1901493750442296, 'kernel_size_2': 3, 'num_filters_2': 17}"}}
exception: None

19:27:55 job_callback for (4, 0, 25) started
19:27:55 job_callback for (4, 0, 25) got condition
19:27:55 DISPATCHER: Trying to submit another job.
19:27:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:27:55 done building a new model for budget 44.444444 based on 17/45 split
Best loss for this budget:-0.466954





19:27:55 HBMASTER: Trying to run another job!
19:27:55 job_callback for (4, 0, 25) finished
19:27:55 start sampling a new configuration.
19:27:55 best_vector: [3, 0, 0.027371766035067108, 0.3549922662106062, 0.15714634538364824, 0, 0.5175309521709683, 0.18223970096813996, 2, 2, 0, 1, 0.02892685165070541, 0.6709511761008762, 0.38004068902909943, 0.8374889714715287], 0.0013170550947889117, 0.0004209965100714567, 5.544755984779634e-07
19:27:55 done sampling a new configuration.
19:27:55 HBMASTER: schedule new run for iteration 4
19:27:55 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
19:27:55 HBMASTER: submitting job (4, 0, 26) to dispatcher
19:27:55 DISPATCHER: trying to submit job (4, 0, 26)
19:27:55 DISPATCHER: trying to notify the job_runner thread.
19:27:55 HBMASTER: job (4, 0, 26) submitted to dispatcher
19:27:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:27:55 DISPATCHER: Trying to submit another job.
19:27:55 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:27:55 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:27:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:27:55 WORKER: start processing job (4, 0, 26)
19:27:55 WORKER: args: ()
19:27:55 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001134340745127703, 'num_filters_1': 33, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.017262326132487436}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:28:27 DISPATCHER: Starting worker discovery
19:28:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:28:27 DISPATCHER: Finished worker discovery
19:29:17 WORKER: done with job (4, 0, 26), trying to register it.
19:29:17 WORKER: registered result for job (4, 0, 26) with dispatcher
19:29:17 DISPATCHER: job (4, 0, 26) finished
19:29:17 DISPATCHER: register_result: lock acquired
19:29:17 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:29:17 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001134340745127703, 'num_filters_1': 33, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.017262326132487436}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.44048305964704093, 'info': {'data03': 0.44048305964704093, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001134340745127703, 'num_filters_1': 33, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.017262326132487436}"}}
exception: None

19:29:17 job_callback for (4, 0, 26) started
19:29:17 DISPATCHER: Trying to submit another job.
19:29:17 job_callback for (4, 0, 26) got condition
19:29:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:29:17 done building a new model for budget 44.444444 based on 17/45 split
Best loss for this budget:-0.466954





19:29:17 HBMASTER: Trying to run another job!
19:29:17 job_callback for (4, 0, 26) finished
19:29:17 ITERATION: Advancing config (4, 0, 2) to next budget 133.333333
19:29:17 ITERATION: Advancing config (4, 0, 5) to next budget 133.333333
19:29:17 ITERATION: Advancing config (4, 0, 11) to next budget 133.333333
19:29:17 ITERATION: Advancing config (4, 0, 13) to next budget 133.333333
19:29:17 ITERATION: Advancing config (4, 0, 14) to next budget 133.333333
19:29:17 ITERATION: Advancing config (4, 0, 15) to next budget 133.333333
19:29:17 ITERATION: Advancing config (4, 0, 20) to next budget 133.333333
19:29:17 ITERATION: Advancing config (4, 0, 24) to next budget 133.333333
19:29:17 ITERATION: Advancing config (4, 0, 26) to next budget 133.333333
19:29:17 HBMASTER: schedule new run for iteration 4
19:29:17 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
19:29:17 HBMASTER: submitting job (4, 0, 2) to dispatcher
19:29:17 DISPATCHER: trying to submit job (4, 0, 2)
19:29:17 DISPATCHER: trying to notify the job_runner thread.
19:29:17 HBMASTER: job (4, 0, 2) submitted to dispatcher
19:29:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:29:17 DISPATCHER: Trying to submit another job.
19:29:17 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:29:17 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:29:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:29:17 WORKER: start processing job (4, 0, 2)
19:29:17 WORKER: args: ()
19:29:17 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004508643708707877, 'num_filters_1': 127, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.058182601930580856, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 93, 'num_filters_3': 115}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:29:27 DISPATCHER: Starting worker discovery
19:29:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:29:27 DISPATCHER: Finished worker discovery
19:30:27 DISPATCHER: Starting worker discovery
19:30:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:30:27 DISPATCHER: Finished worker discovery
19:31:27 DISPATCHER: Starting worker discovery
19:31:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:31:27 DISPATCHER: Finished worker discovery
19:32:10 WORKER: done with job (4, 0, 2), trying to register it.
19:32:10 WORKER: registered result for job (4, 0, 2) with dispatcher
19:32:10 DISPATCHER: job (4, 0, 2) finished
19:32:10 DISPATCHER: register_result: lock acquired
19:32:10 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:32:10 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004508643708707877, 'num_filters_1': 127, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.058182601930580856, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 93, 'num_filters_3': 115}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3756446512073552, 'info': {'data03': 0.3756446512073552, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004508643708707877, 'num_filters_1': 127, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.058182601930580856, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 93, 'num_filters_3': 115}"}}
exception: None

19:32:10 job_callback for (4, 0, 2) started
19:32:10 DISPATCHER: Trying to submit another job.
19:32:10 job_callback for (4, 0, 2) got condition
19:32:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:32:10 HBMASTER: Trying to run another job!
19:32:10 job_callback for (4, 0, 2) finished
19:32:10 HBMASTER: schedule new run for iteration 4
19:32:10 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
19:32:10 HBMASTER: submitting job (4, 0, 5) to dispatcher
19:32:10 DISPATCHER: trying to submit job (4, 0, 5)
19:32:10 DISPATCHER: trying to notify the job_runner thread.
19:32:10 HBMASTER: job (4, 0, 5) submitted to dispatcher
19:32:10 DISPATCHER: Trying to submit another job.
19:32:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:32:10 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:32:10 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:32:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:32:10 WORKER: start processing job (4, 0, 5)
19:32:10 WORKER: args: ()
19:32:10 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.055632181902124066, 'num_filters_1': 95, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.18656043062398547}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:32:27 DISPATCHER: Starting worker discovery
19:32:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:32:27 DISPATCHER: Finished worker discovery
19:33:27 DISPATCHER: Starting worker discovery
19:33:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:33:27 DISPATCHER: Finished worker discovery
19:34:27 DISPATCHER: Starting worker discovery
19:34:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:34:27 DISPATCHER: Finished worker discovery
19:35:02 WORKER: done with job (4, 0, 5), trying to register it.
19:35:02 WORKER: registered result for job (4, 0, 5) with dispatcher
19:35:02 DISPATCHER: job (4, 0, 5) finished
19:35:02 DISPATCHER: register_result: lock acquired
19:35:02 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:35:02 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.055632181902124066, 'num_filters_1': 95, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.18656043062398547}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.23071255853640776, 'info': {'data03': 0.23071255853640776, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.055632181902124066, 'num_filters_1': 95, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.18656043062398547}"}}
exception: None

19:35:02 job_callback for (4, 0, 5) started
19:35:02 job_callback for (4, 0, 5) got condition
19:35:02 DISPATCHER: Trying to submit another job.
19:35:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:35:02 HBMASTER: Trying to run another job!
19:35:02 job_callback for (4, 0, 5) finished
19:35:02 HBMASTER: schedule new run for iteration 4
19:35:02 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
19:35:02 HBMASTER: submitting job (4, 0, 11) to dispatcher
19:35:02 DISPATCHER: trying to submit job (4, 0, 11)
19:35:02 DISPATCHER: trying to notify the job_runner thread.
19:35:02 HBMASTER: job (4, 0, 11) submitted to dispatcher
19:35:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:35:02 DISPATCHER: Trying to submit another job.
19:35:02 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:35:02 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:35:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:35:02 WORKER: start processing job (4, 0, 11)
19:35:02 WORKER: args: ()
19:35:02 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0017627778195941665, 'num_filters_1': 42, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.09630677676626977, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 28, 'num_filters_3': 101, 'num_filters_4': 51, 'num_filters_5': 92}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:35:27 DISPATCHER: Starting worker discovery
19:35:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:35:27 DISPATCHER: Finished worker discovery
19:36:27 DISPATCHER: Starting worker discovery
19:36:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:36:27 DISPATCHER: Finished worker discovery
19:37:27 DISPATCHER: Starting worker discovery
19:37:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:37:27 DISPATCHER: Finished worker discovery
19:37:56 WORKER: done with job (4, 0, 11), trying to register it.
19:37:56 WORKER: registered result for job (4, 0, 11) with dispatcher
19:37:56 DISPATCHER: job (4, 0, 11) finished
19:37:56 DISPATCHER: register_result: lock acquired
19:37:56 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:37:56 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0017627778195941665, 'num_filters_1': 42, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.09630677676626977, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 28, 'num_filters_3': 101, 'num_filters_4': 51, 'num_filters_5': 92}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3669963156522394, 'info': {'data03': 0.3669963156522394, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0017627778195941665, 'num_filters_1': 42, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.09630677676626977, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 28, 'num_filters_3': 101, 'num_filters_4': 51, 'num_filters_5': 92}"}}
exception: None

19:37:56 job_callback for (4, 0, 11) started
19:37:56 DISPATCHER: Trying to submit another job.
19:37:56 job_callback for (4, 0, 11) got condition
19:37:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:37:56 HBMASTER: Trying to run another job!
19:37:56 job_callback for (4, 0, 11) finished
19:37:56 HBMASTER: schedule new run for iteration 4
19:37:56 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
19:37:56 HBMASTER: submitting job (4, 0, 13) to dispatcher
19:37:56 DISPATCHER: trying to submit job (4, 0, 13)
19:37:56 DISPATCHER: trying to notify the job_runner thread.
19:37:56 HBMASTER: job (4, 0, 13) submitted to dispatcher
19:37:56 DISPATCHER: Trying to submit another job.
19:37:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:37:56 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:37:56 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:37:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:37:56 WORKER: start processing job (4, 0, 13)
19:37:56 WORKER: args: ()
19:37:56 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003098456729484919, 'num_filters_1': 123, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.015687521871165597}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:38:27 DISPATCHER: Starting worker discovery
19:38:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:38:27 DISPATCHER: Finished worker discovery
19:39:27 DISPATCHER: Starting worker discovery
19:39:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:39:27 DISPATCHER: Finished worker discovery
19:40:27 DISPATCHER: Starting worker discovery
19:40:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:40:27 DISPATCHER: Finished worker discovery
19:40:47 WORKER: done with job (4, 0, 13), trying to register it.
19:40:47 WORKER: registered result for job (4, 0, 13) with dispatcher
19:40:47 DISPATCHER: job (4, 0, 13) finished
19:40:47 DISPATCHER: register_result: lock acquired
19:40:47 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:40:47 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003098456729484919, 'num_filters_1': 123, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.015687521871165597}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.34741557082272134, 'info': {'data03': 0.34741557082272134, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003098456729484919, 'num_filters_1': 123, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.015687521871165597}"}}
exception: None

19:40:47 job_callback for (4, 0, 13) started
19:40:47 job_callback for (4, 0, 13) got condition
19:40:47 DISPATCHER: Trying to submit another job.
19:40:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:40:47 HBMASTER: Trying to run another job!
19:40:47 job_callback for (4, 0, 13) finished
19:40:47 HBMASTER: schedule new run for iteration 4
19:40:47 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
19:40:47 HBMASTER: submitting job (4, 0, 14) to dispatcher
19:40:47 DISPATCHER: trying to submit job (4, 0, 14)
19:40:47 DISPATCHER: trying to notify the job_runner thread.
19:40:47 HBMASTER: job (4, 0, 14) submitted to dispatcher
19:40:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:40:47 DISPATCHER: Trying to submit another job.
19:40:47 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:40:47 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:40:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:40:47 WORKER: start processing job (4, 0, 14)
19:40:47 WORKER: args: ()
19:40:47 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.017188307458463687, 'num_filters_1': 81, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.01182783281362458, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 24, 'num_filters_3': 18, 'num_filters_4': 38, 'num_filters_5': 67}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:41:27 DISPATCHER: Starting worker discovery
19:41:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:41:27 DISPATCHER: Finished worker discovery
19:42:27 DISPATCHER: Starting worker discovery
19:42:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:42:27 DISPATCHER: Finished worker discovery
19:43:27 DISPATCHER: Starting worker discovery
19:43:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:43:27 DISPATCHER: Finished worker discovery
19:43:43 WORKER: done with job (4, 0, 14), trying to register it.
19:43:43 WORKER: registered result for job (4, 0, 14) with dispatcher
19:43:43 DISPATCHER: job (4, 0, 14) finished
19:43:43 DISPATCHER: register_result: lock acquired
19:43:43 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:43:43 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.017188307458463687, 'num_filters_1': 81, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.01182783281362458, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 24, 'num_filters_3': 18, 'num_filters_4': 38, 'num_filters_5': 67}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4296595387985665, 'info': {'data03': 0.4296595387985665, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.017188307458463687, 'num_filters_1': 81, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.01182783281362458, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 24, 'num_filters_3': 18, 'num_filters_4': 38, 'num_filters_5': 67}"}}
exception: None

19:43:43 job_callback for (4, 0, 14) started
19:43:43 DISPATCHER: Trying to submit another job.
19:43:43 job_callback for (4, 0, 14) got condition
19:43:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:43:43 HBMASTER: Trying to run another job!
19:43:43 job_callback for (4, 0, 14) finished
19:43:43 HBMASTER: schedule new run for iteration 4
19:43:43 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
19:43:43 HBMASTER: submitting job (4, 0, 15) to dispatcher
19:43:43 DISPATCHER: trying to submit job (4, 0, 15)
19:43:43 DISPATCHER: trying to notify the job_runner thread.
19:43:43 HBMASTER: job (4, 0, 15) submitted to dispatcher
19:43:43 DISPATCHER: Trying to submit another job.
19:43:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:43:43 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:43:43 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:43:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:43:43 WORKER: start processing job (4, 0, 15)
19:43:43 WORKER: args: ()
19:43:43 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.002088289197330835, 'num_filters_1': 83, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 53, 'weight_decay': 0.014464569271193353}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:44:27 DISPATCHER: Starting worker discovery
19:44:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:44:27 DISPATCHER: Finished worker discovery
19:45:27 DISPATCHER: Starting worker discovery
19:45:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:45:27 DISPATCHER: Finished worker discovery
19:46:27 DISPATCHER: Starting worker discovery
19:46:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:46:27 DISPATCHER: Finished worker discovery
19:46:37 WORKER: done with job (4, 0, 15), trying to register it.
19:46:37 WORKER: registered result for job (4, 0, 15) with dispatcher
19:46:37 DISPATCHER: job (4, 0, 15) finished
19:46:37 DISPATCHER: register_result: lock acquired
19:46:37 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:46:37 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.002088289197330835, 'num_filters_1': 83, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 53, 'weight_decay': 0.014464569271193353}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2942704853997688, 'info': {'data03': 0.2942704853997688, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.002088289197330835, 'num_filters_1': 83, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 53, 'weight_decay': 0.014464569271193353}"}}
exception: None

19:46:37 job_callback for (4, 0, 15) started
19:46:37 DISPATCHER: Trying to submit another job.
19:46:37 job_callback for (4, 0, 15) got condition
19:46:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:46:37 HBMASTER: Trying to run another job!
19:46:37 job_callback for (4, 0, 15) finished
19:46:37 HBMASTER: schedule new run for iteration 4
19:46:37 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
19:46:37 HBMASTER: submitting job (4, 0, 20) to dispatcher
19:46:37 DISPATCHER: trying to submit job (4, 0, 20)
19:46:37 DISPATCHER: trying to notify the job_runner thread.
19:46:37 HBMASTER: job (4, 0, 20) submitted to dispatcher
19:46:37 DISPATCHER: Trying to submit another job.
19:46:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:46:37 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:46:37 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:46:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:46:37 WORKER: start processing job (4, 0, 20)
19:46:37 WORKER: args: ()
19:46:37 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.01244968541077741, 'num_filters_1': 41, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.04416087202766}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:47:27 DISPATCHER: Starting worker discovery
19:47:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:47:27 DISPATCHER: Finished worker discovery
19:48:27 DISPATCHER: Starting worker discovery
19:48:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:48:27 DISPATCHER: Finished worker discovery
19:49:27 DISPATCHER: Starting worker discovery
19:49:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:49:27 DISPATCHER: Finished worker discovery
19:49:29 WORKER: done with job (4, 0, 20), trying to register it.
19:49:29 WORKER: registered result for job (4, 0, 20) with dispatcher
19:49:29 DISPATCHER: job (4, 0, 20) finished
19:49:29 DISPATCHER: register_result: lock acquired
19:49:29 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:49:29 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.01244968541077741, 'num_filters_1': 41, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.04416087202766}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2887403514505073, 'info': {'data03': 0.2887403514505073, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.01244968541077741, 'num_filters_1': 41, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.04416087202766}"}}
exception: None

19:49:29 job_callback for (4, 0, 20) started
19:49:29 job_callback for (4, 0, 20) got condition
19:49:29 DISPATCHER: Trying to submit another job.
19:49:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:49:29 HBMASTER: Trying to run another job!
19:49:29 job_callback for (4, 0, 20) finished
19:49:29 HBMASTER: schedule new run for iteration 4
19:49:29 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
19:49:29 HBMASTER: submitting job (4, 0, 24) to dispatcher
19:49:29 DISPATCHER: trying to submit job (4, 0, 24)
19:49:29 DISPATCHER: trying to notify the job_runner thread.
19:49:29 HBMASTER: job (4, 0, 24) submitted to dispatcher
19:49:29 DISPATCHER: Trying to submit another job.
19:49:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:49:29 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:49:29 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:49:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:49:29 WORKER: start processing job (4, 0, 24)
19:49:29 WORKER: args: ()
19:49:29 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0010147815284980858, 'num_filters_1': 68, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.04358194817892175}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:50:27 DISPATCHER: Starting worker discovery
19:50:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:50:27 DISPATCHER: Finished worker discovery
19:51:27 DISPATCHER: Starting worker discovery
19:51:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:51:27 DISPATCHER: Finished worker discovery
19:52:22 WORKER: done with job (4, 0, 24), trying to register it.
19:52:22 WORKER: registered result for job (4, 0, 24) with dispatcher
19:52:22 DISPATCHER: job (4, 0, 24) finished
19:52:22 DISPATCHER: register_result: lock acquired
19:52:22 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:52:22 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0010147815284980858, 'num_filters_1': 68, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.04358194817892175}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3574074029271929, 'info': {'data03': 0.3574074029271929, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0010147815284980858, 'num_filters_1': 68, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.04358194817892175}"}}
exception: None

19:52:22 job_callback for (4, 0, 24) started
19:52:22 DISPATCHER: Trying to submit another job.
19:52:22 job_callback for (4, 0, 24) got condition
19:52:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:52:22 HBMASTER: Trying to run another job!
19:52:22 job_callback for (4, 0, 24) finished
19:52:22 HBMASTER: schedule new run for iteration 4
19:52:22 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
19:52:22 HBMASTER: submitting job (4, 0, 26) to dispatcher
19:52:22 DISPATCHER: trying to submit job (4, 0, 26)
19:52:22 DISPATCHER: trying to notify the job_runner thread.
19:52:22 HBMASTER: job (4, 0, 26) submitted to dispatcher
19:52:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:52:22 DISPATCHER: Trying to submit another job.
19:52:22 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:52:22 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:52:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:52:22 WORKER: start processing job (4, 0, 26)
19:52:22 WORKER: args: ()
19:52:22 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001134340745127703, 'num_filters_1': 33, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.017262326132487436}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:52:27 DISPATCHER: Starting worker discovery
19:52:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:52:27 DISPATCHER: Finished worker discovery
19:53:27 DISPATCHER: Starting worker discovery
19:53:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:53:27 DISPATCHER: Finished worker discovery
19:54:27 DISPATCHER: Starting worker discovery
19:54:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:54:27 DISPATCHER: Finished worker discovery
19:55:16 WORKER: done with job (4, 0, 26), trying to register it.
19:55:16 WORKER: registered result for job (4, 0, 26) with dispatcher
19:55:16 DISPATCHER: job (4, 0, 26) finished
19:55:16 DISPATCHER: register_result: lock acquired
19:55:16 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:55:16 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001134340745127703, 'num_filters_1': 33, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.017262326132487436}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.41080767331657875, 'info': {'data03': 0.41080767331657875, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001134340745127703, 'num_filters_1': 33, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.017262326132487436}"}}
exception: None

19:55:16 job_callback for (4, 0, 26) started
19:55:16 DISPATCHER: Trying to submit another job.
19:55:16 job_callback for (4, 0, 26) got condition
19:55:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:55:16 HBMASTER: Trying to run another job!
19:55:16 job_callback for (4, 0, 26) finished
19:55:16 ITERATION: Advancing config (4, 0, 2) to next budget 400.000000
19:55:16 ITERATION: Advancing config (4, 0, 14) to next budget 400.000000
19:55:16 ITERATION: Advancing config (4, 0, 26) to next budget 400.000000
19:55:16 HBMASTER: schedule new run for iteration 4
19:55:16 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
19:55:16 HBMASTER: submitting job (4, 0, 2) to dispatcher
19:55:16 DISPATCHER: trying to submit job (4, 0, 2)
19:55:16 DISPATCHER: trying to notify the job_runner thread.
19:55:16 HBMASTER: job (4, 0, 2) submitted to dispatcher
19:55:16 DISPATCHER: Trying to submit another job.
19:55:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:55:16 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:55:16 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:55:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:55:16 WORKER: start processing job (4, 0, 2)
19:55:16 WORKER: args: ()
19:55:16 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004508643708707877, 'num_filters_1': 127, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.058182601930580856, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 93, 'num_filters_3': 115}, 'budget': 400.0, 'working_directory': '.'}
19:55:27 DISPATCHER: Starting worker discovery
19:55:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:55:27 DISPATCHER: Finished worker discovery
19:56:27 DISPATCHER: Starting worker discovery
19:56:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:56:27 DISPATCHER: Finished worker discovery
19:57:27 DISPATCHER: Starting worker discovery
19:57:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:57:27 DISPATCHER: Finished worker discovery
19:58:27 DISPATCHER: Starting worker discovery
19:58:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:58:27 DISPATCHER: Finished worker discovery
19:59:27 DISPATCHER: Starting worker discovery
19:59:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:59:27 DISPATCHER: Finished worker discovery
20:00:27 DISPATCHER: Starting worker discovery
20:00:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:00:27 DISPATCHER: Finished worker discovery
20:01:27 DISPATCHER: Starting worker discovery
20:01:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:01:27 DISPATCHER: Finished worker discovery
20:02:27 DISPATCHER: Starting worker discovery
20:02:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:02:27 DISPATCHER: Finished worker discovery
20:02:38 WORKER: done with job (4, 0, 2), trying to register it.
20:02:38 WORKER: registered result for job (4, 0, 2) with dispatcher
20:02:38 DISPATCHER: job (4, 0, 2) finished
20:02:38 DISPATCHER: register_result: lock acquired
20:02:38 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
20:02:38 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004508643708707877, 'num_filters_1': 127, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.058182601930580856, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 93, 'num_filters_3': 115}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3540664875259655, 'info': {'data03': 0.3540664875259655, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004508643708707877, 'num_filters_1': 127, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.058182601930580856, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 93, 'num_filters_3': 115}"}}
exception: None

20:02:38 job_callback for (4, 0, 2) started
20:02:38 job_callback for (4, 0, 2) got condition
20:02:38 DISPATCHER: Trying to submit another job.
20:02:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:02:38 Only 13 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
20:02:38 HBMASTER: Trying to run another job!
20:02:38 job_callback for (4, 0, 2) finished
20:02:38 HBMASTER: schedule new run for iteration 4
20:02:38 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
20:02:38 HBMASTER: submitting job (4, 0, 14) to dispatcher
20:02:38 DISPATCHER: trying to submit job (4, 0, 14)
20:02:38 DISPATCHER: trying to notify the job_runner thread.
20:02:38 HBMASTER: job (4, 0, 14) submitted to dispatcher
20:02:38 DISPATCHER: Trying to submit another job.
20:02:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:02:38 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776
20:02:38 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
20:02:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:02:38 WORKER: start processing job (4, 0, 14)
20:02:38 WORKER: args: ()
20:02:38 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.017188307458463687, 'num_filters_1': 81, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.01182783281362458, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 24, 'num_filters_3': 18, 'num_filters_4': 38, 'num_filters_5': 67}, 'budget': 400.0, 'working_directory': '.'}
20:03:27 DISPATCHER: Starting worker discovery
20:03:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:03:27 DISPATCHER: Finished worker discovery
20:04:27 DISPATCHER: Starting worker discovery
20:04:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:04:27 DISPATCHER: Finished worker discovery
20:05:27 DISPATCHER: Starting worker discovery
20:05:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:05:27 DISPATCHER: Finished worker discovery
20:06:27 DISPATCHER: Starting worker discovery
20:06:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:06:27 DISPATCHER: Finished worker discovery
20:07:27 DISPATCHER: Starting worker discovery
20:07:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:07:27 DISPATCHER: Finished worker discovery
20:08:27 DISPATCHER: Starting worker discovery
20:08:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:08:27 DISPATCHER: Finished worker discovery
20:09:27 DISPATCHER: Starting worker discovery
20:09:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:09:28 DISPATCHER: Finished worker discovery
20:09:58 WORKER: done with job (4, 0, 14), trying to register it.
20:09:58 WORKER: registered result for job (4, 0, 14) with dispatcher
20:09:58 DISPATCHER: job (4, 0, 14) finished
20:09:58 DISPATCHER: register_result: lock acquired
20:09:58 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
20:09:58 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.017188307458463687, 'num_filters_1': 81, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.01182783281362458, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 24, 'num_filters_3': 18, 'num_filters_4': 38, 'num_filters_5': 67}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3477003432245929, 'info': {'data03': 0.3477003432245929, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.017188307458463687, 'num_filters_1': 81, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.01182783281362458, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 24, 'num_filters_3': 18, 'num_filters_4': 38, 'num_filters_5': 67}"}}
exception: None

20:09:58 job_callback for (4, 0, 14) started
20:09:58 job_callback for (4, 0, 14) got condition
20:09:58 DISPATCHER: Trying to submit another job.
20:09:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:09:58 Only 14 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
20:09:58 HBMASTER: Trying to run another job!
20:09:58 job_callback for (4, 0, 14) finished
20:09:58 HBMASTER: schedule new run for iteration 4
20:09:58 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
20:09:58 HBMASTER: submitting job (4, 0, 26) to dispatcher
20:09:58 DISPATCHER: trying to submit job (4, 0, 26)
20:09:58 DISPATCHER: trying to notify the job_runner thread.
20:09:58 HBMASTER: job (4, 0, 26) submitted to dispatcher
20:09:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:09:58 DISPATCHER: Trying to submit another job.
20:09:58 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpui.1576139975513683776
20:09:58 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
20:09:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:09:58 WORKER: start processing job (4, 0, 26)
20:09:58 WORKER: args: ()
20:09:58 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001134340745127703, 'num_filters_1': 33, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.017262326132487436}, 'budget': 400.0, 'working_directory': '.'}
20:10:28 DISPATCHER: Starting worker discovery
20:10:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:10:28 DISPATCHER: Finished worker discovery
20:11:28 DISPATCHER: Starting worker discovery
20:11:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:11:28 DISPATCHER: Finished worker discovery
20:12:28 DISPATCHER: Starting worker discovery
20:12:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:12:28 DISPATCHER: Finished worker discovery
20:13:28 DISPATCHER: Starting worker discovery
20:13:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:13:28 DISPATCHER: Finished worker discovery
20:14:28 DISPATCHER: Starting worker discovery
20:14:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:14:28 DISPATCHER: Finished worker discovery
20:15:28 DISPATCHER: Starting worker discovery
20:15:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:15:28 DISPATCHER: Finished worker discovery
20:16:28 DISPATCHER: Starting worker discovery
20:16:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:16:28 DISPATCHER: Finished worker discovery
20:17:19 WORKER: done with job (4, 0, 26), trying to register it.
20:17:19 WORKER: registered result for job (4, 0, 26) with dispatcher
20:17:19 DISPATCHER: job (4, 0, 26) finished
20:17:19 DISPATCHER: register_result: lock acquired
20:17:19 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
20:17:19 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001134340745127703, 'num_filters_1': 33, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.017262326132487436}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3051027390697201, 'info': {'data03': 0.3051027390697201, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001134340745127703, 'num_filters_1': 33, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.017262326132487436}"}}
exception: None

20:17:19 job_callback for (4, 0, 26) started
20:17:19 job_callback for (4, 0, 26) got condition
20:17:19 DISPATCHER: Trying to submit another job.
20:17:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:17:19 Only 15 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
20:17:19 HBMASTER: Trying to run another job!
20:17:19 job_callback for (4, 0, 26) finished
20:17:19 ITERATION: Advancing config (4, 0, 2) to next budget 1200.000000
20:17:19 HBMASTER: schedule new run for iteration 4
20:17:19 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
20:17:19 HBMASTER: submitting job (4, 0, 2) to dispatcher
20:17:19 DISPATCHER: trying to submit job (4, 0, 2)
20:17:19 DISPATCHER: trying to notify the job_runner thread.
20:17:19 HBMASTER: job (4, 0, 2) submitted to dispatcher
20:17:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:17:19 DISPATCHER: Trying to submit another job.
20:17:19 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
20:17:19 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
20:17:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:17:19 WORKER: start processing job (4, 0, 2)
20:17:19 WORKER: args: ()
20:17:19 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004508643708707877, 'num_filters_1': 127, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.058182601930580856, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 93, 'num_filters_3': 115}, 'budget': 1200.0, 'working_directory': '.'}
20:17:28 DISPATCHER: Starting worker discovery
20:17:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:17:28 DISPATCHER: Finished worker discovery
20:18:28 DISPATCHER: Starting worker discovery
20:18:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:18:28 DISPATCHER: Finished worker discovery
20:19:28 DISPATCHER: Starting worker discovery
20:19:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:19:28 DISPATCHER: Finished worker discovery
20:20:28 DISPATCHER: Starting worker discovery
20:20:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:20:28 DISPATCHER: Finished worker discovery
20:21:28 DISPATCHER: Starting worker discovery
20:21:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:21:28 DISPATCHER: Finished worker discovery
20:22:28 DISPATCHER: Starting worker discovery
20:22:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:22:28 DISPATCHER: Finished worker discovery
20:23:28 DISPATCHER: Starting worker discovery
20:23:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:23:28 DISPATCHER: Finished worker discovery
20:24:28 DISPATCHER: Starting worker discovery
20:24:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:24:28 DISPATCHER: Finished worker discovery
20:25:28 DISPATCHER: Starting worker discovery
20:25:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:25:28 DISPATCHER: Finished worker discovery
20:26:28 DISPATCHER: Starting worker discovery
20:26:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:26:28 DISPATCHER: Finished worker discovery
20:27:28 DISPATCHER: Starting worker discovery
20:27:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:27:28 DISPATCHER: Finished worker discovery
20:28:28 DISPATCHER: Starting worker discovery
20:28:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:28:28 DISPATCHER: Finished worker discovery
20:29:28 DISPATCHER: Starting worker discovery
20:29:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:29:28 DISPATCHER: Finished worker discovery
20:30:28 DISPATCHER: Starting worker discovery
20:30:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:30:28 DISPATCHER: Finished worker discovery
20:31:28 DISPATCHER: Starting worker discovery
20:31:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:31:28 DISPATCHER: Finished worker discovery
20:32:28 DISPATCHER: Starting worker discovery
20:32:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:32:28 DISPATCHER: Finished worker discovery
20:33:28 DISPATCHER: Starting worker discovery
20:33:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:33:28 DISPATCHER: Finished worker discovery
20:34:28 DISPATCHER: Starting worker discovery
20:34:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:34:28 DISPATCHER: Finished worker discovery
20:35:28 DISPATCHER: Starting worker discovery
20:35:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:35:28 DISPATCHER: Finished worker discovery
20:36:28 DISPATCHER: Starting worker discovery
20:36:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:36:28 DISPATCHER: Finished worker discovery
20:37:28 DISPATCHER: Starting worker discovery
20:37:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:37:28 DISPATCHER: Finished worker discovery
20:38:00 WORKER: done with job (4, 0, 2), trying to register it.
20:38:00 WORKER: registered result for job (4, 0, 2) with dispatcher
20:38:00 DISPATCHER: job (4, 0, 2) finished
20:38:00 DISPATCHER: register_result: lock acquired
20:38:00 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
20:38:00 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004508643708707877, 'num_filters_1': 127, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.058182601930580856, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 93, 'num_filters_3': 115}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.3509000635511096, 'info': {'data03': 0.3509000635511096, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004508643708707877, 'num_filters_1': 127, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.058182601930580856, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 93, 'num_filters_3': 115}"}}
exception: None

20:38:00 job_callback for (4, 0, 2) started
20:38:00 job_callback for (4, 0, 2) got condition
20:38:00 DISPATCHER: Trying to submit another job.
20:38:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:38:00 Only 9 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
20:38:00 HBMASTER: Trying to run another job!
20:38:00 job_callback for (4, 0, 2) finished
20:38:00 start sampling a new configuration.
20:38:00 best_vector: [0, 0, 0.4369306484782063, 0.9432364496252078, 0.2838412982426197, 0, 0.3500769166661667, 0.5369687661567305, 1, 1, 0, 0, 0.4741019276622861, 0.5358853152837545, 0.06704721349871451, 0.9441572584187357], 0.003923222676296638, 0.0008949893404053311, 3.5112424753219657e-06
20:38:00 done sampling a new configuration.
20:38:00 HBMASTER: schedule new run for iteration 5
20:38:00 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
20:38:00 HBMASTER: submitting job (5, 0, 0) to dispatcher
20:38:00 DISPATCHER: trying to submit job (5, 0, 0)
20:38:00 DISPATCHER: trying to notify the job_runner thread.
20:38:00 HBMASTER: job (5, 0, 0) submitted to dispatcher
20:38:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:38:00 DISPATCHER: Trying to submit another job.
20:38:00 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
20:38:00 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
20:38:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:38:00 WORKER: start processing job (5, 0, 0)
20:38:00 WORKER: args: ()
20:38:00 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.007479305916104296, 'num_filters_1': 114, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.04995885445046006, 'kernel_size_2': 5, 'num_filters_2': 42}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:38:28 DISPATCHER: Starting worker discovery
20:38:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:38:28 DISPATCHER: Finished worker discovery
20:39:28 DISPATCHER: Starting worker discovery
20:39:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:39:28 DISPATCHER: Finished worker discovery
20:40:28 DISPATCHER: Starting worker discovery
20:40:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:40:28 DISPATCHER: Finished worker discovery
20:40:52 WORKER: done with job (5, 0, 0), trying to register it.
20:40:52 WORKER: registered result for job (5, 0, 0) with dispatcher
20:40:52 DISPATCHER: job (5, 0, 0) finished
20:40:52 DISPATCHER: register_result: lock acquired
20:40:52 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
20:40:52 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.007479305916104296, 'num_filters_1': 114, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.04995885445046006, 'kernel_size_2': 5, 'num_filters_2': 42}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2772484386291214, 'info': {'data03': 0.2772484386291214, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.007479305916104296, 'num_filters_1': 114, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.04995885445046006, 'kernel_size_2': 5, 'num_filters_2': 42}"}}
exception: None

20:40:52 job_callback for (5, 0, 0) started
20:40:52 job_callback for (5, 0, 0) got condition
20:40:52 DISPATCHER: Trying to submit another job.
20:40:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:40:52 HBMASTER: Trying to run another job!
20:40:52 job_callback for (5, 0, 0) finished
20:40:52 start sampling a new configuration.
20:40:52 best_vector: [0, 1, 0.4172589227072436, 0.8572096873875301, 0.2545789941213371, 0, 0.1792605452341346, 0.7139520324568246, 2, 0, 0, 0, 0.31230914826948303, 0.8057330077107755, 0.10647133841447809, 0.5579865990056972], 0.008956825490257857, 0.00017540431854683872, 1.5710658714616339e-06
20:40:52 done sampling a new configuration.
20:40:52 HBMASTER: schedule new run for iteration 5
20:40:52 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
20:40:52 HBMASTER: submitting job (5, 0, 1) to dispatcher
20:40:52 DISPATCHER: trying to submit job (5, 0, 1)
20:40:52 DISPATCHER: trying to notify the job_runner thread.
20:40:52 HBMASTER: job (5, 0, 1) submitted to dispatcher
20:40:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:40:52 DISPATCHER: Trying to submit another job.
20:40:52 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
20:40:52 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
20:40:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:40:52 WORKER: start processing job (5, 0, 1)
20:40:52 WORKER: args: ()
20:40:52 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0068315278855055435, 'num_filters_1': 95, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.08489322058773581, 'kernel_size_2': 7, 'num_filters_2': 30}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:41:28 DISPATCHER: Starting worker discovery
20:41:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:41:28 DISPATCHER: Finished worker discovery
20:42:28 DISPATCHER: Starting worker discovery
20:42:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:42:28 DISPATCHER: Finished worker discovery
20:43:28 DISPATCHER: Starting worker discovery
20:43:28 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:43:28 DISPATCHER: Finished worker discovery
20:43:42 WORKER: done with job (5, 0, 1), trying to register it.
20:43:42 WORKER: registered result for job (5, 0, 1) with dispatcher
20:43:42 DISPATCHER: job (5, 0, 1) finished
20:43:42 DISPATCHER: register_result: lock acquired
20:43:42 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
20:43:42 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0068315278855055435, 'num_filters_1': 95, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.08489322058773581, 'kernel_size_2': 7, 'num_filters_2': 30}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.17948504615220023, 'info': {'data03': 0.17948504615220023, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0068315278855055435, 'num_filters_1': 95, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.08489322058773581, 'kernel_size_2': 7, 'num_filters_2': 30}"}}
exception: None

20:43:42 job_callback for (5, 0, 1) started
20:43:42 DISPATCHER: Trying to submit another job.
20:43:42 job_callback for (5, 0, 1) got condition
20:43:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:43:42 HBMASTER: Trying to run another job!
20:43:42 job_callback for (5, 0, 1) finished
20:43:42 start sampling a new configuration.
20:43:42 done sampling a new configuration.
20:43:42 HBMASTER: schedule new run for iteration 5
20:43:42 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
20:43:42 HBMASTER: submitting job (5, 0, 2) to dispatcher
20:43:42 DISPATCHER: trying to submit job (5, 0, 2)
20:43:42 DISPATCHER: trying to notify the job_runner thread.
20:43:42 HBMASTER: job (5, 0, 2) submitted to dispatcher
20:43:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:43:42 DISPATCHER: Trying to submit another job.
20:43:42 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
20:43:42 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
20:43:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:43:42 WORKER: start processing job (5, 0, 2)
20:43:42 WORKER: args: ()
20:43:42 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0017595345931701355, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.03946703811470505, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 35, 'num_filters_3': 71, 'num_filters_4': 25, 'num_filters_5': 50}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:44:30 DISPATCHER: Starting worker discovery
20:44:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:44:30 DISPATCHER: Finished worker discovery
20:45:30 DISPATCHER: Starting worker discovery
20:45:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:45:30 DISPATCHER: Finished worker discovery
20:46:30 DISPATCHER: Starting worker discovery
20:46:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:46:30 DISPATCHER: Finished worker discovery
20:46:36 WORKER: done with job (5, 0, 2), trying to register it.
20:46:36 WORKER: registered result for job (5, 0, 2) with dispatcher
20:46:36 DISPATCHER: job (5, 0, 2) finished
20:46:36 DISPATCHER: register_result: lock acquired
20:46:36 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
20:46:36 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0017595345931701355, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.03946703811470505, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 35, 'num_filters_3': 71, 'num_filters_4': 25, 'num_filters_5': 50}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.30880976981561414, 'info': {'data03': 0.30880976981561414, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0017595345931701355, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.03946703811470505, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 35, 'num_filters_3': 71, 'num_filters_4': 25, 'num_filters_5': 50}"}}
exception: None

20:46:36 job_callback for (5, 0, 2) started
20:46:36 DISPATCHER: Trying to submit another job.
20:46:36 job_callback for (5, 0, 2) got condition
20:46:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:46:36 HBMASTER: Trying to run another job!
20:46:36 job_callback for (5, 0, 2) finished
20:46:36 start sampling a new configuration.
20:46:36 done sampling a new configuration.
20:46:36 HBMASTER: schedule new run for iteration 5
20:46:36 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
20:46:36 HBMASTER: submitting job (5, 0, 3) to dispatcher
20:46:36 DISPATCHER: trying to submit job (5, 0, 3)
20:46:36 DISPATCHER: trying to notify the job_runner thread.
20:46:36 HBMASTER: job (5, 0, 3) submitted to dispatcher
20:46:36 DISPATCHER: Trying to submit another job.
20:46:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:46:36 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
20:46:36 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
20:46:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:46:36 WORKER: start processing job (5, 0, 3)
20:46:36 WORKER: args: ()
20:46:36 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001325292532045633, 'num_filters_1': 31, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.06759376583379614, 'kernel_size_2': 5, 'num_filters_2': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:47:30 DISPATCHER: Starting worker discovery
20:47:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:47:30 DISPATCHER: Finished worker discovery
20:48:30 DISPATCHER: Starting worker discovery
20:48:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:48:30 DISPATCHER: Finished worker discovery
20:49:30 WORKER: done with job (5, 0, 3), trying to register it.
20:49:30 DISPATCHER: Starting worker discovery
20:49:30 WORKER: registered result for job (5, 0, 3) with dispatcher
20:49:30 DISPATCHER: job (5, 0, 3) finished
20:49:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:49:30 DISPATCHER: Finished worker discovery
20:49:30 DISPATCHER: register_result: lock acquired
20:49:30 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
20:49:30 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001325292532045633, 'num_filters_1': 31, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.06759376583379614, 'kernel_size_2': 5, 'num_filters_2': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3363659701243684, 'info': {'data03': 0.3363659701243684, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001325292532045633, 'num_filters_1': 31, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.06759376583379614, 'kernel_size_2': 5, 'num_filters_2': 43}"}}
exception: None

20:49:30 job_callback for (5, 0, 3) started
20:49:30 job_callback for (5, 0, 3) got condition
20:49:30 DISPATCHER: Trying to submit another job.
20:49:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:49:30 HBMASTER: Trying to run another job!
20:49:30 job_callback for (5, 0, 3) finished
20:49:30 start sampling a new configuration.
20:49:30 best_vector: [0, 1, 0.7432012720726761, 0.9841360446028322, 0.24992216204657444, 1, 0.5856879791970693, 0.34311856875692215, 2, 2, 0, 2, 0.5034733802726937, 0.9748675850184699, 0.20077901073271243, 0.9640765427038249], 0.006084254896936697, 0.00013790459700401602, 8.390467196317662e-07
20:49:30 done sampling a new configuration.
20:49:30 HBMASTER: schedule new run for iteration 5
20:49:30 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
20:49:30 HBMASTER: submitting job (5, 0, 4) to dispatcher
20:49:30 DISPATCHER: trying to submit job (5, 0, 4)
20:49:30 DISPATCHER: trying to notify the job_runner thread.
20:49:30 HBMASTER: job (5, 0, 4) submitted to dispatcher
20:49:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:49:30 DISPATCHER: Trying to submit another job.
20:49:30 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
20:49:30 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
20:49:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:49:30 WORKER: start processing job (5, 0, 4)
20:49:30 WORKER: args: ()
20:49:30 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.030648028592732846, 'num_filters_1': 124, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.027951656463173408, 'kernel_size_2': 7, 'num_filters_2': 45}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:50:30 DISPATCHER: Starting worker discovery
20:50:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:50:30 DISPATCHER: Finished worker discovery
20:51:30 DISPATCHER: Starting worker discovery
20:51:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:51:30 DISPATCHER: Finished worker discovery
20:52:25 WORKER: done with job (5, 0, 4), trying to register it.
20:52:25 WORKER: registered result for job (5, 0, 4) with dispatcher
20:52:25 DISPATCHER: job (5, 0, 4) finished
20:52:25 DISPATCHER: register_result: lock acquired
20:52:25 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
20:52:25 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.030648028592732846, 'num_filters_1': 124, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.027951656463173408, 'kernel_size_2': 7, 'num_filters_2': 45}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.32991660580100624, 'info': {'data03': 0.32991660580100624, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.030648028592732846, 'num_filters_1': 124, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.027951656463173408, 'kernel_size_2': 7, 'num_filters_2': 45}"}}
exception: None

20:52:25 job_callback for (5, 0, 4) started
20:52:25 DISPATCHER: Trying to submit another job.
20:52:25 job_callback for (5, 0, 4) got condition
20:52:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:52:25 HBMASTER: Trying to run another job!
20:52:25 job_callback for (5, 0, 4) finished
20:52:25 start sampling a new configuration.
20:52:25 done sampling a new configuration.
20:52:25 HBMASTER: schedule new run for iteration 5
20:52:25 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
20:52:25 HBMASTER: submitting job (5, 0, 5) to dispatcher
20:52:25 DISPATCHER: trying to submit job (5, 0, 5)
20:52:25 DISPATCHER: trying to notify the job_runner thread.
20:52:25 HBMASTER: job (5, 0, 5) submitted to dispatcher
20:52:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:52:25 DISPATCHER: Trying to submit another job.
20:52:25 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
20:52:25 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
20:52:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:52:25 WORKER: start processing job (5, 0, 5)
20:52:25 WORKER: args: ()
20:52:25 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.001479767254042439, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.05643320303506362, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 18, 'num_filters_3': 101, 'num_filters_4': 123}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:52:30 DISPATCHER: Starting worker discovery
20:52:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:52:30 DISPATCHER: Finished worker discovery
20:53:30 DISPATCHER: Starting worker discovery
20:53:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:53:30 DISPATCHER: Finished worker discovery
20:54:30 DISPATCHER: Starting worker discovery
20:54:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:54:30 DISPATCHER: Finished worker discovery
20:55:17 WORKER: done with job (5, 0, 5), trying to register it.
20:55:17 WORKER: registered result for job (5, 0, 5) with dispatcher
20:55:17 DISPATCHER: job (5, 0, 5) finished
20:55:17 DISPATCHER: register_result: lock acquired
20:55:17 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
20:55:17 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.001479767254042439, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.05643320303506362, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 18, 'num_filters_3': 101, 'num_filters_4': 123}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.405050077940006, 'info': {'data03': 0.405050077940006, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.001479767254042439, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.05643320303506362, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 18, 'num_filters_3': 101, 'num_filters_4': 123}"}}
exception: None

20:55:17 job_callback for (5, 0, 5) started
20:55:17 job_callback for (5, 0, 5) got condition
20:55:17 DISPATCHER: Trying to submit another job.
20:55:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:55:17 HBMASTER: Trying to run another job!
20:55:17 job_callback for (5, 0, 5) finished
20:55:17 start sampling a new configuration.
20:55:17 done sampling a new configuration.
20:55:17 HBMASTER: schedule new run for iteration 5
20:55:17 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
20:55:17 HBMASTER: submitting job (5, 0, 6) to dispatcher
20:55:17 DISPATCHER: trying to submit job (5, 0, 6)
20:55:17 DISPATCHER: trying to notify the job_runner thread.
20:55:17 HBMASTER: job (5, 0, 6) submitted to dispatcher
20:55:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:55:17 DISPATCHER: Trying to submit another job.
20:55:17 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776
20:55:17 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
20:55:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:55:17 WORKER: start processing job (5, 0, 6)
20:55:17 WORKER: args: ()
20:55:17 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.003925973543815977, 'num_filters_1': 105, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.06177310126700071, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 87, 'num_filters_3': 115, 'num_filters_4': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:55:30 DISPATCHER: Starting worker discovery
20:55:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:55:30 DISPATCHER: Finished worker discovery
20:56:30 DISPATCHER: Starting worker discovery
20:56:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:56:30 DISPATCHER: Finished worker discovery
20:57:30 DISPATCHER: Starting worker discovery
20:57:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:57:30 DISPATCHER: Finished worker discovery
20:58:10 WORKER: done with job (5, 0, 6), trying to register it.
20:58:10 WORKER: registered result for job (5, 0, 6) with dispatcher
20:58:10 DISPATCHER: job (5, 0, 6) finished
20:58:10 DISPATCHER: register_result: lock acquired
20:58:10 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
20:58:10 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.003925973543815977, 'num_filters_1': 105, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.06177310126700071, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 87, 'num_filters_3': 115, 'num_filters_4': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3203831716847232, 'info': {'data03': 0.3203831716847232, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.003925973543815977, 'num_filters_1': 105, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.06177310126700071, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 87, 'num_filters_3': 115, 'num_filters_4': 43}"}}
exception: None

20:58:10 job_callback for (5, 0, 6) started
20:58:10 job_callback for (5, 0, 6) got condition
20:58:10 DISPATCHER: Trying to submit another job.
20:58:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:58:10 done building a new model for budget 133.333333 based on 17/28 split
Best loss for this budget:-0.433242





20:58:10 HBMASTER: Trying to run another job!
20:58:10 job_callback for (5, 0, 6) finished
20:58:10 start sampling a new configuration.
20:58:10 best_vector: [0, 1, 0.5737354978618316, 0.15175794587584313, 0.8335699565326358, 1, 0.35643182907916815, 0.4967337645921915, 0, 2, 2, 0, 0.8645665897331497, 0.6862113175426329, 0.7510639864013119, 0.39403169201795524], 4.2250334119341073e-29, 0.00023668451879584705, -5.148753719973988e-09
20:58:10 done sampling a new configuration.
20:58:10 HBMASTER: schedule new run for iteration 5
20:58:10 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
20:58:10 HBMASTER: submitting job (5, 0, 7) to dispatcher
20:58:10 DISPATCHER: trying to submit job (5, 0, 7)
20:58:10 DISPATCHER: trying to notify the job_runner thread.
20:58:10 HBMASTER: job (5, 0, 7) submitted to dispatcher
20:58:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:58:10 DISPATCHER: Trying to submit another job.
20:58:10 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776
20:58:10 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
20:58:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:58:10 WORKER: start processing job (5, 0, 7)
20:58:10 WORKER: args: ()
20:58:10 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.014043358921342529, 'num_filters_1': 21, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.04428590535785783, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 96, 'num_filters_3': 66, 'num_filters_4': 76, 'num_filters_5': 36}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:58:30 DISPATCHER: Starting worker discovery
20:58:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:58:30 DISPATCHER: Finished worker discovery
20:59:30 DISPATCHER: Starting worker discovery
20:59:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:59:30 DISPATCHER: Finished worker discovery
21:00:30 DISPATCHER: Starting worker discovery
21:00:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:00:30 DISPATCHER: Finished worker discovery
21:01:02 WORKER: done with job (5, 0, 7), trying to register it.
21:01:02 WORKER: registered result for job (5, 0, 7) with dispatcher
21:01:02 DISPATCHER: job (5, 0, 7) finished
21:01:02 DISPATCHER: register_result: lock acquired
21:01:02 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
21:01:02 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.014043358921342529, 'num_filters_1': 21, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.04428590535785783, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 96, 'num_filters_3': 66, 'num_filters_4': 76, 'num_filters_5': 36}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.41091049867387286, 'info': {'data03': 0.41091049867387286, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.014043358921342529, 'num_filters_1': 21, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.04428590535785783, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 96, 'num_filters_3': 66, 'num_filters_4': 76, 'num_filters_5': 36}"}}
exception: None

21:01:02 job_callback for (5, 0, 7) started
21:01:02 DISPATCHER: Trying to submit another job.
21:01:02 job_callback for (5, 0, 7) got condition
21:01:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:01:02 done building a new model for budget 133.333333 based on 17/29 split
Best loss for this budget:-0.433242





21:01:02 HBMASTER: Trying to run another job!
21:01:02 job_callback for (5, 0, 7) finished
21:01:02 start sampling a new configuration.
21:01:02 done sampling a new configuration.
21:01:02 HBMASTER: schedule new run for iteration 5
21:01:02 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
21:01:02 HBMASTER: submitting job (5, 0, 8) to dispatcher
21:01:02 DISPATCHER: trying to submit job (5, 0, 8)
21:01:02 DISPATCHER: trying to notify the job_runner thread.
21:01:02 HBMASTER: job (5, 0, 8) submitted to dispatcher
21:01:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:01:02 DISPATCHER: Trying to submit another job.
21:01:02 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776
21:01:02 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
21:01:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:01:02 WORKER: start processing job (5, 0, 8)
21:01:02 WORKER: args: ()
21:01:02 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.015224080716921905, 'num_filters_1': 54, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.055492084509943244, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 47, 'num_filters_3': 115, 'num_filters_4': 16}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:01:30 DISPATCHER: Starting worker discovery
21:01:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:01:30 DISPATCHER: Finished worker discovery
21:02:30 DISPATCHER: Starting worker discovery
21:02:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:02:30 DISPATCHER: Finished worker discovery
21:03:30 DISPATCHER: Starting worker discovery
21:03:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:03:30 DISPATCHER: Finished worker discovery
21:03:55 WORKER: done with job (5, 0, 8), trying to register it.
21:03:55 WORKER: registered result for job (5, 0, 8) with dispatcher
21:03:55 DISPATCHER: job (5, 0, 8) finished
21:03:55 DISPATCHER: register_result: lock acquired
21:03:55 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
21:03:55 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.015224080716921905, 'num_filters_1': 54, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.055492084509943244, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 47, 'num_filters_3': 115, 'num_filters_4': 16}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3107378908828454, 'info': {'data03': 0.3107378908828454, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.015224080716921905, 'num_filters_1': 54, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.055492084509943244, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 47, 'num_filters_3': 115, 'num_filters_4': 16}"}}
exception: None

21:03:55 job_callback for (5, 0, 8) started
21:03:55 DISPATCHER: Trying to submit another job.
21:03:55 job_callback for (5, 0, 8) got condition
21:03:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:03:55 done building a new model for budget 133.333333 based on 17/30 split
Best loss for this budget:-0.433242





21:03:55 HBMASTER: Trying to run another job!
21:03:55 job_callback for (5, 0, 8) finished
21:03:55 ITERATION: Advancing config (5, 0, 3) to next budget 400.000000
21:03:55 ITERATION: Advancing config (5, 0, 5) to next budget 400.000000
21:03:55 ITERATION: Advancing config (5, 0, 7) to next budget 400.000000
21:03:55 HBMASTER: schedule new run for iteration 5
21:03:55 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
21:03:55 HBMASTER: submitting job (5, 0, 3) to dispatcher
21:03:55 DISPATCHER: trying to submit job (5, 0, 3)
21:03:55 DISPATCHER: trying to notify the job_runner thread.
21:03:55 HBMASTER: job (5, 0, 3) submitted to dispatcher
21:03:55 DISPATCHER: Trying to submit another job.
21:03:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:03:55 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
21:03:55 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
21:03:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:03:55 WORKER: start processing job (5, 0, 3)
21:03:55 WORKER: args: ()
21:03:55 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001325292532045633, 'num_filters_1': 31, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.06759376583379614, 'kernel_size_2': 5, 'num_filters_2': 43}, 'budget': 400.0, 'working_directory': '.'}
21:04:30 DISPATCHER: Starting worker discovery
21:04:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:04:30 DISPATCHER: Finished worker discovery
21:05:30 DISPATCHER: Starting worker discovery
21:05:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:05:31 DISPATCHER: Finished worker discovery
21:06:31 DISPATCHER: Starting worker discovery
21:06:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:06:31 DISPATCHER: Finished worker discovery
21:07:31 DISPATCHER: Starting worker discovery
21:07:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:07:31 DISPATCHER: Finished worker discovery
21:08:31 DISPATCHER: Starting worker discovery
21:08:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:08:31 DISPATCHER: Finished worker discovery
21:09:31 DISPATCHER: Starting worker discovery
21:09:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:09:31 DISPATCHER: Finished worker discovery
21:10:31 DISPATCHER: Starting worker discovery
21:10:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:10:31 DISPATCHER: Finished worker discovery
21:11:15 WORKER: done with job (5, 0, 3), trying to register it.
21:11:15 WORKER: registered result for job (5, 0, 3) with dispatcher
21:11:15 DISPATCHER: job (5, 0, 3) finished
21:11:15 DISPATCHER: register_result: lock acquired
21:11:15 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
21:11:15 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001325292532045633, 'num_filters_1': 31, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.06759376583379614, 'kernel_size_2': 5, 'num_filters_2': 43}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.367914487729732, 'info': {'data03': 0.367914487729732, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001325292532045633, 'num_filters_1': 31, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.06759376583379614, 'kernel_size_2': 5, 'num_filters_2': 43}"}}
exception: None

21:11:15 job_callback for (5, 0, 3) started
21:11:15 DISPATCHER: Trying to submit another job.
21:11:15 job_callback for (5, 0, 3) got condition
21:11:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:11:15 Only 16 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
21:11:15 HBMASTER: Trying to run another job!
21:11:15 job_callback for (5, 0, 3) finished
21:11:15 HBMASTER: schedule new run for iteration 5
21:11:15 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
21:11:15 HBMASTER: submitting job (5, 0, 5) to dispatcher
21:11:15 DISPATCHER: trying to submit job (5, 0, 5)
21:11:15 DISPATCHER: trying to notify the job_runner thread.
21:11:15 HBMASTER: job (5, 0, 5) submitted to dispatcher
21:11:15 DISPATCHER: Trying to submit another job.
21:11:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:11:15 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
21:11:15 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
21:11:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:11:15 WORKER: start processing job (5, 0, 5)
21:11:15 WORKER: args: ()
21:11:15 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.001479767254042439, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.05643320303506362, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 18, 'num_filters_3': 101, 'num_filters_4': 123}, 'budget': 400.0, 'working_directory': '.'}
21:11:31 DISPATCHER: Starting worker discovery
21:11:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:11:31 DISPATCHER: Finished worker discovery
21:12:31 DISPATCHER: Starting worker discovery
21:12:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:12:31 DISPATCHER: Finished worker discovery
21:13:31 DISPATCHER: Starting worker discovery
21:13:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:13:31 DISPATCHER: Finished worker discovery
21:14:31 DISPATCHER: Starting worker discovery
21:14:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:14:31 DISPATCHER: Finished worker discovery
21:15:31 DISPATCHER: Starting worker discovery
21:15:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:15:31 DISPATCHER: Finished worker discovery
21:16:31 DISPATCHER: Starting worker discovery
21:16:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:16:31 DISPATCHER: Finished worker discovery
21:17:31 DISPATCHER: Starting worker discovery
21:17:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:17:31 DISPATCHER: Finished worker discovery
21:18:31 DISPATCHER: Starting worker discovery
21:18:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:18:31 DISPATCHER: Finished worker discovery
21:18:37 WORKER: done with job (5, 0, 5), trying to register it.
21:18:37 WORKER: registered result for job (5, 0, 5) with dispatcher
21:18:37 DISPATCHER: job (5, 0, 5) finished
21:18:37 DISPATCHER: register_result: lock acquired
21:18:37 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
21:18:37 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.001479767254042439, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.05643320303506362, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 18, 'num_filters_3': 101, 'num_filters_4': 123}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4490430435452726, 'info': {'data03': 0.4490430435452726, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.001479767254042439, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.05643320303506362, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 18, 'num_filters_3': 101, 'num_filters_4': 123}"}}
exception: None

21:18:37 job_callback for (5, 0, 5) started
21:18:37 DISPATCHER: Trying to submit another job.
21:18:37 job_callback for (5, 0, 5) got condition
21:18:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:18:37 HBMASTER: Trying to run another job!
21:18:37 job_callback for (5, 0, 5) finished
21:18:37 HBMASTER: schedule new run for iteration 5
21:18:37 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
21:18:37 HBMASTER: submitting job (5, 0, 7) to dispatcher
21:18:37 DISPATCHER: trying to submit job (5, 0, 7)
21:18:37 DISPATCHER: trying to notify the job_runner thread.
21:18:37 HBMASTER: job (5, 0, 7) submitted to dispatcher
21:18:37 DISPATCHER: Trying to submit another job.
21:18:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:18:37 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776
21:18:37 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
21:18:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:18:37 WORKER: start processing job (5, 0, 7)
21:18:37 WORKER: args: ()
21:18:37 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.014043358921342529, 'num_filters_1': 21, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.04428590535785783, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 96, 'num_filters_3': 66, 'num_filters_4': 76, 'num_filters_5': 36}, 'budget': 400.0, 'working_directory': '.'}
21:19:31 DISPATCHER: Starting worker discovery
21:19:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:19:31 DISPATCHER: Finished worker discovery
21:20:31 DISPATCHER: Starting worker discovery
21:20:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:20:31 DISPATCHER: Finished worker discovery
21:21:31 DISPATCHER: Starting worker discovery
21:21:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:21:31 DISPATCHER: Finished worker discovery
21:22:31 DISPATCHER: Starting worker discovery
21:22:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:22:31 DISPATCHER: Finished worker discovery
21:23:31 DISPATCHER: Starting worker discovery
21:23:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:23:31 DISPATCHER: Finished worker discovery
21:24:31 DISPATCHER: Starting worker discovery
21:24:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:24:31 DISPATCHER: Finished worker discovery
21:25:31 DISPATCHER: Starting worker discovery
21:25:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:25:31 DISPATCHER: Finished worker discovery
21:26:01 WORKER: done with job (5, 0, 7), trying to register it.
21:26:01 WORKER: registered result for job (5, 0, 7) with dispatcher
21:26:01 DISPATCHER: job (5, 0, 7) finished
21:26:01 DISPATCHER: register_result: lock acquired
21:26:01 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
21:26:01 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.014043358921342529, 'num_filters_1': 21, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.04428590535785783, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 96, 'num_filters_3': 66, 'num_filters_4': 76, 'num_filters_5': 36}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3703978480425987, 'info': {'data03': 0.3703978480425987, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.014043358921342529, 'num_filters_1': 21, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.04428590535785783, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 96, 'num_filters_3': 66, 'num_filters_4': 76, 'num_filters_5': 36}"}}
exception: None

21:26:01 job_callback for (5, 0, 7) started
21:26:01 DISPATCHER: Trying to submit another job.
21:26:01 job_callback for (5, 0, 7) got condition
21:26:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:26:01 HBMASTER: Trying to run another job!
21:26:01 job_callback for (5, 0, 7) finished
21:26:01 ITERATION: Advancing config (5, 0, 5) to next budget 1200.000000
21:26:01 HBMASTER: schedule new run for iteration 5
21:26:01 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
21:26:01 HBMASTER: submitting job (5, 0, 5) to dispatcher
21:26:01 DISPATCHER: trying to submit job (5, 0, 5)
21:26:01 DISPATCHER: trying to notify the job_runner thread.
21:26:01 HBMASTER: job (5, 0, 5) submitted to dispatcher
21:26:01 DISPATCHER: Trying to submit another job.
21:26:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:26:01 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
21:26:01 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
21:26:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:26:01 WORKER: start processing job (5, 0, 5)
21:26:01 WORKER: args: ()
21:26:01 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.001479767254042439, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.05643320303506362, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 18, 'num_filters_3': 101, 'num_filters_4': 123}, 'budget': 1200.0, 'working_directory': '.'}
21:26:31 DISPATCHER: Starting worker discovery
21:26:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:26:31 DISPATCHER: Finished worker discovery
21:27:31 DISPATCHER: Starting worker discovery
21:27:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:27:31 DISPATCHER: Finished worker discovery
21:28:31 DISPATCHER: Starting worker discovery
21:28:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:28:31 DISPATCHER: Finished worker discovery
21:29:31 DISPATCHER: Starting worker discovery
21:29:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:29:31 DISPATCHER: Finished worker discovery
21:30:31 DISPATCHER: Starting worker discovery
21:30:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:30:31 DISPATCHER: Finished worker discovery
21:31:31 DISPATCHER: Starting worker discovery
21:31:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:31:31 DISPATCHER: Finished worker discovery
21:32:31 DISPATCHER: Starting worker discovery
21:32:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:32:31 DISPATCHER: Finished worker discovery
21:33:31 DISPATCHER: Starting worker discovery
21:33:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:33:31 DISPATCHER: Finished worker discovery
21:34:31 DISPATCHER: Starting worker discovery
21:34:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:34:31 DISPATCHER: Finished worker discovery
21:35:31 DISPATCHER: Starting worker discovery
21:35:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:35:31 DISPATCHER: Finished worker discovery
21:36:31 DISPATCHER: Starting worker discovery
21:36:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:36:31 DISPATCHER: Finished worker discovery
21:37:31 DISPATCHER: Starting worker discovery
21:37:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:37:31 DISPATCHER: Finished worker discovery
21:38:31 DISPATCHER: Starting worker discovery
21:38:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:38:31 DISPATCHER: Finished worker discovery
21:39:31 DISPATCHER: Starting worker discovery
21:39:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:39:31 DISPATCHER: Finished worker discovery
21:40:31 DISPATCHER: Starting worker discovery
21:40:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:40:31 DISPATCHER: Finished worker discovery
21:41:31 DISPATCHER: Starting worker discovery
21:41:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:41:31 DISPATCHER: Finished worker discovery
21:42:31 DISPATCHER: Starting worker discovery
21:42:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:42:31 DISPATCHER: Finished worker discovery
21:43:31 DISPATCHER: Starting worker discovery
21:43:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:43:31 DISPATCHER: Finished worker discovery
21:44:31 DISPATCHER: Starting worker discovery
21:44:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:44:31 DISPATCHER: Finished worker discovery
21:45:31 DISPATCHER: Starting worker discovery
21:45:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:45:31 DISPATCHER: Finished worker discovery
21:46:31 DISPATCHER: Starting worker discovery
21:46:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:46:31 DISPATCHER: Finished worker discovery
21:46:42 WORKER: done with job (5, 0, 5), trying to register it.
21:46:42 WORKER: registered result for job (5, 0, 5) with dispatcher
21:46:42 DISPATCHER: job (5, 0, 5) finished
21:46:42 DISPATCHER: register_result: lock acquired
21:46:42 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
21:46:42 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.001479767254042439, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.05643320303506362, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 18, 'num_filters_3': 101, 'num_filters_4': 123}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.3724128339667042, 'info': {'data03': 0.3724128339667042, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.001479767254042439, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 64, 'weight_decay': 0.05643320303506362, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 18, 'num_filters_3': 101, 'num_filters_4': 123}"}}
exception: None

21:46:42 job_callback for (5, 0, 5) started
21:46:42 job_callback for (5, 0, 5) got condition
21:46:42 DISPATCHER: Trying to submit another job.
21:46:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:46:42 Only 10 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
21:46:42 HBMASTER: Trying to run another job!
21:46:42 job_callback for (5, 0, 5) finished
21:46:42 start sampling a new configuration.
21:46:43 best_vector: [0, 0, 0.3088227053683817, 0.6356604098634945, 0.14447236024059357, 0, 0.3585824833355757, 0.8285426046156384, 0, 2, 1, 1, 0.7016237250567031, 0.9596286756806031, 0.892360036167059, 0.720327881164382], 9.503388904761677e-30, 0.0010522562109385523, -3.753960912024873e-05
21:46:43 done sampling a new configuration.
21:46:43 HBMASTER: schedule new run for iteration 6
21:46:43 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
21:46:43 HBMASTER: submitting job (6, 0, 0) to dispatcher
21:46:43 DISPATCHER: trying to submit job (6, 0, 0)
21:46:43 DISPATCHER: trying to notify the job_runner thread.
21:46:43 HBMASTER: job (6, 0, 0) submitted to dispatcher
21:46:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:46:43 DISPATCHER: Trying to submit another job.
21:46:43 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
21:46:43 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
21:46:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:46:43 WORKER: start processing job (6, 0, 0)
21:46:43 WORKER: args: ()
21:46:43 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004146153825693579, 'num_filters_1': 59, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.11966269545486796}, 'budget': 400.0, 'working_directory': '.'}
21:47:31 DISPATCHER: Starting worker discovery
21:47:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:47:31 DISPATCHER: Finished worker discovery
21:48:31 DISPATCHER: Starting worker discovery
21:48:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:48:31 DISPATCHER: Finished worker discovery
21:49:31 DISPATCHER: Starting worker discovery
21:49:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:49:31 DISPATCHER: Finished worker discovery
21:50:31 DISPATCHER: Starting worker discovery
21:50:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:50:31 DISPATCHER: Finished worker discovery
21:51:31 DISPATCHER: Starting worker discovery
21:51:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:51:31 DISPATCHER: Finished worker discovery
21:52:31 DISPATCHER: Starting worker discovery
21:52:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:52:31 DISPATCHER: Finished worker discovery
21:53:31 DISPATCHER: Starting worker discovery
21:53:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:53:31 DISPATCHER: Finished worker discovery
21:54:05 WORKER: done with job (6, 0, 0), trying to register it.
21:54:05 WORKER: registered result for job (6, 0, 0) with dispatcher
21:54:05 DISPATCHER: job (6, 0, 0) finished
21:54:05 DISPATCHER: register_result: lock acquired
21:54:05 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
21:54:05 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004146153825693579, 'num_filters_1': 59, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.11966269545486796}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.21616604306995152, 'info': {'data03': 0.21616604306995152, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004146153825693579, 'num_filters_1': 59, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.11966269545486796}"}}
exception: None

21:54:05 job_callback for (6, 0, 0) started
21:54:05 DISPATCHER: Trying to submit another job.
21:54:05 job_callback for (6, 0, 0) got condition
21:54:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:54:05 HBMASTER: Trying to run another job!
21:54:05 job_callback for (6, 0, 0) finished
21:54:05 start sampling a new configuration.
21:54:05 done sampling a new configuration.
21:54:05 HBMASTER: schedule new run for iteration 6
21:54:05 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
21:54:05 HBMASTER: submitting job (6, 0, 1) to dispatcher
21:54:05 DISPATCHER: trying to submit job (6, 0, 1)
21:54:05 DISPATCHER: trying to notify the job_runner thread.
21:54:05 HBMASTER: job (6, 0, 1) submitted to dispatcher
21:54:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:54:05 DISPATCHER: Trying to submit another job.
21:54:05 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
21:54:05 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
21:54:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:54:05 WORKER: start processing job (6, 0, 1)
21:54:05 WORKER: args: ()
21:54:05 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0728495460943677, 'num_filters_1': 43, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.040753131124451066, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 54, 'num_filters_3': 44, 'num_filters_4': 125, 'num_filters_5': 23}, 'budget': 400.0, 'working_directory': '.'}
21:54:31 DISPATCHER: Starting worker discovery
21:54:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:54:31 DISPATCHER: Finished worker discovery
21:55:31 DISPATCHER: Starting worker discovery
21:55:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:55:31 DISPATCHER: Finished worker discovery
21:56:31 DISPATCHER: Starting worker discovery
21:56:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:56:31 DISPATCHER: Finished worker discovery
21:57:31 DISPATCHER: Starting worker discovery
21:57:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:57:31 DISPATCHER: Finished worker discovery
21:58:31 DISPATCHER: Starting worker discovery
21:58:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:58:31 DISPATCHER: Finished worker discovery
21:59:31 DISPATCHER: Starting worker discovery
21:59:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:59:31 DISPATCHER: Finished worker discovery
22:00:31 DISPATCHER: Starting worker discovery
22:00:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:00:31 DISPATCHER: Finished worker discovery
22:01:27 WORKER: done with job (6, 0, 1), trying to register it.
22:01:27 WORKER: registered result for job (6, 0, 1) with dispatcher
22:01:27 DISPATCHER: job (6, 0, 1) finished
22:01:27 DISPATCHER: register_result: lock acquired
22:01:27 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:01:27 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0728495460943677, 'num_filters_1': 43, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.040753131124451066, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 54, 'num_filters_3': 44, 'num_filters_4': 125, 'num_filters_5': 23}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.350185495146005, 'info': {'data03': 0.350185495146005, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0728495460943677, 'num_filters_1': 43, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.040753131124451066, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 54, 'num_filters_3': 44, 'num_filters_4': 125, 'num_filters_5': 23}"}}
exception: None

22:01:27 job_callback for (6, 0, 1) started
22:01:27 job_callback for (6, 0, 1) got condition
22:01:27 DISPATCHER: Trying to submit another job.
22:01:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:01:27 HBMASTER: Trying to run another job!
22:01:27 job_callback for (6, 0, 1) finished
22:01:27 start sampling a new configuration.
22:01:27 best_vector: [2, 1, 0.45767101510704306, 0.1439228191082661, 0.6320046761626864, 1, 0.08888489801482513, 0.9056435412230757, 1, 0, 1, 2, 0.809445727241526, 0.44287787922698035, 0.6670852757977821, 0.21046727011128386], 2.441252002120335e-29, 0.000409625880135052, -2.689108769906373e-16
22:01:27 done sampling a new configuration.
22:01:27 HBMASTER: schedule new run for iteration 6
22:01:27 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
22:01:27 HBMASTER: submitting job (6, 0, 2) to dispatcher
22:01:27 DISPATCHER: trying to submit job (6, 0, 2)
22:01:27 DISPATCHER: trying to notify the job_runner thread.
22:01:27 HBMASTER: job (6, 0, 2) submitted to dispatcher
22:01:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:01:27 DISPATCHER: Trying to submit another job.
22:01:27 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:01:27 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:01:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:01:27 WORKER: start processing job (6, 0, 2)
22:01:27 WORKER: args: ()
22:01:27 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.00822890465226734, 'num_filters_1': 21, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.15075419726471995, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 86, 'num_filters_3': 40, 'num_filters_4': 64}, 'budget': 400.0, 'working_directory': '.'}
22:01:31 DISPATCHER: Starting worker discovery
22:01:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:01:31 DISPATCHER: Finished worker discovery
22:02:31 DISPATCHER: Starting worker discovery
22:02:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:02:31 DISPATCHER: Finished worker discovery
22:03:31 DISPATCHER: Starting worker discovery
22:03:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:03:31 DISPATCHER: Finished worker discovery
22:04:31 DISPATCHER: Starting worker discovery
22:04:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:04:31 DISPATCHER: Finished worker discovery
22:05:31 DISPATCHER: Starting worker discovery
22:05:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:05:31 DISPATCHER: Finished worker discovery
22:06:31 DISPATCHER: Starting worker discovery
22:06:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:06:31 DISPATCHER: Finished worker discovery
22:07:31 DISPATCHER: Starting worker discovery
22:07:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:07:31 DISPATCHER: Finished worker discovery
22:08:31 DISPATCHER: Starting worker discovery
22:08:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:08:31 DISPATCHER: Finished worker discovery
22:08:49 WORKER: done with job (6, 0, 2), trying to register it.
22:08:49 WORKER: registered result for job (6, 0, 2) with dispatcher
22:08:49 DISPATCHER: job (6, 0, 2) finished
22:08:49 DISPATCHER: register_result: lock acquired
22:08:49 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:08:49 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.00822890465226734, 'num_filters_1': 21, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.15075419726471995, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 86, 'num_filters_3': 40, 'num_filters_4': 64}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.30596686062855677, 'info': {'data03': 0.30596686062855677, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.00822890465226734, 'num_filters_1': 21, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.15075419726471995, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 86, 'num_filters_3': 40, 'num_filters_4': 64}"}}
exception: None

22:08:49 job_callback for (6, 0, 2) started
22:08:49 job_callback for (6, 0, 2) got condition
22:08:49 DISPATCHER: Trying to submit another job.
22:08:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:08:49 HBMASTER: Trying to run another job!
22:08:49 job_callback for (6, 0, 2) finished
22:08:49 start sampling a new configuration.
22:08:49 best_vector: [0, 1, 0.10172105947173288, 0.17370450766290846, 0.9971969903132064, 1, 0.038767385237844065, 0.9193542755425901, 2, 2, 0, 2, 0.17459577118306902, 0.5001163084446807, 0.845398171970219, 0.39885182523690216], 4.847690621647338e-29, 0.00020628379120039245, -6.352043008609123e-09
22:08:49 done sampling a new configuration.
22:08:49 HBMASTER: schedule new run for iteration 6
22:08:49 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
22:08:49 HBMASTER: submitting job (6, 0, 3) to dispatcher
22:08:49 DISPATCHER: trying to submit job (6, 0, 3)
22:08:49 DISPATCHER: trying to notify the job_runner thread.
22:08:49 HBMASTER: job (6, 0, 3) submitted to dispatcher
22:08:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:08:49 DISPATCHER: Trying to submit another job.
22:08:49 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:08:49 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:08:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:08:49 WORKER: start processing job (6, 0, 3)
22:08:49 WORKER: args: ()
22:08:49 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0015975046057537673, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.15707515217084989, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 45, 'num_filters_4': 93, 'num_filters_5': 36}, 'budget': 400.0, 'working_directory': '.'}
22:09:31 DISPATCHER: Starting worker discovery
22:09:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:09:31 DISPATCHER: Finished worker discovery
22:10:31 DISPATCHER: Starting worker discovery
22:10:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:10:31 DISPATCHER: Finished worker discovery
22:11:31 DISPATCHER: Starting worker discovery
22:11:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:11:31 DISPATCHER: Finished worker discovery
22:12:31 DISPATCHER: Starting worker discovery
22:12:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:12:31 DISPATCHER: Finished worker discovery
22:13:31 DISPATCHER: Starting worker discovery
22:13:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:13:31 DISPATCHER: Finished worker discovery
22:14:31 DISPATCHER: Starting worker discovery
22:14:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:14:31 DISPATCHER: Finished worker discovery
22:15:31 DISPATCHER: Starting worker discovery
22:15:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:15:31 DISPATCHER: Finished worker discovery
22:16:15 WORKER: done with job (6, 0, 3), trying to register it.
22:16:15 WORKER: registered result for job (6, 0, 3) with dispatcher
22:16:15 DISPATCHER: job (6, 0, 3) finished
22:16:15 DISPATCHER: register_result: lock acquired
22:16:15 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:16:15 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0015975046057537673, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.15707515217084989, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 45, 'num_filters_4': 93, 'num_filters_5': 36}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.2958879859161691, 'info': {'data03': 0.2958879859161691, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0015975046057537673, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 13, 'weight_decay': 0.15707515217084989, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 22, 'num_filters_3': 45, 'num_filters_4': 93, 'num_filters_5': 36}"}}
exception: None

22:16:15 job_callback for (6, 0, 3) started
22:16:15 DISPATCHER: Trying to submit another job.
22:16:15 job_callback for (6, 0, 3) got condition
22:16:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:16:15 HBMASTER: Trying to run another job!
22:16:15 job_callback for (6, 0, 3) finished
22:16:15 start sampling a new configuration.
22:16:15 best_vector: [2, 2, 0.36959816658170097, 0.25100558412070906, 0.09823171650664328, 1, 0.6294704219159046, 0.6174102151463051, 1, 0, 2, 0, 0.3555449551138689, 0.34027839098761636, 0.8071964564518299, 0.3895552670490555], 2.8770459680370307e-29, 0.00034757873565791043, -9.67449415349511e-08
22:16:15 done sampling a new configuration.
22:16:15 HBMASTER: schedule new run for iteration 6
22:16:15 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
22:16:15 HBMASTER: submitting job (6, 0, 4) to dispatcher
22:16:15 DISPATCHER: trying to submit job (6, 0, 4)
22:16:15 DISPATCHER: trying to notify the job_runner thread.
22:16:15 HBMASTER: job (6, 0, 4) submitted to dispatcher
22:16:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:16:15 DISPATCHER: Trying to submit another job.
22:16:15 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:16:15 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:16:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:16:15 WORKER: start processing job (6, 0, 4)
22:16:15 WORKER: args: ()
22:16:15 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005485248826145587, 'num_filters_1': 26, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.06357248815188367}, 'budget': 400.0, 'working_directory': '.'}
22:16:31 DISPATCHER: Starting worker discovery
22:16:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:16:31 DISPATCHER: Finished worker discovery
22:17:31 DISPATCHER: Starting worker discovery
22:17:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:17:31 DISPATCHER: Finished worker discovery
22:18:31 DISPATCHER: Starting worker discovery
22:18:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:18:31 DISPATCHER: Finished worker discovery
22:19:31 DISPATCHER: Starting worker discovery
22:19:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:19:31 DISPATCHER: Finished worker discovery
22:20:31 DISPATCHER: Starting worker discovery
22:20:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:20:31 DISPATCHER: Finished worker discovery
22:21:31 DISPATCHER: Starting worker discovery
22:21:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:21:31 DISPATCHER: Finished worker discovery
22:22:31 DISPATCHER: Starting worker discovery
22:22:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:22:31 DISPATCHER: Finished worker discovery
22:23:31 DISPATCHER: Starting worker discovery
22:23:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:23:31 DISPATCHER: Finished worker discovery
22:23:41 WORKER: done with job (6, 0, 4), trying to register it.
22:23:41 WORKER: registered result for job (6, 0, 4) with dispatcher
22:23:41 DISPATCHER: job (6, 0, 4) finished
22:23:41 DISPATCHER: register_result: lock acquired
22:23:41 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:23:41 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005485248826145587, 'num_filters_1': 26, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.06357248815188367}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3300970176299044, 'info': {'data03': 0.3300970176299044, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005485248826145587, 'num_filters_1': 26, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.06357248815188367}"}}
exception: None

22:23:41 job_callback for (6, 0, 4) started
22:23:41 DISPATCHER: Trying to submit another job.
22:23:41 job_callback for (6, 0, 4) got condition
22:23:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:23:41 HBMASTER: Trying to run another job!
22:23:41 job_callback for (6, 0, 4) finished
22:23:41 start sampling a new configuration.
22:23:41 done sampling a new configuration.
22:23:41 HBMASTER: schedule new run for iteration 6
22:23:41 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
22:23:41 HBMASTER: submitting job (6, 0, 5) to dispatcher
22:23:41 DISPATCHER: trying to submit job (6, 0, 5)
22:23:41 DISPATCHER: trying to notify the job_runner thread.
22:23:41 HBMASTER: job (6, 0, 5) submitted to dispatcher
22:23:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:23:41 DISPATCHER: Trying to submit another job.
22:23:41 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:23:41 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:23:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:23:41 WORKER: start processing job (6, 0, 5)
22:23:41 WORKER: args: ()
22:23:41 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.010630074735982901, 'num_filters_1': 25, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.15542142376019658, 'kernel_size_2': 5, 'num_filters_2': 87}, 'budget': 400.0, 'working_directory': '.'}
22:24:31 DISPATCHER: Starting worker discovery
22:24:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:24:31 DISPATCHER: Finished worker discovery
22:25:31 DISPATCHER: Starting worker discovery
22:25:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:25:31 DISPATCHER: Finished worker discovery
22:26:31 DISPATCHER: Starting worker discovery
22:26:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:26:31 DISPATCHER: Finished worker discovery
22:27:31 DISPATCHER: Starting worker discovery
22:27:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:27:31 DISPATCHER: Finished worker discovery
22:28:31 DISPATCHER: Starting worker discovery
22:28:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:28:31 DISPATCHER: Finished worker discovery
22:29:31 DISPATCHER: Starting worker discovery
22:29:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:29:31 DISPATCHER: Finished worker discovery
22:30:31 DISPATCHER: Starting worker discovery
22:30:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:30:31 DISPATCHER: Finished worker discovery
22:31:11 WORKER: done with job (6, 0, 5), trying to register it.
22:31:11 WORKER: registered result for job (6, 0, 5) with dispatcher
22:31:11 DISPATCHER: job (6, 0, 5) finished
22:31:11 DISPATCHER: register_result: lock acquired
22:31:11 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:31:11 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.010630074735982901, 'num_filters_1': 25, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.15542142376019658, 'kernel_size_2': 5, 'num_filters_2': 87}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.2926071789283661, 'info': {'data03': 0.2926071789283661, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.010630074735982901, 'num_filters_1': 25, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.15542142376019658, 'kernel_size_2': 5, 'num_filters_2': 87}"}}
exception: None

22:31:11 job_callback for (6, 0, 5) started
22:31:11 job_callback for (6, 0, 5) got condition
22:31:11 DISPATCHER: Trying to submit another job.
22:31:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:31:11 HBMASTER: Trying to run another job!
22:31:11 job_callback for (6, 0, 5) finished
22:31:11 ITERATION: Advancing config (6, 0, 1) to next budget 1200.000000
22:31:11 ITERATION: Advancing config (6, 0, 4) to next budget 1200.000000
22:31:11 HBMASTER: schedule new run for iteration 6
22:31:11 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
22:31:11 HBMASTER: submitting job (6, 0, 1) to dispatcher
22:31:11 DISPATCHER: trying to submit job (6, 0, 1)
22:31:11 DISPATCHER: trying to notify the job_runner thread.
22:31:11 HBMASTER: job (6, 0, 1) submitted to dispatcher
22:31:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:31:11 DISPATCHER: Trying to submit another job.
22:31:11 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:31:11 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:31:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:31:11 WORKER: start processing job (6, 0, 1)
22:31:11 WORKER: args: ()
22:31:11 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0728495460943677, 'num_filters_1': 43, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.040753131124451066, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 54, 'num_filters_3': 44, 'num_filters_4': 125, 'num_filters_5': 23}, 'budget': 1200.0, 'working_directory': '.'}
22:31:31 DISPATCHER: Starting worker discovery
22:31:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:31:31 DISPATCHER: Finished worker discovery
22:32:31 DISPATCHER: Starting worker discovery
22:32:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:32:31 DISPATCHER: Finished worker discovery
22:33:31 DISPATCHER: Starting worker discovery
22:33:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:33:31 DISPATCHER: Finished worker discovery
22:34:31 DISPATCHER: Starting worker discovery
22:34:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:34:31 DISPATCHER: Finished worker discovery
22:35:31 DISPATCHER: Starting worker discovery
22:35:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:35:31 DISPATCHER: Finished worker discovery
22:36:31 DISPATCHER: Starting worker discovery
22:36:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:36:31 DISPATCHER: Finished worker discovery
22:37:31 DISPATCHER: Starting worker discovery
22:37:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:37:31 DISPATCHER: Finished worker discovery
22:38:31 DISPATCHER: Starting worker discovery
22:38:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:38:31 DISPATCHER: Finished worker discovery
22:39:31 DISPATCHER: Starting worker discovery
22:39:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:39:31 DISPATCHER: Finished worker discovery
22:40:31 DISPATCHER: Starting worker discovery
22:40:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:40:31 DISPATCHER: Finished worker discovery
22:41:31 DISPATCHER: Starting worker discovery
22:41:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:41:31 DISPATCHER: Finished worker discovery
22:42:31 DISPATCHER: Starting worker discovery
22:42:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:42:31 DISPATCHER: Finished worker discovery
22:43:31 DISPATCHER: Starting worker discovery
22:43:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:43:31 DISPATCHER: Finished worker discovery
22:44:31 DISPATCHER: Starting worker discovery
22:44:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:44:31 DISPATCHER: Finished worker discovery
22:45:31 DISPATCHER: Starting worker discovery
22:45:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:45:31 DISPATCHER: Finished worker discovery
22:46:31 DISPATCHER: Starting worker discovery
22:46:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:46:31 DISPATCHER: Finished worker discovery
22:47:31 DISPATCHER: Starting worker discovery
22:47:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:47:31 DISPATCHER: Finished worker discovery
22:48:31 DISPATCHER: Starting worker discovery
22:48:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:48:31 DISPATCHER: Finished worker discovery
22:49:31 DISPATCHER: Starting worker discovery
22:49:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:49:31 DISPATCHER: Finished worker discovery
22:50:31 DISPATCHER: Starting worker discovery
22:50:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:50:31 DISPATCHER: Finished worker discovery
22:51:31 DISPATCHER: Starting worker discovery
22:51:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:51:31 DISPATCHER: Finished worker discovery
22:51:57 WORKER: done with job (6, 0, 1), trying to register it.
22:51:57 WORKER: registered result for job (6, 0, 1) with dispatcher
22:51:57 DISPATCHER: job (6, 0, 1) finished
22:51:57 DISPATCHER: register_result: lock acquired
22:51:57 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:51:57 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0728495460943677, 'num_filters_1': 43, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.040753131124451066, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 54, 'num_filters_3': 44, 'num_filters_4': 125, 'num_filters_5': 23}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.2838258162717883, 'info': {'data03': 0.2838258162717883, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0728495460943677, 'num_filters_1': 43, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.040753131124451066, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 54, 'num_filters_3': 44, 'num_filters_4': 125, 'num_filters_5': 23}"}}
exception: None

22:51:57 job_callback for (6, 0, 1) started
22:51:57 job_callback for (6, 0, 1) got condition
22:51:57 DISPATCHER: Trying to submit another job.
22:51:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:51:57 Only 11 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
22:51:57 HBMASTER: Trying to run another job!
22:51:57 job_callback for (6, 0, 1) finished
22:51:57 HBMASTER: schedule new run for iteration 6
22:51:57 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
22:51:57 HBMASTER: submitting job (6, 0, 4) to dispatcher
22:51:57 DISPATCHER: trying to submit job (6, 0, 4)
22:51:57 DISPATCHER: trying to notify the job_runner thread.
22:51:57 HBMASTER: job (6, 0, 4) submitted to dispatcher
22:51:57 DISPATCHER: Trying to submit another job.
22:51:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:51:57 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:51:57 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:51:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:51:57 WORKER: start processing job (6, 0, 4)
22:51:57 WORKER: args: ()
22:51:57 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005485248826145587, 'num_filters_1': 26, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.06357248815188367}, 'budget': 1200.0, 'working_directory': '.'}
22:52:31 DISPATCHER: Starting worker discovery
22:52:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:52:31 DISPATCHER: Finished worker discovery
22:53:31 DISPATCHER: Starting worker discovery
22:53:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:53:31 DISPATCHER: Finished worker discovery
22:54:31 DISPATCHER: Starting worker discovery
22:54:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:54:31 DISPATCHER: Finished worker discovery
22:55:31 DISPATCHER: Starting worker discovery
22:55:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:55:31 DISPATCHER: Finished worker discovery
22:56:31 DISPATCHER: Starting worker discovery
22:56:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:56:31 DISPATCHER: Finished worker discovery
22:57:31 DISPATCHER: Starting worker discovery
22:57:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:57:31 DISPATCHER: Finished worker discovery
22:58:31 DISPATCHER: Starting worker discovery
22:58:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:58:31 DISPATCHER: Finished worker discovery
22:59:31 DISPATCHER: Starting worker discovery
22:59:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:59:31 DISPATCHER: Finished worker discovery
23:00:31 DISPATCHER: Starting worker discovery
23:00:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:00:31 DISPATCHER: Finished worker discovery
23:01:31 DISPATCHER: Starting worker discovery
23:01:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:01:31 DISPATCHER: Finished worker discovery
23:02:31 DISPATCHER: Starting worker discovery
23:02:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:02:31 DISPATCHER: Finished worker discovery
23:03:31 DISPATCHER: Starting worker discovery
23:03:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:03:31 DISPATCHER: Finished worker discovery
23:04:31 DISPATCHER: Starting worker discovery
23:04:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:04:31 DISPATCHER: Finished worker discovery
23:05:31 DISPATCHER: Starting worker discovery
23:05:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:05:31 DISPATCHER: Finished worker discovery
23:06:31 DISPATCHER: Starting worker discovery
23:06:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:06:31 DISPATCHER: Finished worker discovery
23:07:31 DISPATCHER: Starting worker discovery
23:07:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:07:31 DISPATCHER: Finished worker discovery
23:08:31 DISPATCHER: Starting worker discovery
23:08:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:08:31 DISPATCHER: Finished worker discovery
23:09:31 DISPATCHER: Starting worker discovery
23:09:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:09:31 DISPATCHER: Finished worker discovery
23:10:31 DISPATCHER: Starting worker discovery
23:10:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:10:31 DISPATCHER: Finished worker discovery
23:11:31 DISPATCHER: Starting worker discovery
23:11:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:11:31 DISPATCHER: Finished worker discovery
23:12:31 DISPATCHER: Starting worker discovery
23:12:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:12:31 DISPATCHER: Finished worker discovery
23:12:39 WORKER: done with job (6, 0, 4), trying to register it.
23:12:39 WORKER: registered result for job (6, 0, 4) with dispatcher
23:12:39 DISPATCHER: job (6, 0, 4) finished
23:12:39 DISPATCHER: register_result: lock acquired
23:12:39 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
23:12:39 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005485248826145587, 'num_filters_1': 26, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.06357248815188367}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.30117738634830893, 'info': {'data03': 0.30117738634830893, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005485248826145587, 'num_filters_1': 26, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.06357248815188367}"}}
exception: None

23:12:39 job_callback for (6, 0, 4) started
23:12:39 job_callback for (6, 0, 4) got condition
23:12:39 DISPATCHER: Trying to submit another job.
23:12:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:12:39 Only 12 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
23:12:39 HBMASTER: Trying to run another job!
23:12:39 job_callback for (6, 0, 4) finished
23:12:39 start sampling a new configuration.
23:12:39 done sampling a new configuration.
23:12:39 HBMASTER: schedule new run for iteration 7
23:12:39 HBMASTER: trying submitting job (7, 0, 0) to dispatcher
23:12:39 HBMASTER: submitting job (7, 0, 0) to dispatcher
23:12:39 DISPATCHER: trying to submit job (7, 0, 0)
23:12:39 DISPATCHER: trying to notify the job_runner thread.
23:12:39 HBMASTER: job (7, 0, 0) submitted to dispatcher
23:12:39 DISPATCHER: Trying to submit another job.
23:12:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:12:39 DISPATCHER: starting job (7, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
23:12:39 DISPATCHER: job (7, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
23:12:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:12:39 WORKER: start processing job (7, 0, 0)
23:12:39 WORKER: args: ()
23:12:39 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0043856777963883296, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.013746974567931, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 20, 'num_filters_3': 19, 'num_filters_4': 110}, 'budget': 1200.0, 'working_directory': '.'}
23:13:31 DISPATCHER: Starting worker discovery
23:13:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:13:32 DISPATCHER: Finished worker discovery
23:14:32 DISPATCHER: Starting worker discovery
23:14:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:14:32 DISPATCHER: Finished worker discovery
23:15:32 DISPATCHER: Starting worker discovery
23:15:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:15:32 DISPATCHER: Finished worker discovery
23:16:32 DISPATCHER: Starting worker discovery
23:16:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:16:32 DISPATCHER: Finished worker discovery
23:17:32 DISPATCHER: Starting worker discovery
23:17:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:17:32 DISPATCHER: Finished worker discovery
23:18:32 DISPATCHER: Starting worker discovery
23:18:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:18:32 DISPATCHER: Finished worker discovery
23:19:32 DISPATCHER: Starting worker discovery
23:19:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:19:32 DISPATCHER: Finished worker discovery
23:20:32 DISPATCHER: Starting worker discovery
23:20:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:20:32 DISPATCHER: Finished worker discovery
23:21:32 DISPATCHER: Starting worker discovery
23:21:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:21:32 DISPATCHER: Finished worker discovery
23:22:32 DISPATCHER: Starting worker discovery
23:22:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:22:32 DISPATCHER: Finished worker discovery
23:23:32 DISPATCHER: Starting worker discovery
23:23:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:23:32 DISPATCHER: Finished worker discovery
23:24:32 DISPATCHER: Starting worker discovery
23:24:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:24:32 DISPATCHER: Finished worker discovery
23:25:32 DISPATCHER: Starting worker discovery
23:25:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:25:32 DISPATCHER: Finished worker discovery
23:26:32 DISPATCHER: Starting worker discovery
23:26:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:26:32 DISPATCHER: Finished worker discovery
23:27:32 DISPATCHER: Starting worker discovery
23:27:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:27:32 DISPATCHER: Finished worker discovery
23:28:32 DISPATCHER: Starting worker discovery
23:28:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:28:32 DISPATCHER: Finished worker discovery
23:29:32 DISPATCHER: Starting worker discovery
23:29:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:29:32 DISPATCHER: Finished worker discovery
23:30:32 DISPATCHER: Starting worker discovery
23:30:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:30:32 DISPATCHER: Finished worker discovery
23:31:32 DISPATCHER: Starting worker discovery
23:31:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:31:32 DISPATCHER: Finished worker discovery
23:32:32 DISPATCHER: Starting worker discovery
23:32:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:32:32 DISPATCHER: Finished worker discovery
23:33:26 WORKER: done with job (7, 0, 0), trying to register it.
23:33:26 WORKER: registered result for job (7, 0, 0) with dispatcher
23:33:26 DISPATCHER: job (7, 0, 0) finished
23:33:26 DISPATCHER: register_result: lock acquired
23:33:26 DISPATCHER: job (7, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
23:33:26 job_id: (7, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0043856777963883296, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.013746974567931, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 20, 'num_filters_3': 19, 'num_filters_4': 110}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.2877783928747383, 'info': {'data03': 0.2877783928747383, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0043856777963883296, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.013746974567931, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 20, 'num_filters_3': 19, 'num_filters_4': 110}"}}
exception: None

23:33:26 job_callback for (7, 0, 0) started
23:33:26 DISPATCHER: Trying to submit another job.
23:33:26 job_callback for (7, 0, 0) got condition
23:33:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:33:26 Only 13 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
23:33:26 HBMASTER: Trying to run another job!
23:33:26 job_callback for (7, 0, 0) finished
23:33:26 start sampling a new configuration.
23:33:26 best_vector: [0, 2, 0.29386649309669005, 0.8325840197985934, 0.5114598116810575, 1, 0.09235755826153363, 0.6217700164995095, 0, 2, 1, 2, 0.7355472378493748, 0.5067183997250585, 0.4058944457680977, 0.8519410456045069], 1.839860538489432e-29, 0.0005435194565458875, -1.3929179011623583e-06
23:33:26 done sampling a new configuration.
23:33:26 HBMASTER: schedule new run for iteration 7
23:33:26 HBMASTER: trying submitting job (7, 0, 1) to dispatcher
23:33:26 HBMASTER: submitting job (7, 0, 1) to dispatcher
23:33:26 DISPATCHER: trying to submit job (7, 0, 1)
23:33:26 DISPATCHER: trying to notify the job_runner thread.
23:33:26 HBMASTER: job (7, 0, 1) submitted to dispatcher
23:33:26 DISPATCHER: Trying to submit another job.
23:33:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:33:26 DISPATCHER: starting job (7, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
23:33:26 DISPATCHER: job (7, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
23:33:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:33:26 WORKER: start processing job (7, 0, 1)
23:33:26 WORKER: args: ()
23:33:26 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.003870196235755688, 'num_filters_1': 90, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.06440824147584398, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 73, 'num_filters_3': 45}, 'budget': 1200.0, 'working_directory': '.'}
23:33:32 DISPATCHER: Starting worker discovery
23:33:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:33:32 DISPATCHER: Finished worker discovery
23:34:32 DISPATCHER: Starting worker discovery
23:34:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:34:32 DISPATCHER: Finished worker discovery
23:35:32 DISPATCHER: Starting worker discovery
23:35:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:35:32 DISPATCHER: Finished worker discovery
23:36:32 DISPATCHER: Starting worker discovery
23:36:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:36:32 DISPATCHER: Finished worker discovery
23:37:32 DISPATCHER: Starting worker discovery
23:37:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:37:32 DISPATCHER: Finished worker discovery
23:38:32 DISPATCHER: Starting worker discovery
23:38:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:38:32 DISPATCHER: Finished worker discovery
23:39:32 DISPATCHER: Starting worker discovery
23:39:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:39:32 DISPATCHER: Finished worker discovery
23:40:32 DISPATCHER: Starting worker discovery
23:40:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:40:32 DISPATCHER: Finished worker discovery
23:41:32 DISPATCHER: Starting worker discovery
23:41:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:41:32 DISPATCHER: Finished worker discovery
23:42:32 DISPATCHER: Starting worker discovery
23:42:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:42:32 DISPATCHER: Finished worker discovery
23:43:32 DISPATCHER: Starting worker discovery
23:43:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:43:32 DISPATCHER: Finished worker discovery
23:44:32 DISPATCHER: Starting worker discovery
23:44:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:44:32 DISPATCHER: Finished worker discovery
23:45:32 DISPATCHER: Starting worker discovery
23:45:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:45:32 DISPATCHER: Finished worker discovery
23:46:32 DISPATCHER: Starting worker discovery
23:46:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:46:32 DISPATCHER: Finished worker discovery
23:47:32 DISPATCHER: Starting worker discovery
23:47:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:47:32 DISPATCHER: Finished worker discovery
23:48:32 DISPATCHER: Starting worker discovery
23:48:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:48:32 DISPATCHER: Finished worker discovery
23:49:32 DISPATCHER: Starting worker discovery
23:49:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:49:32 DISPATCHER: Finished worker discovery
23:50:32 DISPATCHER: Starting worker discovery
23:50:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:50:32 DISPATCHER: Finished worker discovery
23:51:32 DISPATCHER: Starting worker discovery
23:51:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:51:32 DISPATCHER: Finished worker discovery
23:52:32 DISPATCHER: Starting worker discovery
23:52:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:52:32 DISPATCHER: Finished worker discovery
23:53:32 DISPATCHER: Starting worker discovery
23:53:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:53:32 DISPATCHER: Finished worker discovery
23:54:23 WORKER: done with job (7, 0, 1), trying to register it.
23:54:23 WORKER: registered result for job (7, 0, 1) with dispatcher
23:54:23 DISPATCHER: job (7, 0, 1) finished
23:54:23 DISPATCHER: register_result: lock acquired
23:54:23 DISPATCHER: job (7, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
23:54:23 job_id: (7, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.003870196235755688, 'num_filters_1': 90, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.06440824147584398, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 73, 'num_filters_3': 45}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.2837889661856223, 'info': {'data03': 0.2837889661856223, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.003870196235755688, 'num_filters_1': 90, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.06440824147584398, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 73, 'num_filters_3': 45}"}}
exception: None

23:54:23 job_callback for (7, 0, 1) started
23:54:23 DISPATCHER: Trying to submit another job.
23:54:23 job_callback for (7, 0, 1) got condition
23:54:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:54:23 Only 14 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
23:54:23 HBMASTER: Trying to run another job!
23:54:23 job_callback for (7, 0, 1) finished
23:54:23 start sampling a new configuration.
23:54:23 done sampling a new configuration.
23:54:23 HBMASTER: schedule new run for iteration 7
23:54:23 HBMASTER: trying submitting job (7, 0, 2) to dispatcher
23:54:23 HBMASTER: submitting job (7, 0, 2) to dispatcher
23:54:23 DISPATCHER: trying to submit job (7, 0, 2)
23:54:23 DISPATCHER: trying to notify the job_runner thread.
23:54:23 HBMASTER: job (7, 0, 2) submitted to dispatcher
23:54:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:54:23 DISPATCHER: Trying to submit another job.
23:54:23 DISPATCHER: starting job (7, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
23:54:23 DISPATCHER: job (7, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
23:54:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:54:23 WORKER: start processing job (7, 0, 2)
23:54:23 WORKER: args: ()
23:54:23 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.009622669837898964, 'num_filters_1': 55, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.05079859788860179, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 37, 'num_filters_3': 48, 'num_filters_4': 56, 'num_filters_5': 82}, 'budget': 1200.0, 'working_directory': '.'}
23:54:32 DISPATCHER: Starting worker discovery
23:54:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:54:32 DISPATCHER: Finished worker discovery
23:55:32 DISPATCHER: Starting worker discovery
23:55:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:55:32 DISPATCHER: Finished worker discovery
23:56:32 DISPATCHER: Starting worker discovery
23:56:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:56:32 DISPATCHER: Finished worker discovery
23:57:32 DISPATCHER: Starting worker discovery
23:57:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:57:32 DISPATCHER: Finished worker discovery
23:58:32 DISPATCHER: Starting worker discovery
23:58:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:58:32 DISPATCHER: Finished worker discovery
23:59:32 DISPATCHER: Starting worker discovery
23:59:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:59:32 DISPATCHER: Finished worker discovery
00:00:32 DISPATCHER: Starting worker discovery
00:00:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:00:32 DISPATCHER: Finished worker discovery
00:01:32 DISPATCHER: Starting worker discovery
00:01:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:01:32 DISPATCHER: Finished worker discovery
00:02:32 DISPATCHER: Starting worker discovery
00:02:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:02:32 DISPATCHER: Finished worker discovery
00:03:32 DISPATCHER: Starting worker discovery
00:03:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:03:32 DISPATCHER: Finished worker discovery
00:04:32 DISPATCHER: Starting worker discovery
00:04:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:04:32 DISPATCHER: Finished worker discovery
00:05:32 DISPATCHER: Starting worker discovery
00:05:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:05:32 DISPATCHER: Finished worker discovery
00:06:32 DISPATCHER: Starting worker discovery
00:06:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:06:32 DISPATCHER: Finished worker discovery
00:07:32 DISPATCHER: Starting worker discovery
00:07:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:07:32 DISPATCHER: Finished worker discovery
00:08:32 DISPATCHER: Starting worker discovery
00:08:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:08:32 DISPATCHER: Finished worker discovery
00:09:32 DISPATCHER: Starting worker discovery
00:09:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:09:32 DISPATCHER: Finished worker discovery
00:10:32 DISPATCHER: Starting worker discovery
00:10:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:10:32 DISPATCHER: Finished worker discovery
00:11:32 DISPATCHER: Starting worker discovery
00:11:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:11:32 DISPATCHER: Finished worker discovery
00:12:32 DISPATCHER: Starting worker discovery
00:12:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:12:32 DISPATCHER: Finished worker discovery
00:13:32 DISPATCHER: Starting worker discovery
00:13:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:13:32 DISPATCHER: Finished worker discovery
00:14:32 DISPATCHER: Starting worker discovery
00:14:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:14:32 DISPATCHER: Finished worker discovery
00:15:09 WORKER: done with job (7, 0, 2), trying to register it.
00:15:09 WORKER: registered result for job (7, 0, 2) with dispatcher
00:15:09 DISPATCHER: job (7, 0, 2) finished
00:15:09 DISPATCHER: register_result: lock acquired
00:15:09 DISPATCHER: job (7, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:15:09 job_id: (7, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.009622669837898964, 'num_filters_1': 55, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.05079859788860179, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 37, 'num_filters_3': 48, 'num_filters_4': 56, 'num_filters_5': 82}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.23263712787258867, 'info': {'data03': 0.23263712787258867, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.009622669837898964, 'num_filters_1': 55, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.05079859788860179, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 37, 'num_filters_3': 48, 'num_filters_4': 56, 'num_filters_5': 82}"}}
exception: None

00:15:09 job_callback for (7, 0, 2) started
00:15:09 job_callback for (7, 0, 2) got condition
00:15:09 DISPATCHER: Trying to submit another job.
00:15:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:15:09 Only 15 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
00:15:09 HBMASTER: Trying to run another job!
00:15:09 job_callback for (7, 0, 2) finished
00:15:09 start sampling a new configuration.
00:15:09 best_vector: [2, 2, 0.521804761552414, 0.2692424510793394, 0.86465499646047, 1, 0.48687104023407096, 0.41440464658932624, 2, 1, 1, 0, 0.4799701622808853, 0.4228572068480705, 0.8223160760256065, 0.3592814800819657], 4.305865193718757e-30, 0.002322413626554692, -3.16976004719112e-09
00:15:09 done sampling a new configuration.
00:15:09 HBMASTER: schedule new run for iteration 7
00:15:09 HBMASTER: trying submitting job (7, 0, 3) to dispatcher
00:15:09 HBMASTER: submitting job (7, 0, 3) to dispatcher
00:15:09 DISPATCHER: trying to submit job (7, 0, 3)
00:15:09 DISPATCHER: trying to notify the job_runner thread.
00:15:09 HBMASTER: job (7, 0, 3) submitted to dispatcher
00:15:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:15:09 DISPATCHER: Trying to submit another job.
00:15:09 DISPATCHER: starting job (7, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:15:09 DISPATCHER: job (7, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:15:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:15:09 WORKER: start processing job (7, 0, 3)
00:15:09 WORKER: args: ()
00:15:09 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.01105629258745066, 'num_filters_1': 27, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.034606117302702515, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 43, 'num_filters_3': 38, 'num_filters_4': 88, 'num_filters_5': 33}, 'budget': 1200.0, 'working_directory': '.'}
00:15:32 DISPATCHER: Starting worker discovery
00:15:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:15:32 DISPATCHER: Finished worker discovery
00:16:32 DISPATCHER: Starting worker discovery
00:16:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:16:32 DISPATCHER: Finished worker discovery
00:17:32 DISPATCHER: Starting worker discovery
00:17:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:17:32 DISPATCHER: Finished worker discovery
00:18:32 DISPATCHER: Starting worker discovery
00:18:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:18:32 DISPATCHER: Finished worker discovery
00:19:32 DISPATCHER: Starting worker discovery
00:19:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:19:32 DISPATCHER: Finished worker discovery
00:20:32 DISPATCHER: Starting worker discovery
00:20:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:20:32 DISPATCHER: Finished worker discovery
00:21:32 DISPATCHER: Starting worker discovery
00:21:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:21:32 DISPATCHER: Finished worker discovery
00:22:32 DISPATCHER: Starting worker discovery
00:22:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:22:32 DISPATCHER: Finished worker discovery
00:23:32 DISPATCHER: Starting worker discovery
00:23:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:23:32 DISPATCHER: Finished worker discovery
00:24:32 DISPATCHER: Starting worker discovery
00:24:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:24:32 DISPATCHER: Finished worker discovery
00:25:32 DISPATCHER: Starting worker discovery
00:25:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:25:32 DISPATCHER: Finished worker discovery
00:26:32 DISPATCHER: Starting worker discovery
00:26:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:26:32 DISPATCHER: Finished worker discovery
00:27:32 DISPATCHER: Starting worker discovery
00:27:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:27:32 DISPATCHER: Finished worker discovery
00:28:32 DISPATCHER: Starting worker discovery
00:28:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:28:32 DISPATCHER: Finished worker discovery
00:29:32 DISPATCHER: Starting worker discovery
00:29:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:29:32 DISPATCHER: Finished worker discovery
00:30:32 DISPATCHER: Starting worker discovery
00:30:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:30:32 DISPATCHER: Finished worker discovery
00:31:32 DISPATCHER: Starting worker discovery
00:31:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:31:32 DISPATCHER: Finished worker discovery
00:32:32 DISPATCHER: Starting worker discovery
00:32:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:32:32 DISPATCHER: Finished worker discovery
00:33:32 DISPATCHER: Starting worker discovery
00:33:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:33:32 DISPATCHER: Finished worker discovery
00:34:32 DISPATCHER: Starting worker discovery
00:34:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:34:32 DISPATCHER: Finished worker discovery
00:35:32 DISPATCHER: Starting worker discovery
00:35:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:35:32 DISPATCHER: Finished worker discovery
00:35:55 WORKER: done with job (7, 0, 3), trying to register it.
00:35:55 WORKER: registered result for job (7, 0, 3) with dispatcher
00:35:55 DISPATCHER: job (7, 0, 3) finished
00:35:55 DISPATCHER: register_result: lock acquired
00:35:55 DISPATCHER: job (7, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:35:55 job_id: (7, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.01105629258745066, 'num_filters_1': 27, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.034606117302702515, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 43, 'num_filters_3': 38, 'num_filters_4': 88, 'num_filters_5': 33}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.39195857002889223, 'info': {'data03': 0.39195857002889223, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.01105629258745066, 'num_filters_1': 27, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.034606117302702515, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 43, 'num_filters_3': 38, 'num_filters_4': 88, 'num_filters_5': 33}"}}
exception: None

00:35:55 job_callback for (7, 0, 3) started
00:35:55 job_callback for (7, 0, 3) got condition
00:35:55 DISPATCHER: Trying to submit another job.
00:35:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:35:55 Only 16 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
00:35:55 HBMASTER: Trying to run another job!
00:35:55 job_callback for (7, 0, 3) finished
00:35:55 start sampling a new configuration.
00:35:55 best_vector: [0, 0, 0.25000468727116565, 0.3209781404482112, 0.7459786339761869, 1, 0.17966740063822945, 0.3255216287578268, 2, 2, 1, 2, 0.38793658539485204, 0.8794071697289638, 0.26461707681291136, 0.6957329116587386], 5.600848990694504e-29, 0.00017854436026778153, -1.3552391483753994e-05
00:35:55 done sampling a new configuration.
00:35:55 HBMASTER: schedule new run for iteration 8
00:35:55 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
00:35:55 HBMASTER: submitting job (8, 0, 0) to dispatcher
00:35:55 DISPATCHER: trying to submit job (8, 0, 0)
00:35:55 DISPATCHER: trying to notify the job_runner thread.
00:35:55 HBMASTER: job (8, 0, 0) submitted to dispatcher
00:35:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:35:55 DISPATCHER: Trying to submit another job.
00:35:55 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:35:55 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:35:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:35:55 WORKER: start processing job (8, 0, 0)
00:35:55 WORKER: args: ()
00:35:55 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0031623459208232566, 'num_filters_1': 31, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.026516329267777815, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 35, 'num_filters_3': 100, 'num_filters_4': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:36:32 DISPATCHER: Starting worker discovery
00:36:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:36:32 DISPATCHER: Finished worker discovery
00:37:22 WORKER: done with job (8, 0, 0), trying to register it.
00:37:22 WORKER: registered result for job (8, 0, 0) with dispatcher
00:37:22 DISPATCHER: job (8, 0, 0) finished
00:37:22 DISPATCHER: register_result: lock acquired
00:37:22 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:37:22 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0031623459208232566, 'num_filters_1': 31, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.026516329267777815, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 35, 'num_filters_3': 100, 'num_filters_4': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.43345780231333003, 'info': {'data03': 0.43345780231333003, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0031623459208232566, 'num_filters_1': 31, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.026516329267777815, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 35, 'num_filters_3': 100, 'num_filters_4': 27}"}}
exception: None

00:37:22 job_callback for (8, 0, 0) started
00:37:22 job_callback for (8, 0, 0) got condition
00:37:22 DISPATCHER: Trying to submit another job.
00:37:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:37:22 HBMASTER: Trying to run another job!
00:37:22 job_callback for (8, 0, 0) finished
00:37:22 start sampling a new configuration.
00:37:22 done sampling a new configuration.
00:37:22 HBMASTER: schedule new run for iteration 8
00:37:22 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
00:37:22 HBMASTER: submitting job (8, 0, 1) to dispatcher
00:37:22 DISPATCHER: trying to submit job (8, 0, 1)
00:37:22 DISPATCHER: trying to notify the job_runner thread.
00:37:22 HBMASTER: job (8, 0, 1) submitted to dispatcher
00:37:22 DISPATCHER: Trying to submit another job.
00:37:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:37:22 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:37:22 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:37:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:37:22 WORKER: start processing job (8, 0, 1)
00:37:22 WORKER: args: ()
00:37:22 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.007784613460156825, 'num_filters_1': 83, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.15358030032181674}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:37:32 DISPATCHER: Starting worker discovery
00:37:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:37:32 DISPATCHER: Finished worker discovery
00:38:32 DISPATCHER: Starting worker discovery
00:38:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:38:32 DISPATCHER: Finished worker discovery
00:38:46 WORKER: done with job (8, 0, 1), trying to register it.
00:38:46 WORKER: registered result for job (8, 0, 1) with dispatcher
00:38:46 DISPATCHER: job (8, 0, 1) finished
00:38:46 DISPATCHER: register_result: lock acquired
00:38:46 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:38:46 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.007784613460156825, 'num_filters_1': 83, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.15358030032181674}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.33954129988999127, 'info': {'data03': 0.33954129988999127, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.007784613460156825, 'num_filters_1': 83, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.15358030032181674}"}}
exception: None

00:38:46 job_callback for (8, 0, 1) started
00:38:46 job_callback for (8, 0, 1) got condition
00:38:46 DISPATCHER: Trying to submit another job.
00:38:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:38:46 HBMASTER: Trying to run another job!
00:38:46 job_callback for (8, 0, 1) finished
00:38:46 start sampling a new configuration.
00:38:46 best_vector: [0, 1, 0.5472519520356907, 0.729997629458768, 0.05571114105000191, 1, 0.2246120516065, 0.6625116649945606, 0, 2, 2, 0, 0.8552535964040696, 0.6792137061783006, 0.5143233236957588, 0.7914848480436854], 5.3348547824608775e-30, 0.0018744652680849864, -3.624280540421443e-05
00:38:46 done sampling a new configuration.
00:38:46 HBMASTER: schedule new run for iteration 8
00:38:46 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
00:38:46 HBMASTER: submitting job (8, 0, 2) to dispatcher
00:38:46 DISPATCHER: trying to submit job (8, 0, 2)
00:38:46 DISPATCHER: trying to notify the job_runner thread.
00:38:46 HBMASTER: job (8, 0, 2) submitted to dispatcher
00:38:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:38:46 DISPATCHER: Trying to submit another job.
00:38:46 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:38:46 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:38:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:38:46 WORKER: start processing job (8, 0, 2)
00:38:46 WORKER: args: ()
00:38:46 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.012430938105322111, 'num_filters_1': 73, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.07276919131623134}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:39:32 DISPATCHER: Starting worker discovery
00:39:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:39:32 DISPATCHER: Finished worker discovery
00:40:09 WORKER: done with job (8, 0, 2), trying to register it.
00:40:09 WORKER: registered result for job (8, 0, 2) with dispatcher
00:40:09 DISPATCHER: job (8, 0, 2) finished
00:40:09 DISPATCHER: register_result: lock acquired
00:40:09 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:40:09 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.012430938105322111, 'num_filters_1': 73, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.07276919131623134}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2561682416664438, 'info': {'data03': 0.2561682416664438, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.012430938105322111, 'num_filters_1': 73, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.07276919131623134}"}}
exception: None

00:40:09 job_callback for (8, 0, 2) started
00:40:09 DISPATCHER: Trying to submit another job.
00:40:09 job_callback for (8, 0, 2) got condition
00:40:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:40:09 HBMASTER: Trying to run another job!
00:40:09 job_callback for (8, 0, 2) finished
00:40:09 start sampling a new configuration.
00:40:09 best_vector: [2, 1, 0.5370433511670945, 0.5288874311898264, 0.7385099150488579, 1, 0.7703065762580816, 0.6064981465462518, 2, 2, 0, 1, 0.19773063260333504, 0.48969766304856416, 0.6155039859899482, 0.4237073841419062], 5.994827880018898e-29, 0.00016681046061940442, -5.032327631233311e-06
00:40:09 done sampling a new configuration.
00:40:09 HBMASTER: schedule new run for iteration 8
00:40:09 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
00:40:09 HBMASTER: submitting job (8, 0, 3) to dispatcher
00:40:09 DISPATCHER: trying to submit job (8, 0, 3)
00:40:09 DISPATCHER: trying to notify the job_runner thread.
00:40:09 HBMASTER: job (8, 0, 3) submitted to dispatcher
00:40:09 DISPATCHER: Trying to submit another job.
00:40:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:40:09 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:40:09 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:40:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:40:09 WORKER: start processing job (8, 0, 3)
00:40:09 WORKER: args: ()
00:40:09 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.011860054980813373, 'num_filters_1': 47, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.06152792670164974, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 24, 'num_filters_3': 44, 'num_filters_4': 57}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:40:32 DISPATCHER: Starting worker discovery
00:40:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:40:32 DISPATCHER: Finished worker discovery
00:41:30 WORKER: done with job (8, 0, 3), trying to register it.
00:41:30 WORKER: registered result for job (8, 0, 3) with dispatcher
00:41:30 DISPATCHER: job (8, 0, 3) finished
00:41:30 DISPATCHER: register_result: lock acquired
00:41:30 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:41:30 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.011860054980813373, 'num_filters_1': 47, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.06152792670164974, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 24, 'num_filters_3': 44, 'num_filters_4': 57}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.38513816568982007, 'info': {'data03': 0.38513816568982007, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.011860054980813373, 'num_filters_1': 47, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.06152792670164974, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 24, 'num_filters_3': 44, 'num_filters_4': 57}"}}
exception: None

00:41:30 job_callback for (8, 0, 3) started
00:41:30 job_callback for (8, 0, 3) got condition
00:41:30 DISPATCHER: Trying to submit another job.
00:41:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:41:30 HBMASTER: Trying to run another job!
00:41:30 job_callback for (8, 0, 3) finished
00:41:30 start sampling a new configuration.
00:41:30 done sampling a new configuration.
00:41:30 HBMASTER: schedule new run for iteration 8
00:41:30 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
00:41:30 HBMASTER: submitting job (8, 0, 4) to dispatcher
00:41:30 DISPATCHER: trying to submit job (8, 0, 4)
00:41:30 DISPATCHER: trying to notify the job_runner thread.
00:41:30 HBMASTER: job (8, 0, 4) submitted to dispatcher
00:41:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:41:30 DISPATCHER: Trying to submit another job.
00:41:30 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:41:30 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:41:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:41:30 WORKER: start processing job (8, 0, 4)
00:41:30 WORKER: args: ()
00:41:30 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0028067733686685196, 'num_filters_1': 127, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.022690889418959404, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 22, 'num_filters_3': 68}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:41:32 DISPATCHER: Starting worker discovery
00:41:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:41:32 DISPATCHER: Finished worker discovery
00:42:32 DISPATCHER: Starting worker discovery
00:42:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:42:32 DISPATCHER: Finished worker discovery
00:42:50 WORKER: done with job (8, 0, 4), trying to register it.
00:42:50 WORKER: registered result for job (8, 0, 4) with dispatcher
00:42:50 DISPATCHER: job (8, 0, 4) finished
00:42:50 DISPATCHER: register_result: lock acquired
00:42:50 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:42:50 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0028067733686685196, 'num_filters_1': 127, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.022690889418959404, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 22, 'num_filters_3': 68}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2741617844235917, 'info': {'data03': 0.2741617844235917, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0028067733686685196, 'num_filters_1': 127, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.022690889418959404, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 22, 'num_filters_3': 68}"}}
exception: None

00:42:50 job_callback for (8, 0, 4) started
00:42:50 DISPATCHER: Trying to submit another job.
00:42:50 job_callback for (8, 0, 4) got condition
00:42:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:42:50 HBMASTER: Trying to run another job!
00:42:50 job_callback for (8, 0, 4) finished
00:42:50 start sampling a new configuration.
00:42:50 best_vector: [1, 2, 0.024700378408122725, 0.8634732017029594, 0.3677903591733378, 1, 0.5899189725324957, 0.9415946084914588, 2, 2, 1, 2, 0.8107282515272478, 0.8187354044965357, 0.6423019961183616, 0.5583145750418634], 1.6778756332421753e-29, 0.0005959917291770251, -1.0343003518766364e-06
00:42:50 done sampling a new configuration.
00:42:50 HBMASTER: schedule new run for iteration 8
00:42:50 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
00:42:50 HBMASTER: submitting job (8, 0, 5) to dispatcher
00:42:50 DISPATCHER: trying to submit job (8, 0, 5)
00:42:50 DISPATCHER: trying to notify the job_runner thread.
00:42:50 HBMASTER: job (8, 0, 5) submitted to dispatcher
00:42:50 DISPATCHER: Trying to submit another job.
00:42:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:42:50 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:42:50 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:42:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:42:50 WORKER: start processing job (8, 0, 5)
00:42:50 WORKER: args: ()
00:42:50 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001120471351387361, 'num_filters_1': 96, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.16789695871596597, 'kernel_size_2': 7, 'num_filters_2': 86}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:43:32 DISPATCHER: Starting worker discovery
00:43:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:43:32 DISPATCHER: Finished worker discovery
00:44:09 WORKER: done with job (8, 0, 5), trying to register it.
00:44:09 WORKER: registered result for job (8, 0, 5) with dispatcher
00:44:09 DISPATCHER: job (8, 0, 5) finished
00:44:09 DISPATCHER: register_result: lock acquired
00:44:09 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:44:09 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001120471351387361, 'num_filters_1': 96, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.16789695871596597, 'kernel_size_2': 7, 'num_filters_2': 86}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.41418387183729055, 'info': {'data03': 0.41418387183729055, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001120471351387361, 'num_filters_1': 96, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.16789695871596597, 'kernel_size_2': 7, 'num_filters_2': 86}"}}
exception: None

00:44:09 job_callback for (8, 0, 5) started
00:44:09 job_callback for (8, 0, 5) got condition
00:44:09 DISPATCHER: Trying to submit another job.
00:44:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:44:09 HBMASTER: Trying to run another job!
00:44:09 job_callback for (8, 0, 5) finished
00:44:09 start sampling a new configuration.
00:44:09 done sampling a new configuration.
00:44:09 HBMASTER: schedule new run for iteration 8
00:44:09 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
00:44:09 HBMASTER: submitting job (8, 0, 6) to dispatcher
00:44:09 DISPATCHER: trying to submit job (8, 0, 6)
00:44:09 DISPATCHER: trying to notify the job_runner thread.
00:44:09 HBMASTER: job (8, 0, 6) submitted to dispatcher
00:44:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:44:09 DISPATCHER: Trying to submit another job.
00:44:09 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:44:09 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:44:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:44:09 WORKER: start processing job (8, 0, 6)
00:44:09 WORKER: args: ()
00:44:09 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0040170118719747225, 'num_filters_1': 31, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.018944750962633823}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:44:32 DISPATCHER: Starting worker discovery
00:44:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:44:32 DISPATCHER: Finished worker discovery
00:45:27 WORKER: done with job (8, 0, 6), trying to register it.
00:45:27 WORKER: registered result for job (8, 0, 6) with dispatcher
00:45:27 DISPATCHER: job (8, 0, 6) finished
00:45:27 DISPATCHER: register_result: lock acquired
00:45:27 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:45:27 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0040170118719747225, 'num_filters_1': 31, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.018944750962633823}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.27720745852631506, 'info': {'data03': 0.27720745852631506, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0040170118719747225, 'num_filters_1': 31, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.018944750962633823}"}}
exception: None

00:45:27 job_callback for (8, 0, 6) started
00:45:27 job_callback for (8, 0, 6) got condition
00:45:27 DISPATCHER: Trying to submit another job.
00:45:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:45:27 HBMASTER: Trying to run another job!
00:45:27 job_callback for (8, 0, 6) finished
00:45:27 start sampling a new configuration.
00:45:27 done sampling a new configuration.
00:45:27 HBMASTER: schedule new run for iteration 8
00:45:27 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
00:45:27 HBMASTER: submitting job (8, 0, 7) to dispatcher
00:45:27 DISPATCHER: trying to submit job (8, 0, 7)
00:45:27 DISPATCHER: trying to notify the job_runner thread.
00:45:27 HBMASTER: job (8, 0, 7) submitted to dispatcher
00:45:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:45:27 DISPATCHER: Trying to submit another job.
00:45:27 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:45:27 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:45:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:45:27 WORKER: start processing job (8, 0, 7)
00:45:27 WORKER: args: ()
00:45:27 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0012010396690682913, 'num_filters_1': 74, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.02944280047358764, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 81, 'num_filters_3': 21, 'num_filters_4': 37, 'num_filters_5': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:45:32 DISPATCHER: Starting worker discovery
00:45:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:45:32 DISPATCHER: Finished worker discovery
00:46:32 DISPATCHER: Starting worker discovery
00:46:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:46:32 DISPATCHER: Finished worker discovery
00:46:45 WORKER: done with job (8, 0, 7), trying to register it.
00:46:45 WORKER: registered result for job (8, 0, 7) with dispatcher
00:46:45 DISPATCHER: job (8, 0, 7) finished
00:46:45 DISPATCHER: register_result: lock acquired
00:46:45 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:46:45 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0012010396690682913, 'num_filters_1': 74, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.02944280047358764, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 81, 'num_filters_3': 21, 'num_filters_4': 37, 'num_filters_5': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.43570615967058435, 'info': {'data03': 0.43570615967058435, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0012010396690682913, 'num_filters_1': 74, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.02944280047358764, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 81, 'num_filters_3': 21, 'num_filters_4': 37, 'num_filters_5': 17}"}}
exception: None

00:46:45 job_callback for (8, 0, 7) started
00:46:45 job_callback for (8, 0, 7) got condition
00:46:45 DISPATCHER: Trying to submit another job.
00:46:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:46:45 HBMASTER: Trying to run another job!
00:46:45 job_callback for (8, 0, 7) finished
00:46:45 start sampling a new configuration.
00:46:46 best_vector: [0, 0, 0.1583793710224077, 0.4106956983466393, 0.03527264478761928, 0, 0.8706213629100696, 0.4639829118987633, 2, 2, 1, 0, 0.2113389361790654, 0.863564044575902, 0.6299669347414883, 0.9643419897806296], 5.290386020294016e-29, 0.00018902212355846666, -8.49149604816435e-14
00:46:46 done sampling a new configuration.
00:46:46 HBMASTER: schedule new run for iteration 8
00:46:46 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
00:46:46 HBMASTER: submitting job (8, 0, 8) to dispatcher
00:46:46 DISPATCHER: trying to submit job (8, 0, 8)
00:46:46 DISPATCHER: trying to notify the job_runner thread.
00:46:46 HBMASTER: job (8, 0, 8) submitted to dispatcher
00:46:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:46:46 DISPATCHER: Trying to submit another job.
00:46:46 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:46:46 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:46:46 WORKER: start processing job (8, 0, 8)
00:46:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:46:46 WORKER: args: ()
00:46:46 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002073761187881196, 'num_filters_1': 37, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.04014723922650323}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:47:32 DISPATCHER: Starting worker discovery
00:47:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:47:32 DISPATCHER: Finished worker discovery
00:48:04 WORKER: done with job (8, 0, 8), trying to register it.
00:48:04 WORKER: registered result for job (8, 0, 8) with dispatcher
00:48:04 DISPATCHER: job (8, 0, 8) finished
00:48:04 DISPATCHER: register_result: lock acquired
00:48:04 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:48:04 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002073761187881196, 'num_filters_1': 37, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.04014723922650323}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.31347661761862755, 'info': {'data03': 0.31347661761862755, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002073761187881196, 'num_filters_1': 37, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.04014723922650323}"}}
exception: None

00:48:04 job_callback for (8, 0, 8) started
00:48:04 DISPATCHER: Trying to submit another job.
00:48:04 job_callback for (8, 0, 8) got condition
00:48:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:48:04 HBMASTER: Trying to run another job!
00:48:04 job_callback for (8, 0, 8) finished
00:48:04 start sampling a new configuration.
00:48:04 done sampling a new configuration.
00:48:04 HBMASTER: schedule new run for iteration 8
00:48:04 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
00:48:04 HBMASTER: submitting job (8, 0, 9) to dispatcher
00:48:04 DISPATCHER: trying to submit job (8, 0, 9)
00:48:04 DISPATCHER: trying to notify the job_runner thread.
00:48:04 HBMASTER: job (8, 0, 9) submitted to dispatcher
00:48:04 DISPATCHER: Trying to submit another job.
00:48:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:48:04 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:48:04 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:48:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:48:04 WORKER: start processing job (8, 0, 9)
00:48:04 WORKER: args: ()
00:48:04 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.03594136761306271, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.060036008458797314}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:48:32 DISPATCHER: Starting worker discovery
00:48:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:48:32 DISPATCHER: Finished worker discovery
00:49:23 WORKER: done with job (8, 0, 9), trying to register it.
00:49:23 WORKER: registered result for job (8, 0, 9) with dispatcher
00:49:23 DISPATCHER: job (8, 0, 9) finished
00:49:23 DISPATCHER: register_result: lock acquired
00:49:23 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:49:23 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.03594136761306271, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.060036008458797314}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.394944461793835, 'info': {'data03': 0.394944461793835, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.03594136761306271, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.060036008458797314}"}}
exception: None

00:49:23 job_callback for (8, 0, 9) started
00:49:23 DISPATCHER: Trying to submit another job.
00:49:23 job_callback for (8, 0, 9) got condition
00:49:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:49:23 HBMASTER: Trying to run another job!
00:49:23 job_callback for (8, 0, 9) finished
00:49:23 start sampling a new configuration.
00:49:23 best_vector: [2, 0, 0.052519632964762156, 0.3092874574147837, 0.7490750411857572, 1, 0.892349807687694, 0.6962521456275802, 1, 1, 2, 2, 0.6217484537630793, 0.4061301047479675, 0.9600621691371477, 0.4336799896054147], 4.3274711780482024e-30, 0.0023108183945225605, -8.552768694236519e-08
00:49:23 done sampling a new configuration.
00:49:23 HBMASTER: schedule new run for iteration 8
00:49:23 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
00:49:23 HBMASTER: submitting job (8, 0, 10) to dispatcher
00:49:23 DISPATCHER: trying to submit job (8, 0, 10)
00:49:23 DISPATCHER: trying to notify the job_runner thread.
00:49:23 HBMASTER: job (8, 0, 10) submitted to dispatcher
00:49:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:49:23 DISPATCHER: Trying to submit another job.
00:49:23 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:49:23 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:49:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:49:23 WORKER: start processing job (8, 0, 10)
00:49:23 WORKER: args: ()
00:49:23 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0012736182276393967, 'num_filters_1': 30, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.0805090915198123, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 58, 'num_filters_3': 37, 'num_filters_4': 118}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:49:32 DISPATCHER: Starting worker discovery
00:49:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:49:32 DISPATCHER: Finished worker discovery
00:50:32 DISPATCHER: Starting worker discovery
00:50:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:50:32 DISPATCHER: Finished worker discovery
00:50:47 WORKER: done with job (8, 0, 10), trying to register it.
00:50:47 WORKER: registered result for job (8, 0, 10) with dispatcher
00:50:47 DISPATCHER: job (8, 0, 10) finished
00:50:47 DISPATCHER: register_result: lock acquired
00:50:47 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:50:47 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0012736182276393967, 'num_filters_1': 30, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.0805090915198123, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 58, 'num_filters_3': 37, 'num_filters_4': 118}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.38014645808936964, 'info': {'data03': 0.38014645808936964, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0012736182276393967, 'num_filters_1': 30, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.0805090915198123, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 58, 'num_filters_3': 37, 'num_filters_4': 118}"}}
exception: None

00:50:47 job_callback for (8, 0, 10) started
00:50:47 job_callback for (8, 0, 10) got condition
00:50:47 DISPATCHER: Trying to submit another job.
00:50:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:50:47 HBMASTER: Trying to run another job!
00:50:47 job_callback for (8, 0, 10) finished
00:50:47 start sampling a new configuration.
00:50:47 best_vector: [2, 1, 0.8634235236952658, 0.16457975287338678, 0.8566073020709315, 1, 0.616969269758808, 0.2010839942356253, 1, 1, 1, 0, 0.6212565510625763, 0.4217740255420727, 0.5674122829735959, 0.1451285886031387], 2.114140113828523e-28, 4.73005546538298e-05, -7.678307374567111e-20
00:50:47 done sampling a new configuration.
00:50:47 HBMASTER: schedule new run for iteration 8
00:50:47 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
00:50:47 HBMASTER: submitting job (8, 0, 11) to dispatcher
00:50:47 DISPATCHER: trying to submit job (8, 0, 11)
00:50:47 DISPATCHER: trying to notify the job_runner thread.
00:50:47 HBMASTER: job (8, 0, 11) submitted to dispatcher
00:50:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:50:47 DISPATCHER: Trying to submit another job.
00:50:47 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:50:47 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:50:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:50:47 WORKER: start processing job (8, 0, 11)
00:50:47 WORKER: args: ()
00:50:47 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.05331470952638704, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.01826485833672732, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 58, 'num_filters_3': 38, 'num_filters_4': 51, 'num_filters_5': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:51:32 DISPATCHER: Starting worker discovery
00:51:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:51:32 DISPATCHER: Finished worker discovery
00:52:11 WORKER: done with job (8, 0, 11), trying to register it.
00:52:11 WORKER: registered result for job (8, 0, 11) with dispatcher
00:52:11 DISPATCHER: job (8, 0, 11) finished
00:52:11 DISPATCHER: register_result: lock acquired
00:52:11 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:52:11 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.05331470952638704, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.01826485833672732, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 58, 'num_filters_3': 38, 'num_filters_4': 51, 'num_filters_5': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2849366112857954, 'info': {'data03': 0.2849366112857954, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.05331470952638704, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.01826485833672732, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 58, 'num_filters_3': 38, 'num_filters_4': 51, 'num_filters_5': 21}"}}
exception: None

00:52:11 job_callback for (8, 0, 11) started
00:52:11 DISPATCHER: Trying to submit another job.
00:52:11 job_callback for (8, 0, 11) got condition
00:52:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:52:11 HBMASTER: Trying to run another job!
00:52:11 job_callback for (8, 0, 11) finished
00:52:11 start sampling a new configuration.
00:52:11 best_vector: [2, 0, 0.6918429168713379, 0.370317404606087, 0.7173205236113108, 1, 0.7220021961753306, 0.6267407872493804, 0, 1, 0, 0, 0.750934725699098, 0.9775600471285772, 0.7449991673516067, 0.264131513772631], 1.3169562536823744e-29, 0.0007593266649547964, -5.566499138112245e-14
00:52:11 done sampling a new configuration.
00:52:11 HBMASTER: schedule new run for iteration 8
00:52:11 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
00:52:11 HBMASTER: submitting job (8, 0, 12) to dispatcher
00:52:11 DISPATCHER: trying to submit job (8, 0, 12)
00:52:11 DISPATCHER: trying to notify the job_runner thread.
00:52:11 HBMASTER: job (8, 0, 12) submitted to dispatcher
00:52:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:52:11 DISPATCHER: Trying to submit another job.
00:52:11 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:52:11 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:52:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:52:11 WORKER: start processing job (8, 0, 12)
00:52:11 WORKER: args: ()
00:52:11 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.02419278320849685, 'num_filters_1': 34, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.06537452761010007, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 76, 'num_filters_3': 123, 'num_filters_4': 75}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:52:32 DISPATCHER: Starting worker discovery
00:52:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:52:32 DISPATCHER: Finished worker discovery
00:53:32 DISPATCHER: Starting worker discovery
00:53:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:53:32 DISPATCHER: Finished worker discovery
00:53:36 WORKER: done with job (8, 0, 12), trying to register it.
00:53:36 WORKER: registered result for job (8, 0, 12) with dispatcher
00:53:36 DISPATCHER: job (8, 0, 12) finished
00:53:36 DISPATCHER: register_result: lock acquired
00:53:36 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:53:36 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.02419278320849685, 'num_filters_1': 34, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.06537452761010007, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 76, 'num_filters_3': 123, 'num_filters_4': 75}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3103048005256554, 'info': {'data03': 0.3103048005256554, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.02419278320849685, 'num_filters_1': 34, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.06537452761010007, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 76, 'num_filters_3': 123, 'num_filters_4': 75}"}}
exception: None

00:53:36 job_callback for (8, 0, 12) started
00:53:36 DISPATCHER: Trying to submit another job.
00:53:36 job_callback for (8, 0, 12) got condition
00:53:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:53:36 HBMASTER: Trying to run another job!
00:53:36 job_callback for (8, 0, 12) finished
00:53:36 start sampling a new configuration.
00:53:36 done sampling a new configuration.
00:53:36 HBMASTER: schedule new run for iteration 8
00:53:36 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
00:53:36 HBMASTER: submitting job (8, 0, 13) to dispatcher
00:53:36 DISPATCHER: trying to submit job (8, 0, 13)
00:53:36 DISPATCHER: trying to notify the job_runner thread.
00:53:36 HBMASTER: job (8, 0, 13) submitted to dispatcher
00:53:36 DISPATCHER: Trying to submit another job.
00:53:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:53:36 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:53:36 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:53:36 WORKER: start processing job (8, 0, 13)
00:53:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:53:36 WORKER: args: ()
00:53:36 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0011601569412783886, 'num_filters_1': 28, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.015332787749611419, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 118, 'num_filters_3': 16, 'num_filters_4': 53, 'num_filters_5': 37}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:54:32 DISPATCHER: Starting worker discovery
00:54:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:54:32 DISPATCHER: Finished worker discovery
00:55:00 WORKER: done with job (8, 0, 13), trying to register it.
00:55:00 WORKER: registered result for job (8, 0, 13) with dispatcher
00:55:00 DISPATCHER: job (8, 0, 13) finished
00:55:00 DISPATCHER: register_result: lock acquired
00:55:00 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:55:00 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0011601569412783886, 'num_filters_1': 28, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.015332787749611419, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 118, 'num_filters_3': 16, 'num_filters_4': 53, 'num_filters_5': 37}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3528050809944495, 'info': {'data03': 0.3528050809944495, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0011601569412783886, 'num_filters_1': 28, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.015332787749611419, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 118, 'num_filters_3': 16, 'num_filters_4': 53, 'num_filters_5': 37}"}}
exception: None

00:55:00 job_callback for (8, 0, 13) started
00:55:00 DISPATCHER: Trying to submit another job.
00:55:00 job_callback for (8, 0, 13) got condition
00:55:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:55:00 HBMASTER: Trying to run another job!
00:55:00 job_callback for (8, 0, 13) finished
00:55:00 start sampling a new configuration.
00:55:00 best_vector: [0, 2, 0.38607003519917615, 0.8225132141838448, 0.2941575540698028, 1, 0.4183834577933825, 0.8933710033212442, 0, 2, 0, 2, 0.5333466991245095, 0.7711532362380594, 0.7313221504823351, 0.9634913682914865], 3.0367142450432616e-29, 0.0003293032927389432, -9.234980411511487e-12
00:55:00 done sampling a new configuration.
00:55:00 HBMASTER: schedule new run for iteration 8
00:55:00 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
00:55:00 HBMASTER: submitting job (8, 0, 14) to dispatcher
00:55:00 DISPATCHER: trying to submit job (8, 0, 14)
00:55:00 DISPATCHER: trying to notify the job_runner thread.
00:55:00 HBMASTER: job (8, 0, 14) submitted to dispatcher
00:55:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:55:00 DISPATCHER: Trying to submit another job.
00:55:00 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:55:00 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:55:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:55:00 WORKER: start processing job (8, 0, 14)
00:55:00 WORKER: args: ()
00:55:00 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005917524577775523, 'num_filters_1': 88, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.14531233203615834, 'kernel_size_2': 3, 'num_filters_2': 48}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:55:32 DISPATCHER: Starting worker discovery
00:55:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:55:32 DISPATCHER: Finished worker discovery
00:56:24 WORKER: done with job (8, 0, 14), trying to register it.
00:56:24 WORKER: registered result for job (8, 0, 14) with dispatcher
00:56:24 DISPATCHER: job (8, 0, 14) finished
00:56:24 DISPATCHER: register_result: lock acquired
00:56:24 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:56:24 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005917524577775523, 'num_filters_1': 88, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.14531233203615834, 'kernel_size_2': 3, 'num_filters_2': 48}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.301535410499715, 'info': {'data03': 0.301535410499715, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005917524577775523, 'num_filters_1': 88, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.14531233203615834, 'kernel_size_2': 3, 'num_filters_2': 48}"}}
exception: None

00:56:24 job_callback for (8, 0, 14) started
00:56:24 job_callback for (8, 0, 14) got condition
00:56:24 DISPATCHER: Trying to submit another job.
00:56:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:56:24 HBMASTER: Trying to run another job!
00:56:24 job_callback for (8, 0, 14) finished
00:56:24 start sampling a new configuration.
00:56:25 best_vector: [0, 2, 0.030721891872180284, 0.029256027322256628, 0.6470741020834, 0, 0.8699405954082746, 0.8577614092759202, 0, 0, 0, 2, 0.2530057428315497, 0.7011874823746975, 0.7565981631208057, 0.8084212362176729], 2.0087956122472214e-29, 0.0004978107249454359, -1.0112312414255292e-10
00:56:25 done sampling a new configuration.
00:56:25 HBMASTER: schedule new run for iteration 8
00:56:25 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
00:56:25 HBMASTER: submitting job (8, 0, 15) to dispatcher
00:56:25 DISPATCHER: trying to submit job (8, 0, 15)
00:56:25 DISPATCHER: trying to notify the job_runner thread.
00:56:25 HBMASTER: job (8, 0, 15) submitted to dispatcher
00:56:25 DISPATCHER: Trying to submit another job.
00:56:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:56:25 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:56:25 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:56:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:56:25 WORKER: start processing job (8, 0, 15)
00:56:25 WORKER: args: ()
00:56:25 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.001151976935155564, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.13060906564312658, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 26, 'num_filters_3': 68, 'num_filters_4': 77}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:56:32 DISPATCHER: Starting worker discovery
00:56:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:56:32 DISPATCHER: Finished worker discovery
00:57:32 DISPATCHER: Starting worker discovery
00:57:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:57:32 DISPATCHER: Finished worker discovery
00:57:47 WORKER: done with job (8, 0, 15), trying to register it.
00:57:47 WORKER: registered result for job (8, 0, 15) with dispatcher
00:57:47 DISPATCHER: job (8, 0, 15) finished
00:57:47 DISPATCHER: register_result: lock acquired
00:57:47 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:57:47 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.001151976935155564, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.13060906564312658, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 26, 'num_filters_3': 68, 'num_filters_4': 77}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.33162269861331173, 'info': {'data03': 0.33162269861331173, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.001151976935155564, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.13060906564312658, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 26, 'num_filters_3': 68, 'num_filters_4': 77}"}}
exception: None

00:57:47 job_callback for (8, 0, 15) started
00:57:47 job_callback for (8, 0, 15) got condition
00:57:47 DISPATCHER: Trying to submit another job.
00:57:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:57:47 HBMASTER: Trying to run another job!
00:57:47 job_callback for (8, 0, 15) finished
00:57:47 start sampling a new configuration.
00:57:47 best_vector: [3, 1, 0.6005577422599668, 0.030965934851748145, 0.2050770737631769, 1, 0.22103877027736152, 0.6185862779305209, 2, 2, 0, 0, 0.49396080360507344, 0.8576491683936461, 0.7990511993918605, 0.696815012158349], 9.795774189161108e-30, 0.0010208483583732325, -7.800118920208965e-05
00:57:47 done sampling a new configuration.
00:57:47 HBMASTER: schedule new run for iteration 8
00:57:47 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
00:57:47 HBMASTER: submitting job (8, 0, 16) to dispatcher
00:57:47 DISPATCHER: trying to submit job (8, 0, 16)
00:57:47 DISPATCHER: trying to notify the job_runner thread.
00:57:47 HBMASTER: job (8, 0, 16) submitted to dispatcher
00:57:47 DISPATCHER: Trying to submit another job.
00:57:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:57:47 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:57:47 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:57:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:57:47 WORKER: start processing job (8, 0, 16)
00:57:47 WORKER: args: ()
00:57:47 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.015889692198924093, 'num_filters_1': 17, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.063796859804112, 'kernel_size_2': 7, 'num_filters_2': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:58:32 DISPATCHER: Starting worker discovery
00:58:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:58:32 DISPATCHER: Finished worker discovery
00:59:10 WORKER: done with job (8, 0, 16), trying to register it.
00:59:10 WORKER: registered result for job (8, 0, 16) with dispatcher
00:59:10 DISPATCHER: job (8, 0, 16) finished
00:59:10 DISPATCHER: register_result: lock acquired
00:59:10 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:59:10 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.015889692198924093, 'num_filters_1': 17, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.063796859804112, 'kernel_size_2': 7, 'num_filters_2': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3892415673266175, 'info': {'data03': 0.3892415673266175, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.015889692198924093, 'num_filters_1': 17, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.063796859804112, 'kernel_size_2': 7, 'num_filters_2': 44}"}}
exception: None

00:59:10 job_callback for (8, 0, 16) started
00:59:10 DISPATCHER: Trying to submit another job.
00:59:10 job_callback for (8, 0, 16) got condition
00:59:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:59:10 HBMASTER: Trying to run another job!
00:59:10 job_callback for (8, 0, 16) finished
00:59:10 start sampling a new configuration.
00:59:10 done sampling a new configuration.
00:59:10 HBMASTER: schedule new run for iteration 8
00:59:10 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
00:59:10 HBMASTER: submitting job (8, 0, 17) to dispatcher
00:59:10 DISPATCHER: trying to submit job (8, 0, 17)
00:59:10 DISPATCHER: trying to notify the job_runner thread.
00:59:10 HBMASTER: job (8, 0, 17) submitted to dispatcher
00:59:10 DISPATCHER: Trying to submit another job.
00:59:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:59:10 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:59:10 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:59:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:59:10 WORKER: start processing job (8, 0, 17)
00:59:10 WORKER: args: ()
00:59:10 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.09495101524000768, 'num_filters_1': 101, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.04122953308558951, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 112, 'num_filters_3': 33, 'num_filters_4': 63}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:59:32 DISPATCHER: Starting worker discovery
00:59:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:59:32 DISPATCHER: Finished worker discovery
01:00:32 WORKER: done with job (8, 0, 17), trying to register it.
01:00:32 WORKER: registered result for job (8, 0, 17) with dispatcher
01:00:32 DISPATCHER: job (8, 0, 17) finished
01:00:32 DISPATCHER: register_result: lock acquired
01:00:32 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:00:32 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.09495101524000768, 'num_filters_1': 101, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.04122953308558951, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 112, 'num_filters_3': 33, 'num_filters_4': 63}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.09495101524000768, 'num_filters_1': 101, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.04122953308558951, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 112, 'num_filters_3': 33, 'num_filters_4': 63}"}}
exception: None

01:00:32 job_callback for (8, 0, 17) started
01:00:32 DISPATCHER: Trying to submit another job.
01:00:32 job_callback for (8, 0, 17) got condition
01:00:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:00:32 HBMASTER: Trying to run another job!
01:00:32 job_callback for (8, 0, 17) finished
01:00:32 start sampling a new configuration.
01:00:32 best_vector: [3, 0, 0.12132542797155042, 0.9722915269913905, 0.0781670208389755, 1, 0.5177246197226989, 0.12140491046817814, 1, 0, 1, 0, 0.005365923644789911, 0.15488690572979344, 0.8489294828063477, 0.6520532147956757], 1.7942000655616054e-29, 0.0005573514454682558, -7.254039492718704e-09
01:00:32 done sampling a new configuration.
01:00:32 HBMASTER: schedule new run for iteration 8
01:00:32 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
01:00:32 HBMASTER: submitting job (8, 0, 18) to dispatcher
01:00:32 DISPATCHER: trying to submit job (8, 0, 18)
01:00:32 DISPATCHER: trying to notify the job_runner thread.
01:00:32 HBMASTER: job (8, 0, 18) submitted to dispatcher
01:00:32 DISPATCHER: Trying to submit another job.
01:00:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:00:32 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:00:32 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:00:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:00:32 WORKER: start processing job (8, 0, 18)
01:00:32 WORKER: args: ()
01:00:32 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0017484404928705586, 'num_filters_1': 121, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.014386376774364988}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:00:32 DISPATCHER: Starting worker discovery
01:00:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:00:32 DISPATCHER: Finished worker discovery
01:01:32 DISPATCHER: Starting worker discovery
01:01:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:01:32 DISPATCHER: Finished worker discovery
01:01:53 WORKER: done with job (8, 0, 18), trying to register it.
01:01:53 WORKER: registered result for job (8, 0, 18) with dispatcher
01:01:53 DISPATCHER: job (8, 0, 18) finished
01:01:53 DISPATCHER: register_result: lock acquired
01:01:53 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:01:53 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0017484404928705586, 'num_filters_1': 121, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.014386376774364988}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3869118515086819, 'info': {'data03': 0.3869118515086819, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0017484404928705586, 'num_filters_1': 121, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.014386376774364988}"}}
exception: None

01:01:53 job_callback for (8, 0, 18) started
01:01:53 DISPATCHER: Trying to submit another job.
01:01:53 job_callback for (8, 0, 18) got condition
01:01:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:01:53 HBMASTER: Trying to run another job!
01:01:53 job_callback for (8, 0, 18) finished
01:01:53 start sampling a new configuration.
01:01:53 done sampling a new configuration.
01:01:53 HBMASTER: schedule new run for iteration 8
01:01:53 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
01:01:53 HBMASTER: submitting job (8, 0, 19) to dispatcher
01:01:53 DISPATCHER: trying to submit job (8, 0, 19)
01:01:53 DISPATCHER: trying to notify the job_runner thread.
01:01:53 HBMASTER: job (8, 0, 19) submitted to dispatcher
01:01:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:01:53 DISPATCHER: Trying to submit another job.
01:01:53 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:01:53 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:01:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:01:53 WORKER: start processing job (8, 0, 19)
01:01:53 WORKER: args: ()
01:01:53 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.00946860668725265, 'num_filters_1': 56, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.03838526432241355}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:02:32 DISPATCHER: Starting worker discovery
01:02:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:02:32 DISPATCHER: Finished worker discovery
01:03:14 WORKER: done with job (8, 0, 19), trying to register it.
01:03:14 WORKER: registered result for job (8, 0, 19) with dispatcher
01:03:14 DISPATCHER: job (8, 0, 19) finished
01:03:14 DISPATCHER: register_result: lock acquired
01:03:14 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:03:14 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.00946860668725265, 'num_filters_1': 56, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.03838526432241355}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.45188688069726834, 'info': {'data03': 0.45188688069726834, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.00946860668725265, 'num_filters_1': 56, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.03838526432241355}"}}
exception: None

01:03:14 job_callback for (8, 0, 19) started
01:03:14 job_callback for (8, 0, 19) got condition
01:03:14 DISPATCHER: Trying to submit another job.
01:03:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:03:14 HBMASTER: Trying to run another job!
01:03:14 job_callback for (8, 0, 19) finished
01:03:14 start sampling a new configuration.
01:03:14 best_vector: [1, 2, 0.08715614317285914, 0.7618979413079154, 0.2703679437481104, 1, 0.6759093317755586, 0.3399059437290073, 2, 2, 2, 1, 0.6963956374947836, 0.8310019097151788, 0.7424892693696711, 0.5407146424035455], 4.5578946123219145e-30, 0.0021939954410015922, -0.0022092174367160477
01:03:14 done sampling a new configuration.
01:03:14 HBMASTER: schedule new run for iteration 8
01:03:14 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
01:03:14 HBMASTER: submitting job (8, 0, 20) to dispatcher
01:03:14 DISPATCHER: trying to submit job (8, 0, 20)
01:03:14 DISPATCHER: trying to notify the job_runner thread.
01:03:14 HBMASTER: job (8, 0, 20) submitted to dispatcher
01:03:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:03:14 DISPATCHER: Trying to submit another job.
01:03:14 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:03:14 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:03:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:03:14 WORKER: start processing job (8, 0, 20)
01:03:14 WORKER: args: ()
01:03:14 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0014938682131328252, 'num_filters_1': 78, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.027683935485731236, 'kernel_size_2': 7, 'num_filters_2': 68}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:03:32 DISPATCHER: Starting worker discovery
01:03:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:03:32 DISPATCHER: Finished worker discovery
01:04:32 DISPATCHER: Starting worker discovery
01:04:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:04:32 DISPATCHER: Finished worker discovery
01:04:34 WORKER: done with job (8, 0, 20), trying to register it.
01:04:34 WORKER: registered result for job (8, 0, 20) with dispatcher
01:04:34 DISPATCHER: job (8, 0, 20) finished
01:04:34 DISPATCHER: register_result: lock acquired
01:04:34 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:04:34 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0014938682131328252, 'num_filters_1': 78, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.027683935485731236, 'kernel_size_2': 7, 'num_filters_2': 68}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3195138282850077, 'info': {'data03': 0.3195138282850077, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0014938682131328252, 'num_filters_1': 78, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.027683935485731236, 'kernel_size_2': 7, 'num_filters_2': 68}"}}
exception: None

01:04:34 job_callback for (8, 0, 20) started
01:04:34 DISPATCHER: Trying to submit another job.
01:04:34 job_callback for (8, 0, 20) got condition
01:04:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:04:34 HBMASTER: Trying to run another job!
01:04:34 job_callback for (8, 0, 20) finished
01:04:34 start sampling a new configuration.
01:04:34 best_vector: [2, 2, 0.3813270338871406, 0.14701894126415027, 0.7338080841460737, 0, 0.2806622828622408, 0.6550215044550303, 0, 2, 1, 2, 0.8099396282554248, 0.56476291973512, 0.9313348732223802, 0.32366126663445177], 2.193197648325409e-30, 0.00455955258188216, -9.63992106921755e-12
01:04:34 done sampling a new configuration.
01:04:34 HBMASTER: schedule new run for iteration 8
01:04:34 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
01:04:34 HBMASTER: submitting job (8, 0, 21) to dispatcher
01:04:34 DISPATCHER: trying to submit job (8, 0, 21)
01:04:34 DISPATCHER: trying to notify the job_runner thread.
01:04:34 HBMASTER: job (8, 0, 21) submitted to dispatcher
01:04:34 DISPATCHER: Trying to submit another job.
01:04:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:04:34 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:04:34 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:04:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:04:34 WORKER: start processing job (8, 0, 21)
01:04:34 WORKER: args: ()
01:04:34 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0057896734299540615, 'num_filters_1': 21, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.07115454159437212, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 86, 'num_filters_3': 51, 'num_filters_4': 111}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:05:32 DISPATCHER: Starting worker discovery
01:05:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:05:32 DISPATCHER: Finished worker discovery
01:05:54 WORKER: done with job (8, 0, 21), trying to register it.
01:05:54 WORKER: registered result for job (8, 0, 21) with dispatcher
01:05:54 DISPATCHER: job (8, 0, 21) finished
01:05:54 DISPATCHER: register_result: lock acquired
01:05:54 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:05:54 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0057896734299540615, 'num_filters_1': 21, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.07115454159437212, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 86, 'num_filters_3': 51, 'num_filters_4': 111}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.23497369254722347, 'info': {'data03': 0.23497369254722347, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0057896734299540615, 'num_filters_1': 21, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.07115454159437212, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 86, 'num_filters_3': 51, 'num_filters_4': 111}"}}
exception: None

01:05:54 job_callback for (8, 0, 21) started
01:05:54 DISPATCHER: Trying to submit another job.
01:05:54 job_callback for (8, 0, 21) got condition
01:05:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:05:54 HBMASTER: Trying to run another job!
01:05:54 job_callback for (8, 0, 21) finished
01:05:54 start sampling a new configuration.
01:05:54 best_vector: [2, 0, 0.2787988652687137, 0.15524524083177782, 0.7671231661451089, 1, 0.8224662806953429, 0.16192782749820656, 1, 1, 2, 2, 0.48958184995819265, 0.6452997198160515, 0.8408302957054344, 0.32332929846610103], 1.0859267897129928e-29, 0.0009208723916501747, -2.0516652605240822e-10
01:05:54 done sampling a new configuration.
01:05:54 HBMASTER: schedule new run for iteration 8
01:05:54 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
01:05:54 HBMASTER: submitting job (8, 0, 22) to dispatcher
01:05:54 DISPATCHER: trying to submit job (8, 0, 22)
01:05:54 DISPATCHER: trying to notify the job_runner thread.
01:05:54 HBMASTER: job (8, 0, 22) submitted to dispatcher
01:05:54 DISPATCHER: Trying to submit another job.
01:05:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:05:54 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:05:54 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:05:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:05:54 WORKER: start processing job (8, 0, 22)
01:05:54 WORKER: args: ()
01:05:54 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0036107525824947253, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.016243251201231143, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 44, 'num_filters_3': 61, 'num_filters_4': 92}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:06:32 DISPATCHER: Starting worker discovery
01:06:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:06:32 DISPATCHER: Finished worker discovery
01:07:14 WORKER: done with job (8, 0, 22), trying to register it.
01:07:14 WORKER: registered result for job (8, 0, 22) with dispatcher
01:07:14 DISPATCHER: job (8, 0, 22) finished
01:07:14 DISPATCHER: register_result: lock acquired
01:07:14 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:07:14 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0036107525824947253, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.016243251201231143, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 44, 'num_filters_3': 61, 'num_filters_4': 92}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.41440942728157043, 'info': {'data03': 0.41440942728157043, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0036107525824947253, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.016243251201231143, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 44, 'num_filters_3': 61, 'num_filters_4': 92}"}}
exception: None

01:07:14 job_callback for (8, 0, 22) started
01:07:14 DISPATCHER: Trying to submit another job.
01:07:14 job_callback for (8, 0, 22) got condition
01:07:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:07:14 HBMASTER: Trying to run another job!
01:07:14 job_callback for (8, 0, 22) finished
01:07:14 start sampling a new configuration.
01:07:14 best_vector: [1, 1, 0.08849786161900702, 0.22043554996919212, 0.25530355331832627, 1, 0.6159691014998507, 0.018478428820590878, 2, 1, 0, 2, 0.8565535740406025, 0.9855005349347392, 0.6854538669031179, 0.4351291327739709], 1.9077636398374795e-30, 0.0052417394855328574, -5.253371278895787e-05
01:07:14 done sampling a new configuration.
01:07:14 HBMASTER: schedule new run for iteration 8
01:07:14 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
01:07:14 HBMASTER: submitting job (8, 0, 23) to dispatcher
01:07:14 DISPATCHER: trying to submit job (8, 0, 23)
01:07:14 DISPATCHER: trying to notify the job_runner thread.
01:07:14 HBMASTER: job (8, 0, 23) submitted to dispatcher
01:07:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:07:14 DISPATCHER: Trying to submit another job.
01:07:14 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:07:14 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:07:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:07:14 WORKER: start processing job (8, 0, 23)
01:07:14 WORKER: args: ()
01:07:14 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0015031271638094625, 'num_filters_1': 25, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.01056917259898434, 'kernel_size_2': 7, 'num_filters_2': 95}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:07:32 DISPATCHER: Starting worker discovery
01:07:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:07:32 DISPATCHER: Finished worker discovery
01:08:32 DISPATCHER: Starting worker discovery
01:08:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:08:32 DISPATCHER: Finished worker discovery
01:08:33 WORKER: done with job (8, 0, 23), trying to register it.
01:08:33 WORKER: registered result for job (8, 0, 23) with dispatcher
01:08:33 DISPATCHER: job (8, 0, 23) finished
01:08:33 DISPATCHER: register_result: lock acquired
01:08:33 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:08:33 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0015031271638094625, 'num_filters_1': 25, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.01056917259898434, 'kernel_size_2': 7, 'num_filters_2': 95}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.35845781249188124, 'info': {'data03': 0.35845781249188124, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0015031271638094625, 'num_filters_1': 25, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.01056917259898434, 'kernel_size_2': 7, 'num_filters_2': 95}"}}
exception: None

01:08:33 job_callback for (8, 0, 23) started
01:08:33 DISPATCHER: Trying to submit another job.
01:08:33 job_callback for (8, 0, 23) got condition
01:08:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:08:33 HBMASTER: Trying to run another job!
01:08:33 job_callback for (8, 0, 23) finished
01:08:33 start sampling a new configuration.
01:08:33 done sampling a new configuration.
01:08:33 HBMASTER: schedule new run for iteration 8
01:08:33 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
01:08:33 HBMASTER: submitting job (8, 0, 24) to dispatcher
01:08:33 DISPATCHER: trying to submit job (8, 0, 24)
01:08:33 DISPATCHER: trying to notify the job_runner thread.
01:08:33 HBMASTER: job (8, 0, 24) submitted to dispatcher
01:08:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:08:33 DISPATCHER: Trying to submit another job.
01:08:33 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:08:33 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:08:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:08:33 WORKER: start processing job (8, 0, 24)
01:08:33 WORKER: args: ()
01:08:33 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.04400045687429192, 'num_filters_1': 17, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.16457475616666606}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:09:32 DISPATCHER: Starting worker discovery
01:09:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:09:32 DISPATCHER: Finished worker discovery
01:09:52 WORKER: done with job (8, 0, 24), trying to register it.
01:09:52 WORKER: registered result for job (8, 0, 24) with dispatcher
01:09:52 DISPATCHER: job (8, 0, 24) finished
01:09:52 DISPATCHER: register_result: lock acquired
01:09:52 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:09:52 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.04400045687429192, 'num_filters_1': 17, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.16457475616666606}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.004728169154688057, 'info': {'data03': 0.004728169154688057, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.04400045687429192, 'num_filters_1': 17, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.16457475616666606}"}}
exception: None

01:09:52 job_callback for (8, 0, 24) started
01:09:52 DISPATCHER: Trying to submit another job.
01:09:52 job_callback for (8, 0, 24) got condition
01:09:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:09:52 HBMASTER: Trying to run another job!
01:09:52 job_callback for (8, 0, 24) finished
01:09:52 start sampling a new configuration.
01:09:52 done sampling a new configuration.
01:09:52 HBMASTER: schedule new run for iteration 8
01:09:52 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
01:09:52 HBMASTER: submitting job (8, 0, 25) to dispatcher
01:09:52 DISPATCHER: trying to submit job (8, 0, 25)
01:09:52 DISPATCHER: trying to notify the job_runner thread.
01:09:52 HBMASTER: job (8, 0, 25) submitted to dispatcher
01:09:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:09:52 DISPATCHER: Trying to submit another job.
01:09:52 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:09:52 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:09:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:09:52 WORKER: start processing job (8, 0, 25)
01:09:52 WORKER: args: ()
01:09:52 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.00688618824619057, 'num_filters_1': 114, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.012955546964772705, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 27, 'num_filters_3': 113, 'num_filters_4': 27, 'num_filters_5': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:10:32 DISPATCHER: Starting worker discovery
01:10:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:10:32 DISPATCHER: Finished worker discovery
01:11:13 WORKER: done with job (8, 0, 25), trying to register it.
01:11:13 WORKER: registered result for job (8, 0, 25) with dispatcher
01:11:13 DISPATCHER: job (8, 0, 25) finished
01:11:13 DISPATCHER: register_result: lock acquired
01:11:13 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:11:13 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.00688618824619057, 'num_filters_1': 114, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.012955546964772705, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 27, 'num_filters_3': 113, 'num_filters_4': 27, 'num_filters_5': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.34561400202041803, 'info': {'data03': 0.34561400202041803, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.00688618824619057, 'num_filters_1': 114, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.012955546964772705, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 27, 'num_filters_3': 113, 'num_filters_4': 27, 'num_filters_5': 44}"}}
exception: None

01:11:13 job_callback for (8, 0, 25) started
01:11:13 DISPATCHER: Trying to submit another job.
01:11:13 job_callback for (8, 0, 25) got condition
01:11:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:11:13 HBMASTER: Trying to run another job!
01:11:13 job_callback for (8, 0, 25) finished
01:11:13 start sampling a new configuration.
01:11:13 best_vector: [3, 2, 0.08505042271124962, 0.44944394410930755, 0.5722630639977591, 0, 0.7723683990334982, 0.4531366799903622, 2, 2, 1, 1, 0.4554722678346024, 0.2423137667453621, 0.6528095675040859, 0.8667699888425903], 7.254648798702613e-30, 0.0013784264790031398, -3.933872649073545e-10
01:11:13 done sampling a new configuration.
01:11:13 HBMASTER: schedule new run for iteration 8
01:11:13 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
01:11:13 HBMASTER: submitting job (8, 0, 26) to dispatcher
01:11:13 DISPATCHER: trying to submit job (8, 0, 26)
01:11:13 DISPATCHER: trying to notify the job_runner thread.
01:11:13 HBMASTER: job (8, 0, 26) submitted to dispatcher
01:11:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:11:13 DISPATCHER: Trying to submit another job.
01:11:13 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:11:13 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:11:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:11:13 WORKER: start processing job (8, 0, 26)
01:11:13 WORKER: args: ()
01:11:13 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.001479451884657105, 'num_filters_1': 40, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.03886372396213192, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 41, 'num_filters_3': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:11:32 DISPATCHER: Starting worker discovery
01:11:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:11:32 DISPATCHER: Finished worker discovery
01:12:32 DISPATCHER: Starting worker discovery
01:12:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:12:32 DISPATCHER: Finished worker discovery
01:12:33 WORKER: done with job (8, 0, 26), trying to register it.
01:12:33 WORKER: registered result for job (8, 0, 26) with dispatcher
01:12:33 DISPATCHER: job (8, 0, 26) finished
01:12:33 DISPATCHER: register_result: lock acquired
01:12:33 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:12:33 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.001479451884657105, 'num_filters_1': 40, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.03886372396213192, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 41, 'num_filters_3': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.39932319669144584, 'info': {'data03': 0.39932319669144584, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.001479451884657105, 'num_filters_1': 40, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.03886372396213192, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 41, 'num_filters_3': 26}"}}
exception: None

01:12:33 job_callback for (8, 0, 26) started
01:12:33 job_callback for (8, 0, 26) got condition
01:12:33 DISPATCHER: Trying to submit another job.
01:12:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:12:33 HBMASTER: Trying to run another job!
01:12:33 job_callback for (8, 0, 26) finished
01:12:33 ITERATION: Advancing config (8, 0, 0) to next budget 133.333333
01:12:33 ITERATION: Advancing config (8, 0, 5) to next budget 133.333333
01:12:33 ITERATION: Advancing config (8, 0, 7) to next budget 133.333333
01:12:33 ITERATION: Advancing config (8, 0, 9) to next budget 133.333333
01:12:33 ITERATION: Advancing config (8, 0, 16) to next budget 133.333333
01:12:33 ITERATION: Advancing config (8, 0, 18) to next budget 133.333333
01:12:33 ITERATION: Advancing config (8, 0, 19) to next budget 133.333333
01:12:33 ITERATION: Advancing config (8, 0, 22) to next budget 133.333333
01:12:33 ITERATION: Advancing config (8, 0, 26) to next budget 133.333333
01:12:33 HBMASTER: schedule new run for iteration 8
01:12:33 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
01:12:33 HBMASTER: submitting job (8, 0, 0) to dispatcher
01:12:33 DISPATCHER: trying to submit job (8, 0, 0)
01:12:33 DISPATCHER: trying to notify the job_runner thread.
01:12:33 HBMASTER: job (8, 0, 0) submitted to dispatcher
01:12:33 DISPATCHER: Trying to submit another job.
01:12:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:12:33 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:12:33 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:12:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:12:33 WORKER: start processing job (8, 0, 0)
01:12:33 WORKER: args: ()
01:12:33 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0031623459208232566, 'num_filters_1': 31, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.026516329267777815, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 35, 'num_filters_3': 100, 'num_filters_4': 27}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:13:32 DISPATCHER: Starting worker discovery
01:13:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:13:32 DISPATCHER: Finished worker discovery
01:14:32 DISPATCHER: Starting worker discovery
01:14:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:14:32 DISPATCHER: Finished worker discovery
01:15:27 WORKER: done with job (8, 0, 0), trying to register it.
01:15:27 WORKER: registered result for job (8, 0, 0) with dispatcher
01:15:27 DISPATCHER: job (8, 0, 0) finished
01:15:27 DISPATCHER: register_result: lock acquired
01:15:27 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:15:27 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0031623459208232566, 'num_filters_1': 31, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.026516329267777815, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 35, 'num_filters_3': 100, 'num_filters_4': 27}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.40439717776394185, 'info': {'data03': 0.40439717776394185, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0031623459208232566, 'num_filters_1': 31, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.026516329267777815, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 35, 'num_filters_3': 100, 'num_filters_4': 27}"}}
exception: None

01:15:27 job_callback for (8, 0, 0) started
01:15:27 job_callback for (8, 0, 0) got condition
01:15:27 DISPATCHER: Trying to submit another job.
01:15:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:15:27 done building a new model for budget 133.333333 based on 17/31 split
Best loss for this budget:-0.433242





01:15:27 HBMASTER: Trying to run another job!
01:15:27 job_callback for (8, 0, 0) finished
01:15:27 HBMASTER: schedule new run for iteration 8
01:15:27 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
01:15:27 HBMASTER: submitting job (8, 0, 5) to dispatcher
01:15:27 DISPATCHER: trying to submit job (8, 0, 5)
01:15:27 DISPATCHER: trying to notify the job_runner thread.
01:15:27 HBMASTER: job (8, 0, 5) submitted to dispatcher
01:15:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:15:27 DISPATCHER: Trying to submit another job.
01:15:27 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:15:27 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:15:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:15:27 WORKER: start processing job (8, 0, 5)
01:15:27 WORKER: args: ()
01:15:27 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001120471351387361, 'num_filters_1': 96, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.16789695871596597, 'kernel_size_2': 7, 'num_filters_2': 86}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:15:32 DISPATCHER: Starting worker discovery
01:15:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:15:32 DISPATCHER: Finished worker discovery
01:16:32 DISPATCHER: Starting worker discovery
01:16:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:16:32 DISPATCHER: Finished worker discovery
01:17:32 DISPATCHER: Starting worker discovery
01:17:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:17:32 DISPATCHER: Finished worker discovery
01:18:15 WORKER: done with job (8, 0, 5), trying to register it.
01:18:15 WORKER: registered result for job (8, 0, 5) with dispatcher
01:18:15 DISPATCHER: job (8, 0, 5) finished
01:18:15 DISPATCHER: register_result: lock acquired
01:18:15 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:18:15 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001120471351387361, 'num_filters_1': 96, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.16789695871596597, 'kernel_size_2': 7, 'num_filters_2': 86}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.28784982775559215, 'info': {'data03': 0.28784982775559215, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.001120471351387361, 'num_filters_1': 96, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.16789695871596597, 'kernel_size_2': 7, 'num_filters_2': 86}"}}
exception: None

01:18:15 job_callback for (8, 0, 5) started
01:18:15 DISPATCHER: Trying to submit another job.
01:18:15 job_callback for (8, 0, 5) got condition
01:18:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:18:15 done building a new model for budget 133.333333 based on 17/32 split
Best loss for this budget:-0.433242





01:18:15 HBMASTER: Trying to run another job!
01:18:15 job_callback for (8, 0, 5) finished
01:18:15 HBMASTER: schedule new run for iteration 8
01:18:15 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
01:18:15 HBMASTER: submitting job (8, 0, 7) to dispatcher
01:18:15 DISPATCHER: trying to submit job (8, 0, 7)
01:18:15 DISPATCHER: trying to notify the job_runner thread.
01:18:15 HBMASTER: job (8, 0, 7) submitted to dispatcher
01:18:15 DISPATCHER: Trying to submit another job.
01:18:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:18:15 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:18:15 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:18:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:18:15 WORKER: start processing job (8, 0, 7)
01:18:15 WORKER: args: ()
01:18:15 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0012010396690682913, 'num_filters_1': 74, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.02944280047358764, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 81, 'num_filters_3': 21, 'num_filters_4': 37, 'num_filters_5': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:18:32 DISPATCHER: Starting worker discovery
01:18:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:18:32 DISPATCHER: Finished worker discovery
01:19:32 DISPATCHER: Starting worker discovery
01:19:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:19:32 DISPATCHER: Finished worker discovery
01:20:32 DISPATCHER: Starting worker discovery
01:20:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:20:32 DISPATCHER: Finished worker discovery
01:21:03 WORKER: done with job (8, 0, 7), trying to register it.
01:21:03 WORKER: registered result for job (8, 0, 7) with dispatcher
01:21:03 DISPATCHER: job (8, 0, 7) finished
01:21:03 DISPATCHER: register_result: lock acquired
01:21:03 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:21:03 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0012010396690682913, 'num_filters_1': 74, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.02944280047358764, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 81, 'num_filters_3': 21, 'num_filters_4': 37, 'num_filters_5': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3679772776062794, 'info': {'data03': 0.3679772776062794, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0012010396690682913, 'num_filters_1': 74, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.02944280047358764, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 81, 'num_filters_3': 21, 'num_filters_4': 37, 'num_filters_5': 17}"}}
exception: None

01:21:03 job_callback for (8, 0, 7) started
01:21:03 job_callback for (8, 0, 7) got condition
01:21:03 DISPATCHER: Trying to submit another job.
01:21:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:21:03 done building a new model for budget 133.333333 based on 17/33 split
Best loss for this budget:-0.433242





01:21:03 HBMASTER: Trying to run another job!
01:21:03 job_callback for (8, 0, 7) finished
01:21:03 HBMASTER: schedule new run for iteration 8
01:21:03 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
01:21:03 HBMASTER: submitting job (8, 0, 9) to dispatcher
01:21:03 DISPATCHER: trying to submit job (8, 0, 9)
01:21:03 DISPATCHER: trying to notify the job_runner thread.
01:21:03 HBMASTER: job (8, 0, 9) submitted to dispatcher
01:21:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:21:03 DISPATCHER: Trying to submit another job.
01:21:03 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:21:03 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:21:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:21:03 WORKER: start processing job (8, 0, 9)
01:21:03 WORKER: args: ()
01:21:03 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.03594136761306271, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.060036008458797314}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:21:32 DISPATCHER: Starting worker discovery
01:21:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:21:32 DISPATCHER: Finished worker discovery
01:22:32 DISPATCHER: Starting worker discovery
01:22:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:22:32 DISPATCHER: Finished worker discovery
01:23:32 DISPATCHER: Starting worker discovery
01:23:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:23:32 DISPATCHER: Finished worker discovery
01:23:52 WORKER: done with job (8, 0, 9), trying to register it.
01:23:52 WORKER: registered result for job (8, 0, 9) with dispatcher
01:23:52 DISPATCHER: job (8, 0, 9) finished
01:23:52 DISPATCHER: register_result: lock acquired
01:23:52 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:23:52 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.03594136761306271, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.060036008458797314}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3338647453637361, 'info': {'data03': 0.3338647453637361, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.03594136761306271, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.060036008458797314}"}}
exception: None

01:23:52 job_callback for (8, 0, 9) started
01:23:52 DISPATCHER: Trying to submit another job.
01:23:52 job_callback for (8, 0, 9) got condition
01:23:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:23:52 done building a new model for budget 133.333333 based on 17/34 split
Best loss for this budget:-0.433242





01:23:52 HBMASTER: Trying to run another job!
01:23:52 job_callback for (8, 0, 9) finished
01:23:52 HBMASTER: schedule new run for iteration 8
01:23:52 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
01:23:52 HBMASTER: submitting job (8, 0, 16) to dispatcher
01:23:52 DISPATCHER: trying to submit job (8, 0, 16)
01:23:52 DISPATCHER: trying to notify the job_runner thread.
01:23:52 HBMASTER: job (8, 0, 16) submitted to dispatcher
01:23:52 DISPATCHER: Trying to submit another job.
01:23:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:23:52 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:23:52 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:23:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:23:52 WORKER: start processing job (8, 0, 16)
01:23:52 WORKER: args: ()
01:23:52 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.015889692198924093, 'num_filters_1': 17, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.063796859804112, 'kernel_size_2': 7, 'num_filters_2': 44}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:24:32 DISPATCHER: Starting worker discovery
01:24:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:24:32 DISPATCHER: Finished worker discovery
01:25:32 DISPATCHER: Starting worker discovery
01:25:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:25:32 DISPATCHER: Finished worker discovery
01:26:32 DISPATCHER: Starting worker discovery
01:26:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:26:32 DISPATCHER: Finished worker discovery
01:26:41 WORKER: done with job (8, 0, 16), trying to register it.
01:26:41 WORKER: registered result for job (8, 0, 16) with dispatcher
01:26:41 DISPATCHER: job (8, 0, 16) finished
01:26:41 DISPATCHER: register_result: lock acquired
01:26:41 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:26:41 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.015889692198924093, 'num_filters_1': 17, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.063796859804112, 'kernel_size_2': 7, 'num_filters_2': 44}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3553815968592233, 'info': {'data03': 0.3553815968592233, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.015889692198924093, 'num_filters_1': 17, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.063796859804112, 'kernel_size_2': 7, 'num_filters_2': 44}"}}
exception: None

01:26:41 job_callback for (8, 0, 16) started
01:26:41 job_callback for (8, 0, 16) got condition
01:26:41 DISPATCHER: Trying to submit another job.
01:26:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:26:41 done building a new model for budget 133.333333 based on 17/34 split
Best loss for this budget:-0.433242





01:26:41 HBMASTER: Trying to run another job!
01:26:41 job_callback for (8, 0, 16) finished
01:26:41 HBMASTER: schedule new run for iteration 8
01:26:41 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
01:26:41 HBMASTER: submitting job (8, 0, 18) to dispatcher
01:26:41 DISPATCHER: trying to submit job (8, 0, 18)
01:26:41 DISPATCHER: trying to notify the job_runner thread.
01:26:41 HBMASTER: job (8, 0, 18) submitted to dispatcher
01:26:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:26:41 DISPATCHER: Trying to submit another job.
01:26:41 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:26:41 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:26:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:26:41 WORKER: start processing job (8, 0, 18)
01:26:41 WORKER: args: ()
01:26:41 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0017484404928705586, 'num_filters_1': 121, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.014386376774364988}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:27:32 DISPATCHER: Starting worker discovery
01:27:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:27:32 DISPATCHER: Finished worker discovery
01:28:32 DISPATCHER: Starting worker discovery
01:28:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:28:32 DISPATCHER: Finished worker discovery
01:29:32 WORKER: done with job (8, 0, 18), trying to register it.
01:29:32 WORKER: registered result for job (8, 0, 18) with dispatcher
01:29:32 DISPATCHER: job (8, 0, 18) finished
01:29:32 DISPATCHER: register_result: lock acquired
01:29:32 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:29:32 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0017484404928705586, 'num_filters_1': 121, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.014386376774364988}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.39242661923749506, 'info': {'data03': 0.39242661923749506, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0017484404928705586, 'num_filters_1': 121, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.014386376774364988}"}}
exception: None

01:29:32 job_callback for (8, 0, 18) started
01:29:32 DISPATCHER: Trying to submit another job.
01:29:32 job_callback for (8, 0, 18) got condition
01:29:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:29:32 done building a new model for budget 133.333333 based on 17/35 split
Best loss for this budget:-0.433242





01:29:32 HBMASTER: Trying to run another job!
01:29:32 job_callback for (8, 0, 18) finished
01:29:32 HBMASTER: schedule new run for iteration 8
01:29:32 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
01:29:32 HBMASTER: submitting job (8, 0, 19) to dispatcher
01:29:32 DISPATCHER: trying to submit job (8, 0, 19)
01:29:32 DISPATCHER: trying to notify the job_runner thread.
01:29:32 HBMASTER: job (8, 0, 19) submitted to dispatcher
01:29:32 DISPATCHER: Trying to submit another job.
01:29:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:29:32 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:29:32 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:29:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:29:32 WORKER: start processing job (8, 0, 19)
01:29:32 WORKER: args: ()
01:29:32 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.00946860668725265, 'num_filters_1': 56, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.03838526432241355}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:29:32 DISPATCHER: Starting worker discovery
01:29:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:29:32 DISPATCHER: Finished worker discovery
01:30:32 DISPATCHER: Starting worker discovery
01:30:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:30:32 DISPATCHER: Finished worker discovery
01:31:32 DISPATCHER: Starting worker discovery
01:31:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:31:32 DISPATCHER: Finished worker discovery
01:32:21 WORKER: done with job (8, 0, 19), trying to register it.
01:32:21 WORKER: registered result for job (8, 0, 19) with dispatcher
01:32:21 DISPATCHER: job (8, 0, 19) finished
01:32:21 DISPATCHER: register_result: lock acquired
01:32:21 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:32:21 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.00946860668725265, 'num_filters_1': 56, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.03838526432241355}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3680649045807028, 'info': {'data03': 0.3680649045807028, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.00946860668725265, 'num_filters_1': 56, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.03838526432241355}"}}
exception: None

01:32:21 job_callback for (8, 0, 19) started
01:32:21 DISPATCHER: Trying to submit another job.
01:32:21 job_callback for (8, 0, 19) got condition
01:32:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:32:21 done building a new model for budget 133.333333 based on 17/36 split
Best loss for this budget:-0.433242





01:32:21 HBMASTER: Trying to run another job!
01:32:21 job_callback for (8, 0, 19) finished
01:32:21 HBMASTER: schedule new run for iteration 8
01:32:21 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
01:32:21 HBMASTER: submitting job (8, 0, 22) to dispatcher
01:32:21 DISPATCHER: trying to submit job (8, 0, 22)
01:32:21 DISPATCHER: trying to notify the job_runner thread.
01:32:21 HBMASTER: job (8, 0, 22) submitted to dispatcher
01:32:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:32:21 DISPATCHER: Trying to submit another job.
01:32:21 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:32:21 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:32:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:32:21 WORKER: start processing job (8, 0, 22)
01:32:21 WORKER: args: ()
01:32:21 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0036107525824947253, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.016243251201231143, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 44, 'num_filters_3': 61, 'num_filters_4': 92}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:32:32 DISPATCHER: Starting worker discovery
01:32:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:32:32 DISPATCHER: Finished worker discovery
01:33:32 DISPATCHER: Starting worker discovery
01:33:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:33:33 DISPATCHER: Finished worker discovery
01:34:33 DISPATCHER: Starting worker discovery
01:34:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:34:33 DISPATCHER: Finished worker discovery
01:35:12 WORKER: done with job (8, 0, 22), trying to register it.
01:35:12 WORKER: registered result for job (8, 0, 22) with dispatcher
01:35:12 DISPATCHER: job (8, 0, 22) finished
01:35:12 DISPATCHER: register_result: lock acquired
01:35:12 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:35:12 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0036107525824947253, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.016243251201231143, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 44, 'num_filters_3': 61, 'num_filters_4': 92}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4351006454528562, 'info': {'data03': 0.4351006454528562, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0036107525824947253, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.016243251201231143, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 44, 'num_filters_3': 61, 'num_filters_4': 92}"}}
exception: None

01:35:12 job_callback for (8, 0, 22) started
01:35:12 DISPATCHER: Trying to submit another job.
01:35:12 job_callback for (8, 0, 22) got condition
01:35:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:35:12 done building a new model for budget 133.333333 based on 17/37 split
Best loss for this budget:-0.435101





01:35:12 HBMASTER: Trying to run another job!
01:35:12 job_callback for (8, 0, 22) finished
01:35:12 HBMASTER: schedule new run for iteration 8
01:35:12 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
01:35:12 HBMASTER: submitting job (8, 0, 26) to dispatcher
01:35:12 DISPATCHER: trying to submit job (8, 0, 26)
01:35:12 DISPATCHER: trying to notify the job_runner thread.
01:35:12 HBMASTER: job (8, 0, 26) submitted to dispatcher
01:35:12 DISPATCHER: Trying to submit another job.
01:35:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:35:12 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:35:12 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:35:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:35:12 WORKER: start processing job (8, 0, 26)
01:35:12 WORKER: args: ()
01:35:12 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.001479451884657105, 'num_filters_1': 40, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.03886372396213192, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 41, 'num_filters_3': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:35:33 DISPATCHER: Starting worker discovery
01:35:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:35:33 DISPATCHER: Finished worker discovery
01:36:33 DISPATCHER: Starting worker discovery
01:36:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:36:33 DISPATCHER: Finished worker discovery
01:37:33 DISPATCHER: Starting worker discovery
01:37:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:37:33 DISPATCHER: Finished worker discovery
01:38:05 WORKER: done with job (8, 0, 26), trying to register it.
01:38:05 WORKER: registered result for job (8, 0, 26) with dispatcher
01:38:05 DISPATCHER: job (8, 0, 26) finished
01:38:05 DISPATCHER: register_result: lock acquired
01:38:05 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:38:05 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.001479451884657105, 'num_filters_1': 40, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.03886372396213192, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 41, 'num_filters_3': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3578794434490877, 'info': {'data03': 0.3578794434490877, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.001479451884657105, 'num_filters_1': 40, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.03886372396213192, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 41, 'num_filters_3': 26}"}}
exception: None

01:38:05 job_callback for (8, 0, 26) started
01:38:05 DISPATCHER: Trying to submit another job.
01:38:05 job_callback for (8, 0, 26) got condition
01:38:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:38:05 done building a new model for budget 133.333333 based on 17/38 split
Best loss for this budget:-0.435101





01:38:05 HBMASTER: Trying to run another job!
01:38:05 job_callback for (8, 0, 26) finished
01:38:05 ITERATION: Advancing config (8, 0, 0) to next budget 400.000000
01:38:05 ITERATION: Advancing config (8, 0, 18) to next budget 400.000000
01:38:05 ITERATION: Advancing config (8, 0, 22) to next budget 400.000000
01:38:05 HBMASTER: schedule new run for iteration 8
01:38:05 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
01:38:05 HBMASTER: submitting job (8, 0, 0) to dispatcher
01:38:05 DISPATCHER: trying to submit job (8, 0, 0)
01:38:05 DISPATCHER: trying to notify the job_runner thread.
01:38:05 HBMASTER: job (8, 0, 0) submitted to dispatcher
01:38:05 DISPATCHER: Trying to submit another job.
01:38:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:38:05 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:38:05 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:38:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:38:05 WORKER: start processing job (8, 0, 0)
01:38:05 WORKER: args: ()
01:38:05 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0031623459208232566, 'num_filters_1': 31, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.026516329267777815, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 35, 'num_filters_3': 100, 'num_filters_4': 27}, 'budget': 400.0, 'working_directory': '.'}
01:38:33 DISPATCHER: Starting worker discovery
01:38:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:38:33 DISPATCHER: Finished worker discovery
01:39:33 DISPATCHER: Starting worker discovery
01:39:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:39:33 DISPATCHER: Finished worker discovery
01:40:33 DISPATCHER: Starting worker discovery
01:40:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:40:33 DISPATCHER: Finished worker discovery
01:41:33 DISPATCHER: Starting worker discovery
01:41:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:41:33 DISPATCHER: Finished worker discovery
01:42:33 DISPATCHER: Starting worker discovery
01:42:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:42:33 DISPATCHER: Finished worker discovery
01:43:33 DISPATCHER: Starting worker discovery
01:43:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:43:33 DISPATCHER: Finished worker discovery
01:44:33 DISPATCHER: Starting worker discovery
01:44:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:44:33 DISPATCHER: Finished worker discovery
01:45:23 WORKER: done with job (8, 0, 0), trying to register it.
01:45:23 WORKER: registered result for job (8, 0, 0) with dispatcher
01:45:23 DISPATCHER: job (8, 0, 0) finished
01:45:23 DISPATCHER: register_result: lock acquired
01:45:23 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:45:23 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0031623459208232566, 'num_filters_1': 31, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.026516329267777815, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 35, 'num_filters_3': 100, 'num_filters_4': 27}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3978079289975579, 'info': {'data03': 0.3978079289975579, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0031623459208232566, 'num_filters_1': 31, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.026516329267777815, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 35, 'num_filters_3': 100, 'num_filters_4': 27}"}}
exception: None

01:45:23 job_callback for (8, 0, 0) started
01:45:23 job_callback for (8, 0, 0) got condition
01:45:23 DISPATCHER: Trying to submit another job.
01:45:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:45:23 HBMASTER: Trying to run another job!
01:45:23 job_callback for (8, 0, 0) finished
01:45:23 HBMASTER: schedule new run for iteration 8
01:45:23 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
01:45:23 HBMASTER: submitting job (8, 0, 18) to dispatcher
01:45:23 DISPATCHER: trying to submit job (8, 0, 18)
01:45:23 DISPATCHER: trying to notify the job_runner thread.
01:45:23 HBMASTER: job (8, 0, 18) submitted to dispatcher
01:45:23 DISPATCHER: Trying to submit another job.
01:45:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:45:23 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:45:23 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:45:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:45:23 WORKER: start processing job (8, 0, 18)
01:45:23 WORKER: args: ()
01:45:23 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0017484404928705586, 'num_filters_1': 121, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.014386376774364988}, 'budget': 400.0, 'working_directory': '.'}
01:45:33 DISPATCHER: Starting worker discovery
01:45:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:45:33 DISPATCHER: Finished worker discovery
01:46:33 DISPATCHER: Starting worker discovery
01:46:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:46:33 DISPATCHER: Finished worker discovery
01:47:33 DISPATCHER: Starting worker discovery
01:47:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:47:33 DISPATCHER: Finished worker discovery
01:48:33 DISPATCHER: Starting worker discovery
01:48:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:48:33 DISPATCHER: Finished worker discovery
01:49:33 DISPATCHER: Starting worker discovery
01:49:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:49:33 DISPATCHER: Finished worker discovery
01:50:33 DISPATCHER: Starting worker discovery
01:50:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:50:33 DISPATCHER: Finished worker discovery
01:51:33 DISPATCHER: Starting worker discovery
01:51:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:51:33 DISPATCHER: Finished worker discovery
01:52:33 DISPATCHER: Starting worker discovery
01:52:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:52:33 DISPATCHER: Finished worker discovery
01:52:40 WORKER: done with job (8, 0, 18), trying to register it.
01:52:40 WORKER: registered result for job (8, 0, 18) with dispatcher
01:52:40 DISPATCHER: job (8, 0, 18) finished
01:52:40 DISPATCHER: register_result: lock acquired
01:52:40 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:52:40 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0017484404928705586, 'num_filters_1': 121, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.014386376774364988}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.42331562690161606, 'info': {'data03': 0.42331562690161606, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0017484404928705586, 'num_filters_1': 121, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.014386376774364988}"}}
exception: None

01:52:40 job_callback for (8, 0, 18) started
01:52:40 job_callback for (8, 0, 18) got condition
01:52:40 DISPATCHER: Trying to submit another job.
01:52:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:52:40 HBMASTER: Trying to run another job!
01:52:40 job_callback for (8, 0, 18) finished
01:52:40 HBMASTER: schedule new run for iteration 8
01:52:40 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
01:52:40 HBMASTER: submitting job (8, 0, 22) to dispatcher
01:52:40 DISPATCHER: trying to submit job (8, 0, 22)
01:52:40 DISPATCHER: trying to notify the job_runner thread.
01:52:40 HBMASTER: job (8, 0, 22) submitted to dispatcher
01:52:40 DISPATCHER: Trying to submit another job.
01:52:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:52:40 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:52:40 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:52:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:52:40 WORKER: start processing job (8, 0, 22)
01:52:40 WORKER: args: ()
01:52:40 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0036107525824947253, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.016243251201231143, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 44, 'num_filters_3': 61, 'num_filters_4': 92}, 'budget': 400.0, 'working_directory': '.'}
01:53:33 DISPATCHER: Starting worker discovery
01:53:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:53:33 DISPATCHER: Finished worker discovery
01:54:33 DISPATCHER: Starting worker discovery
01:54:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:54:33 DISPATCHER: Finished worker discovery
01:55:33 DISPATCHER: Starting worker discovery
01:55:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:55:33 DISPATCHER: Finished worker discovery
01:56:33 DISPATCHER: Starting worker discovery
01:56:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:56:33 DISPATCHER: Finished worker discovery
01:57:33 DISPATCHER: Starting worker discovery
01:57:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:57:33 DISPATCHER: Finished worker discovery
01:58:33 DISPATCHER: Starting worker discovery
01:58:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:58:33 DISPATCHER: Finished worker discovery
01:59:33 DISPATCHER: Starting worker discovery
01:59:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:59:33 DISPATCHER: Finished worker discovery
01:59:55 WORKER: done with job (8, 0, 22), trying to register it.
01:59:55 WORKER: registered result for job (8, 0, 22) with dispatcher
01:59:55 DISPATCHER: job (8, 0, 22) finished
01:59:55 DISPATCHER: register_result: lock acquired
01:59:55 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:59:55 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0036107525824947253, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.016243251201231143, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 44, 'num_filters_3': 61, 'num_filters_4': 92}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3950951160744194, 'info': {'data03': 0.3950951160744194, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0036107525824947253, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.016243251201231143, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 44, 'num_filters_3': 61, 'num_filters_4': 92}"}}
exception: None

01:59:55 job_callback for (8, 0, 22) started
01:59:55 job_callback for (8, 0, 22) got condition
01:59:55 DISPATCHER: Trying to submit another job.
01:59:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:59:55 HBMASTER: Trying to run another job!
01:59:55 job_callback for (8, 0, 22) finished
01:59:55 ITERATION: Advancing config (8, 0, 18) to next budget 1200.000000
01:59:55 HBMASTER: schedule new run for iteration 8
01:59:55 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
01:59:55 HBMASTER: submitting job (8, 0, 18) to dispatcher
01:59:55 DISPATCHER: trying to submit job (8, 0, 18)
01:59:55 DISPATCHER: trying to notify the job_runner thread.
01:59:55 HBMASTER: job (8, 0, 18) submitted to dispatcher
01:59:55 DISPATCHER: Trying to submit another job.
01:59:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:59:55 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:59:55 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:59:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:59:55 WORKER: start processing job (8, 0, 18)
01:59:55 WORKER: args: ()
01:59:55 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0017484404928705586, 'num_filters_1': 121, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.014386376774364988}, 'budget': 1200.0, 'working_directory': '.'}
02:00:33 DISPATCHER: Starting worker discovery
02:00:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:00:33 DISPATCHER: Finished worker discovery
02:01:33 DISPATCHER: Starting worker discovery
02:01:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:01:33 DISPATCHER: Finished worker discovery
02:02:33 DISPATCHER: Starting worker discovery
02:02:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:02:33 DISPATCHER: Finished worker discovery
02:03:33 DISPATCHER: Starting worker discovery
02:03:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:03:33 DISPATCHER: Finished worker discovery
02:04:33 DISPATCHER: Starting worker discovery
02:04:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:04:33 DISPATCHER: Finished worker discovery
02:05:33 DISPATCHER: Starting worker discovery
02:05:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:05:33 DISPATCHER: Finished worker discovery
02:06:33 DISPATCHER: Starting worker discovery
02:06:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:06:33 DISPATCHER: Finished worker discovery
02:07:33 DISPATCHER: Starting worker discovery
02:07:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:07:33 DISPATCHER: Finished worker discovery
02:08:33 DISPATCHER: Starting worker discovery
02:08:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:08:33 DISPATCHER: Finished worker discovery
02:09:33 DISPATCHER: Starting worker discovery
02:09:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:09:33 DISPATCHER: Finished worker discovery
02:10:33 DISPATCHER: Starting worker discovery
02:10:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:10:33 DISPATCHER: Finished worker discovery
02:11:33 DISPATCHER: Starting worker discovery
02:11:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:11:33 DISPATCHER: Finished worker discovery
02:12:33 DISPATCHER: Starting worker discovery
02:12:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:12:33 DISPATCHER: Finished worker discovery
02:13:33 DISPATCHER: Starting worker discovery
02:13:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:13:33 DISPATCHER: Finished worker discovery
02:14:33 DISPATCHER: Starting worker discovery
02:14:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:14:33 DISPATCHER: Finished worker discovery
02:15:33 DISPATCHER: Starting worker discovery
02:15:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:15:33 DISPATCHER: Finished worker discovery
02:16:33 DISPATCHER: Starting worker discovery
02:16:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:16:33 DISPATCHER: Finished worker discovery
02:17:33 DISPATCHER: Starting worker discovery
02:17:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:17:33 DISPATCHER: Finished worker discovery
02:18:33 DISPATCHER: Starting worker discovery
02:18:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:18:33 DISPATCHER: Finished worker discovery
02:19:33 DISPATCHER: Starting worker discovery
02:19:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:19:33 DISPATCHER: Finished worker discovery
02:20:33 WORKER: done with job (8, 0, 18), trying to register it.
02:20:33 WORKER: registered result for job (8, 0, 18) with dispatcher
02:20:33 DISPATCHER: job (8, 0, 18) finished
02:20:33 DISPATCHER: register_result: lock acquired
02:20:33 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
02:20:33 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0017484404928705586, 'num_filters_1': 121, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.014386376774364988}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.39807926411610167, 'info': {'data03': 0.39807926411610167, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0017484404928705586, 'num_filters_1': 121, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.014386376774364988}"}}
exception: None

02:20:33 job_callback for (8, 0, 18) started
02:20:33 job_callback for (8, 0, 18) got condition
02:20:33 DISPATCHER: Trying to submit another job.
02:20:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:20:33 HBMASTER: Trying to run another job!
02:20:33 job_callback for (8, 0, 18) finished
02:20:33 start sampling a new configuration.
02:20:33 best_vector: [2, 2, 0.4451680326848859, 0.7545297713734637, 0.5675925479719047, 1, 0.6107956547400968, 0.45681996119389484, 1, 1, 1, 2, 0.6285096932611475, 0.2426593166000623, 0.06504657296238159, 0.006342837078416243], 1.3664269831396866e-28, 7.318356650878377e-05, -1.8702553616394458e-34
02:20:33 done sampling a new configuration.
02:20:33 HBMASTER: schedule new run for iteration 9
02:20:33 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
02:20:33 HBMASTER: submitting job (9, 0, 0) to dispatcher
02:20:33 DISPATCHER: trying to submit job (9, 0, 0)
02:20:33 DISPATCHER: trying to notify the job_runner thread.
02:20:33 HBMASTER: job (9, 0, 0) submitted to dispatcher
02:20:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:20:33 DISPATCHER: Trying to submit another job.
02:20:33 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
02:20:33 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
02:20:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:20:33 WORKER: start processing job (9, 0, 0)
02:20:33 WORKER: args: ()
02:20:33 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.007768480239489704, 'num_filters_1': 76, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.03929492571790799, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 59, 'num_filters_3': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:20:33 DISPATCHER: Starting worker discovery
02:20:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:20:33 DISPATCHER: Finished worker discovery
02:21:33 DISPATCHER: Starting worker discovery
02:21:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:21:33 DISPATCHER: Finished worker discovery
02:22:33 DISPATCHER: Starting worker discovery
02:22:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:22:33 DISPATCHER: Finished worker discovery
02:23:20 WORKER: done with job (9, 0, 0), trying to register it.
02:23:20 WORKER: registered result for job (9, 0, 0) with dispatcher
02:23:20 DISPATCHER: job (9, 0, 0) finished
02:23:20 DISPATCHER: register_result: lock acquired
02:23:20 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
02:23:20 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.007768480239489704, 'num_filters_1': 76, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.03929492571790799, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 59, 'num_filters_3': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4229364900674347, 'info': {'data03': 0.4229364900674347, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.007768480239489704, 'num_filters_1': 76, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.03929492571790799, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 59, 'num_filters_3': 26}"}}
exception: None

02:23:20 job_callback for (9, 0, 0) started
02:23:20 job_callback for (9, 0, 0) got condition
02:23:20 DISPATCHER: Trying to submit another job.
02:23:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:23:20 done building a new model for budget 133.333333 based on 17/39 split
Best loss for this budget:-0.435101





02:23:20 HBMASTER: Trying to run another job!
02:23:20 job_callback for (9, 0, 0) finished
02:23:20 start sampling a new configuration.
02:23:21 best_vector: [3, 2, 0.8533274244458395, 0.11587042392938526, 0.6830787091185088, 1, 0.5413931525913666, 0.2334211698400177, 0, 1, 1, 0, 0.7214789900101536, 0.6135631262538153, 0.5929101233479326, 0.43033532526729046], 2.2135578581591018e-29, 0.0004517614013629835, -1.2363353700504482e-07
02:23:21 done sampling a new configuration.
02:23:21 HBMASTER: schedule new run for iteration 9
02:23:21 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
02:23:21 HBMASTER: submitting job (9, 0, 1) to dispatcher
02:23:21 DISPATCHER: trying to submit job (9, 0, 1)
02:23:21 DISPATCHER: trying to notify the job_runner thread.
02:23:21 HBMASTER: job (9, 0, 1) submitted to dispatcher
02:23:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:23:21 DISPATCHER: Trying to submit another job.
02:23:21 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
02:23:21 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
02:23:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:23:21 WORKER: start processing job (9, 0, 1)
02:23:21 WORKER: args: ()
02:23:21 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.05089262463511777, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.020122778353021977, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 71, 'num_filters_3': 57, 'num_filters_4': 54}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:23:33 DISPATCHER: Starting worker discovery
02:23:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:23:33 DISPATCHER: Finished worker discovery
02:24:33 DISPATCHER: Starting worker discovery
02:24:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:24:33 DISPATCHER: Finished worker discovery
02:25:33 DISPATCHER: Starting worker discovery
02:25:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:25:33 DISPATCHER: Finished worker discovery
02:26:15 WORKER: done with job (9, 0, 1), trying to register it.
02:26:15 WORKER: registered result for job (9, 0, 1) with dispatcher
02:26:15 DISPATCHER: job (9, 0, 1) finished
02:26:15 DISPATCHER: register_result: lock acquired
02:26:15 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
02:26:15 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.05089262463511777, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.020122778353021977, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 71, 'num_filters_3': 57, 'num_filters_4': 54}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1969438679688697, 'info': {'data03': 0.1969438679688697, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.05089262463511777, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.020122778353021977, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 71, 'num_filters_3': 57, 'num_filters_4': 54}"}}
exception: None

02:26:15 job_callback for (9, 0, 1) started
02:26:15 job_callback for (9, 0, 1) got condition
02:26:15 DISPATCHER: Trying to submit another job.
02:26:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:26:15 done building a new model for budget 133.333333 based on 17/39 split
Best loss for this budget:-0.435101





02:26:15 HBMASTER: Trying to run another job!
02:26:15 job_callback for (9, 0, 1) finished
02:26:15 start sampling a new configuration.
02:26:15 best_vector: [1, 1, 0.209578382263307, 0.9489029943165452, 0.09642374835764991, 1, 0.7452929602626034, 0.4262271524017047, 2, 2, 1, 0, 0.924613364641807, 0.7806612161806086, 0.5755748020042659, 0.4618998299778671], 1.0622742961874071e-29, 0.000941376444473038, -3.957256193701234e-06
02:26:15 done sampling a new configuration.
02:26:15 HBMASTER: schedule new run for iteration 9
02:26:15 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
02:26:15 HBMASTER: submitting job (9, 0, 2) to dispatcher
02:26:15 DISPATCHER: trying to submit job (9, 0, 2)
02:26:15 DISPATCHER: trying to notify the job_runner thread.
02:26:15 HBMASTER: job (9, 0, 2) submitted to dispatcher
02:26:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:26:15 DISPATCHER: Trying to submit another job.
02:26:15 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
02:26:15 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
02:26:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:26:15 WORKER: start processing job (9, 0, 2)
02:26:15 WORKER: args: ()
02:26:15 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0026251659619015333, 'num_filters_1': 115, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.035853727240879235}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:26:33 DISPATCHER: Starting worker discovery
02:26:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:26:33 DISPATCHER: Finished worker discovery
02:27:33 DISPATCHER: Starting worker discovery
02:27:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:27:33 DISPATCHER: Finished worker discovery
02:28:33 DISPATCHER: Starting worker discovery
02:28:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:28:33 DISPATCHER: Finished worker discovery
02:29:08 WORKER: done with job (9, 0, 2), trying to register it.
02:29:08 WORKER: registered result for job (9, 0, 2) with dispatcher
02:29:08 DISPATCHER: job (9, 0, 2) finished
02:29:08 DISPATCHER: register_result: lock acquired
02:29:08 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
02:29:08 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0026251659619015333, 'num_filters_1': 115, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.035853727240879235}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3400147627520058, 'info': {'data03': 0.3400147627520058, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0026251659619015333, 'num_filters_1': 115, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.035853727240879235}"}}
exception: None

02:29:08 job_callback for (9, 0, 2) started
02:29:08 job_callback for (9, 0, 2) got condition
02:29:08 DISPATCHER: Trying to submit another job.
02:29:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:29:08 done building a new model for budget 133.333333 based on 17/40 split
Best loss for this budget:-0.435101





02:29:08 HBMASTER: Trying to run another job!
02:29:08 job_callback for (9, 0, 2) finished
02:29:08 start sampling a new configuration.
02:29:08 best_vector: [1, 2, 0.2022733159259672, 0.5450221844082965, 0.21571906490267584, 1, 0.8624967549276104, 0.5033721899484811, 0, 1, 1, 1, 0.9683273416446178, 0.08650166190943365, 0.9951900538764439, 0.304430290712125], 1.920399394945244e-28, 5.207250130530857e-05, -6.636911214776014e-12
02:29:08 done sampling a new configuration.
02:29:08 HBMASTER: schedule new run for iteration 9
02:29:08 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
02:29:08 HBMASTER: submitting job (9, 0, 3) to dispatcher
02:29:08 DISPATCHER: trying to submit job (9, 0, 3)
02:29:08 DISPATCHER: trying to notify the job_runner thread.
02:29:08 HBMASTER: job (9, 0, 3) submitted to dispatcher
02:29:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:29:08 DISPATCHER: Trying to submit another job.
02:29:08 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
02:29:08 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
02:29:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:29:08 WORKER: start processing job (9, 0, 3)
02:29:08 WORKER: args: ()
02:29:08 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0025383215205773465, 'num_filters_1': 49, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.04517543239701986, 'kernel_size_2': 3, 'num_filters_2': 120}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:29:33 DISPATCHER: Starting worker discovery
02:29:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:29:33 DISPATCHER: Finished worker discovery
02:30:33 DISPATCHER: Starting worker discovery
02:30:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:30:33 DISPATCHER: Finished worker discovery
02:31:33 DISPATCHER: Starting worker discovery
02:31:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:31:33 DISPATCHER: Finished worker discovery
02:32:02 WORKER: done with job (9, 0, 3), trying to register it.
02:32:02 WORKER: registered result for job (9, 0, 3) with dispatcher
02:32:02 DISPATCHER: job (9, 0, 3) finished
02:32:02 DISPATCHER: register_result: lock acquired
02:32:02 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
02:32:02 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0025383215205773465, 'num_filters_1': 49, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.04517543239701986, 'kernel_size_2': 3, 'num_filters_2': 120}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.37615456912159073, 'info': {'data03': 0.37615456912159073, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0025383215205773465, 'num_filters_1': 49, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.04517543239701986, 'kernel_size_2': 3, 'num_filters_2': 120}"}}
exception: None

02:32:02 job_callback for (9, 0, 3) started
02:32:02 DISPATCHER: Trying to submit another job.
02:32:02 job_callback for (9, 0, 3) got condition
02:32:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:32:02 done building a new model for budget 133.333333 based on 17/41 split
Best loss for this budget:-0.435101





02:32:02 HBMASTER: Trying to run another job!
02:32:02 job_callback for (9, 0, 3) finished
02:32:02 start sampling a new configuration.
02:32:03 best_vector: [2, 0, 0.8861453912355519, 0.7133207499071051, 0.34260994030255054, 1, 0.9423987934936715, 0.3992352028217282, 1, 1, 0, 1, 0.16321909052969863, 0.3302775112681171, 0.7121716054657106, 0.7716231535804546], 5.48377016347784e-29, 0.00018235629324147204, -3.0644257104697197e-06
02:32:03 done sampling a new configuration.
02:32:03 HBMASTER: schedule new run for iteration 9
02:32:03 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
02:32:03 HBMASTER: submitting job (9, 0, 4) to dispatcher
02:32:03 DISPATCHER: trying to submit job (9, 0, 4)
02:32:03 DISPATCHER: trying to notify the job_runner thread.
02:32:03 HBMASTER: job (9, 0, 4) submitted to dispatcher
02:32:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:32:03 DISPATCHER: Trying to submit another job.
02:32:03 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
02:32:03 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
02:32:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:32:03 WORKER: start processing job (9, 0, 4)
02:32:03 WORKER: args: ()
02:32:03 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.05919578477137839, 'num_filters_1': 70, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.033068688728810684, 'kernel_size_2': 5, 'num_filters_2': 22}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:32:33 DISPATCHER: Starting worker discovery
02:32:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:32:33 DISPATCHER: Finished worker discovery
02:33:33 DISPATCHER: Starting worker discovery
02:33:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:33:33 DISPATCHER: Finished worker discovery
02:34:33 DISPATCHER: Starting worker discovery
02:34:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:34:33 DISPATCHER: Finished worker discovery
02:34:55 WORKER: done with job (9, 0, 4), trying to register it.
02:34:55 WORKER: registered result for job (9, 0, 4) with dispatcher
02:34:55 DISPATCHER: job (9, 0, 4) finished
02:34:55 DISPATCHER: register_result: lock acquired
02:34:55 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
02:34:55 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.05919578477137839, 'num_filters_1': 70, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.033068688728810684, 'kernel_size_2': 5, 'num_filters_2': 22}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.19025114486211192, 'info': {'data03': 0.19025114486211192, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.05919578477137839, 'num_filters_1': 70, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.033068688728810684, 'kernel_size_2': 5, 'num_filters_2': 22}"}}
exception: None

02:34:55 job_callback for (9, 0, 4) started
02:34:55 DISPATCHER: Trying to submit another job.
02:34:55 job_callback for (9, 0, 4) got condition
02:34:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:34:55 done building a new model for budget 133.333333 based on 17/42 split
Best loss for this budget:-0.435101





02:34:55 HBMASTER: Trying to run another job!
02:34:55 job_callback for (9, 0, 4) finished
02:34:55 start sampling a new configuration.
02:34:55 done sampling a new configuration.
02:34:55 HBMASTER: schedule new run for iteration 9
02:34:55 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
02:34:55 HBMASTER: submitting job (9, 0, 5) to dispatcher
02:34:55 DISPATCHER: trying to submit job (9, 0, 5)
02:34:55 DISPATCHER: trying to notify the job_runner thread.
02:34:55 HBMASTER: job (9, 0, 5) submitted to dispatcher
02:34:55 DISPATCHER: Trying to submit another job.
02:34:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:34:55 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
02:34:55 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
02:34:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:34:55 WORKER: start processing job (9, 0, 5)
02:34:55 WORKER: args: ()
02:34:55 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.05005652060931849, 'num_filters_1': 55, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.012135469747212012, 'kernel_size_2': 7, 'num_filters_2': 105}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:35:33 DISPATCHER: Starting worker discovery
02:35:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:35:33 DISPATCHER: Finished worker discovery
02:36:33 DISPATCHER: Starting worker discovery
02:36:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:36:33 DISPATCHER: Finished worker discovery
02:37:33 DISPATCHER: Starting worker discovery
02:37:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:37:33 DISPATCHER: Finished worker discovery
02:37:45 WORKER: done with job (9, 0, 5), trying to register it.
02:37:45 WORKER: registered result for job (9, 0, 5) with dispatcher
02:37:45 DISPATCHER: job (9, 0, 5) finished
02:37:45 DISPATCHER: register_result: lock acquired
02:37:45 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
02:37:45 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.05005652060931849, 'num_filters_1': 55, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.012135469747212012, 'kernel_size_2': 7, 'num_filters_2': 105}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0004880815857097797, 'info': {'data03': 0.0004880815857097797, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.05005652060931849, 'num_filters_1': 55, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.012135469747212012, 'kernel_size_2': 7, 'num_filters_2': 105}"}}
exception: None

02:37:45 job_callback for (9, 0, 5) started
02:37:45 DISPATCHER: Trying to submit another job.
02:37:45 job_callback for (9, 0, 5) got condition
02:37:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:37:45 done building a new model for budget 133.333333 based on 17/43 split
Best loss for this budget:-0.435101





02:37:45 HBMASTER: Trying to run another job!
02:37:45 job_callback for (9, 0, 5) finished
02:37:45 start sampling a new configuration.
02:37:45 done sampling a new configuration.
02:37:45 HBMASTER: schedule new run for iteration 9
02:37:45 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
02:37:45 HBMASTER: submitting job (9, 0, 6) to dispatcher
02:37:45 DISPATCHER: trying to submit job (9, 0, 6)
02:37:45 DISPATCHER: trying to notify the job_runner thread.
02:37:45 HBMASTER: job (9, 0, 6) submitted to dispatcher
02:37:45 DISPATCHER: Trying to submit another job.
02:37:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:37:45 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776
02:37:45 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
02:37:45 WORKER: start processing job (9, 0, 6)
02:37:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:37:45 WORKER: args: ()
02:37:45 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.016967308702673035, 'num_filters_1': 23, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.037690243100956713, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 25, 'num_filters_3': 66, 'num_filters_4': 34, 'num_filters_5': 33}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:38:33 DISPATCHER: Starting worker discovery
02:38:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:38:33 DISPATCHER: Finished worker discovery
02:39:33 DISPATCHER: Starting worker discovery
02:39:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:39:33 DISPATCHER: Finished worker discovery
02:40:33 DISPATCHER: Starting worker discovery
02:40:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:40:33 DISPATCHER: Finished worker discovery
02:40:34 WORKER: done with job (9, 0, 6), trying to register it.
02:40:34 WORKER: registered result for job (9, 0, 6) with dispatcher
02:40:34 DISPATCHER: job (9, 0, 6) finished
02:40:34 DISPATCHER: register_result: lock acquired
02:40:34 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
02:40:34 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.016967308702673035, 'num_filters_1': 23, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.037690243100956713, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 25, 'num_filters_3': 66, 'num_filters_4': 34, 'num_filters_5': 33}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.32643650035783855, 'info': {'data03': 0.32643650035783855, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.016967308702673035, 'num_filters_1': 23, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.037690243100956713, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 25, 'num_filters_3': 66, 'num_filters_4': 34, 'num_filters_5': 33}"}}
exception: None

02:40:34 job_callback for (9, 0, 6) started
02:40:34 job_callback for (9, 0, 6) got condition
02:40:34 DISPATCHER: Trying to submit another job.
02:40:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:40:34 done building a new model for budget 133.333333 based on 17/44 split
Best loss for this budget:-0.435101





02:40:34 HBMASTER: Trying to run another job!
02:40:34 job_callback for (9, 0, 6) finished
02:40:34 start sampling a new configuration.
02:40:34 best_vector: [0, 1, 0.15409529603114264, 0.9177804809951615, 0.6341656743133264, 1, 0.11183954330932211, 0.7233296190011902, 2, 0, 1, 0, 0.9790896432402962, 0.530562269124631, 0.8164941083466988, 0.5688150722764308], 3.9307714266940796e-29, 0.0002544029889931901, -1.1103805028993481e-05
02:40:34 done sampling a new configuration.
02:40:34 HBMASTER: schedule new run for iteration 9
02:40:34 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
02:40:34 HBMASTER: submitting job (9, 0, 7) to dispatcher
02:40:34 DISPATCHER: trying to submit job (9, 0, 7)
02:40:34 DISPATCHER: trying to notify the job_runner thread.
02:40:34 HBMASTER: job (9, 0, 7) submitted to dispatcher
02:40:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:40:34 DISPATCHER: Trying to submit another job.
02:40:34 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776
02:40:34 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
02:40:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:40:34 WORKER: start processing job (9, 0, 7)
02:40:34 WORKER: args: ()
02:40:34 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002033249115574831, 'num_filters_1': 108, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.0873119185038508, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 123, 'num_filters_3': 48, 'num_filters_4': 87}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:41:33 DISPATCHER: Starting worker discovery
02:41:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:41:33 DISPATCHER: Finished worker discovery
02:42:33 DISPATCHER: Starting worker discovery
02:42:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:42:33 DISPATCHER: Finished worker discovery
02:43:28 WORKER: done with job (9, 0, 7), trying to register it.
02:43:28 WORKER: registered result for job (9, 0, 7) with dispatcher
02:43:28 DISPATCHER: job (9, 0, 7) finished
02:43:28 DISPATCHER: register_result: lock acquired
02:43:28 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
02:43:28 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002033249115574831, 'num_filters_1': 108, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.0873119185038508, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 123, 'num_filters_3': 48, 'num_filters_4': 87}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.30813020271081715, 'info': {'data03': 0.30813020271081715, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002033249115574831, 'num_filters_1': 108, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 20, 'weight_decay': 0.0873119185038508, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 123, 'num_filters_3': 48, 'num_filters_4': 87}"}}
exception: None

02:43:28 job_callback for (9, 0, 7) started
02:43:28 DISPATCHER: Trying to submit another job.
02:43:28 job_callback for (9, 0, 7) got condition
02:43:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:43:28 done building a new model for budget 133.333333 based on 17/45 split
Best loss for this budget:-0.435101





02:43:28 HBMASTER: Trying to run another job!
02:43:28 job_callback for (9, 0, 7) finished
02:43:28 start sampling a new configuration.
02:43:28 done sampling a new configuration.
02:43:28 HBMASTER: schedule new run for iteration 9
02:43:28 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
02:43:28 HBMASTER: submitting job (9, 0, 8) to dispatcher
02:43:28 DISPATCHER: trying to submit job (9, 0, 8)
02:43:28 DISPATCHER: trying to notify the job_runner thread.
02:43:28 HBMASTER: job (9, 0, 8) submitted to dispatcher
02:43:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:43:28 DISPATCHER: Trying to submit another job.
02:43:28 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776
02:43:28 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
02:43:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:43:28 WORKER: start processing job (9, 0, 8)
02:43:28 WORKER: args: ()
02:43:28 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.06679494919352004, 'num_filters_1': 48, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.11039332044423569, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 27, 'num_filters_3': 21, 'num_filters_4': 18, 'num_filters_5': 23}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:43:33 DISPATCHER: Starting worker discovery
02:43:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:43:33 DISPATCHER: Finished worker discovery
02:44:33 DISPATCHER: Starting worker discovery
02:44:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:44:33 DISPATCHER: Finished worker discovery
02:45:33 DISPATCHER: Starting worker discovery
02:45:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:45:33 DISPATCHER: Finished worker discovery
02:46:20 WORKER: done with job (9, 0, 8), trying to register it.
02:46:20 WORKER: registered result for job (9, 0, 8) with dispatcher
02:46:20 DISPATCHER: job (9, 0, 8) finished
02:46:20 DISPATCHER: register_result: lock acquired
02:46:20 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
02:46:20 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.06679494919352004, 'num_filters_1': 48, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.11039332044423569, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 27, 'num_filters_3': 21, 'num_filters_4': 18, 'num_filters_5': 23}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2854294960697658, 'info': {'data03': 0.2854294960697658, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.06679494919352004, 'num_filters_1': 48, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.11039332044423569, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 27, 'num_filters_3': 21, 'num_filters_4': 18, 'num_filters_5': 23}"}}
exception: None

02:46:20 job_callback for (9, 0, 8) started
02:46:20 job_callback for (9, 0, 8) got condition
02:46:20 DISPATCHER: Trying to submit another job.
02:46:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:46:20 done building a new model for budget 133.333333 based on 17/45 split
Best loss for this budget:-0.435101





02:46:20 HBMASTER: Trying to run another job!
02:46:20 job_callback for (9, 0, 8) finished
02:46:20 ITERATION: Advancing config (9, 0, 0) to next budget 400.000000
02:46:20 ITERATION: Advancing config (9, 0, 2) to next budget 400.000000
02:46:20 ITERATION: Advancing config (9, 0, 3) to next budget 400.000000
02:46:20 HBMASTER: schedule new run for iteration 9
02:46:20 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
02:46:20 HBMASTER: submitting job (9, 0, 0) to dispatcher
02:46:20 DISPATCHER: trying to submit job (9, 0, 0)
02:46:20 DISPATCHER: trying to notify the job_runner thread.
02:46:20 HBMASTER: job (9, 0, 0) submitted to dispatcher
02:46:20 DISPATCHER: Trying to submit another job.
02:46:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:46:20 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
02:46:20 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
02:46:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:46:20 WORKER: start processing job (9, 0, 0)
02:46:20 WORKER: args: ()
02:46:20 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.007768480239489704, 'num_filters_1': 76, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.03929492571790799, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 59, 'num_filters_3': 26}, 'budget': 400.0, 'working_directory': '.'}
02:46:33 DISPATCHER: Starting worker discovery
02:46:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:46:33 DISPATCHER: Finished worker discovery
02:47:33 DISPATCHER: Starting worker discovery
02:47:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:47:33 DISPATCHER: Finished worker discovery
02:48:33 DISPATCHER: Starting worker discovery
02:48:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:48:33 DISPATCHER: Finished worker discovery
02:49:33 DISPATCHER: Starting worker discovery
02:49:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:49:33 DISPATCHER: Finished worker discovery
02:50:33 DISPATCHER: Starting worker discovery
02:50:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:50:33 DISPATCHER: Finished worker discovery
02:51:33 DISPATCHER: Starting worker discovery
02:51:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:51:33 DISPATCHER: Finished worker discovery
02:52:33 DISPATCHER: Starting worker discovery
02:52:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:52:33 DISPATCHER: Finished worker discovery
02:53:33 DISPATCHER: Starting worker discovery
02:53:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:53:33 DISPATCHER: Finished worker discovery
02:53:39 WORKER: done with job (9, 0, 0), trying to register it.
02:53:39 WORKER: registered result for job (9, 0, 0) with dispatcher
02:53:39 DISPATCHER: job (9, 0, 0) finished
02:53:39 DISPATCHER: register_result: lock acquired
02:53:39 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
02:53:39 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.007768480239489704, 'num_filters_1': 76, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.03929492571790799, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 59, 'num_filters_3': 26}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.28556457338252106, 'info': {'data03': 0.28556457338252106, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.007768480239489704, 'num_filters_1': 76, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.03929492571790799, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 59, 'num_filters_3': 26}"}}
exception: None

02:53:39 job_callback for (9, 0, 0) started
02:53:39 job_callback for (9, 0, 0) got condition
02:53:39 DISPATCHER: Trying to submit another job.
02:53:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:53:39 HBMASTER: Trying to run another job!
02:53:39 job_callback for (9, 0, 0) finished
02:53:39 HBMASTER: schedule new run for iteration 9
02:53:39 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
02:53:39 HBMASTER: submitting job (9, 0, 2) to dispatcher
02:53:39 DISPATCHER: trying to submit job (9, 0, 2)
02:53:39 DISPATCHER: trying to notify the job_runner thread.
02:53:39 HBMASTER: job (9, 0, 2) submitted to dispatcher
02:53:39 DISPATCHER: Trying to submit another job.
02:53:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:53:39 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
02:53:39 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
02:53:39 WORKER: start processing job (9, 0, 2)
02:53:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:53:39 WORKER: args: ()
02:53:39 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0026251659619015333, 'num_filters_1': 115, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.035853727240879235}, 'budget': 400.0, 'working_directory': '.'}
02:54:33 DISPATCHER: Starting worker discovery
02:54:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:54:33 DISPATCHER: Finished worker discovery
02:55:33 DISPATCHER: Starting worker discovery
02:55:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:55:33 DISPATCHER: Finished worker discovery
02:56:33 DISPATCHER: Starting worker discovery
02:56:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:56:33 DISPATCHER: Finished worker discovery
02:57:33 DISPATCHER: Starting worker discovery
02:57:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:57:33 DISPATCHER: Finished worker discovery
02:58:33 DISPATCHER: Starting worker discovery
02:58:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:58:33 DISPATCHER: Finished worker discovery
02:59:33 DISPATCHER: Starting worker discovery
02:59:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:59:33 DISPATCHER: Finished worker discovery
03:00:33 DISPATCHER: Starting worker discovery
03:00:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:00:33 DISPATCHER: Finished worker discovery
03:01:00 WORKER: done with job (9, 0, 2), trying to register it.
03:01:00 WORKER: registered result for job (9, 0, 2) with dispatcher
03:01:00 DISPATCHER: job (9, 0, 2) finished
03:01:00 DISPATCHER: register_result: lock acquired
03:01:00 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
03:01:00 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0026251659619015333, 'num_filters_1': 115, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.035853727240879235}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3758988054244497, 'info': {'data03': 0.3758988054244497, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0026251659619015333, 'num_filters_1': 115, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.035853727240879235}"}}
exception: None

03:01:00 job_callback for (9, 0, 2) started
03:01:00 job_callback for (9, 0, 2) got condition
03:01:00 DISPATCHER: Trying to submit another job.
03:01:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:01:00 HBMASTER: Trying to run another job!
03:01:00 job_callback for (9, 0, 2) finished
03:01:00 HBMASTER: schedule new run for iteration 9
03:01:00 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
03:01:00 HBMASTER: submitting job (9, 0, 3) to dispatcher
03:01:00 DISPATCHER: trying to submit job (9, 0, 3)
03:01:00 DISPATCHER: trying to notify the job_runner thread.
03:01:00 HBMASTER: job (9, 0, 3) submitted to dispatcher
03:01:00 DISPATCHER: Trying to submit another job.
03:01:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:01:00 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
03:01:00 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
03:01:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:01:00 WORKER: start processing job (9, 0, 3)
03:01:00 WORKER: args: ()
03:01:00 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0025383215205773465, 'num_filters_1': 49, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.04517543239701986, 'kernel_size_2': 3, 'num_filters_2': 120}, 'budget': 400.0, 'working_directory': '.'}
03:01:33 DISPATCHER: Starting worker discovery
03:01:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:01:33 DISPATCHER: Finished worker discovery
03:02:33 DISPATCHER: Starting worker discovery
03:02:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:02:33 DISPATCHER: Finished worker discovery
03:03:33 DISPATCHER: Starting worker discovery
03:03:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:03:33 DISPATCHER: Finished worker discovery
03:04:33 DISPATCHER: Starting worker discovery
03:04:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:04:33 DISPATCHER: Finished worker discovery
03:05:33 DISPATCHER: Starting worker discovery
03:05:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:05:33 DISPATCHER: Finished worker discovery
03:06:33 DISPATCHER: Starting worker discovery
03:06:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:06:33 DISPATCHER: Finished worker discovery
03:07:33 DISPATCHER: Starting worker discovery
03:07:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:07:33 DISPATCHER: Finished worker discovery
03:08:21 WORKER: done with job (9, 0, 3), trying to register it.
03:08:21 WORKER: registered result for job (9, 0, 3) with dispatcher
03:08:21 DISPATCHER: job (9, 0, 3) finished
03:08:21 DISPATCHER: register_result: lock acquired
03:08:21 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
03:08:21 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0025383215205773465, 'num_filters_1': 49, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.04517543239701986, 'kernel_size_2': 3, 'num_filters_2': 120}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3240911889869287, 'info': {'data03': 0.3240911889869287, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0025383215205773465, 'num_filters_1': 49, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.04517543239701986, 'kernel_size_2': 3, 'num_filters_2': 120}"}}
exception: None

03:08:21 job_callback for (9, 0, 3) started
03:08:21 job_callback for (9, 0, 3) got condition
03:08:21 DISPATCHER: Trying to submit another job.
03:08:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:08:21 HBMASTER: Trying to run another job!
03:08:21 job_callback for (9, 0, 3) finished
03:08:21 ITERATION: Advancing config (9, 0, 2) to next budget 1200.000000
03:08:21 HBMASTER: schedule new run for iteration 9
03:08:21 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
03:08:21 HBMASTER: submitting job (9, 0, 2) to dispatcher
03:08:21 DISPATCHER: trying to submit job (9, 0, 2)
03:08:21 DISPATCHER: trying to notify the job_runner thread.
03:08:21 HBMASTER: job (9, 0, 2) submitted to dispatcher
03:08:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:08:21 DISPATCHER: Trying to submit another job.
03:08:21 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
03:08:21 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
03:08:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:08:21 WORKER: start processing job (9, 0, 2)
03:08:21 WORKER: args: ()
03:08:21 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0026251659619015333, 'num_filters_1': 115, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.035853727240879235}, 'budget': 1200.0, 'working_directory': '.'}
03:08:33 DISPATCHER: Starting worker discovery
03:08:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:08:33 DISPATCHER: Finished worker discovery
03:09:33 DISPATCHER: Starting worker discovery
03:09:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:09:33 DISPATCHER: Finished worker discovery
03:10:33 DISPATCHER: Starting worker discovery
03:10:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:10:33 DISPATCHER: Finished worker discovery
03:11:33 DISPATCHER: Starting worker discovery
03:11:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:11:33 DISPATCHER: Finished worker discovery
03:12:33 DISPATCHER: Starting worker discovery
03:12:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:12:33 DISPATCHER: Finished worker discovery
03:13:33 DISPATCHER: Starting worker discovery
03:13:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:13:33 DISPATCHER: Finished worker discovery
03:14:33 DISPATCHER: Starting worker discovery
03:14:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:14:33 DISPATCHER: Finished worker discovery
03:15:33 DISPATCHER: Starting worker discovery
03:15:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:15:33 DISPATCHER: Finished worker discovery
03:16:33 DISPATCHER: Starting worker discovery
03:16:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:16:33 DISPATCHER: Finished worker discovery
03:17:33 DISPATCHER: Starting worker discovery
03:17:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:17:33 DISPATCHER: Finished worker discovery
03:18:33 DISPATCHER: Starting worker discovery
03:18:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:18:33 DISPATCHER: Finished worker discovery
03:19:33 DISPATCHER: Starting worker discovery
03:19:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:19:33 DISPATCHER: Finished worker discovery
03:20:33 DISPATCHER: Starting worker discovery
03:20:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:20:33 DISPATCHER: Finished worker discovery
03:21:33 DISPATCHER: Starting worker discovery
03:21:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:21:33 DISPATCHER: Finished worker discovery
03:22:33 DISPATCHER: Starting worker discovery
03:22:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:22:33 DISPATCHER: Finished worker discovery
03:23:33 DISPATCHER: Starting worker discovery
03:23:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:23:33 DISPATCHER: Finished worker discovery
03:24:33 DISPATCHER: Starting worker discovery
03:24:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:24:33 DISPATCHER: Finished worker discovery
03:25:33 DISPATCHER: Starting worker discovery
03:25:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:25:33 DISPATCHER: Finished worker discovery
03:26:33 DISPATCHER: Starting worker discovery
03:26:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:26:33 DISPATCHER: Finished worker discovery
03:27:33 DISPATCHER: Starting worker discovery
03:27:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:27:33 DISPATCHER: Finished worker discovery
03:28:33 DISPATCHER: Starting worker discovery
03:28:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:28:33 DISPATCHER: Finished worker discovery
03:29:02 WORKER: done with job (9, 0, 2), trying to register it.
03:29:02 WORKER: registered result for job (9, 0, 2) with dispatcher
03:29:02 DISPATCHER: job (9, 0, 2) finished
03:29:02 DISPATCHER: register_result: lock acquired
03:29:02 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
03:29:02 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0026251659619015333, 'num_filters_1': 115, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.035853727240879235}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.36065980457672847, 'info': {'data03': 0.36065980457672847, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0026251659619015333, 'num_filters_1': 115, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.035853727240879235}"}}
exception: None

03:29:02 job_callback for (9, 0, 2) started
03:29:02 DISPATCHER: Trying to submit another job.
03:29:02 job_callback for (9, 0, 2) got condition
03:29:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:29:02 HBMASTER: Trying to run another job!
03:29:02 job_callback for (9, 0, 2) finished
03:29:02 HBMASTER: shutdown initiated, shutdown_workers = True
03:29:02 WORKER: shutting down now!
03:29:02 DISPATCHER: Dispatcher shutting down
03:29:02 DISPATCHER: Trying to submit another job.
03:29:02 DISPATCHER: job_runner shutting down
03:29:02 DISPATCHER: discover_workers shutting down
03:29:02 DISPATCHER: 'discover_worker' thread exited
03:29:02 DISPATCHER: 'job_runner' thread exited
03:29:02 DISPATCHER: shut down complete
03:29:03 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7f4dc815ab00; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:31180>
03:29:03 WORKER: No dispatcher found. Waiting for one to initiate contact.
03:29:03 WORKER: start listening for jobs
03:29:03 wait_for_workers trying to get the condition
03:29:03 DISPATCHER: started the 'discover_worker' thread
03:29:03 DISPATCHER: started the 'job_runner' thread
03:29:03 DISPATCHER: Pyro daemon running on localhost:40593
03:29:03 DISPATCHER: Starting worker discovery
03:29:03 DISPATCHER: Found 1 potential workers, 0 currently in the pool.
03:29:03 DISPATCHER: discovered new worker, hpbandster.run_0.worker.metagpui.1576139975513683776
03:29:03 HBMASTER: number of workers changed to 1
03:29:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:29:03 HBMASTER: only 1 worker(s) available, waiting for at least 1.
03:29:03 adjust_queue_size: lock accquired
03:29:03 HBMASTER: adjusted queue size to (0, 1)
03:29:03 DISPATCHER: Finished worker discovery
03:29:03 DISPATCHER: A new worker triggered discover_worker
03:29:03 DISPATCHER: Trying to submit another job.
03:29:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:29:03 Enough workers to start this run!
03:29:03 DISPATCHER: Starting worker discovery
03:29:03 HBMASTER: starting run at 1583893743.0261147
03:29:03 start sampling a new configuration.
03:29:03 done sampling a new configuration.
03:29:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:29:03 HBMASTER: schedule new run for iteration 0
03:29:03 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
03:29:03 HBMASTER: submitting job (0, 0, 0) to dispatcher
03:29:03 DISPATCHER: trying to submit job (0, 0, 0)
03:29:03 DISPATCHER: Finished worker discovery
03:29:03 DISPATCHER: trying to notify the job_runner thread.
03:29:03 HBMASTER: job (0, 0, 0) submitted to dispatcher
03:29:03 DISPATCHER: Trying to submit another job.
03:29:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:29:03 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
03:29:03 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
03:29:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:29:03 WORKER: start processing job (0, 0, 0)
03:29:03 WORKER: args: ()
03:29:03 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 80, 'last_n_outputs': 23, 'lr': 0.02954494129661249, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.010582977294060058}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-406:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:30:03 DISPATCHER: Starting worker discovery
03:30:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:30:03 DISPATCHER: Finished worker discovery
03:30:26 WORKER: done with job (0, 0, 0), trying to register it.
03:30:26 WORKER: registered result for job (0, 0, 0) with dispatcher
03:30:26 DISPATCHER: job (0, 0, 0) finished
03:30:26 DISPATCHER: register_result: lock acquired
03:30:26 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
03:30:26 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 80, 'last_n_outputs': 23, 'lr': 0.02954494129661249, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.010582977294060058}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 80, 'last_n_outputs': 23, 'lr': 0.02954494129661249, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.010582977294060058}"}}
exception: None

03:30:26 job_callback for (0, 0, 0) started
03:30:26 job_callback for (0, 0, 0) got condition
03:30:26 DISPATCHER: Trying to submit another job.
03:30:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:30:26 Only 1 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
03:30:26 HBMASTER: Trying to run another job!
03:30:26 job_callback for (0, 0, 0) finished
03:30:26 start sampling a new configuration.
03:30:26 done sampling a new configuration.
03:30:26 HBMASTER: schedule new run for iteration 0
03:30:26 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
03:30:26 HBMASTER: submitting job (0, 0, 1) to dispatcher
03:30:26 DISPATCHER: trying to submit job (0, 0, 1)
03:30:26 DISPATCHER: trying to notify the job_runner thread.
03:30:26 HBMASTER: job (0, 0, 1) submitted to dispatcher
03:30:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:30:26 DISPATCHER: Trying to submit another job.
03:30:26 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
03:30:26 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
03:30:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:30:26 WORKER: start processing job (0, 0, 1)
03:30:26 WORKER: args: ()
03:30:26 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 49, 'last_n_outputs': 26, 'lr': 0.0020966410540700178, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.05872025812319122}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:31:03 DISPATCHER: Starting worker discovery
03:31:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:31:03 DISPATCHER: Finished worker discovery
Exception in thread Thread-407:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:31:49 WORKER: done with job (0, 0, 1), trying to register it.
03:31:49 WORKER: registered result for job (0, 0, 1) with dispatcher
03:31:49 DISPATCHER: job (0, 0, 1) finished
03:31:49 DISPATCHER: register_result: lock acquired
03:31:49 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
03:31:49 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 49, 'last_n_outputs': 26, 'lr': 0.0020966410540700178, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.05872025812319122}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 49, 'last_n_outputs': 26, 'lr': 0.0020966410540700178, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.05872025812319122}"}}
exception: None

03:31:49 job_callback for (0, 0, 1) started
03:31:49 DISPATCHER: Trying to submit another job.
03:31:49 job_callback for (0, 0, 1) got condition
03:31:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:31:49 Only 2 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
03:31:49 HBMASTER: Trying to run another job!
03:31:49 job_callback for (0, 0, 1) finished
03:31:49 start sampling a new configuration.
03:31:49 done sampling a new configuration.
03:31:49 HBMASTER: schedule new run for iteration 0
03:31:49 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
03:31:49 HBMASTER: submitting job (0, 0, 2) to dispatcher
03:31:49 DISPATCHER: trying to submit job (0, 0, 2)
03:31:49 DISPATCHER: trying to notify the job_runner thread.
03:31:49 HBMASTER: job (0, 0, 2) submitted to dispatcher
03:31:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:31:49 DISPATCHER: Trying to submit another job.
03:31:49 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
03:31:49 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
03:31:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:31:49 WORKER: start processing job (0, 0, 2)
03:31:49 WORKER: args: ()
03:31:49 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 59, 'last_n_outputs': 34, 'lr': 0.0032396191266153038, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.1540656374857601}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:32:03 DISPATCHER: Starting worker discovery
03:32:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:32:03 DISPATCHER: Finished worker discovery
Exception in thread Thread-408:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:33:03 DISPATCHER: Starting worker discovery
03:33:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:33:03 DISPATCHER: Finished worker discovery
03:33:11 WORKER: done with job (0, 0, 2), trying to register it.
03:33:11 WORKER: registered result for job (0, 0, 2) with dispatcher
03:33:11 DISPATCHER: job (0, 0, 2) finished
03:33:11 DISPATCHER: register_result: lock acquired
03:33:11 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
03:33:11 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 59, 'last_n_outputs': 34, 'lr': 0.0032396191266153038, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.1540656374857601}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 59, 'last_n_outputs': 34, 'lr': 0.0032396191266153038, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.1540656374857601}"}}
exception: None

03:33:11 job_callback for (0, 0, 2) started
03:33:11 DISPATCHER: Trying to submit another job.
03:33:11 job_callback for (0, 0, 2) got condition
03:33:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:33:11 Only 3 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
03:33:11 HBMASTER: Trying to run another job!
03:33:11 job_callback for (0, 0, 2) finished
03:33:11 start sampling a new configuration.
03:33:11 done sampling a new configuration.
03:33:11 HBMASTER: schedule new run for iteration 0
03:33:11 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
03:33:11 HBMASTER: submitting job (0, 0, 3) to dispatcher
03:33:11 DISPATCHER: trying to submit job (0, 0, 3)
03:33:11 DISPATCHER: trying to notify the job_runner thread.
03:33:11 HBMASTER: job (0, 0, 3) submitted to dispatcher
03:33:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:33:11 DISPATCHER: Trying to submit another job.
03:33:11 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
03:33:11 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
03:33:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:33:11 WORKER: start processing job (0, 0, 3)
03:33:11 WORKER: args: ()
03:33:11 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 59, 'last_n_outputs': 17, 'lr': 0.0057495508829871434, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.08290201481591009}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-409:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:34:03 DISPATCHER: Starting worker discovery
03:34:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:34:03 DISPATCHER: Finished worker discovery
03:34:33 WORKER: done with job (0, 0, 3), trying to register it.
03:34:33 WORKER: registered result for job (0, 0, 3) with dispatcher
03:34:33 DISPATCHER: job (0, 0, 3) finished
03:34:33 DISPATCHER: register_result: lock acquired
03:34:33 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
03:34:33 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 59, 'last_n_outputs': 17, 'lr': 0.0057495508829871434, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.08290201481591009}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 59, 'last_n_outputs': 17, 'lr': 0.0057495508829871434, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.08290201481591009}"}}
exception: None

03:34:33 job_callback for (0, 0, 3) started
03:34:33 job_callback for (0, 0, 3) got condition
03:34:33 DISPATCHER: Trying to submit another job.
03:34:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:34:33 Only 4 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
03:34:33 HBMASTER: Trying to run another job!
03:34:33 job_callback for (0, 0, 3) finished
03:34:33 start sampling a new configuration.
03:34:33 done sampling a new configuration.
03:34:33 HBMASTER: schedule new run for iteration 0
03:34:33 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
03:34:33 HBMASTER: submitting job (0, 0, 4) to dispatcher
03:34:33 DISPATCHER: trying to submit job (0, 0, 4)
03:34:33 DISPATCHER: trying to notify the job_runner thread.
03:34:33 HBMASTER: job (0, 0, 4) submitted to dispatcher
03:34:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:34:33 DISPATCHER: Trying to submit another job.
03:34:33 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
03:34:33 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
03:34:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:34:33 WORKER: start processing job (0, 0, 4)
03:34:33 WORKER: args: ()
03:34:33 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 39, 'last_n_outputs': 21, 'lr': 0.007259987320293249, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.17249807308750847}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:35:03 DISPATCHER: Starting worker discovery
03:35:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:35:03 DISPATCHER: Finished worker discovery
Exception in thread Thread-410:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:35:51 WORKER: done with job (0, 0, 4), trying to register it.
03:35:51 WORKER: registered result for job (0, 0, 4) with dispatcher
03:35:51 DISPATCHER: job (0, 0, 4) finished
03:35:51 DISPATCHER: register_result: lock acquired
03:35:51 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
03:35:51 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 39, 'last_n_outputs': 21, 'lr': 0.007259987320293249, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.17249807308750847}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 39, 'last_n_outputs': 21, 'lr': 0.007259987320293249, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.17249807308750847}"}}
exception: None

03:35:51 job_callback for (0, 0, 4) started
03:35:51 job_callback for (0, 0, 4) got condition
03:35:51 DISPATCHER: Trying to submit another job.
03:35:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:35:51 Only 5 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
03:35:51 HBMASTER: Trying to run another job!
03:35:51 job_callback for (0, 0, 4) finished
03:35:51 start sampling a new configuration.
03:35:51 done sampling a new configuration.
03:35:51 HBMASTER: schedule new run for iteration 0
03:35:51 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
03:35:51 HBMASTER: submitting job (0, 0, 5) to dispatcher
03:35:51 DISPATCHER: trying to submit job (0, 0, 5)
03:35:51 DISPATCHER: trying to notify the job_runner thread.
03:35:51 HBMASTER: job (0, 0, 5) submitted to dispatcher
03:35:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:35:51 DISPATCHER: Trying to submit another job.
03:35:51 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
03:35:51 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
03:35:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:35:51 WORKER: start processing job (0, 0, 5)
03:35:51 WORKER: args: ()
03:35:51 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 69, 'last_n_outputs': 19, 'lr': 0.004230709287538498, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.1336229367295111}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:36:03 DISPATCHER: Starting worker discovery
03:36:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:36:03 DISPATCHER: Finished worker discovery
Exception in thread Thread-411:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:37:03 DISPATCHER: Starting worker discovery
03:37:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:37:03 DISPATCHER: Finished worker discovery
03:37:15 WORKER: done with job (0, 0, 5), trying to register it.
03:37:15 WORKER: registered result for job (0, 0, 5) with dispatcher
03:37:15 DISPATCHER: job (0, 0, 5) finished
03:37:15 DISPATCHER: register_result: lock acquired
03:37:15 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
03:37:15 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 69, 'last_n_outputs': 19, 'lr': 0.004230709287538498, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.1336229367295111}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 69, 'last_n_outputs': 19, 'lr': 0.004230709287538498, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.1336229367295111}"}}
exception: None

03:37:15 job_callback for (0, 0, 5) started
03:37:15 DISPATCHER: Trying to submit another job.
03:37:15 job_callback for (0, 0, 5) got condition
03:37:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:37:15 Only 6 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
03:37:15 HBMASTER: Trying to run another job!
03:37:15 job_callback for (0, 0, 5) finished
03:37:15 start sampling a new configuration.
03:37:15 done sampling a new configuration.
03:37:15 HBMASTER: schedule new run for iteration 0
03:37:15 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
03:37:15 HBMASTER: submitting job (0, 0, 6) to dispatcher
03:37:15 DISPATCHER: trying to submit job (0, 0, 6)
03:37:15 DISPATCHER: trying to notify the job_runner thread.
03:37:15 HBMASTER: job (0, 0, 6) submitted to dispatcher
03:37:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:37:15 DISPATCHER: Trying to submit another job.
03:37:15 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776
03:37:15 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
03:37:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:37:15 WORKER: start processing job (0, 0, 6)
03:37:15 WORKER: args: ()
03:37:15 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 50, 'last_n_outputs': 41, 'lr': 0.009504149293771896, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.014962916707733701}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:38:03 DISPATCHER: Starting worker discovery
03:38:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:38:03 DISPATCHER: Finished worker discovery
Exception in thread Thread-412:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:38:41 WORKER: done with job (0, 0, 6), trying to register it.
03:38:41 WORKER: registered result for job (0, 0, 6) with dispatcher
03:38:41 DISPATCHER: job (0, 0, 6) finished
03:38:41 DISPATCHER: register_result: lock acquired
03:38:41 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
03:38:41 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 50, 'last_n_outputs': 41, 'lr': 0.009504149293771896, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.014962916707733701}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 50, 'last_n_outputs': 41, 'lr': 0.009504149293771896, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.014962916707733701}"}}
exception: None

03:38:41 job_callback for (0, 0, 6) started
03:38:41 job_callback for (0, 0, 6) got condition
03:38:41 DISPATCHER: Trying to submit another job.
03:38:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:38:41 Only 7 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
03:38:41 HBMASTER: Trying to run another job!
03:38:41 job_callback for (0, 0, 6) finished
03:38:41 start sampling a new configuration.
03:38:41 done sampling a new configuration.
03:38:41 HBMASTER: schedule new run for iteration 0
03:38:41 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
03:38:41 HBMASTER: submitting job (0, 0, 7) to dispatcher
03:38:41 DISPATCHER: trying to submit job (0, 0, 7)
03:38:41 DISPATCHER: trying to notify the job_runner thread.
03:38:41 HBMASTER: job (0, 0, 7) submitted to dispatcher
03:38:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:38:41 DISPATCHER: Trying to submit another job.
03:38:41 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776
03:38:41 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
03:38:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:38:41 WORKER: start processing job (0, 0, 7)
03:38:41 WORKER: args: ()
03:38:41 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 75, 'last_n_outputs': 4, 'lr': 0.041456881429167466, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.016822744441875287}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:39:03 DISPATCHER: Starting worker discovery
03:39:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:39:03 DISPATCHER: Finished worker discovery
Exception in thread Thread-413:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:40:03 DISPATCHER: Starting worker discovery
03:40:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:40:03 DISPATCHER: Finished worker discovery
03:40:04 WORKER: done with job (0, 0, 7), trying to register it.
03:40:04 WORKER: registered result for job (0, 0, 7) with dispatcher
03:40:04 DISPATCHER: job (0, 0, 7) finished
03:40:04 DISPATCHER: register_result: lock acquired
03:40:04 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
03:40:04 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 75, 'last_n_outputs': 4, 'lr': 0.041456881429167466, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.016822744441875287}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 75, 'last_n_outputs': 4, 'lr': 0.041456881429167466, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.016822744441875287}"}}
exception: None

03:40:04 job_callback for (0, 0, 7) started
03:40:04 job_callback for (0, 0, 7) got condition
03:40:04 DISPATCHER: Trying to submit another job.
03:40:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:40:04 Only 8 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
03:40:04 HBMASTER: Trying to run another job!
03:40:04 job_callback for (0, 0, 7) finished
03:40:04 start sampling a new configuration.
03:40:04 done sampling a new configuration.
03:40:04 HBMASTER: schedule new run for iteration 0
03:40:04 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
03:40:04 HBMASTER: submitting job (0, 0, 8) to dispatcher
03:40:04 DISPATCHER: trying to submit job (0, 0, 8)
03:40:04 DISPATCHER: trying to notify the job_runner thread.
03:40:04 HBMASTER: job (0, 0, 8) submitted to dispatcher
03:40:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:40:04 DISPATCHER: Trying to submit another job.
03:40:04 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776
03:40:04 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
03:40:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:40:04 WORKER: start processing job (0, 0, 8)
03:40:04 WORKER: args: ()
03:40:04 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 81, 'last_n_outputs': 42, 'lr': 0.033366825041843316, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.016172103692500366}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-414:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:41:03 DISPATCHER: Starting worker discovery
03:41:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:41:03 DISPATCHER: Finished worker discovery
03:41:27 WORKER: done with job (0, 0, 8), trying to register it.
03:41:27 WORKER: registered result for job (0, 0, 8) with dispatcher
03:41:27 DISPATCHER: job (0, 0, 8) finished
03:41:27 DISPATCHER: register_result: lock acquired
03:41:27 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
03:41:27 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 81, 'last_n_outputs': 42, 'lr': 0.033366825041843316, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.016172103692500366}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 81, 'last_n_outputs': 42, 'lr': 0.033366825041843316, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.016172103692500366}"}}
exception: None

03:41:27 job_callback for (0, 0, 8) started
03:41:27 DISPATCHER: Trying to submit another job.
03:41:27 job_callback for (0, 0, 8) got condition
03:41:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:41:27 HBMASTER: Trying to run another job!
03:41:27 job_callback for (0, 0, 8) finished
03:41:27 start sampling a new configuration.
03:41:27 done sampling a new configuration.
03:41:27 HBMASTER: schedule new run for iteration 0
03:41:27 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
03:41:27 HBMASTER: submitting job (0, 0, 9) to dispatcher
03:41:27 DISPATCHER: trying to submit job (0, 0, 9)
03:41:27 DISPATCHER: trying to notify the job_runner thread.
03:41:27 HBMASTER: job (0, 0, 9) submitted to dispatcher
03:41:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:41:27 DISPATCHER: Trying to submit another job.
03:41:27 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpui.1576139975513683776
03:41:27 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
03:41:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:41:27 WORKER: start processing job (0, 0, 9)
03:41:27 WORKER: args: ()
03:41:27 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 75, 'last_n_outputs': 2, 'lr': 0.01599784554010851, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.1335273700834898}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:42:03 DISPATCHER: Starting worker discovery
03:42:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:42:03 DISPATCHER: Finished worker discovery
Exception in thread Thread-415:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:42:51 WORKER: done with job (0, 0, 9), trying to register it.
03:42:51 WORKER: registered result for job (0, 0, 9) with dispatcher
03:42:51 DISPATCHER: job (0, 0, 9) finished
03:42:51 DISPATCHER: register_result: lock acquired
03:42:51 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
03:42:51 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 75, 'last_n_outputs': 2, 'lr': 0.01599784554010851, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.1335273700834898}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 75, 'last_n_outputs': 2, 'lr': 0.01599784554010851, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.1335273700834898}"}}
exception: None

03:42:51 job_callback for (0, 0, 9) started
03:42:51 DISPATCHER: Trying to submit another job.
03:42:51 job_callback for (0, 0, 9) got condition
03:42:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:42:51 HBMASTER: Trying to run another job!
03:42:51 job_callback for (0, 0, 9) finished
03:42:51 start sampling a new configuration.
03:42:51 done sampling a new configuration.
03:42:51 HBMASTER: schedule new run for iteration 0
03:42:51 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
03:42:51 HBMASTER: submitting job (0, 0, 10) to dispatcher
03:42:51 DISPATCHER: trying to submit job (0, 0, 10)
03:42:51 DISPATCHER: trying to notify the job_runner thread.
03:42:51 HBMASTER: job (0, 0, 10) submitted to dispatcher
03:42:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:42:51 DISPATCHER: Trying to submit another job.
03:42:51 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpui.1576139975513683776
03:42:51 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
03:42:51 WORKER: start processing job (0, 0, 10)
03:42:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:42:51 WORKER: args: ()
03:42:51 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 2, 'lr': 0.0014828984023386536, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.040067986516424396}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:43:03 DISPATCHER: Starting worker discovery
03:43:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:43:03 DISPATCHER: Finished worker discovery
Exception in thread Thread-416:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:44:03 DISPATCHER: Starting worker discovery
03:44:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:44:03 DISPATCHER: Finished worker discovery
03:44:15 WORKER: done with job (0, 0, 10), trying to register it.
03:44:15 WORKER: registered result for job (0, 0, 10) with dispatcher
03:44:15 DISPATCHER: job (0, 0, 10) finished
03:44:15 DISPATCHER: register_result: lock acquired
03:44:15 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
03:44:15 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 2, 'lr': 0.0014828984023386536, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.040067986516424396}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 2, 'lr': 0.0014828984023386536, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.040067986516424396}"}}
exception: None

03:44:15 job_callback for (0, 0, 10) started
03:44:15 job_callback for (0, 0, 10) got condition
03:44:15 DISPATCHER: Trying to submit another job.
03:44:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:44:15 HBMASTER: Trying to run another job!
03:44:15 job_callback for (0, 0, 10) finished
03:44:15 start sampling a new configuration.
03:44:15 done sampling a new configuration.
03:44:15 HBMASTER: schedule new run for iteration 0
03:44:15 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
03:44:15 HBMASTER: submitting job (0, 0, 11) to dispatcher
03:44:15 DISPATCHER: trying to submit job (0, 0, 11)
03:44:15 DISPATCHER: trying to notify the job_runner thread.
03:44:15 HBMASTER: job (0, 0, 11) submitted to dispatcher
03:44:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:44:15 DISPATCHER: Trying to submit another job.
03:44:15 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776
03:44:15 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
03:44:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:44:15 WORKER: start processing job (0, 0, 11)
03:44:15 WORKER: args: ()
03:44:15 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 75, 'last_n_outputs': 49, 'lr': 0.0077301627241755065, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.010831861867239593}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:45:03 DISPATCHER: Starting worker discovery
03:45:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:45:03 DISPATCHER: Finished worker discovery
Exception in thread Thread-417:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:45:41 WORKER: done with job (0, 0, 11), trying to register it.
03:45:41 WORKER: registered result for job (0, 0, 11) with dispatcher
03:45:41 DISPATCHER: job (0, 0, 11) finished
03:45:41 DISPATCHER: register_result: lock acquired
03:45:41 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
03:45:41 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 75, 'last_n_outputs': 49, 'lr': 0.0077301627241755065, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.010831861867239593}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.17742140137024873, 'info': {'data03': 0.17742140137024873, 'config': "{'batch_size': 128, 'hidden_dim': 75, 'last_n_outputs': 49, 'lr': 0.0077301627241755065, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.010831861867239593}"}}
exception: None

03:45:41 job_callback for (0, 0, 11) started
03:45:41 job_callback for (0, 0, 11) got condition
03:45:41 DISPATCHER: Trying to submit another job.
03:45:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:45:41 HBMASTER: Trying to run another job!
03:45:41 job_callback for (0, 0, 11) finished
03:45:41 start sampling a new configuration.
03:45:41 done sampling a new configuration.
03:45:41 HBMASTER: schedule new run for iteration 0
03:45:41 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
03:45:41 HBMASTER: submitting job (0, 0, 12) to dispatcher
03:45:41 DISPATCHER: trying to submit job (0, 0, 12)
03:45:41 DISPATCHER: trying to notify the job_runner thread.
03:45:41 HBMASTER: job (0, 0, 12) submitted to dispatcher
03:45:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:45:41 DISPATCHER: Trying to submit another job.
03:45:41 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpui.1576139975513683776
03:45:41 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
03:45:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:45:41 WORKER: start processing job (0, 0, 12)
03:45:41 WORKER: args: ()
03:45:41 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 32, 'lr': 0.015805592431518488, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.07225049468887908}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:46:03 DISPATCHER: Starting worker discovery
03:46:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:46:03 DISPATCHER: Finished worker discovery
Exception in thread Thread-418:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:47:03 DISPATCHER: Starting worker discovery
03:47:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:47:03 DISPATCHER: Finished worker discovery
03:47:06 WORKER: done with job (0, 0, 12), trying to register it.
03:47:06 WORKER: registered result for job (0, 0, 12) with dispatcher
03:47:06 DISPATCHER: job (0, 0, 12) finished
03:47:06 DISPATCHER: register_result: lock acquired
03:47:06 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
03:47:06 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 32, 'lr': 0.015805592431518488, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.07225049468887908}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 32, 'lr': 0.015805592431518488, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.07225049468887908}"}}
exception: None

03:47:06 job_callback for (0, 0, 12) started
03:47:06 DISPATCHER: Trying to submit another job.
03:47:06 job_callback for (0, 0, 12) got condition
03:47:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:47:06 HBMASTER: Trying to run another job!
03:47:06 job_callback for (0, 0, 12) finished
03:47:06 start sampling a new configuration.
03:47:06 done sampling a new configuration.
03:47:06 HBMASTER: schedule new run for iteration 0
03:47:06 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
03:47:06 HBMASTER: submitting job (0, 0, 13) to dispatcher
03:47:06 DISPATCHER: trying to submit job (0, 0, 13)
03:47:06 DISPATCHER: trying to notify the job_runner thread.
03:47:06 HBMASTER: job (0, 0, 13) submitted to dispatcher
03:47:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:47:06 DISPATCHER: Trying to submit another job.
03:47:06 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpui.1576139975513683776
03:47:06 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
03:47:06 WORKER: start processing job (0, 0, 13)
03:47:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:47:06 WORKER: args: ()
03:47:06 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 11, 'lr': 0.0433458116423278, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.09979327149045675}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-419:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:48:03 DISPATCHER: Starting worker discovery
03:48:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:48:03 DISPATCHER: Finished worker discovery
03:48:30 WORKER: done with job (0, 0, 13), trying to register it.
03:48:30 WORKER: registered result for job (0, 0, 13) with dispatcher
03:48:30 DISPATCHER: job (0, 0, 13) finished
03:48:30 DISPATCHER: register_result: lock acquired
03:48:30 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
03:48:30 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 11, 'lr': 0.0433458116423278, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.09979327149045675}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 11, 'lr': 0.0433458116423278, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.09979327149045675}"}}
exception: None

03:48:30 job_callback for (0, 0, 13) started
03:48:30 DISPATCHER: Trying to submit another job.
03:48:30 job_callback for (0, 0, 13) got condition
03:48:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:48:30 HBMASTER: Trying to run another job!
03:48:30 job_callback for (0, 0, 13) finished
03:48:30 start sampling a new configuration.
03:48:30 done sampling a new configuration.
03:48:30 HBMASTER: schedule new run for iteration 0
03:48:30 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
03:48:30 HBMASTER: submitting job (0, 0, 14) to dispatcher
03:48:30 DISPATCHER: trying to submit job (0, 0, 14)
03:48:30 DISPATCHER: trying to notify the job_runner thread.
03:48:30 HBMASTER: job (0, 0, 14) submitted to dispatcher
03:48:30 DISPATCHER: Trying to submit another job.
03:48:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:48:30 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776
03:48:30 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
03:48:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:48:30 WORKER: start processing job (0, 0, 14)
03:48:30 WORKER: args: ()
03:48:30 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 95, 'last_n_outputs': 36, 'lr': 0.0024903105771332708, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.018108113535766735}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:49:03 DISPATCHER: Starting worker discovery
03:49:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:49:03 DISPATCHER: Finished worker discovery
Exception in thread Thread-420:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:49:54 WORKER: done with job (0, 0, 14), trying to register it.
03:49:54 WORKER: registered result for job (0, 0, 14) with dispatcher
03:49:54 DISPATCHER: job (0, 0, 14) finished
03:49:54 DISPATCHER: register_result: lock acquired
03:49:54 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
03:49:54 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 95, 'last_n_outputs': 36, 'lr': 0.0024903105771332708, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.018108113535766735}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 95, 'last_n_outputs': 36, 'lr': 0.0024903105771332708, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.018108113535766735}"}}
exception: None

03:49:54 job_callback for (0, 0, 14) started
03:49:54 DISPATCHER: Trying to submit another job.
03:49:54 job_callback for (0, 0, 14) got condition
03:49:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:49:54 HBMASTER: Trying to run another job!
03:49:54 job_callback for (0, 0, 14) finished
03:49:54 start sampling a new configuration.
03:49:54 done sampling a new configuration.
03:49:54 HBMASTER: schedule new run for iteration 0
03:49:54 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
03:49:54 HBMASTER: submitting job (0, 0, 15) to dispatcher
03:49:54 DISPATCHER: trying to submit job (0, 0, 15)
03:49:54 DISPATCHER: trying to notify the job_runner thread.
03:49:54 HBMASTER: job (0, 0, 15) submitted to dispatcher
03:49:54 DISPATCHER: Trying to submit another job.
03:49:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:49:54 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776
03:49:54 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
03:49:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:49:54 WORKER: start processing job (0, 0, 15)
03:49:54 WORKER: args: ()
03:49:54 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 48, 'last_n_outputs': 48, 'lr': 0.002016049610580376, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.15170816469886625}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:50:03 DISPATCHER: Starting worker discovery
03:50:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:50:03 DISPATCHER: Finished worker discovery
Exception in thread Thread-421:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:51:03 DISPATCHER: Starting worker discovery
03:51:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:51:03 DISPATCHER: Finished worker discovery
03:51:16 WORKER: done with job (0, 0, 15), trying to register it.
03:51:16 WORKER: registered result for job (0, 0, 15) with dispatcher
03:51:16 DISPATCHER: job (0, 0, 15) finished
03:51:16 DISPATCHER: register_result: lock acquired
03:51:16 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
03:51:16 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 48, 'last_n_outputs': 48, 'lr': 0.002016049610580376, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.15170816469886625}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.15962507607177948, 'info': {'data03': 0.15962507607177948, 'config': "{'batch_size': 16, 'hidden_dim': 48, 'last_n_outputs': 48, 'lr': 0.002016049610580376, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.15170816469886625}"}}
exception: None

03:51:16 job_callback for (0, 0, 15) started
03:51:16 DISPATCHER: Trying to submit another job.
03:51:16 job_callback for (0, 0, 15) got condition
03:51:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:51:16 HBMASTER: Trying to run another job!
03:51:16 job_callback for (0, 0, 15) finished
03:51:16 start sampling a new configuration.
03:51:16 done sampling a new configuration.
03:51:16 HBMASTER: schedule new run for iteration 0
03:51:16 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
03:51:16 HBMASTER: submitting job (0, 0, 16) to dispatcher
03:51:16 DISPATCHER: trying to submit job (0, 0, 16)
03:51:16 DISPATCHER: trying to notify the job_runner thread.
03:51:16 HBMASTER: job (0, 0, 16) submitted to dispatcher
03:51:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:51:16 DISPATCHER: Trying to submit another job.
03:51:16 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpui.1576139975513683776
03:51:16 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
03:51:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:51:16 WORKER: start processing job (0, 0, 16)
03:51:16 WORKER: args: ()
03:51:16 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 58, 'last_n_outputs': 7, 'lr': 0.009168744365120014, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.021704513607725334}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-422:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:52:03 DISPATCHER: Starting worker discovery
03:52:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:52:03 DISPATCHER: Finished worker discovery
03:52:39 WORKER: done with job (0, 0, 16), trying to register it.
03:52:39 WORKER: registered result for job (0, 0, 16) with dispatcher
03:52:39 DISPATCHER: job (0, 0, 16) finished
03:52:39 DISPATCHER: register_result: lock acquired
03:52:39 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
03:52:39 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 58, 'last_n_outputs': 7, 'lr': 0.009168744365120014, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.021704513607725334}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 58, 'last_n_outputs': 7, 'lr': 0.009168744365120014, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.021704513607725334}"}}
exception: None

03:52:39 job_callback for (0, 0, 16) started
03:52:39 job_callback for (0, 0, 16) got condition
03:52:39 DISPATCHER: Trying to submit another job.
03:52:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:52:39 HBMASTER: Trying to run another job!
03:52:39 job_callback for (0, 0, 16) finished
03:52:39 start sampling a new configuration.
03:52:39 done sampling a new configuration.
03:52:39 HBMASTER: schedule new run for iteration 0
03:52:39 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
03:52:39 HBMASTER: submitting job (0, 0, 17) to dispatcher
03:52:39 DISPATCHER: trying to submit job (0, 0, 17)
03:52:39 DISPATCHER: trying to notify the job_runner thread.
03:52:39 HBMASTER: job (0, 0, 17) submitted to dispatcher
03:52:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:52:39 DISPATCHER: Trying to submit another job.
03:52:39 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpui.1576139975513683776
03:52:39 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
03:52:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:52:39 WORKER: start processing job (0, 0, 17)
03:52:39 WORKER: args: ()
03:52:39 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 44, 'last_n_outputs': 24, 'lr': 0.06582902241003817, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.1636035415419047}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:53:03 DISPATCHER: Starting worker discovery
03:53:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:53:03 DISPATCHER: Finished worker discovery
Exception in thread Thread-423:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:54:03 DISPATCHER: Starting worker discovery
03:54:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:54:03 DISPATCHER: Finished worker discovery
03:54:05 WORKER: done with job (0, 0, 17), trying to register it.
03:54:05 WORKER: registered result for job (0, 0, 17) with dispatcher
03:54:05 DISPATCHER: job (0, 0, 17) finished
03:54:05 DISPATCHER: register_result: lock acquired
03:54:05 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
03:54:05 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 44, 'last_n_outputs': 24, 'lr': 0.06582902241003817, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.1636035415419047}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 44, 'last_n_outputs': 24, 'lr': 0.06582902241003817, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.1636035415419047}"}}
exception: None

03:54:05 job_callback for (0, 0, 17) started
03:54:05 job_callback for (0, 0, 17) got condition
03:54:05 DISPATCHER: Trying to submit another job.
03:54:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:54:05 done building a new model for budget 44.444444 based on 9/15 split
Best loss for this budget:-0.177421





03:54:05 HBMASTER: Trying to run another job!
03:54:05 job_callback for (0, 0, 17) finished
03:54:05 start sampling a new configuration.
03:54:05 best_vector: [3, 0.6568747420249197, 0.2018981728740742, 0.9263800615284189, 0.0983753586959942, 1, 0.9410670753879176, 0.42393713725072074], 0.00025917410725728637, 0.03770518845965507, 9.77220855799884e-06
03:54:05 done sampling a new configuration.
03:54:05 HBMASTER: schedule new run for iteration 0
03:54:05 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
03:54:05 HBMASTER: submitting job (0, 0, 18) to dispatcher
03:54:05 DISPATCHER: trying to submit job (0, 0, 18)
03:54:05 DISPATCHER: trying to notify the job_runner thread.
03:54:05 HBMASTER: job (0, 0, 18) submitted to dispatcher
03:54:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:54:05 DISPATCHER: Trying to submit another job.
03:54:05 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpui.1576139975513683776
03:54:05 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
03:54:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:54:05 WORKER: start processing job (0, 0, 18)
03:54:05 WORKER: args: ()
03:54:05 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 73, 'last_n_outputs': 11, 'lr': 0.07124594036872846, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.035608602681202785}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:55:03 DISPATCHER: Starting worker discovery
03:55:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:55:03 DISPATCHER: Finished worker discovery
Exception in thread Thread-424:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:55:33 WORKER: done with job (0, 0, 18), trying to register it.
03:55:33 WORKER: registered result for job (0, 0, 18) with dispatcher
03:55:33 DISPATCHER: job (0, 0, 18) finished
03:55:33 DISPATCHER: register_result: lock acquired
03:55:33 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
03:55:33 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 73, 'last_n_outputs': 11, 'lr': 0.07124594036872846, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.035608602681202785}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 73, 'last_n_outputs': 11, 'lr': 0.07124594036872846, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.035608602681202785}"}}
exception: None

03:55:33 DISPATCHER: Trying to submit another job.
03:55:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:55:33 job_callback for (0, 0, 18) started
03:55:33 job_callback for (0, 0, 18) got condition
03:55:33 done building a new model for budget 44.444444 based on 9/16 split
Best loss for this budget:-0.177421





03:55:33 HBMASTER: Trying to run another job!
03:55:33 job_callback for (0, 0, 18) finished
03:55:33 start sampling a new configuration.
03:55:33 best_vector: [1, 0.9917389909475678, 0.502078592063944, 0.8815129675134259, 0.8438327912282775, 0, 0.10733778646329067, 0.8837218401636506], 0.016359143799799303, 0.02355622234118357, 0.00038535962865946703
03:55:33 done sampling a new configuration.
03:55:33 HBMASTER: schedule new run for iteration 0
03:55:33 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
03:55:33 HBMASTER: submitting job (0, 0, 19) to dispatcher
03:55:33 DISPATCHER: trying to submit job (0, 0, 19)
03:55:33 DISPATCHER: trying to notify the job_runner thread.
03:55:33 HBMASTER: job (0, 0, 19) submitted to dispatcher
03:55:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:55:33 DISPATCHER: Trying to submit another job.
03:55:33 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpui.1576139975513683776
03:55:33 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
03:55:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:55:33 WORKER: start processing job (0, 0, 19)
03:55:33 WORKER: args: ()
03:55:33 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 100, 'last_n_outputs': 26, 'lr': 0.057946329955480234, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.1411720176895671}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:56:03 DISPATCHER: Starting worker discovery
03:56:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:56:03 DISPATCHER: Finished worker discovery
Exception in thread Thread-425:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:56:59 WORKER: done with job (0, 0, 19), trying to register it.
03:56:59 WORKER: registered result for job (0, 0, 19) with dispatcher
03:56:59 DISPATCHER: job (0, 0, 19) finished
03:56:59 DISPATCHER: register_result: lock acquired
03:56:59 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
03:56:59 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 100, 'last_n_outputs': 26, 'lr': 0.057946329955480234, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.1411720176895671}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 100, 'last_n_outputs': 26, 'lr': 0.057946329955480234, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.1411720176895671}"}}
exception: None

03:56:59 job_callback for (0, 0, 19) started
03:56:59 job_callback for (0, 0, 19) got condition
03:56:59 DISPATCHER: Trying to submit another job.
03:56:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:56:59 done building a new model for budget 44.444444 based on 9/17 split
Best loss for this budget:-0.177421





03:56:59 HBMASTER: Trying to run another job!
03:56:59 job_callback for (0, 0, 19) finished
03:56:59 start sampling a new configuration.
03:56:59 best_vector: [3, 0.9174349083901367, 0.9083852520322251, 0.18526885833645906, 0.464839833190576, 1, 0.17685566548587686, 0.015262972053373874], 0.06670914639822964, 0.07523547223920041, 0.005018894131944762
03:56:59 done sampling a new configuration.
03:56:59 HBMASTER: schedule new run for iteration 0
03:56:59 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
03:56:59 HBMASTER: submitting job (0, 0, 20) to dispatcher
03:56:59 DISPATCHER: trying to submit job (0, 0, 20)
03:56:59 DISPATCHER: trying to notify the job_runner thread.
03:56:59 HBMASTER: job (0, 0, 20) submitted to dispatcher
03:56:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:56:59 DISPATCHER: Trying to submit another job.
03:56:59 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpui.1576139975513683776
03:56:59 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
03:56:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:56:59 WORKER: start processing job (0, 0, 20)
03:56:59 WORKER: args: ()
03:56:59 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 94, 'last_n_outputs': 46, 'lr': 0.0023471330926011632, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.010467852258797405}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:57:03 DISPATCHER: Starting worker discovery
03:57:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:57:03 DISPATCHER: Finished worker discovery
Exception in thread Thread-426:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:58:03 DISPATCHER: Starting worker discovery
03:58:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:58:03 DISPATCHER: Finished worker discovery
03:58:23 WORKER: done with job (0, 0, 20), trying to register it.
03:58:23 WORKER: registered result for job (0, 0, 20) with dispatcher
03:58:23 DISPATCHER: job (0, 0, 20) finished
03:58:23 DISPATCHER: register_result: lock acquired
03:58:23 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
03:58:23 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 94, 'last_n_outputs': 46, 'lr': 0.0023471330926011632, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.010467852258797405}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 94, 'last_n_outputs': 46, 'lr': 0.0023471330926011632, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.010467852258797405}"}}
exception: None

03:58:23 job_callback for (0, 0, 20) started
03:58:23 DISPATCHER: Trying to submit another job.
03:58:23 job_callback for (0, 0, 20) got condition
03:58:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:58:23 done building a new model for budget 44.444444 based on 9/17 split
Best loss for this budget:-0.177421





03:58:23 HBMASTER: Trying to run another job!
03:58:23 job_callback for (0, 0, 20) finished
03:58:23 start sampling a new configuration.
03:58:23 done sampling a new configuration.
03:58:23 HBMASTER: schedule new run for iteration 0
03:58:23 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
03:58:23 HBMASTER: submitting job (0, 0, 21) to dispatcher
03:58:23 DISPATCHER: trying to submit job (0, 0, 21)
03:58:23 DISPATCHER: trying to notify the job_runner thread.
03:58:23 HBMASTER: job (0, 0, 21) submitted to dispatcher
03:58:23 DISPATCHER: Trying to submit another job.
03:58:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:58:23 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776
03:58:23 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
03:58:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:58:23 WORKER: start processing job (0, 0, 21)
03:58:23 WORKER: args: ()
03:58:23 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 82, 'last_n_outputs': 36, 'lr': 0.013659657913790892, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.01840009785726866}, 'budget': 44.44444444444444, 'working_directory': '.'}
03:59:03 DISPATCHER: Starting worker discovery
03:59:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:59:03 DISPATCHER: Finished worker discovery
Exception in thread Thread-427:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:59:48 WORKER: done with job (0, 0, 21), trying to register it.
03:59:48 WORKER: registered result for job (0, 0, 21) with dispatcher
03:59:48 DISPATCHER: job (0, 0, 21) finished
03:59:48 DISPATCHER: register_result: lock acquired
03:59:48 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
03:59:48 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 82, 'last_n_outputs': 36, 'lr': 0.013659657913790892, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.01840009785726866}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 82, 'last_n_outputs': 36, 'lr': 0.013659657913790892, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.01840009785726866}"}}
exception: None

03:59:48 job_callback for (0, 0, 21) started
03:59:48 job_callback for (0, 0, 21) got condition
03:59:48 DISPATCHER: Trying to submit another job.
03:59:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:59:48 done building a new model for budget 44.444444 based on 9/18 split
Best loss for this budget:-0.177421





03:59:48 HBMASTER: Trying to run another job!
03:59:48 job_callback for (0, 0, 21) finished
03:59:48 start sampling a new configuration.
03:59:48 done sampling a new configuration.
03:59:48 HBMASTER: schedule new run for iteration 0
03:59:48 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
03:59:48 HBMASTER: submitting job (0, 0, 22) to dispatcher
03:59:48 DISPATCHER: trying to submit job (0, 0, 22)
03:59:48 DISPATCHER: trying to notify the job_runner thread.
03:59:48 HBMASTER: job (0, 0, 22) submitted to dispatcher
03:59:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:59:48 DISPATCHER: Trying to submit another job.
03:59:48 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776
03:59:48 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
03:59:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:59:48 WORKER: start processing job (0, 0, 22)
03:59:48 WORKER: args: ()
03:59:48 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 96, 'last_n_outputs': 31, 'lr': 0.0013762418968848577, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.05070961837044123}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:00:03 DISPATCHER: Starting worker discovery
04:00:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:00:03 DISPATCHER: Finished worker discovery
Exception in thread Thread-428:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:01:03 DISPATCHER: Starting worker discovery
04:01:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:01:03 DISPATCHER: Finished worker discovery
04:01:11 WORKER: done with job (0, 0, 22), trying to register it.
04:01:11 WORKER: registered result for job (0, 0, 22) with dispatcher
04:01:11 DISPATCHER: job (0, 0, 22) finished
04:01:11 DISPATCHER: register_result: lock acquired
04:01:11 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:01:11 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 96, 'last_n_outputs': 31, 'lr': 0.0013762418968848577, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.05070961837044123}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 96, 'last_n_outputs': 31, 'lr': 0.0013762418968848577, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.05070961837044123}"}}
exception: None

04:01:11 job_callback for (0, 0, 22) started
04:01:11 job_callback for (0, 0, 22) got condition
04:01:11 DISPATCHER: Trying to submit another job.
04:01:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:01:11 done building a new model for budget 44.444444 based on 9/19 split
Best loss for this budget:-0.177421





04:01:11 HBMASTER: Trying to run another job!
04:01:11 job_callback for (0, 0, 22) finished
04:01:11 start sampling a new configuration.
04:01:11 best_vector: [2, 0.022147168936504147, 0.938264408050895, 0.7229445115663061, 0.0052733055955744845, 1, 0.6754184105917813, 0.23577442549453234], 0.024338408599685616, 0.0006550273328591415, 1.594232287108806e-05
04:01:11 done sampling a new configuration.
04:01:11 HBMASTER: schedule new run for iteration 0
04:01:11 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
04:01:11 HBMASTER: submitting job (0, 0, 23) to dispatcher
04:01:11 DISPATCHER: trying to submit job (0, 0, 23)
04:01:11 DISPATCHER: trying to notify the job_runner thread.
04:01:11 HBMASTER: job (0, 0, 23) submitted to dispatcher
04:01:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:01:11 DISPATCHER: Trying to submit another job.
04:01:11 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:01:11 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:01:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:01:11 WORKER: start processing job (0, 0, 23)
04:01:11 WORKER: args: ()
04:01:11 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 21, 'last_n_outputs': 47, 'lr': 0.02791830343396838, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.02026513959890003}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-429:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:02:03 DISPATCHER: Starting worker discovery
04:02:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:02:03 DISPATCHER: Finished worker discovery
04:02:37 WORKER: done with job (0, 0, 23), trying to register it.
04:02:37 WORKER: registered result for job (0, 0, 23) with dispatcher
04:02:37 DISPATCHER: job (0, 0, 23) finished
04:02:37 DISPATCHER: register_result: lock acquired
04:02:37 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:02:37 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 21, 'last_n_outputs': 47, 'lr': 0.02791830343396838, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.02026513959890003}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 21, 'last_n_outputs': 47, 'lr': 0.02791830343396838, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.02026513959890003}"}}
exception: None

04:02:37 job_callback for (0, 0, 23) started
04:02:37 DISPATCHER: Trying to submit another job.
04:02:37 job_callback for (0, 0, 23) got condition
04:02:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:02:37 done building a new model for budget 44.444444 based on 9/20 split
Best loss for this budget:-0.177421





04:02:37 HBMASTER: Trying to run another job!
04:02:37 job_callback for (0, 0, 23) finished
04:02:37 start sampling a new configuration.
04:02:37 done sampling a new configuration.
04:02:37 HBMASTER: schedule new run for iteration 0
04:02:37 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
04:02:37 HBMASTER: submitting job (0, 0, 24) to dispatcher
04:02:37 DISPATCHER: trying to submit job (0, 0, 24)
04:02:37 DISPATCHER: trying to notify the job_runner thread.
04:02:37 HBMASTER: job (0, 0, 24) submitted to dispatcher
04:02:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:02:37 DISPATCHER: Trying to submit another job.
04:02:37 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:02:37 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:02:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:02:37 WORKER: start processing job (0, 0, 24)
04:02:37 WORKER: args: ()
04:02:37 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 20, 'last_n_outputs': 33, 'lr': 0.0185062273759796, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.12216540121925527}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:03:03 DISPATCHER: Starting worker discovery
04:03:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:03:03 DISPATCHER: Finished worker discovery
Exception in thread Thread-430:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:04:00 WORKER: done with job (0, 0, 24), trying to register it.
04:04:00 WORKER: registered result for job (0, 0, 24) with dispatcher
04:04:00 DISPATCHER: job (0, 0, 24) finished
04:04:00 DISPATCHER: register_result: lock acquired
04:04:00 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:04:00 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 20, 'last_n_outputs': 33, 'lr': 0.0185062273759796, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.12216540121925527}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 20, 'last_n_outputs': 33, 'lr': 0.0185062273759796, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.12216540121925527}"}}
exception: None

04:04:00 job_callback for (0, 0, 24) started
04:04:00 DISPATCHER: Trying to submit another job.
04:04:00 job_callback for (0, 0, 24) got condition
04:04:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:04:00 done building a new model for budget 44.444444 based on 9/21 split
Best loss for this budget:-0.177421





04:04:00 HBMASTER: Trying to run another job!
04:04:00 job_callback for (0, 0, 24) finished
04:04:00 start sampling a new configuration.
04:04:00 best_vector: [0, 0.8968456890354057, 0.019089024855551, 0.9983415468168672, 0.39399057899629647, 1, 0.981573195034592, 0.7367383051053007], 0.005730644990809996, 0.05489740866455049, 0.00031459755997195553
04:04:00 done sampling a new configuration.
04:04:00 HBMASTER: schedule new run for iteration 0
04:04:00 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
04:04:00 HBMASTER: submitting job (0, 0, 25) to dispatcher
04:04:00 DISPATCHER: trying to submit job (0, 0, 25)
04:04:00 DISPATCHER: trying to notify the job_runner thread.
04:04:00 HBMASTER: job (0, 0, 25) submitted to dispatcher
04:04:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:04:00 DISPATCHER: Trying to submit another job.
04:04:00 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:04:00 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:04:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:04:00 WORKER: start processing job (0, 0, 25)
04:04:00 WORKER: args: ()
04:04:00 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 92, 'last_n_outputs': 1, 'lr': 0.0992391632129069, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.09089052958401472}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:04:03 DISPATCHER: Starting worker discovery
04:04:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:04:03 DISPATCHER: Finished worker discovery
Exception in thread Thread-431:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:05:03 DISPATCHER: Starting worker discovery
04:05:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:05:03 DISPATCHER: Finished worker discovery
04:05:27 WORKER: done with job (0, 0, 25), trying to register it.
04:05:27 WORKER: registered result for job (0, 0, 25) with dispatcher
04:05:27 DISPATCHER: job (0, 0, 25) finished
04:05:27 DISPATCHER: register_result: lock acquired
04:05:27 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:05:27 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 92, 'last_n_outputs': 1, 'lr': 0.0992391632129069, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.09089052958401472}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 92, 'last_n_outputs': 1, 'lr': 0.0992391632129069, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.09089052958401472}"}}
exception: None

04:05:27 DISPATCHER: Trying to submit another job.
04:05:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:05:27 job_callback for (0, 0, 25) started
04:05:27 job_callback for (0, 0, 25) got condition
04:05:27 done building a new model for budget 44.444444 based on 9/22 split
Best loss for this budget:-0.177421





04:05:27 HBMASTER: Trying to run another job!
04:05:27 job_callback for (0, 0, 25) finished
04:05:27 start sampling a new configuration.
04:05:27 done sampling a new configuration.
04:05:27 HBMASTER: schedule new run for iteration 0
04:05:27 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
04:05:27 HBMASTER: submitting job (0, 0, 26) to dispatcher
04:05:27 DISPATCHER: trying to submit job (0, 0, 26)
04:05:27 DISPATCHER: trying to notify the job_runner thread.
04:05:27 HBMASTER: job (0, 0, 26) submitted to dispatcher
04:05:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:05:27 DISPATCHER: Trying to submit another job.
04:05:27 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:05:27 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:05:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:05:27 WORKER: start processing job (0, 0, 26)
04:05:27 WORKER: args: ()
04:05:27 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 28, 'last_n_outputs': 22, 'lr': 0.0023603007529754555, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.0148894681095683}, 'budget': 44.44444444444444, 'working_directory': '.'}
04:06:03 DISPATCHER: Starting worker discovery
04:06:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:06:03 DISPATCHER: Finished worker discovery
Exception in thread Thread-432:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:06:47 WORKER: done with job (0, 0, 26), trying to register it.
04:06:47 WORKER: registered result for job (0, 0, 26) with dispatcher
04:06:47 DISPATCHER: job (0, 0, 26) finished
04:06:47 DISPATCHER: register_result: lock acquired
04:06:47 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:06:47 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 28, 'last_n_outputs': 22, 'lr': 0.0023603007529754555, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.0148894681095683}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 28, 'last_n_outputs': 22, 'lr': 0.0023603007529754555, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.0148894681095683}"}}
exception: None

04:06:47 job_callback for (0, 0, 26) started
04:06:47 job_callback for (0, 0, 26) got condition
04:06:47 DISPATCHER: Trying to submit another job.
04:06:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:06:47 done building a new model for budget 44.444444 based on 9/22 split
Best loss for this budget:-0.177421





04:06:47 HBMASTER: Trying to run another job!
04:06:47 job_callback for (0, 0, 26) finished
04:06:47 ITERATION: Advancing config (0, 0, 0) to next budget 133.333333
04:06:47 ITERATION: Advancing config (0, 0, 11) to next budget 133.333333
04:06:47 ITERATION: Advancing config (0, 0, 15) to next budget 133.333333
04:06:47 ITERATION: Advancing config (0, 0, 19) to next budget 133.333333
04:06:47 ITERATION: Advancing config (0, 0, 20) to next budget 133.333333
04:06:47 ITERATION: Advancing config (0, 0, 21) to next budget 133.333333
04:06:47 ITERATION: Advancing config (0, 0, 22) to next budget 133.333333
04:06:47 ITERATION: Advancing config (0, 0, 23) to next budget 133.333333
04:06:47 ITERATION: Advancing config (0, 0, 24) to next budget 133.333333
04:06:47 HBMASTER: schedule new run for iteration 0
04:06:47 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
04:06:47 HBMASTER: submitting job (0, 0, 0) to dispatcher
04:06:47 DISPATCHER: trying to submit job (0, 0, 0)
04:06:47 DISPATCHER: trying to notify the job_runner thread.
04:06:47 HBMASTER: job (0, 0, 0) submitted to dispatcher
04:06:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:06:47 DISPATCHER: Trying to submit another job.
04:06:47 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:06:47 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:06:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:06:47 WORKER: start processing job (0, 0, 0)
04:06:47 WORKER: args: ()
04:06:47 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 80, 'last_n_outputs': 23, 'lr': 0.02954494129661249, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.010582977294060058}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:07:03 DISPATCHER: Starting worker discovery
04:07:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:07:03 DISPATCHER: Finished worker discovery
Exception in thread Thread-433:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:08:03 DISPATCHER: Starting worker discovery
04:08:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:08:03 DISPATCHER: Finished worker discovery
04:09:03 DISPATCHER: Starting worker discovery
04:09:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:09:03 DISPATCHER: Finished worker discovery
04:09:39 WORKER: done with job (0, 0, 0), trying to register it.
04:09:39 WORKER: registered result for job (0, 0, 0) with dispatcher
04:09:39 DISPATCHER: job (0, 0, 0) finished
04:09:39 DISPATCHER: register_result: lock acquired
04:09:39 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:09:39 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 80, 'last_n_outputs': 23, 'lr': 0.02954494129661249, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.010582977294060058}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.002060612658974376, 'info': {'data03': 0.002060612658974376, 'config': "{'batch_size': 128, 'hidden_dim': 80, 'last_n_outputs': 23, 'lr': 0.02954494129661249, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.010582977294060058}"}}
exception: None

04:09:39 job_callback for (0, 0, 0) started
04:09:39 job_callback for (0, 0, 0) got condition
04:09:39 DISPATCHER: Trying to submit another job.
04:09:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:09:39 Only 1 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
04:09:39 HBMASTER: Trying to run another job!
04:09:39 job_callback for (0, 0, 0) finished
04:09:39 HBMASTER: schedule new run for iteration 0
04:09:39 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
04:09:39 HBMASTER: submitting job (0, 0, 11) to dispatcher
04:09:39 DISPATCHER: trying to submit job (0, 0, 11)
04:09:39 DISPATCHER: trying to notify the job_runner thread.
04:09:39 HBMASTER: job (0, 0, 11) submitted to dispatcher
04:09:39 DISPATCHER: Trying to submit another job.
04:09:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:09:39 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:09:39 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:09:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:09:39 WORKER: start processing job (0, 0, 11)
04:09:39 WORKER: args: ()
04:09:39 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 75, 'last_n_outputs': 49, 'lr': 0.0077301627241755065, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.010831861867239593}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:10:03 DISPATCHER: Starting worker discovery
04:10:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:10:03 DISPATCHER: Finished worker discovery
Exception in thread Thread-434:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:11:03 DISPATCHER: Starting worker discovery
04:11:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:11:03 DISPATCHER: Finished worker discovery
04:12:03 DISPATCHER: Starting worker discovery
04:12:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:12:03 DISPATCHER: Finished worker discovery
04:12:29 WORKER: done with job (0, 0, 11), trying to register it.
04:12:29 WORKER: registered result for job (0, 0, 11) with dispatcher
04:12:29 DISPATCHER: job (0, 0, 11) finished
04:12:29 DISPATCHER: register_result: lock acquired
04:12:29 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:12:29 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 75, 'last_n_outputs': 49, 'lr': 0.0077301627241755065, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.010831861867239593}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4079201865900278, 'info': {'data03': 0.4079201865900278, 'config': "{'batch_size': 128, 'hidden_dim': 75, 'last_n_outputs': 49, 'lr': 0.0077301627241755065, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.010831861867239593}"}}
exception: None

04:12:29 job_callback for (0, 0, 11) started
04:12:29 job_callback for (0, 0, 11) got condition
04:12:29 DISPATCHER: Trying to submit another job.
04:12:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:12:29 Only 2 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
04:12:29 HBMASTER: Trying to run another job!
04:12:29 job_callback for (0, 0, 11) finished
04:12:29 HBMASTER: schedule new run for iteration 0
04:12:29 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
04:12:29 HBMASTER: submitting job (0, 0, 15) to dispatcher
04:12:29 DISPATCHER: trying to submit job (0, 0, 15)
04:12:29 DISPATCHER: trying to notify the job_runner thread.
04:12:29 HBMASTER: job (0, 0, 15) submitted to dispatcher
04:12:29 DISPATCHER: Trying to submit another job.
04:12:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:12:29 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:12:29 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:12:29 WORKER: start processing job (0, 0, 15)
04:12:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:12:29 WORKER: args: ()
04:12:29 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 48, 'last_n_outputs': 48, 'lr': 0.002016049610580376, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.15170816469886625}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:13:03 DISPATCHER: Starting worker discovery
04:13:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:13:03 DISPATCHER: Finished worker discovery
Exception in thread Thread-435:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:14:03 DISPATCHER: Starting worker discovery
04:14:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:14:03 DISPATCHER: Finished worker discovery
04:15:03 DISPATCHER: Starting worker discovery
04:15:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:15:03 DISPATCHER: Finished worker discovery
04:15:26 WORKER: done with job (0, 0, 15), trying to register it.
04:15:26 WORKER: registered result for job (0, 0, 15) with dispatcher
04:15:26 DISPATCHER: job (0, 0, 15) finished
04:15:26 DISPATCHER: register_result: lock acquired
04:15:26 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:15:26 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 48, 'last_n_outputs': 48, 'lr': 0.002016049610580376, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.15170816469886625}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.15583092265628268, 'info': {'data03': 0.15583092265628268, 'config': "{'batch_size': 16, 'hidden_dim': 48, 'last_n_outputs': 48, 'lr': 0.002016049610580376, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.15170816469886625}"}}
exception: None

04:15:26 job_callback for (0, 0, 15) started
04:15:26 job_callback for (0, 0, 15) got condition
04:15:26 DISPATCHER: Trying to submit another job.
04:15:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:15:26 Only 3 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
04:15:26 HBMASTER: Trying to run another job!
04:15:26 job_callback for (0, 0, 15) finished
04:15:26 HBMASTER: schedule new run for iteration 0
04:15:26 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
04:15:26 HBMASTER: submitting job (0, 0, 19) to dispatcher
04:15:26 DISPATCHER: trying to submit job (0, 0, 19)
04:15:26 DISPATCHER: trying to notify the job_runner thread.
04:15:26 HBMASTER: job (0, 0, 19) submitted to dispatcher
04:15:26 DISPATCHER: Trying to submit another job.
04:15:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:15:26 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:15:26 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:15:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:15:26 WORKER: start processing job (0, 0, 19)
04:15:26 WORKER: args: ()
04:15:26 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 100, 'last_n_outputs': 26, 'lr': 0.057946329955480234, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.1411720176895671}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:16:03 DISPATCHER: Starting worker discovery
04:16:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:16:03 DISPATCHER: Finished worker discovery
Exception in thread Thread-436:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:17:03 DISPATCHER: Starting worker discovery
04:17:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:17:03 DISPATCHER: Finished worker discovery
04:18:03 DISPATCHER: Starting worker discovery
04:18:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:18:03 DISPATCHER: Finished worker discovery
04:18:18 WORKER: done with job (0, 0, 19), trying to register it.
04:18:18 WORKER: registered result for job (0, 0, 19) with dispatcher
04:18:18 DISPATCHER: job (0, 0, 19) finished
04:18:18 DISPATCHER: register_result: lock acquired
04:18:18 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:18:18 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 100, 'last_n_outputs': 26, 'lr': 0.057946329955480234, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.1411720176895671}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 100, 'last_n_outputs': 26, 'lr': 0.057946329955480234, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.1411720176895671}"}}
exception: None

04:18:18 job_callback for (0, 0, 19) started
04:18:18 job_callback for (0, 0, 19) got condition
04:18:18 DISPATCHER: Trying to submit another job.
04:18:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:18:18 Only 4 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
04:18:18 HBMASTER: Trying to run another job!
04:18:18 job_callback for (0, 0, 19) finished
04:18:18 HBMASTER: schedule new run for iteration 0
04:18:18 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
04:18:18 HBMASTER: submitting job (0, 0, 20) to dispatcher
04:18:18 DISPATCHER: trying to submit job (0, 0, 20)
04:18:18 DISPATCHER: trying to notify the job_runner thread.
04:18:18 HBMASTER: job (0, 0, 20) submitted to dispatcher
04:18:18 DISPATCHER: Trying to submit another job.
04:18:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:18:18 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:18:18 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:18:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:18:18 WORKER: start processing job (0, 0, 20)
04:18:18 WORKER: args: ()
04:18:18 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 94, 'last_n_outputs': 46, 'lr': 0.0023471330926011632, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.010467852258797405}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:19:03 DISPATCHER: Starting worker discovery
04:19:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:19:03 DISPATCHER: Finished worker discovery
Exception in thread Thread-437:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:20:03 DISPATCHER: Starting worker discovery
04:20:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:20:03 DISPATCHER: Finished worker discovery
04:21:03 DISPATCHER: Starting worker discovery
04:21:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:21:03 DISPATCHER: Finished worker discovery
04:21:10 WORKER: done with job (0, 0, 20), trying to register it.
04:21:10 WORKER: registered result for job (0, 0, 20) with dispatcher
04:21:10 DISPATCHER: job (0, 0, 20) finished
04:21:10 DISPATCHER: register_result: lock acquired
04:21:10 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:21:10 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 94, 'last_n_outputs': 46, 'lr': 0.0023471330926011632, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.010467852258797405}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 94, 'last_n_outputs': 46, 'lr': 0.0023471330926011632, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.010467852258797405}"}}
exception: None

04:21:10 job_callback for (0, 0, 20) started
04:21:10 DISPATCHER: Trying to submit another job.
04:21:10 job_callback for (0, 0, 20) got condition
04:21:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:21:10 Only 5 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
04:21:10 HBMASTER: Trying to run another job!
04:21:10 job_callback for (0, 0, 20) finished
04:21:10 HBMASTER: schedule new run for iteration 0
04:21:10 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
04:21:10 HBMASTER: submitting job (0, 0, 21) to dispatcher
04:21:10 DISPATCHER: trying to submit job (0, 0, 21)
04:21:10 DISPATCHER: trying to notify the job_runner thread.
04:21:10 HBMASTER: job (0, 0, 21) submitted to dispatcher
04:21:10 DISPATCHER: Trying to submit another job.
04:21:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:21:10 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:21:10 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:21:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:21:10 WORKER: start processing job (0, 0, 21)
04:21:10 WORKER: args: ()
04:21:10 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 82, 'last_n_outputs': 36, 'lr': 0.013659657913790892, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.01840009785726866}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-438:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:22:03 DISPATCHER: Starting worker discovery
04:22:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:22:03 DISPATCHER: Finished worker discovery
04:23:03 DISPATCHER: Starting worker discovery
04:23:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:23:03 DISPATCHER: Finished worker discovery
04:24:03 DISPATCHER: Starting worker discovery
04:24:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:24:03 DISPATCHER: Finished worker discovery
04:24:06 WORKER: done with job (0, 0, 21), trying to register it.
04:24:06 WORKER: registered result for job (0, 0, 21) with dispatcher
04:24:06 DISPATCHER: job (0, 0, 21) finished
04:24:06 DISPATCHER: register_result: lock acquired
04:24:06 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:24:06 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 82, 'last_n_outputs': 36, 'lr': 0.013659657913790892, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.01840009785726866}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 82, 'last_n_outputs': 36, 'lr': 0.013659657913790892, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.01840009785726866}"}}
exception: None

04:24:06 job_callback for (0, 0, 21) started
04:24:06 job_callback for (0, 0, 21) got condition
04:24:06 DISPATCHER: Trying to submit another job.
04:24:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:24:06 Only 6 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
04:24:06 HBMASTER: Trying to run another job!
04:24:06 job_callback for (0, 0, 21) finished
04:24:06 HBMASTER: schedule new run for iteration 0
04:24:06 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
04:24:06 HBMASTER: submitting job (0, 0, 22) to dispatcher
04:24:06 DISPATCHER: trying to submit job (0, 0, 22)
04:24:06 DISPATCHER: trying to notify the job_runner thread.
04:24:06 HBMASTER: job (0, 0, 22) submitted to dispatcher
04:24:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:24:06 DISPATCHER: Trying to submit another job.
04:24:06 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:24:06 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:24:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:24:06 WORKER: start processing job (0, 0, 22)
04:24:06 WORKER: args: ()
04:24:06 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 96, 'last_n_outputs': 31, 'lr': 0.0013762418968848577, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.05070961837044123}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-439:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:25:03 DISPATCHER: Starting worker discovery
04:25:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:25:03 DISPATCHER: Finished worker discovery
04:26:03 DISPATCHER: Starting worker discovery
04:26:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:26:03 DISPATCHER: Finished worker discovery
04:26:57 WORKER: done with job (0, 0, 22), trying to register it.
04:26:57 WORKER: registered result for job (0, 0, 22) with dispatcher
04:26:57 DISPATCHER: job (0, 0, 22) finished
04:26:57 DISPATCHER: register_result: lock acquired
04:26:57 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:26:57 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 96, 'last_n_outputs': 31, 'lr': 0.0013762418968848577, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.05070961837044123}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 96, 'last_n_outputs': 31, 'lr': 0.0013762418968848577, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.05070961837044123}"}}
exception: None

04:26:57 job_callback for (0, 0, 22) started
04:26:57 DISPATCHER: Trying to submit another job.
04:26:57 job_callback for (0, 0, 22) got condition
04:26:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:26:57 Only 7 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
04:26:57 HBMASTER: Trying to run another job!
04:26:57 job_callback for (0, 0, 22) finished
04:26:57 HBMASTER: schedule new run for iteration 0
04:26:57 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
04:26:57 HBMASTER: submitting job (0, 0, 23) to dispatcher
04:26:57 DISPATCHER: trying to submit job (0, 0, 23)
04:26:57 DISPATCHER: trying to notify the job_runner thread.
04:26:57 HBMASTER: job (0, 0, 23) submitted to dispatcher
04:26:57 DISPATCHER: Trying to submit another job.
04:26:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:26:57 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:26:57 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:26:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:26:57 WORKER: start processing job (0, 0, 23)
04:26:57 WORKER: args: ()
04:26:57 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 21, 'last_n_outputs': 47, 'lr': 0.02791830343396838, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.02026513959890003}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:27:03 DISPATCHER: Starting worker discovery
04:27:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:27:03 DISPATCHER: Finished worker discovery
Exception in thread Thread-440:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:28:03 DISPATCHER: Starting worker discovery
04:28:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:28:03 DISPATCHER: Finished worker discovery
04:29:03 DISPATCHER: Starting worker discovery
04:29:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:29:03 DISPATCHER: Finished worker discovery
04:29:56 WORKER: done with job (0, 0, 23), trying to register it.
04:29:56 WORKER: registered result for job (0, 0, 23) with dispatcher
04:29:56 DISPATCHER: job (0, 0, 23) finished
04:29:56 DISPATCHER: register_result: lock acquired
04:29:56 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:29:56 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 21, 'last_n_outputs': 47, 'lr': 0.02791830343396838, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.02026513959890003}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 21, 'last_n_outputs': 47, 'lr': 0.02791830343396838, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.02026513959890003}"}}
exception: None

04:29:56 job_callback for (0, 0, 23) started
04:29:56 job_callback for (0, 0, 23) got condition
04:29:56 DISPATCHER: Trying to submit another job.
04:29:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:29:56 Only 8 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
04:29:56 HBMASTER: Trying to run another job!
04:29:56 job_callback for (0, 0, 23) finished
04:29:56 HBMASTER: schedule new run for iteration 0
04:29:56 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
04:29:56 HBMASTER: submitting job (0, 0, 24) to dispatcher
04:29:56 DISPATCHER: trying to submit job (0, 0, 24)
04:29:56 DISPATCHER: trying to notify the job_runner thread.
04:29:56 HBMASTER: job (0, 0, 24) submitted to dispatcher
04:29:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:29:56 DISPATCHER: Trying to submit another job.
04:29:56 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:29:56 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:29:56 WORKER: start processing job (0, 0, 24)
04:29:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:29:56 WORKER: args: ()
04:29:56 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 20, 'last_n_outputs': 33, 'lr': 0.0185062273759796, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.12216540121925527}, 'budget': 133.33333333333331, 'working_directory': '.'}
04:30:03 DISPATCHER: Starting worker discovery
04:30:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:30:03 DISPATCHER: Finished worker discovery
Exception in thread Thread-441:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:31:03 DISPATCHER: Starting worker discovery
04:31:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:31:03 DISPATCHER: Finished worker discovery
04:32:03 DISPATCHER: Starting worker discovery
04:32:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:32:03 DISPATCHER: Finished worker discovery
04:32:57 WORKER: done with job (0, 0, 24), trying to register it.
04:32:57 WORKER: registered result for job (0, 0, 24) with dispatcher
04:32:57 DISPATCHER: job (0, 0, 24) finished
04:32:57 DISPATCHER: register_result: lock acquired
04:32:57 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:32:57 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 20, 'last_n_outputs': 33, 'lr': 0.0185062273759796, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.12216540121925527}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 20, 'last_n_outputs': 33, 'lr': 0.0185062273759796, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.12216540121925527}"}}
exception: None

04:32:57 job_callback for (0, 0, 24) started
04:32:57 DISPATCHER: Trying to submit another job.
04:32:57 job_callback for (0, 0, 24) got condition
04:32:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:32:57 HBMASTER: Trying to run another job!
04:32:57 job_callback for (0, 0, 24) finished
04:32:57 ITERATION: Advancing config (0, 0, 0) to next budget 400.000000
04:32:57 ITERATION: Advancing config (0, 0, 11) to next budget 400.000000
04:32:57 ITERATION: Advancing config (0, 0, 15) to next budget 400.000000
04:32:57 HBMASTER: schedule new run for iteration 0
04:32:57 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
04:32:57 HBMASTER: submitting job (0, 0, 0) to dispatcher
04:32:57 DISPATCHER: trying to submit job (0, 0, 0)
04:32:57 DISPATCHER: trying to notify the job_runner thread.
04:32:57 HBMASTER: job (0, 0, 0) submitted to dispatcher
04:32:57 DISPATCHER: Trying to submit another job.
04:32:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:32:57 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:32:57 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:32:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:32:57 WORKER: start processing job (0, 0, 0)
04:32:57 WORKER: args: ()
04:32:57 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 80, 'last_n_outputs': 23, 'lr': 0.02954494129661249, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.010582977294060058}, 'budget': 400.0, 'working_directory': '.'}
04:33:03 DISPATCHER: Starting worker discovery
04:33:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:33:03 DISPATCHER: Finished worker discovery
Exception in thread Thread-442:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:34:03 DISPATCHER: Starting worker discovery
04:34:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:34:03 DISPATCHER: Finished worker discovery
04:35:03 DISPATCHER: Starting worker discovery
04:35:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:35:03 DISPATCHER: Finished worker discovery
04:36:03 DISPATCHER: Starting worker discovery
04:36:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:36:03 DISPATCHER: Finished worker discovery
04:37:03 DISPATCHER: Starting worker discovery
04:37:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:37:03 DISPATCHER: Finished worker discovery
04:38:03 DISPATCHER: Starting worker discovery
04:38:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:38:03 DISPATCHER: Finished worker discovery
04:39:03 DISPATCHER: Starting worker discovery
04:39:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:39:03 DISPATCHER: Finished worker discovery
04:40:03 DISPATCHER: Starting worker discovery
04:40:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:40:03 DISPATCHER: Finished worker discovery
04:40:15 WORKER: done with job (0, 0, 0), trying to register it.
04:40:15 WORKER: registered result for job (0, 0, 0) with dispatcher
04:40:15 DISPATCHER: job (0, 0, 0) finished
04:40:15 DISPATCHER: register_result: lock acquired
04:40:15 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:40:15 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 80, 'last_n_outputs': 23, 'lr': 0.02954494129661249, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.010582977294060058}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.16471830583856628, 'info': {'data03': 0.16471830583856628, 'config': "{'batch_size': 128, 'hidden_dim': 80, 'last_n_outputs': 23, 'lr': 0.02954494129661249, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.010582977294060058}"}}
exception: None

04:40:15 job_callback for (0, 0, 0) started
04:40:15 DISPATCHER: Trying to submit another job.
04:40:15 job_callback for (0, 0, 0) got condition
04:40:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:40:15 Only 1 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
04:40:15 HBMASTER: Trying to run another job!
04:40:15 job_callback for (0, 0, 0) finished
04:40:15 HBMASTER: schedule new run for iteration 0
04:40:15 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
04:40:15 HBMASTER: submitting job (0, 0, 11) to dispatcher
04:40:15 DISPATCHER: trying to submit job (0, 0, 11)
04:40:15 DISPATCHER: trying to notify the job_runner thread.
04:40:15 HBMASTER: job (0, 0, 11) submitted to dispatcher
04:40:15 DISPATCHER: Trying to submit another job.
04:40:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:40:15 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:40:15 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:40:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:40:15 WORKER: start processing job (0, 0, 11)
04:40:15 WORKER: args: ()
04:40:15 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 75, 'last_n_outputs': 49, 'lr': 0.0077301627241755065, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.010831861867239593}, 'budget': 400.0, 'working_directory': '.'}
04:41:03 DISPATCHER: Starting worker discovery
04:41:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:41:03 DISPATCHER: Finished worker discovery
Exception in thread Thread-443:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:42:03 DISPATCHER: Starting worker discovery
04:42:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:42:03 DISPATCHER: Finished worker discovery
04:43:03 DISPATCHER: Starting worker discovery
04:43:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:43:03 DISPATCHER: Finished worker discovery
04:44:03 DISPATCHER: Starting worker discovery
04:44:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:44:03 DISPATCHER: Finished worker discovery
04:45:03 DISPATCHER: Starting worker discovery
04:45:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:45:03 DISPATCHER: Finished worker discovery
04:46:03 DISPATCHER: Starting worker discovery
04:46:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:46:03 DISPATCHER: Finished worker discovery
04:47:03 DISPATCHER: Starting worker discovery
04:47:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:47:03 DISPATCHER: Finished worker discovery
04:47:39 WORKER: done with job (0, 0, 11), trying to register it.
04:47:39 WORKER: registered result for job (0, 0, 11) with dispatcher
04:47:39 DISPATCHER: job (0, 0, 11) finished
04:47:39 DISPATCHER: register_result: lock acquired
04:47:39 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:47:39 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 75, 'last_n_outputs': 49, 'lr': 0.0077301627241755065, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.010831861867239593}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.1672757629738822, 'info': {'data03': 0.1672757629738822, 'config': "{'batch_size': 128, 'hidden_dim': 75, 'last_n_outputs': 49, 'lr': 0.0077301627241755065, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.010831861867239593}"}}
exception: None

04:47:39 job_callback for (0, 0, 11) started
04:47:39 DISPATCHER: Trying to submit another job.
04:47:39 job_callback for (0, 0, 11) got condition
04:47:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:47:39 Only 2 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
04:47:39 HBMASTER: Trying to run another job!
04:47:39 job_callback for (0, 0, 11) finished
04:47:39 HBMASTER: schedule new run for iteration 0
04:47:39 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
04:47:39 HBMASTER: submitting job (0, 0, 15) to dispatcher
04:47:39 DISPATCHER: trying to submit job (0, 0, 15)
04:47:39 DISPATCHER: trying to notify the job_runner thread.
04:47:39 HBMASTER: job (0, 0, 15) submitted to dispatcher
04:47:39 DISPATCHER: Trying to submit another job.
04:47:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:47:39 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:47:39 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:47:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:47:39 WORKER: start processing job (0, 0, 15)
04:47:39 WORKER: args: ()
04:47:39 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 48, 'last_n_outputs': 48, 'lr': 0.002016049610580376, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.15170816469886625}, 'budget': 400.0, 'working_directory': '.'}
04:48:03 DISPATCHER: Starting worker discovery
04:48:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:48:03 DISPATCHER: Finished worker discovery
Exception in thread Thread-444:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:49:03 DISPATCHER: Starting worker discovery
04:49:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:49:04 DISPATCHER: Finished worker discovery
04:50:04 DISPATCHER: Starting worker discovery
04:50:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:50:04 DISPATCHER: Finished worker discovery
04:51:04 DISPATCHER: Starting worker discovery
04:51:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:51:04 DISPATCHER: Finished worker discovery
04:52:04 DISPATCHER: Starting worker discovery
04:52:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:52:04 DISPATCHER: Finished worker discovery
04:53:04 DISPATCHER: Starting worker discovery
04:53:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:53:04 DISPATCHER: Finished worker discovery
04:54:04 DISPATCHER: Starting worker discovery
04:54:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:54:04 DISPATCHER: Finished worker discovery
04:55:04 DISPATCHER: Starting worker discovery
04:55:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:55:04 DISPATCHER: Finished worker discovery
04:55:05 WORKER: done with job (0, 0, 15), trying to register it.
04:55:05 WORKER: registered result for job (0, 0, 15) with dispatcher
04:55:05 DISPATCHER: job (0, 0, 15) finished
04:55:05 DISPATCHER: register_result: lock acquired
04:55:05 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:55:05 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 48, 'last_n_outputs': 48, 'lr': 0.002016049610580376, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.15170816469886625}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.18349050025725608, 'info': {'data03': 0.18349050025725608, 'config': "{'batch_size': 16, 'hidden_dim': 48, 'last_n_outputs': 48, 'lr': 0.002016049610580376, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.15170816469886625}"}}
exception: None

04:55:05 job_callback for (0, 0, 15) started
04:55:05 job_callback for (0, 0, 15) got condition
04:55:05 DISPATCHER: Trying to submit another job.
04:55:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:55:05 Only 3 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
04:55:05 HBMASTER: Trying to run another job!
04:55:05 job_callback for (0, 0, 15) finished
04:55:05 ITERATION: Advancing config (0, 0, 15) to next budget 1200.000000
04:55:05 HBMASTER: schedule new run for iteration 0
04:55:05 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
04:55:05 HBMASTER: submitting job (0, 0, 15) to dispatcher
04:55:05 DISPATCHER: trying to submit job (0, 0, 15)
04:55:05 DISPATCHER: trying to notify the job_runner thread.
04:55:05 HBMASTER: job (0, 0, 15) submitted to dispatcher
04:55:05 DISPATCHER: Trying to submit another job.
04:55:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:55:05 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:55:05 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:55:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:55:05 WORKER: start processing job (0, 0, 15)
04:55:05 WORKER: args: ()
04:55:05 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 48, 'last_n_outputs': 48, 'lr': 0.002016049610580376, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.15170816469886625}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-445:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:56:04 DISPATCHER: Starting worker discovery
04:56:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:56:04 DISPATCHER: Finished worker discovery
04:57:04 DISPATCHER: Starting worker discovery
04:57:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:57:04 DISPATCHER: Finished worker discovery
04:58:04 DISPATCHER: Starting worker discovery
04:58:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:58:04 DISPATCHER: Finished worker discovery
04:59:04 DISPATCHER: Starting worker discovery
04:59:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:59:04 DISPATCHER: Finished worker discovery
05:00:04 DISPATCHER: Starting worker discovery
05:00:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:00:04 DISPATCHER: Finished worker discovery
05:01:04 DISPATCHER: Starting worker discovery
05:01:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:01:04 DISPATCHER: Finished worker discovery
05:02:04 DISPATCHER: Starting worker discovery
05:02:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:02:04 DISPATCHER: Finished worker discovery
05:03:04 DISPATCHER: Starting worker discovery
05:03:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:03:04 DISPATCHER: Finished worker discovery
05:04:04 DISPATCHER: Starting worker discovery
05:04:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:04:04 DISPATCHER: Finished worker discovery
05:05:04 DISPATCHER: Starting worker discovery
05:05:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:05:04 DISPATCHER: Finished worker discovery
05:06:04 DISPATCHER: Starting worker discovery
05:06:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:06:04 DISPATCHER: Finished worker discovery
05:07:04 DISPATCHER: Starting worker discovery
05:07:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:07:04 DISPATCHER: Finished worker discovery
05:08:04 DISPATCHER: Starting worker discovery
05:08:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:08:04 DISPATCHER: Finished worker discovery
05:09:04 DISPATCHER: Starting worker discovery
05:09:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:09:04 DISPATCHER: Finished worker discovery
05:10:04 DISPATCHER: Starting worker discovery
05:10:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:10:04 DISPATCHER: Finished worker discovery
05:11:04 DISPATCHER: Starting worker discovery
05:11:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:11:04 DISPATCHER: Finished worker discovery
05:12:04 DISPATCHER: Starting worker discovery
05:12:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:12:04 DISPATCHER: Finished worker discovery
05:13:04 DISPATCHER: Starting worker discovery
05:13:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:13:04 DISPATCHER: Finished worker discovery
05:14:04 DISPATCHER: Starting worker discovery
05:14:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:14:04 DISPATCHER: Finished worker discovery
05:15:04 DISPATCHER: Starting worker discovery
05:15:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:15:04 DISPATCHER: Finished worker discovery
05:15:52 WORKER: done with job (0, 0, 15), trying to register it.
05:15:52 WORKER: registered result for job (0, 0, 15) with dispatcher
05:15:52 DISPATCHER: job (0, 0, 15) finished
05:15:52 DISPATCHER: register_result: lock acquired
05:15:52 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:15:52 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 48, 'last_n_outputs': 48, 'lr': 0.002016049610580376, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.15170816469886625}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.062088847683474876, 'info': {'data03': 0.062088847683474876, 'config': "{'batch_size': 16, 'hidden_dim': 48, 'last_n_outputs': 48, 'lr': 0.002016049610580376, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.15170816469886625}"}}
exception: None

05:15:52 job_callback for (0, 0, 15) started
05:15:52 job_callback for (0, 0, 15) got condition
05:15:52 DISPATCHER: Trying to submit another job.
05:15:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:15:52 Only 1 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
05:15:52 HBMASTER: Trying to run another job!
05:15:52 job_callback for (0, 0, 15) finished
05:15:52 start sampling a new configuration.
05:15:52 done sampling a new configuration.
05:15:52 HBMASTER: schedule new run for iteration 1
05:15:52 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
05:15:52 HBMASTER: submitting job (1, 0, 0) to dispatcher
05:15:52 DISPATCHER: trying to submit job (1, 0, 0)
05:15:52 DISPATCHER: trying to notify the job_runner thread.
05:15:52 HBMASTER: job (1, 0, 0) submitted to dispatcher
05:15:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:15:52 DISPATCHER: Trying to submit another job.
05:15:52 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:15:52 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:15:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:15:52 WORKER: start processing job (1, 0, 0)
05:15:52 WORKER: args: ()
05:15:52 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 84, 'last_n_outputs': 21, 'lr': 0.002991968261052859, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.01498046674899398}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:16:04 DISPATCHER: Starting worker discovery
05:16:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:16:04 DISPATCHER: Finished worker discovery
05:17:04 DISPATCHER: Starting worker discovery
05:17:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:17:04 DISPATCHER: Finished worker discovery
Exception in thread Thread-446:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:18:04 DISPATCHER: Starting worker discovery
05:18:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:18:04 DISPATCHER: Finished worker discovery
05:18:56 WORKER: done with job (1, 0, 0), trying to register it.
05:18:56 WORKER: registered result for job (1, 0, 0) with dispatcher
05:18:56 DISPATCHER: job (1, 0, 0) finished
05:18:56 DISPATCHER: register_result: lock acquired
05:18:56 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:18:56 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 84, 'last_n_outputs': 21, 'lr': 0.002991968261052859, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.01498046674899398}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 84, 'last_n_outputs': 21, 'lr': 0.002991968261052859, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.01498046674899398}"}}
exception: None

05:18:56 job_callback for (1, 0, 0) started
05:18:56 job_callback for (1, 0, 0) got condition
05:18:56 DISPATCHER: Trying to submit another job.
05:18:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:18:56 HBMASTER: Trying to run another job!
05:18:56 job_callback for (1, 0, 0) finished
05:18:56 start sampling a new configuration.
05:18:56 best_vector: [1, 0.009159698197773125, 0.873419520912165, 0.9595746744514527, 0.21157651326258653, 1, 0.8101160767865797, 0.7756368387183744], 0.01177160198143368, 0.03562027132115088, 0.000419307656463265
05:18:56 done sampling a new configuration.
05:18:56 HBMASTER: schedule new run for iteration 1
05:18:56 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
05:18:56 HBMASTER: submitting job (1, 0, 1) to dispatcher
05:18:56 DISPATCHER: trying to submit job (1, 0, 1)
05:18:56 DISPATCHER: trying to notify the job_runner thread.
05:18:56 HBMASTER: job (1, 0, 1) submitted to dispatcher
05:18:56 DISPATCHER: Trying to submit another job.
05:18:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:18:56 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:18:56 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:18:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:18:56 WORKER: start processing job (1, 0, 1)
05:18:56 WORKER: args: ()
05:18:56 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 20, 'last_n_outputs': 44, 'lr': 0.0830136192772219, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.10212375920103307}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:19:04 DISPATCHER: Starting worker discovery
05:19:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:19:04 DISPATCHER: Finished worker discovery
05:20:04 DISPATCHER: Starting worker discovery
05:20:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:20:04 DISPATCHER: Finished worker discovery
Exception in thread Thread-447:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:21:04 DISPATCHER: Starting worker discovery
05:21:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:21:04 DISPATCHER: Finished worker discovery
05:22:01 WORKER: done with job (1, 0, 1), trying to register it.
05:22:01 WORKER: registered result for job (1, 0, 1) with dispatcher
05:22:01 DISPATCHER: job (1, 0, 1) finished
05:22:01 DISPATCHER: register_result: lock acquired
05:22:01 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:22:01 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 20, 'last_n_outputs': 44, 'lr': 0.0830136192772219, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.10212375920103307}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 20, 'last_n_outputs': 44, 'lr': 0.0830136192772219, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.10212375920103307}"}}
exception: None

05:22:01 job_callback for (1, 0, 1) started
05:22:01 DISPATCHER: Trying to submit another job.
05:22:01 job_callback for (1, 0, 1) got condition
05:22:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:22:01 HBMASTER: Trying to run another job!
05:22:01 job_callback for (1, 0, 1) finished
05:22:01 start sampling a new configuration.
05:22:01 best_vector: [3, 0.04652644625838065, 0.578246058065367, 0.863498208108438, 0.13170780384674224, 0, 0.2940870818217276, 0.5870884795171191], 0.012925822504882901, 0.09406428483490135, 0.0012158582498246833
05:22:01 done sampling a new configuration.
05:22:01 HBMASTER: schedule new run for iteration 1
05:22:01 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
05:22:01 HBMASTER: submitting job (1, 0, 2) to dispatcher
05:22:01 DISPATCHER: trying to submit job (1, 0, 2)
05:22:01 DISPATCHER: trying to notify the job_runner thread.
05:22:01 HBMASTER: job (1, 0, 2) submitted to dispatcher
05:22:01 DISPATCHER: Trying to submit another job.
05:22:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:22:01 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:22:01 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:22:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:22:01 WORKER: start processing job (1, 0, 2)
05:22:01 WORKER: args: ()
05:22:01 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 23, 'last_n_outputs': 29, 'lr': 0.05333304944445702, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.058052338903172455}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:22:04 DISPATCHER: Starting worker discovery
05:22:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:22:04 DISPATCHER: Finished worker discovery
Exception in thread Thread-448:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:23:04 DISPATCHER: Starting worker discovery
05:23:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:23:04 DISPATCHER: Finished worker discovery
05:24:04 DISPATCHER: Starting worker discovery
05:24:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:24:04 DISPATCHER: Finished worker discovery
05:25:04 DISPATCHER: Starting worker discovery
05:25:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:25:04 DISPATCHER: Finished worker discovery
05:25:04 WORKER: done with job (1, 0, 2), trying to register it.
05:25:04 WORKER: registered result for job (1, 0, 2) with dispatcher
05:25:04 DISPATCHER: job (1, 0, 2) finished
05:25:04 DISPATCHER: register_result: lock acquired
05:25:04 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:25:04 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 23, 'last_n_outputs': 29, 'lr': 0.05333304944445702, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.058052338903172455}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 23, 'last_n_outputs': 29, 'lr': 0.05333304944445702, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.058052338903172455}"}}
exception: None

05:25:04 job_callback for (1, 0, 2) started
05:25:04 DISPATCHER: Trying to submit another job.
05:25:04 job_callback for (1, 0, 2) got condition
05:25:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:25:04 HBMASTER: Trying to run another job!
05:25:04 job_callback for (1, 0, 2) finished
05:25:04 start sampling a new configuration.
05:25:04 best_vector: [0, 0.2562899378065672, 0.443535208208626, 0.5409976974300978, 0.21866215503075542, 1, 0.7245711747257386, 0.05428434552054773], 0.07104421093194087, 0.04398778482134161, 0.00312507746327622
05:25:04 done sampling a new configuration.
05:25:04 HBMASTER: schedule new run for iteration 1
05:25:04 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
05:25:04 HBMASTER: submitting job (1, 0, 3) to dispatcher
05:25:04 DISPATCHER: trying to submit job (1, 0, 3)
05:25:04 DISPATCHER: trying to notify the job_runner thread.
05:25:04 HBMASTER: job (1, 0, 3) submitted to dispatcher
05:25:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:25:04 DISPATCHER: Trying to submit another job.
05:25:04 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:25:04 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:25:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:25:04 WORKER: start processing job (1, 0, 3)
05:25:04 WORKER: args: ()
05:25:04 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 40, 'last_n_outputs': 23, 'lr': 0.012078010278473973, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.011765911077337248}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:26:04 DISPATCHER: Starting worker discovery
05:26:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:26:04 DISPATCHER: Finished worker discovery
Exception in thread Thread-449:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:27:04 DISPATCHER: Starting worker discovery
05:27:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:27:04 DISPATCHER: Finished worker discovery
05:28:04 DISPATCHER: Starting worker discovery
05:28:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:28:04 DISPATCHER: Finished worker discovery
05:28:08 WORKER: done with job (1, 0, 3), trying to register it.
05:28:08 WORKER: registered result for job (1, 0, 3) with dispatcher
05:28:08 DISPATCHER: job (1, 0, 3) finished
05:28:08 DISPATCHER: register_result: lock acquired
05:28:08 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:28:08 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 40, 'last_n_outputs': 23, 'lr': 0.012078010278473973, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.011765911077337248}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 40, 'last_n_outputs': 23, 'lr': 0.012078010278473973, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.011765911077337248}"}}
exception: None

05:28:08 job_callback for (1, 0, 3) started
05:28:08 DISPATCHER: Trying to submit another job.
05:28:08 job_callback for (1, 0, 3) got condition
05:28:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:28:08 HBMASTER: Trying to run another job!
05:28:08 job_callback for (1, 0, 3) finished
05:28:08 start sampling a new configuration.
05:28:08 best_vector: [2, 0.6875505821098014, 0.8796769503667998, 0.05348615889357233, 0.11649126951707389, 0, 0.8781212797287743, 0.30194212798197795], 0.027360745167586457, 0.09501493568829911, 0.002599679442482168
05:28:08 done sampling a new configuration.
05:28:08 HBMASTER: schedule new run for iteration 1
05:28:08 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
05:28:08 HBMASTER: submitting job (1, 0, 4) to dispatcher
05:28:08 DISPATCHER: trying to submit job (1, 0, 4)
05:28:08 DISPATCHER: trying to notify the job_runner thread.
05:28:08 HBMASTER: job (1, 0, 4) submitted to dispatcher
05:28:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:28:08 DISPATCHER: Trying to submit another job.
05:28:08 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:28:08 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:28:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:28:08 WORKER: start processing job (1, 0, 4)
05:28:08 WORKER: args: ()
05:28:08 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 75, 'last_n_outputs': 44, 'lr': 0.001279299758159678, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.024707896046289177}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:29:04 DISPATCHER: Starting worker discovery
05:29:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:29:04 DISPATCHER: Finished worker discovery
Exception in thread Thread-450:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:30:04 DISPATCHER: Starting worker discovery
05:30:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:30:04 DISPATCHER: Finished worker discovery
05:31:02 WORKER: done with job (1, 0, 4), trying to register it.
05:31:02 WORKER: registered result for job (1, 0, 4) with dispatcher
05:31:02 DISPATCHER: job (1, 0, 4) finished
05:31:02 DISPATCHER: register_result: lock acquired
05:31:02 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:31:02 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 75, 'last_n_outputs': 44, 'lr': 0.001279299758159678, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.024707896046289177}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2719253826527773, 'info': {'data03': 0.2719253826527773, 'config': "{'batch_size': 64, 'hidden_dim': 75, 'last_n_outputs': 44, 'lr': 0.001279299758159678, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.024707896046289177}"}}
exception: None

05:31:02 job_callback for (1, 0, 4) started
05:31:02 DISPATCHER: Trying to submit another job.
05:31:02 job_callback for (1, 0, 4) got condition
05:31:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:31:02 HBMASTER: Trying to run another job!
05:31:02 job_callback for (1, 0, 4) finished
05:31:02 start sampling a new configuration.
05:31:02 best_vector: [3, 0.12251186491897498, 0.9616029140030221, 0.21055378391464105, 0.05030830612761857, 0, 0.7504296800606536, 0.24742170103391048], 0.008022098724986215, 0.04864813391145448, 0.0003902601330240376
05:31:02 done sampling a new configuration.
05:31:02 HBMASTER: schedule new run for iteration 1
05:31:02 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
05:31:02 HBMASTER: submitting job (1, 0, 5) to dispatcher
05:31:02 DISPATCHER: trying to submit job (1, 0, 5)
05:31:02 DISPATCHER: trying to notify the job_runner thread.
05:31:02 HBMASTER: job (1, 0, 5) submitted to dispatcher
05:31:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:31:02 DISPATCHER: Trying to submit another job.
05:31:02 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:31:02 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:31:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:31:02 WORKER: start processing job (1, 0, 5)
05:31:02 WORKER: args: ()
05:31:02 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 29, 'last_n_outputs': 49, 'lr': 0.0026369844440124763, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.02098471400102281}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:31:04 DISPATCHER: Starting worker discovery
05:31:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:31:04 DISPATCHER: Finished worker discovery
Exception in thread Thread-451:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:32:04 DISPATCHER: Starting worker discovery
05:32:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:32:04 DISPATCHER: Finished worker discovery
05:33:04 DISPATCHER: Starting worker discovery
05:33:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:33:04 DISPATCHER: Finished worker discovery
05:34:01 WORKER: done with job (1, 0, 5), trying to register it.
05:34:01 WORKER: registered result for job (1, 0, 5) with dispatcher
05:34:01 DISPATCHER: job (1, 0, 5) finished
05:34:01 DISPATCHER: register_result: lock acquired
05:34:01 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:34:01 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 29, 'last_n_outputs': 49, 'lr': 0.0026369844440124763, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.02098471400102281}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.275325110908526, 'info': {'data03': 0.275325110908526, 'config': "{'batch_size': 128, 'hidden_dim': 29, 'last_n_outputs': 49, 'lr': 0.0026369844440124763, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.02098471400102281}"}}
exception: None

05:34:01 job_callback for (1, 0, 5) started
05:34:01 job_callback for (1, 0, 5) got condition
05:34:01 DISPATCHER: Trying to submit another job.
05:34:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:34:01 HBMASTER: Trying to run another job!
05:34:01 job_callback for (1, 0, 5) finished
05:34:01 start sampling a new configuration.
05:34:01 done sampling a new configuration.
05:34:01 HBMASTER: schedule new run for iteration 1
05:34:01 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
05:34:01 HBMASTER: submitting job (1, 0, 6) to dispatcher
05:34:01 DISPATCHER: trying to submit job (1, 0, 6)
05:34:01 DISPATCHER: trying to notify the job_runner thread.
05:34:01 HBMASTER: job (1, 0, 6) submitted to dispatcher
05:34:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:34:01 DISPATCHER: Trying to submit another job.
05:34:01 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:34:01 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:34:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:34:01 WORKER: start processing job (1, 0, 6)
05:34:01 WORKER: args: ()
05:34:01 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 29, 'last_n_outputs': 7, 'lr': 0.01290806023114953, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.015807907584772418}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:34:04 DISPATCHER: Starting worker discovery
05:34:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:34:04 DISPATCHER: Finished worker discovery
Exception in thread Thread-452:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:35:04 DISPATCHER: Starting worker discovery
05:35:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:35:04 DISPATCHER: Finished worker discovery
05:36:04 DISPATCHER: Starting worker discovery
05:36:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:36:04 DISPATCHER: Finished worker discovery
05:36:56 WORKER: done with job (1, 0, 6), trying to register it.
05:36:56 WORKER: registered result for job (1, 0, 6) with dispatcher
05:36:56 DISPATCHER: job (1, 0, 6) finished
05:36:56 DISPATCHER: register_result: lock acquired
05:36:56 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:36:56 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 29, 'last_n_outputs': 7, 'lr': 0.01290806023114953, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.015807907584772418}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 29, 'last_n_outputs': 7, 'lr': 0.01290806023114953, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.015807907584772418}"}}
exception: None

05:36:56 job_callback for (1, 0, 6) started
05:36:56 job_callback for (1, 0, 6) got condition
05:36:56 DISPATCHER: Trying to submit another job.
05:36:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:36:56 HBMASTER: Trying to run another job!
05:36:56 job_callback for (1, 0, 6) finished
05:36:56 start sampling a new configuration.
05:36:57 best_vector: [3, 0.24061437898833507, 0.8743651986577075, 0.33141517833789996, 0.22898130683084167, 1, 0.8146122291758388, 0.6770683991659894], 0.04994732252769399, 0.15034362539459772, 0.007509261547566777
05:36:57 done sampling a new configuration.
05:36:57 HBMASTER: schedule new run for iteration 1
05:36:57 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
05:36:57 HBMASTER: submitting job (1, 0, 7) to dispatcher
05:36:57 DISPATCHER: trying to submit job (1, 0, 7)
05:36:57 DISPATCHER: trying to notify the job_runner thread.
05:36:57 HBMASTER: job (1, 0, 7) submitted to dispatcher
05:36:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:36:57 DISPATCHER: Trying to submit another job.
05:36:57 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:36:57 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:36:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:36:57 WORKER: start processing job (1, 0, 7)
05:36:57 WORKER: args: ()
05:36:57 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 39, 'last_n_outputs': 44, 'lr': 0.00460076824100905, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.07601272403447284}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:37:04 DISPATCHER: Starting worker discovery
05:37:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:37:04 DISPATCHER: Finished worker discovery
Exception in thread Thread-453:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:38:04 DISPATCHER: Starting worker discovery
05:38:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:38:04 DISPATCHER: Finished worker discovery
05:39:04 DISPATCHER: Starting worker discovery
05:39:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:39:04 DISPATCHER: Finished worker discovery
05:39:50 WORKER: done with job (1, 0, 7), trying to register it.
05:39:50 WORKER: registered result for job (1, 0, 7) with dispatcher
05:39:50 DISPATCHER: job (1, 0, 7) finished
05:39:50 DISPATCHER: register_result: lock acquired
05:39:50 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:39:50 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 39, 'last_n_outputs': 44, 'lr': 0.00460076824100905, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.07601272403447284}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 39, 'last_n_outputs': 44, 'lr': 0.00460076824100905, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.07601272403447284}"}}
exception: None

05:39:50 job_callback for (1, 0, 7) started
05:39:50 job_callback for (1, 0, 7) got condition
05:39:50 DISPATCHER: Trying to submit another job.
05:39:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:39:50 HBMASTER: Trying to run another job!
05:39:50 job_callback for (1, 0, 7) finished
05:39:50 start sampling a new configuration.
05:39:50 best_vector: [0, 0.7556501487003601, 0.948437780811805, 0.11956762736709298, 0.025033526726945116, 0, 0.8162061656749453, 0.1473179636230828], 0.006203551227998805, 0.11026613850151601, 0.0006840416389077659
05:39:50 done sampling a new configuration.
05:39:50 HBMASTER: schedule new run for iteration 1
05:39:50 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
05:39:50 HBMASTER: submitting job (1, 0, 8) to dispatcher
05:39:50 DISPATCHER: trying to submit job (1, 0, 8)
05:39:50 DISPATCHER: trying to notify the job_runner thread.
05:39:50 HBMASTER: job (1, 0, 8) submitted to dispatcher
05:39:50 DISPATCHER: Trying to submit another job.
05:39:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:39:50 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:39:50 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:39:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:39:50 WORKER: start processing job (1, 0, 8)
05:39:50 WORKER: args: ()
05:39:50 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 81, 'last_n_outputs': 48, 'lr': 0.0017343440500206004, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.015547661960675686}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:40:04 DISPATCHER: Starting worker discovery
05:40:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:40:04 DISPATCHER: Finished worker discovery
Exception in thread Thread-454:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:41:04 DISPATCHER: Starting worker discovery
05:41:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:41:04 DISPATCHER: Finished worker discovery
05:42:04 DISPATCHER: Starting worker discovery
05:42:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:42:04 DISPATCHER: Finished worker discovery
05:42:44 WORKER: done with job (1, 0, 8), trying to register it.
05:42:44 WORKER: registered result for job (1, 0, 8) with dispatcher
05:42:44 DISPATCHER: job (1, 0, 8) finished
05:42:44 DISPATCHER: register_result: lock acquired
05:42:44 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:42:44 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 81, 'last_n_outputs': 48, 'lr': 0.0017343440500206004, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.015547661960675686}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.02726491487823225, 'info': {'data03': 0.02726491487823225, 'config': "{'batch_size': 16, 'hidden_dim': 81, 'last_n_outputs': 48, 'lr': 0.0017343440500206004, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.015547661960675686}"}}
exception: None

05:42:44 job_callback for (1, 0, 8) started
05:42:44 job_callback for (1, 0, 8) got condition
05:42:44 DISPATCHER: Trying to submit another job.
05:42:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:42:44 done building a new model for budget 133.333333 based on 9/15 split
Best loss for this budget:-0.407920





05:42:44 HBMASTER: Trying to run another job!
05:42:44 job_callback for (1, 0, 8) finished
05:42:44 ITERATION: Advancing config (1, 0, 4) to next budget 400.000000
05:42:44 ITERATION: Advancing config (1, 0, 5) to next budget 400.000000
05:42:44 ITERATION: Advancing config (1, 0, 8) to next budget 400.000000
05:42:44 HBMASTER: schedule new run for iteration 1
05:42:44 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
05:42:44 HBMASTER: submitting job (1, 0, 4) to dispatcher
05:42:44 DISPATCHER: trying to submit job (1, 0, 4)
05:42:44 DISPATCHER: trying to notify the job_runner thread.
05:42:44 HBMASTER: job (1, 0, 4) submitted to dispatcher
05:42:44 DISPATCHER: Trying to submit another job.
05:42:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:42:44 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:42:44 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:42:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:42:44 WORKER: start processing job (1, 0, 4)
05:42:44 WORKER: args: ()
05:42:44 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 75, 'last_n_outputs': 44, 'lr': 0.001279299758159678, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.024707896046289177}, 'budget': 400.0, 'working_directory': '.'}
05:43:04 DISPATCHER: Starting worker discovery
05:43:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:43:04 DISPATCHER: Finished worker discovery
Exception in thread Thread-455:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:44:04 DISPATCHER: Starting worker discovery
05:44:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:44:04 DISPATCHER: Finished worker discovery
05:45:04 DISPATCHER: Starting worker discovery
05:45:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:45:04 DISPATCHER: Finished worker discovery
05:46:04 DISPATCHER: Starting worker discovery
05:46:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:46:04 DISPATCHER: Finished worker discovery
05:47:04 DISPATCHER: Starting worker discovery
05:47:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:47:04 DISPATCHER: Finished worker discovery
05:48:04 DISPATCHER: Starting worker discovery
05:48:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:48:04 DISPATCHER: Finished worker discovery
05:49:04 DISPATCHER: Starting worker discovery
05:49:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:49:04 DISPATCHER: Finished worker discovery
05:50:03 WORKER: done with job (1, 0, 4), trying to register it.
05:50:03 WORKER: registered result for job (1, 0, 4) with dispatcher
05:50:03 DISPATCHER: job (1, 0, 4) finished
05:50:03 DISPATCHER: register_result: lock acquired
05:50:03 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:50:03 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 75, 'last_n_outputs': 44, 'lr': 0.001279299758159678, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.024707896046289177}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.36026551512059446, 'info': {'data03': 0.36026551512059446, 'config': "{'batch_size': 64, 'hidden_dim': 75, 'last_n_outputs': 44, 'lr': 0.001279299758159678, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.024707896046289177}"}}
exception: None

05:50:03 job_callback for (1, 0, 4) started
05:50:03 DISPATCHER: Trying to submit another job.
05:50:03 job_callback for (1, 0, 4) got condition
05:50:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:50:03 Only 4 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
05:50:03 HBMASTER: Trying to run another job!
05:50:03 job_callback for (1, 0, 4) finished
05:50:03 HBMASTER: schedule new run for iteration 1
05:50:03 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
05:50:03 HBMASTER: submitting job (1, 0, 5) to dispatcher
05:50:03 DISPATCHER: trying to submit job (1, 0, 5)
05:50:03 DISPATCHER: trying to notify the job_runner thread.
05:50:03 HBMASTER: job (1, 0, 5) submitted to dispatcher
05:50:03 DISPATCHER: Trying to submit another job.
05:50:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:50:03 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:50:03 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:50:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:50:03 WORKER: start processing job (1, 0, 5)
05:50:03 WORKER: args: ()
05:50:03 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 29, 'last_n_outputs': 49, 'lr': 0.0026369844440124763, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.02098471400102281}, 'budget': 400.0, 'working_directory': '.'}
05:50:04 DISPATCHER: Starting worker discovery
05:50:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:50:04 DISPATCHER: Finished worker discovery
Exception in thread Thread-456:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:51:04 DISPATCHER: Starting worker discovery
05:51:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:51:04 DISPATCHER: Finished worker discovery
05:52:04 DISPATCHER: Starting worker discovery
05:52:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:52:04 DISPATCHER: Finished worker discovery
05:53:04 DISPATCHER: Starting worker discovery
05:53:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:53:04 DISPATCHER: Finished worker discovery
05:54:04 DISPATCHER: Starting worker discovery
05:54:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:54:04 DISPATCHER: Finished worker discovery
05:55:04 DISPATCHER: Starting worker discovery
05:55:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:55:04 DISPATCHER: Finished worker discovery
05:56:04 DISPATCHER: Starting worker discovery
05:56:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:56:04 DISPATCHER: Finished worker discovery
05:57:04 DISPATCHER: Starting worker discovery
05:57:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:57:04 DISPATCHER: Finished worker discovery
05:57:26 WORKER: done with job (1, 0, 5), trying to register it.
05:57:26 WORKER: registered result for job (1, 0, 5) with dispatcher
05:57:26 DISPATCHER: job (1, 0, 5) finished
05:57:26 DISPATCHER: register_result: lock acquired
05:57:26 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:57:26 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 29, 'last_n_outputs': 49, 'lr': 0.0026369844440124763, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.02098471400102281}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3058721203998326, 'info': {'data03': 0.3058721203998326, 'config': "{'batch_size': 128, 'hidden_dim': 29, 'last_n_outputs': 49, 'lr': 0.0026369844440124763, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.02098471400102281}"}}
exception: None

05:57:26 job_callback for (1, 0, 5) started
05:57:26 DISPATCHER: Trying to submit another job.
05:57:26 job_callback for (1, 0, 5) got condition
05:57:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:57:26 Only 5 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
05:57:26 HBMASTER: Trying to run another job!
05:57:26 job_callback for (1, 0, 5) finished
05:57:26 HBMASTER: schedule new run for iteration 1
05:57:26 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
05:57:26 HBMASTER: submitting job (1, 0, 8) to dispatcher
05:57:26 DISPATCHER: trying to submit job (1, 0, 8)
05:57:26 DISPATCHER: trying to notify the job_runner thread.
05:57:26 HBMASTER: job (1, 0, 8) submitted to dispatcher
05:57:26 DISPATCHER: Trying to submit another job.
05:57:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:57:26 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:57:26 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:57:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:57:26 WORKER: start processing job (1, 0, 8)
05:57:26 WORKER: args: ()
05:57:26 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 81, 'last_n_outputs': 48, 'lr': 0.0017343440500206004, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.015547661960675686}, 'budget': 400.0, 'working_directory': '.'}
05:58:04 DISPATCHER: Starting worker discovery
05:58:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:58:04 DISPATCHER: Finished worker discovery
Exception in thread Thread-457:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:59:04 DISPATCHER: Starting worker discovery
05:59:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:59:04 DISPATCHER: Finished worker discovery
06:00:04 DISPATCHER: Starting worker discovery
06:00:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:00:04 DISPATCHER: Finished worker discovery
06:01:04 DISPATCHER: Starting worker discovery
06:01:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:01:04 DISPATCHER: Finished worker discovery
06:02:04 DISPATCHER: Starting worker discovery
06:02:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:02:04 DISPATCHER: Finished worker discovery
06:03:04 DISPATCHER: Starting worker discovery
06:03:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:03:04 DISPATCHER: Finished worker discovery
06:04:04 DISPATCHER: Starting worker discovery
06:04:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:04:04 DISPATCHER: Finished worker discovery
06:04:55 WORKER: done with job (1, 0, 8), trying to register it.
06:04:55 WORKER: registered result for job (1, 0, 8) with dispatcher
06:04:55 DISPATCHER: job (1, 0, 8) finished
06:04:55 DISPATCHER: register_result: lock acquired
06:04:55 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
06:04:55 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 81, 'last_n_outputs': 48, 'lr': 0.0017343440500206004, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.015547661960675686}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.09310789728156707, 'info': {'data03': 0.09310789728156707, 'config': "{'batch_size': 16, 'hidden_dim': 81, 'last_n_outputs': 48, 'lr': 0.0017343440500206004, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.015547661960675686}"}}
exception: None

06:04:55 job_callback for (1, 0, 8) started
06:04:55 job_callback for (1, 0, 8) got condition
06:04:55 DISPATCHER: Trying to submit another job.
06:04:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:04:55 Only 6 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
06:04:55 HBMASTER: Trying to run another job!
06:04:55 job_callback for (1, 0, 8) finished
06:04:55 ITERATION: Advancing config (1, 0, 4) to next budget 1200.000000
06:04:55 HBMASTER: schedule new run for iteration 1
06:04:55 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
06:04:55 HBMASTER: submitting job (1, 0, 4) to dispatcher
06:04:55 DISPATCHER: trying to submit job (1, 0, 4)
06:04:55 DISPATCHER: trying to notify the job_runner thread.
06:04:55 HBMASTER: job (1, 0, 4) submitted to dispatcher
06:04:55 DISPATCHER: Trying to submit another job.
06:04:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:04:55 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
06:04:55 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
06:04:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:04:55 WORKER: start processing job (1, 0, 4)
06:04:55 WORKER: args: ()
06:04:55 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 75, 'last_n_outputs': 44, 'lr': 0.001279299758159678, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.024707896046289177}, 'budget': 1200.0, 'working_directory': '.'}
06:05:04 DISPATCHER: Starting worker discovery
06:05:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:05:04 DISPATCHER: Finished worker discovery
Exception in thread Thread-458:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:06:04 DISPATCHER: Starting worker discovery
06:06:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:06:04 DISPATCHER: Finished worker discovery
06:07:04 DISPATCHER: Starting worker discovery
06:07:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:07:04 DISPATCHER: Finished worker discovery
06:08:04 DISPATCHER: Starting worker discovery
06:08:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:08:04 DISPATCHER: Finished worker discovery
06:09:04 DISPATCHER: Starting worker discovery
06:09:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:09:04 DISPATCHER: Finished worker discovery
06:10:04 DISPATCHER: Starting worker discovery
06:10:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:10:04 DISPATCHER: Finished worker discovery
06:11:04 DISPATCHER: Starting worker discovery
06:11:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:11:04 DISPATCHER: Finished worker discovery
06:12:04 DISPATCHER: Starting worker discovery
06:12:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:12:04 DISPATCHER: Finished worker discovery
06:13:04 DISPATCHER: Starting worker discovery
06:13:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:13:04 DISPATCHER: Finished worker discovery
06:14:04 DISPATCHER: Starting worker discovery
06:14:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:14:04 DISPATCHER: Finished worker discovery
06:15:04 DISPATCHER: Starting worker discovery
06:15:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:15:04 DISPATCHER: Finished worker discovery
06:16:04 DISPATCHER: Starting worker discovery
06:16:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:16:04 DISPATCHER: Finished worker discovery
06:17:04 DISPATCHER: Starting worker discovery
06:17:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:17:04 DISPATCHER: Finished worker discovery
06:18:04 DISPATCHER: Starting worker discovery
06:18:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:18:04 DISPATCHER: Finished worker discovery
06:19:04 DISPATCHER: Starting worker discovery
06:19:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:19:04 DISPATCHER: Finished worker discovery
06:20:04 DISPATCHER: Starting worker discovery
06:20:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:20:04 DISPATCHER: Finished worker discovery
06:21:04 DISPATCHER: Starting worker discovery
06:21:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:21:04 DISPATCHER: Finished worker discovery
06:22:04 DISPATCHER: Starting worker discovery
06:22:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:22:04 DISPATCHER: Finished worker discovery
06:23:04 DISPATCHER: Starting worker discovery
06:23:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:23:04 DISPATCHER: Finished worker discovery
06:24:04 DISPATCHER: Starting worker discovery
06:24:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:24:04 DISPATCHER: Finished worker discovery
06:25:04 DISPATCHER: Starting worker discovery
06:25:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:25:04 DISPATCHER: Finished worker discovery
06:25:39 WORKER: done with job (1, 0, 4), trying to register it.
06:25:39 WORKER: registered result for job (1, 0, 4) with dispatcher
06:25:39 DISPATCHER: job (1, 0, 4) finished
06:25:39 DISPATCHER: register_result: lock acquired
06:25:39 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
06:25:39 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 75, 'last_n_outputs': 44, 'lr': 0.001279299758159678, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.024707896046289177}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.18532437117157588, 'info': {'data03': 0.18532437117157588, 'config': "{'batch_size': 64, 'hidden_dim': 75, 'last_n_outputs': 44, 'lr': 0.001279299758159678, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.024707896046289177}"}}
exception: None

06:25:39 job_callback for (1, 0, 4) started
06:25:39 DISPATCHER: Trying to submit another job.
06:25:39 job_callback for (1, 0, 4) got condition
06:25:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:25:39 Only 2 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
06:25:39 HBMASTER: Trying to run another job!
06:25:39 job_callback for (1, 0, 4) finished
06:25:39 start sampling a new configuration.
06:25:39 best_vector: [3, 0.5023220557421452, 0.07215824236939716, 0.10414867204280909, 0.18819645111494307, 1, 0.3095559730526645, 0.19872516235075505], 2.3160831660195325e-29, 0.00043176342485085295, -0.004080449601125833
06:25:39 done sampling a new configuration.
06:25:39 HBMASTER: schedule new run for iteration 2
06:25:39 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
06:25:39 HBMASTER: submitting job (2, 0, 0) to dispatcher
06:25:39 DISPATCHER: trying to submit job (2, 0, 0)
06:25:39 DISPATCHER: trying to notify the job_runner thread.
06:25:39 HBMASTER: job (2, 0, 0) submitted to dispatcher
06:25:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:25:39 DISPATCHER: Trying to submit another job.
06:25:39 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
06:25:39 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
06:25:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:25:39 WORKER: start processing job (2, 0, 0)
06:25:39 WORKER: args: ()
06:25:39 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 60, 'last_n_outputs': 4, 'lr': 0.0016154642221105453, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.018136245965912668}, 'budget': 400.0, 'working_directory': '.'}
06:26:04 DISPATCHER: Starting worker discovery
06:26:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:26:04 DISPATCHER: Finished worker discovery
Exception in thread Thread-459:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:27:04 DISPATCHER: Starting worker discovery
06:27:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:27:04 DISPATCHER: Finished worker discovery
06:28:04 DISPATCHER: Starting worker discovery
06:28:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:28:04 DISPATCHER: Finished worker discovery
06:29:04 DISPATCHER: Starting worker discovery
06:29:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:29:04 DISPATCHER: Finished worker discovery
06:30:04 DISPATCHER: Starting worker discovery
06:30:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:30:04 DISPATCHER: Finished worker discovery
06:31:04 DISPATCHER: Starting worker discovery
06:31:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:31:04 DISPATCHER: Finished worker discovery
06:32:04 DISPATCHER: Starting worker discovery
06:32:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:32:04 DISPATCHER: Finished worker discovery
06:33:04 DISPATCHER: Starting worker discovery
06:33:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:33:04 DISPATCHER: Finished worker discovery
06:33:06 WORKER: done with job (2, 0, 0), trying to register it.
06:33:06 WORKER: registered result for job (2, 0, 0) with dispatcher
06:33:06 DISPATCHER: job (2, 0, 0) finished
06:33:06 DISPATCHER: register_result: lock acquired
06:33:06 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
06:33:06 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 60, 'last_n_outputs': 4, 'lr': 0.0016154642221105453, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.018136245965912668}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 60, 'last_n_outputs': 4, 'lr': 0.0016154642221105453, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.018136245965912668}"}}
exception: None

06:33:06 job_callback for (2, 0, 0) started
06:33:06 DISPATCHER: Trying to submit another job.
06:33:06 job_callback for (2, 0, 0) got condition
06:33:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:33:06 Only 7 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
06:33:06 HBMASTER: Trying to run another job!
06:33:06 job_callback for (2, 0, 0) finished
06:33:06 start sampling a new configuration.
06:33:06 done sampling a new configuration.
06:33:06 HBMASTER: schedule new run for iteration 2
06:33:06 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
06:33:06 HBMASTER: submitting job (2, 0, 1) to dispatcher
06:33:06 DISPATCHER: trying to submit job (2, 0, 1)
06:33:06 DISPATCHER: trying to notify the job_runner thread.
06:33:06 HBMASTER: job (2, 0, 1) submitted to dispatcher
06:33:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:33:06 DISPATCHER: Trying to submit another job.
06:33:06 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
06:33:06 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
06:33:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:33:06 WORKER: start processing job (2, 0, 1)
06:33:06 WORKER: args: ()
06:33:06 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 81, 'last_n_outputs': 11, 'lr': 0.018323816919112244, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.013459619696096735}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-460:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:34:04 DISPATCHER: Starting worker discovery
06:34:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:34:04 DISPATCHER: Finished worker discovery
06:35:04 DISPATCHER: Starting worker discovery
06:35:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:35:04 DISPATCHER: Finished worker discovery
06:36:04 DISPATCHER: Starting worker discovery
06:36:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:36:04 DISPATCHER: Finished worker discovery
06:37:04 DISPATCHER: Starting worker discovery
06:37:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:37:04 DISPATCHER: Finished worker discovery
06:38:04 DISPATCHER: Starting worker discovery
06:38:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:38:04 DISPATCHER: Finished worker discovery
06:39:04 DISPATCHER: Starting worker discovery
06:39:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:39:04 DISPATCHER: Finished worker discovery
06:40:05 DISPATCHER: Starting worker discovery
06:40:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:40:05 DISPATCHER: Finished worker discovery
06:40:30 WORKER: done with job (2, 0, 1), trying to register it.
06:40:30 WORKER: registered result for job (2, 0, 1) with dispatcher
06:40:30 DISPATCHER: job (2, 0, 1) finished
06:40:30 DISPATCHER: register_result: lock acquired
06:40:30 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
06:40:30 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 81, 'last_n_outputs': 11, 'lr': 0.018323816919112244, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.013459619696096735}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 81, 'last_n_outputs': 11, 'lr': 0.018323816919112244, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.013459619696096735}"}}
exception: None

06:40:30 job_callback for (2, 0, 1) started
06:40:30 DISPATCHER: Trying to submit another job.
06:40:30 job_callback for (2, 0, 1) got condition
06:40:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:40:30 Only 8 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
06:40:30 HBMASTER: Trying to run another job!
06:40:30 job_callback for (2, 0, 1) finished
06:40:30 start sampling a new configuration.
06:40:30 done sampling a new configuration.
06:40:30 HBMASTER: schedule new run for iteration 2
06:40:30 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
06:40:30 HBMASTER: submitting job (2, 0, 2) to dispatcher
06:40:30 DISPATCHER: trying to submit job (2, 0, 2)
06:40:30 DISPATCHER: trying to notify the job_runner thread.
06:40:30 HBMASTER: job (2, 0, 2) submitted to dispatcher
06:40:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:40:30 DISPATCHER: Trying to submit another job.
06:40:30 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
06:40:30 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
06:40:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:40:30 WORKER: start processing job (2, 0, 2)
06:40:30 WORKER: args: ()
06:40:30 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 92, 'last_n_outputs': 43, 'lr': 0.00743697404089649, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.0350467148943146}, 'budget': 400.0, 'working_directory': '.'}
06:41:05 DISPATCHER: Starting worker discovery
06:41:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:41:05 DISPATCHER: Finished worker discovery
Exception in thread Thread-461:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:42:05 DISPATCHER: Starting worker discovery
06:42:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:42:05 DISPATCHER: Finished worker discovery
06:43:05 DISPATCHER: Starting worker discovery
06:43:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:43:05 DISPATCHER: Finished worker discovery
06:44:05 DISPATCHER: Starting worker discovery
06:44:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:44:05 DISPATCHER: Finished worker discovery
06:45:05 DISPATCHER: Starting worker discovery
06:45:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:45:05 DISPATCHER: Finished worker discovery
06:46:05 DISPATCHER: Starting worker discovery
06:46:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:46:05 DISPATCHER: Finished worker discovery
06:47:05 DISPATCHER: Starting worker discovery
06:47:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:47:05 DISPATCHER: Finished worker discovery
06:47:47 WORKER: done with job (2, 0, 2), trying to register it.
06:47:47 WORKER: registered result for job (2, 0, 2) with dispatcher
06:47:47 DISPATCHER: job (2, 0, 2) finished
06:47:47 DISPATCHER: register_result: lock acquired
06:47:47 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
06:47:47 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 92, 'last_n_outputs': 43, 'lr': 0.00743697404089649, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.0350467148943146}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.24272795032204475, 'info': {'data03': 0.24272795032204475, 'config': "{'batch_size': 64, 'hidden_dim': 92, 'last_n_outputs': 43, 'lr': 0.00743697404089649, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.0350467148943146}"}}
exception: None

06:47:47 job_callback for (2, 0, 2) started
06:47:47 job_callback for (2, 0, 2) got condition
06:47:47 DISPATCHER: Trying to submit another job.
06:47:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:47:47 HBMASTER: Trying to run another job!
06:47:47 job_callback for (2, 0, 2) finished
06:47:47 start sampling a new configuration.
06:47:47 best_vector: [1, 0.0015695453018437916, 0.8874460732266655, 0.36697899191846006, 0.5238890164394774, 1, 0.5235461553137946, 0.9116077684830975], 5.0764584518024e-29, 0.0001969877247089355, -0.010697629041755327
06:47:47 done sampling a new configuration.
06:47:47 HBMASTER: schedule new run for iteration 2
06:47:47 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
06:47:47 HBMASTER: submitting job (2, 0, 3) to dispatcher
06:47:47 DISPATCHER: trying to submit job (2, 0, 3)
06:47:47 DISPATCHER: trying to notify the job_runner thread.
06:47:47 HBMASTER: job (2, 0, 3) submitted to dispatcher
06:47:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:47:47 DISPATCHER: Trying to submit another job.
06:47:47 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
06:47:47 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
06:47:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:47:47 WORKER: start processing job (2, 0, 3)
06:47:47 WORKER: args: ()
06:47:47 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 20, 'last_n_outputs': 45, 'lr': 0.00541948456633297, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.15347196407165672}, 'budget': 400.0, 'working_directory': '.'}
06:48:05 DISPATCHER: Starting worker discovery
06:48:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:48:05 DISPATCHER: Finished worker discovery
Exception in thread Thread-462:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:49:05 DISPATCHER: Starting worker discovery
06:49:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:49:05 DISPATCHER: Finished worker discovery
06:50:05 DISPATCHER: Starting worker discovery
06:50:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:50:05 DISPATCHER: Finished worker discovery
06:51:05 DISPATCHER: Starting worker discovery
06:51:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:51:05 DISPATCHER: Finished worker discovery
06:52:05 DISPATCHER: Starting worker discovery
06:52:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:52:05 DISPATCHER: Finished worker discovery
06:53:05 DISPATCHER: Starting worker discovery
06:53:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:53:05 DISPATCHER: Finished worker discovery
06:54:05 DISPATCHER: Starting worker discovery
06:54:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:54:05 DISPATCHER: Finished worker discovery
06:55:05 DISPATCHER: Starting worker discovery
06:55:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:55:05 DISPATCHER: Finished worker discovery
06:55:07 WORKER: done with job (2, 0, 3), trying to register it.
06:55:07 WORKER: registered result for job (2, 0, 3) with dispatcher
06:55:07 DISPATCHER: job (2, 0, 3) finished
06:55:07 DISPATCHER: register_result: lock acquired
06:55:07 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
06:55:07 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 20, 'last_n_outputs': 45, 'lr': 0.00541948456633297, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.15347196407165672}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 20, 'last_n_outputs': 45, 'lr': 0.00541948456633297, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.15347196407165672}"}}
exception: None

06:55:07 job_callback for (2, 0, 3) started
06:55:07 job_callback for (2, 0, 3) got condition
06:55:07 DISPATCHER: Trying to submit another job.
06:55:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:55:07 HBMASTER: Trying to run another job!
06:55:07 job_callback for (2, 0, 3) finished
06:55:07 start sampling a new configuration.
06:55:07 done sampling a new configuration.
06:55:07 HBMASTER: schedule new run for iteration 2
06:55:07 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
06:55:07 HBMASTER: submitting job (2, 0, 4) to dispatcher
06:55:07 DISPATCHER: trying to submit job (2, 0, 4)
06:55:07 DISPATCHER: trying to notify the job_runner thread.
06:55:07 HBMASTER: job (2, 0, 4) submitted to dispatcher
06:55:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:55:07 DISPATCHER: Trying to submit another job.
06:55:07 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
06:55:07 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
06:55:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:55:07 WORKER: start processing job (2, 0, 4)
06:55:07 WORKER: args: ()
06:55:07 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 98, 'last_n_outputs': 46, 'lr': 0.0025283074017429857, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.03409328375635539}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-463:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:56:05 DISPATCHER: Starting worker discovery
06:56:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:56:05 DISPATCHER: Finished worker discovery
06:57:05 DISPATCHER: Starting worker discovery
06:57:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:57:05 DISPATCHER: Finished worker discovery
06:58:05 DISPATCHER: Starting worker discovery
06:58:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:58:05 DISPATCHER: Finished worker discovery
06:59:05 DISPATCHER: Starting worker discovery
06:59:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:59:05 DISPATCHER: Finished worker discovery
07:00:05 DISPATCHER: Starting worker discovery
07:00:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:00:05 DISPATCHER: Finished worker discovery
07:01:05 DISPATCHER: Starting worker discovery
07:01:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:01:05 DISPATCHER: Finished worker discovery
07:02:05 DISPATCHER: Starting worker discovery
07:02:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:02:05 DISPATCHER: Finished worker discovery
07:02:27 WORKER: done with job (2, 0, 4), trying to register it.
07:02:27 WORKER: registered result for job (2, 0, 4) with dispatcher
07:02:27 DISPATCHER: job (2, 0, 4) finished
07:02:27 DISPATCHER: register_result: lock acquired
07:02:27 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
07:02:27 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 98, 'last_n_outputs': 46, 'lr': 0.0025283074017429857, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.03409328375635539}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 98, 'last_n_outputs': 46, 'lr': 0.0025283074017429857, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.03409328375635539}"}}
exception: None

07:02:27 job_callback for (2, 0, 4) started
07:02:27 DISPATCHER: Trying to submit another job.
07:02:27 job_callback for (2, 0, 4) got condition
07:02:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:02:27 HBMASTER: Trying to run another job!
07:02:27 job_callback for (2, 0, 4) finished
07:02:27 start sampling a new configuration.
07:02:27 best_vector: [0, 0.970279263313068, 0.4841711674966001, 0.8770335243379346, 0.17915846701229216, 0, 0.6101729141168869, 0.2091045450076659], 4.6893902803080483e-32, 0.2132473392541577, -0.003241047531124163
07:02:27 done sampling a new configuration.
07:02:27 HBMASTER: schedule new run for iteration 2
07:02:27 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
07:02:27 HBMASTER: submitting job (2, 0, 5) to dispatcher
07:02:27 DISPATCHER: trying to submit job (2, 0, 5)
07:02:27 DISPATCHER: trying to notify the job_runner thread.
07:02:27 HBMASTER: job (2, 0, 5) submitted to dispatcher
07:02:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:02:27 DISPATCHER: Trying to submit another job.
07:02:27 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
07:02:27 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
07:02:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:02:27 WORKER: start processing job (2, 0, 5)
07:02:27 WORKER: args: ()
07:02:27 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 98, 'last_n_outputs': 25, 'lr': 0.056763223270626065, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.018709030598913556}, 'budget': 400.0, 'working_directory': '.'}
07:03:05 DISPATCHER: Starting worker discovery
07:03:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:03:05 DISPATCHER: Finished worker discovery
Exception in thread Thread-464:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:04:05 DISPATCHER: Starting worker discovery
07:04:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:04:05 DISPATCHER: Finished worker discovery
07:05:05 DISPATCHER: Starting worker discovery
07:05:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:05:05 DISPATCHER: Finished worker discovery
07:06:05 DISPATCHER: Starting worker discovery
07:06:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:06:05 DISPATCHER: Finished worker discovery
07:07:05 DISPATCHER: Starting worker discovery
07:07:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:07:05 DISPATCHER: Finished worker discovery
07:08:05 DISPATCHER: Starting worker discovery
07:08:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:08:05 DISPATCHER: Finished worker discovery
07:09:05 DISPATCHER: Starting worker discovery
07:09:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:09:05 DISPATCHER: Finished worker discovery
07:09:46 WORKER: done with job (2, 0, 5), trying to register it.
07:09:46 WORKER: registered result for job (2, 0, 5) with dispatcher
07:09:46 DISPATCHER: job (2, 0, 5) finished
07:09:46 DISPATCHER: register_result: lock acquired
07:09:46 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
07:09:46 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 98, 'last_n_outputs': 25, 'lr': 0.056763223270626065, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.018709030598913556}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 98, 'last_n_outputs': 25, 'lr': 0.056763223270626065, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.018709030598913556}"}}
exception: None

07:09:46 job_callback for (2, 0, 5) started
07:09:46 job_callback for (2, 0, 5) got condition
07:09:46 DISPATCHER: Trying to submit another job.
07:09:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:09:47 HBMASTER: Trying to run another job!
07:09:47 job_callback for (2, 0, 5) finished
07:09:47 ITERATION: Advancing config (2, 0, 0) to next budget 1200.000000
07:09:47 ITERATION: Advancing config (2, 0, 2) to next budget 1200.000000
07:09:47 HBMASTER: schedule new run for iteration 2
07:09:47 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
07:09:47 HBMASTER: submitting job (2, 0, 0) to dispatcher
07:09:47 DISPATCHER: trying to submit job (2, 0, 0)
07:09:47 DISPATCHER: trying to notify the job_runner thread.
07:09:47 HBMASTER: job (2, 0, 0) submitted to dispatcher
07:09:47 DISPATCHER: Trying to submit another job.
07:09:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:09:47 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
07:09:47 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
07:09:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:09:47 WORKER: start processing job (2, 0, 0)
07:09:47 WORKER: args: ()
07:09:47 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 60, 'last_n_outputs': 4, 'lr': 0.0016154642221105453, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.018136245965912668}, 'budget': 1200.0, 'working_directory': '.'}
07:10:05 DISPATCHER: Starting worker discovery
07:10:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:10:05 DISPATCHER: Finished worker discovery
Exception in thread Thread-465:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:11:05 DISPATCHER: Starting worker discovery
07:11:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:11:05 DISPATCHER: Finished worker discovery
07:12:05 DISPATCHER: Starting worker discovery
07:12:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:12:05 DISPATCHER: Finished worker discovery
07:13:05 DISPATCHER: Starting worker discovery
07:13:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:13:05 DISPATCHER: Finished worker discovery
07:14:05 DISPATCHER: Starting worker discovery
07:14:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:14:05 DISPATCHER: Finished worker discovery
07:15:05 DISPATCHER: Starting worker discovery
07:15:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:15:05 DISPATCHER: Finished worker discovery
07:16:05 DISPATCHER: Starting worker discovery
07:16:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:16:05 DISPATCHER: Finished worker discovery
07:17:05 DISPATCHER: Starting worker discovery
07:17:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:17:05 DISPATCHER: Finished worker discovery
07:18:05 DISPATCHER: Starting worker discovery
07:18:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:18:05 DISPATCHER: Finished worker discovery
07:19:05 DISPATCHER: Starting worker discovery
07:19:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:19:05 DISPATCHER: Finished worker discovery
07:20:05 DISPATCHER: Starting worker discovery
07:20:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:20:05 DISPATCHER: Finished worker discovery
07:21:05 DISPATCHER: Starting worker discovery
07:21:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:21:05 DISPATCHER: Finished worker discovery
07:22:05 DISPATCHER: Starting worker discovery
07:22:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:22:05 DISPATCHER: Finished worker discovery
07:23:05 DISPATCHER: Starting worker discovery
07:23:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:23:05 DISPATCHER: Finished worker discovery
07:24:05 DISPATCHER: Starting worker discovery
07:24:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:24:05 DISPATCHER: Finished worker discovery
07:25:05 DISPATCHER: Starting worker discovery
07:25:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:25:05 DISPATCHER: Finished worker discovery
07:26:05 DISPATCHER: Starting worker discovery
07:26:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:26:05 DISPATCHER: Finished worker discovery
07:27:05 DISPATCHER: Starting worker discovery
07:27:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:27:05 DISPATCHER: Finished worker discovery
07:28:05 DISPATCHER: Starting worker discovery
07:28:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:28:05 DISPATCHER: Finished worker discovery
07:29:05 DISPATCHER: Starting worker discovery
07:29:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:29:05 DISPATCHER: Finished worker discovery
07:30:05 DISPATCHER: Starting worker discovery
07:30:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:30:05 DISPATCHER: Finished worker discovery
07:30:26 WORKER: done with job (2, 0, 0), trying to register it.
07:30:26 WORKER: registered result for job (2, 0, 0) with dispatcher
07:30:26 DISPATCHER: job (2, 0, 0) finished
07:30:26 DISPATCHER: register_result: lock acquired
07:30:26 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
07:30:26 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 60, 'last_n_outputs': 4, 'lr': 0.0016154642221105453, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.018136245965912668}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': 0.004767774063111019, 'info': {'data03': -0.004767774063111019, 'config': "{'batch_size': 128, 'hidden_dim': 60, 'last_n_outputs': 4, 'lr': 0.0016154642221105453, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.018136245965912668}"}}
exception: None

07:30:26 job_callback for (2, 0, 0) started
07:30:26 DISPATCHER: Trying to submit another job.
07:30:26 job_callback for (2, 0, 0) got condition
07:30:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:30:26 Only 3 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
07:30:26 HBMASTER: Trying to run another job!
07:30:26 job_callback for (2, 0, 0) finished
07:30:26 HBMASTER: schedule new run for iteration 2
07:30:26 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
07:30:26 HBMASTER: submitting job (2, 0, 2) to dispatcher
07:30:26 DISPATCHER: trying to submit job (2, 0, 2)
07:30:26 DISPATCHER: trying to notify the job_runner thread.
07:30:26 HBMASTER: job (2, 0, 2) submitted to dispatcher
07:30:26 DISPATCHER: Trying to submit another job.
07:30:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:30:26 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
07:30:26 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
07:30:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:30:26 WORKER: start processing job (2, 0, 2)
07:30:26 WORKER: args: ()
07:30:26 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 92, 'last_n_outputs': 43, 'lr': 0.00743697404089649, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.0350467148943146}, 'budget': 1200.0, 'working_directory': '.'}
07:31:05 DISPATCHER: Starting worker discovery
07:31:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:31:05 DISPATCHER: Finished worker discovery
Exception in thread Thread-466:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:32:05 DISPATCHER: Starting worker discovery
07:32:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:32:05 DISPATCHER: Finished worker discovery
07:33:05 DISPATCHER: Starting worker discovery
07:33:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:33:05 DISPATCHER: Finished worker discovery
07:34:05 DISPATCHER: Starting worker discovery
07:34:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:34:05 DISPATCHER: Finished worker discovery
07:35:05 DISPATCHER: Starting worker discovery
07:35:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:35:05 DISPATCHER: Finished worker discovery
07:36:05 DISPATCHER: Starting worker discovery
07:36:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:36:05 DISPATCHER: Finished worker discovery
07:37:05 DISPATCHER: Starting worker discovery
07:37:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:37:05 DISPATCHER: Finished worker discovery
07:38:05 DISPATCHER: Starting worker discovery
07:38:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:38:05 DISPATCHER: Finished worker discovery
07:39:05 DISPATCHER: Starting worker discovery
07:39:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:39:05 DISPATCHER: Finished worker discovery
07:40:05 DISPATCHER: Starting worker discovery
07:40:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:40:05 DISPATCHER: Finished worker discovery
07:41:05 DISPATCHER: Starting worker discovery
07:41:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:41:05 DISPATCHER: Finished worker discovery
07:42:05 DISPATCHER: Starting worker discovery
07:42:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:42:05 DISPATCHER: Finished worker discovery
07:43:05 DISPATCHER: Starting worker discovery
07:43:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:43:05 DISPATCHER: Finished worker discovery
07:44:05 DISPATCHER: Starting worker discovery
07:44:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:44:05 DISPATCHER: Finished worker discovery
07:45:05 DISPATCHER: Starting worker discovery
07:45:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:45:05 DISPATCHER: Finished worker discovery
07:46:05 DISPATCHER: Starting worker discovery
07:46:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:46:05 DISPATCHER: Finished worker discovery
07:47:05 DISPATCHER: Starting worker discovery
07:47:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:47:05 DISPATCHER: Finished worker discovery
07:48:05 DISPATCHER: Starting worker discovery
07:48:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:48:05 DISPATCHER: Finished worker discovery
07:49:05 DISPATCHER: Starting worker discovery
07:49:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:49:05 DISPATCHER: Finished worker discovery
07:50:05 DISPATCHER: Starting worker discovery
07:50:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:50:05 DISPATCHER: Finished worker discovery
07:51:05 DISPATCHER: Starting worker discovery
07:51:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:51:05 DISPATCHER: Finished worker discovery
07:51:08 WORKER: done with job (2, 0, 2), trying to register it.
07:51:08 WORKER: registered result for job (2, 0, 2) with dispatcher
07:51:08 DISPATCHER: job (2, 0, 2) finished
07:51:08 DISPATCHER: register_result: lock acquired
07:51:08 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
07:51:08 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 92, 'last_n_outputs': 43, 'lr': 0.00743697404089649, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.0350467148943146}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.27804495379688093, 'info': {'data03': 0.27804495379688093, 'config': "{'batch_size': 64, 'hidden_dim': 92, 'last_n_outputs': 43, 'lr': 0.00743697404089649, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.0350467148943146}"}}
exception: None

07:51:08 job_callback for (2, 0, 2) started
07:51:08 job_callback for (2, 0, 2) got condition
07:51:08 DISPATCHER: Trying to submit another job.
07:51:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:51:08 Only 4 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
07:51:08 HBMASTER: Trying to run another job!
07:51:08 job_callback for (2, 0, 2) finished
07:51:08 start sampling a new configuration.
07:51:08 best_vector: [1, 0.5336084942299912, 0.9401330020981613, 0.2364000427051705, 0.08832722520139984, 1, 0.8743816044294401, 0.9666539147453558], 2.0094051181067112e-06, 3.534342219017778, 7.101925344034953e-06
07:51:08 done sampling a new configuration.
07:51:09 HBMASTER: schedule new run for iteration 3
07:51:09 HBMASTER: trying submitting job (3, 0, 0) to dispatcher
07:51:09 HBMASTER: submitting job (3, 0, 0) to dispatcher
07:51:09 DISPATCHER: trying to submit job (3, 0, 0)
07:51:09 DISPATCHER: trying to notify the job_runner thread.
07:51:09 HBMASTER: job (3, 0, 0) submitted to dispatcher
07:51:09 DISPATCHER: Trying to submit another job.
07:51:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:51:09 DISPATCHER: starting job (3, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
07:51:09 DISPATCHER: job (3, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
07:51:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:51:09 WORKER: start processing job (3, 0, 0)
07:51:09 WORKER: args: ()
07:51:09 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 63, 'last_n_outputs': 48, 'lr': 0.002970298428170294, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.18098631537670598}, 'budget': 1200.0, 'working_directory': '.'}
07:52:05 DISPATCHER: Starting worker discovery
07:52:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:52:05 DISPATCHER: Finished worker discovery
Exception in thread Thread-467:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:53:05 DISPATCHER: Starting worker discovery
07:53:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:53:05 DISPATCHER: Finished worker discovery
07:54:05 DISPATCHER: Starting worker discovery
07:54:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:54:05 DISPATCHER: Finished worker discovery
07:55:05 DISPATCHER: Starting worker discovery
07:55:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:55:05 DISPATCHER: Finished worker discovery
07:56:05 DISPATCHER: Starting worker discovery
07:56:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:56:05 DISPATCHER: Finished worker discovery
07:57:05 DISPATCHER: Starting worker discovery
07:57:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:57:05 DISPATCHER: Finished worker discovery
07:58:05 DISPATCHER: Starting worker discovery
07:58:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:58:05 DISPATCHER: Finished worker discovery
07:59:05 DISPATCHER: Starting worker discovery
07:59:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:59:05 DISPATCHER: Finished worker discovery
08:00:05 DISPATCHER: Starting worker discovery
08:00:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:00:05 DISPATCHER: Finished worker discovery
08:01:05 DISPATCHER: Starting worker discovery
08:01:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:01:05 DISPATCHER: Finished worker discovery
08:02:05 DISPATCHER: Starting worker discovery
08:02:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:02:05 DISPATCHER: Finished worker discovery
08:03:05 DISPATCHER: Starting worker discovery
08:03:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:03:05 DISPATCHER: Finished worker discovery
08:04:05 DISPATCHER: Starting worker discovery
08:04:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:04:05 DISPATCHER: Finished worker discovery
08:05:05 DISPATCHER: Starting worker discovery
08:05:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:05:05 DISPATCHER: Finished worker discovery
08:06:05 DISPATCHER: Starting worker discovery
08:06:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:06:05 DISPATCHER: Finished worker discovery
08:07:05 DISPATCHER: Starting worker discovery
08:07:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:07:05 DISPATCHER: Finished worker discovery
08:08:05 DISPATCHER: Starting worker discovery
08:08:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:08:05 DISPATCHER: Finished worker discovery
08:09:05 DISPATCHER: Starting worker discovery
08:09:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:09:05 DISPATCHER: Finished worker discovery
08:10:05 DISPATCHER: Starting worker discovery
08:10:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:10:05 DISPATCHER: Finished worker discovery
08:11:05 DISPATCHER: Starting worker discovery
08:11:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:11:05 DISPATCHER: Finished worker discovery
08:11:56 WORKER: done with job (3, 0, 0), trying to register it.
08:11:56 WORKER: registered result for job (3, 0, 0) with dispatcher
08:11:56 DISPATCHER: job (3, 0, 0) finished
08:11:56 DISPATCHER: register_result: lock acquired
08:11:56 DISPATCHER: job (3, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
08:11:56 job_id: (3, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 63, 'last_n_outputs': 48, 'lr': 0.002970298428170294, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.18098631537670598}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 63, 'last_n_outputs': 48, 'lr': 0.002970298428170294, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.18098631537670598}"}}
exception: None

08:11:56 job_callback for (3, 0, 0) started
08:11:56 job_callback for (3, 0, 0) got condition
08:11:56 DISPATCHER: Trying to submit another job.
08:11:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:11:56 Only 5 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
08:11:56 HBMASTER: Trying to run another job!
08:11:56 job_callback for (3, 0, 0) finished
08:11:56 start sampling a new configuration.
08:11:56 best_vector: [3, 0.8757968911478138, 0.8210924423051564, 0.3305314481929585, 0.009481738142790297, 1, 0.9189490300602681, 0.5840084181316372], 2.840339595676592e-32, 0.35207057688529386, -0.0005468378509793906
08:11:56 done sampling a new configuration.
08:11:56 HBMASTER: schedule new run for iteration 3
08:11:56 HBMASTER: trying submitting job (3, 0, 1) to dispatcher
08:11:56 HBMASTER: submitting job (3, 0, 1) to dispatcher
08:11:56 DISPATCHER: trying to submit job (3, 0, 1)
08:11:56 DISPATCHER: trying to notify the job_runner thread.
08:11:56 HBMASTER: job (3, 0, 1) submitted to dispatcher
08:11:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:11:56 DISPATCHER: Trying to submit another job.
08:11:56 DISPATCHER: starting job (3, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
08:11:56 DISPATCHER: job (3, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
08:11:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:11:56 WORKER: start processing job (3, 0, 1)
08:11:56 WORKER: args: ()
08:11:56 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 90, 'last_n_outputs': 42, 'lr': 0.004582082415884794, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.05751915134498803}, 'budget': 1200.0, 'working_directory': '.'}
08:12:05 DISPATCHER: Starting worker discovery
08:12:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:12:05 DISPATCHER: Finished worker discovery
Exception in thread Thread-468:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:13:05 DISPATCHER: Starting worker discovery
08:13:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:13:05 DISPATCHER: Finished worker discovery
08:14:05 DISPATCHER: Starting worker discovery
08:14:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:14:05 DISPATCHER: Finished worker discovery
08:15:05 DISPATCHER: Starting worker discovery
08:15:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:15:05 DISPATCHER: Finished worker discovery
08:16:05 DISPATCHER: Starting worker discovery
08:16:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:16:05 DISPATCHER: Finished worker discovery
08:17:05 DISPATCHER: Starting worker discovery
08:17:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:17:05 DISPATCHER: Finished worker discovery
08:18:05 DISPATCHER: Starting worker discovery
08:18:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:18:05 DISPATCHER: Finished worker discovery
08:19:05 DISPATCHER: Starting worker discovery
08:19:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:19:05 DISPATCHER: Finished worker discovery
08:20:05 DISPATCHER: Starting worker discovery
08:20:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:20:05 DISPATCHER: Finished worker discovery
08:21:05 DISPATCHER: Starting worker discovery
08:21:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:21:05 DISPATCHER: Finished worker discovery
08:22:05 DISPATCHER: Starting worker discovery
08:22:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:22:05 DISPATCHER: Finished worker discovery
08:23:05 DISPATCHER: Starting worker discovery
08:23:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:23:05 DISPATCHER: Finished worker discovery
08:24:05 DISPATCHER: Starting worker discovery
08:24:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:24:05 DISPATCHER: Finished worker discovery
08:25:05 DISPATCHER: Starting worker discovery
08:25:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:25:05 DISPATCHER: Finished worker discovery
08:26:05 DISPATCHER: Starting worker discovery
08:26:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:26:05 DISPATCHER: Finished worker discovery
08:27:05 DISPATCHER: Starting worker discovery
08:27:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:27:05 DISPATCHER: Finished worker discovery
08:28:05 DISPATCHER: Starting worker discovery
08:28:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:28:05 DISPATCHER: Finished worker discovery
08:29:05 DISPATCHER: Starting worker discovery
08:29:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:29:05 DISPATCHER: Finished worker discovery
08:30:05 DISPATCHER: Starting worker discovery
08:30:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:30:05 DISPATCHER: Finished worker discovery
08:31:05 DISPATCHER: Starting worker discovery
08:31:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:31:05 DISPATCHER: Finished worker discovery
08:32:05 DISPATCHER: Starting worker discovery
08:32:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:32:05 DISPATCHER: Finished worker discovery
08:32:36 WORKER: done with job (3, 0, 1), trying to register it.
08:32:36 WORKER: registered result for job (3, 0, 1) with dispatcher
08:32:36 DISPATCHER: job (3, 0, 1) finished
08:32:36 DISPATCHER: register_result: lock acquired
08:32:36 DISPATCHER: job (3, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
08:32:36 job_id: (3, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 90, 'last_n_outputs': 42, 'lr': 0.004582082415884794, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.05751915134498803}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 90, 'last_n_outputs': 42, 'lr': 0.004582082415884794, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.05751915134498803}"}}
exception: None

08:32:36 job_callback for (3, 0, 1) started
08:32:36 DISPATCHER: Trying to submit another job.
08:32:36 job_callback for (3, 0, 1) got condition
08:32:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:32:36 Only 6 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
08:32:36 HBMASTER: Trying to run another job!
08:32:36 job_callback for (3, 0, 1) finished
08:32:36 start sampling a new configuration.
08:32:36 best_vector: [1, 0.323323068500702, 0.5745229901070641, 0.4577186733288053, 0.3774582272822734, 0, 0.665981774944831, 0.782539516865137], 6.932679152627636e-32, 0.1442443791187103, -0.0011325498547266426
08:32:36 done sampling a new configuration.
08:32:36 HBMASTER: schedule new run for iteration 3
08:32:36 HBMASTER: trying submitting job (3, 0, 2) to dispatcher
08:32:36 HBMASTER: submitting job (3, 0, 2) to dispatcher
08:32:36 DISPATCHER: trying to submit job (3, 0, 2)
08:32:36 DISPATCHER: trying to notify the job_runner thread.
08:32:36 HBMASTER: job (3, 0, 2) submitted to dispatcher
08:32:36 DISPATCHER: Trying to submit another job.
08:32:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:32:36 DISPATCHER: starting job (3, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
08:32:36 DISPATCHER: job (3, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
08:32:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:32:36 WORKER: start processing job (3, 0, 2)
08:32:36 WORKER: args: ()
08:32:36 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 46, 'last_n_outputs': 29, 'lr': 0.0082307108829169, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.10425751860590603}, 'budget': 1200.0, 'working_directory': '.'}
08:33:05 DISPATCHER: Starting worker discovery
08:33:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:33:05 DISPATCHER: Finished worker discovery
Exception in thread Thread-469:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:34:05 DISPATCHER: Starting worker discovery
08:34:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:34:05 DISPATCHER: Finished worker discovery
08:35:05 DISPATCHER: Starting worker discovery
08:35:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:35:05 DISPATCHER: Finished worker discovery
08:36:05 DISPATCHER: Starting worker discovery
08:36:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:36:05 DISPATCHER: Finished worker discovery
08:37:05 DISPATCHER: Starting worker discovery
08:37:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:37:05 DISPATCHER: Finished worker discovery
08:38:05 DISPATCHER: Starting worker discovery
08:38:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:38:05 DISPATCHER: Finished worker discovery
08:39:05 DISPATCHER: Starting worker discovery
08:39:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:39:05 DISPATCHER: Finished worker discovery
08:40:05 DISPATCHER: Starting worker discovery
08:40:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:40:05 DISPATCHER: Finished worker discovery
08:41:05 DISPATCHER: Starting worker discovery
08:41:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:41:05 DISPATCHER: Finished worker discovery
08:42:05 DISPATCHER: Starting worker discovery
08:42:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:42:05 DISPATCHER: Finished worker discovery
08:43:05 DISPATCHER: Starting worker discovery
08:43:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:43:05 DISPATCHER: Finished worker discovery
08:44:05 DISPATCHER: Starting worker discovery
08:44:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:44:05 DISPATCHER: Finished worker discovery
08:45:05 DISPATCHER: Starting worker discovery
08:45:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:45:05 DISPATCHER: Finished worker discovery
08:46:05 DISPATCHER: Starting worker discovery
08:46:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:46:05 DISPATCHER: Finished worker discovery
08:47:05 DISPATCHER: Starting worker discovery
08:47:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:47:05 DISPATCHER: Finished worker discovery
08:48:05 DISPATCHER: Starting worker discovery
08:48:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:48:05 DISPATCHER: Finished worker discovery
08:49:05 DISPATCHER: Starting worker discovery
08:49:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:49:05 DISPATCHER: Finished worker discovery
08:50:05 DISPATCHER: Starting worker discovery
08:50:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:50:05 DISPATCHER: Finished worker discovery
08:51:05 DISPATCHER: Starting worker discovery
08:51:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:51:05 DISPATCHER: Finished worker discovery
08:52:05 DISPATCHER: Starting worker discovery
08:52:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:52:05 DISPATCHER: Finished worker discovery
08:53:05 DISPATCHER: Starting worker discovery
08:53:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:53:05 DISPATCHER: Finished worker discovery
08:53:14 WORKER: done with job (3, 0, 2), trying to register it.
08:53:14 WORKER: registered result for job (3, 0, 2) with dispatcher
08:53:14 DISPATCHER: job (3, 0, 2) finished
08:53:14 DISPATCHER: register_result: lock acquired
08:53:14 DISPATCHER: job (3, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
08:53:14 job_id: (3, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 46, 'last_n_outputs': 29, 'lr': 0.0082307108829169, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.10425751860590603}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 46, 'last_n_outputs': 29, 'lr': 0.0082307108829169, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.10425751860590603}"}}
exception: None

08:53:14 job_callback for (3, 0, 2) started
08:53:14 DISPATCHER: Trying to submit another job.
08:53:14 job_callback for (3, 0, 2) got condition
08:53:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:53:14 Only 7 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
08:53:14 HBMASTER: Trying to run another job!
08:53:14 job_callback for (3, 0, 2) finished
08:53:14 start sampling a new configuration.
08:53:15 best_vector: [1, 0.29433902247601035, 0.8722973680872474, 0.7772474366379655, 0.21433889017252974, 0, 0.8293259694407508, 0.5224158079609], 3.4389996858651364e-32, 0.2907822306905602, -0.012848553948236542
08:53:15 done sampling a new configuration.
08:53:15 HBMASTER: schedule new run for iteration 3
08:53:15 HBMASTER: trying submitting job (3, 0, 3) to dispatcher
08:53:15 HBMASTER: submitting job (3, 0, 3) to dispatcher
08:53:15 DISPATCHER: trying to submit job (3, 0, 3)
08:53:15 DISPATCHER: trying to notify the job_runner thread.
08:53:15 HBMASTER: job (3, 0, 3) submitted to dispatcher
08:53:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:53:15 DISPATCHER: Trying to submit another job.
08:53:15 DISPATCHER: starting job (3, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
08:53:15 DISPATCHER: job (3, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
08:53:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:53:15 WORKER: start processing job (3, 0, 3)
08:53:15 WORKER: args: ()
08:53:15 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 43, 'last_n_outputs': 44, 'lr': 0.03585047162043499, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.04782760528001279}, 'budget': 1200.0, 'working_directory': '.'}
08:54:05 DISPATCHER: Starting worker discovery
08:54:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:54:05 DISPATCHER: Finished worker discovery
Exception in thread Thread-470:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:55:05 DISPATCHER: Starting worker discovery
08:55:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:55:05 DISPATCHER: Finished worker discovery
08:56:05 DISPATCHER: Starting worker discovery
08:56:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:56:05 DISPATCHER: Finished worker discovery
08:57:05 DISPATCHER: Starting worker discovery
08:57:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:57:05 DISPATCHER: Finished worker discovery
08:58:05 DISPATCHER: Starting worker discovery
08:58:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:58:05 DISPATCHER: Finished worker discovery
08:59:05 DISPATCHER: Starting worker discovery
08:59:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:59:05 DISPATCHER: Finished worker discovery
09:00:05 DISPATCHER: Starting worker discovery
09:00:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:00:05 DISPATCHER: Finished worker discovery
09:01:05 DISPATCHER: Starting worker discovery
09:01:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:01:05 DISPATCHER: Finished worker discovery
09:02:05 DISPATCHER: Starting worker discovery
09:02:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:02:05 DISPATCHER: Finished worker discovery
09:03:05 DISPATCHER: Starting worker discovery
09:03:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:03:05 DISPATCHER: Finished worker discovery
09:04:05 DISPATCHER: Starting worker discovery
09:04:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:04:05 DISPATCHER: Finished worker discovery
09:05:05 DISPATCHER: Starting worker discovery
09:05:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:05:05 DISPATCHER: Finished worker discovery
09:06:05 DISPATCHER: Starting worker discovery
09:06:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:06:05 DISPATCHER: Finished worker discovery
09:07:05 DISPATCHER: Starting worker discovery
09:07:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:07:05 DISPATCHER: Finished worker discovery
09:08:05 DISPATCHER: Starting worker discovery
09:08:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:08:05 DISPATCHER: Finished worker discovery
09:09:05 DISPATCHER: Starting worker discovery
09:09:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:09:06 DISPATCHER: Finished worker discovery
09:10:06 DISPATCHER: Starting worker discovery
09:10:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:10:06 DISPATCHER: Finished worker discovery
09:11:06 DISPATCHER: Starting worker discovery
09:11:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:11:06 DISPATCHER: Finished worker discovery
09:12:06 DISPATCHER: Starting worker discovery
09:12:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:12:06 DISPATCHER: Finished worker discovery
09:13:06 DISPATCHER: Starting worker discovery
09:13:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:13:06 DISPATCHER: Finished worker discovery
09:13:55 WORKER: done with job (3, 0, 3), trying to register it.
09:13:55 WORKER: registered result for job (3, 0, 3) with dispatcher
09:13:55 DISPATCHER: job (3, 0, 3) finished
09:13:55 DISPATCHER: register_result: lock acquired
09:13:55 DISPATCHER: job (3, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
09:13:55 job_id: (3, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 43, 'last_n_outputs': 44, 'lr': 0.03585047162043499, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.04782760528001279}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 43, 'last_n_outputs': 44, 'lr': 0.03585047162043499, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.04782760528001279}"}}
exception: None

09:13:55 job_callback for (3, 0, 3) started
09:13:55 job_callback for (3, 0, 3) got condition
09:13:55 DISPATCHER: Trying to submit another job.
09:13:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:13:55 Only 8 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
09:13:55 HBMASTER: Trying to run another job!
09:13:55 job_callback for (3, 0, 3) finished
09:13:55 start sampling a new configuration.
09:13:55 best_vector: [3, 0.9578520835729076, 0.5818856200464534, 0.11732410268278642, 0.065189773476617, 0, 0.7337246102221673, 0.7059761873778325], 4.432649610961248e-32, 0.225598702303732, -0.0028262964154285738
09:13:55 done sampling a new configuration.
09:13:55 HBMASTER: schedule new run for iteration 4
09:13:55 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
09:13:55 HBMASTER: submitting job (4, 0, 0) to dispatcher
09:13:55 DISPATCHER: trying to submit job (4, 0, 0)
09:13:55 DISPATCHER: trying to notify the job_runner thread.
09:13:55 HBMASTER: job (4, 0, 0) submitted to dispatcher
09:13:55 DISPATCHER: Trying to submit another job.
09:13:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:13:55 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
09:13:55 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
09:13:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:13:55 WORKER: start processing job (4, 0, 0)
09:13:55 WORKER: args: ()
09:13:55 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 30, 'lr': 0.0017165173811214782, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.08288886559834752}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:14:06 DISPATCHER: Starting worker discovery
09:14:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:14:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-471:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:15:06 DISPATCHER: Starting worker discovery
09:15:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:15:06 DISPATCHER: Finished worker discovery
09:15:17 WORKER: done with job (4, 0, 0), trying to register it.
09:15:17 WORKER: registered result for job (4, 0, 0) with dispatcher
09:15:17 DISPATCHER: job (4, 0, 0) finished
09:15:17 DISPATCHER: register_result: lock acquired
09:15:17 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
09:15:17 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 30, 'lr': 0.0017165173811214782, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.08288886559834752}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.301820228856165, 'info': {'data03': 0.301820228856165, 'config': "{'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 30, 'lr': 0.0017165173811214782, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.08288886559834752}"}}
exception: None

09:15:17 job_callback for (4, 0, 0) started
09:15:17 DISPATCHER: Trying to submit another job.
09:15:17 job_callback for (4, 0, 0) got condition
09:15:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:15:17 HBMASTER: Trying to run another job!
09:15:17 job_callback for (4, 0, 0) finished
09:15:17 start sampling a new configuration.
09:15:17 best_vector: [1, 0.00278944241728607, 0.5598452757177672, 0.47560056137286144, 0.28472939556751875, 0, 0.9643901402024615, 0.8880717996601658], 6.03215539403269e-32, 0.1657782226547496, -0.010304151338051348
09:15:17 done sampling a new configuration.
09:15:17 HBMASTER: schedule new run for iteration 4
09:15:17 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
09:15:17 HBMASTER: submitting job (4, 0, 1) to dispatcher
09:15:17 DISPATCHER: trying to submit job (4, 0, 1)
09:15:17 DISPATCHER: trying to notify the job_runner thread.
09:15:17 HBMASTER: job (4, 0, 1) submitted to dispatcher
09:15:17 DISPATCHER: Trying to submit another job.
09:15:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:15:17 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
09:15:17 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
09:15:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:15:17 WORKER: start processing job (4, 0, 1)
09:15:17 WORKER: args: ()
09:15:17 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 20, 'last_n_outputs': 28, 'lr': 0.008937192713059698, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.14302371339788064}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:16:06 DISPATCHER: Starting worker discovery
09:16:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:16:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-472:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:16:38 WORKER: done with job (4, 0, 1), trying to register it.
09:16:38 WORKER: registered result for job (4, 0, 1) with dispatcher
09:16:38 DISPATCHER: job (4, 0, 1) finished
09:16:38 DISPATCHER: register_result: lock acquired
09:16:38 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
09:16:38 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 20, 'last_n_outputs': 28, 'lr': 0.008937192713059698, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.14302371339788064}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 20, 'last_n_outputs': 28, 'lr': 0.008937192713059698, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.14302371339788064}"}}
exception: None

09:16:38 job_callback for (4, 0, 1) started
09:16:38 DISPATCHER: Trying to submit another job.
09:16:38 job_callback for (4, 0, 1) got condition
09:16:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:16:38 HBMASTER: Trying to run another job!
09:16:38 job_callback for (4, 0, 1) finished
09:16:38 start sampling a new configuration.
09:16:38 best_vector: [1, 0.1746058073024875, 0.6323464030406668, 0.47655347451494545, 0.08362049118825877, 0, 0.7499978415031624, 0.8680346550572614], 4.999017282775146e-32, 0.20003931641637812, -0.009780784050881024
09:16:38 done sampling a new configuration.
09:16:38 HBMASTER: schedule new run for iteration 4
09:16:38 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
09:16:38 HBMASTER: submitting job (4, 0, 2) to dispatcher
09:16:38 DISPATCHER: trying to submit job (4, 0, 2)
09:16:38 DISPATCHER: trying to notify the job_runner thread.
09:16:38 HBMASTER: job (4, 0, 2) submitted to dispatcher
09:16:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:16:38 DISPATCHER: Trying to submit another job.
09:16:38 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
09:16:38 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
09:16:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:16:38 WORKER: start processing job (4, 0, 2)
09:16:38 WORKER: args: ()
09:16:38 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 34, 'last_n_outputs': 32, 'lr': 0.008976498218492716, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.13469116939734982}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:17:06 DISPATCHER: Starting worker discovery
09:17:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:17:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-473:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:18:01 WORKER: done with job (4, 0, 2), trying to register it.
09:18:01 WORKER: registered result for job (4, 0, 2) with dispatcher
09:18:01 DISPATCHER: job (4, 0, 2) finished
09:18:01 DISPATCHER: register_result: lock acquired
09:18:01 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
09:18:01 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 34, 'last_n_outputs': 32, 'lr': 0.008976498218492716, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.13469116939734982}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1488663097243359, 'info': {'data03': 0.1488663097243359, 'config': "{'batch_size': 32, 'hidden_dim': 34, 'last_n_outputs': 32, 'lr': 0.008976498218492716, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.13469116939734982}"}}
exception: None

09:18:01 job_callback for (4, 0, 2) started
09:18:01 DISPATCHER: Trying to submit another job.
09:18:01 job_callback for (4, 0, 2) got condition
09:18:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:18:01 HBMASTER: Trying to run another job!
09:18:01 job_callback for (4, 0, 2) finished
09:18:01 start sampling a new configuration.
09:18:01 best_vector: [3, 0.6359983034047484, 0.9457566673722562, 0.08252972985044539, 0.04997839870869271, 0, 0.7894814524703644, 0.06581328041086948], 0.0001793100224395592, 5.692574045514131, 0.0010207355798399912
09:18:01 done sampling a new configuration.
09:18:01 HBMASTER: schedule new run for iteration 4
09:18:01 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
09:18:01 HBMASTER: submitting job (4, 0, 3) to dispatcher
09:18:01 DISPATCHER: trying to submit job (4, 0, 3)
09:18:01 DISPATCHER: trying to notify the job_runner thread.
09:18:01 HBMASTER: job (4, 0, 3) submitted to dispatcher
09:18:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:18:01 DISPATCHER: Trying to submit another job.
09:18:01 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
09:18:01 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
09:18:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:18:01 WORKER: start processing job (4, 0, 3)
09:18:01 WORKER: args: ()
09:18:01 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 71, 'last_n_outputs': 48, 'lr': 0.0014623773763310255, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.012179376386172322}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:18:06 DISPATCHER: Starting worker discovery
09:18:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:18:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-474:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:19:06 DISPATCHER: Starting worker discovery
09:19:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:19:06 DISPATCHER: Finished worker discovery
09:19:22 WORKER: done with job (4, 0, 3), trying to register it.
09:19:22 WORKER: registered result for job (4, 0, 3) with dispatcher
09:19:22 DISPATCHER: job (4, 0, 3) finished
09:19:22 DISPATCHER: register_result: lock acquired
09:19:22 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
09:19:22 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 71, 'last_n_outputs': 48, 'lr': 0.0014623773763310255, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.012179376386172322}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.29298168698787935, 'info': {'data03': 0.29298168698787935, 'config': "{'batch_size': 128, 'hidden_dim': 71, 'last_n_outputs': 48, 'lr': 0.0014623773763310255, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.012179376386172322}"}}
exception: None

09:19:22 job_callback for (4, 0, 3) started
09:19:22 DISPATCHER: Trying to submit another job.
09:19:22 job_callback for (4, 0, 3) got condition
09:19:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:19:22 HBMASTER: Trying to run another job!
09:19:22 job_callback for (4, 0, 3) finished
09:19:22 start sampling a new configuration.
09:19:22 best_vector: [1, 0.055886961205236285, 0.8408721291650784, 0.3300413623935567, 0.2678324848981736, 0, 0.9746579790292297, 0.9155682551087512], 7.279743498833668e-33, 1.3736747732392167, -0.005018101204433792
09:19:22 done sampling a new configuration.
09:19:22 HBMASTER: schedule new run for iteration 4
09:19:22 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
09:19:22 HBMASTER: submitting job (4, 0, 4) to dispatcher
09:19:22 DISPATCHER: trying to submit job (4, 0, 4)
09:19:22 DISPATCHER: trying to notify the job_runner thread.
09:19:22 HBMASTER: job (4, 0, 4) submitted to dispatcher
09:19:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:19:22 DISPATCHER: Trying to submit another job.
09:19:22 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
09:19:22 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
09:19:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:19:22 WORKER: start processing job (4, 0, 4)
09:19:22 WORKER: args: ()
09:19:22 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 24, 'last_n_outputs': 43, 'lr': 0.004571752644598557, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.1553036858268129}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:20:06 DISPATCHER: Starting worker discovery
09:20:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:20:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-475:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:20:44 WORKER: done with job (4, 0, 4), trying to register it.
09:20:44 WORKER: registered result for job (4, 0, 4) with dispatcher
09:20:44 DISPATCHER: job (4, 0, 4) finished
09:20:44 DISPATCHER: register_result: lock acquired
09:20:44 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
09:20:44 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 24, 'last_n_outputs': 43, 'lr': 0.004571752644598557, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.1553036858268129}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 24, 'last_n_outputs': 43, 'lr': 0.004571752644598557, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.1553036858268129}"}}
exception: None

09:20:44 job_callback for (4, 0, 4) started
09:20:44 DISPATCHER: Trying to submit another job.
09:20:44 job_callback for (4, 0, 4) got condition
09:20:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:20:44 HBMASTER: Trying to run another job!
09:20:44 job_callback for (4, 0, 4) finished
09:20:44 start sampling a new configuration.
09:20:44 done sampling a new configuration.
09:20:44 HBMASTER: schedule new run for iteration 4
09:20:44 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
09:20:44 HBMASTER: submitting job (4, 0, 5) to dispatcher
09:20:44 DISPATCHER: trying to submit job (4, 0, 5)
09:20:44 DISPATCHER: trying to notify the job_runner thread.
09:20:44 HBMASTER: job (4, 0, 5) submitted to dispatcher
09:20:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:20:44 DISPATCHER: Trying to submit another job.
09:20:44 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
09:20:44 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
09:20:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:20:44 WORKER: start processing job (4, 0, 5)
09:20:44 WORKER: args: ()
09:20:44 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 86, 'last_n_outputs': 47, 'lr': 0.01769089166543606, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.013377378953612922}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:21:06 DISPATCHER: Starting worker discovery
09:21:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:21:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-476:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:22:02 WORKER: done with job (4, 0, 5), trying to register it.
09:22:02 WORKER: registered result for job (4, 0, 5) with dispatcher
09:22:02 DISPATCHER: job (4, 0, 5) finished
09:22:02 DISPATCHER: register_result: lock acquired
09:22:02 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
09:22:02 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 86, 'last_n_outputs': 47, 'lr': 0.01769089166543606, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.013377378953612922}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 86, 'last_n_outputs': 47, 'lr': 0.01769089166543606, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.013377378953612922}"}}
exception: None

09:22:02 job_callback for (4, 0, 5) started
09:22:02 job_callback for (4, 0, 5) got condition
09:22:02 DISPATCHER: Trying to submit another job.
09:22:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:22:02 HBMASTER: Trying to run another job!
09:22:02 job_callback for (4, 0, 5) finished
09:22:02 start sampling a new configuration.
09:22:02 best_vector: [3, 0.6568255255135584, 0.8208544431293835, 0.20115309085984673, 0.004256940142553095, 0, 0.897856545559936, 0.1577830501490402], 5.9505910393327415e-33, 1.6805053370162928, -0.002408783985696933
09:22:02 done sampling a new configuration.
09:22:02 HBMASTER: schedule new run for iteration 4
09:22:02 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
09:22:02 HBMASTER: submitting job (4, 0, 6) to dispatcher
09:22:02 DISPATCHER: trying to submit job (4, 0, 6)
09:22:02 DISPATCHER: trying to notify the job_runner thread.
09:22:02 HBMASTER: job (4, 0, 6) submitted to dispatcher
09:22:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:22:02 DISPATCHER: Trying to submit another job.
09:22:02 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776
09:22:02 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
09:22:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:22:02 WORKER: start processing job (4, 0, 6)
09:22:02 WORKER: args: ()
09:22:02 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 73, 'last_n_outputs': 42, 'lr': 0.002525260477586925, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.016042811514729822}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:22:06 DISPATCHER: Starting worker discovery
09:22:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:22:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-477:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:23:06 DISPATCHER: Starting worker discovery
09:23:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:23:06 DISPATCHER: Finished worker discovery
09:23:21 WORKER: done with job (4, 0, 6), trying to register it.
09:23:21 WORKER: registered result for job (4, 0, 6) with dispatcher
09:23:21 DISPATCHER: job (4, 0, 6) finished
09:23:21 DISPATCHER: register_result: lock acquired
09:23:21 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
09:23:21 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 73, 'last_n_outputs': 42, 'lr': 0.002525260477586925, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.016042811514729822}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.20395189995103827, 'info': {'data03': 0.20395189995103827, 'config': "{'batch_size': 128, 'hidden_dim': 73, 'last_n_outputs': 42, 'lr': 0.002525260477586925, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.016042811514729822}"}}
exception: None

09:23:21 job_callback for (4, 0, 6) started
09:23:21 DISPATCHER: Trying to submit another job.
09:23:21 job_callback for (4, 0, 6) got condition
09:23:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:23:21 HBMASTER: Trying to run another job!
09:23:21 job_callback for (4, 0, 6) finished
09:23:21 start sampling a new configuration.
09:23:22 best_vector: [1, 0.006136296465819591, 0.8668375380488755, 0.47201462621587775, 0.11898488882094625, 0, 0.5891409064006761, 0.6808083711800769], 1.0799097946189591e-32, 0.9260032689608535, -0.0036603253552577966
09:23:22 done sampling a new configuration.
09:23:22 HBMASTER: schedule new run for iteration 4
09:23:22 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
09:23:22 HBMASTER: submitting job (4, 0, 7) to dispatcher
09:23:22 DISPATCHER: trying to submit job (4, 0, 7)
09:23:22 DISPATCHER: trying to notify the job_runner thread.
09:23:22 HBMASTER: job (4, 0, 7) submitted to dispatcher
09:23:22 DISPATCHER: Trying to submit another job.
09:23:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:23:22 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776
09:23:22 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
09:23:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:23:22 WORKER: start processing job (4, 0, 7)
09:23:22 WORKER: args: ()
09:23:22 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 20, 'last_n_outputs': 44, 'lr': 0.00879081726453064, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.07686915591690979}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-478:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:24:06 DISPATCHER: Starting worker discovery
09:24:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:24:06 DISPATCHER: Finished worker discovery
09:24:40 WORKER: done with job (4, 0, 7), trying to register it.
09:24:40 WORKER: registered result for job (4, 0, 7) with dispatcher
09:24:40 DISPATCHER: job (4, 0, 7) finished
09:24:40 DISPATCHER: register_result: lock acquired
09:24:40 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
09:24:40 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 20, 'last_n_outputs': 44, 'lr': 0.00879081726453064, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.07686915591690979}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.15074184935954285, 'info': {'data03': 0.15074184935954285, 'config': "{'batch_size': 32, 'hidden_dim': 20, 'last_n_outputs': 44, 'lr': 0.00879081726453064, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.07686915591690979}"}}
exception: None

09:24:40 job_callback for (4, 0, 7) started
09:24:40 DISPATCHER: Trying to submit another job.
09:24:40 job_callback for (4, 0, 7) got condition
09:24:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:24:40 HBMASTER: Trying to run another job!
09:24:40 job_callback for (4, 0, 7) finished
09:24:40 start sampling a new configuration.
09:24:40 best_vector: [1, 0.346283993074508, 0.7845566131809124, 0.9502324892095935, 0.0901507882319354, 0, 0.7856095741819722, 0.8412995548444977], 2.157642992969333e-31, 0.04634687032370481, -0.015346050430521023
09:24:40 done sampling a new configuration.
09:24:40 HBMASTER: schedule new run for iteration 4
09:24:40 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
09:24:40 HBMASTER: submitting job (4, 0, 8) to dispatcher
09:24:40 DISPATCHER: trying to submit job (4, 0, 8)
09:24:40 DISPATCHER: trying to notify the job_runner thread.
09:24:40 HBMASTER: job (4, 0, 8) submitted to dispatcher
09:24:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:24:40 DISPATCHER: Trying to submit another job.
09:24:40 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776
09:24:40 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
09:24:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:24:40 WORKER: start processing job (4, 0, 8)
09:24:40 WORKER: args: ()
09:24:40 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 48, 'last_n_outputs': 40, 'lr': 0.07951791395669405, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.12432428097683501}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:25:06 DISPATCHER: Starting worker discovery
09:25:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:25:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-479:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:25:58 WORKER: done with job (4, 0, 8), trying to register it.
09:25:58 WORKER: registered result for job (4, 0, 8) with dispatcher
09:25:58 DISPATCHER: job (4, 0, 8) finished
09:25:58 DISPATCHER: register_result: lock acquired
09:25:58 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
09:25:58 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 48, 'last_n_outputs': 40, 'lr': 0.07951791395669405, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.12432428097683501}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 48, 'last_n_outputs': 40, 'lr': 0.07951791395669405, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.12432428097683501}"}}
exception: None

09:25:58 job_callback for (4, 0, 8) started
09:25:58 job_callback for (4, 0, 8) got condition
09:25:58 DISPATCHER: Trying to submit another job.
09:25:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:25:58 HBMASTER: Trying to run another job!
09:25:58 job_callback for (4, 0, 8) finished
09:25:58 start sampling a new configuration.
09:25:58 done sampling a new configuration.
09:25:58 HBMASTER: schedule new run for iteration 4
09:25:58 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
09:25:58 HBMASTER: submitting job (4, 0, 9) to dispatcher
09:25:58 DISPATCHER: trying to submit job (4, 0, 9)
09:25:58 DISPATCHER: trying to notify the job_runner thread.
09:25:58 HBMASTER: job (4, 0, 9) submitted to dispatcher
09:25:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:25:58 DISPATCHER: Trying to submit another job.
09:25:58 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpui.1576139975513683776
09:25:58 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
09:25:58 WORKER: start processing job (4, 0, 9)
09:25:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:25:58 WORKER: args: ()
09:25:58 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 70, 'last_n_outputs': 11, 'lr': 0.0019384964656109225, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.06567412369373346}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:26:06 DISPATCHER: Starting worker discovery
09:26:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:26:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-480:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:27:06 DISPATCHER: Starting worker discovery
09:27:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:27:06 DISPATCHER: Finished worker discovery
09:27:16 WORKER: done with job (4, 0, 9), trying to register it.
09:27:16 WORKER: registered result for job (4, 0, 9) with dispatcher
09:27:16 DISPATCHER: job (4, 0, 9) finished
09:27:16 DISPATCHER: register_result: lock acquired
09:27:16 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
09:27:16 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 70, 'last_n_outputs': 11, 'lr': 0.0019384964656109225, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.06567412369373346}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 70, 'last_n_outputs': 11, 'lr': 0.0019384964656109225, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.06567412369373346}"}}
exception: None

09:27:16 job_callback for (4, 0, 9) started
09:27:16 DISPATCHER: Trying to submit another job.
09:27:16 job_callback for (4, 0, 9) got condition
09:27:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:27:16 HBMASTER: Trying to run another job!
09:27:16 job_callback for (4, 0, 9) finished
09:27:16 start sampling a new configuration.
09:27:17 best_vector: [3, 0.9078333859627828, 0.3797793746452575, 0.1809872710299361, 0.09368596584544465, 1, 0.8021330744919011, 0.8411682191471923], 9.953679252204001e-31, 0.010046536307452085, -0.004405332271437788
09:27:17 done sampling a new configuration.
09:27:17 HBMASTER: schedule new run for iteration 4
09:27:17 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
09:27:17 HBMASTER: submitting job (4, 0, 10) to dispatcher
09:27:17 DISPATCHER: trying to submit job (4, 0, 10)
09:27:17 DISPATCHER: trying to notify the job_runner thread.
09:27:17 HBMASTER: job (4, 0, 10) submitted to dispatcher
09:27:17 DISPATCHER: Trying to submit another job.
09:27:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:27:17 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpui.1576139975513683776
09:27:17 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
09:27:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:27:17 WORKER: start processing job (4, 0, 10)
09:27:17 WORKER: args: ()
09:27:17 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 19, 'lr': 0.0023013069129756295, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.12427537563424355}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:28:06 DISPATCHER: Starting worker discovery
09:28:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:28:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-481:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:28:34 WORKER: done with job (4, 0, 10), trying to register it.
09:28:34 WORKER: registered result for job (4, 0, 10) with dispatcher
09:28:34 DISPATCHER: job (4, 0, 10) finished
09:28:34 DISPATCHER: register_result: lock acquired
09:28:34 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
09:28:34 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 19, 'lr': 0.0023013069129756295, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.12427537563424355}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 19, 'lr': 0.0023013069129756295, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.12427537563424355}"}}
exception: None

09:28:34 job_callback for (4, 0, 10) started
09:28:34 job_callback for (4, 0, 10) got condition
09:28:34 DISPATCHER: Trying to submit another job.
09:28:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:28:34 HBMASTER: Trying to run another job!
09:28:34 job_callback for (4, 0, 10) finished
09:28:34 start sampling a new configuration.
09:28:34 best_vector: [1, 0.22572897422705873, 0.8955019545065739, 0.3074058013952595, 0.29246566651962647, 0, 0.9776488956162248, 0.8106881894504282], 3.743305253718786e-33, 2.6714358894630625, -0.0021479280148833666
09:28:34 done sampling a new configuration.
09:28:34 HBMASTER: schedule new run for iteration 4
09:28:34 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
09:28:34 HBMASTER: submitting job (4, 0, 11) to dispatcher
09:28:34 DISPATCHER: trying to submit job (4, 0, 11)
09:28:34 DISPATCHER: trying to notify the job_runner thread.
09:28:34 HBMASTER: job (4, 0, 11) submitted to dispatcher
09:28:34 DISPATCHER: Trying to submit another job.
09:28:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:28:34 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776
09:28:34 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
09:28:34 WORKER: start processing job (4, 0, 11)
09:28:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:28:34 WORKER: args: ()
09:28:34 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 38, 'last_n_outputs': 45, 'lr': 0.0041191878971302874, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.11343044910982283}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:29:06 DISPATCHER: Starting worker discovery
09:29:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:29:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-482:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:29:53 WORKER: done with job (4, 0, 11), trying to register it.
09:29:53 WORKER: registered result for job (4, 0, 11) with dispatcher
09:29:53 DISPATCHER: job (4, 0, 11) finished
09:29:53 DISPATCHER: register_result: lock acquired
09:29:53 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
09:29:53 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 38, 'last_n_outputs': 45, 'lr': 0.0041191878971302874, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.11343044910982283}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 38, 'last_n_outputs': 45, 'lr': 0.0041191878971302874, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.11343044910982283}"}}
exception: None

09:29:53 job_callback for (4, 0, 11) started
09:29:53 DISPATCHER: Trying to submit another job.
09:29:53 job_callback for (4, 0, 11) got condition
09:29:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:29:53 HBMASTER: Trying to run another job!
09:29:53 job_callback for (4, 0, 11) finished
09:29:53 start sampling a new configuration.
09:29:53 best_vector: [0, 0.1402210270707234, 0.888129889911037, 0.45832318176359854, 0.09540334248128202, 1, 0.6598805720504471, 0.024561310392355873], 2.8896403950576564e-33, 3.460638222355856, -0.0003250026211581694
09:29:53 done sampling a new configuration.
09:29:53 HBMASTER: schedule new run for iteration 4
09:29:53 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
09:29:53 HBMASTER: submitting job (4, 0, 12) to dispatcher
09:29:53 DISPATCHER: trying to submit job (4, 0, 12)
09:29:53 DISPATCHER: trying to notify the job_runner thread.
09:29:53 HBMASTER: job (4, 0, 12) submitted to dispatcher
09:29:53 DISPATCHER: Trying to submit another job.
09:29:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:29:53 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpui.1576139975513683776
09:29:53 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
09:29:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:29:53 WORKER: start processing job (4, 0, 12)
09:29:53 WORKER: args: ()
09:29:53 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 31, 'last_n_outputs': 45, 'lr': 0.00825365598766753, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.010763536838839688}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:30:06 DISPATCHER: Starting worker discovery
09:30:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:30:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-483:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:31:06 DISPATCHER: Starting worker discovery
09:31:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:31:06 DISPATCHER: Finished worker discovery
09:31:12 WORKER: done with job (4, 0, 12), trying to register it.
09:31:12 WORKER: registered result for job (4, 0, 12) with dispatcher
09:31:12 DISPATCHER: job (4, 0, 12) finished
09:31:12 DISPATCHER: register_result: lock acquired
09:31:12 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
09:31:12 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 31, 'last_n_outputs': 45, 'lr': 0.00825365598766753, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.010763536838839688}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 31, 'last_n_outputs': 45, 'lr': 0.00825365598766753, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.010763536838839688}"}}
exception: None

09:31:12 job_callback for (4, 0, 12) started
09:31:12 job_callback for (4, 0, 12) got condition
09:31:12 DISPATCHER: Trying to submit another job.
09:31:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:31:12 HBMASTER: Trying to run another job!
09:31:12 job_callback for (4, 0, 12) finished
09:31:12 start sampling a new configuration.
09:31:12 best_vector: [1, 0.2451514711555522, 0.874322721321032, 0.6354067397673175, 0.4026935524701989, 1, 0.6757466207233898, 0.8994270113729456], 4.381964119255517e-32, 0.22820816711066477, -0.040139496973473174
09:31:12 done sampling a new configuration.
09:31:12 HBMASTER: schedule new run for iteration 4
09:31:12 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
09:31:12 HBMASTER: submitting job (4, 0, 13) to dispatcher
09:31:12 DISPATCHER: trying to submit job (4, 0, 13)
09:31:12 DISPATCHER: trying to notify the job_runner thread.
09:31:12 HBMASTER: job (4, 0, 13) submitted to dispatcher
09:31:12 DISPATCHER: Trying to submit another job.
09:31:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:31:12 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpui.1576139975513683776
09:31:12 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
09:31:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:31:12 WORKER: start processing job (4, 0, 13)
09:31:12 WORKER: args: ()
09:31:12 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 39, 'last_n_outputs': 44, 'lr': 0.018655782916022233, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.14797267356915922}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-484:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:32:06 DISPATCHER: Starting worker discovery
09:32:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:32:06 DISPATCHER: Finished worker discovery
09:32:30 WORKER: done with job (4, 0, 13), trying to register it.
09:32:30 WORKER: registered result for job (4, 0, 13) with dispatcher
09:32:30 DISPATCHER: job (4, 0, 13) finished
09:32:30 DISPATCHER: register_result: lock acquired
09:32:30 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
09:32:30 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 39, 'last_n_outputs': 44, 'lr': 0.018655782916022233, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.14797267356915922}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 39, 'last_n_outputs': 44, 'lr': 0.018655782916022233, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.14797267356915922}"}}
exception: None

09:32:30 job_callback for (4, 0, 13) started
09:32:30 DISPATCHER: Trying to submit another job.
09:32:30 job_callback for (4, 0, 13) got condition
09:32:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:32:30 HBMASTER: Trying to run another job!
09:32:30 job_callback for (4, 0, 13) finished
09:32:30 start sampling a new configuration.
09:32:30 done sampling a new configuration.
09:32:30 HBMASTER: schedule new run for iteration 4
09:32:30 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
09:32:30 HBMASTER: submitting job (4, 0, 14) to dispatcher
09:32:30 DISPATCHER: trying to submit job (4, 0, 14)
09:32:30 DISPATCHER: trying to notify the job_runner thread.
09:32:30 HBMASTER: job (4, 0, 14) submitted to dispatcher
09:32:30 DISPATCHER: Trying to submit another job.
09:32:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:32:30 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776
09:32:30 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
09:32:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:32:30 WORKER: start processing job (4, 0, 14)
09:32:30 WORKER: args: ()
09:32:30 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 84, 'last_n_outputs': 23, 'lr': 0.07069380367960798, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.016118423983192683}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:33:06 DISPATCHER: Starting worker discovery
09:33:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:33:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-485:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:33:49 WORKER: done with job (4, 0, 14), trying to register it.
09:33:49 WORKER: registered result for job (4, 0, 14) with dispatcher
09:33:49 DISPATCHER: job (4, 0, 14) finished
09:33:49 DISPATCHER: register_result: lock acquired
09:33:49 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
09:33:49 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 84, 'last_n_outputs': 23, 'lr': 0.07069380367960798, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.016118423983192683}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 84, 'last_n_outputs': 23, 'lr': 0.07069380367960798, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.016118423983192683}"}}
exception: None

09:33:49 job_callback for (4, 0, 14) started
09:33:49 DISPATCHER: Trying to submit another job.
09:33:49 job_callback for (4, 0, 14) got condition
09:33:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:33:49 HBMASTER: Trying to run another job!
09:33:49 job_callback for (4, 0, 14) finished
09:33:49 start sampling a new configuration.
09:33:49 best_vector: [3, 0.887979884963001, 0.592713757588149, 0.3242570720088232, 0.06712528923985615, 0, 0.932186500838075, 0.01598298298200157], 6.796125301162374e-32, 0.1471426666940595, -0.026224793799976272
09:33:49 done sampling a new configuration.
09:33:49 HBMASTER: schedule new run for iteration 4
09:33:49 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
09:33:49 HBMASTER: submitting job (4, 0, 15) to dispatcher
09:33:49 DISPATCHER: trying to submit job (4, 0, 15)
09:33:49 DISPATCHER: trying to notify the job_runner thread.
09:33:49 HBMASTER: job (4, 0, 15) submitted to dispatcher
09:33:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:33:49 DISPATCHER: Trying to submit another job.
09:33:49 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776
09:33:49 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
09:33:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:33:49 WORKER: start processing job (4, 0, 15)
09:33:49 WORKER: args: ()
09:33:49 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 91, 'last_n_outputs': 30, 'lr': 0.004451579605013246, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.01049045536539118}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:34:06 DISPATCHER: Starting worker discovery
09:34:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:34:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-486:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:35:06 DISPATCHER: Starting worker discovery
09:35:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:35:06 DISPATCHER: Finished worker discovery
09:35:07 WORKER: done with job (4, 0, 15), trying to register it.
09:35:07 WORKER: registered result for job (4, 0, 15) with dispatcher
09:35:07 DISPATCHER: job (4, 0, 15) finished
09:35:07 DISPATCHER: register_result: lock acquired
09:35:07 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
09:35:07 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 91, 'last_n_outputs': 30, 'lr': 0.004451579605013246, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.01049045536539118}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.37448444812667464, 'info': {'data03': 0.37448444812667464, 'config': "{'batch_size': 128, 'hidden_dim': 91, 'last_n_outputs': 30, 'lr': 0.004451579605013246, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.01049045536539118}"}}
exception: None

09:35:07 job_callback for (4, 0, 15) started
09:35:07 DISPATCHER: Trying to submit another job.
09:35:07 job_callback for (4, 0, 15) got condition
09:35:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:35:07 HBMASTER: Trying to run another job!
09:35:07 job_callback for (4, 0, 15) finished
09:35:07 start sampling a new configuration.
09:35:07 best_vector: [3, 0.8248109911598038, 0.9175081994422299, 0.03488686534406893, 0.17412848193945157, 1, 0.6732235976979927, 0.5525802032314866], 0.0018994664597177485, 0.9354667167446356, 0.0017768876526387187
09:35:07 done sampling a new configuration.
09:35:07 HBMASTER: schedule new run for iteration 4
09:35:07 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
09:35:07 HBMASTER: submitting job (4, 0, 16) to dispatcher
09:35:07 DISPATCHER: trying to submit job (4, 0, 16)
09:35:07 DISPATCHER: trying to notify the job_runner thread.
09:35:07 HBMASTER: job (4, 0, 16) submitted to dispatcher
09:35:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:35:07 DISPATCHER: Trying to submit another job.
09:35:07 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpui.1576139975513683776
09:35:07 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
09:35:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:35:07 WORKER: start processing job (4, 0, 16)
09:35:07 WORKER: args: ()
09:35:07 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 86, 'last_n_outputs': 46, 'lr': 0.001174285587641722, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.052350811652475356}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-487:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:36:06 DISPATCHER: Starting worker discovery
09:36:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:36:06 DISPATCHER: Finished worker discovery
09:36:25 WORKER: done with job (4, 0, 16), trying to register it.
09:36:25 WORKER: registered result for job (4, 0, 16) with dispatcher
09:36:25 DISPATCHER: job (4, 0, 16) finished
09:36:25 DISPATCHER: register_result: lock acquired
09:36:25 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
09:36:25 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 86, 'last_n_outputs': 46, 'lr': 0.001174285587641722, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.052350811652475356}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 86, 'last_n_outputs': 46, 'lr': 0.001174285587641722, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.052350811652475356}"}}
exception: None

09:36:25 job_callback for (4, 0, 16) started
09:36:25 job_callback for (4, 0, 16) got condition
09:36:25 DISPATCHER: Trying to submit another job.
09:36:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:36:25 HBMASTER: Trying to run another job!
09:36:25 job_callback for (4, 0, 16) finished
09:36:25 start sampling a new configuration.
09:36:25 done sampling a new configuration.
09:36:25 HBMASTER: schedule new run for iteration 4
09:36:25 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
09:36:25 HBMASTER: submitting job (4, 0, 17) to dispatcher
09:36:25 DISPATCHER: trying to submit job (4, 0, 17)
09:36:25 DISPATCHER: trying to notify the job_runner thread.
09:36:25 HBMASTER: job (4, 0, 17) submitted to dispatcher
09:36:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:36:25 DISPATCHER: Trying to submit another job.
09:36:25 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpui.1576139975513683776
09:36:25 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
09:36:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:36:25 WORKER: start processing job (4, 0, 17)
09:36:25 WORKER: args: ()
09:36:25 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 65, 'last_n_outputs': 12, 'lr': 0.006592046698886609, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.01767837836076753}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:37:06 DISPATCHER: Starting worker discovery
09:37:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:37:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-488:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:37:43 WORKER: done with job (4, 0, 17), trying to register it.
09:37:43 WORKER: registered result for job (4, 0, 17) with dispatcher
09:37:43 DISPATCHER: job (4, 0, 17) finished
09:37:43 DISPATCHER: register_result: lock acquired
09:37:43 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
09:37:43 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 65, 'last_n_outputs': 12, 'lr': 0.006592046698886609, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.01767837836076753}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 65, 'last_n_outputs': 12, 'lr': 0.006592046698886609, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.01767837836076753}"}}
exception: None

09:37:43 job_callback for (4, 0, 17) started
09:37:43 DISPATCHER: Trying to submit another job.
09:37:43 job_callback for (4, 0, 17) got condition
09:37:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:37:43 HBMASTER: Trying to run another job!
09:37:43 job_callback for (4, 0, 17) finished
09:37:43 start sampling a new configuration.
09:37:43 best_vector: [1, 0.37850516383798327, 0.8352477823022356, 0.005656175110050871, 0.27889684971667567, 0, 0.7699983869537108, 0.6207206616555827], 0.002934103831082159, 1.2437129940853828, 0.003649183060712584
09:37:43 done sampling a new configuration.
09:37:43 HBMASTER: schedule new run for iteration 4
09:37:43 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
09:37:43 HBMASTER: submitting job (4, 0, 18) to dispatcher
09:37:43 DISPATCHER: trying to submit job (4, 0, 18)
09:37:43 DISPATCHER: trying to notify the job_runner thread.
09:37:43 HBMASTER: job (4, 0, 18) submitted to dispatcher
09:37:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:37:43 DISPATCHER: Trying to submit another job.
09:37:43 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpui.1576139975513683776
09:37:43 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
09:37:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:37:43 WORKER: start processing job (4, 0, 18)
09:37:43 WORKER: args: ()
09:37:43 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 50, 'last_n_outputs': 42, 'lr': 0.001026389853741531, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.0642060865307762}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:38:06 DISPATCHER: Starting worker discovery
09:38:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:38:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-489:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:39:01 WORKER: done with job (4, 0, 18), trying to register it.
09:39:01 WORKER: registered result for job (4, 0, 18) with dispatcher
09:39:01 DISPATCHER: job (4, 0, 18) finished
09:39:01 DISPATCHER: register_result: lock acquired
09:39:01 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
09:39:01 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 50, 'last_n_outputs': 42, 'lr': 0.001026389853741531, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.0642060865307762}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0020545783014871617, 'info': {'data03': 0.0020545783014871617, 'config': "{'batch_size': 32, 'hidden_dim': 50, 'last_n_outputs': 42, 'lr': 0.001026389853741531, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.0642060865307762}"}}
exception: None

09:39:01 job_callback for (4, 0, 18) started
09:39:01 DISPATCHER: Trying to submit another job.
09:39:01 job_callback for (4, 0, 18) got condition
09:39:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:39:01 HBMASTER: Trying to run another job!
09:39:01 job_callback for (4, 0, 18) finished
09:39:01 start sampling a new configuration.
09:39:01 best_vector: [3, 0.5528423489452852, 0.15713969272451112, 0.24285240424144827, 0.002368362215214012, 0, 0.18093797455146543, 0.20398774908386108], 7.947380745247507e-30, 0.001258276194453116, -0.0010225597019297792
09:39:01 done sampling a new configuration.
09:39:01 HBMASTER: schedule new run for iteration 4
09:39:01 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
09:39:01 HBMASTER: submitting job (4, 0, 19) to dispatcher
09:39:01 DISPATCHER: trying to submit job (4, 0, 19)
09:39:01 DISPATCHER: trying to notify the job_runner thread.
09:39:01 HBMASTER: job (4, 0, 19) submitted to dispatcher
09:39:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:39:01 DISPATCHER: Trying to submit another job.
09:39:01 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpui.1576139975513683776
09:39:01 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
09:39:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:39:01 WORKER: start processing job (4, 0, 19)
09:39:01 WORKER: args: ()
09:39:01 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 64, 'last_n_outputs': 8, 'lr': 0.0030598829133106457, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.018424435066079402}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:39:06 DISPATCHER: Starting worker discovery
09:39:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:39:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-490:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:40:06 DISPATCHER: Starting worker discovery
09:40:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:40:06 DISPATCHER: Finished worker discovery
09:40:24 WORKER: done with job (4, 0, 19), trying to register it.
09:40:24 WORKER: registered result for job (4, 0, 19) with dispatcher
09:40:24 DISPATCHER: job (4, 0, 19) finished
09:40:24 DISPATCHER: register_result: lock acquired
09:40:24 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
09:40:24 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 64, 'last_n_outputs': 8, 'lr': 0.0030598829133106457, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.018424435066079402}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 64, 'last_n_outputs': 8, 'lr': 0.0030598829133106457, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.018424435066079402}"}}
exception: None

09:40:24 job_callback for (4, 0, 19) started
09:40:24 DISPATCHER: Trying to submit another job.
09:40:24 job_callback for (4, 0, 19) got condition
09:40:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:40:24 HBMASTER: Trying to run another job!
09:40:24 job_callback for (4, 0, 19) finished
09:40:24 start sampling a new configuration.
09:40:24 done sampling a new configuration.
09:40:24 HBMASTER: schedule new run for iteration 4
09:40:24 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
09:40:24 HBMASTER: submitting job (4, 0, 20) to dispatcher
09:40:24 DISPATCHER: trying to submit job (4, 0, 20)
09:40:24 DISPATCHER: trying to notify the job_runner thread.
09:40:24 HBMASTER: job (4, 0, 20) submitted to dispatcher
09:40:24 DISPATCHER: Trying to submit another job.
09:40:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:40:24 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpui.1576139975513683776
09:40:24 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
09:40:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:40:24 WORKER: start processing job (4, 0, 20)
09:40:24 WORKER: args: ()
09:40:24 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 43, 'last_n_outputs': 28, 'lr': 0.0076504104574157935, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.04702497326042788}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:41:06 DISPATCHER: Starting worker discovery
09:41:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:41:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-491:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:41:47 WORKER: done with job (4, 0, 20), trying to register it.
09:41:47 WORKER: registered result for job (4, 0, 20) with dispatcher
09:41:47 DISPATCHER: job (4, 0, 20) finished
09:41:47 DISPATCHER: register_result: lock acquired
09:41:47 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
09:41:47 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 43, 'last_n_outputs': 28, 'lr': 0.0076504104574157935, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.04702497326042788}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 43, 'last_n_outputs': 28, 'lr': 0.0076504104574157935, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.04702497326042788}"}}
exception: None

09:41:47 job_callback for (4, 0, 20) started
09:41:47 job_callback for (4, 0, 20) got condition
09:41:47 DISPATCHER: Trying to submit another job.
09:41:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:41:47 HBMASTER: Trying to run another job!
09:41:47 job_callback for (4, 0, 20) finished
09:41:47 start sampling a new configuration.
09:41:47 best_vector: [0, 0.8200862487207847, 0.9330242734459101, 0.6166941638707607, 0.0357786066708691, 1, 0.48837373916695026, 0.014064837566817038], 1.9509877826046243e-31, 0.0512560872454553, -0.00873532640798155
09:41:47 done sampling a new configuration.
09:41:47 HBMASTER: schedule new run for iteration 4
09:41:47 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
09:41:47 HBMASTER: submitting job (4, 0, 21) to dispatcher
09:41:47 DISPATCHER: trying to submit job (4, 0, 21)
09:41:47 DISPATCHER: trying to notify the job_runner thread.
09:41:47 HBMASTER: job (4, 0, 21) submitted to dispatcher
09:41:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:41:47 DISPATCHER: Trying to submit another job.
09:41:47 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776
09:41:47 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
09:41:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:41:47 WORKER: start processing job (4, 0, 21)
09:41:47 WORKER: args: ()
09:41:47 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 86, 'last_n_outputs': 47, 'lr': 0.017115450221958324, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.010430347447887865}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:42:06 DISPATCHER: Starting worker discovery
09:42:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:42:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-492:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:43:06 DISPATCHER: Starting worker discovery
09:43:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:43:06 DISPATCHER: Finished worker discovery
09:43:10 WORKER: done with job (4, 0, 21), trying to register it.
09:43:10 WORKER: registered result for job (4, 0, 21) with dispatcher
09:43:10 DISPATCHER: job (4, 0, 21) finished
09:43:10 DISPATCHER: register_result: lock acquired
09:43:10 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
09:43:10 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 86, 'last_n_outputs': 47, 'lr': 0.017115450221958324, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.010430347447887865}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.022694142423059494, 'info': {'data03': 0.022694142423059494, 'config': "{'batch_size': 16, 'hidden_dim': 86, 'last_n_outputs': 47, 'lr': 0.017115450221958324, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.010430347447887865}"}}
exception: None

09:43:10 job_callback for (4, 0, 21) started
09:43:10 DISPATCHER: Trying to submit another job.
09:43:10 job_callback for (4, 0, 21) got condition
09:43:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:43:10 HBMASTER: Trying to run another job!
09:43:10 job_callback for (4, 0, 21) finished
09:43:10 start sampling a new configuration.
09:43:10 best_vector: [1, 0.5709974991532248, 0.891752291431102, 0.2681343639333689, 0.34346066169580747, 1, 0.8448483665100184, 0.9604637746973939], 8.319470935870791e-33, 1.2019995113972124, -0.0004134470730530451
09:43:10 done sampling a new configuration.
09:43:10 HBMASTER: schedule new run for iteration 4
09:43:10 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
09:43:10 HBMASTER: submitting job (4, 0, 22) to dispatcher
09:43:10 DISPATCHER: trying to submit job (4, 0, 22)
09:43:10 DISPATCHER: trying to notify the job_runner thread.
09:43:10 HBMASTER: job (4, 0, 22) submitted to dispatcher
09:43:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:43:10 DISPATCHER: Trying to submit another job.
09:43:10 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776
09:43:10 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
09:43:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:43:10 WORKER: start processing job (4, 0, 22)
09:43:10 WORKER: args: ()
09:43:10 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 66, 'last_n_outputs': 45, 'lr': 0.003437705966155723, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.17766103204645337}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-493:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:44:06 DISPATCHER: Starting worker discovery
09:44:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:44:06 DISPATCHER: Finished worker discovery
09:44:33 WORKER: done with job (4, 0, 22), trying to register it.
09:44:33 WORKER: registered result for job (4, 0, 22) with dispatcher
09:44:33 DISPATCHER: job (4, 0, 22) finished
09:44:33 DISPATCHER: register_result: lock acquired
09:44:33 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
09:44:33 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 66, 'last_n_outputs': 45, 'lr': 0.003437705966155723, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.17766103204645337}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 66, 'last_n_outputs': 45, 'lr': 0.003437705966155723, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.17766103204645337}"}}
exception: None

09:44:33 job_callback for (4, 0, 22) started
09:44:33 job_callback for (4, 0, 22) got condition
09:44:33 DISPATCHER: Trying to submit another job.
09:44:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:44:33 HBMASTER: Trying to run another job!
09:44:33 job_callback for (4, 0, 22) finished
09:44:33 start sampling a new configuration.
09:44:33 best_vector: [0, 0.661111526318929, 0.966495633930536, 0.6927586469844739, 0.3022816099750202, 0, 0.24684295379433563, 0.3054942434089334], 2.2170205362385733e-29, 0.0004510558128147128, -0.01577940095627302
09:44:33 done sampling a new configuration.
09:44:33 HBMASTER: schedule new run for iteration 4
09:44:33 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
09:44:33 HBMASTER: submitting job (4, 0, 23) to dispatcher
09:44:33 DISPATCHER: trying to submit job (4, 0, 23)
09:44:33 DISPATCHER: trying to notify the job_runner thread.
09:44:33 HBMASTER: job (4, 0, 23) submitted to dispatcher
09:44:33 DISPATCHER: Trying to submit another job.
09:44:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:44:33 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpui.1576139975513683776
09:44:33 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
09:44:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:44:33 WORKER: start processing job (4, 0, 23)
09:44:33 WORKER: args: ()
09:44:33 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 73, 'last_n_outputs': 49, 'lr': 0.024295021849000946, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.02497222125688693}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:45:06 DISPATCHER: Starting worker discovery
09:45:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:45:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-494:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:45:52 WORKER: done with job (4, 0, 23), trying to register it.
09:45:52 WORKER: registered result for job (4, 0, 23) with dispatcher
09:45:52 DISPATCHER: job (4, 0, 23) finished
09:45:52 DISPATCHER: register_result: lock acquired
09:45:52 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
09:45:52 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 73, 'last_n_outputs': 49, 'lr': 0.024295021849000946, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.02497222125688693}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 73, 'last_n_outputs': 49, 'lr': 0.024295021849000946, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.02497222125688693}"}}
exception: None

09:45:52 job_callback for (4, 0, 23) started
09:45:52 job_callback for (4, 0, 23) got condition
09:45:52 DISPATCHER: Trying to submit another job.
09:45:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:45:52 HBMASTER: Trying to run another job!
09:45:52 job_callback for (4, 0, 23) finished
09:45:52 start sampling a new configuration.
09:45:52 done sampling a new configuration.
09:45:52 HBMASTER: schedule new run for iteration 4
09:45:52 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
09:45:52 HBMASTER: submitting job (4, 0, 24) to dispatcher
09:45:52 DISPATCHER: trying to submit job (4, 0, 24)
09:45:52 DISPATCHER: trying to notify the job_runner thread.
09:45:52 HBMASTER: job (4, 0, 24) submitted to dispatcher
09:45:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:45:52 DISPATCHER: Trying to submit another job.
09:45:52 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776
09:45:52 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
09:45:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:45:52 WORKER: start processing job (4, 0, 24)
09:45:52 WORKER: args: ()
09:45:52 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 86, 'last_n_outputs': 14, 'lr': 0.004417680073748775, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.08952754947636334}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:46:06 DISPATCHER: Starting worker discovery
09:46:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:46:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-495:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:47:06 DISPATCHER: Starting worker discovery
09:47:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:47:06 DISPATCHER: Finished worker discovery
09:47:10 WORKER: done with job (4, 0, 24), trying to register it.
09:47:10 WORKER: registered result for job (4, 0, 24) with dispatcher
09:47:10 DISPATCHER: job (4, 0, 24) finished
09:47:10 DISPATCHER: register_result: lock acquired
09:47:10 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
09:47:10 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 86, 'last_n_outputs': 14, 'lr': 0.004417680073748775, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.08952754947636334}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 86, 'last_n_outputs': 14, 'lr': 0.004417680073748775, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.08952754947636334}"}}
exception: None

09:47:10 job_callback for (4, 0, 24) started
09:47:10 DISPATCHER: Trying to submit another job.
09:47:10 job_callback for (4, 0, 24) got condition
09:47:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:47:10 HBMASTER: Trying to run another job!
09:47:10 job_callback for (4, 0, 24) finished
09:47:10 start sampling a new configuration.
09:47:11 best_vector: [0, 0.6909842024992392, 0.7561770378874623, 0.38690104228867944, 0.20032292859481388, 0, 0.5929925694245616, 0.21464742182689547], 7.324540290203768e-32, 0.13652733965262687, -6.0025008611015264e-05
09:47:11 done sampling a new configuration.
09:47:11 HBMASTER: schedule new run for iteration 4
09:47:11 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
09:47:11 HBMASTER: submitting job (4, 0, 25) to dispatcher
09:47:11 DISPATCHER: trying to submit job (4, 0, 25)
09:47:11 DISPATCHER: trying to notify the job_runner thread.
09:47:11 HBMASTER: job (4, 0, 25) submitted to dispatcher
09:47:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:47:11 DISPATCHER: Trying to submit another job.
09:47:11 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpui.1576139975513683776
09:47:11 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
09:47:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:47:11 WORKER: start processing job (4, 0, 25)
09:47:11 WORKER: args: ()
09:47:11 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 75, 'last_n_outputs': 38, 'lr': 0.005940213912167513, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.019022287195103578}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-496:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:48:06 DISPATCHER: Starting worker discovery
09:48:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:48:06 DISPATCHER: Finished worker discovery
09:48:32 WORKER: done with job (4, 0, 25), trying to register it.
09:48:32 WORKER: registered result for job (4, 0, 25) with dispatcher
09:48:32 DISPATCHER: job (4, 0, 25) finished
09:48:32 DISPATCHER: register_result: lock acquired
09:48:32 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
09:48:32 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 75, 'last_n_outputs': 38, 'lr': 0.005940213912167513, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.019022287195103578}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 75, 'last_n_outputs': 38, 'lr': 0.005940213912167513, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.019022287195103578}"}}
exception: None

09:48:32 job_callback for (4, 0, 25) started
09:48:32 job_callback for (4, 0, 25) got condition
09:48:32 DISPATCHER: Trying to submit another job.
09:48:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:48:32 HBMASTER: Trying to run another job!
09:48:32 job_callback for (4, 0, 25) finished
09:48:32 start sampling a new configuration.
09:48:32 best_vector: [1, 0.1943519559213969, 0.7862377723310859, 0.3626080343568992, 0.3321031649577624, 0, 0.5277797305633509, 0.8680636762022754], 1.6127883587261367e-32, 0.6200441580505031, -0.02421769429925284
09:48:32 done sampling a new configuration.
09:48:32 HBMASTER: schedule new run for iteration 4
09:48:32 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
09:48:32 HBMASTER: submitting job (4, 0, 26) to dispatcher
09:48:32 DISPATCHER: trying to submit job (4, 0, 26)
09:48:32 DISPATCHER: trying to notify the job_runner thread.
09:48:32 HBMASTER: job (4, 0, 26) submitted to dispatcher
09:48:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:48:32 DISPATCHER: Trying to submit another job.
09:48:32 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpui.1576139975513683776
09:48:32 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
09:48:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:48:32 WORKER: start processing job (4, 0, 26)
09:48:32 WORKER: args: ()
09:48:32 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 35, 'last_n_outputs': 40, 'lr': 0.005311486337682761, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.13470287990019156}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:49:06 DISPATCHER: Starting worker discovery
09:49:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:49:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-497:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:49:50 WORKER: done with job (4, 0, 26), trying to register it.
09:49:50 WORKER: registered result for job (4, 0, 26) with dispatcher
09:49:50 DISPATCHER: job (4, 0, 26) finished
09:49:50 DISPATCHER: register_result: lock acquired
09:49:50 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
09:49:50 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 35, 'last_n_outputs': 40, 'lr': 0.005311486337682761, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.13470287990019156}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 35, 'last_n_outputs': 40, 'lr': 0.005311486337682761, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.13470287990019156}"}}
exception: None

09:49:50 job_callback for (4, 0, 26) started
09:49:50 job_callback for (4, 0, 26) got condition
09:49:50 DISPATCHER: Trying to submit another job.
09:49:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:49:50 HBMASTER: Trying to run another job!
09:49:51 job_callback for (4, 0, 26) finished
09:49:51 ITERATION: Advancing config (4, 0, 0) to next budget 133.333333
09:49:51 ITERATION: Advancing config (4, 0, 2) to next budget 133.333333
09:49:51 ITERATION: Advancing config (4, 0, 3) to next budget 133.333333
09:49:51 ITERATION: Advancing config (4, 0, 6) to next budget 133.333333
09:49:51 ITERATION: Advancing config (4, 0, 7) to next budget 133.333333
09:49:51 ITERATION: Advancing config (4, 0, 15) to next budget 133.333333
09:49:51 ITERATION: Advancing config (4, 0, 18) to next budget 133.333333
09:49:51 ITERATION: Advancing config (4, 0, 21) to next budget 133.333333
09:49:51 ITERATION: Advancing config (4, 0, 24) to next budget 133.333333
09:49:51 HBMASTER: schedule new run for iteration 4
09:49:51 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
09:49:51 HBMASTER: submitting job (4, 0, 0) to dispatcher
09:49:51 DISPATCHER: trying to submit job (4, 0, 0)
09:49:51 DISPATCHER: trying to notify the job_runner thread.
09:49:51 HBMASTER: job (4, 0, 0) submitted to dispatcher
09:49:51 DISPATCHER: Trying to submit another job.
09:49:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:49:51 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
09:49:51 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
09:49:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:49:51 WORKER: start processing job (4, 0, 0)
09:49:51 WORKER: args: ()
09:49:51 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 30, 'lr': 0.0017165173811214782, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.08288886559834752}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:50:06 DISPATCHER: Starting worker discovery
09:50:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:50:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-498:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:51:06 DISPATCHER: Starting worker discovery
09:51:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:51:06 DISPATCHER: Finished worker discovery
09:52:06 DISPATCHER: Starting worker discovery
09:52:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:52:06 DISPATCHER: Finished worker discovery
09:52:37 WORKER: done with job (4, 0, 0), trying to register it.
09:52:37 WORKER: registered result for job (4, 0, 0) with dispatcher
09:52:37 DISPATCHER: job (4, 0, 0) finished
09:52:37 DISPATCHER: register_result: lock acquired
09:52:37 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
09:52:37 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 30, 'lr': 0.0017165173811214782, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.08288886559834752}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.23916207429420192, 'info': {'data03': 0.23916207429420192, 'config': "{'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 30, 'lr': 0.0017165173811214782, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.08288886559834752}"}}
exception: None

09:52:37 job_callback for (4, 0, 0) started
09:52:37 DISPATCHER: Trying to submit another job.
09:52:37 job_callback for (4, 0, 0) got condition
09:52:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:52:37 done building a new model for budget 133.333333 based on 9/16 split
Best loss for this budget:-0.407920





09:52:37 HBMASTER: Trying to run another job!
09:52:37 job_callback for (4, 0, 0) finished
09:52:37 HBMASTER: schedule new run for iteration 4
09:52:37 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
09:52:37 HBMASTER: submitting job (4, 0, 2) to dispatcher
09:52:37 DISPATCHER: trying to submit job (4, 0, 2)
09:52:37 DISPATCHER: trying to notify the job_runner thread.
09:52:37 HBMASTER: job (4, 0, 2) submitted to dispatcher
09:52:37 DISPATCHER: Trying to submit another job.
09:52:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:52:37 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
09:52:37 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
09:52:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:52:37 WORKER: start processing job (4, 0, 2)
09:52:37 WORKER: args: ()
09:52:37 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 34, 'last_n_outputs': 32, 'lr': 0.008976498218492716, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.13469116939734982}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:53:06 DISPATCHER: Starting worker discovery
09:53:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:53:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-499:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:54:06 DISPATCHER: Starting worker discovery
09:54:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:54:06 DISPATCHER: Finished worker discovery
09:55:06 DISPATCHER: Starting worker discovery
09:55:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:55:06 DISPATCHER: Finished worker discovery
09:55:25 WORKER: done with job (4, 0, 2), trying to register it.
09:55:25 WORKER: registered result for job (4, 0, 2) with dispatcher
09:55:25 DISPATCHER: job (4, 0, 2) finished
09:55:25 DISPATCHER: register_result: lock acquired
09:55:25 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
09:55:25 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 34, 'last_n_outputs': 32, 'lr': 0.008976498218492716, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.13469116939734982}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 34, 'last_n_outputs': 32, 'lr': 0.008976498218492716, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.13469116939734982}"}}
exception: None

09:55:25 job_callback for (4, 0, 2) started
09:55:25 DISPATCHER: Trying to submit another job.
09:55:25 job_callback for (4, 0, 2) got condition
09:55:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:55:25 done building a new model for budget 133.333333 based on 9/17 split
Best loss for this budget:-0.407920





09:55:25 HBMASTER: Trying to run another job!
09:55:25 job_callback for (4, 0, 2) finished
09:55:25 HBMASTER: schedule new run for iteration 4
09:55:25 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
09:55:25 HBMASTER: submitting job (4, 0, 3) to dispatcher
09:55:25 DISPATCHER: trying to submit job (4, 0, 3)
09:55:25 DISPATCHER: trying to notify the job_runner thread.
09:55:25 HBMASTER: job (4, 0, 3) submitted to dispatcher
09:55:25 DISPATCHER: Trying to submit another job.
09:55:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:55:25 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
09:55:25 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
09:55:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:55:25 WORKER: start processing job (4, 0, 3)
09:55:25 WORKER: args: ()
09:55:25 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 71, 'last_n_outputs': 48, 'lr': 0.0014623773763310255, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.012179376386172322}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:56:06 DISPATCHER: Starting worker discovery
09:56:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:56:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-500:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:57:06 DISPATCHER: Starting worker discovery
09:57:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:57:06 DISPATCHER: Finished worker discovery
09:58:06 DISPATCHER: Starting worker discovery
09:58:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:58:06 DISPATCHER: Finished worker discovery
09:58:13 WORKER: done with job (4, 0, 3), trying to register it.
09:58:13 WORKER: registered result for job (4, 0, 3) with dispatcher
09:58:13 DISPATCHER: job (4, 0, 3) finished
09:58:13 DISPATCHER: register_result: lock acquired
09:58:13 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
09:58:13 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 71, 'last_n_outputs': 48, 'lr': 0.0014623773763310255, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.012179376386172322}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3497302760902163, 'info': {'data03': 0.3497302760902163, 'config': "{'batch_size': 128, 'hidden_dim': 71, 'last_n_outputs': 48, 'lr': 0.0014623773763310255, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.012179376386172322}"}}
exception: None

09:58:13 job_callback for (4, 0, 3) started
09:58:13 job_callback for (4, 0, 3) got condition
09:58:13 DISPATCHER: Trying to submit another job.
09:58:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:58:13 done building a new model for budget 133.333333 based on 9/17 split
Best loss for this budget:-0.407920





09:58:13 HBMASTER: Trying to run another job!
09:58:13 job_callback for (4, 0, 3) finished
09:58:13 HBMASTER: schedule new run for iteration 4
09:58:13 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
09:58:13 HBMASTER: submitting job (4, 0, 6) to dispatcher
09:58:13 DISPATCHER: trying to submit job (4, 0, 6)
09:58:13 DISPATCHER: trying to notify the job_runner thread.
09:58:13 HBMASTER: job (4, 0, 6) submitted to dispatcher
09:58:13 DISPATCHER: Trying to submit another job.
09:58:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:58:13 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776
09:58:13 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
09:58:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:58:13 WORKER: start processing job (4, 0, 6)
09:58:13 WORKER: args: ()
09:58:13 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 73, 'last_n_outputs': 42, 'lr': 0.002525260477586925, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.016042811514729822}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-501:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:59:06 DISPATCHER: Starting worker discovery
09:59:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:59:06 DISPATCHER: Finished worker discovery
10:00:06 DISPATCHER: Starting worker discovery
10:00:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:00:06 DISPATCHER: Finished worker discovery
10:01:00 WORKER: done with job (4, 0, 6), trying to register it.
10:01:00 WORKER: registered result for job (4, 0, 6) with dispatcher
10:01:00 DISPATCHER: job (4, 0, 6) finished
10:01:00 DISPATCHER: register_result: lock acquired
10:01:00 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:01:00 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 73, 'last_n_outputs': 42, 'lr': 0.002525260477586925, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.016042811514729822}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.24118921748484518, 'info': {'data03': 0.24118921748484518, 'config': "{'batch_size': 128, 'hidden_dim': 73, 'last_n_outputs': 42, 'lr': 0.002525260477586925, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.016042811514729822}"}}
exception: None

10:01:00 job_callback for (4, 0, 6) started
10:01:00 DISPATCHER: Trying to submit another job.
10:01:00 job_callback for (4, 0, 6) got condition
10:01:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:01:00 done building a new model for budget 133.333333 based on 9/18 split
Best loss for this budget:-0.407920





10:01:00 HBMASTER: Trying to run another job!
10:01:00 job_callback for (4, 0, 6) finished
10:01:00 HBMASTER: schedule new run for iteration 4
10:01:00 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
10:01:00 HBMASTER: submitting job (4, 0, 7) to dispatcher
10:01:00 DISPATCHER: trying to submit job (4, 0, 7)
10:01:00 DISPATCHER: trying to notify the job_runner thread.
10:01:00 HBMASTER: job (4, 0, 7) submitted to dispatcher
10:01:00 DISPATCHER: Trying to submit another job.
10:01:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:01:00 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:01:00 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:01:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:01:00 WORKER: start processing job (4, 0, 7)
10:01:00 WORKER: args: ()
10:01:00 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 20, 'last_n_outputs': 44, 'lr': 0.00879081726453064, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.07686915591690979}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:01:06 DISPATCHER: Starting worker discovery
10:01:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:01:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-502:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:02:06 DISPATCHER: Starting worker discovery
10:02:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:02:06 DISPATCHER: Finished worker discovery
10:03:06 DISPATCHER: Starting worker discovery
10:03:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:03:06 DISPATCHER: Finished worker discovery
10:03:47 WORKER: done with job (4, 0, 7), trying to register it.
10:03:47 WORKER: registered result for job (4, 0, 7) with dispatcher
10:03:47 DISPATCHER: job (4, 0, 7) finished
10:03:47 DISPATCHER: register_result: lock acquired
10:03:47 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:03:47 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 20, 'last_n_outputs': 44, 'lr': 0.00879081726453064, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.07686915591690979}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.19886173903019325, 'info': {'data03': 0.19886173903019325, 'config': "{'batch_size': 32, 'hidden_dim': 20, 'last_n_outputs': 44, 'lr': 0.00879081726453064, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.07686915591690979}"}}
exception: None

10:03:47 job_callback for (4, 0, 7) started
10:03:47 job_callback for (4, 0, 7) got condition
10:03:47 DISPATCHER: Trying to submit another job.
10:03:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:03:47 done building a new model for budget 133.333333 based on 9/19 split
Best loss for this budget:-0.407920





10:03:47 HBMASTER: Trying to run another job!
10:03:47 job_callback for (4, 0, 7) finished
10:03:47 HBMASTER: schedule new run for iteration 4
10:03:47 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
10:03:47 HBMASTER: submitting job (4, 0, 15) to dispatcher
10:03:47 DISPATCHER: trying to submit job (4, 0, 15)
10:03:47 DISPATCHER: trying to notify the job_runner thread.
10:03:47 HBMASTER: job (4, 0, 15) submitted to dispatcher
10:03:47 DISPATCHER: Trying to submit another job.
10:03:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:03:47 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:03:47 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:03:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:03:47 WORKER: start processing job (4, 0, 15)
10:03:47 WORKER: args: ()
10:03:47 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 91, 'last_n_outputs': 30, 'lr': 0.004451579605013246, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.01049045536539118}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:04:06 DISPATCHER: Starting worker discovery
10:04:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:04:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-503:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:05:06 DISPATCHER: Starting worker discovery
10:05:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:05:06 DISPATCHER: Finished worker discovery
10:06:06 DISPATCHER: Starting worker discovery
10:06:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:06:06 DISPATCHER: Finished worker discovery
10:06:39 WORKER: done with job (4, 0, 15), trying to register it.
10:06:39 WORKER: registered result for job (4, 0, 15) with dispatcher
10:06:39 DISPATCHER: job (4, 0, 15) finished
10:06:39 DISPATCHER: register_result: lock acquired
10:06:39 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:06:39 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 91, 'last_n_outputs': 30, 'lr': 0.004451579605013246, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.01049045536539118}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2927241428258791, 'info': {'data03': 0.2927241428258791, 'config': "{'batch_size': 128, 'hidden_dim': 91, 'last_n_outputs': 30, 'lr': 0.004451579605013246, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.01049045536539118}"}}
exception: None

10:06:39 job_callback for (4, 0, 15) started
10:06:39 DISPATCHER: Trying to submit another job.
10:06:39 job_callback for (4, 0, 15) got condition
10:06:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:06:39 done building a new model for budget 133.333333 based on 9/20 split
Best loss for this budget:-0.407920





10:06:39 HBMASTER: Trying to run another job!
10:06:39 job_callback for (4, 0, 15) finished
10:06:39 HBMASTER: schedule new run for iteration 4
10:06:39 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
10:06:39 HBMASTER: submitting job (4, 0, 18) to dispatcher
10:06:39 DISPATCHER: trying to submit job (4, 0, 18)
10:06:39 DISPATCHER: trying to notify the job_runner thread.
10:06:39 HBMASTER: job (4, 0, 18) submitted to dispatcher
10:06:39 DISPATCHER: Trying to submit another job.
10:06:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:06:39 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:06:39 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:06:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:06:39 WORKER: start processing job (4, 0, 18)
10:06:39 WORKER: args: ()
10:06:39 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 50, 'last_n_outputs': 42, 'lr': 0.001026389853741531, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.0642060865307762}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:07:06 DISPATCHER: Starting worker discovery
10:07:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:07:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-504:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:08:06 DISPATCHER: Starting worker discovery
10:08:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:08:06 DISPATCHER: Finished worker discovery
10:09:06 DISPATCHER: Starting worker discovery
10:09:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:09:06 DISPATCHER: Finished worker discovery
10:09:32 WORKER: done with job (4, 0, 18), trying to register it.
10:09:32 WORKER: registered result for job (4, 0, 18) with dispatcher
10:09:32 DISPATCHER: job (4, 0, 18) finished
10:09:32 DISPATCHER: register_result: lock acquired
10:09:32 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:09:32 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 50, 'last_n_outputs': 42, 'lr': 0.001026389853741531, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.0642060865307762}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 50, 'last_n_outputs': 42, 'lr': 0.001026389853741531, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.0642060865307762}"}}
exception: None

10:09:32 job_callback for (4, 0, 18) started
10:09:32 DISPATCHER: Trying to submit another job.
10:09:32 job_callback for (4, 0, 18) got condition
10:09:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:09:32 done building a new model for budget 133.333333 based on 9/21 split
Best loss for this budget:-0.407920





10:09:32 HBMASTER: Trying to run another job!
10:09:32 job_callback for (4, 0, 18) finished
10:09:32 HBMASTER: schedule new run for iteration 4
10:09:32 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
10:09:32 HBMASTER: submitting job (4, 0, 21) to dispatcher
10:09:32 DISPATCHER: trying to submit job (4, 0, 21)
10:09:32 DISPATCHER: trying to notify the job_runner thread.
10:09:32 HBMASTER: job (4, 0, 21) submitted to dispatcher
10:09:32 DISPATCHER: Trying to submit another job.
10:09:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:09:32 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:09:32 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:09:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:09:32 WORKER: start processing job (4, 0, 21)
10:09:32 WORKER: args: ()
10:09:32 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 86, 'last_n_outputs': 47, 'lr': 0.017115450221958324, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.010430347447887865}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:10:06 DISPATCHER: Starting worker discovery
10:10:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:10:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-505:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:11:06 DISPATCHER: Starting worker discovery
10:11:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:11:06 DISPATCHER: Finished worker discovery
10:12:06 DISPATCHER: Starting worker discovery
10:12:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:12:06 DISPATCHER: Finished worker discovery
10:12:24 WORKER: done with job (4, 0, 21), trying to register it.
10:12:24 WORKER: registered result for job (4, 0, 21) with dispatcher
10:12:24 DISPATCHER: job (4, 0, 21) finished
10:12:24 DISPATCHER: register_result: lock acquired
10:12:24 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:12:24 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 86, 'last_n_outputs': 47, 'lr': 0.017115450221958324, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.010430347447887865}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 86, 'last_n_outputs': 47, 'lr': 0.017115450221958324, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.010430347447887865}"}}
exception: None

10:12:24 job_callback for (4, 0, 21) started
10:12:24 job_callback for (4, 0, 21) got condition
10:12:24 DISPATCHER: Trying to submit another job.
10:12:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:12:24 done building a new model for budget 133.333333 based on 9/22 split
Best loss for this budget:-0.407920





10:12:24 HBMASTER: Trying to run another job!
10:12:24 job_callback for (4, 0, 21) finished
10:12:24 HBMASTER: schedule new run for iteration 4
10:12:24 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
10:12:24 HBMASTER: submitting job (4, 0, 24) to dispatcher
10:12:24 DISPATCHER: trying to submit job (4, 0, 24)
10:12:24 DISPATCHER: trying to notify the job_runner thread.
10:12:24 HBMASTER: job (4, 0, 24) submitted to dispatcher
10:12:24 DISPATCHER: Trying to submit another job.
10:12:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:12:24 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:12:24 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:12:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:12:24 WORKER: start processing job (4, 0, 24)
10:12:24 WORKER: args: ()
10:12:24 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 86, 'last_n_outputs': 14, 'lr': 0.004417680073748775, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.08952754947636334}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:13:06 DISPATCHER: Starting worker discovery
10:13:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:13:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-506:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:14:06 DISPATCHER: Starting worker discovery
10:14:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:14:06 DISPATCHER: Finished worker discovery
10:15:06 DISPATCHER: Starting worker discovery
10:15:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:15:06 DISPATCHER: Finished worker discovery
10:15:17 WORKER: done with job (4, 0, 24), trying to register it.
10:15:17 WORKER: registered result for job (4, 0, 24) with dispatcher
10:15:17 DISPATCHER: job (4, 0, 24) finished
10:15:17 DISPATCHER: register_result: lock acquired
10:15:17 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:15:17 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 86, 'last_n_outputs': 14, 'lr': 0.004417680073748775, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.08952754947636334}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 86, 'last_n_outputs': 14, 'lr': 0.004417680073748775, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.08952754947636334}"}}
exception: None

10:15:17 job_callback for (4, 0, 24) started
10:15:17 job_callback for (4, 0, 24) got condition
10:15:17 DISPATCHER: Trying to submit another job.
10:15:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:15:17 done building a new model for budget 133.333333 based on 9/22 split
Best loss for this budget:-0.407920





10:15:17 HBMASTER: Trying to run another job!
10:15:17 job_callback for (4, 0, 24) finished
10:15:17 ITERATION: Advancing config (4, 0, 3) to next budget 400.000000
10:15:17 ITERATION: Advancing config (4, 0, 6) to next budget 400.000000
10:15:17 ITERATION: Advancing config (4, 0, 15) to next budget 400.000000
10:15:17 HBMASTER: schedule new run for iteration 4
10:15:17 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
10:15:17 HBMASTER: submitting job (4, 0, 3) to dispatcher
10:15:17 DISPATCHER: trying to submit job (4, 0, 3)
10:15:17 DISPATCHER: trying to notify the job_runner thread.
10:15:17 HBMASTER: job (4, 0, 3) submitted to dispatcher
10:15:17 DISPATCHER: Trying to submit another job.
10:15:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:15:17 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:15:17 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:15:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:15:17 WORKER: start processing job (4, 0, 3)
10:15:17 WORKER: args: ()
10:15:17 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 71, 'last_n_outputs': 48, 'lr': 0.0014623773763310255, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.012179376386172322}, 'budget': 400.0, 'working_directory': '.'}
10:16:06 DISPATCHER: Starting worker discovery
10:16:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:16:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-507:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:17:06 DISPATCHER: Starting worker discovery
10:17:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:17:06 DISPATCHER: Finished worker discovery
10:18:06 DISPATCHER: Starting worker discovery
10:18:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:18:06 DISPATCHER: Finished worker discovery
10:19:06 DISPATCHER: Starting worker discovery
10:19:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:19:06 DISPATCHER: Finished worker discovery
10:20:06 DISPATCHER: Starting worker discovery
10:20:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:20:06 DISPATCHER: Finished worker discovery
10:21:06 DISPATCHER: Starting worker discovery
10:21:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:21:06 DISPATCHER: Finished worker discovery
10:22:06 DISPATCHER: Starting worker discovery
10:22:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:22:06 DISPATCHER: Finished worker discovery
10:22:36 WORKER: done with job (4, 0, 3), trying to register it.
10:22:36 WORKER: registered result for job (4, 0, 3) with dispatcher
10:22:36 DISPATCHER: job (4, 0, 3) finished
10:22:36 DISPATCHER: register_result: lock acquired
10:22:36 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:22:36 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 71, 'last_n_outputs': 48, 'lr': 0.0014623773763310255, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.012179376386172322}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.35655363473732715, 'info': {'data03': 0.35655363473732715, 'config': "{'batch_size': 128, 'hidden_dim': 71, 'last_n_outputs': 48, 'lr': 0.0014623773763310255, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.012179376386172322}"}}
exception: None

10:22:36 job_callback for (4, 0, 3) started
10:22:36 job_callback for (4, 0, 3) got condition
10:22:36 DISPATCHER: Trying to submit another job.
10:22:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:22:36 HBMASTER: Trying to run another job!
10:22:36 job_callback for (4, 0, 3) finished
10:22:36 HBMASTER: schedule new run for iteration 4
10:22:36 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
10:22:36 HBMASTER: submitting job (4, 0, 6) to dispatcher
10:22:36 DISPATCHER: trying to submit job (4, 0, 6)
10:22:36 DISPATCHER: trying to notify the job_runner thread.
10:22:36 HBMASTER: job (4, 0, 6) submitted to dispatcher
10:22:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:22:36 DISPATCHER: Trying to submit another job.
10:22:36 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:22:36 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:22:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:22:36 WORKER: start processing job (4, 0, 6)
10:22:36 WORKER: args: ()
10:22:36 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 73, 'last_n_outputs': 42, 'lr': 0.002525260477586925, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.016042811514729822}, 'budget': 400.0, 'working_directory': '.'}
10:23:06 DISPATCHER: Starting worker discovery
10:23:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:23:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-508:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:24:06 DISPATCHER: Starting worker discovery
10:24:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:24:06 DISPATCHER: Finished worker discovery
10:25:06 DISPATCHER: Starting worker discovery
10:25:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:25:06 DISPATCHER: Finished worker discovery
10:26:06 DISPATCHER: Starting worker discovery
10:26:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:26:06 DISPATCHER: Finished worker discovery
10:27:06 DISPATCHER: Starting worker discovery
10:27:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:27:06 DISPATCHER: Finished worker discovery
10:28:06 DISPATCHER: Starting worker discovery
10:28:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:28:06 DISPATCHER: Finished worker discovery
10:29:06 DISPATCHER: Starting worker discovery
10:29:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:29:06 DISPATCHER: Finished worker discovery
10:29:55 WORKER: done with job (4, 0, 6), trying to register it.
10:29:55 WORKER: registered result for job (4, 0, 6) with dispatcher
10:29:55 DISPATCHER: job (4, 0, 6) finished
10:29:55 DISPATCHER: register_result: lock acquired
10:29:55 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:29:55 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 73, 'last_n_outputs': 42, 'lr': 0.002525260477586925, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.016042811514729822}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.38042104253620695, 'info': {'data03': 0.38042104253620695, 'config': "{'batch_size': 128, 'hidden_dim': 73, 'last_n_outputs': 42, 'lr': 0.002525260477586925, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.016042811514729822}"}}
exception: None

10:29:55 job_callback for (4, 0, 6) started
10:29:55 job_callback for (4, 0, 6) got condition
10:29:55 DISPATCHER: Trying to submit another job.
10:29:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:29:55 HBMASTER: Trying to run another job!
10:29:55 job_callback for (4, 0, 6) finished
10:29:55 HBMASTER: schedule new run for iteration 4
10:29:55 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
10:29:55 HBMASTER: submitting job (4, 0, 15) to dispatcher
10:29:55 DISPATCHER: trying to submit job (4, 0, 15)
10:29:55 DISPATCHER: trying to notify the job_runner thread.
10:29:55 HBMASTER: job (4, 0, 15) submitted to dispatcher
10:29:55 DISPATCHER: Trying to submit another job.
10:29:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:29:55 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:29:55 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:29:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:29:55 WORKER: start processing job (4, 0, 15)
10:29:55 WORKER: args: ()
10:29:55 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 91, 'last_n_outputs': 30, 'lr': 0.004451579605013246, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.01049045536539118}, 'budget': 400.0, 'working_directory': '.'}
10:30:06 DISPATCHER: Starting worker discovery
10:30:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:30:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-509:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:31:06 DISPATCHER: Starting worker discovery
10:31:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:31:06 DISPATCHER: Finished worker discovery
10:32:06 DISPATCHER: Starting worker discovery
10:32:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:32:06 DISPATCHER: Finished worker discovery
10:33:06 DISPATCHER: Starting worker discovery
10:33:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:33:06 DISPATCHER: Finished worker discovery
10:34:06 DISPATCHER: Starting worker discovery
10:34:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:34:06 DISPATCHER: Finished worker discovery
10:35:06 DISPATCHER: Starting worker discovery
10:35:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:35:06 DISPATCHER: Finished worker discovery
10:36:06 DISPATCHER: Starting worker discovery
10:36:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:36:06 DISPATCHER: Finished worker discovery
10:37:06 DISPATCHER: Starting worker discovery
10:37:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:37:06 DISPATCHER: Finished worker discovery
10:37:14 WORKER: done with job (4, 0, 15), trying to register it.
10:37:14 WORKER: registered result for job (4, 0, 15) with dispatcher
10:37:14 DISPATCHER: job (4, 0, 15) finished
10:37:14 DISPATCHER: register_result: lock acquired
10:37:14 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:37:14 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 91, 'last_n_outputs': 30, 'lr': 0.004451579605013246, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.01049045536539118}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.31324133651856595, 'info': {'data03': 0.31324133651856595, 'config': "{'batch_size': 128, 'hidden_dim': 91, 'last_n_outputs': 30, 'lr': 0.004451579605013246, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.01049045536539118}"}}
exception: None

10:37:14 job_callback for (4, 0, 15) started
10:37:14 DISPATCHER: Trying to submit another job.
10:37:14 job_callback for (4, 0, 15) got condition
10:37:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:37:14 HBMASTER: Trying to run another job!
10:37:14 job_callback for (4, 0, 15) finished
10:37:14 ITERATION: Advancing config (4, 0, 6) to next budget 1200.000000
10:37:14 HBMASTER: schedule new run for iteration 4
10:37:14 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
10:37:14 HBMASTER: submitting job (4, 0, 6) to dispatcher
10:37:14 DISPATCHER: trying to submit job (4, 0, 6)
10:37:14 DISPATCHER: trying to notify the job_runner thread.
10:37:14 HBMASTER: job (4, 0, 6) submitted to dispatcher
10:37:14 DISPATCHER: Trying to submit another job.
10:37:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:37:14 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:37:14 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:37:14 WORKER: start processing job (4, 0, 6)
10:37:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:37:14 WORKER: args: ()
10:37:14 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 73, 'last_n_outputs': 42, 'lr': 0.002525260477586925, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.016042811514729822}, 'budget': 1200.0, 'working_directory': '.'}
10:38:06 DISPATCHER: Starting worker discovery
10:38:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:38:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-510:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:39:06 DISPATCHER: Starting worker discovery
10:39:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:39:06 DISPATCHER: Finished worker discovery
10:40:06 DISPATCHER: Starting worker discovery
10:40:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:40:06 DISPATCHER: Finished worker discovery
10:41:06 DISPATCHER: Starting worker discovery
10:41:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:41:06 DISPATCHER: Finished worker discovery
10:42:06 DISPATCHER: Starting worker discovery
10:42:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:42:06 DISPATCHER: Finished worker discovery
10:43:06 DISPATCHER: Starting worker discovery
10:43:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:43:06 DISPATCHER: Finished worker discovery
10:44:06 DISPATCHER: Starting worker discovery
10:44:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:44:06 DISPATCHER: Finished worker discovery
10:45:06 DISPATCHER: Starting worker discovery
10:45:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:45:06 DISPATCHER: Finished worker discovery
10:46:06 DISPATCHER: Starting worker discovery
10:46:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:46:06 DISPATCHER: Finished worker discovery
10:47:06 DISPATCHER: Starting worker discovery
10:47:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:47:06 DISPATCHER: Finished worker discovery
10:48:06 DISPATCHER: Starting worker discovery
10:48:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:48:06 DISPATCHER: Finished worker discovery
10:49:06 DISPATCHER: Starting worker discovery
10:49:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:49:06 DISPATCHER: Finished worker discovery
10:50:06 DISPATCHER: Starting worker discovery
10:50:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:50:06 DISPATCHER: Finished worker discovery
10:51:06 DISPATCHER: Starting worker discovery
10:51:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:51:06 DISPATCHER: Finished worker discovery
10:52:06 DISPATCHER: Starting worker discovery
10:52:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:52:06 DISPATCHER: Finished worker discovery
10:53:06 DISPATCHER: Starting worker discovery
10:53:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:53:06 DISPATCHER: Finished worker discovery
10:54:06 DISPATCHER: Starting worker discovery
10:54:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:54:06 DISPATCHER: Finished worker discovery
10:55:06 DISPATCHER: Starting worker discovery
10:55:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:55:06 DISPATCHER: Finished worker discovery
10:56:06 DISPATCHER: Starting worker discovery
10:56:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:56:06 DISPATCHER: Finished worker discovery
10:57:06 DISPATCHER: Starting worker discovery
10:57:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:57:06 DISPATCHER: Finished worker discovery
10:57:53 WORKER: done with job (4, 0, 6), trying to register it.
10:57:53 WORKER: registered result for job (4, 0, 6) with dispatcher
10:57:53 DISPATCHER: job (4, 0, 6) finished
10:57:53 DISPATCHER: register_result: lock acquired
10:57:53 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
10:57:53 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 73, 'last_n_outputs': 42, 'lr': 0.002525260477586925, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.016042811514729822}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.3321204079603957, 'info': {'data03': 0.3321204079603957, 'config': "{'batch_size': 128, 'hidden_dim': 73, 'last_n_outputs': 42, 'lr': 0.002525260477586925, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.016042811514729822}"}}
exception: None

10:57:53 job_callback for (4, 0, 6) started
10:57:53 job_callback for (4, 0, 6) got condition
10:57:53 DISPATCHER: Trying to submit another job.
10:57:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:57:53 HBMASTER: Trying to run another job!
10:57:53 job_callback for (4, 0, 6) finished
10:57:53 start sampling a new configuration.
10:57:53 done sampling a new configuration.
10:57:53 HBMASTER: schedule new run for iteration 5
10:57:53 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
10:57:53 HBMASTER: submitting job (5, 0, 0) to dispatcher
10:57:53 DISPATCHER: trying to submit job (5, 0, 0)
10:57:53 DISPATCHER: trying to notify the job_runner thread.
10:57:53 HBMASTER: job (5, 0, 0) submitted to dispatcher
10:57:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:57:53 DISPATCHER: Trying to submit another job.
10:57:53 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
10:57:53 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
10:57:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:57:53 WORKER: start processing job (5, 0, 0)
10:57:53 WORKER: args: ()
10:57:53 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 11, 'lr': 0.01877739612884069, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.02042291173875004}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:58:06 DISPATCHER: Starting worker discovery
10:58:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:58:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-511:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

10:59:06 DISPATCHER: Starting worker discovery
10:59:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:59:06 DISPATCHER: Finished worker discovery
11:00:06 DISPATCHER: Starting worker discovery
11:00:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:00:06 DISPATCHER: Finished worker discovery
11:00:49 WORKER: done with job (5, 0, 0), trying to register it.
11:00:49 WORKER: registered result for job (5, 0, 0) with dispatcher
11:00:49 DISPATCHER: job (5, 0, 0) finished
11:00:49 DISPATCHER: register_result: lock acquired
11:00:49 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
11:00:49 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 11, 'lr': 0.01877739612884069, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.02042291173875004}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 11, 'lr': 0.01877739612884069, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.02042291173875004}"}}
exception: None

11:00:49 job_callback for (5, 0, 0) started
11:00:49 DISPATCHER: Trying to submit another job.
11:00:49 job_callback for (5, 0, 0) got condition
11:00:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:00:49 done building a new model for budget 133.333333 based on 9/23 split
Best loss for this budget:-0.407920





11:00:49 HBMASTER: Trying to run another job!
11:00:49 job_callback for (5, 0, 0) finished
11:00:49 start sampling a new configuration.
11:00:49 best_vector: [1, 0.830683632685691, 0.8177606821692954, 0.8972232158327552, 0.10036202910683734, 0, 0.7848949365970079, 0.951069774228685], 7.685438491711672e-30, 0.001301161932501894, -1.338606052854093e-05
11:00:49 done sampling a new configuration.
11:00:49 HBMASTER: schedule new run for iteration 5
11:00:49 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
11:00:49 HBMASTER: submitting job (5, 0, 1) to dispatcher
11:00:49 DISPATCHER: trying to submit job (5, 0, 1)
11:00:49 DISPATCHER: trying to notify the job_runner thread.
11:00:49 HBMASTER: job (5, 0, 1) submitted to dispatcher
11:00:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:00:49 DISPATCHER: Trying to submit another job.
11:00:49 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
11:00:49 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
11:00:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:00:49 WORKER: start processing job (5, 0, 1)
11:00:49 WORKER: args: ()
11:00:49 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 87, 'last_n_outputs': 41, 'lr': 0.06229403057141609, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.17273100673338568}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:01:06 DISPATCHER: Starting worker discovery
11:01:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:01:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-512:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:02:06 DISPATCHER: Starting worker discovery
11:02:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:02:06 DISPATCHER: Finished worker discovery
11:03:06 DISPATCHER: Starting worker discovery
11:03:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:03:06 DISPATCHER: Finished worker discovery
11:03:43 WORKER: done with job (5, 0, 1), trying to register it.
11:03:43 WORKER: registered result for job (5, 0, 1) with dispatcher
11:03:43 DISPATCHER: job (5, 0, 1) finished
11:03:43 DISPATCHER: register_result: lock acquired
11:03:43 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
11:03:43 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 87, 'last_n_outputs': 41, 'lr': 0.06229403057141609, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.17273100673338568}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.008166973043034646, 'info': {'data03': 0.008166973043034646, 'config': "{'batch_size': 32, 'hidden_dim': 87, 'last_n_outputs': 41, 'lr': 0.06229403057141609, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.17273100673338568}"}}
exception: None

11:03:43 job_callback for (5, 0, 1) started
11:03:43 job_callback for (5, 0, 1) got condition
11:03:43 DISPATCHER: Trying to submit another job.
11:03:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:03:43 done building a new model for budget 133.333333 based on 9/24 split
Best loss for this budget:-0.407920





11:03:43 HBMASTER: Trying to run another job!
11:03:43 job_callback for (5, 0, 1) finished
11:03:43 start sampling a new configuration.
11:03:43 best_vector: [0, 0.8333765664677926, 0.9909680880398208, 0.014810583448224751, 0.10379830150414418, 0, 0.5490149769060666, 0.06114428371375227], 3.2695588183937414e-31, 0.030585166242437473, -0.0015282858050405877
11:03:43 done sampling a new configuration.
11:03:43 HBMASTER: schedule new run for iteration 5
11:03:43 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
11:03:43 HBMASTER: submitting job (5, 0, 2) to dispatcher
11:03:43 DISPATCHER: trying to submit job (5, 0, 2)
11:03:43 DISPATCHER: trying to notify the job_runner thread.
11:03:43 HBMASTER: job (5, 0, 2) submitted to dispatcher
11:03:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:03:43 DISPATCHER: Trying to submit another job.
11:03:43 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
11:03:43 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
11:03:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:03:43 WORKER: start processing job (5, 0, 2)
11:03:43 WORKER: args: ()
11:03:43 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 87, 'last_n_outputs': 50, 'lr': 0.0010705850313562663, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.012010208507021001}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:04:06 DISPATCHER: Starting worker discovery
11:04:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:04:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-513:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:05:06 DISPATCHER: Starting worker discovery
11:05:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:05:06 DISPATCHER: Finished worker discovery
11:06:06 DISPATCHER: Starting worker discovery
11:06:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:06:06 DISPATCHER: Finished worker discovery
11:06:35 WORKER: done with job (5, 0, 2), trying to register it.
11:06:35 WORKER: registered result for job (5, 0, 2) with dispatcher
11:06:35 DISPATCHER: job (5, 0, 2) finished
11:06:35 DISPATCHER: register_result: lock acquired
11:06:35 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
11:06:35 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 87, 'last_n_outputs': 50, 'lr': 0.0010705850313562663, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.012010208507021001}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.12194210255880703, 'info': {'data03': 0.12194210255880703, 'config': "{'batch_size': 16, 'hidden_dim': 87, 'last_n_outputs': 50, 'lr': 0.0010705850313562663, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.012010208507021001}"}}
exception: None

11:06:35 job_callback for (5, 0, 2) started
11:06:35 DISPATCHER: Trying to submit another job.
11:06:35 job_callback for (5, 0, 2) got condition
11:06:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:06:35 done building a new model for budget 133.333333 based on 9/25 split
Best loss for this budget:-0.407920





11:06:35 HBMASTER: Trying to run another job!
11:06:35 job_callback for (5, 0, 2) finished
11:06:35 start sampling a new configuration.
11:06:35 done sampling a new configuration.
11:06:35 HBMASTER: schedule new run for iteration 5
11:06:35 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
11:06:35 HBMASTER: submitting job (5, 0, 3) to dispatcher
11:06:35 DISPATCHER: trying to submit job (5, 0, 3)
11:06:35 DISPATCHER: trying to notify the job_runner thread.
11:06:35 HBMASTER: job (5, 0, 3) submitted to dispatcher
11:06:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:06:35 DISPATCHER: Trying to submit another job.
11:06:35 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
11:06:35 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
11:06:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:06:35 WORKER: start processing job (5, 0, 3)
11:06:35 WORKER: args: ()
11:06:35 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 89, 'last_n_outputs': 3, 'lr': 0.016681555190104787, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.015800704629477656}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:07:06 DISPATCHER: Starting worker discovery
11:07:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:07:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-514:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:08:06 DISPATCHER: Starting worker discovery
11:08:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:08:06 DISPATCHER: Finished worker discovery
11:09:06 DISPATCHER: Starting worker discovery
11:09:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:09:06 DISPATCHER: Finished worker discovery
11:09:28 WORKER: done with job (5, 0, 3), trying to register it.
11:09:28 WORKER: registered result for job (5, 0, 3) with dispatcher
11:09:28 DISPATCHER: job (5, 0, 3) finished
11:09:28 DISPATCHER: register_result: lock acquired
11:09:28 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
11:09:28 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 89, 'last_n_outputs': 3, 'lr': 0.016681555190104787, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.015800704629477656}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 89, 'last_n_outputs': 3, 'lr': 0.016681555190104787, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.015800704629477656}"}}
exception: None

11:09:28 job_callback for (5, 0, 3) started
11:09:28 job_callback for (5, 0, 3) got condition
11:09:28 DISPATCHER: Trying to submit another job.
11:09:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:09:28 done building a new model for budget 133.333333 based on 9/26 split
Best loss for this budget:-0.407920





11:09:28 HBMASTER: Trying to run another job!
11:09:28 job_callback for (5, 0, 3) finished
11:09:28 start sampling a new configuration.
11:09:28 done sampling a new configuration.
11:09:28 HBMASTER: schedule new run for iteration 5
11:09:28 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
11:09:28 HBMASTER: submitting job (5, 0, 4) to dispatcher
11:09:28 DISPATCHER: trying to submit job (5, 0, 4)
11:09:28 DISPATCHER: trying to notify the job_runner thread.
11:09:28 HBMASTER: job (5, 0, 4) submitted to dispatcher
11:09:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:09:28 DISPATCHER: Trying to submit another job.
11:09:28 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
11:09:28 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
11:09:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:09:28 WORKER: start processing job (5, 0, 4)
11:09:28 WORKER: args: ()
11:09:28 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 37, 'last_n_outputs': 28, 'lr': 0.02348537058272699, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.097933500397826}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:10:06 DISPATCHER: Starting worker discovery
11:10:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:10:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-515:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:11:06 DISPATCHER: Starting worker discovery
11:11:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:11:06 DISPATCHER: Finished worker discovery
11:12:06 DISPATCHER: Starting worker discovery
11:12:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:12:06 DISPATCHER: Finished worker discovery
11:12:19 WORKER: done with job (5, 0, 4), trying to register it.
11:12:19 WORKER: registered result for job (5, 0, 4) with dispatcher
11:12:19 DISPATCHER: job (5, 0, 4) finished
11:12:19 DISPATCHER: register_result: lock acquired
11:12:19 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
11:12:19 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 37, 'last_n_outputs': 28, 'lr': 0.02348537058272699, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.097933500397826}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 37, 'last_n_outputs': 28, 'lr': 0.02348537058272699, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.097933500397826}"}}
exception: None

11:12:19 job_callback for (5, 0, 4) started
11:12:19 DISPATCHER: Trying to submit another job.
11:12:19 job_callback for (5, 0, 4) got condition
11:12:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:12:19 done building a new model for budget 133.333333 based on 9/27 split
Best loss for this budget:-0.407920





11:12:19 HBMASTER: Trying to run another job!
11:12:19 job_callback for (5, 0, 4) finished
11:12:19 start sampling a new configuration.
11:12:20 best_vector: [0, 0.9295078700417212, 0.7455238915665978, 0.3170434916203394, 0.09937961496834424, 0, 0.3097890246545595, 0.5429349327852719], 4.287770821293148e-31, 0.023322142009875663, -0.0010057730825330491
11:12:20 done sampling a new configuration.
11:12:20 HBMASTER: schedule new run for iteration 5
11:12:20 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
11:12:20 HBMASTER: submitting job (5, 0, 5) to dispatcher
11:12:20 DISPATCHER: trying to submit job (5, 0, 5)
11:12:20 DISPATCHER: trying to notify the job_runner thread.
11:12:20 HBMASTER: job (5, 0, 5) submitted to dispatcher
11:12:20 DISPATCHER: Trying to submit another job.
11:12:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:12:20 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
11:12:20 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
11:12:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:12:20 WORKER: start processing job (5, 0, 5)
11:12:20 WORKER: args: ()
11:12:20 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 95, 'last_n_outputs': 38, 'lr': 0.004306128477150951, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.050859798268521904}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-516:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:13:06 DISPATCHER: Starting worker discovery
11:13:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:13:06 DISPATCHER: Finished worker discovery
11:14:06 DISPATCHER: Starting worker discovery
11:14:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:14:06 DISPATCHER: Finished worker discovery
11:15:06 DISPATCHER: Starting worker discovery
11:15:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:15:06 DISPATCHER: Finished worker discovery
11:15:08 WORKER: done with job (5, 0, 5), trying to register it.
11:15:08 WORKER: registered result for job (5, 0, 5) with dispatcher
11:15:08 DISPATCHER: job (5, 0, 5) finished
11:15:08 DISPATCHER: register_result: lock acquired
11:15:08 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
11:15:08 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 95, 'last_n_outputs': 38, 'lr': 0.004306128477150951, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.050859798268521904}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.263546601646414, 'info': {'data03': 0.263546601646414, 'config': "{'batch_size': 16, 'hidden_dim': 95, 'last_n_outputs': 38, 'lr': 0.004306128477150951, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.050859798268521904}"}}
exception: None

11:15:08 job_callback for (5, 0, 5) started
11:15:08 DISPATCHER: Trying to submit another job.
11:15:08 job_callback for (5, 0, 5) got condition
11:15:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:15:08 done building a new model for budget 133.333333 based on 9/28 split
Best loss for this budget:-0.407920





11:15:08 HBMASTER: Trying to run another job!
11:15:08 job_callback for (5, 0, 5) finished
11:15:08 start sampling a new configuration.
11:15:08 done sampling a new configuration.
11:15:08 HBMASTER: schedule new run for iteration 5
11:15:08 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
11:15:08 HBMASTER: submitting job (5, 0, 6) to dispatcher
11:15:08 DISPATCHER: trying to submit job (5, 0, 6)
11:15:08 DISPATCHER: trying to notify the job_runner thread.
11:15:08 HBMASTER: job (5, 0, 6) submitted to dispatcher
11:15:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:15:08 DISPATCHER: Trying to submit another job.
11:15:08 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776
11:15:08 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
11:15:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:15:08 WORKER: start processing job (5, 0, 6)
11:15:08 WORKER: args: ()
11:15:08 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 40, 'last_n_outputs': 13, 'lr': 0.0017765584067762044, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.061768629134410766}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-517:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:16:06 DISPATCHER: Starting worker discovery
11:16:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:16:06 DISPATCHER: Finished worker discovery
11:17:06 DISPATCHER: Starting worker discovery
11:17:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:17:06 DISPATCHER: Finished worker discovery
11:17:57 WORKER: done with job (5, 0, 6), trying to register it.
11:17:57 WORKER: registered result for job (5, 0, 6) with dispatcher
11:17:57 DISPATCHER: job (5, 0, 6) finished
11:17:57 DISPATCHER: register_result: lock acquired
11:17:57 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
11:17:57 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 40, 'last_n_outputs': 13, 'lr': 0.0017765584067762044, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.061768629134410766}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 40, 'last_n_outputs': 13, 'lr': 0.0017765584067762044, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.061768629134410766}"}}
exception: None

11:17:57 job_callback for (5, 0, 6) started
11:17:57 job_callback for (5, 0, 6) got condition
11:17:57 DISPATCHER: Trying to submit another job.
11:17:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:17:57 done building a new model for budget 133.333333 based on 9/28 split
Best loss for this budget:-0.407920





11:17:57 HBMASTER: Trying to run another job!
11:17:57 job_callback for (5, 0, 6) finished
11:17:57 start sampling a new configuration.
11:17:57 done sampling a new configuration.
11:17:57 HBMASTER: schedule new run for iteration 5
11:17:57 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
11:17:57 HBMASTER: submitting job (5, 0, 7) to dispatcher
11:17:57 DISPATCHER: trying to submit job (5, 0, 7)
11:17:57 DISPATCHER: trying to notify the job_runner thread.
11:17:57 HBMASTER: job (5, 0, 7) submitted to dispatcher
11:17:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:17:57 DISPATCHER: Trying to submit another job.
11:17:57 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776
11:17:57 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
11:17:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:17:57 WORKER: start processing job (5, 0, 7)
11:17:57 WORKER: args: ()
11:17:57 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 75, 'last_n_outputs': 29, 'lr': 0.01642235986593944, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.014429432355117835}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:18:06 DISPATCHER: Starting worker discovery
11:18:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:18:06 DISPATCHER: Finished worker discovery
Exception in thread Thread-518:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:19:06 DISPATCHER: Starting worker discovery
11:19:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:19:06 DISPATCHER: Finished worker discovery
11:20:06 DISPATCHER: Starting worker discovery
11:20:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:20:06 DISPATCHER: Finished worker discovery
11:20:50 WORKER: done with job (5, 0, 7), trying to register it.
11:20:50 WORKER: registered result for job (5, 0, 7) with dispatcher
11:20:50 DISPATCHER: job (5, 0, 7) finished
11:20:50 DISPATCHER: register_result: lock acquired
11:20:50 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
11:20:50 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 75, 'last_n_outputs': 29, 'lr': 0.01642235986593944, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.014429432355117835}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 75, 'last_n_outputs': 29, 'lr': 0.01642235986593944, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.014429432355117835}"}}
exception: None

11:20:50 job_callback for (5, 0, 7) started
11:20:50 DISPATCHER: Trying to submit another job.
11:20:50 job_callback for (5, 0, 7) got condition
11:20:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:20:50 done building a new model for budget 133.333333 based on 9/29 split
Best loss for this budget:-0.407920





11:20:50 HBMASTER: Trying to run another job!
11:20:50 job_callback for (5, 0, 7) finished
11:20:50 start sampling a new configuration.
11:20:50 best_vector: [0, 0.057538306125840655, 0.9770028234926125, 0.06210275336301613, 0.10164808114008471, 0, 0.6175506829901188, 0.12202360899326113], 0.0001254492592926207, 82.68652869530064, 0.010372963778303494
11:20:50 done sampling a new configuration.
11:20:50 HBMASTER: schedule new run for iteration 5
11:20:50 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
11:20:50 HBMASTER: submitting job (5, 0, 8) to dispatcher
11:20:50 DISPATCHER: trying to submit job (5, 0, 8)
11:20:50 DISPATCHER: trying to notify the job_runner thread.
11:20:50 HBMASTER: job (5, 0, 8) submitted to dispatcher
11:20:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:20:50 DISPATCHER: Trying to submit another job.
11:20:50 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776
11:20:50 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
11:20:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:20:50 WORKER: start processing job (5, 0, 8)
11:20:50 WORKER: args: ()
11:20:50 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 24, 'last_n_outputs': 49, 'lr': 0.0013310841336278809, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.014413066004336547}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:21:06 DISPATCHER: Starting worker discovery
11:21:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:21:07 DISPATCHER: Finished worker discovery
Exception in thread Thread-519:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:22:07 DISPATCHER: Starting worker discovery
11:22:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:22:07 DISPATCHER: Finished worker discovery
11:23:07 DISPATCHER: Starting worker discovery
11:23:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:23:07 DISPATCHER: Finished worker discovery
11:23:43 WORKER: done with job (5, 0, 8), trying to register it.
11:23:43 WORKER: registered result for job (5, 0, 8) with dispatcher
11:23:43 DISPATCHER: job (5, 0, 8) finished
11:23:43 DISPATCHER: register_result: lock acquired
11:23:43 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
11:23:43 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 24, 'last_n_outputs': 49, 'lr': 0.0013310841336278809, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.014413066004336547}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.20645008305330065, 'info': {'data03': 0.20645008305330065, 'config': "{'batch_size': 16, 'hidden_dim': 24, 'last_n_outputs': 49, 'lr': 0.0013310841336278809, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.014413066004336547}"}}
exception: None

11:23:43 job_callback for (5, 0, 8) started
11:23:43 job_callback for (5, 0, 8) got condition
11:23:43 DISPATCHER: Trying to submit another job.
11:23:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:23:43 done building a new model for budget 133.333333 based on 9/30 split
Best loss for this budget:-0.407920





11:23:43 HBMASTER: Trying to run another job!
11:23:43 job_callback for (5, 0, 8) finished
11:23:43 ITERATION: Advancing config (5, 0, 2) to next budget 400.000000
11:23:43 ITERATION: Advancing config (5, 0, 5) to next budget 400.000000
11:23:43 ITERATION: Advancing config (5, 0, 8) to next budget 400.000000
11:23:43 HBMASTER: schedule new run for iteration 5
11:23:43 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
11:23:43 HBMASTER: submitting job (5, 0, 2) to dispatcher
11:23:43 DISPATCHER: trying to submit job (5, 0, 2)
11:23:43 DISPATCHER: trying to notify the job_runner thread.
11:23:43 HBMASTER: job (5, 0, 2) submitted to dispatcher
11:23:43 DISPATCHER: Trying to submit another job.
11:23:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:23:43 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
11:23:43 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
11:23:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:23:43 WORKER: start processing job (5, 0, 2)
11:23:43 WORKER: args: ()
11:23:43 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 87, 'last_n_outputs': 50, 'lr': 0.0010705850313562663, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.012010208507021001}, 'budget': 400.0, 'working_directory': '.'}
11:24:07 DISPATCHER: Starting worker discovery
11:24:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:24:07 DISPATCHER: Finished worker discovery
Exception in thread Thread-520:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:25:07 DISPATCHER: Starting worker discovery
11:25:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:25:07 DISPATCHER: Finished worker discovery
11:26:07 DISPATCHER: Starting worker discovery
11:26:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:26:07 DISPATCHER: Finished worker discovery
11:27:07 DISPATCHER: Starting worker discovery
11:27:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:27:07 DISPATCHER: Finished worker discovery
11:28:07 DISPATCHER: Starting worker discovery
11:28:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:28:07 DISPATCHER: Finished worker discovery
11:29:07 DISPATCHER: Starting worker discovery
11:29:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:29:07 DISPATCHER: Finished worker discovery
11:30:07 DISPATCHER: Starting worker discovery
11:30:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:30:07 DISPATCHER: Finished worker discovery
11:31:02 WORKER: done with job (5, 0, 2), trying to register it.
11:31:02 WORKER: registered result for job (5, 0, 2) with dispatcher
11:31:02 DISPATCHER: job (5, 0, 2) finished
11:31:02 DISPATCHER: register_result: lock acquired
11:31:02 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
11:31:02 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 87, 'last_n_outputs': 50, 'lr': 0.0010705850313562663, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.012010208507021001}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.14542376749041985, 'info': {'data03': 0.14542376749041985, 'config': "{'batch_size': 16, 'hidden_dim': 87, 'last_n_outputs': 50, 'lr': 0.0010705850313562663, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.012010208507021001}"}}
exception: None

11:31:02 job_callback for (5, 0, 2) started
11:31:02 job_callback for (5, 0, 2) got condition
11:31:02 DISPATCHER: Trying to submit another job.
11:31:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:31:02 HBMASTER: Trying to run another job!
11:31:02 job_callback for (5, 0, 2) finished
11:31:02 HBMASTER: schedule new run for iteration 5
11:31:02 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
11:31:02 HBMASTER: submitting job (5, 0, 5) to dispatcher
11:31:02 DISPATCHER: trying to submit job (5, 0, 5)
11:31:02 DISPATCHER: trying to notify the job_runner thread.
11:31:02 HBMASTER: job (5, 0, 5) submitted to dispatcher
11:31:02 DISPATCHER: Trying to submit another job.
11:31:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:31:02 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
11:31:02 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
11:31:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:31:02 WORKER: start processing job (5, 0, 5)
11:31:02 WORKER: args: ()
11:31:02 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 95, 'last_n_outputs': 38, 'lr': 0.004306128477150951, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.050859798268521904}, 'budget': 400.0, 'working_directory': '.'}
11:31:07 DISPATCHER: Starting worker discovery
11:31:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:31:07 DISPATCHER: Finished worker discovery
Exception in thread Thread-521:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:32:07 DISPATCHER: Starting worker discovery
11:32:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:32:07 DISPATCHER: Finished worker discovery
11:33:07 DISPATCHER: Starting worker discovery
11:33:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:33:07 DISPATCHER: Finished worker discovery
11:34:07 DISPATCHER: Starting worker discovery
11:34:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:34:07 DISPATCHER: Finished worker discovery
11:35:07 DISPATCHER: Starting worker discovery
11:35:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:35:07 DISPATCHER: Finished worker discovery
11:36:07 DISPATCHER: Starting worker discovery
11:36:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:36:07 DISPATCHER: Finished worker discovery
11:37:07 DISPATCHER: Starting worker discovery
11:37:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:37:07 DISPATCHER: Finished worker discovery
11:38:07 DISPATCHER: Starting worker discovery
11:38:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:38:07 DISPATCHER: Finished worker discovery
11:38:22 WORKER: done with job (5, 0, 5), trying to register it.
11:38:22 WORKER: registered result for job (5, 0, 5) with dispatcher
11:38:22 DISPATCHER: job (5, 0, 5) finished
11:38:22 DISPATCHER: register_result: lock acquired
11:38:22 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
11:38:22 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 95, 'last_n_outputs': 38, 'lr': 0.004306128477150951, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.050859798268521904}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.08504583118389814, 'info': {'data03': 0.08504583118389814, 'config': "{'batch_size': 16, 'hidden_dim': 95, 'last_n_outputs': 38, 'lr': 0.004306128477150951, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.050859798268521904}"}}
exception: None

11:38:22 job_callback for (5, 0, 5) started
11:38:22 job_callback for (5, 0, 5) got condition
11:38:22 DISPATCHER: Trying to submit another job.
11:38:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:38:22 HBMASTER: Trying to run another job!
11:38:22 job_callback for (5, 0, 5) finished
11:38:22 HBMASTER: schedule new run for iteration 5
11:38:22 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
11:38:22 HBMASTER: submitting job (5, 0, 8) to dispatcher
11:38:22 DISPATCHER: trying to submit job (5, 0, 8)
11:38:22 DISPATCHER: trying to notify the job_runner thread.
11:38:22 HBMASTER: job (5, 0, 8) submitted to dispatcher
11:38:22 DISPATCHER: Trying to submit another job.
11:38:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:38:22 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776
11:38:22 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
11:38:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:38:22 WORKER: start processing job (5, 0, 8)
11:38:22 WORKER: args: ()
11:38:22 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 24, 'last_n_outputs': 49, 'lr': 0.0013310841336278809, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.014413066004336547}, 'budget': 400.0, 'working_directory': '.'}
11:39:07 DISPATCHER: Starting worker discovery
11:39:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:39:07 DISPATCHER: Finished worker discovery
Exception in thread Thread-522:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:40:07 DISPATCHER: Starting worker discovery
11:40:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:40:07 DISPATCHER: Finished worker discovery
11:41:07 DISPATCHER: Starting worker discovery
11:41:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:41:07 DISPATCHER: Finished worker discovery
11:42:07 DISPATCHER: Starting worker discovery
11:42:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:42:07 DISPATCHER: Finished worker discovery
11:43:07 DISPATCHER: Starting worker discovery
11:43:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:43:07 DISPATCHER: Finished worker discovery
11:44:07 DISPATCHER: Starting worker discovery
11:44:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:44:07 DISPATCHER: Finished worker discovery
11:45:07 DISPATCHER: Starting worker discovery
11:45:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:45:07 DISPATCHER: Finished worker discovery
11:45:41 WORKER: done with job (5, 0, 8), trying to register it.
11:45:41 WORKER: registered result for job (5, 0, 8) with dispatcher
11:45:41 DISPATCHER: job (5, 0, 8) finished
11:45:41 DISPATCHER: register_result: lock acquired
11:45:41 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
11:45:41 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 24, 'last_n_outputs': 49, 'lr': 0.0013310841336278809, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.014413066004336547}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 24, 'last_n_outputs': 49, 'lr': 0.0013310841336278809, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.014413066004336547}"}}
exception: None

11:45:41 job_callback for (5, 0, 8) started
11:45:41 job_callback for (5, 0, 8) got condition
11:45:41 DISPATCHER: Trying to submit another job.
11:45:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:45:41 done building a new model for budget 400.000000 based on 9/15 split
Best loss for this budget:-0.380421





11:45:41 HBMASTER: Trying to run another job!
11:45:41 job_callback for (5, 0, 8) finished
11:45:41 ITERATION: Advancing config (5, 0, 2) to next budget 1200.000000
11:45:41 HBMASTER: schedule new run for iteration 5
11:45:41 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
11:45:41 HBMASTER: submitting job (5, 0, 2) to dispatcher
11:45:41 DISPATCHER: trying to submit job (5, 0, 2)
11:45:41 DISPATCHER: trying to notify the job_runner thread.
11:45:41 HBMASTER: job (5, 0, 2) submitted to dispatcher
11:45:41 DISPATCHER: Trying to submit another job.
11:45:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:45:41 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
11:45:41 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
11:45:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:45:41 WORKER: start processing job (5, 0, 2)
11:45:41 WORKER: args: ()
11:45:41 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 87, 'last_n_outputs': 50, 'lr': 0.0010705850313562663, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.012010208507021001}, 'budget': 1200.0, 'working_directory': '.'}
11:46:07 DISPATCHER: Starting worker discovery
11:46:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:46:07 DISPATCHER: Finished worker discovery
Exception in thread Thread-523:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

11:47:07 DISPATCHER: Starting worker discovery
11:47:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:47:07 DISPATCHER: Finished worker discovery
11:48:07 DISPATCHER: Starting worker discovery
11:48:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:48:07 DISPATCHER: Finished worker discovery
11:49:07 DISPATCHER: Starting worker discovery
11:49:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:49:07 DISPATCHER: Finished worker discovery
11:50:07 DISPATCHER: Starting worker discovery
11:50:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:50:07 DISPATCHER: Finished worker discovery
11:51:07 DISPATCHER: Starting worker discovery
11:51:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:51:07 DISPATCHER: Finished worker discovery
11:52:07 DISPATCHER: Starting worker discovery
11:52:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:52:07 DISPATCHER: Finished worker discovery
11:53:07 DISPATCHER: Starting worker discovery
11:53:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:53:07 DISPATCHER: Finished worker discovery
11:54:07 DISPATCHER: Starting worker discovery
11:54:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:54:07 DISPATCHER: Finished worker discovery
11:55:07 DISPATCHER: Starting worker discovery
11:55:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:55:07 DISPATCHER: Finished worker discovery
11:56:07 DISPATCHER: Starting worker discovery
11:56:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:56:07 DISPATCHER: Finished worker discovery
11:57:07 DISPATCHER: Starting worker discovery
11:57:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:57:07 DISPATCHER: Finished worker discovery
11:58:07 DISPATCHER: Starting worker discovery
11:58:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:58:07 DISPATCHER: Finished worker discovery
11:59:07 DISPATCHER: Starting worker discovery
11:59:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:59:07 DISPATCHER: Finished worker discovery
12:00:07 DISPATCHER: Starting worker discovery
12:00:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:00:07 DISPATCHER: Finished worker discovery
12:01:07 DISPATCHER: Starting worker discovery
12:01:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:01:07 DISPATCHER: Finished worker discovery
12:02:07 DISPATCHER: Starting worker discovery
12:02:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:02:07 DISPATCHER: Finished worker discovery
12:03:07 DISPATCHER: Starting worker discovery
12:03:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:03:07 DISPATCHER: Finished worker discovery
12:04:07 DISPATCHER: Starting worker discovery
12:04:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:04:07 DISPATCHER: Finished worker discovery
12:05:07 DISPATCHER: Starting worker discovery
12:05:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:05:07 DISPATCHER: Finished worker discovery
12:06:07 DISPATCHER: Starting worker discovery
12:06:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:06:07 DISPATCHER: Finished worker discovery
12:06:18 WORKER: done with job (5, 0, 2), trying to register it.
12:06:18 WORKER: registered result for job (5, 0, 2) with dispatcher
12:06:18 DISPATCHER: job (5, 0, 2) finished
12:06:18 DISPATCHER: register_result: lock acquired
12:06:18 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
12:06:18 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 87, 'last_n_outputs': 50, 'lr': 0.0010705850313562663, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.012010208507021001}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.2092161513972811, 'info': {'data03': 0.2092161513972811, 'config': "{'batch_size': 16, 'hidden_dim': 87, 'last_n_outputs': 50, 'lr': 0.0010705850313562663, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.012010208507021001}"}}
exception: None

12:06:18 job_callback for (5, 0, 2) started
12:06:18 job_callback for (5, 0, 2) got condition
12:06:18 DISPATCHER: Trying to submit another job.
12:06:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:06:18 HBMASTER: Trying to run another job!
12:06:18 job_callback for (5, 0, 2) finished
12:06:18 start sampling a new configuration.
12:06:18 done sampling a new configuration.
12:06:18 HBMASTER: schedule new run for iteration 6
12:06:18 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
12:06:18 HBMASTER: submitting job (6, 0, 0) to dispatcher
12:06:18 DISPATCHER: trying to submit job (6, 0, 0)
12:06:18 DISPATCHER: trying to notify the job_runner thread.
12:06:18 HBMASTER: job (6, 0, 0) submitted to dispatcher
12:06:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:06:18 DISPATCHER: Trying to submit another job.
12:06:18 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
12:06:18 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
12:06:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:06:18 WORKER: start processing job (6, 0, 0)
12:06:18 WORKER: args: ()
12:06:18 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 38, 'last_n_outputs': 48, 'lr': 0.0021210773170602082, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.1555943223244901}, 'budget': 400.0, 'working_directory': '.'}
12:07:07 DISPATCHER: Starting worker discovery
12:07:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:07:07 DISPATCHER: Finished worker discovery
Exception in thread Thread-524:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:08:07 DISPATCHER: Starting worker discovery
12:08:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:08:07 DISPATCHER: Finished worker discovery
12:09:07 DISPATCHER: Starting worker discovery
12:09:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:09:07 DISPATCHER: Finished worker discovery
12:10:07 DISPATCHER: Starting worker discovery
12:10:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:10:07 DISPATCHER: Finished worker discovery
12:11:07 DISPATCHER: Starting worker discovery
12:11:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:11:07 DISPATCHER: Finished worker discovery
12:12:07 DISPATCHER: Starting worker discovery
12:12:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:12:07 DISPATCHER: Finished worker discovery
12:13:07 DISPATCHER: Starting worker discovery
12:13:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:13:07 DISPATCHER: Finished worker discovery
12:13:35 WORKER: done with job (6, 0, 0), trying to register it.
12:13:35 WORKER: registered result for job (6, 0, 0) with dispatcher
12:13:35 DISPATCHER: job (6, 0, 0) finished
12:13:35 DISPATCHER: register_result: lock acquired
12:13:35 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
12:13:35 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 38, 'last_n_outputs': 48, 'lr': 0.0021210773170602082, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.1555943223244901}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 38, 'last_n_outputs': 48, 'lr': 0.0021210773170602082, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.1555943223244901}"}}
exception: None

12:13:35 job_callback for (6, 0, 0) started
12:13:35 DISPATCHER: Trying to submit another job.
12:13:35 job_callback for (6, 0, 0) got condition
12:13:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:13:35 done building a new model for budget 400.000000 based on 9/16 split
Best loss for this budget:-0.380421





12:13:35 HBMASTER: Trying to run another job!
12:13:35 job_callback for (6, 0, 0) finished
12:13:35 start sampling a new configuration.
12:13:35 best_vector: [1, 0.5834275297371827, 0.41075679607431076, 0.6999578977424581, 0.10004878087489232, 0, 0.9689383544659036, 0.24173725568656998], 3.7751147561033716e-05, 533.4780135065988, 0.020139407208454748
12:13:35 done sampling a new configuration.
12:13:35 HBMASTER: schedule new run for iteration 6
12:13:35 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
12:13:35 HBMASTER: submitting job (6, 0, 1) to dispatcher
12:13:35 DISPATCHER: trying to submit job (6, 0, 1)
12:13:35 DISPATCHER: trying to notify the job_runner thread.
12:13:35 HBMASTER: job (6, 0, 1) submitted to dispatcher
12:13:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:13:35 DISPATCHER: Trying to submit another job.
12:13:35 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
12:13:35 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
12:13:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:13:35 WORKER: start processing job (6, 0, 1)
12:13:35 WORKER: args: ()
12:13:35 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 67, 'last_n_outputs': 21, 'lr': 0.0251139945393053, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.020630389178130787}, 'budget': 400.0, 'working_directory': '.'}
12:14:07 DISPATCHER: Starting worker discovery
12:14:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:14:07 DISPATCHER: Finished worker discovery
Exception in thread Thread-525:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:15:07 DISPATCHER: Starting worker discovery
12:15:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:15:07 DISPATCHER: Finished worker discovery
12:16:07 DISPATCHER: Starting worker discovery
12:16:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:16:07 DISPATCHER: Finished worker discovery
12:17:07 DISPATCHER: Starting worker discovery
12:17:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:17:07 DISPATCHER: Finished worker discovery
12:18:07 DISPATCHER: Starting worker discovery
12:18:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:18:07 DISPATCHER: Finished worker discovery
12:19:07 DISPATCHER: Starting worker discovery
12:19:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:19:07 DISPATCHER: Finished worker discovery
12:20:07 DISPATCHER: Starting worker discovery
12:20:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:20:07 DISPATCHER: Finished worker discovery
12:20:55 WORKER: done with job (6, 0, 1), trying to register it.
12:20:55 WORKER: registered result for job (6, 0, 1) with dispatcher
12:20:55 DISPATCHER: job (6, 0, 1) finished
12:20:55 DISPATCHER: register_result: lock acquired
12:20:55 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
12:20:55 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 67, 'last_n_outputs': 21, 'lr': 0.0251139945393053, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.020630389178130787}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 67, 'last_n_outputs': 21, 'lr': 0.0251139945393053, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.020630389178130787}"}}
exception: None

12:20:55 job_callback for (6, 0, 1) started
12:20:55 DISPATCHER: Trying to submit another job.
12:20:55 job_callback for (6, 0, 1) got condition
12:20:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:20:55 done building a new model for budget 400.000000 based on 9/17 split
Best loss for this budget:-0.380421





12:20:55 HBMASTER: Trying to run another job!
12:20:55 job_callback for (6, 0, 1) finished
12:20:55 start sampling a new configuration.
12:20:55 done sampling a new configuration.
12:20:55 HBMASTER: schedule new run for iteration 6
12:20:55 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
12:20:55 HBMASTER: submitting job (6, 0, 2) to dispatcher
12:20:55 DISPATCHER: trying to submit job (6, 0, 2)
12:20:55 DISPATCHER: trying to notify the job_runner thread.
12:20:55 HBMASTER: job (6, 0, 2) submitted to dispatcher
12:20:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:20:55 DISPATCHER: Trying to submit another job.
12:20:55 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
12:20:55 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
12:20:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:20:55 WORKER: start processing job (6, 0, 2)
12:20:55 WORKER: args: ()
12:20:55 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 94, 'last_n_outputs': 1, 'lr': 0.0040768096470877365, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.030820086039165293}, 'budget': 400.0, 'working_directory': '.'}
12:21:07 DISPATCHER: Starting worker discovery
12:21:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:21:07 DISPATCHER: Finished worker discovery
Exception in thread Thread-526:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:22:07 DISPATCHER: Starting worker discovery
12:22:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:22:07 DISPATCHER: Finished worker discovery
12:23:07 DISPATCHER: Starting worker discovery
12:23:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:23:07 DISPATCHER: Finished worker discovery
12:24:07 DISPATCHER: Starting worker discovery
12:24:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:24:07 DISPATCHER: Finished worker discovery
12:25:07 DISPATCHER: Starting worker discovery
12:25:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:25:07 DISPATCHER: Finished worker discovery
12:26:07 DISPATCHER: Starting worker discovery
12:26:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:26:07 DISPATCHER: Finished worker discovery
12:27:07 DISPATCHER: Starting worker discovery
12:27:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:27:07 DISPATCHER: Finished worker discovery
12:28:07 DISPATCHER: Starting worker discovery
12:28:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:28:07 DISPATCHER: Finished worker discovery
12:28:13 WORKER: done with job (6, 0, 2), trying to register it.
12:28:13 WORKER: registered result for job (6, 0, 2) with dispatcher
12:28:13 DISPATCHER: job (6, 0, 2) finished
12:28:13 DISPATCHER: register_result: lock acquired
12:28:13 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
12:28:13 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 94, 'last_n_outputs': 1, 'lr': 0.0040768096470877365, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.030820086039165293}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 94, 'last_n_outputs': 1, 'lr': 0.0040768096470877365, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.030820086039165293}"}}
exception: None

12:28:13 job_callback for (6, 0, 2) started
12:28:13 job_callback for (6, 0, 2) got condition
12:28:13 DISPATCHER: Trying to submit another job.
12:28:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:28:13 done building a new model for budget 400.000000 based on 9/17 split
Best loss for this budget:-0.380421





12:28:13 HBMASTER: Trying to run another job!
12:28:13 job_callback for (6, 0, 2) finished
12:28:13 start sampling a new configuration.
12:28:13 best_vector: [3, 0.038781480629239695, 0.36548424054229756, 0.6164180495440016, 0.1011774928241783, 1, 0.830788780920469, 0.35151597237776655], 0.0, inf, 0.030049744122532435
12:28:13 done sampling a new configuration.
12:28:13 HBMASTER: schedule new run for iteration 6
12:28:13 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
12:28:13 HBMASTER: submitting job (6, 0, 3) to dispatcher
12:28:13 DISPATCHER: trying to submit job (6, 0, 3)
12:28:13 DISPATCHER: trying to notify the job_runner thread.
12:28:13 HBMASTER: job (6, 0, 3) submitted to dispatcher
12:28:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:28:13 DISPATCHER: Trying to submit another job.
12:28:13 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
12:28:13 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
12:28:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:28:13 WORKER: start processing job (6, 0, 3)
12:28:13 WORKER: args: ()
12:28:13 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 23, 'last_n_outputs': 19, 'lr': 0.017093700842594546, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.02866373790082655}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-527:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:29:07 DISPATCHER: Starting worker discovery
12:29:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:29:07 DISPATCHER: Finished worker discovery
12:30:07 DISPATCHER: Starting worker discovery
12:30:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:30:07 DISPATCHER: Finished worker discovery
12:31:07 DISPATCHER: Starting worker discovery
12:31:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:31:07 DISPATCHER: Finished worker discovery
12:32:07 DISPATCHER: Starting worker discovery
12:32:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:32:07 DISPATCHER: Finished worker discovery
12:33:07 DISPATCHER: Starting worker discovery
12:33:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:33:07 DISPATCHER: Finished worker discovery
12:34:07 DISPATCHER: Starting worker discovery
12:34:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:34:07 DISPATCHER: Finished worker discovery
12:35:07 DISPATCHER: Starting worker discovery
12:35:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:35:07 DISPATCHER: Finished worker discovery
12:35:32 WORKER: done with job (6, 0, 3), trying to register it.
12:35:32 WORKER: registered result for job (6, 0, 3) with dispatcher
12:35:32 DISPATCHER: job (6, 0, 3) finished
12:35:32 DISPATCHER: register_result: lock acquired
12:35:32 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
12:35:32 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 23, 'last_n_outputs': 19, 'lr': 0.017093700842594546, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.02866373790082655}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 23, 'last_n_outputs': 19, 'lr': 0.017093700842594546, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.02866373790082655}"}}
exception: None

12:35:32 job_callback for (6, 0, 3) started
12:35:32 job_callback for (6, 0, 3) got condition
12:35:32 DISPATCHER: Trying to submit another job.
12:35:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:35:32 done building a new model for budget 400.000000 based on 9/18 split
Best loss for this budget:-0.380421





12:35:32 HBMASTER: Trying to run another job!
12:35:32 job_callback for (6, 0, 3) finished
12:35:32 start sampling a new configuration.
12:35:32 best_vector: [0, 0.7684221612355955, 0.752619598104208, 0.3484211496637677, 0.10126555635984731, 0, 0.41509967877248916, 0.8208086324287335], 2.436329895077091e-34, 41.045344557837794, -0.006019963686318027
12:35:32 done sampling a new configuration.
12:35:32 HBMASTER: schedule new run for iteration 6
12:35:32 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
12:35:32 HBMASTER: submitting job (6, 0, 4) to dispatcher
12:35:32 DISPATCHER: trying to submit job (6, 0, 4)
12:35:32 DISPATCHER: trying to notify the job_runner thread.
12:35:32 HBMASTER: job (6, 0, 4) submitted to dispatcher
12:35:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:35:32 DISPATCHER: Trying to submit another job.
12:35:32 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
12:35:32 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
12:35:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:35:32 WORKER: start processing job (6, 0, 4)
12:35:32 WORKER: args: ()
12:35:32 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 82, 'last_n_outputs': 38, 'lr': 0.0049755637988881316, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.11692211198355659}, 'budget': 400.0, 'working_directory': '.'}
12:36:07 DISPATCHER: Starting worker discovery
12:36:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:36:07 DISPATCHER: Finished worker discovery
Exception in thread Thread-528:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:37:07 DISPATCHER: Starting worker discovery
12:37:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:37:07 DISPATCHER: Finished worker discovery
12:38:07 DISPATCHER: Starting worker discovery
12:38:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:38:07 DISPATCHER: Finished worker discovery
12:39:07 DISPATCHER: Starting worker discovery
12:39:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:39:07 DISPATCHER: Finished worker discovery
12:40:07 DISPATCHER: Starting worker discovery
12:40:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:40:07 DISPATCHER: Finished worker discovery
12:41:07 DISPATCHER: Starting worker discovery
12:41:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:41:07 DISPATCHER: Finished worker discovery
12:42:07 DISPATCHER: Starting worker discovery
12:42:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:42:07 DISPATCHER: Finished worker discovery
12:42:50 WORKER: done with job (6, 0, 4), trying to register it.
12:42:50 WORKER: registered result for job (6, 0, 4) with dispatcher
12:42:50 DISPATCHER: job (6, 0, 4) finished
12:42:50 DISPATCHER: register_result: lock acquired
12:42:50 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
12:42:50 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 82, 'last_n_outputs': 38, 'lr': 0.0049755637988881316, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.11692211198355659}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 82, 'last_n_outputs': 38, 'lr': 0.0049755637988881316, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.11692211198355659}"}}
exception: None

12:42:50 job_callback for (6, 0, 4) started
12:42:50 DISPATCHER: Trying to submit another job.
12:42:50 job_callback for (6, 0, 4) got condition
12:42:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:42:50 done building a new model for budget 400.000000 based on 9/19 split
Best loss for this budget:-0.380421





12:42:50 HBMASTER: Trying to run another job!
12:42:50 job_callback for (6, 0, 4) finished
12:42:50 start sampling a new configuration.
12:42:50 done sampling a new configuration.
12:42:50 HBMASTER: schedule new run for iteration 6
12:42:50 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
12:42:50 HBMASTER: submitting job (6, 0, 5) to dispatcher
12:42:50 DISPATCHER: trying to submit job (6, 0, 5)
12:42:50 DISPATCHER: trying to notify the job_runner thread.
12:42:50 HBMASTER: job (6, 0, 5) submitted to dispatcher
12:42:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:42:50 DISPATCHER: Trying to submit another job.
12:42:50 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
12:42:50 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
12:42:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:42:50 WORKER: start processing job (6, 0, 5)
12:42:50 WORKER: args: ()
12:42:50 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 59, 'last_n_outputs': 7, 'lr': 0.01003741305263515, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.1468487503807536}, 'budget': 400.0, 'working_directory': '.'}
12:43:07 DISPATCHER: Starting worker discovery
12:43:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:43:07 DISPATCHER: Finished worker discovery
Exception in thread Thread-529:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:44:07 DISPATCHER: Starting worker discovery
12:44:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:44:07 DISPATCHER: Finished worker discovery
12:45:07 DISPATCHER: Starting worker discovery
12:45:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:45:07 DISPATCHER: Finished worker discovery
12:46:07 DISPATCHER: Starting worker discovery
12:46:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:46:07 DISPATCHER: Finished worker discovery
12:47:07 DISPATCHER: Starting worker discovery
12:47:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:47:07 DISPATCHER: Finished worker discovery
12:48:07 DISPATCHER: Starting worker discovery
12:48:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:48:07 DISPATCHER: Finished worker discovery
12:49:07 DISPATCHER: Starting worker discovery
12:49:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:49:07 DISPATCHER: Finished worker discovery
12:50:04 WORKER: done with job (6, 0, 5), trying to register it.
12:50:04 WORKER: registered result for job (6, 0, 5) with dispatcher
12:50:04 DISPATCHER: job (6, 0, 5) finished
12:50:04 DISPATCHER: register_result: lock acquired
12:50:04 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
12:50:04 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 59, 'last_n_outputs': 7, 'lr': 0.01003741305263515, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.1468487503807536}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 59, 'last_n_outputs': 7, 'lr': 0.01003741305263515, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.1468487503807536}"}}
exception: None

12:50:04 job_callback for (6, 0, 5) started
12:50:04 DISPATCHER: Trying to submit another job.
12:50:04 job_callback for (6, 0, 5) got condition
12:50:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:50:04 done building a new model for budget 400.000000 based on 9/20 split
Best loss for this budget:-0.380421





12:50:04 HBMASTER: Trying to run another job!
12:50:04 job_callback for (6, 0, 5) finished
12:50:04 ITERATION: Advancing config (6, 0, 0) to next budget 1200.000000
12:50:04 ITERATION: Advancing config (6, 0, 1) to next budget 1200.000000
12:50:04 HBMASTER: schedule new run for iteration 6
12:50:04 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
12:50:04 HBMASTER: submitting job (6, 0, 0) to dispatcher
12:50:04 DISPATCHER: trying to submit job (6, 0, 0)
12:50:04 DISPATCHER: trying to notify the job_runner thread.
12:50:04 HBMASTER: job (6, 0, 0) submitted to dispatcher
12:50:04 DISPATCHER: Trying to submit another job.
12:50:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:50:04 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
12:50:04 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
12:50:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:50:04 WORKER: start processing job (6, 0, 0)
12:50:04 WORKER: args: ()
12:50:04 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 38, 'last_n_outputs': 48, 'lr': 0.0021210773170602082, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.1555943223244901}, 'budget': 1200.0, 'working_directory': '.'}
12:50:07 DISPATCHER: Starting worker discovery
12:50:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:50:07 DISPATCHER: Finished worker discovery
12:51:07 DISPATCHER: Starting worker discovery
12:51:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:51:07 DISPATCHER: Finished worker discovery
Exception in thread Thread-530:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

12:52:07 DISPATCHER: Starting worker discovery
12:52:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:52:07 DISPATCHER: Finished worker discovery
12:53:07 DISPATCHER: Starting worker discovery
12:53:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:53:07 DISPATCHER: Finished worker discovery
12:54:07 DISPATCHER: Starting worker discovery
12:54:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:54:07 DISPATCHER: Finished worker discovery
12:55:07 DISPATCHER: Starting worker discovery
12:55:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:55:07 DISPATCHER: Finished worker discovery
12:56:07 DISPATCHER: Starting worker discovery
12:56:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:56:07 DISPATCHER: Finished worker discovery
12:57:07 DISPATCHER: Starting worker discovery
12:57:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:57:07 DISPATCHER: Finished worker discovery
12:58:07 DISPATCHER: Starting worker discovery
12:58:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:58:07 DISPATCHER: Finished worker discovery
12:59:07 DISPATCHER: Starting worker discovery
12:59:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:59:07 DISPATCHER: Finished worker discovery
13:00:07 DISPATCHER: Starting worker discovery
13:00:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:00:07 DISPATCHER: Finished worker discovery
13:01:07 DISPATCHER: Starting worker discovery
13:01:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:01:07 DISPATCHER: Finished worker discovery
13:02:07 DISPATCHER: Starting worker discovery
13:02:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:02:07 DISPATCHER: Finished worker discovery
13:03:07 DISPATCHER: Starting worker discovery
13:03:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:03:07 DISPATCHER: Finished worker discovery
13:04:07 DISPATCHER: Starting worker discovery
13:04:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:04:07 DISPATCHER: Finished worker discovery
13:05:07 DISPATCHER: Starting worker discovery
13:05:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:05:07 DISPATCHER: Finished worker discovery
13:06:07 DISPATCHER: Starting worker discovery
13:06:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:06:07 DISPATCHER: Finished worker discovery
13:07:07 DISPATCHER: Starting worker discovery
13:07:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:07:07 DISPATCHER: Finished worker discovery
13:08:07 DISPATCHER: Starting worker discovery
13:08:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:08:07 DISPATCHER: Finished worker discovery
13:09:07 DISPATCHER: Starting worker discovery
13:09:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:09:07 DISPATCHER: Finished worker discovery
13:10:07 DISPATCHER: Starting worker discovery
13:10:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:10:07 DISPATCHER: Finished worker discovery
13:10:41 WORKER: done with job (6, 0, 0), trying to register it.
13:10:41 WORKER: registered result for job (6, 0, 0) with dispatcher
13:10:41 DISPATCHER: job (6, 0, 0) finished
13:10:41 DISPATCHER: register_result: lock acquired
13:10:41 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
13:10:41 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 38, 'last_n_outputs': 48, 'lr': 0.0021210773170602082, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.1555943223244901}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 38, 'last_n_outputs': 48, 'lr': 0.0021210773170602082, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.1555943223244901}"}}
exception: None

13:10:41 job_callback for (6, 0, 0) started
13:10:41 DISPATCHER: Trying to submit another job.
13:10:41 job_callback for (6, 0, 0) got condition
13:10:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:10:41 HBMASTER: Trying to run another job!
13:10:41 job_callback for (6, 0, 0) finished
13:10:41 HBMASTER: schedule new run for iteration 6
13:10:41 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
13:10:41 HBMASTER: submitting job (6, 0, 1) to dispatcher
13:10:41 DISPATCHER: trying to submit job (6, 0, 1)
13:10:41 DISPATCHER: trying to notify the job_runner thread.
13:10:41 HBMASTER: job (6, 0, 1) submitted to dispatcher
13:10:41 DISPATCHER: Trying to submit another job.
13:10:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:10:41 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
13:10:41 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
13:10:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:10:41 WORKER: start processing job (6, 0, 1)
13:10:41 WORKER: args: ()
13:10:41 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 67, 'last_n_outputs': 21, 'lr': 0.0251139945393053, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.020630389178130787}, 'budget': 1200.0, 'working_directory': '.'}
13:11:07 DISPATCHER: Starting worker discovery
13:11:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:11:07 DISPATCHER: Finished worker discovery
Exception in thread Thread-531:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:12:07 DISPATCHER: Starting worker discovery
13:12:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:12:07 DISPATCHER: Finished worker discovery
13:13:07 DISPATCHER: Starting worker discovery
13:13:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:13:07 DISPATCHER: Finished worker discovery
13:14:07 DISPATCHER: Starting worker discovery
13:14:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:14:07 DISPATCHER: Finished worker discovery
13:15:07 DISPATCHER: Starting worker discovery
13:15:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:15:07 DISPATCHER: Finished worker discovery
13:16:07 DISPATCHER: Starting worker discovery
13:16:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:16:07 DISPATCHER: Finished worker discovery
13:17:07 DISPATCHER: Starting worker discovery
13:17:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:17:07 DISPATCHER: Finished worker discovery
13:18:07 DISPATCHER: Starting worker discovery
13:18:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:18:07 DISPATCHER: Finished worker discovery
13:19:07 DISPATCHER: Starting worker discovery
13:19:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:19:07 DISPATCHER: Finished worker discovery
13:20:07 DISPATCHER: Starting worker discovery
13:20:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:20:07 DISPATCHER: Finished worker discovery
13:21:07 DISPATCHER: Starting worker discovery
13:21:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:21:07 DISPATCHER: Finished worker discovery
13:22:07 DISPATCHER: Starting worker discovery
13:22:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:22:07 DISPATCHER: Finished worker discovery
13:23:07 DISPATCHER: Starting worker discovery
13:23:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:23:07 DISPATCHER: Finished worker discovery
13:24:07 DISPATCHER: Starting worker discovery
13:24:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:24:07 DISPATCHER: Finished worker discovery
13:25:07 DISPATCHER: Starting worker discovery
13:25:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:25:07 DISPATCHER: Finished worker discovery
13:26:07 DISPATCHER: Starting worker discovery
13:26:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:26:07 DISPATCHER: Finished worker discovery
13:27:07 DISPATCHER: Starting worker discovery
13:27:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:27:07 DISPATCHER: Finished worker discovery
13:28:07 DISPATCHER: Starting worker discovery
13:28:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:28:07 DISPATCHER: Finished worker discovery
13:29:07 DISPATCHER: Starting worker discovery
13:29:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:29:07 DISPATCHER: Finished worker discovery
13:30:07 DISPATCHER: Starting worker discovery
13:30:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:30:07 DISPATCHER: Finished worker discovery
13:31:07 DISPATCHER: Starting worker discovery
13:31:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:31:07 DISPATCHER: Finished worker discovery
13:31:21 WORKER: done with job (6, 0, 1), trying to register it.
13:31:21 WORKER: registered result for job (6, 0, 1) with dispatcher
13:31:21 DISPATCHER: job (6, 0, 1) finished
13:31:21 DISPATCHER: register_result: lock acquired
13:31:21 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
13:31:21 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 67, 'last_n_outputs': 21, 'lr': 0.0251139945393053, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.020630389178130787}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 67, 'last_n_outputs': 21, 'lr': 0.0251139945393053, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.020630389178130787}"}}
exception: None

13:31:21 job_callback for (6, 0, 1) started
13:31:21 job_callback for (6, 0, 1) got condition
13:31:21 DISPATCHER: Trying to submit another job.
13:31:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:31:21 HBMASTER: Trying to run another job!
13:31:21 job_callback for (6, 0, 1) finished
13:31:21 start sampling a new configuration.
13:31:21 best_vector: [0, 0.9923324852047146, 0.9909560692841732, 0.3467666351212593, 0.10229035425804808, 0, 0.6630142155985934, 0.12062470511384923], 9.091113936589418e-05, 17.744341354191842, 0.001613158289806934
13:31:21 done sampling a new configuration.
13:31:21 HBMASTER: schedule new run for iteration 7
13:31:21 HBMASTER: trying submitting job (7, 0, 0) to dispatcher
13:31:21 HBMASTER: submitting job (7, 0, 0) to dispatcher
13:31:21 DISPATCHER: trying to submit job (7, 0, 0)
13:31:21 DISPATCHER: trying to notify the job_runner thread.
13:31:21 HBMASTER: job (7, 0, 0) submitted to dispatcher
13:31:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:31:21 DISPATCHER: Trying to submit another job.
13:31:21 DISPATCHER: starting job (7, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
13:31:21 DISPATCHER: job (7, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
13:31:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:31:21 WORKER: start processing job (7, 0, 0)
13:31:21 WORKER: args: ()
13:31:21 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 50, 'lr': 0.004937797440643658, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.01435279095728673}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-532:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:32:07 DISPATCHER: Starting worker discovery
13:32:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:32:07 DISPATCHER: Finished worker discovery
13:33:07 DISPATCHER: Starting worker discovery
13:33:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:33:07 DISPATCHER: Finished worker discovery
13:34:07 DISPATCHER: Starting worker discovery
13:34:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:34:07 DISPATCHER: Finished worker discovery
13:35:07 DISPATCHER: Starting worker discovery
13:35:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:35:07 DISPATCHER: Finished worker discovery
13:36:07 DISPATCHER: Starting worker discovery
13:36:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:36:07 DISPATCHER: Finished worker discovery
13:37:07 DISPATCHER: Starting worker discovery
13:37:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:37:07 DISPATCHER: Finished worker discovery
13:38:07 DISPATCHER: Starting worker discovery
13:38:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:38:07 DISPATCHER: Finished worker discovery
13:39:07 DISPATCHER: Starting worker discovery
13:39:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:39:07 DISPATCHER: Finished worker discovery
13:40:07 DISPATCHER: Starting worker discovery
13:40:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:40:07 DISPATCHER: Finished worker discovery
13:41:07 DISPATCHER: Starting worker discovery
13:41:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:41:07 DISPATCHER: Finished worker discovery
13:42:07 DISPATCHER: Starting worker discovery
13:42:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:42:07 DISPATCHER: Finished worker discovery
13:43:07 DISPATCHER: Starting worker discovery
13:43:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:43:07 DISPATCHER: Finished worker discovery
13:44:07 DISPATCHER: Starting worker discovery
13:44:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:44:07 DISPATCHER: Finished worker discovery
13:45:07 DISPATCHER: Starting worker discovery
13:45:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:45:07 DISPATCHER: Finished worker discovery
13:46:07 DISPATCHER: Starting worker discovery
13:46:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:46:07 DISPATCHER: Finished worker discovery
13:47:07 DISPATCHER: Starting worker discovery
13:47:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:47:07 DISPATCHER: Finished worker discovery
13:48:07 DISPATCHER: Starting worker discovery
13:48:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:48:07 DISPATCHER: Finished worker discovery
13:49:07 DISPATCHER: Starting worker discovery
13:49:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:49:07 DISPATCHER: Finished worker discovery
13:50:07 DISPATCHER: Starting worker discovery
13:50:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:50:07 DISPATCHER: Finished worker discovery
13:51:07 DISPATCHER: Starting worker discovery
13:51:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:51:07 DISPATCHER: Finished worker discovery
13:51:56 WORKER: done with job (7, 0, 0), trying to register it.
13:51:56 WORKER: registered result for job (7, 0, 0) with dispatcher
13:51:56 DISPATCHER: job (7, 0, 0) finished
13:51:56 DISPATCHER: register_result: lock acquired
13:51:56 DISPATCHER: job (7, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
13:51:56 job_id: (7, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 50, 'lr': 0.004937797440643658, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.01435279095728673}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.18710547716103684, 'info': {'data03': 0.18710547716103684, 'config': "{'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 50, 'lr': 0.004937797440643658, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.01435279095728673}"}}
exception: None

13:51:56 job_callback for (7, 0, 0) started
13:51:56 job_callback for (7, 0, 0) got condition
13:51:56 DISPATCHER: Trying to submit another job.
13:51:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:51:56 HBMASTER: Trying to run another job!
13:51:56 job_callback for (7, 0, 0) finished
13:51:56 start sampling a new configuration.
13:51:57 best_vector: [0, 0.7503059259416789, 0.814912637607711, 0.524653692789788, 0.10097644559403612, 0, 0.9359128020380281, 0.3010180084432585], 0.00012975662117354345, 418.1765334096741, 0.05426117402930472
13:51:57 done sampling a new configuration.
13:51:57 HBMASTER: schedule new run for iteration 7
13:51:57 HBMASTER: trying submitting job (7, 0, 1) to dispatcher
13:51:57 HBMASTER: submitting job (7, 0, 1) to dispatcher
13:51:57 DISPATCHER: trying to submit job (7, 0, 1)
13:51:57 DISPATCHER: trying to notify the job_runner thread.
13:51:57 HBMASTER: job (7, 0, 1) submitted to dispatcher
13:51:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:51:57 DISPATCHER: Trying to submit another job.
13:51:57 DISPATCHER: starting job (7, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
13:51:57 DISPATCHER: job (7, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
13:51:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:51:57 WORKER: start processing job (7, 0, 1)
13:51:57 WORKER: args: ()
13:51:57 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 80, 'last_n_outputs': 41, 'lr': 0.011202304812991634, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.024639588937835927}, 'budget': 1200.0, 'working_directory': '.'}
13:52:07 DISPATCHER: Starting worker discovery
13:52:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:52:07 DISPATCHER: Finished worker discovery
Exception in thread Thread-533:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

13:53:07 DISPATCHER: Starting worker discovery
13:53:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:53:07 DISPATCHER: Finished worker discovery
13:54:07 DISPATCHER: Starting worker discovery
13:54:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:54:07 DISPATCHER: Finished worker discovery
13:55:07 DISPATCHER: Starting worker discovery
13:55:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:55:07 DISPATCHER: Finished worker discovery
13:56:07 DISPATCHER: Starting worker discovery
13:56:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:56:07 DISPATCHER: Finished worker discovery
13:57:07 DISPATCHER: Starting worker discovery
13:57:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:57:07 DISPATCHER: Finished worker discovery
13:58:07 DISPATCHER: Starting worker discovery
13:58:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:58:07 DISPATCHER: Finished worker discovery
13:59:07 DISPATCHER: Starting worker discovery
13:59:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:59:07 DISPATCHER: Finished worker discovery
14:00:07 DISPATCHER: Starting worker discovery
14:00:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:00:07 DISPATCHER: Finished worker discovery
14:01:07 DISPATCHER: Starting worker discovery
14:01:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:01:07 DISPATCHER: Finished worker discovery
14:02:07 DISPATCHER: Starting worker discovery
14:02:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:02:07 DISPATCHER: Finished worker discovery
14:03:07 DISPATCHER: Starting worker discovery
14:03:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:03:07 DISPATCHER: Finished worker discovery
14:04:07 DISPATCHER: Starting worker discovery
14:04:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:04:07 DISPATCHER: Finished worker discovery
14:05:07 DISPATCHER: Starting worker discovery
14:05:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:05:07 DISPATCHER: Finished worker discovery
14:06:07 DISPATCHER: Starting worker discovery
14:06:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:06:07 DISPATCHER: Finished worker discovery
14:07:07 DISPATCHER: Starting worker discovery
14:07:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:07:07 DISPATCHER: Finished worker discovery
14:08:07 DISPATCHER: Starting worker discovery
14:08:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:08:08 DISPATCHER: Finished worker discovery
14:09:08 DISPATCHER: Starting worker discovery
14:09:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:09:08 DISPATCHER: Finished worker discovery
14:10:08 DISPATCHER: Starting worker discovery
14:10:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:10:08 DISPATCHER: Finished worker discovery
14:11:08 DISPATCHER: Starting worker discovery
14:11:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:11:08 DISPATCHER: Finished worker discovery
14:12:08 DISPATCHER: Starting worker discovery
14:12:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:12:08 DISPATCHER: Finished worker discovery
14:12:35 WORKER: done with job (7, 0, 1), trying to register it.
14:12:35 WORKER: registered result for job (7, 0, 1) with dispatcher
14:12:35 DISPATCHER: job (7, 0, 1) finished
14:12:35 DISPATCHER: register_result: lock acquired
14:12:35 DISPATCHER: job (7, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
14:12:35 job_id: (7, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 80, 'last_n_outputs': 41, 'lr': 0.011202304812991634, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.024639588937835927}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.1383903890859785, 'info': {'data03': 0.1383903890859785, 'config': "{'batch_size': 16, 'hidden_dim': 80, 'last_n_outputs': 41, 'lr': 0.011202304812991634, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.024639588937835927}"}}
exception: None

14:12:35 job_callback for (7, 0, 1) started
14:12:35 job_callback for (7, 0, 1) got condition
14:12:35 DISPATCHER: Trying to submit another job.
14:12:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:12:35 HBMASTER: Trying to run another job!
14:12:35 job_callback for (7, 0, 1) finished
14:12:35 start sampling a new configuration.
14:12:35 best_vector: [0, 0.31574074987339373, 0.9077856917250126, 0.14284392122784445, 0.09883071125428425, 0, 0.7160092727103394, 0.5187874650758479], 1.4560120992070705e-05, 260.4784955963828, 0.00379259841171589
14:12:35 done sampling a new configuration.
14:12:35 HBMASTER: schedule new run for iteration 7
14:12:35 HBMASTER: trying submitting job (7, 0, 2) to dispatcher
14:12:35 HBMASTER: submitting job (7, 0, 2) to dispatcher
14:12:35 DISPATCHER: trying to submit job (7, 0, 2)
14:12:35 DISPATCHER: trying to notify the job_runner thread.
14:12:35 HBMASTER: job (7, 0, 2) submitted to dispatcher
14:12:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:12:35 DISPATCHER: Trying to submit another job.
14:12:35 DISPATCHER: starting job (7, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
14:12:35 DISPATCHER: job (7, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
14:12:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:12:35 WORKER: start processing job (7, 0, 2)
14:12:35 WORKER: args: ()
14:12:35 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 45, 'last_n_outputs': 46, 'lr': 0.0019305801764224358, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.04731055616041974}, 'budget': 1200.0, 'working_directory': '.'}
14:13:08 DISPATCHER: Starting worker discovery
14:13:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:13:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-534:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:14:08 DISPATCHER: Starting worker discovery
14:14:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:14:08 DISPATCHER: Finished worker discovery
14:15:08 DISPATCHER: Starting worker discovery
14:15:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:15:08 DISPATCHER: Finished worker discovery
14:16:08 DISPATCHER: Starting worker discovery
14:16:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:16:08 DISPATCHER: Finished worker discovery
14:17:08 DISPATCHER: Starting worker discovery
14:17:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:17:08 DISPATCHER: Finished worker discovery
14:18:08 DISPATCHER: Starting worker discovery
14:18:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:18:08 DISPATCHER: Finished worker discovery
14:19:08 DISPATCHER: Starting worker discovery
14:19:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:19:08 DISPATCHER: Finished worker discovery
14:20:08 DISPATCHER: Starting worker discovery
14:20:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:20:08 DISPATCHER: Finished worker discovery
14:21:08 DISPATCHER: Starting worker discovery
14:21:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:21:08 DISPATCHER: Finished worker discovery
14:22:08 DISPATCHER: Starting worker discovery
14:22:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:22:08 DISPATCHER: Finished worker discovery
14:23:08 DISPATCHER: Starting worker discovery
14:23:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:23:08 DISPATCHER: Finished worker discovery
14:24:08 DISPATCHER: Starting worker discovery
14:24:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:24:08 DISPATCHER: Finished worker discovery
14:25:08 DISPATCHER: Starting worker discovery
14:25:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:25:08 DISPATCHER: Finished worker discovery
14:26:08 DISPATCHER: Starting worker discovery
14:26:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:26:08 DISPATCHER: Finished worker discovery
14:27:08 DISPATCHER: Starting worker discovery
14:27:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:27:08 DISPATCHER: Finished worker discovery
14:28:08 DISPATCHER: Starting worker discovery
14:28:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:28:08 DISPATCHER: Finished worker discovery
14:29:08 DISPATCHER: Starting worker discovery
14:29:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:29:08 DISPATCHER: Finished worker discovery
14:30:08 DISPATCHER: Starting worker discovery
14:30:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:30:08 DISPATCHER: Finished worker discovery
14:31:08 DISPATCHER: Starting worker discovery
14:31:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:31:08 DISPATCHER: Finished worker discovery
14:32:08 DISPATCHER: Starting worker discovery
14:32:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:32:08 DISPATCHER: Finished worker discovery
14:33:08 DISPATCHER: Starting worker discovery
14:33:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:33:08 DISPATCHER: Finished worker discovery
14:33:13 WORKER: done with job (7, 0, 2), trying to register it.
14:33:13 WORKER: registered result for job (7, 0, 2) with dispatcher
14:33:13 DISPATCHER: job (7, 0, 2) finished
14:33:13 DISPATCHER: register_result: lock acquired
14:33:13 DISPATCHER: job (7, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
14:33:13 job_id: (7, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 45, 'last_n_outputs': 46, 'lr': 0.0019305801764224358, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.04731055616041974}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': 0.004826035039949845, 'info': {'data03': -0.004826035039949845, 'config': "{'batch_size': 16, 'hidden_dim': 45, 'last_n_outputs': 46, 'lr': 0.0019305801764224358, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.04731055616041974}"}}
exception: None

14:33:13 job_callback for (7, 0, 2) started
14:33:13 DISPATCHER: Trying to submit another job.
14:33:13 job_callback for (7, 0, 2) got condition
14:33:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:33:13 HBMASTER: Trying to run another job!
14:33:13 job_callback for (7, 0, 2) finished
14:33:13 start sampling a new configuration.
14:33:13 done sampling a new configuration.
14:33:13 HBMASTER: schedule new run for iteration 7
14:33:13 HBMASTER: trying submitting job (7, 0, 3) to dispatcher
14:33:13 HBMASTER: submitting job (7, 0, 3) to dispatcher
14:33:13 DISPATCHER: trying to submit job (7, 0, 3)
14:33:13 DISPATCHER: trying to notify the job_runner thread.
14:33:13 HBMASTER: job (7, 0, 3) submitted to dispatcher
14:33:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:33:13 DISPATCHER: Trying to submit another job.
14:33:13 DISPATCHER: starting job (7, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
14:33:13 DISPATCHER: job (7, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
14:33:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:33:13 WORKER: start processing job (7, 0, 3)
14:33:13 WORKER: args: ()
14:33:13 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 96, 'last_n_outputs': 19, 'lr': 0.018937222533370716, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.01453649021446047}, 'budget': 1200.0, 'working_directory': '.'}
14:34:08 DISPATCHER: Starting worker discovery
14:34:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:34:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-535:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:35:08 DISPATCHER: Starting worker discovery
14:35:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:35:08 DISPATCHER: Finished worker discovery
14:36:08 DISPATCHER: Starting worker discovery
14:36:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:36:08 DISPATCHER: Finished worker discovery
14:37:08 DISPATCHER: Starting worker discovery
14:37:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:37:08 DISPATCHER: Finished worker discovery
14:38:08 DISPATCHER: Starting worker discovery
14:38:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:38:08 DISPATCHER: Finished worker discovery
14:39:08 DISPATCHER: Starting worker discovery
14:39:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:39:08 DISPATCHER: Finished worker discovery
14:40:08 DISPATCHER: Starting worker discovery
14:40:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:40:08 DISPATCHER: Finished worker discovery
14:41:08 DISPATCHER: Starting worker discovery
14:41:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:41:08 DISPATCHER: Finished worker discovery
14:42:08 DISPATCHER: Starting worker discovery
14:42:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:42:08 DISPATCHER: Finished worker discovery
14:43:08 DISPATCHER: Starting worker discovery
14:43:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:43:08 DISPATCHER: Finished worker discovery
14:44:08 DISPATCHER: Starting worker discovery
14:44:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:44:08 DISPATCHER: Finished worker discovery
14:45:08 DISPATCHER: Starting worker discovery
14:45:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:45:08 DISPATCHER: Finished worker discovery
14:46:08 DISPATCHER: Starting worker discovery
14:46:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:46:08 DISPATCHER: Finished worker discovery
14:47:08 DISPATCHER: Starting worker discovery
14:47:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:47:08 DISPATCHER: Finished worker discovery
14:48:08 DISPATCHER: Starting worker discovery
14:48:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:48:08 DISPATCHER: Finished worker discovery
14:49:08 DISPATCHER: Starting worker discovery
14:49:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:49:08 DISPATCHER: Finished worker discovery
14:50:08 DISPATCHER: Starting worker discovery
14:50:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:50:08 DISPATCHER: Finished worker discovery
14:51:08 DISPATCHER: Starting worker discovery
14:51:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:51:08 DISPATCHER: Finished worker discovery
14:52:08 DISPATCHER: Starting worker discovery
14:52:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:52:08 DISPATCHER: Finished worker discovery
14:53:08 DISPATCHER: Starting worker discovery
14:53:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:53:08 DISPATCHER: Finished worker discovery
14:53:49 WORKER: done with job (7, 0, 3), trying to register it.
14:53:49 WORKER: registered result for job (7, 0, 3) with dispatcher
14:53:49 DISPATCHER: job (7, 0, 3) finished
14:53:49 DISPATCHER: register_result: lock acquired
14:53:49 DISPATCHER: job (7, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
14:53:49 job_id: (7, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 96, 'last_n_outputs': 19, 'lr': 0.018937222533370716, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.01453649021446047}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 96, 'last_n_outputs': 19, 'lr': 0.018937222533370716, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.01453649021446047}"}}
exception: None

14:53:49 job_callback for (7, 0, 3) started
14:53:49 DISPATCHER: Trying to submit another job.
14:53:49 job_callback for (7, 0, 3) got condition
14:53:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:53:49 HBMASTER: Trying to run another job!
14:53:49 job_callback for (7, 0, 3) finished
14:53:49 start sampling a new configuration.
14:53:49 best_vector: [0, 0.44373356116259105, 0.6840621494093707, 0.18053062607965709, 0.10028246850078745, 0, 0.882752929972334, 0.6304678690684031], 2.3887601189946346e-05, 220.04805394436897, 0.005256420155246886
14:53:49 done sampling a new configuration.
14:53:49 HBMASTER: schedule new run for iteration 8
14:53:49 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
14:53:49 HBMASTER: submitting job (8, 0, 0) to dispatcher
14:53:49 DISPATCHER: trying to submit job (8, 0, 0)
14:53:49 DISPATCHER: trying to notify the job_runner thread.
14:53:49 HBMASTER: job (8, 0, 0) submitted to dispatcher
14:53:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:53:49 DISPATCHER: Trying to submit another job.
14:53:49 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
14:53:49 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
14:53:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:53:49 WORKER: start processing job (8, 0, 0)
14:53:49 WORKER: args: ()
14:53:49 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 55, 'last_n_outputs': 35, 'lr': 0.002296472515873136, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.06610854655163631}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:54:08 DISPATCHER: Starting worker discovery
14:54:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:54:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-536:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:55:08 DISPATCHER: Starting worker discovery
14:55:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:55:08 DISPATCHER: Finished worker discovery
14:55:12 WORKER: done with job (8, 0, 0), trying to register it.
14:55:12 WORKER: registered result for job (8, 0, 0) with dispatcher
14:55:12 DISPATCHER: job (8, 0, 0) finished
14:55:12 DISPATCHER: register_result: lock acquired
14:55:12 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
14:55:12 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 55, 'last_n_outputs': 35, 'lr': 0.002296472515873136, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.06610854655163631}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.250437303766817, 'info': {'data03': 0.250437303766817, 'config': "{'batch_size': 16, 'hidden_dim': 55, 'last_n_outputs': 35, 'lr': 0.002296472515873136, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.06610854655163631}"}}
exception: None

14:55:12 job_callback for (8, 0, 0) started
14:55:12 job_callback for (8, 0, 0) got condition
14:55:12 DISPATCHER: Trying to submit another job.
14:55:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:55:12 HBMASTER: Trying to run another job!
14:55:12 job_callback for (8, 0, 0) finished
14:55:12 start sampling a new configuration.
14:55:12 best_vector: [0, 0.8888351602399407, 0.8475359481614778, 0.11679278101769017, 0.10171721586798621, 0, 0.7817712873296806, 0.26398990202529937], 5.925930896757167e-06, 282.41395022804477, 0.0016735655533316111
14:55:12 done sampling a new configuration.
14:55:12 HBMASTER: schedule new run for iteration 8
14:55:12 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
14:55:12 HBMASTER: submitting job (8, 0, 1) to dispatcher
14:55:12 DISPATCHER: trying to submit job (8, 0, 1)
14:55:12 DISPATCHER: trying to notify the job_runner thread.
14:55:12 HBMASTER: job (8, 0, 1) submitted to dispatcher
14:55:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:55:12 DISPATCHER: Trying to submit another job.
14:55:12 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
14:55:12 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
14:55:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:55:12 WORKER: start processing job (8, 0, 1)
14:55:12 WORKER: args: ()
14:55:12 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 91, 'last_n_outputs': 43, 'lr': 0.0017123224947501745, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.022052548256056764}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-537:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:56:08 DISPATCHER: Starting worker discovery
14:56:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:56:08 DISPATCHER: Finished worker discovery
14:56:33 WORKER: done with job (8, 0, 1), trying to register it.
14:56:33 WORKER: registered result for job (8, 0, 1) with dispatcher
14:56:33 DISPATCHER: job (8, 0, 1) finished
14:56:33 DISPATCHER: register_result: lock acquired
14:56:33 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
14:56:33 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 91, 'last_n_outputs': 43, 'lr': 0.0017123224947501745, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.022052548256056764}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.20711351654203977, 'info': {'data03': 0.20711351654203977, 'config': "{'batch_size': 16, 'hidden_dim': 91, 'last_n_outputs': 43, 'lr': 0.0017123224947501745, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.022052548256056764}"}}
exception: None

14:56:33 job_callback for (8, 0, 1) started
14:56:33 DISPATCHER: Trying to submit another job.
14:56:33 job_callback for (8, 0, 1) got condition
14:56:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:56:33 HBMASTER: Trying to run another job!
14:56:33 job_callback for (8, 0, 1) finished
14:56:33 start sampling a new configuration.
14:56:33 best_vector: [0, 0.5523164855135397, 0.9268222701242802, 0.014515713677168002, 0.1010914321953539, 0, 0.6029912100308334, 0.38659339722351227], 1.4338475472556232e-05, 103.37967232461762, 0.00148230689598743
14:56:33 done sampling a new configuration.
14:56:33 HBMASTER: schedule new run for iteration 8
14:56:33 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
14:56:33 HBMASTER: submitting job (8, 0, 2) to dispatcher
14:56:33 DISPATCHER: trying to submit job (8, 0, 2)
14:56:33 DISPATCHER: trying to notify the job_runner thread.
14:56:33 HBMASTER: job (8, 0, 2) submitted to dispatcher
14:56:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:56:33 DISPATCHER: Trying to submit another job.
14:56:33 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
14:56:33 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
14:56:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:56:33 WORKER: start processing job (8, 0, 2)
14:56:33 WORKER: args: ()
14:56:33 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 64, 'last_n_outputs': 47, 'lr': 0.0010691322432775869, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.03183974683553772}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:57:08 DISPATCHER: Starting worker discovery
14:57:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:57:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-538:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:57:56 WORKER: done with job (8, 0, 2), trying to register it.
14:57:56 WORKER: registered result for job (8, 0, 2) with dispatcher
14:57:56 DISPATCHER: job (8, 0, 2) finished
14:57:56 DISPATCHER: register_result: lock acquired
14:57:56 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
14:57:56 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 64, 'last_n_outputs': 47, 'lr': 0.0010691322432775869, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.03183974683553772}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.16763577614285582, 'info': {'data03': 0.16763577614285582, 'config': "{'batch_size': 16, 'hidden_dim': 64, 'last_n_outputs': 47, 'lr': 0.0010691322432775869, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.03183974683553772}"}}
exception: None

14:57:56 job_callback for (8, 0, 2) started
14:57:56 DISPATCHER: Trying to submit another job.
14:57:56 job_callback for (8, 0, 2) got condition
14:57:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:57:56 HBMASTER: Trying to run another job!
14:57:56 job_callback for (8, 0, 2) finished
14:57:56 start sampling a new configuration.
14:57:56 done sampling a new configuration.
14:57:56 HBMASTER: schedule new run for iteration 8
14:57:56 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
14:57:56 HBMASTER: submitting job (8, 0, 3) to dispatcher
14:57:56 DISPATCHER: trying to submit job (8, 0, 3)
14:57:56 DISPATCHER: trying to notify the job_runner thread.
14:57:56 HBMASTER: job (8, 0, 3) submitted to dispatcher
14:57:56 DISPATCHER: Trying to submit another job.
14:57:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:57:56 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
14:57:56 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
14:57:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:57:56 WORKER: start processing job (8, 0, 3)
14:57:56 WORKER: args: ()
14:57:56 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 87, 'last_n_outputs': 16, 'lr': 0.003271407655901078, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.037829207272180025}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:58:08 DISPATCHER: Starting worker discovery
14:58:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:58:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-539:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

14:59:08 DISPATCHER: Starting worker discovery
14:59:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:59:08 DISPATCHER: Finished worker discovery
14:59:22 WORKER: done with job (8, 0, 3), trying to register it.
14:59:22 WORKER: registered result for job (8, 0, 3) with dispatcher
14:59:22 DISPATCHER: job (8, 0, 3) finished
14:59:22 DISPATCHER: register_result: lock acquired
14:59:22 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
14:59:22 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 87, 'last_n_outputs': 16, 'lr': 0.003271407655901078, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.037829207272180025}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 87, 'last_n_outputs': 16, 'lr': 0.003271407655901078, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.037829207272180025}"}}
exception: None

14:59:22 job_callback for (8, 0, 3) started
14:59:22 DISPATCHER: Trying to submit another job.
14:59:22 job_callback for (8, 0, 3) got condition
14:59:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:59:22 HBMASTER: Trying to run another job!
14:59:22 job_callback for (8, 0, 3) finished
14:59:22 start sampling a new configuration.
14:59:22 best_vector: [0, 0.6640048932079694, 0.5286088124661539, 0.33433747606708736, 0.10050579739833104, 0, 0.987279532816928, 0.12747529260865176], 7.075230956844585e-05, 630.5577436986919, 0.04461341668295058
14:59:22 done sampling a new configuration.
14:59:22 HBMASTER: schedule new run for iteration 8
14:59:22 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
14:59:22 HBMASTER: submitting job (8, 0, 4) to dispatcher
14:59:22 DISPATCHER: trying to submit job (8, 0, 4)
14:59:22 DISPATCHER: trying to notify the job_runner thread.
14:59:22 HBMASTER: job (8, 0, 4) submitted to dispatcher
14:59:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:59:22 DISPATCHER: Trying to submit another job.
14:59:22 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
14:59:22 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
14:59:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:59:22 WORKER: start processing job (8, 0, 4)
14:59:22 WORKER: args: ()
14:59:22 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 73, 'last_n_outputs': 27, 'lr': 0.004663102396018074, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.014650389778389028}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:00:08 DISPATCHER: Starting worker discovery
15:00:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:00:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-540:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:00:47 WORKER: done with job (8, 0, 4), trying to register it.
15:00:47 WORKER: registered result for job (8, 0, 4) with dispatcher
15:00:47 DISPATCHER: job (8, 0, 4) finished
15:00:47 DISPATCHER: register_result: lock acquired
15:00:47 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:00:47 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 73, 'last_n_outputs': 27, 'lr': 0.004663102396018074, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.014650389778389028}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 73, 'last_n_outputs': 27, 'lr': 0.004663102396018074, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.014650389778389028}"}}
exception: None

15:00:47 job_callback for (8, 0, 4) started
15:00:47 job_callback for (8, 0, 4) got condition
15:00:47 DISPATCHER: Trying to submit another job.
15:00:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:00:47 HBMASTER: Trying to run another job!
15:00:47 job_callback for (8, 0, 4) finished
15:00:47 start sampling a new configuration.
15:00:47 done sampling a new configuration.
15:00:47 HBMASTER: schedule new run for iteration 8
15:00:47 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
15:00:47 HBMASTER: submitting job (8, 0, 5) to dispatcher
15:00:47 DISPATCHER: trying to submit job (8, 0, 5)
15:00:47 DISPATCHER: trying to notify the job_runner thread.
15:00:47 HBMASTER: job (8, 0, 5) submitted to dispatcher
15:00:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:00:47 DISPATCHER: Trying to submit another job.
15:00:47 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:00:47 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:00:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:00:47 WORKER: start processing job (8, 0, 5)
15:00:47 WORKER: args: ()
15:00:47 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 51, 'last_n_outputs': 18, 'lr': 0.026984222391860192, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.13430848762222913}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:01:08 DISPATCHER: Starting worker discovery
15:01:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:01:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-541:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:02:08 DISPATCHER: Starting worker discovery
15:02:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:02:08 DISPATCHER: Finished worker discovery
15:02:10 WORKER: done with job (8, 0, 5), trying to register it.
15:02:10 WORKER: registered result for job (8, 0, 5) with dispatcher
15:02:10 DISPATCHER: job (8, 0, 5) finished
15:02:10 DISPATCHER: register_result: lock acquired
15:02:10 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:02:10 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 51, 'last_n_outputs': 18, 'lr': 0.026984222391860192, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.13430848762222913}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 51, 'last_n_outputs': 18, 'lr': 0.026984222391860192, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.13430848762222913}"}}
exception: None

15:02:10 job_callback for (8, 0, 5) started
15:02:10 DISPATCHER: Trying to submit another job.
15:02:10 job_callback for (8, 0, 5) got condition
15:02:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:02:10 HBMASTER: Trying to run another job!
15:02:10 job_callback for (8, 0, 5) finished
15:02:10 start sampling a new configuration.
15:02:11 best_vector: [0, 0.9377992670889552, 0.8983114671805866, 0.17306547452953222, 0.09950954848008836, 0, 0.7984245351528401, 0.08155495615380959], 1.691606715714626e-06, 909.66752751919, 0.0015387996986189812
15:02:11 done sampling a new configuration.
15:02:11 HBMASTER: schedule new run for iteration 8
15:02:11 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
15:02:11 HBMASTER: submitting job (8, 0, 6) to dispatcher
15:02:11 DISPATCHER: trying to submit job (8, 0, 6)
15:02:11 DISPATCHER: trying to notify the job_runner thread.
15:02:11 HBMASTER: job (8, 0, 6) submitted to dispatcher
15:02:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:02:11 DISPATCHER: Trying to submit another job.
15:02:11 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:02:11 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:02:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:02:11 WORKER: start processing job (8, 0, 6)
15:02:11 WORKER: args: ()
15:02:11 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 95, 'last_n_outputs': 45, 'lr': 0.0022188653542262017, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.012767487585816367}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-542:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:03:08 DISPATCHER: Starting worker discovery
15:03:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:03:08 DISPATCHER: Finished worker discovery
15:03:33 WORKER: done with job (8, 0, 6), trying to register it.
15:03:33 WORKER: registered result for job (8, 0, 6) with dispatcher
15:03:33 DISPATCHER: job (8, 0, 6) finished
15:03:33 DISPATCHER: register_result: lock acquired
15:03:33 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:03:33 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 95, 'last_n_outputs': 45, 'lr': 0.0022188653542262017, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.012767487585816367}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.24188905715735176, 'info': {'data03': 0.24188905715735176, 'config': "{'batch_size': 16, 'hidden_dim': 95, 'last_n_outputs': 45, 'lr': 0.0022188653542262017, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.012767487585816367}"}}
exception: None

15:03:33 job_callback for (8, 0, 6) started
15:03:33 DISPATCHER: Trying to submit another job.
15:03:33 job_callback for (8, 0, 6) got condition
15:03:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:03:33 HBMASTER: Trying to run another job!
15:03:33 job_callback for (8, 0, 6) finished
15:03:33 start sampling a new configuration.
15:03:33 best_vector: [0, 0.40941485255187027, 0.855957606195456, 0.3783664842861182, 0.10055957666304872, 0, 0.9745339696987383, 0.5366317222802786], 9.299650642755461e-05, 181.02951545623804, 0.01683511249770314
15:03:33 done sampling a new configuration.
15:03:33 HBMASTER: schedule new run for iteration 8
15:03:33 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
15:03:33 HBMASTER: submitting job (8, 0, 7) to dispatcher
15:03:33 DISPATCHER: trying to submit job (8, 0, 7)
15:03:33 DISPATCHER: trying to notify the job_runner thread.
15:03:33 HBMASTER: job (8, 0, 7) submitted to dispatcher
15:03:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:03:33 DISPATCHER: Trying to submit another job.
15:03:33 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:03:33 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:03:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:03:33 WORKER: start processing job (8, 0, 7)
15:03:33 WORKER: args: ()
15:03:33 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 53, 'last_n_outputs': 43, 'lr': 0.005711273638434178, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.04990843679139539}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:04:08 DISPATCHER: Starting worker discovery
15:04:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:04:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-543:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:04:56 WORKER: done with job (8, 0, 7), trying to register it.
15:04:56 WORKER: registered result for job (8, 0, 7) with dispatcher
15:04:56 DISPATCHER: job (8, 0, 7) finished
15:04:56 DISPATCHER: register_result: lock acquired
15:04:56 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:04:56 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 53, 'last_n_outputs': 43, 'lr': 0.005711273638434178, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.04990843679139539}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.08705357421272132, 'info': {'data03': 0.08705357421272132, 'config': "{'batch_size': 16, 'hidden_dim': 53, 'last_n_outputs': 43, 'lr': 0.005711273638434178, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.04990843679139539}"}}
exception: None

15:04:56 job_callback for (8, 0, 7) started
15:04:56 DISPATCHER: Trying to submit another job.
15:04:56 job_callback for (8, 0, 7) got condition
15:04:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:04:56 HBMASTER: Trying to run another job!
15:04:56 job_callback for (8, 0, 7) finished
15:04:56 start sampling a new configuration.
15:04:56 best_vector: [0, 0.4010368889922893, 0.7220740266649345, 0.17878740143643856, 0.09916548658152613, 0, 0.6971855233514324, 0.7454907901095211], 0.00011445295581982741, 49.815116082439744, 0.00570148728014305
15:04:56 done sampling a new configuration.
15:04:56 HBMASTER: schedule new run for iteration 8
15:04:56 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
15:04:56 HBMASTER: submitting job (8, 0, 8) to dispatcher
15:04:56 DISPATCHER: trying to submit job (8, 0, 8)
15:04:56 DISPATCHER: trying to notify the job_runner thread.
15:04:56 HBMASTER: job (8, 0, 8) submitted to dispatcher
15:04:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:04:56 DISPATCHER: Trying to submit another job.
15:04:56 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:04:56 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:04:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:04:56 WORKER: start processing job (8, 0, 8)
15:04:56 WORKER: args: ()
15:04:56 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 52, 'last_n_outputs': 37, 'lr': 0.002278110589789775, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.09330520672463798}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:05:08 DISPATCHER: Starting worker discovery
15:05:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:05:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-544:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:06:08 DISPATCHER: Starting worker discovery
15:06:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:06:08 DISPATCHER: Finished worker discovery
15:06:23 WORKER: done with job (8, 0, 8), trying to register it.
15:06:23 WORKER: registered result for job (8, 0, 8) with dispatcher
15:06:23 DISPATCHER: job (8, 0, 8) finished
15:06:23 DISPATCHER: register_result: lock acquired
15:06:23 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:06:23 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 52, 'last_n_outputs': 37, 'lr': 0.002278110589789775, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.09330520672463798}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2015033985116037, 'info': {'data03': 0.2015033985116037, 'config': "{'batch_size': 16, 'hidden_dim': 52, 'last_n_outputs': 37, 'lr': 0.002278110589789775, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.09330520672463798}"}}
exception: None

15:06:23 job_callback for (8, 0, 8) started
15:06:23 DISPATCHER: Trying to submit another job.
15:06:23 job_callback for (8, 0, 8) got condition
15:06:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:06:23 HBMASTER: Trying to run another job!
15:06:23 job_callback for (8, 0, 8) finished
15:06:23 start sampling a new configuration.
15:06:23 done sampling a new configuration.
15:06:23 HBMASTER: schedule new run for iteration 8
15:06:23 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
15:06:23 HBMASTER: submitting job (8, 0, 9) to dispatcher
15:06:23 DISPATCHER: trying to submit job (8, 0, 9)
15:06:23 DISPATCHER: trying to notify the job_runner thread.
15:06:23 HBMASTER: job (8, 0, 9) submitted to dispatcher
15:06:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:06:23 DISPATCHER: Trying to submit another job.
15:06:23 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:06:23 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:06:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:06:23 WORKER: start processing job (8, 0, 9)
15:06:23 WORKER: args: ()
15:06:23 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 8, 'lr': 0.002429055851083979, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.04243278330123336}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:07:08 DISPATCHER: Starting worker discovery
15:07:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:07:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-545:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:07:48 WORKER: done with job (8, 0, 9), trying to register it.
15:07:48 WORKER: registered result for job (8, 0, 9) with dispatcher
15:07:48 DISPATCHER: job (8, 0, 9) finished
15:07:48 DISPATCHER: register_result: lock acquired
15:07:48 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:07:48 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 8, 'lr': 0.002429055851083979, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.04243278330123336}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 8, 'lr': 0.002429055851083979, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.04243278330123336}"}}
exception: None

15:07:48 job_callback for (8, 0, 9) started
15:07:48 job_callback for (8, 0, 9) got condition
15:07:48 DISPATCHER: Trying to submit another job.
15:07:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:07:48 HBMASTER: Trying to run another job!
15:07:48 job_callback for (8, 0, 9) finished
15:07:48 start sampling a new configuration.
15:07:48 best_vector: [0, 0.9026127891836488, 0.45005433202594997, 0.09291601311137494, 0.10124559514627514, 0, 0.8646952945335973, 0.563825402896434], 9.739832375436986e-05, 17.64113185975541, 0.0017182166722699865
15:07:48 done sampling a new configuration.
15:07:48 HBMASTER: schedule new run for iteration 8
15:07:48 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
15:07:48 HBMASTER: submitting job (8, 0, 10) to dispatcher
15:07:48 DISPATCHER: trying to submit job (8, 0, 10)
15:07:48 DISPATCHER: trying to notify the job_runner thread.
15:07:48 HBMASTER: job (8, 0, 10) submitted to dispatcher
15:07:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:07:48 DISPATCHER: Trying to submit another job.
15:07:48 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:07:48 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:07:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:07:48 WORKER: start processing job (8, 0, 10)
15:07:48 WORKER: args: ()
15:07:48 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 93, 'last_n_outputs': 23, 'lr': 0.0015340235477500454, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.054144426933442714}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:08:08 DISPATCHER: Starting worker discovery
15:08:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:08:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-546:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:09:08 DISPATCHER: Starting worker discovery
15:09:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:09:08 DISPATCHER: Finished worker discovery
15:09:10 WORKER: done with job (8, 0, 10), trying to register it.
15:09:10 WORKER: registered result for job (8, 0, 10) with dispatcher
15:09:10 DISPATCHER: job (8, 0, 10) finished
15:09:10 DISPATCHER: register_result: lock acquired
15:09:10 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:09:10 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 93, 'last_n_outputs': 23, 'lr': 0.0015340235477500454, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.054144426933442714}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 93, 'last_n_outputs': 23, 'lr': 0.0015340235477500454, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.054144426933442714}"}}
exception: None

15:09:10 job_callback for (8, 0, 10) started
15:09:10 job_callback for (8, 0, 10) got condition
15:09:10 DISPATCHER: Trying to submit another job.
15:09:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:09:10 HBMASTER: Trying to run another job!
15:09:10 job_callback for (8, 0, 10) finished
15:09:10 start sampling a new configuration.
15:09:10 best_vector: [0, 0.7897451081743048, 0.7949747212443372, 0.2523123264205951, 0.100796040939085, 0, 0.7864857671441114, 0.8387089048101956], 1.893736001157175e-05, 54.66501196997555, 0.0010352110117123061
15:09:10 done sampling a new configuration.
15:09:10 HBMASTER: schedule new run for iteration 8
15:09:10 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
15:09:10 HBMASTER: submitting job (8, 0, 11) to dispatcher
15:09:10 DISPATCHER: trying to submit job (8, 0, 11)
15:09:10 DISPATCHER: trying to notify the job_runner thread.
15:09:10 HBMASTER: job (8, 0, 11) submitted to dispatcher
15:09:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:09:10 DISPATCHER: Trying to submit another job.
15:09:10 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:09:10 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:09:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:09:10 WORKER: start processing job (8, 0, 11)
15:09:10 WORKER: args: ()
15:09:10 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 83, 'last_n_outputs': 40, 'lr': 0.0031961315989214047, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.1233631478710739}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-547:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:10:08 DISPATCHER: Starting worker discovery
15:10:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:10:08 DISPATCHER: Finished worker discovery
15:10:31 WORKER: done with job (8, 0, 11), trying to register it.
15:10:31 WORKER: registered result for job (8, 0, 11) with dispatcher
15:10:31 DISPATCHER: job (8, 0, 11) finished
15:10:31 DISPATCHER: register_result: lock acquired
15:10:31 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:10:31 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 83, 'last_n_outputs': 40, 'lr': 0.0031961315989214047, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.1233631478710739}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 83, 'last_n_outputs': 40, 'lr': 0.0031961315989214047, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.1233631478710739}"}}
exception: None

15:10:31 job_callback for (8, 0, 11) started
15:10:31 DISPATCHER: Trying to submit another job.
15:10:31 job_callback for (8, 0, 11) got condition
15:10:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:10:31 HBMASTER: Trying to run another job!
15:10:31 job_callback for (8, 0, 11) finished
15:10:31 start sampling a new configuration.
15:10:31 best_vector: [0, 0.6039324604370714, 0.7197205014296788, 0.3468564711033951, 0.10022238626881219, 0, 0.49713518289123404, 0.8071672802064426], 0.00010263136628647317, 70.67730667898483, 0.0072537085499122895
15:10:31 done sampling a new configuration.
15:10:31 HBMASTER: schedule new run for iteration 8
15:10:31 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
15:10:31 HBMASTER: submitting job (8, 0, 12) to dispatcher
15:10:31 DISPATCHER: trying to submit job (8, 0, 12)
15:10:31 DISPATCHER: trying to notify the job_runner thread.
15:10:31 HBMASTER: job (8, 0, 12) submitted to dispatcher
15:10:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:10:31 DISPATCHER: Trying to submit another job.
15:10:31 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:10:31 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:10:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:10:31 WORKER: start processing job (8, 0, 12)
15:10:31 WORKER: args: ()
15:10:31 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 68, 'last_n_outputs': 36, 'lr': 0.0049398406793814565, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.11224030626645962}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:11:08 DISPATCHER: Starting worker discovery
15:11:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:11:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-548:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:11:54 WORKER: done with job (8, 0, 12), trying to register it.
15:11:54 WORKER: registered result for job (8, 0, 12) with dispatcher
15:11:54 DISPATCHER: job (8, 0, 12) finished
15:11:54 DISPATCHER: register_result: lock acquired
15:11:54 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:11:54 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 68, 'last_n_outputs': 36, 'lr': 0.0049398406793814565, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.11224030626645962}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.034516381625178, 'info': {'data03': 0.034516381625178, 'config': "{'batch_size': 16, 'hidden_dim': 68, 'last_n_outputs': 36, 'lr': 0.0049398406793814565, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.11224030626645962}"}}
exception: None

15:11:54 job_callback for (8, 0, 12) started
15:11:54 DISPATCHER: Trying to submit another job.
15:11:54 job_callback for (8, 0, 12) got condition
15:11:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:11:54 HBMASTER: Trying to run another job!
15:11:54 job_callback for (8, 0, 12) finished
15:11:54 start sampling a new configuration.
15:11:54 best_vector: [0, 0.04474242528505856, 0.9301048362993134, 0.11244828319933733, 0.10046038112758138, 0, 0.645098484218515, 0.3597208482272345], 5.756326893810857e-06, 495.3906959028512, 0.0028516307857692582
15:11:54 done sampling a new configuration.
15:11:54 HBMASTER: schedule new run for iteration 8
15:11:54 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
15:11:54 HBMASTER: submitting job (8, 0, 13) to dispatcher
15:11:54 DISPATCHER: trying to submit job (8, 0, 13)
15:11:54 DISPATCHER: trying to notify the job_runner thread.
15:11:54 HBMASTER: job (8, 0, 13) submitted to dispatcher
15:11:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:11:54 DISPATCHER: Trying to submit another job.
15:11:54 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:11:54 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:11:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:11:54 WORKER: start processing job (8, 0, 13)
15:11:54 WORKER: args: ()
15:11:54 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 23, 'last_n_outputs': 47, 'lr': 0.001678404233929188, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.02937701152300034}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:12:08 DISPATCHER: Starting worker discovery
15:12:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:12:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-549:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:13:08 DISPATCHER: Starting worker discovery
15:13:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:13:08 DISPATCHER: Finished worker discovery
15:13:18 WORKER: done with job (8, 0, 13), trying to register it.
15:13:18 WORKER: registered result for job (8, 0, 13) with dispatcher
15:13:18 DISPATCHER: job (8, 0, 13) finished
15:13:18 DISPATCHER: register_result: lock acquired
15:13:18 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:13:18 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 23, 'last_n_outputs': 47, 'lr': 0.001678404233929188, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.02937701152300034}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 23, 'last_n_outputs': 47, 'lr': 0.001678404233929188, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.02937701152300034}"}}
exception: None

15:13:18 job_callback for (8, 0, 13) started
15:13:18 job_callback for (8, 0, 13) got condition
15:13:18 DISPATCHER: Trying to submit another job.
15:13:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:13:18 HBMASTER: Trying to run another job!
15:13:18 job_callback for (8, 0, 13) finished
15:13:18 start sampling a new configuration.
15:13:18 best_vector: [0, 0.9222353912870153, 0.9715161300003107, 0.3148517886743836, 0.10108144990287769, 0, 0.6251716874676401, 0.2628698253002856], 6.656082322425785e-06, 293.6186826636363, 0.001954350123211376
15:13:18 done sampling a new configuration.
15:13:18 HBMASTER: schedule new run for iteration 8
15:13:18 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
15:13:18 HBMASTER: submitting job (8, 0, 14) to dispatcher
15:13:18 DISPATCHER: trying to submit job (8, 0, 14)
15:13:18 DISPATCHER: trying to notify the job_runner thread.
15:13:18 HBMASTER: job (8, 0, 14) submitted to dispatcher
15:13:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:13:18 DISPATCHER: Trying to submit another job.
15:13:18 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:13:18 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:13:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:13:18 WORKER: start processing job (8, 0, 14)
15:13:18 WORKER: args: ()
15:13:18 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 94, 'last_n_outputs': 49, 'lr': 0.004262884612490358, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.021978676039718523}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-550:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:14:08 DISPATCHER: Starting worker discovery
15:14:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:14:08 DISPATCHER: Finished worker discovery
15:14:40 WORKER: done with job (8, 0, 14), trying to register it.
15:14:40 WORKER: registered result for job (8, 0, 14) with dispatcher
15:14:40 DISPATCHER: job (8, 0, 14) finished
15:14:40 DISPATCHER: register_result: lock acquired
15:14:40 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:14:40 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 94, 'last_n_outputs': 49, 'lr': 0.004262884612490358, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.021978676039718523}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2708199302635205, 'info': {'data03': 0.2708199302635205, 'config': "{'batch_size': 16, 'hidden_dim': 94, 'last_n_outputs': 49, 'lr': 0.004262884612490358, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.021978676039718523}"}}
exception: None

15:14:40 job_callback for (8, 0, 14) started
15:14:40 DISPATCHER: Trying to submit another job.
15:14:40 job_callback for (8, 0, 14) got condition
15:14:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:14:40 HBMASTER: Trying to run another job!
15:14:40 job_callback for (8, 0, 14) finished
15:14:40 start sampling a new configuration.
15:14:40 best_vector: [0, 0.8783883752964231, 0.7100246869648537, 0.5990751858627716, 0.10110638519725947, 0, 0.3174443175600886, 0.18107616147699954], 0.00020679893040246404, 19.523946490287365, 0.004037531251426369
15:14:40 done sampling a new configuration.
15:14:40 HBMASTER: schedule new run for iteration 8
15:14:40 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
15:14:40 HBMASTER: submitting job (8, 0, 15) to dispatcher
15:14:40 DISPATCHER: trying to submit job (8, 0, 15)
15:14:40 DISPATCHER: trying to notify the job_runner thread.
15:14:40 HBMASTER: job (8, 0, 15) submitted to dispatcher
15:14:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:14:40 DISPATCHER: Trying to submit another job.
15:14:40 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:14:40 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:14:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:14:40 WORKER: start processing job (8, 0, 15)
15:14:40 WORKER: args: ()
15:14:40 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 91, 'last_n_outputs': 36, 'lr': 0.015781576022291424, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.017202260401936585}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:15:08 DISPATCHER: Starting worker discovery
15:15:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:15:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-551:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:16:02 WORKER: done with job (8, 0, 15), trying to register it.
15:16:02 WORKER: registered result for job (8, 0, 15) with dispatcher
15:16:02 DISPATCHER: job (8, 0, 15) finished
15:16:02 DISPATCHER: register_result: lock acquired
15:16:02 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:16:02 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 91, 'last_n_outputs': 36, 'lr': 0.015781576022291424, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.017202260401936585}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.27252363466873314, 'info': {'data03': 0.27252363466873314, 'config': "{'batch_size': 16, 'hidden_dim': 91, 'last_n_outputs': 36, 'lr': 0.015781576022291424, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.017202260401936585}"}}
exception: None

15:16:02 job_callback for (8, 0, 15) started
15:16:02 DISPATCHER: Trying to submit another job.
15:16:02 job_callback for (8, 0, 15) got condition
15:16:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:16:02 HBMASTER: Trying to run another job!
15:16:02 job_callback for (8, 0, 15) finished
15:16:02 start sampling a new configuration.
15:16:02 done sampling a new configuration.
15:16:02 HBMASTER: schedule new run for iteration 8
15:16:02 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
15:16:02 HBMASTER: submitting job (8, 0, 16) to dispatcher
15:16:02 DISPATCHER: trying to submit job (8, 0, 16)
15:16:02 DISPATCHER: trying to notify the job_runner thread.
15:16:02 HBMASTER: job (8, 0, 16) submitted to dispatcher
15:16:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:16:02 DISPATCHER: Trying to submit another job.
15:16:02 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:16:02 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:16:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:16:02 WORKER: start processing job (8, 0, 16)
15:16:02 WORKER: args: ()
15:16:02 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 42, 'last_n_outputs': 42, 'lr': 0.05462310282382893, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.031264434259647235}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:16:08 DISPATCHER: Starting worker discovery
15:16:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:16:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-552:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:17:08 DISPATCHER: Starting worker discovery
15:17:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:17:08 DISPATCHER: Finished worker discovery
15:17:24 WORKER: done with job (8, 0, 16), trying to register it.
15:17:24 WORKER: registered result for job (8, 0, 16) with dispatcher
15:17:24 DISPATCHER: job (8, 0, 16) finished
15:17:24 DISPATCHER: register_result: lock acquired
15:17:24 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:17:24 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 42, 'last_n_outputs': 42, 'lr': 0.05462310282382893, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.031264434259647235}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 42, 'last_n_outputs': 42, 'lr': 0.05462310282382893, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 45, 'weight_decay': 0.031264434259647235}"}}
exception: None

15:17:24 job_callback for (8, 0, 16) started
15:17:24 job_callback for (8, 0, 16) got condition
15:17:24 DISPATCHER: Trying to submit another job.
15:17:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:17:24 HBMASTER: Trying to run another job!
15:17:24 job_callback for (8, 0, 16) finished
15:17:24 start sampling a new configuration.
15:17:24 done sampling a new configuration.
15:17:24 HBMASTER: schedule new run for iteration 8
15:17:24 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
15:17:24 HBMASTER: submitting job (8, 0, 17) to dispatcher
15:17:24 DISPATCHER: trying to submit job (8, 0, 17)
15:17:24 DISPATCHER: trying to notify the job_runner thread.
15:17:24 HBMASTER: job (8, 0, 17) submitted to dispatcher
15:17:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:17:24 DISPATCHER: Trying to submit another job.
15:17:24 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:17:24 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:17:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:17:24 WORKER: start processing job (8, 0, 17)
15:17:24 WORKER: args: ()
15:17:24 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 81, 'last_n_outputs': 29, 'lr': 0.0077948590183182075, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.16450873112901981}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:18:08 DISPATCHER: Starting worker discovery
15:18:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:18:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-553:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:18:48 WORKER: done with job (8, 0, 17), trying to register it.
15:18:48 WORKER: registered result for job (8, 0, 17) with dispatcher
15:18:48 DISPATCHER: job (8, 0, 17) finished
15:18:48 DISPATCHER: register_result: lock acquired
15:18:48 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:18:48 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 81, 'last_n_outputs': 29, 'lr': 0.0077948590183182075, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.16450873112901981}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 81, 'last_n_outputs': 29, 'lr': 0.0077948590183182075, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.16450873112901981}"}}
exception: None

15:18:48 job_callback for (8, 0, 17) started
15:18:48 DISPATCHER: Trying to submit another job.
15:18:48 job_callback for (8, 0, 17) got condition
15:18:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:18:48 HBMASTER: Trying to run another job!
15:18:48 job_callback for (8, 0, 17) finished
15:18:48 start sampling a new configuration.
15:18:48 done sampling a new configuration.
15:18:48 HBMASTER: schedule new run for iteration 8
15:18:48 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
15:18:48 HBMASTER: submitting job (8, 0, 18) to dispatcher
15:18:48 DISPATCHER: trying to submit job (8, 0, 18)
15:18:48 DISPATCHER: trying to notify the job_runner thread.
15:18:48 HBMASTER: job (8, 0, 18) submitted to dispatcher
15:18:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:18:48 DISPATCHER: Trying to submit another job.
15:18:48 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:18:48 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:18:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:18:48 WORKER: start processing job (8, 0, 18)
15:18:48 WORKER: args: ()
15:18:48 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 42, 'last_n_outputs': 37, 'lr': 0.0017743685039282142, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.04141285468995221}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:19:08 DISPATCHER: Starting worker discovery
15:19:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:19:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-554:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:20:08 DISPATCHER: Starting worker discovery
15:20:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:20:08 DISPATCHER: Finished worker discovery
15:20:12 WORKER: done with job (8, 0, 18), trying to register it.
15:20:12 WORKER: registered result for job (8, 0, 18) with dispatcher
15:20:12 DISPATCHER: job (8, 0, 18) finished
15:20:12 DISPATCHER: register_result: lock acquired
15:20:12 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:20:12 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 42, 'last_n_outputs': 37, 'lr': 0.0017743685039282142, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.04141285468995221}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 42, 'last_n_outputs': 37, 'lr': 0.0017743685039282142, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.04141285468995221}"}}
exception: None

15:20:12 job_callback for (8, 0, 18) started
15:20:12 DISPATCHER: Trying to submit another job.
15:20:12 job_callback for (8, 0, 18) got condition
15:20:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:20:12 HBMASTER: Trying to run another job!
15:20:12 job_callback for (8, 0, 18) finished
15:20:12 start sampling a new configuration.
15:20:12 done sampling a new configuration.
15:20:12 HBMASTER: schedule new run for iteration 8
15:20:12 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
15:20:12 HBMASTER: submitting job (8, 0, 19) to dispatcher
15:20:12 DISPATCHER: trying to submit job (8, 0, 19)
15:20:12 DISPATCHER: trying to notify the job_runner thread.
15:20:12 HBMASTER: job (8, 0, 19) submitted to dispatcher
15:20:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:20:12 DISPATCHER: Trying to submit another job.
15:20:12 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:20:12 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:20:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:20:12 WORKER: start processing job (8, 0, 19)
15:20:12 WORKER: args: ()
15:20:12 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 96, 'last_n_outputs': 47, 'lr': 0.013902473262139201, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.012246874191298877}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-555:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:21:08 DISPATCHER: Starting worker discovery
15:21:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:21:08 DISPATCHER: Finished worker discovery
15:21:36 WORKER: done with job (8, 0, 19), trying to register it.
15:21:36 WORKER: registered result for job (8, 0, 19) with dispatcher
15:21:36 DISPATCHER: job (8, 0, 19) finished
15:21:36 DISPATCHER: register_result: lock acquired
15:21:36 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:21:36 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 96, 'last_n_outputs': 47, 'lr': 0.013902473262139201, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.012246874191298877}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 96, 'last_n_outputs': 47, 'lr': 0.013902473262139201, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.012246874191298877}"}}
exception: None

15:21:36 job_callback for (8, 0, 19) started
15:21:36 job_callback for (8, 0, 19) got condition
15:21:36 DISPATCHER: Trying to submit another job.
15:21:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:21:36 HBMASTER: Trying to run another job!
15:21:36 job_callback for (8, 0, 19) finished
15:21:36 start sampling a new configuration.
15:21:36 done sampling a new configuration.
15:21:36 HBMASTER: schedule new run for iteration 8
15:21:36 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
15:21:36 HBMASTER: submitting job (8, 0, 20) to dispatcher
15:21:36 DISPATCHER: trying to submit job (8, 0, 20)
15:21:36 DISPATCHER: trying to notify the job_runner thread.
15:21:36 HBMASTER: job (8, 0, 20) submitted to dispatcher
15:21:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:21:36 DISPATCHER: Trying to submit another job.
15:21:36 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:21:36 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:21:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:21:36 WORKER: start processing job (8, 0, 20)
15:21:36 WORKER: args: ()
15:21:36 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 87, 'last_n_outputs': 15, 'lr': 0.0014367819240908234, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.10817027728668617}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:22:08 DISPATCHER: Starting worker discovery
15:22:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:22:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-556:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:22:59 WORKER: done with job (8, 0, 20), trying to register it.
15:22:59 WORKER: registered result for job (8, 0, 20) with dispatcher
15:22:59 DISPATCHER: job (8, 0, 20) finished
15:22:59 DISPATCHER: register_result: lock acquired
15:22:59 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:22:59 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 87, 'last_n_outputs': 15, 'lr': 0.0014367819240908234, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.10817027728668617}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 87, 'last_n_outputs': 15, 'lr': 0.0014367819240908234, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.10817027728668617}"}}
exception: None

15:22:59 job_callback for (8, 0, 20) started
15:22:59 job_callback for (8, 0, 20) got condition
15:22:59 DISPATCHER: Trying to submit another job.
15:22:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:22:59 HBMASTER: Trying to run another job!
15:22:59 job_callback for (8, 0, 20) finished
15:22:59 start sampling a new configuration.
15:22:59 done sampling a new configuration.
15:22:59 HBMASTER: schedule new run for iteration 8
15:22:59 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
15:22:59 HBMASTER: submitting job (8, 0, 21) to dispatcher
15:22:59 DISPATCHER: trying to submit job (8, 0, 21)
15:22:59 DISPATCHER: trying to notify the job_runner thread.
15:22:59 HBMASTER: job (8, 0, 21) submitted to dispatcher
15:22:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:22:59 DISPATCHER: Trying to submit another job.
15:22:59 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:22:59 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:22:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:22:59 WORKER: start processing job (8, 0, 21)
15:22:59 WORKER: args: ()
15:22:59 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 85, 'last_n_outputs': 20, 'lr': 0.0045863369740415235, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.02834148354926029}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:23:08 DISPATCHER: Starting worker discovery
15:23:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:23:08 DISPATCHER: Finished worker discovery
15:24:08 DISPATCHER: Starting worker discovery
15:24:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:24:08 DISPATCHER: Finished worker discovery
15:24:25 WORKER: done with job (8, 0, 21), trying to register it.
15:24:25 WORKER: registered result for job (8, 0, 21) with dispatcher
15:24:25 DISPATCHER: job (8, 0, 21) finished
15:24:25 DISPATCHER: register_result: lock acquired
15:24:25 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:24:25 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 85, 'last_n_outputs': 20, 'lr': 0.0045863369740415235, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.02834148354926029}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 85, 'last_n_outputs': 20, 'lr': 0.0045863369740415235, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.02834148354926029}"}}
exception: None

15:24:25 job_callback for (8, 0, 21) started
15:24:25 job_callback for (8, 0, 21) got condition
15:24:25 DISPATCHER: Trying to submit another job.
15:24:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:24:25 HBMASTER: Trying to run another job!
15:24:25 job_callback for (8, 0, 21) finished
15:24:25 start sampling a new configuration.
15:24:25 best_vector: [0, 0.8434033234711941, 0.9820055067703283, 0.597780446999698, 0.10111405959336785, 0, 0.6954273814487034, 0.522796951955319], 6.080612102044222e-05, 107.58993487341188, 0.00654212660049418
15:24:25 done sampling a new configuration.
15:24:25 HBMASTER: schedule new run for iteration 8
15:24:25 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
15:24:25 HBMASTER: submitting job (8, 0, 22) to dispatcher
15:24:25 DISPATCHER: trying to submit job (8, 0, 22)
15:24:25 DISPATCHER: trying to notify the job_runner thread.
15:24:25 HBMASTER: job (8, 0, 22) submitted to dispatcher
15:24:25 DISPATCHER: Trying to submit another job.
15:24:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:24:25 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:24:25 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:24:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:24:25 WORKER: start processing job (8, 0, 22)
15:24:25 WORKER: args: ()
15:24:25 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 88, 'last_n_outputs': 50, 'lr': 0.015687758459929604, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.04788224628507429}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:25:08 DISPATCHER: Starting worker discovery
15:25:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:25:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-558:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:25:48 WORKER: done with job (8, 0, 22), trying to register it.
15:25:48 WORKER: registered result for job (8, 0, 22) with dispatcher
15:25:48 DISPATCHER: job (8, 0, 22) finished
15:25:48 DISPATCHER: register_result: lock acquired
15:25:48 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:25:48 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 88, 'last_n_outputs': 50, 'lr': 0.015687758459929604, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.04788224628507429}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 88, 'last_n_outputs': 50, 'lr': 0.015687758459929604, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.04788224628507429}"}}
exception: None

15:25:48 job_callback for (8, 0, 22) started
15:25:48 DISPATCHER: Trying to submit another job.
15:25:48 job_callback for (8, 0, 22) got condition
15:25:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:25:48 HBMASTER: Trying to run another job!
15:25:48 job_callback for (8, 0, 22) finished
15:25:48 start sampling a new configuration.
15:25:48 best_vector: [0, 0.8329410456669497, 0.6803307503569472, 0.10525742507696186, 0.09897599897640003, 0, 0.9669505703372154, 0.32505081399979846], 4.904688192089516e-06, 505.90709983401484, 0.002481316578850145
15:25:48 done sampling a new configuration.
15:25:48 HBMASTER: schedule new run for iteration 8
15:25:48 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
15:25:48 HBMASTER: submitting job (8, 0, 23) to dispatcher
15:25:48 DISPATCHER: trying to submit job (8, 0, 23)
15:25:48 DISPATCHER: trying to notify the job_runner thread.
15:25:48 HBMASTER: job (8, 0, 23) submitted to dispatcher
15:25:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:25:48 DISPATCHER: Trying to submit another job.
15:25:48 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:25:48 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:25:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:25:48 WORKER: start processing job (8, 0, 23)
15:25:48 WORKER: args: ()
15:25:48 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 87, 'last_n_outputs': 35, 'lr': 0.0016237338710719815, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.026478956072248566}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:26:08 DISPATCHER: Starting worker discovery
15:26:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:26:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-559:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:27:08 DISPATCHER: Starting worker discovery
15:27:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:27:08 DISPATCHER: Finished worker discovery
15:27:13 WORKER: done with job (8, 0, 23), trying to register it.
15:27:13 WORKER: registered result for job (8, 0, 23) with dispatcher
15:27:13 DISPATCHER: job (8, 0, 23) finished
15:27:13 DISPATCHER: register_result: lock acquired
15:27:13 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:27:13 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 87, 'last_n_outputs': 35, 'lr': 0.0016237338710719815, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.026478956072248566}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.21302689388205784, 'info': {'data03': 0.21302689388205784, 'config': "{'batch_size': 16, 'hidden_dim': 87, 'last_n_outputs': 35, 'lr': 0.0016237338710719815, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.026478956072248566}"}}
exception: None

15:27:13 job_callback for (8, 0, 23) started
15:27:13 DISPATCHER: Trying to submit another job.
15:27:13 job_callback for (8, 0, 23) got condition
15:27:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:27:13 HBMASTER: Trying to run another job!
15:27:13 job_callback for (8, 0, 23) finished
15:27:13 start sampling a new configuration.
15:27:13 best_vector: [1, 0.04867074892004512, 0.9245783114806078, 0.07179332539950645, 0.10122505350246336, 0, 0.9205561402452549, 0.9567806535815756], 6.669410638648203e-06, 158.41705145113605, 0.0010565483682914865
15:27:13 done sampling a new configuration.
15:27:13 HBMASTER: schedule new run for iteration 8
15:27:13 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
15:27:13 HBMASTER: submitting job (8, 0, 24) to dispatcher
15:27:13 DISPATCHER: trying to submit job (8, 0, 24)
15:27:13 DISPATCHER: trying to notify the job_runner thread.
15:27:13 HBMASTER: job (8, 0, 24) submitted to dispatcher
15:27:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:27:13 DISPATCHER: Trying to submit another job.
15:27:13 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:27:13 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:27:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:27:13 WORKER: start processing job (8, 0, 24)
15:27:13 WORKER: args: ()
15:27:13 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 23, 'last_n_outputs': 47, 'lr': 0.0013918314665238068, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.17571155800474952}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-560:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:28:08 DISPATCHER: Starting worker discovery
15:28:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:28:08 DISPATCHER: Finished worker discovery
15:28:37 WORKER: done with job (8, 0, 24), trying to register it.
15:28:37 WORKER: registered result for job (8, 0, 24) with dispatcher
15:28:37 DISPATCHER: job (8, 0, 24) finished
15:28:37 DISPATCHER: register_result: lock acquired
15:28:37 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:28:37 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 23, 'last_n_outputs': 47, 'lr': 0.0013918314665238068, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.17571155800474952}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 23, 'last_n_outputs': 47, 'lr': 0.0013918314665238068, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.17571155800474952}"}}
exception: None

15:28:37 job_callback for (8, 0, 24) started
15:28:37 job_callback for (8, 0, 24) got condition
15:28:37 DISPATCHER: Trying to submit another job.
15:28:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:28:37 HBMASTER: Trying to run another job!
15:28:37 job_callback for (8, 0, 24) finished
15:28:37 start sampling a new configuration.
15:28:37 best_vector: [1, 0.8677223799052269, 0.9812670203072303, 0.4165096913053644, 0.10024749508404533, 0, 0.9197298117739033, 0.12164304697914737], 7.978423362245127e-05, 1085.8009923787672, 0.086629800043437
15:28:37 done sampling a new configuration.
15:28:37 HBMASTER: schedule new run for iteration 8
15:28:37 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
15:28:37 HBMASTER: submitting job (8, 0, 25) to dispatcher
15:28:37 DISPATCHER: trying to submit job (8, 0, 25)
15:28:37 DISPATCHER: trying to notify the job_runner thread.
15:28:37 HBMASTER: job (8, 0, 25) submitted to dispatcher
15:28:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:28:37 DISPATCHER: Trying to submit another job.
15:28:37 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:28:37 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:28:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:28:37 WORKER: start processing job (8, 0, 25)
15:28:37 WORKER: args: ()
15:28:37 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 90, 'last_n_outputs': 50, 'lr': 0.006807997421834681, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.014396643579879862}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:29:08 DISPATCHER: Starting worker discovery
15:29:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:29:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-561:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:30:00 WORKER: done with job (8, 0, 25), trying to register it.
15:30:00 WORKER: registered result for job (8, 0, 25) with dispatcher
15:30:00 DISPATCHER: job (8, 0, 25) finished
15:30:00 DISPATCHER: register_result: lock acquired
15:30:00 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:30:00 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 90, 'last_n_outputs': 50, 'lr': 0.006807997421834681, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.014396643579879862}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1673045249378694, 'info': {'data03': 0.1673045249378694, 'config': "{'batch_size': 32, 'hidden_dim': 90, 'last_n_outputs': 50, 'lr': 0.006807997421834681, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.014396643579879862}"}}
exception: None

15:30:00 job_callback for (8, 0, 25) started
15:30:00 job_callback for (8, 0, 25) got condition
15:30:00 DISPATCHER: Trying to submit another job.
15:30:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:30:00 HBMASTER: Trying to run another job!
15:30:00 job_callback for (8, 0, 25) finished
15:30:00 start sampling a new configuration.
15:30:00 done sampling a new configuration.
15:30:00 HBMASTER: schedule new run for iteration 8
15:30:00 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
15:30:00 HBMASTER: submitting job (8, 0, 26) to dispatcher
15:30:00 DISPATCHER: trying to submit job (8, 0, 26)
15:30:00 DISPATCHER: trying to notify the job_runner thread.
15:30:00 HBMASTER: job (8, 0, 26) submitted to dispatcher
15:30:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:30:00 DISPATCHER: Trying to submit another job.
15:30:00 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:30:00 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:30:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:30:00 WORKER: start processing job (8, 0, 26)
15:30:00 WORKER: args: ()
15:30:00 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 87, 'last_n_outputs': 20, 'lr': 0.01917935493517603, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.06794968825834476}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:30:08 DISPATCHER: Starting worker discovery
15:30:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:30:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-562:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:31:08 DISPATCHER: Starting worker discovery
15:31:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:31:08 DISPATCHER: Finished worker discovery
15:31:21 WORKER: done with job (8, 0, 26), trying to register it.
15:31:21 WORKER: registered result for job (8, 0, 26) with dispatcher
15:31:21 DISPATCHER: job (8, 0, 26) finished
15:31:21 DISPATCHER: register_result: lock acquired
15:31:21 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:31:21 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 87, 'last_n_outputs': 20, 'lr': 0.01917935493517603, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.06794968825834476}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 87, 'last_n_outputs': 20, 'lr': 0.01917935493517603, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.06794968825834476}"}}
exception: None

15:31:21 job_callback for (8, 0, 26) started
15:31:21 DISPATCHER: Trying to submit another job.
15:31:21 job_callback for (8, 0, 26) got condition
15:31:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:31:21 HBMASTER: Trying to run another job!
15:31:21 job_callback for (8, 0, 26) finished
15:31:21 ITERATION: Advancing config (8, 0, 0) to next budget 133.333333
15:31:21 ITERATION: Advancing config (8, 0, 1) to next budget 133.333333
15:31:21 ITERATION: Advancing config (8, 0, 2) to next budget 133.333333
15:31:21 ITERATION: Advancing config (8, 0, 6) to next budget 133.333333
15:31:21 ITERATION: Advancing config (8, 0, 8) to next budget 133.333333
15:31:21 ITERATION: Advancing config (8, 0, 14) to next budget 133.333333
15:31:21 ITERATION: Advancing config (8, 0, 15) to next budget 133.333333
15:31:21 ITERATION: Advancing config (8, 0, 23) to next budget 133.333333
15:31:21 ITERATION: Advancing config (8, 0, 25) to next budget 133.333333
15:31:21 HBMASTER: schedule new run for iteration 8
15:31:21 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
15:31:21 HBMASTER: submitting job (8, 0, 0) to dispatcher
15:31:21 DISPATCHER: trying to submit job (8, 0, 0)
15:31:21 DISPATCHER: trying to notify the job_runner thread.
15:31:21 HBMASTER: job (8, 0, 0) submitted to dispatcher
15:31:21 DISPATCHER: Trying to submit another job.
15:31:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:31:21 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:31:21 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:31:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:31:21 WORKER: start processing job (8, 0, 0)
15:31:21 WORKER: args: ()
15:31:21 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 55, 'last_n_outputs': 35, 'lr': 0.002296472515873136, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.06610854655163631}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:32:08 DISPATCHER: Starting worker discovery
15:32:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:32:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-563:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:33:08 DISPATCHER: Starting worker discovery
15:33:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:33:08 DISPATCHER: Finished worker discovery
15:34:08 DISPATCHER: Starting worker discovery
15:34:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:34:08 DISPATCHER: Finished worker discovery
15:34:14 WORKER: done with job (8, 0, 0), trying to register it.
15:34:14 WORKER: registered result for job (8, 0, 0) with dispatcher
15:34:14 DISPATCHER: job (8, 0, 0) finished
15:34:14 DISPATCHER: register_result: lock acquired
15:34:14 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:34:14 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 55, 'last_n_outputs': 35, 'lr': 0.002296472515873136, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.06610854655163631}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.19253124214451023, 'info': {'data03': 0.19253124214451023, 'config': "{'batch_size': 16, 'hidden_dim': 55, 'last_n_outputs': 35, 'lr': 0.002296472515873136, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.06610854655163631}"}}
exception: None

15:34:14 job_callback for (8, 0, 0) started
15:34:14 DISPATCHER: Trying to submit another job.
15:34:14 job_callback for (8, 0, 0) got condition
15:34:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:34:14 HBMASTER: Trying to run another job!
15:34:14 job_callback for (8, 0, 0) finished
15:34:14 HBMASTER: schedule new run for iteration 8
15:34:14 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
15:34:14 HBMASTER: submitting job (8, 0, 1) to dispatcher
15:34:14 DISPATCHER: trying to submit job (8, 0, 1)
15:34:14 DISPATCHER: trying to notify the job_runner thread.
15:34:14 HBMASTER: job (8, 0, 1) submitted to dispatcher
15:34:14 DISPATCHER: Trying to submit another job.
15:34:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:34:14 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:34:14 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:34:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:34:14 WORKER: start processing job (8, 0, 1)
15:34:14 WORKER: args: ()
15:34:14 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 91, 'last_n_outputs': 43, 'lr': 0.0017123224947501745, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.022052548256056764}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-564:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:35:08 DISPATCHER: Starting worker discovery
15:35:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:35:08 DISPATCHER: Finished worker discovery
15:36:08 DISPATCHER: Starting worker discovery
15:36:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:36:08 DISPATCHER: Finished worker discovery
15:37:06 WORKER: done with job (8, 0, 1), trying to register it.
15:37:06 WORKER: registered result for job (8, 0, 1) with dispatcher
15:37:06 DISPATCHER: job (8, 0, 1) finished
15:37:06 DISPATCHER: register_result: lock acquired
15:37:06 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:37:06 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 91, 'last_n_outputs': 43, 'lr': 0.0017123224947501745, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.022052548256056764}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.23920925845064106, 'info': {'data03': 0.23920925845064106, 'config': "{'batch_size': 16, 'hidden_dim': 91, 'last_n_outputs': 43, 'lr': 0.0017123224947501745, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.022052548256056764}"}}
exception: None

15:37:06 job_callback for (8, 0, 1) started
15:37:06 DISPATCHER: Trying to submit another job.
15:37:06 job_callback for (8, 0, 1) got condition
15:37:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:37:06 HBMASTER: Trying to run another job!
15:37:06 job_callback for (8, 0, 1) finished
15:37:06 HBMASTER: schedule new run for iteration 8
15:37:06 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
15:37:06 HBMASTER: submitting job (8, 0, 2) to dispatcher
15:37:06 DISPATCHER: trying to submit job (8, 0, 2)
15:37:06 DISPATCHER: trying to notify the job_runner thread.
15:37:06 HBMASTER: job (8, 0, 2) submitted to dispatcher
15:37:06 DISPATCHER: Trying to submit another job.
15:37:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:37:06 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:37:06 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:37:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:37:06 WORKER: start processing job (8, 0, 2)
15:37:06 WORKER: args: ()
15:37:06 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 64, 'last_n_outputs': 47, 'lr': 0.0010691322432775869, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.03183974683553772}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:37:08 DISPATCHER: Starting worker discovery
15:37:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:37:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-565:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:38:08 DISPATCHER: Starting worker discovery
15:38:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:38:08 DISPATCHER: Finished worker discovery
15:39:08 DISPATCHER: Starting worker discovery
15:39:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:39:08 DISPATCHER: Finished worker discovery
15:39:55 WORKER: done with job (8, 0, 2), trying to register it.
15:39:55 WORKER: registered result for job (8, 0, 2) with dispatcher
15:39:55 DISPATCHER: job (8, 0, 2) finished
15:39:55 DISPATCHER: register_result: lock acquired
15:39:55 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:39:55 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 64, 'last_n_outputs': 47, 'lr': 0.0010691322432775869, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.03183974683553772}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 64, 'last_n_outputs': 47, 'lr': 0.0010691322432775869, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.03183974683553772}"}}
exception: None

15:39:55 job_callback for (8, 0, 2) started
15:39:55 DISPATCHER: Trying to submit another job.
15:39:55 job_callback for (8, 0, 2) got condition
15:39:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:39:55 HBMASTER: Trying to run another job!
15:39:55 job_callback for (8, 0, 2) finished
15:39:55 HBMASTER: schedule new run for iteration 8
15:39:55 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
15:39:55 HBMASTER: submitting job (8, 0, 6) to dispatcher
15:39:55 DISPATCHER: trying to submit job (8, 0, 6)
15:39:55 DISPATCHER: trying to notify the job_runner thread.
15:39:55 HBMASTER: job (8, 0, 6) submitted to dispatcher
15:39:55 DISPATCHER: Trying to submit another job.
15:39:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:39:55 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:39:55 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:39:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:39:55 WORKER: start processing job (8, 0, 6)
15:39:55 WORKER: args: ()
15:39:55 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 95, 'last_n_outputs': 45, 'lr': 0.0022188653542262017, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.012767487585816367}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:40:08 DISPATCHER: Starting worker discovery
15:40:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:40:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-566:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:41:08 DISPATCHER: Starting worker discovery
15:41:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:41:08 DISPATCHER: Finished worker discovery
15:42:08 DISPATCHER: Starting worker discovery
15:42:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:42:08 DISPATCHER: Finished worker discovery
15:42:50 WORKER: done with job (8, 0, 6), trying to register it.
15:42:50 WORKER: registered result for job (8, 0, 6) with dispatcher
15:42:50 DISPATCHER: job (8, 0, 6) finished
15:42:50 DISPATCHER: register_result: lock acquired
15:42:50 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:42:50 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 95, 'last_n_outputs': 45, 'lr': 0.0022188653542262017, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.012767487585816367}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.28463746777360827, 'info': {'data03': 0.28463746777360827, 'config': "{'batch_size': 16, 'hidden_dim': 95, 'last_n_outputs': 45, 'lr': 0.0022188653542262017, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.012767487585816367}"}}
exception: None

15:42:50 job_callback for (8, 0, 6) started
15:42:50 DISPATCHER: Trying to submit another job.
15:42:50 job_callback for (8, 0, 6) got condition
15:42:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:42:50 HBMASTER: Trying to run another job!
15:42:50 job_callback for (8, 0, 6) finished
15:42:50 HBMASTER: schedule new run for iteration 8
15:42:50 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
15:42:50 HBMASTER: submitting job (8, 0, 8) to dispatcher
15:42:50 DISPATCHER: trying to submit job (8, 0, 8)
15:42:50 DISPATCHER: trying to notify the job_runner thread.
15:42:50 HBMASTER: job (8, 0, 8) submitted to dispatcher
15:42:50 DISPATCHER: Trying to submit another job.
15:42:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:42:50 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:42:50 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:42:50 WORKER: start processing job (8, 0, 8)
15:42:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:42:50 WORKER: args: ()
15:42:50 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 52, 'last_n_outputs': 37, 'lr': 0.002278110589789775, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.09330520672463798}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:43:08 DISPATCHER: Starting worker discovery
15:43:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:43:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-567:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:44:08 DISPATCHER: Starting worker discovery
15:44:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:44:08 DISPATCHER: Finished worker discovery
15:45:08 DISPATCHER: Starting worker discovery
15:45:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:45:08 DISPATCHER: Finished worker discovery
15:45:44 WORKER: done with job (8, 0, 8), trying to register it.
15:45:44 WORKER: registered result for job (8, 0, 8) with dispatcher
15:45:44 DISPATCHER: job (8, 0, 8) finished
15:45:44 DISPATCHER: register_result: lock acquired
15:45:44 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:45:44 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 52, 'last_n_outputs': 37, 'lr': 0.002278110589789775, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.09330520672463798}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 52, 'last_n_outputs': 37, 'lr': 0.002278110589789775, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.09330520672463798}"}}
exception: None

15:45:44 job_callback for (8, 0, 8) started
15:45:44 job_callback for (8, 0, 8) got condition
15:45:44 DISPATCHER: Trying to submit another job.
15:45:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:45:44 HBMASTER: Trying to run another job!
15:45:44 job_callback for (8, 0, 8) finished
15:45:44 HBMASTER: schedule new run for iteration 8
15:45:44 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
15:45:44 HBMASTER: submitting job (8, 0, 14) to dispatcher
15:45:44 DISPATCHER: trying to submit job (8, 0, 14)
15:45:44 DISPATCHER: trying to notify the job_runner thread.
15:45:44 HBMASTER: job (8, 0, 14) submitted to dispatcher
15:45:44 DISPATCHER: Trying to submit another job.
15:45:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:45:44 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:45:44 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:45:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:45:44 WORKER: start processing job (8, 0, 14)
15:45:44 WORKER: args: ()
15:45:44 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 94, 'last_n_outputs': 49, 'lr': 0.004262884612490358, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.021978676039718523}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:46:08 DISPATCHER: Starting worker discovery
15:46:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:46:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-568:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:47:08 DISPATCHER: Starting worker discovery
15:47:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:47:08 DISPATCHER: Finished worker discovery
15:48:08 DISPATCHER: Starting worker discovery
15:48:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:48:08 DISPATCHER: Finished worker discovery
15:48:36 WORKER: done with job (8, 0, 14), trying to register it.
15:48:36 WORKER: registered result for job (8, 0, 14) with dispatcher
15:48:36 DISPATCHER: job (8, 0, 14) finished
15:48:36 DISPATCHER: register_result: lock acquired
15:48:36 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:48:36 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 94, 'last_n_outputs': 49, 'lr': 0.004262884612490358, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.021978676039718523}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.29701760887129236, 'info': {'data03': 0.29701760887129236, 'config': "{'batch_size': 16, 'hidden_dim': 94, 'last_n_outputs': 49, 'lr': 0.004262884612490358, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.021978676039718523}"}}
exception: None

15:48:36 job_callback for (8, 0, 14) started
15:48:36 DISPATCHER: Trying to submit another job.
15:48:36 job_callback for (8, 0, 14) got condition
15:48:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:48:36 HBMASTER: Trying to run another job!
15:48:36 job_callback for (8, 0, 14) finished
15:48:36 HBMASTER: schedule new run for iteration 8
15:48:36 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
15:48:36 HBMASTER: submitting job (8, 0, 15) to dispatcher
15:48:36 DISPATCHER: trying to submit job (8, 0, 15)
15:48:36 DISPATCHER: trying to notify the job_runner thread.
15:48:36 HBMASTER: job (8, 0, 15) submitted to dispatcher
15:48:36 DISPATCHER: Trying to submit another job.
15:48:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:48:36 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:48:36 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:48:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:48:36 WORKER: start processing job (8, 0, 15)
15:48:36 WORKER: args: ()
15:48:36 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 91, 'last_n_outputs': 36, 'lr': 0.015781576022291424, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.017202260401936585}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:49:08 DISPATCHER: Starting worker discovery
15:49:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:49:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-569:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:50:08 DISPATCHER: Starting worker discovery
15:50:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:50:08 DISPATCHER: Finished worker discovery
15:51:08 DISPATCHER: Starting worker discovery
15:51:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:51:08 DISPATCHER: Finished worker discovery
15:51:28 WORKER: done with job (8, 0, 15), trying to register it.
15:51:28 WORKER: registered result for job (8, 0, 15) with dispatcher
15:51:28 DISPATCHER: job (8, 0, 15) finished
15:51:28 DISPATCHER: register_result: lock acquired
15:51:28 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:51:28 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 91, 'last_n_outputs': 36, 'lr': 0.015781576022291424, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.017202260401936585}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 91, 'last_n_outputs': 36, 'lr': 0.015781576022291424, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.017202260401936585}"}}
exception: None

15:51:28 job_callback for (8, 0, 15) started
15:51:28 job_callback for (8, 0, 15) got condition
15:51:28 DISPATCHER: Trying to submit another job.
15:51:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:51:28 HBMASTER: Trying to run another job!
15:51:28 job_callback for (8, 0, 15) finished
15:51:28 HBMASTER: schedule new run for iteration 8
15:51:28 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
15:51:28 HBMASTER: submitting job (8, 0, 23) to dispatcher
15:51:28 DISPATCHER: trying to submit job (8, 0, 23)
15:51:28 DISPATCHER: trying to notify the job_runner thread.
15:51:28 HBMASTER: job (8, 0, 23) submitted to dispatcher
15:51:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:51:28 DISPATCHER: Trying to submit another job.
15:51:28 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:51:28 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:51:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:51:28 WORKER: start processing job (8, 0, 23)
15:51:28 WORKER: args: ()
15:51:28 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 87, 'last_n_outputs': 35, 'lr': 0.0016237338710719815, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.026478956072248566}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:52:08 DISPATCHER: Starting worker discovery
15:52:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:52:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-570:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:53:08 DISPATCHER: Starting worker discovery
15:53:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:53:08 DISPATCHER: Finished worker discovery
15:54:08 DISPATCHER: Starting worker discovery
15:54:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:54:08 DISPATCHER: Finished worker discovery
15:54:19 WORKER: done with job (8, 0, 23), trying to register it.
15:54:19 WORKER: registered result for job (8, 0, 23) with dispatcher
15:54:19 DISPATCHER: job (8, 0, 23) finished
15:54:19 DISPATCHER: register_result: lock acquired
15:54:19 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:54:19 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 87, 'last_n_outputs': 35, 'lr': 0.0016237338710719815, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.026478956072248566}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 87, 'last_n_outputs': 35, 'lr': 0.0016237338710719815, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.026478956072248566}"}}
exception: None

15:54:19 job_callback for (8, 0, 23) started
15:54:19 job_callback for (8, 0, 23) got condition
15:54:19 DISPATCHER: Trying to submit another job.
15:54:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:54:19 HBMASTER: Trying to run another job!
15:54:19 job_callback for (8, 0, 23) finished
15:54:19 HBMASTER: schedule new run for iteration 8
15:54:19 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
15:54:19 HBMASTER: submitting job (8, 0, 25) to dispatcher
15:54:19 DISPATCHER: trying to submit job (8, 0, 25)
15:54:19 DISPATCHER: trying to notify the job_runner thread.
15:54:19 HBMASTER: job (8, 0, 25) submitted to dispatcher
15:54:19 DISPATCHER: Trying to submit another job.
15:54:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:54:19 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:54:19 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:54:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:54:19 WORKER: start processing job (8, 0, 25)
15:54:19 WORKER: args: ()
15:54:19 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 90, 'last_n_outputs': 50, 'lr': 0.006807997421834681, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.014396643579879862}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:55:08 DISPATCHER: Starting worker discovery
15:55:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:55:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-571:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:56:08 DISPATCHER: Starting worker discovery
15:56:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:56:08 DISPATCHER: Finished worker discovery
15:57:08 DISPATCHER: Starting worker discovery
15:57:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:57:08 DISPATCHER: Finished worker discovery
15:57:14 WORKER: done with job (8, 0, 25), trying to register it.
15:57:14 WORKER: registered result for job (8, 0, 25) with dispatcher
15:57:14 DISPATCHER: job (8, 0, 25) finished
15:57:14 DISPATCHER: register_result: lock acquired
15:57:14 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
15:57:14 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 90, 'last_n_outputs': 50, 'lr': 0.006807997421834681, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.014396643579879862}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1498713156639256, 'info': {'data03': 0.1498713156639256, 'config': "{'batch_size': 32, 'hidden_dim': 90, 'last_n_outputs': 50, 'lr': 0.006807997421834681, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.014396643579879862}"}}
exception: None

15:57:14 job_callback for (8, 0, 25) started
15:57:14 job_callback for (8, 0, 25) got condition
15:57:14 DISPATCHER: Trying to submit another job.
15:57:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:57:14 HBMASTER: Trying to run another job!
15:57:14 job_callback for (8, 0, 25) finished
15:57:14 ITERATION: Advancing config (8, 0, 1) to next budget 400.000000
15:57:14 ITERATION: Advancing config (8, 0, 6) to next budget 400.000000
15:57:14 ITERATION: Advancing config (8, 0, 14) to next budget 400.000000
15:57:14 HBMASTER: schedule new run for iteration 8
15:57:14 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
15:57:14 HBMASTER: submitting job (8, 0, 1) to dispatcher
15:57:14 DISPATCHER: trying to submit job (8, 0, 1)
15:57:14 DISPATCHER: trying to notify the job_runner thread.
15:57:14 HBMASTER: job (8, 0, 1) submitted to dispatcher
15:57:14 DISPATCHER: Trying to submit another job.
15:57:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:57:14 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
15:57:14 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
15:57:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:57:14 WORKER: start processing job (8, 0, 1)
15:57:14 WORKER: args: ()
15:57:14 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 91, 'last_n_outputs': 43, 'lr': 0.0017123224947501745, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.022052548256056764}, 'budget': 400.0, 'working_directory': '.'}
15:58:08 DISPATCHER: Starting worker discovery
15:58:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:58:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-572:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

15:59:08 DISPATCHER: Starting worker discovery
15:59:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:59:08 DISPATCHER: Finished worker discovery
16:00:08 DISPATCHER: Starting worker discovery
16:00:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:00:08 DISPATCHER: Finished worker discovery
16:01:08 DISPATCHER: Starting worker discovery
16:01:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:01:08 DISPATCHER: Finished worker discovery
16:02:08 DISPATCHER: Starting worker discovery
16:02:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:02:08 DISPATCHER: Finished worker discovery
16:03:08 DISPATCHER: Starting worker discovery
16:03:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:03:08 DISPATCHER: Finished worker discovery
16:04:08 DISPATCHER: Starting worker discovery
16:04:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:04:08 DISPATCHER: Finished worker discovery
16:04:39 WORKER: done with job (8, 0, 1), trying to register it.
16:04:39 WORKER: registered result for job (8, 0, 1) with dispatcher
16:04:39 DISPATCHER: job (8, 0, 1) finished
16:04:39 DISPATCHER: register_result: lock acquired
16:04:39 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
16:04:39 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 91, 'last_n_outputs': 43, 'lr': 0.0017123224947501745, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.022052548256056764}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.05418865858257848, 'info': {'data03': 0.05418865858257848, 'config': "{'batch_size': 16, 'hidden_dim': 91, 'last_n_outputs': 43, 'lr': 0.0017123224947501745, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.022052548256056764}"}}
exception: None

16:04:39 job_callback for (8, 0, 1) started
16:04:39 DISPATCHER: Trying to submit another job.
16:04:39 job_callback for (8, 0, 1) got condition
16:04:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:04:39 done building a new model for budget 400.000000 based on 9/21 split
Best loss for this budget:-0.380421





16:04:39 HBMASTER: Trying to run another job!
16:04:39 job_callback for (8, 0, 1) finished
16:04:39 HBMASTER: schedule new run for iteration 8
16:04:39 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
16:04:39 HBMASTER: submitting job (8, 0, 6) to dispatcher
16:04:39 DISPATCHER: trying to submit job (8, 0, 6)
16:04:39 DISPATCHER: trying to notify the job_runner thread.
16:04:39 HBMASTER: job (8, 0, 6) submitted to dispatcher
16:04:39 DISPATCHER: Trying to submit another job.
16:04:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:04:39 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776
16:04:39 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
16:04:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:04:39 WORKER: start processing job (8, 0, 6)
16:04:39 WORKER: args: ()
16:04:39 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 95, 'last_n_outputs': 45, 'lr': 0.0022188653542262017, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.012767487585816367}, 'budget': 400.0, 'working_directory': '.'}
16:05:08 DISPATCHER: Starting worker discovery
16:05:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:05:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-573:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

16:06:08 DISPATCHER: Starting worker discovery
16:06:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:06:08 DISPATCHER: Finished worker discovery
16:07:08 DISPATCHER: Starting worker discovery
16:07:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:07:08 DISPATCHER: Finished worker discovery
16:08:08 DISPATCHER: Starting worker discovery
16:08:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:08:08 DISPATCHER: Finished worker discovery
16:09:08 DISPATCHER: Starting worker discovery
16:09:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:09:08 DISPATCHER: Finished worker discovery
16:10:08 DISPATCHER: Starting worker discovery
16:10:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:10:08 DISPATCHER: Finished worker discovery
16:11:08 DISPATCHER: Starting worker discovery
16:11:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:11:08 DISPATCHER: Finished worker discovery
16:12:04 WORKER: done with job (8, 0, 6), trying to register it.
16:12:04 WORKER: registered result for job (8, 0, 6) with dispatcher
16:12:04 DISPATCHER: job (8, 0, 6) finished
16:12:04 DISPATCHER: register_result: lock acquired
16:12:04 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
16:12:04 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 95, 'last_n_outputs': 45, 'lr': 0.0022188653542262017, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.012767487585816367}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.32711148340226043, 'info': {'data03': 0.32711148340226043, 'config': "{'batch_size': 16, 'hidden_dim': 95, 'last_n_outputs': 45, 'lr': 0.0022188653542262017, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.012767487585816367}"}}
exception: None

16:12:04 job_callback for (8, 0, 6) started
16:12:04 DISPATCHER: Trying to submit another job.
16:12:04 job_callback for (8, 0, 6) got condition
16:12:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:12:04 done building a new model for budget 400.000000 based on 9/22 split
Best loss for this budget:-0.380421





16:12:04 HBMASTER: Trying to run another job!
16:12:04 job_callback for (8, 0, 6) finished
16:12:04 HBMASTER: schedule new run for iteration 8
16:12:04 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
16:12:04 HBMASTER: submitting job (8, 0, 14) to dispatcher
16:12:04 DISPATCHER: trying to submit job (8, 0, 14)
16:12:04 DISPATCHER: trying to notify the job_runner thread.
16:12:04 HBMASTER: job (8, 0, 14) submitted to dispatcher
16:12:04 DISPATCHER: Trying to submit another job.
16:12:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:12:04 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776
16:12:04 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
16:12:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:12:04 WORKER: start processing job (8, 0, 14)
16:12:04 WORKER: args: ()
16:12:04 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 94, 'last_n_outputs': 49, 'lr': 0.004262884612490358, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.021978676039718523}, 'budget': 400.0, 'working_directory': '.'}
16:12:08 DISPATCHER: Starting worker discovery
16:12:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:12:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-574:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

16:13:08 DISPATCHER: Starting worker discovery
16:13:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:13:08 DISPATCHER: Finished worker discovery
16:14:08 DISPATCHER: Starting worker discovery
16:14:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:14:08 DISPATCHER: Finished worker discovery
16:15:08 DISPATCHER: Starting worker discovery
16:15:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:15:08 DISPATCHER: Finished worker discovery
16:16:08 DISPATCHER: Starting worker discovery
16:16:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:16:08 DISPATCHER: Finished worker discovery
16:17:08 DISPATCHER: Starting worker discovery
16:17:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:17:08 DISPATCHER: Finished worker discovery
16:18:08 DISPATCHER: Starting worker discovery
16:18:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:18:08 DISPATCHER: Finished worker discovery
16:19:08 DISPATCHER: Starting worker discovery
16:19:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:19:08 DISPATCHER: Finished worker discovery
16:19:24 WORKER: done with job (8, 0, 14), trying to register it.
16:19:24 WORKER: registered result for job (8, 0, 14) with dispatcher
16:19:24 DISPATCHER: job (8, 0, 14) finished
16:19:24 DISPATCHER: register_result: lock acquired
16:19:24 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
16:19:24 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 94, 'last_n_outputs': 49, 'lr': 0.004262884612490358, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.021978676039718523}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.004092976651834398, 'info': {'data03': 0.004092976651834398, 'config': "{'batch_size': 16, 'hidden_dim': 94, 'last_n_outputs': 49, 'lr': 0.004262884612490358, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.021978676039718523}"}}
exception: None

16:19:24 job_callback for (8, 0, 14) started
16:19:24 DISPATCHER: Trying to submit another job.
16:19:24 job_callback for (8, 0, 14) got condition
16:19:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:19:24 done building a new model for budget 400.000000 based on 9/22 split
Best loss for this budget:-0.380421





16:19:24 HBMASTER: Trying to run another job!
16:19:24 job_callback for (8, 0, 14) finished
16:19:24 ITERATION: Advancing config (8, 0, 6) to next budget 1200.000000
16:19:24 HBMASTER: schedule new run for iteration 8
16:19:24 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
16:19:24 HBMASTER: submitting job (8, 0, 6) to dispatcher
16:19:24 DISPATCHER: trying to submit job (8, 0, 6)
16:19:24 DISPATCHER: trying to notify the job_runner thread.
16:19:24 HBMASTER: job (8, 0, 6) submitted to dispatcher
16:19:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:19:24 DISPATCHER: Trying to submit another job.
16:19:24 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776
16:19:24 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
16:19:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:19:24 WORKER: start processing job (8, 0, 6)
16:19:24 WORKER: args: ()
16:19:24 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 95, 'last_n_outputs': 45, 'lr': 0.0022188653542262017, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.012767487585816367}, 'budget': 1200.0, 'working_directory': '.'}
16:20:08 DISPATCHER: Starting worker discovery
16:20:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:20:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-575:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

16:21:08 DISPATCHER: Starting worker discovery
16:21:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:21:08 DISPATCHER: Finished worker discovery
16:22:08 DISPATCHER: Starting worker discovery
16:22:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:22:08 DISPATCHER: Finished worker discovery
16:23:08 DISPATCHER: Starting worker discovery
16:23:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:23:08 DISPATCHER: Finished worker discovery
16:24:08 DISPATCHER: Starting worker discovery
16:24:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:24:08 DISPATCHER: Finished worker discovery
16:25:08 DISPATCHER: Starting worker discovery
16:25:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:25:08 DISPATCHER: Finished worker discovery
16:26:08 DISPATCHER: Starting worker discovery
16:26:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:26:08 DISPATCHER: Finished worker discovery
16:27:08 DISPATCHER: Starting worker discovery
16:27:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:27:08 DISPATCHER: Finished worker discovery
16:28:08 DISPATCHER: Starting worker discovery
16:28:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:28:08 DISPATCHER: Finished worker discovery
16:29:08 DISPATCHER: Starting worker discovery
16:29:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:29:08 DISPATCHER: Finished worker discovery
16:30:08 DISPATCHER: Starting worker discovery
16:30:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:30:08 DISPATCHER: Finished worker discovery
16:31:08 DISPATCHER: Starting worker discovery
16:31:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:31:08 DISPATCHER: Finished worker discovery
16:32:08 DISPATCHER: Starting worker discovery
16:32:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:32:08 DISPATCHER: Finished worker discovery
16:33:08 DISPATCHER: Starting worker discovery
16:33:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:33:08 DISPATCHER: Finished worker discovery
16:34:08 DISPATCHER: Starting worker discovery
16:34:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:34:08 DISPATCHER: Finished worker discovery
16:35:08 DISPATCHER: Starting worker discovery
16:35:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:35:08 DISPATCHER: Finished worker discovery
16:36:08 DISPATCHER: Starting worker discovery
16:36:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:36:08 DISPATCHER: Finished worker discovery
16:37:08 DISPATCHER: Starting worker discovery
16:37:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:37:08 DISPATCHER: Finished worker discovery
16:38:08 DISPATCHER: Starting worker discovery
16:38:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:38:08 DISPATCHER: Finished worker discovery
16:39:08 DISPATCHER: Starting worker discovery
16:39:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:39:08 DISPATCHER: Finished worker discovery
16:40:05 WORKER: done with job (8, 0, 6), trying to register it.
16:40:05 WORKER: registered result for job (8, 0, 6) with dispatcher
16:40:05 DISPATCHER: job (8, 0, 6) finished
16:40:05 DISPATCHER: register_result: lock acquired
16:40:05 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
16:40:05 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 95, 'last_n_outputs': 45, 'lr': 0.0022188653542262017, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.012767487585816367}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.12489650223382144, 'info': {'data03': 0.12489650223382144, 'config': "{'batch_size': 16, 'hidden_dim': 95, 'last_n_outputs': 45, 'lr': 0.0022188653542262017, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.012767487585816367}"}}
exception: None

16:40:05 job_callback for (8, 0, 6) started
16:40:05 job_callback for (8, 0, 6) got condition
16:40:05 DISPATCHER: Trying to submit another job.
16:40:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:40:05 HBMASTER: Trying to run another job!
16:40:05 job_callback for (8, 0, 6) finished
16:40:05 start sampling a new configuration.
16:40:05 done sampling a new configuration.
16:40:05 HBMASTER: schedule new run for iteration 9
16:40:05 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
16:40:05 HBMASTER: submitting job (9, 0, 0) to dispatcher
16:40:05 DISPATCHER: trying to submit job (9, 0, 0)
16:40:05 DISPATCHER: trying to notify the job_runner thread.
16:40:05 HBMASTER: job (9, 0, 0) submitted to dispatcher
16:40:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:40:05 DISPATCHER: Trying to submit another job.
16:40:05 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
16:40:05 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
16:40:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:40:05 WORKER: start processing job (9, 0, 0)
16:40:05 WORKER: args: ()
16:40:05 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 98, 'last_n_outputs': 16, 'lr': 0.0031389303030476103, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.0642605628913522}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:40:08 DISPATCHER: Starting worker discovery
16:40:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:40:08 DISPATCHER: Finished worker discovery
16:41:08 DISPATCHER: Starting worker discovery
16:41:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:41:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-576:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

16:42:08 DISPATCHER: Starting worker discovery
16:42:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:42:08 DISPATCHER: Finished worker discovery
16:43:03 WORKER: done with job (9, 0, 0), trying to register it.
16:43:03 WORKER: registered result for job (9, 0, 0) with dispatcher
16:43:03 DISPATCHER: job (9, 0, 0) finished
16:43:03 DISPATCHER: register_result: lock acquired
16:43:03 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
16:43:03 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 98, 'last_n_outputs': 16, 'lr': 0.0031389303030476103, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.0642605628913522}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 98, 'last_n_outputs': 16, 'lr': 0.0031389303030476103, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.0642605628913522}"}}
exception: None

16:43:03 job_callback for (9, 0, 0) started
16:43:03 job_callback for (9, 0, 0) got condition
16:43:03 DISPATCHER: Trying to submit another job.
16:43:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:43:03 HBMASTER: Trying to run another job!
16:43:03 job_callback for (9, 0, 0) finished
16:43:03 start sampling a new configuration.
16:43:03 best_vector: [0, 0.5768780462881482, 0.9709056955659477, 0.30407320468272137, 0.10107273608755232, 0, 0.6524141243396734, 0.025111822579315157], 3.569479691019211e-35, 280.1528756462725, -0.0121241743080415
16:43:03 done sampling a new configuration.
16:43:03 HBMASTER: schedule new run for iteration 9
16:43:03 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
16:43:03 HBMASTER: submitting job (9, 0, 1) to dispatcher
16:43:03 DISPATCHER: trying to submit job (9, 0, 1)
16:43:03 DISPATCHER: trying to notify the job_runner thread.
16:43:03 HBMASTER: job (9, 0, 1) submitted to dispatcher
16:43:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:43:03 DISPATCHER: Trying to submit another job.
16:43:03 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
16:43:03 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
16:43:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:43:03 WORKER: start processing job (9, 0, 1)
16:43:03 WORKER: args: ()
16:43:03 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 66, 'last_n_outputs': 49, 'lr': 0.004056452635405084, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.010781302570700202}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:43:08 DISPATCHER: Starting worker discovery
16:43:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:43:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-577:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

16:44:08 DISPATCHER: Starting worker discovery
16:44:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:44:08 DISPATCHER: Finished worker discovery
16:45:08 DISPATCHER: Starting worker discovery
16:45:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:45:08 DISPATCHER: Finished worker discovery
16:45:56 WORKER: done with job (9, 0, 1), trying to register it.
16:45:56 WORKER: registered result for job (9, 0, 1) with dispatcher
16:45:56 DISPATCHER: job (9, 0, 1) finished
16:45:56 DISPATCHER: register_result: lock acquired
16:45:56 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
16:45:56 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 66, 'last_n_outputs': 49, 'lr': 0.004056452635405084, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.010781302570700202}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.037223567120210646, 'info': {'data03': 0.037223567120210646, 'config': "{'batch_size': 16, 'hidden_dim': 66, 'last_n_outputs': 49, 'lr': 0.004056452635405084, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.010781302570700202}"}}
exception: None

16:45:56 job_callback for (9, 0, 1) started
16:45:56 job_callback for (9, 0, 1) got condition
16:45:56 DISPATCHER: Trying to submit another job.
16:45:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:45:56 HBMASTER: Trying to run another job!
16:45:56 job_callback for (9, 0, 1) finished
16:45:56 start sampling a new configuration.
16:45:56 best_vector: [0, 0.9210076536783286, 0.9362853208013862, 0.12882883923117522, 0.0980669659050617, 0, 0.9651652099245045, 0.04450227048399438], 4.4761057884896835e-35, 223.40848211664309, -0.019964164614191107
16:45:56 done sampling a new configuration.
16:45:56 HBMASTER: schedule new run for iteration 9
16:45:56 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
16:45:56 HBMASTER: submitting job (9, 0, 2) to dispatcher
16:45:56 DISPATCHER: trying to submit job (9, 0, 2)
16:45:56 DISPATCHER: trying to notify the job_runner thread.
16:45:56 HBMASTER: job (9, 0, 2) submitted to dispatcher
16:45:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:45:56 DISPATCHER: Trying to submit another job.
16:45:56 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
16:45:56 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
16:45:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:45:56 WORKER: start processing job (9, 0, 2)
16:45:56 WORKER: args: ()
16:45:56 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 94, 'last_n_outputs': 47, 'lr': 0.0018099129125788357, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.011426120209317658}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:46:08 DISPATCHER: Starting worker discovery
16:46:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:46:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-578:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

16:47:08 DISPATCHER: Starting worker discovery
16:47:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:47:08 DISPATCHER: Finished worker discovery
16:48:08 DISPATCHER: Starting worker discovery
16:48:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:48:08 DISPATCHER: Finished worker discovery
16:48:49 WORKER: done with job (9, 0, 2), trying to register it.
16:48:49 WORKER: registered result for job (9, 0, 2) with dispatcher
16:48:49 DISPATCHER: job (9, 0, 2) finished
16:48:49 DISPATCHER: register_result: lock acquired
16:48:49 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
16:48:49 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 94, 'last_n_outputs': 47, 'lr': 0.0018099129125788357, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.011426120209317658}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.19112575475418786, 'info': {'data03': 0.19112575475418786, 'config': "{'batch_size': 16, 'hidden_dim': 94, 'last_n_outputs': 47, 'lr': 0.0018099129125788357, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.011426120209317658}"}}
exception: None

16:48:49 job_callback for (9, 0, 2) started
16:48:49 job_callback for (9, 0, 2) got condition
16:48:49 DISPATCHER: Trying to submit another job.
16:48:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:48:49 HBMASTER: Trying to run another job!
16:48:49 job_callback for (9, 0, 2) finished
16:48:49 start sampling a new configuration.
16:48:49 best_vector: [0, 0.49246992056503336, 0.9614393829429254, 0.34160359722897443, 0.1030867630924194, 0, 0.7968908376151858, 0.37388902294242143], 1.225191088608179e-33, 8.161992111255095, -0.0012290093153908624
16:48:49 done sampling a new configuration.
16:48:49 HBMASTER: schedule new run for iteration 9
16:48:49 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
16:48:49 HBMASTER: submitting job (9, 0, 3) to dispatcher
16:48:49 DISPATCHER: trying to submit job (9, 0, 3)
16:48:49 DISPATCHER: trying to notify the job_runner thread.
16:48:49 HBMASTER: job (9, 0, 3) submitted to dispatcher
16:48:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:48:49 DISPATCHER: Trying to submit another job.
16:48:49 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
16:48:49 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
16:48:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:48:49 WORKER: start processing job (9, 0, 3)
16:48:49 WORKER: args: ()
16:48:49 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 59, 'last_n_outputs': 49, 'lr': 0.004821777815200426, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.030650730807941808}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:49:08 DISPATCHER: Starting worker discovery
16:49:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:49:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-579:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

16:50:08 DISPATCHER: Starting worker discovery
16:50:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:50:08 DISPATCHER: Finished worker discovery
16:51:08 DISPATCHER: Starting worker discovery
16:51:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:51:08 DISPATCHER: Finished worker discovery
16:51:40 WORKER: done with job (9, 0, 3), trying to register it.
16:51:40 WORKER: registered result for job (9, 0, 3) with dispatcher
16:51:40 DISPATCHER: job (9, 0, 3) finished
16:51:40 DISPATCHER: register_result: lock acquired
16:51:40 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
16:51:40 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 59, 'last_n_outputs': 49, 'lr': 0.004821777815200426, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.030650730807941808}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.19872214222892487, 'info': {'data03': 0.19872214222892487, 'config': "{'batch_size': 16, 'hidden_dim': 59, 'last_n_outputs': 49, 'lr': 0.004821777815200426, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.030650730807941808}"}}
exception: None

16:51:40 job_callback for (9, 0, 3) started
16:51:40 job_callback for (9, 0, 3) got condition
16:51:40 DISPATCHER: Trying to submit another job.
16:51:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:51:40 HBMASTER: Trying to run another job!
16:51:40 job_callback for (9, 0, 3) finished
16:51:40 start sampling a new configuration.
16:51:40 best_vector: [0, 0.7557922718912454, 0.7451650642791592, 0.3707565993073699, 0.09905889977784818, 0, 0.38123377981533724, 0.6924685085098388], 6.942485406590155e-35, 144.04063407187718, -0.01881837395806231
16:51:40 done sampling a new configuration.
16:51:40 HBMASTER: schedule new run for iteration 9
16:51:40 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
16:51:40 HBMASTER: submitting job (9, 0, 4) to dispatcher
16:51:40 DISPATCHER: trying to submit job (9, 0, 4)
16:51:40 DISPATCHER: trying to notify the job_runner thread.
16:51:40 HBMASTER: job (9, 0, 4) submitted to dispatcher
16:51:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:51:40 DISPATCHER: Trying to submit another job.
16:51:40 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
16:51:40 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
16:51:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:51:40 WORKER: start processing job (9, 0, 4)
16:51:40 WORKER: args: ()
16:51:40 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 81, 'last_n_outputs': 38, 'lr': 0.005514589614797333, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.07960169227470013}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:52:08 DISPATCHER: Starting worker discovery
16:52:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:52:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-580:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

16:53:08 DISPATCHER: Starting worker discovery
16:53:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:53:08 DISPATCHER: Finished worker discovery
16:54:08 DISPATCHER: Starting worker discovery
16:54:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:54:08 DISPATCHER: Finished worker discovery
16:54:36 WORKER: done with job (9, 0, 4), trying to register it.
16:54:36 WORKER: registered result for job (9, 0, 4) with dispatcher
16:54:36 DISPATCHER: job (9, 0, 4) finished
16:54:36 DISPATCHER: register_result: lock acquired
16:54:36 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
16:54:36 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 81, 'last_n_outputs': 38, 'lr': 0.005514589614797333, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.07960169227470013}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 81, 'last_n_outputs': 38, 'lr': 0.005514589614797333, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.07960169227470013}"}}
exception: None

16:54:36 job_callback for (9, 0, 4) started
16:54:36 DISPATCHER: Trying to submit another job.
16:54:36 job_callback for (9, 0, 4) got condition
16:54:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:54:36 HBMASTER: Trying to run another job!
16:54:36 job_callback for (9, 0, 4) finished
16:54:36 start sampling a new configuration.
16:54:36 best_vector: [0, 0.7321970674441206, 0.9818464019881153, 0.23368276873791965, 0.09813779212291839, 0, 0.936124867505462, 0.05529383957952013], 2.4194261663840175e-35, 413.32114775569374, -0.016797029553656195
16:54:36 done sampling a new configuration.
16:54:36 HBMASTER: schedule new run for iteration 9
16:54:36 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
16:54:36 HBMASTER: submitting job (9, 0, 5) to dispatcher
16:54:36 DISPATCHER: trying to submit job (9, 0, 5)
16:54:36 DISPATCHER: trying to notify the job_runner thread.
16:54:36 HBMASTER: job (9, 0, 5) submitted to dispatcher
16:54:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:54:36 DISPATCHER: Trying to submit another job.
16:54:36 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
16:54:36 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
16:54:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:54:36 WORKER: start processing job (9, 0, 5)
16:54:36 WORKER: args: ()
16:54:36 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 79, 'last_n_outputs': 50, 'lr': 0.0029333611612799002, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.0118015470965092}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:55:08 DISPATCHER: Starting worker discovery
16:55:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:55:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-581:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

16:56:08 DISPATCHER: Starting worker discovery
16:56:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:56:08 DISPATCHER: Finished worker discovery
16:57:08 DISPATCHER: Starting worker discovery
16:57:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:57:08 DISPATCHER: Finished worker discovery
16:57:30 WORKER: done with job (9, 0, 5), trying to register it.
16:57:30 WORKER: registered result for job (9, 0, 5) with dispatcher
16:57:30 DISPATCHER: job (9, 0, 5) finished
16:57:30 DISPATCHER: register_result: lock acquired
16:57:30 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
16:57:30 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 79, 'last_n_outputs': 50, 'lr': 0.0029333611612799002, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.0118015470965092}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2123578254694802, 'info': {'data03': 0.2123578254694802, 'config': "{'batch_size': 16, 'hidden_dim': 79, 'last_n_outputs': 50, 'lr': 0.0029333611612799002, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.0118015470965092}"}}
exception: None

16:57:30 job_callback for (9, 0, 5) started
16:57:30 DISPATCHER: Trying to submit another job.
16:57:30 job_callback for (9, 0, 5) got condition
16:57:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:57:30 HBMASTER: Trying to run another job!
16:57:30 job_callback for (9, 0, 5) finished
16:57:30 start sampling a new configuration.
16:57:30 best_vector: [0, 0.4437317580605638, 0.8515756690389373, 0.22808304481210284, 0.100799311251288, 0, 0.6116376529472394, 0.3464148260012911], 3.05984048109088e-35, 326.81442257522025, -0.008419063092152339
16:57:30 done sampling a new configuration.
16:57:30 HBMASTER: schedule new run for iteration 9
16:57:30 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
16:57:30 HBMASTER: submitting job (9, 0, 6) to dispatcher
16:57:30 DISPATCHER: trying to submit job (9, 0, 6)
16:57:30 DISPATCHER: trying to notify the job_runner thread.
16:57:30 HBMASTER: job (9, 0, 6) submitted to dispatcher
16:57:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:57:30 DISPATCHER: Trying to submit another job.
16:57:30 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776
16:57:30 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
16:57:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:57:30 WORKER: start processing job (9, 0, 6)
16:57:30 WORKER: args: ()
16:57:30 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 55, 'last_n_outputs': 43, 'lr': 0.002858683596420434, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.028229038079655572}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:58:08 DISPATCHER: Starting worker discovery
16:58:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:58:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-582:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

16:59:08 DISPATCHER: Starting worker discovery
16:59:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:59:09 DISPATCHER: Finished worker discovery
17:00:09 DISPATCHER: Starting worker discovery
17:00:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:00:09 DISPATCHER: Finished worker discovery
17:00:20 WORKER: done with job (9, 0, 6), trying to register it.
17:00:20 WORKER: registered result for job (9, 0, 6) with dispatcher
17:00:20 DISPATCHER: job (9, 0, 6) finished
17:00:20 DISPATCHER: register_result: lock acquired
17:00:20 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
17:00:20 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 55, 'last_n_outputs': 43, 'lr': 0.002858683596420434, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.028229038079655572}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.17994831947651888, 'info': {'data03': 0.17994831947651888, 'config': "{'batch_size': 16, 'hidden_dim': 55, 'last_n_outputs': 43, 'lr': 0.002858683596420434, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.028229038079655572}"}}
exception: None

17:00:20 job_callback for (9, 0, 6) started
17:00:20 DISPATCHER: Trying to submit another job.
17:00:20 job_callback for (9, 0, 6) got condition
17:00:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:00:20 HBMASTER: Trying to run another job!
17:00:20 job_callback for (9, 0, 6) finished
17:00:20 start sampling a new configuration.
17:00:20 done sampling a new configuration.
17:00:20 HBMASTER: schedule new run for iteration 9
17:00:20 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
17:00:20 HBMASTER: submitting job (9, 0, 7) to dispatcher
17:00:20 DISPATCHER: trying to submit job (9, 0, 7)
17:00:20 DISPATCHER: trying to notify the job_runner thread.
17:00:20 HBMASTER: job (9, 0, 7) submitted to dispatcher
17:00:20 DISPATCHER: Trying to submit another job.
17:00:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:00:20 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776
17:00:20 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
17:00:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:00:20 WORKER: start processing job (9, 0, 7)
17:00:20 WORKER: args: ()
17:00:20 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 54, 'last_n_outputs': 16, 'lr': 0.08112161907470199, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 68, 'weight_decay': 0.02381075121508316}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:01:09 DISPATCHER: Starting worker discovery
17:01:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:01:09 DISPATCHER: Finished worker discovery
Exception in thread Thread-583:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

17:02:09 DISPATCHER: Starting worker discovery
17:02:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:02:09 DISPATCHER: Finished worker discovery
17:03:09 DISPATCHER: Starting worker discovery
17:03:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:03:09 DISPATCHER: Finished worker discovery
17:03:13 WORKER: done with job (9, 0, 7), trying to register it.
17:03:13 WORKER: registered result for job (9, 0, 7) with dispatcher
17:03:13 DISPATCHER: job (9, 0, 7) finished
17:03:13 DISPATCHER: register_result: lock acquired
17:03:13 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
17:03:13 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 54, 'last_n_outputs': 16, 'lr': 0.08112161907470199, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 68, 'weight_decay': 0.02381075121508316}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 54, 'last_n_outputs': 16, 'lr': 0.08112161907470199, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 68, 'weight_decay': 0.02381075121508316}"}}
exception: None

17:03:13 job_callback for (9, 0, 7) started
17:03:13 DISPATCHER: Trying to submit another job.
17:03:13 job_callback for (9, 0, 7) got condition
17:03:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:03:13 HBMASTER: Trying to run another job!
17:03:13 job_callback for (9, 0, 7) finished
17:03:13 start sampling a new configuration.
17:03:13 done sampling a new configuration.
17:03:13 HBMASTER: schedule new run for iteration 9
17:03:13 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
17:03:13 HBMASTER: submitting job (9, 0, 8) to dispatcher
17:03:13 DISPATCHER: trying to submit job (9, 0, 8)
17:03:13 DISPATCHER: trying to notify the job_runner thread.
17:03:13 HBMASTER: job (9, 0, 8) submitted to dispatcher
17:03:13 DISPATCHER: Trying to submit another job.
17:03:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:03:13 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776
17:03:13 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
17:03:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:03:13 WORKER: start processing job (9, 0, 8)
17:03:13 WORKER: args: ()
17:03:13 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 88, 'last_n_outputs': 36, 'lr': 0.0028055734560864525, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.06160651921181206}, 'budget': 133.33333333333331, 'working_directory': '.'}
17:04:09 DISPATCHER: Starting worker discovery
17:04:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:04:09 DISPATCHER: Finished worker discovery
Exception in thread Thread-584:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

17:05:09 DISPATCHER: Starting worker discovery
17:05:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:05:09 DISPATCHER: Finished worker discovery
17:06:03 WORKER: done with job (9, 0, 8), trying to register it.
17:06:03 WORKER: registered result for job (9, 0, 8) with dispatcher
17:06:03 DISPATCHER: job (9, 0, 8) finished
17:06:03 DISPATCHER: register_result: lock acquired
17:06:03 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
17:06:03 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 88, 'last_n_outputs': 36, 'lr': 0.0028055734560864525, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.06160651921181206}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 88, 'last_n_outputs': 36, 'lr': 0.0028055734560864525, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.06160651921181206}"}}
exception: None

17:06:03 job_callback for (9, 0, 8) started
17:06:03 DISPATCHER: Trying to submit another job.
17:06:03 job_callback for (9, 0, 8) got condition
17:06:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:06:03 HBMASTER: Trying to run another job!
17:06:03 job_callback for (9, 0, 8) finished
17:06:03 ITERATION: Advancing config (9, 0, 2) to next budget 400.000000
17:06:03 ITERATION: Advancing config (9, 0, 3) to next budget 400.000000
17:06:03 ITERATION: Advancing config (9, 0, 5) to next budget 400.000000
17:06:03 HBMASTER: schedule new run for iteration 9
17:06:03 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
17:06:03 HBMASTER: submitting job (9, 0, 2) to dispatcher
17:06:03 DISPATCHER: trying to submit job (9, 0, 2)
17:06:03 DISPATCHER: trying to notify the job_runner thread.
17:06:03 HBMASTER: job (9, 0, 2) submitted to dispatcher
17:06:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:06:03 DISPATCHER: Trying to submit another job.
17:06:03 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
17:06:03 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
17:06:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:06:03 WORKER: start processing job (9, 0, 2)
17:06:03 WORKER: args: ()
17:06:03 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 94, 'last_n_outputs': 47, 'lr': 0.0018099129125788357, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.011426120209317658}, 'budget': 400.0, 'working_directory': '.'}
17:06:09 DISPATCHER: Starting worker discovery
17:06:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:06:09 DISPATCHER: Finished worker discovery
Exception in thread Thread-585:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

17:07:09 DISPATCHER: Starting worker discovery
17:07:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:07:09 DISPATCHER: Finished worker discovery
17:08:09 DISPATCHER: Starting worker discovery
17:08:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:08:09 DISPATCHER: Finished worker discovery
17:09:09 DISPATCHER: Starting worker discovery
17:09:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:09:09 DISPATCHER: Finished worker discovery
17:10:09 DISPATCHER: Starting worker discovery
17:10:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:10:09 DISPATCHER: Finished worker discovery
17:11:09 DISPATCHER: Starting worker discovery
17:11:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:11:09 DISPATCHER: Finished worker discovery
17:12:09 DISPATCHER: Starting worker discovery
17:12:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:12:09 DISPATCHER: Finished worker discovery
17:13:09 DISPATCHER: Starting worker discovery
17:13:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:13:09 DISPATCHER: Finished worker discovery
17:13:31 WORKER: done with job (9, 0, 2), trying to register it.
17:13:31 WORKER: registered result for job (9, 0, 2) with dispatcher
17:13:31 DISPATCHER: job (9, 0, 2) finished
17:13:31 DISPATCHER: register_result: lock acquired
17:13:31 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
17:13:31 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 94, 'last_n_outputs': 47, 'lr': 0.0018099129125788357, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.011426120209317658}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.23394479502940235, 'info': {'data03': 0.23394479502940235, 'config': "{'batch_size': 16, 'hidden_dim': 94, 'last_n_outputs': 47, 'lr': 0.0018099129125788357, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.011426120209317658}"}}
exception: None

17:13:31 job_callback for (9, 0, 2) started
17:13:31 job_callback for (9, 0, 2) got condition
17:13:31 DISPATCHER: Trying to submit another job.
17:13:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:13:31 done building a new model for budget 400.000000 based on 9/23 split
Best loss for this budget:-0.380421





17:13:31 HBMASTER: Trying to run another job!
17:13:31 job_callback for (9, 0, 2) finished
17:13:31 HBMASTER: schedule new run for iteration 9
17:13:31 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
17:13:31 HBMASTER: submitting job (9, 0, 3) to dispatcher
17:13:31 DISPATCHER: trying to submit job (9, 0, 3)
17:13:31 DISPATCHER: trying to notify the job_runner thread.
17:13:31 HBMASTER: job (9, 0, 3) submitted to dispatcher
17:13:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:13:31 DISPATCHER: Trying to submit another job.
17:13:31 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
17:13:31 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
17:13:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:13:31 WORKER: start processing job (9, 0, 3)
17:13:31 WORKER: args: ()
17:13:31 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 59, 'last_n_outputs': 49, 'lr': 0.004821777815200426, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.030650730807941808}, 'budget': 400.0, 'working_directory': '.'}
17:14:09 DISPATCHER: Starting worker discovery
17:14:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:14:09 DISPATCHER: Finished worker discovery
Exception in thread Thread-586:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

17:15:09 DISPATCHER: Starting worker discovery
17:15:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:15:09 DISPATCHER: Finished worker discovery
17:16:09 DISPATCHER: Starting worker discovery
17:16:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:16:09 DISPATCHER: Finished worker discovery
17:17:09 DISPATCHER: Starting worker discovery
17:17:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:17:09 DISPATCHER: Finished worker discovery
17:18:09 DISPATCHER: Starting worker discovery
17:18:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:18:09 DISPATCHER: Finished worker discovery
17:19:09 DISPATCHER: Starting worker discovery
17:19:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:19:09 DISPATCHER: Finished worker discovery
17:20:09 DISPATCHER: Starting worker discovery
17:20:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:20:09 DISPATCHER: Finished worker discovery
17:20:54 WORKER: done with job (9, 0, 3), trying to register it.
17:20:54 WORKER: registered result for job (9, 0, 3) with dispatcher
17:20:54 DISPATCHER: job (9, 0, 3) finished
17:20:54 DISPATCHER: register_result: lock acquired
17:20:54 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
17:20:54 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 59, 'last_n_outputs': 49, 'lr': 0.004821777815200426, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.030650730807941808}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.10705354093987741, 'info': {'data03': 0.10705354093987741, 'config': "{'batch_size': 16, 'hidden_dim': 59, 'last_n_outputs': 49, 'lr': 0.004821777815200426, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.030650730807941808}"}}
exception: None

17:20:54 job_callback for (9, 0, 3) started
17:20:54 job_callback for (9, 0, 3) got condition
17:20:54 DISPATCHER: Trying to submit another job.
17:20:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:20:54 done building a new model for budget 400.000000 based on 9/24 split
Best loss for this budget:-0.380421





17:20:54 HBMASTER: Trying to run another job!
17:20:54 job_callback for (9, 0, 3) finished
17:20:54 HBMASTER: schedule new run for iteration 9
17:20:54 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
17:20:54 HBMASTER: submitting job (9, 0, 5) to dispatcher
17:20:54 DISPATCHER: trying to submit job (9, 0, 5)
17:20:54 DISPATCHER: trying to notify the job_runner thread.
17:20:54 HBMASTER: job (9, 0, 5) submitted to dispatcher
17:20:54 DISPATCHER: Trying to submit another job.
17:20:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:20:54 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
17:20:54 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
17:20:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:20:54 WORKER: start processing job (9, 0, 5)
17:20:54 WORKER: args: ()
17:20:54 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 79, 'last_n_outputs': 50, 'lr': 0.0029333611612799002, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.0118015470965092}, 'budget': 400.0, 'working_directory': '.'}
17:21:09 DISPATCHER: Starting worker discovery
17:21:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:21:09 DISPATCHER: Finished worker discovery
Exception in thread Thread-587:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

17:22:09 DISPATCHER: Starting worker discovery
17:22:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:22:09 DISPATCHER: Finished worker discovery
17:23:09 DISPATCHER: Starting worker discovery
17:23:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:23:09 DISPATCHER: Finished worker discovery
17:24:09 DISPATCHER: Starting worker discovery
17:24:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:24:09 DISPATCHER: Finished worker discovery
17:25:09 DISPATCHER: Starting worker discovery
17:25:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:25:09 DISPATCHER: Finished worker discovery
17:26:09 DISPATCHER: Starting worker discovery
17:26:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:26:09 DISPATCHER: Finished worker discovery
17:27:09 DISPATCHER: Starting worker discovery
17:27:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:27:09 DISPATCHER: Finished worker discovery
17:28:09 DISPATCHER: Starting worker discovery
17:28:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:28:09 DISPATCHER: Finished worker discovery
17:28:17 WORKER: done with job (9, 0, 5), trying to register it.
17:28:17 WORKER: registered result for job (9, 0, 5) with dispatcher
17:28:17 DISPATCHER: job (9, 0, 5) finished
17:28:17 DISPATCHER: register_result: lock acquired
17:28:17 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
17:28:17 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 79, 'last_n_outputs': 50, 'lr': 0.0029333611612799002, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.0118015470965092}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.025332006575861474, 'info': {'data03': 0.025332006575861474, 'config': "{'batch_size': 16, 'hidden_dim': 79, 'last_n_outputs': 50, 'lr': 0.0029333611612799002, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.0118015470965092}"}}
exception: None

17:28:17 job_callback for (9, 0, 5) started
17:28:17 DISPATCHER: Trying to submit another job.
17:28:17 job_callback for (9, 0, 5) got condition
17:28:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:28:17 done building a new model for budget 400.000000 based on 9/25 split
Best loss for this budget:-0.380421





17:28:17 HBMASTER: Trying to run another job!
17:28:17 job_callback for (9, 0, 5) finished
17:28:17 ITERATION: Advancing config (9, 0, 2) to next budget 1200.000000
17:28:17 HBMASTER: schedule new run for iteration 9
17:28:17 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
17:28:17 HBMASTER: submitting job (9, 0, 2) to dispatcher
17:28:17 DISPATCHER: trying to submit job (9, 0, 2)
17:28:17 DISPATCHER: trying to notify the job_runner thread.
17:28:17 HBMASTER: job (9, 0, 2) submitted to dispatcher
17:28:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:28:17 DISPATCHER: Trying to submit another job.
17:28:17 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
17:28:17 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
17:28:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:28:17 WORKER: start processing job (9, 0, 2)
17:28:17 WORKER: args: ()
17:28:17 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 94, 'last_n_outputs': 47, 'lr': 0.0018099129125788357, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.011426120209317658}, 'budget': 1200.0, 'working_directory': '.'}
17:29:09 DISPATCHER: Starting worker discovery
17:29:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:29:09 DISPATCHER: Finished worker discovery
Exception in thread Thread-588:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

17:30:09 DISPATCHER: Starting worker discovery
17:30:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:30:09 DISPATCHER: Finished worker discovery
17:31:09 DISPATCHER: Starting worker discovery
17:31:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:31:09 DISPATCHER: Finished worker discovery
17:32:09 DISPATCHER: Starting worker discovery
17:32:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:32:09 DISPATCHER: Finished worker discovery
17:33:09 DISPATCHER: Starting worker discovery
17:33:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:33:09 DISPATCHER: Finished worker discovery
17:34:09 DISPATCHER: Starting worker discovery
17:34:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:34:09 DISPATCHER: Finished worker discovery
17:35:09 DISPATCHER: Starting worker discovery
17:35:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:35:09 DISPATCHER: Finished worker discovery
17:36:09 DISPATCHER: Starting worker discovery
17:36:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:36:09 DISPATCHER: Finished worker discovery
17:37:09 DISPATCHER: Starting worker discovery
17:37:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:37:09 DISPATCHER: Finished worker discovery
17:38:09 DISPATCHER: Starting worker discovery
17:38:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:38:09 DISPATCHER: Finished worker discovery
17:39:09 DISPATCHER: Starting worker discovery
17:39:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:39:09 DISPATCHER: Finished worker discovery
17:40:09 DISPATCHER: Starting worker discovery
17:40:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:40:09 DISPATCHER: Finished worker discovery
17:41:09 DISPATCHER: Starting worker discovery
17:41:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:41:09 DISPATCHER: Finished worker discovery
17:42:09 DISPATCHER: Starting worker discovery
17:42:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:42:09 DISPATCHER: Finished worker discovery
17:43:09 DISPATCHER: Starting worker discovery
17:43:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:43:09 DISPATCHER: Finished worker discovery
17:44:09 DISPATCHER: Starting worker discovery
17:44:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:44:09 DISPATCHER: Finished worker discovery
17:45:09 DISPATCHER: Starting worker discovery
17:45:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:45:09 DISPATCHER: Finished worker discovery
17:46:09 DISPATCHER: Starting worker discovery
17:46:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:46:09 DISPATCHER: Finished worker discovery
17:47:09 DISPATCHER: Starting worker discovery
17:47:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:47:09 DISPATCHER: Finished worker discovery
17:48:09 DISPATCHER: Starting worker discovery
17:48:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:48:09 DISPATCHER: Finished worker discovery
17:49:00 WORKER: done with job (9, 0, 2), trying to register it.
17:49:00 WORKER: registered result for job (9, 0, 2) with dispatcher
17:49:00 DISPATCHER: job (9, 0, 2) finished
17:49:00 DISPATCHER: register_result: lock acquired
17:49:00 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
17:49:00 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 94, 'last_n_outputs': 47, 'lr': 0.0018099129125788357, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.011426120209317658}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.09018337187993848, 'info': {'data03': 0.09018337187993848, 'config': "{'batch_size': 16, 'hidden_dim': 94, 'last_n_outputs': 47, 'lr': 0.0018099129125788357, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.011426120209317658}"}}
exception: None

17:49:00 job_callback for (9, 0, 2) started
17:49:00 DISPATCHER: Trying to submit another job.
17:49:00 job_callback for (9, 0, 2) got condition
17:49:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:49:00 done building a new model for budget 1200.000000 based on 9/15 split
Best loss for this budget:-0.332120





17:49:00 HBMASTER: Trying to run another job!
17:49:00 job_callback for (9, 0, 2) finished
17:49:00 HBMASTER: shutdown initiated, shutdown_workers = True
17:49:00 WORKER: shutting down now!
17:49:00 DISPATCHER: Dispatcher shutting down
17:49:00 DISPATCHER: discover_workers shutting down
17:49:00 DISPATCHER: Trying to submit another job.
17:49:00 DISPATCHER: 'discover_worker' thread exited
17:49:00 DISPATCHER: job_runner shutting down
17:49:00 DISPATCHER: 'job_runner' thread exited
17:49:00 DISPATCHER: shut down complete
17:49:00 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7f4dc80fe390; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:34997>
17:49:00 WORKER: No dispatcher found. Waiting for one to initiate contact.
17:49:00 WORKER: start listening for jobs
17:49:00 wait_for_workers trying to get the condition
17:49:00 DISPATCHER: started the 'discover_worker' thread
17:49:00 DISPATCHER: started the 'job_runner' thread
17:49:00 DISPATCHER: Pyro daemon running on localhost:42909
17:49:00 HBMASTER: only 0 worker(s) available, waiting for at least 1.
17:49:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:49:00 DISPATCHER: Starting worker discovery
17:49:00 DISPATCHER: Found 1 potential workers, 0 currently in the pool.
17:49:00 DISPATCHER: discovered new worker, hpbandster.run_0.worker.metagpui.1576139975513683776
17:49:00 HBMASTER: number of workers changed to 1
17:49:00 adjust_queue_size: lock accquired
17:49:00 HBMASTER: adjusted queue size to (0, 1)
17:49:00 DISPATCHER: Finished worker discovery
17:49:00 DISPATCHER: A new worker triggered discover_worker
17:49:00 DISPATCHER: Trying to submit another job.
17:49:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:49:00 Enough workers to start this run!
17:49:00 DISPATCHER: Starting worker discovery
17:49:00 HBMASTER: starting run at 1583945340.966824
17:49:00 start sampling a new configuration.
17:49:00 done sampling a new configuration.
17:49:00 HBMASTER: schedule new run for iteration 0
17:49:00 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
17:49:00 HBMASTER: submitting job (0, 0, 0) to dispatcher
17:49:00 DISPATCHER: trying to submit job (0, 0, 0)
17:49:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:49:00 DISPATCHER: Finished worker discovery
17:49:00 DISPATCHER: trying to notify the job_runner thread.
17:49:00 HBMASTER: job (0, 0, 0) submitted to dispatcher
17:49:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:49:00 DISPATCHER: Trying to submit another job.
17:49:00 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
17:49:00 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
17:49:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:49:00 WORKER: start processing job (0, 0, 0)
17:49:00 WORKER: args: ()
17:49:00 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0038201049917058467, 'num_filters_1': 78, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.01563608096253674, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 29, 'num_filters_3': 88, 'num_filters_4': 38, 'num_filters_5': 52}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:50:00 DISPATCHER: Starting worker discovery
17:50:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:50:00 DISPATCHER: Finished worker discovery
17:50:28 WORKER: done with job (0, 0, 0), trying to register it.
17:50:28 WORKER: registered result for job (0, 0, 0) with dispatcher
17:50:28 DISPATCHER: job (0, 0, 0) finished
17:50:28 DISPATCHER: register_result: lock acquired
17:50:28 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
17:50:28 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0038201049917058467, 'num_filters_1': 78, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.01563608096253674, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 29, 'num_filters_3': 88, 'num_filters_4': 38, 'num_filters_5': 52}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2919064103939787, 'info': {'data03': 0.2919064103939787, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0038201049917058467, 'num_filters_1': 78, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.01563608096253674, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 29, 'num_filters_3': 88, 'num_filters_4': 38, 'num_filters_5': 52}"}}
exception: None

17:50:28 job_callback for (0, 0, 0) started
17:50:28 job_callback for (0, 0, 0) got condition
17:50:28 DISPATCHER: Trying to submit another job.
17:50:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:50:28 Only 1 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
17:50:28 HBMASTER: Trying to run another job!
17:50:28 job_callback for (0, 0, 0) finished
17:50:28 start sampling a new configuration.
17:50:28 done sampling a new configuration.
17:50:28 HBMASTER: schedule new run for iteration 0
17:50:28 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
17:50:28 HBMASTER: submitting job (0, 0, 1) to dispatcher
17:50:28 DISPATCHER: trying to submit job (0, 0, 1)
17:50:28 DISPATCHER: trying to notify the job_runner thread.
17:50:28 HBMASTER: job (0, 0, 1) submitted to dispatcher
17:50:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:50:28 DISPATCHER: Trying to submit another job.
17:50:28 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
17:50:28 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
17:50:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:50:28 WORKER: start processing job (0, 0, 1)
17:50:28 WORKER: args: ()
17:50:28 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.04609671832142337, 'num_filters_1': 53, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.0566724784635436}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:51:00 DISPATCHER: Starting worker discovery
17:51:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:51:01 DISPATCHER: Finished worker discovery
17:52:01 DISPATCHER: Starting worker discovery
17:52:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:52:01 DISPATCHER: Finished worker discovery
17:52:07 WORKER: done with job (0, 0, 1), trying to register it.
17:52:07 WORKER: registered result for job (0, 0, 1) with dispatcher
17:52:07 DISPATCHER: job (0, 0, 1) finished
17:52:07 DISPATCHER: register_result: lock acquired
17:52:07 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
17:52:07 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.04609671832142337, 'num_filters_1': 53, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.0566724784635436}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.32940067114070587, 'info': {'data03': 0.32940067114070587, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.04609671832142337, 'num_filters_1': 53, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.0566724784635436}"}}
exception: None

17:52:07 job_callback for (0, 0, 1) started
17:52:07 DISPATCHER: Trying to submit another job.
17:52:07 job_callback for (0, 0, 1) got condition
17:52:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:52:07 Only 2 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
17:52:07 HBMASTER: Trying to run another job!
17:52:07 job_callback for (0, 0, 1) finished
17:52:07 start sampling a new configuration.
17:52:07 done sampling a new configuration.
17:52:07 HBMASTER: schedule new run for iteration 0
17:52:07 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
17:52:07 HBMASTER: submitting job (0, 0, 2) to dispatcher
17:52:07 DISPATCHER: trying to submit job (0, 0, 2)
17:52:07 DISPATCHER: trying to notify the job_runner thread.
17:52:07 HBMASTER: job (0, 0, 2) submitted to dispatcher
17:52:07 DISPATCHER: Trying to submit another job.
17:52:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:52:07 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
17:52:07 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
17:52:07 WORKER: start processing job (0, 0, 2)
17:52:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:52:07 WORKER: args: ()
17:52:07 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00645974879509834, 'num_filters_1': 87, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.012859992184415444, 'kernel_size_2': 5, 'num_filters_2': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:53:01 DISPATCHER: Starting worker discovery
17:53:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:53:01 DISPATCHER: Finished worker discovery
17:53:34 WORKER: done with job (0, 0, 2), trying to register it.
17:53:34 WORKER: registered result for job (0, 0, 2) with dispatcher
17:53:34 DISPATCHER: job (0, 0, 2) finished
17:53:34 DISPATCHER: register_result: lock acquired
17:53:34 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
17:53:34 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00645974879509834, 'num_filters_1': 87, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.012859992184415444, 'kernel_size_2': 5, 'num_filters_2': 43}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.37264759630499117, 'info': {'data03': 0.37264759630499117, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00645974879509834, 'num_filters_1': 87, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.012859992184415444, 'kernel_size_2': 5, 'num_filters_2': 43}"}}
exception: None

17:53:34 job_callback for (0, 0, 2) started
17:53:34 job_callback for (0, 0, 2) got condition
17:53:34 DISPATCHER: Trying to submit another job.
17:53:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:53:34 Only 3 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
17:53:34 HBMASTER: Trying to run another job!
17:53:34 job_callback for (0, 0, 2) finished
17:53:34 start sampling a new configuration.
17:53:34 done sampling a new configuration.
17:53:34 HBMASTER: schedule new run for iteration 0
17:53:34 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
17:53:34 HBMASTER: submitting job (0, 0, 3) to dispatcher
17:53:34 DISPATCHER: trying to submit job (0, 0, 3)
17:53:34 DISPATCHER: trying to notify the job_runner thread.
17:53:34 HBMASTER: job (0, 0, 3) submitted to dispatcher
17:53:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:53:34 DISPATCHER: Trying to submit another job.
17:53:34 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
17:53:34 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
17:53:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:53:34 WORKER: start processing job (0, 0, 3)
17:53:34 WORKER: args: ()
17:53:34 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.011114870716381309, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.013608413807084996, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 35, 'num_filters_3': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:54:01 DISPATCHER: Starting worker discovery
17:54:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:54:01 DISPATCHER: Finished worker discovery
17:54:59 WORKER: done with job (0, 0, 3), trying to register it.
17:54:59 WORKER: registered result for job (0, 0, 3) with dispatcher
17:54:59 DISPATCHER: job (0, 0, 3) finished
17:54:59 DISPATCHER: register_result: lock acquired
17:54:59 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
17:54:59 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.011114870716381309, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.013608413807084996, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 35, 'num_filters_3': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.22706228251884666, 'info': {'data03': 0.22706228251884666, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.011114870716381309, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.013608413807084996, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 35, 'num_filters_3': 16}"}}
exception: None

17:54:59 job_callback for (0, 0, 3) started
17:54:59 DISPATCHER: Trying to submit another job.
17:54:59 job_callback for (0, 0, 3) got condition
17:54:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:54:59 Only 4 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
17:54:59 HBMASTER: Trying to run another job!
17:54:59 job_callback for (0, 0, 3) finished
17:54:59 start sampling a new configuration.
17:54:59 done sampling a new configuration.
17:54:59 HBMASTER: schedule new run for iteration 0
17:54:59 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
17:54:59 HBMASTER: submitting job (0, 0, 4) to dispatcher
17:54:59 DISPATCHER: trying to submit job (0, 0, 4)
17:54:59 DISPATCHER: trying to notify the job_runner thread.
17:54:59 HBMASTER: job (0, 0, 4) submitted to dispatcher
17:54:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:54:59 DISPATCHER: Trying to submit another job.
17:54:59 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
17:54:59 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
17:54:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:54:59 WORKER: start processing job (0, 0, 4)
17:54:59 WORKER: args: ()
17:54:59 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.00546782466267872, 'num_filters_1': 81, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.0664785803711794}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:55:01 DISPATCHER: Starting worker discovery
17:55:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:55:01 DISPATCHER: Finished worker discovery
17:56:01 DISPATCHER: Starting worker discovery
17:56:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:56:01 DISPATCHER: Finished worker discovery
17:56:29 WORKER: done with job (0, 0, 4), trying to register it.
17:56:29 WORKER: registered result for job (0, 0, 4) with dispatcher
17:56:29 DISPATCHER: job (0, 0, 4) finished
17:56:29 DISPATCHER: register_result: lock acquired
17:56:29 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
17:56:29 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.00546782466267872, 'num_filters_1': 81, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.0664785803711794}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4005917017419232, 'info': {'data03': 0.4005917017419232, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.00546782466267872, 'num_filters_1': 81, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.0664785803711794}"}}
exception: None

17:56:29 job_callback for (0, 0, 4) started
17:56:29 DISPATCHER: Trying to submit another job.
17:56:29 job_callback for (0, 0, 4) got condition
17:56:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:56:29 Only 5 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
17:56:29 HBMASTER: Trying to run another job!
17:56:29 job_callback for (0, 0, 4) finished
17:56:29 start sampling a new configuration.
17:56:29 done sampling a new configuration.
17:56:29 HBMASTER: schedule new run for iteration 0
17:56:29 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
17:56:29 HBMASTER: submitting job (0, 0, 5) to dispatcher
17:56:29 DISPATCHER: trying to submit job (0, 0, 5)
17:56:29 DISPATCHER: trying to notify the job_runner thread.
17:56:29 HBMASTER: job (0, 0, 5) submitted to dispatcher
17:56:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:56:29 DISPATCHER: Trying to submit another job.
17:56:29 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
17:56:29 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
17:56:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:56:29 WORKER: start processing job (0, 0, 5)
17:56:29 WORKER: args: ()
17:56:29 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.009209318573638397, 'num_filters_1': 103, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.012103040993522187}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:57:01 DISPATCHER: Starting worker discovery
17:57:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:57:01 DISPATCHER: Finished worker discovery
17:57:52 WORKER: done with job (0, 0, 5), trying to register it.
17:57:52 WORKER: registered result for job (0, 0, 5) with dispatcher
17:57:52 DISPATCHER: job (0, 0, 5) finished
17:57:52 DISPATCHER: register_result: lock acquired
17:57:52 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
17:57:52 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.009209318573638397, 'num_filters_1': 103, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.012103040993522187}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.33653645796530196, 'info': {'data03': 0.33653645796530196, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.009209318573638397, 'num_filters_1': 103, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.012103040993522187}"}}
exception: None

17:57:52 job_callback for (0, 0, 5) started
17:57:52 job_callback for (0, 0, 5) got condition
17:57:52 DISPATCHER: Trying to submit another job.
17:57:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:57:52 Only 6 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
17:57:52 HBMASTER: Trying to run another job!
17:57:52 job_callback for (0, 0, 5) finished
17:57:52 start sampling a new configuration.
17:57:52 done sampling a new configuration.
17:57:52 HBMASTER: schedule new run for iteration 0
17:57:52 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
17:57:52 HBMASTER: submitting job (0, 0, 6) to dispatcher
17:57:52 DISPATCHER: trying to submit job (0, 0, 6)
17:57:52 DISPATCHER: trying to notify the job_runner thread.
17:57:52 HBMASTER: job (0, 0, 6) submitted to dispatcher
17:57:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:57:52 DISPATCHER: Trying to submit another job.
17:57:52 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776
17:57:52 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
17:57:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:57:52 WORKER: start processing job (0, 0, 6)
17:57:52 WORKER: args: ()
17:57:52 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0293884944362528, 'num_filters_1': 35, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.017098494326423096}, 'budget': 44.44444444444444, 'working_directory': '.'}
17:58:01 DISPATCHER: Starting worker discovery
17:58:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:58:01 DISPATCHER: Finished worker discovery
17:59:01 DISPATCHER: Starting worker discovery
17:59:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:59:01 DISPATCHER: Finished worker discovery
17:59:19 WORKER: done with job (0, 0, 6), trying to register it.
17:59:19 WORKER: registered result for job (0, 0, 6) with dispatcher
17:59:19 DISPATCHER: job (0, 0, 6) finished
17:59:19 DISPATCHER: register_result: lock acquired
17:59:19 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
17:59:19 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0293884944362528, 'num_filters_1': 35, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.017098494326423096}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.26637569835329916, 'info': {'data03': 0.26637569835329916, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0293884944362528, 'num_filters_1': 35, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.017098494326423096}"}}
exception: None

17:59:19 job_callback for (0, 0, 6) started
17:59:19 DISPATCHER: Trying to submit another job.
17:59:19 job_callback for (0, 0, 6) got condition
17:59:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:59:19 Only 7 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
17:59:19 HBMASTER: Trying to run another job!
17:59:19 job_callback for (0, 0, 6) finished
17:59:19 start sampling a new configuration.
17:59:19 done sampling a new configuration.
17:59:19 HBMASTER: schedule new run for iteration 0
17:59:19 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
17:59:19 HBMASTER: submitting job (0, 0, 7) to dispatcher
17:59:19 DISPATCHER: trying to submit job (0, 0, 7)
17:59:19 DISPATCHER: trying to notify the job_runner thread.
17:59:19 HBMASTER: job (0, 0, 7) submitted to dispatcher
17:59:19 DISPATCHER: Trying to submit another job.
17:59:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:59:19 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776
17:59:19 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
17:59:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:59:19 WORKER: start processing job (0, 0, 7)
17:59:19 WORKER: args: ()
17:59:19 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.019920267584761047, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.11417682987367975, 'kernel_size_2': 7, 'num_filters_2': 76}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:00:01 DISPATCHER: Starting worker discovery
18:00:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:00:01 DISPATCHER: Finished worker discovery
18:00:56 WORKER: done with job (0, 0, 7), trying to register it.
18:00:56 WORKER: registered result for job (0, 0, 7) with dispatcher
18:00:56 DISPATCHER: job (0, 0, 7) finished
18:00:56 DISPATCHER: register_result: lock acquired
18:00:56 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:00:56 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.019920267584761047, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.11417682987367975, 'kernel_size_2': 7, 'num_filters_2': 76}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0039426047290717775, 'info': {'data03': 0.0039426047290717775, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.019920267584761047, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.11417682987367975, 'kernel_size_2': 7, 'num_filters_2': 76}"}}
exception: None

18:00:56 job_callback for (0, 0, 7) started
18:00:56 DISPATCHER: Trying to submit another job.
18:00:56 job_callback for (0, 0, 7) got condition
18:00:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:00:56 Only 8 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
18:00:56 HBMASTER: Trying to run another job!
18:00:56 job_callback for (0, 0, 7) finished
18:00:56 start sampling a new configuration.
18:00:56 done sampling a new configuration.
18:00:56 HBMASTER: schedule new run for iteration 0
18:00:56 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
18:00:56 HBMASTER: submitting job (0, 0, 8) to dispatcher
18:00:56 DISPATCHER: trying to submit job (0, 0, 8)
18:00:56 DISPATCHER: trying to notify the job_runner thread.
18:00:56 HBMASTER: job (0, 0, 8) submitted to dispatcher
18:00:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:00:56 DISPATCHER: Trying to submit another job.
18:00:56 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:00:56 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:00:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:00:56 WORKER: start processing job (0, 0, 8)
18:00:56 WORKER: args: ()
18:00:56 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.011329069639315013, 'num_filters_1': 37, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.03702997695239431}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:01:01 DISPATCHER: Starting worker discovery
18:01:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:01:01 DISPATCHER: Finished worker discovery
18:02:01 DISPATCHER: Starting worker discovery
18:02:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:02:01 DISPATCHER: Finished worker discovery
18:02:48 WORKER: done with job (0, 0, 8), trying to register it.
18:02:48 WORKER: registered result for job (0, 0, 8) with dispatcher
18:02:48 DISPATCHER: job (0, 0, 8) finished
18:02:48 DISPATCHER: register_result: lock acquired
18:02:48 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:02:48 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.011329069639315013, 'num_filters_1': 37, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.03702997695239431}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.29411602821586047, 'info': {'data03': 0.29411602821586047, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.011329069639315013, 'num_filters_1': 37, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.03702997695239431}"}}
exception: None

18:02:48 job_callback for (0, 0, 8) started
18:02:48 DISPATCHER: Trying to submit another job.
18:02:48 job_callback for (0, 0, 8) got condition
18:02:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:02:49 Only 9 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
18:02:49 HBMASTER: Trying to run another job!
18:02:49 job_callback for (0, 0, 8) finished
18:02:49 start sampling a new configuration.
18:02:49 done sampling a new configuration.
18:02:49 HBMASTER: schedule new run for iteration 0
18:02:49 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
18:02:49 HBMASTER: submitting job (0, 0, 9) to dispatcher
18:02:49 DISPATCHER: trying to submit job (0, 0, 9)
18:02:49 DISPATCHER: trying to notify the job_runner thread.
18:02:49 HBMASTER: job (0, 0, 9) submitted to dispatcher
18:02:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:02:49 DISPATCHER: Trying to submit another job.
18:02:49 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:02:49 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:02:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:02:49 WORKER: start processing job (0, 0, 9)
18:02:49 WORKER: args: ()
18:02:49 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.006811227044895317, 'num_filters_1': 53, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.04394286579352468, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 48, 'num_filters_3': 22}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:03:01 DISPATCHER: Starting worker discovery
18:03:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:03:01 DISPATCHER: Finished worker discovery
18:04:01 DISPATCHER: Starting worker discovery
18:04:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:04:01 DISPATCHER: Finished worker discovery
18:04:19 WORKER: done with job (0, 0, 9), trying to register it.
18:04:19 WORKER: registered result for job (0, 0, 9) with dispatcher
18:04:19 DISPATCHER: job (0, 0, 9) finished
18:04:19 DISPATCHER: register_result: lock acquired
18:04:19 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:04:19 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.006811227044895317, 'num_filters_1': 53, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.04394286579352468, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 48, 'num_filters_3': 22}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.15045534774395314, 'info': {'data03': 0.15045534774395314, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.006811227044895317, 'num_filters_1': 53, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.04394286579352468, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 48, 'num_filters_3': 22}"}}
exception: None

18:04:19 job_callback for (0, 0, 9) started
18:04:19 job_callback for (0, 0, 9) got condition
18:04:19 DISPATCHER: Trying to submit another job.
18:04:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:04:19 Only 10 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
18:04:19 HBMASTER: Trying to run another job!
18:04:19 job_callback for (0, 0, 9) finished
18:04:19 start sampling a new configuration.
18:04:19 done sampling a new configuration.
18:04:19 HBMASTER: schedule new run for iteration 0
18:04:19 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
18:04:19 HBMASTER: submitting job (0, 0, 10) to dispatcher
18:04:19 DISPATCHER: trying to submit job (0, 0, 10)
18:04:19 DISPATCHER: trying to notify the job_runner thread.
18:04:19 HBMASTER: job (0, 0, 10) submitted to dispatcher
18:04:19 DISPATCHER: Trying to submit another job.
18:04:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:04:19 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:04:19 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:04:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:04:19 WORKER: start processing job (0, 0, 10)
18:04:19 WORKER: args: ()
18:04:19 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.018097005510684487, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.13452499569955198, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 31, 'num_filters_3': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:05:01 DISPATCHER: Starting worker discovery
18:05:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:05:01 DISPATCHER: Finished worker discovery
18:05:47 WORKER: done with job (0, 0, 10), trying to register it.
18:05:47 WORKER: registered result for job (0, 0, 10) with dispatcher
18:05:47 DISPATCHER: job (0, 0, 10) finished
18:05:47 DISPATCHER: register_result: lock acquired
18:05:47 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:05:47 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.018097005510684487, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.13452499569955198, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 31, 'num_filters_3': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3319657117482896, 'info': {'data03': 0.3319657117482896, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.018097005510684487, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.13452499569955198, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 31, 'num_filters_3': 17}"}}
exception: None

18:05:47 job_callback for (0, 0, 10) started
18:05:47 job_callback for (0, 0, 10) got condition
18:05:47 DISPATCHER: Trying to submit another job.
18:05:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:05:47 Only 11 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
18:05:47 HBMASTER: Trying to run another job!
18:05:47 job_callback for (0, 0, 10) finished
18:05:47 start sampling a new configuration.
18:05:47 done sampling a new configuration.
18:05:47 HBMASTER: schedule new run for iteration 0
18:05:47 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
18:05:47 HBMASTER: submitting job (0, 0, 11) to dispatcher
18:05:47 DISPATCHER: trying to submit job (0, 0, 11)
18:05:47 DISPATCHER: trying to notify the job_runner thread.
18:05:47 HBMASTER: job (0, 0, 11) submitted to dispatcher
18:05:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:05:47 DISPATCHER: Trying to submit another job.
18:05:47 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:05:47 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:05:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:05:47 WORKER: start processing job (0, 0, 11)
18:05:47 WORKER: args: ()
18:05:47 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0037175193509066096, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.017053011368687043, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 34, 'num_filters_3': 35, 'num_filters_4': 34, 'num_filters_5': 35}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:06:01 DISPATCHER: Starting worker discovery
18:06:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:06:01 DISPATCHER: Finished worker discovery
18:07:01 DISPATCHER: Starting worker discovery
18:07:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:07:01 DISPATCHER: Finished worker discovery
18:07:14 WORKER: done with job (0, 0, 11), trying to register it.
18:07:14 WORKER: registered result for job (0, 0, 11) with dispatcher
18:07:14 DISPATCHER: job (0, 0, 11) finished
18:07:14 DISPATCHER: register_result: lock acquired
18:07:14 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:07:14 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0037175193509066096, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.017053011368687043, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 34, 'num_filters_3': 35, 'num_filters_4': 34, 'num_filters_5': 35}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.21859783081192247, 'info': {'data03': 0.21859783081192247, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0037175193509066096, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.017053011368687043, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 34, 'num_filters_3': 35, 'num_filters_4': 34, 'num_filters_5': 35}"}}
exception: None

18:07:14 job_callback for (0, 0, 11) started
18:07:14 DISPATCHER: Trying to submit another job.
18:07:14 job_callback for (0, 0, 11) got condition
18:07:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:07:14 Only 12 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
18:07:14 HBMASTER: Trying to run another job!
18:07:14 job_callback for (0, 0, 11) finished
18:07:14 start sampling a new configuration.
18:07:14 done sampling a new configuration.
18:07:14 HBMASTER: schedule new run for iteration 0
18:07:14 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
18:07:14 HBMASTER: submitting job (0, 0, 12) to dispatcher
18:07:14 DISPATCHER: trying to submit job (0, 0, 12)
18:07:14 DISPATCHER: trying to notify the job_runner thread.
18:07:14 HBMASTER: job (0, 0, 12) submitted to dispatcher
18:07:14 DISPATCHER: Trying to submit another job.
18:07:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:07:14 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:07:14 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:07:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:07:14 WORKER: start processing job (0, 0, 12)
18:07:14 WORKER: args: ()
18:07:14 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0924023589737773, 'num_filters_1': 37, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.1437740757915953, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 37, 'num_filters_3': 37, 'num_filters_4': 33, 'num_filters_5': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:08:01 DISPATCHER: Starting worker discovery
18:08:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:08:01 DISPATCHER: Finished worker discovery
18:08:42 WORKER: done with job (0, 0, 12), trying to register it.
18:08:42 WORKER: registered result for job (0, 0, 12) with dispatcher
18:08:42 DISPATCHER: job (0, 0, 12) finished
18:08:42 DISPATCHER: register_result: lock acquired
18:08:42 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:08:42 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0924023589737773, 'num_filters_1': 37, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.1437740757915953, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 37, 'num_filters_3': 37, 'num_filters_4': 33, 'num_filters_5': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0924023589737773, 'num_filters_1': 37, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.1437740757915953, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 37, 'num_filters_3': 37, 'num_filters_4': 33, 'num_filters_5': 23}"}}
exception: None

18:08:42 job_callback for (0, 0, 12) started
18:08:42 DISPATCHER: Trying to submit another job.
18:08:42 job_callback for (0, 0, 12) got condition
18:08:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:08:42 Only 13 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
18:08:42 HBMASTER: Trying to run another job!
18:08:42 job_callback for (0, 0, 12) finished
18:08:42 start sampling a new configuration.
18:08:42 done sampling a new configuration.
18:08:42 HBMASTER: schedule new run for iteration 0
18:08:42 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
18:08:42 HBMASTER: submitting job (0, 0, 13) to dispatcher
18:08:42 DISPATCHER: trying to submit job (0, 0, 13)
18:08:42 DISPATCHER: trying to notify the job_runner thread.
18:08:42 HBMASTER: job (0, 0, 13) submitted to dispatcher
18:08:42 DISPATCHER: Trying to submit another job.
18:08:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:08:42 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:08:42 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:08:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:08:42 WORKER: start processing job (0, 0, 13)
18:08:42 WORKER: args: ()
18:08:42 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.027379023496609714, 'num_filters_1': 99, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.11507531325193905}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:09:01 DISPATCHER: Starting worker discovery
18:09:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:09:01 DISPATCHER: Finished worker discovery
18:10:01 DISPATCHER: Starting worker discovery
18:10:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:10:01 DISPATCHER: Finished worker discovery
18:10:11 WORKER: done with job (0, 0, 13), trying to register it.
18:10:11 WORKER: registered result for job (0, 0, 13) with dispatcher
18:10:11 DISPATCHER: job (0, 0, 13) finished
18:10:11 DISPATCHER: register_result: lock acquired
18:10:11 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:10:11 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.027379023496609714, 'num_filters_1': 99, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.11507531325193905}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.11490077632299603, 'info': {'data03': 0.11490077632299603, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.027379023496609714, 'num_filters_1': 99, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.11507531325193905}"}}
exception: None

18:10:11 job_callback for (0, 0, 13) started
18:10:11 job_callback for (0, 0, 13) got condition
18:10:11 DISPATCHER: Trying to submit another job.
18:10:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:10:11 Only 14 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
18:10:11 HBMASTER: Trying to run another job!
18:10:11 job_callback for (0, 0, 13) finished
18:10:11 start sampling a new configuration.
18:10:11 done sampling a new configuration.
18:10:11 HBMASTER: schedule new run for iteration 0
18:10:11 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
18:10:11 HBMASTER: submitting job (0, 0, 14) to dispatcher
18:10:11 DISPATCHER: trying to submit job (0, 0, 14)
18:10:11 DISPATCHER: trying to notify the job_runner thread.
18:10:11 HBMASTER: job (0, 0, 14) submitted to dispatcher
18:10:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:10:11 DISPATCHER: Trying to submit another job.
18:10:11 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:10:11 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:10:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:10:11 WORKER: start processing job (0, 0, 14)
18:10:11 WORKER: args: ()
18:10:11 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001514331567671718, 'num_filters_1': 110, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.04424820520548099, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 65, 'num_filters_3': 28, 'num_filters_4': 36, 'num_filters_5': 66}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:11:01 DISPATCHER: Starting worker discovery
18:11:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:11:01 DISPATCHER: Finished worker discovery
18:11:40 WORKER: done with job (0, 0, 14), trying to register it.
18:11:40 WORKER: registered result for job (0, 0, 14) with dispatcher
18:11:40 DISPATCHER: job (0, 0, 14) finished
18:11:40 DISPATCHER: register_result: lock acquired
18:11:40 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:11:40 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001514331567671718, 'num_filters_1': 110, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.04424820520548099, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 65, 'num_filters_3': 28, 'num_filters_4': 36, 'num_filters_5': 66}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.358432121938625, 'info': {'data03': 0.358432121938625, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001514331567671718, 'num_filters_1': 110, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.04424820520548099, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 65, 'num_filters_3': 28, 'num_filters_4': 36, 'num_filters_5': 66}"}}
exception: None

18:11:40 job_callback for (0, 0, 14) started
18:11:40 job_callback for (0, 0, 14) got condition
18:11:40 DISPATCHER: Trying to submit another job.
18:11:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:11:40 Only 15 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
18:11:40 HBMASTER: Trying to run another job!
18:11:40 job_callback for (0, 0, 14) finished
18:11:40 start sampling a new configuration.
18:11:40 done sampling a new configuration.
18:11:40 HBMASTER: schedule new run for iteration 0
18:11:40 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
18:11:40 HBMASTER: submitting job (0, 0, 15) to dispatcher
18:11:40 DISPATCHER: trying to submit job (0, 0, 15)
18:11:40 DISPATCHER: trying to notify the job_runner thread.
18:11:40 HBMASTER: job (0, 0, 15) submitted to dispatcher
18:11:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:11:40 DISPATCHER: Trying to submit another job.
18:11:40 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:11:40 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:11:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:11:40 WORKER: start processing job (0, 0, 15)
18:11:40 WORKER: args: ()
18:11:40 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0417106170411527, 'num_filters_1': 48, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.1200504866198332, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 76, 'num_filters_3': 40}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:12:01 DISPATCHER: Starting worker discovery
18:12:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:12:01 DISPATCHER: Finished worker discovery
18:13:01 DISPATCHER: Starting worker discovery
18:13:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:13:01 DISPATCHER: Finished worker discovery
18:13:09 WORKER: done with job (0, 0, 15), trying to register it.
18:13:09 WORKER: registered result for job (0, 0, 15) with dispatcher
18:13:09 DISPATCHER: job (0, 0, 15) finished
18:13:09 DISPATCHER: register_result: lock acquired
18:13:09 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:13:09 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0417106170411527, 'num_filters_1': 48, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.1200504866198332, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 76, 'num_filters_3': 40}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.27549279526161286, 'info': {'data03': 0.27549279526161286, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0417106170411527, 'num_filters_1': 48, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.1200504866198332, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 76, 'num_filters_3': 40}"}}
exception: None

18:13:09 job_callback for (0, 0, 15) started
18:13:09 job_callback for (0, 0, 15) got condition
18:13:09 DISPATCHER: Trying to submit another job.
18:13:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:13:09 Only 16 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
18:13:09 HBMASTER: Trying to run another job!
18:13:09 job_callback for (0, 0, 15) finished
18:13:09 start sampling a new configuration.
18:13:09 done sampling a new configuration.
18:13:09 HBMASTER: schedule new run for iteration 0
18:13:09 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
18:13:09 HBMASTER: submitting job (0, 0, 16) to dispatcher
18:13:09 DISPATCHER: trying to submit job (0, 0, 16)
18:13:09 DISPATCHER: trying to notify the job_runner thread.
18:13:09 HBMASTER: job (0, 0, 16) submitted to dispatcher
18:13:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:13:09 DISPATCHER: Trying to submit another job.
18:13:09 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:13:09 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:13:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:13:09 WORKER: start processing job (0, 0, 16)
18:13:09 WORKER: args: ()
18:13:09 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.03146024169583022, 'num_filters_1': 27, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.01022498801840524, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 66, 'num_filters_3': 20, 'num_filters_4': 41, 'num_filters_5': 40}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:14:01 DISPATCHER: Starting worker discovery
18:14:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:14:01 DISPATCHER: Finished worker discovery
18:14:35 WORKER: done with job (0, 0, 16), trying to register it.
18:14:35 WORKER: registered result for job (0, 0, 16) with dispatcher
18:14:35 DISPATCHER: job (0, 0, 16) finished
18:14:35 DISPATCHER: register_result: lock acquired
18:14:35 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:14:35 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.03146024169583022, 'num_filters_1': 27, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.01022498801840524, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 66, 'num_filters_3': 20, 'num_filters_4': 41, 'num_filters_5': 40}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3318130219424747, 'info': {'data03': 0.3318130219424747, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.03146024169583022, 'num_filters_1': 27, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.01022498801840524, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 66, 'num_filters_3': 20, 'num_filters_4': 41, 'num_filters_5': 40}"}}
exception: None

18:14:35 job_callback for (0, 0, 16) started
18:14:35 DISPATCHER: Trying to submit another job.
18:14:35 job_callback for (0, 0, 16) got condition
18:14:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:14:35 HBMASTER: Trying to run another job!
18:14:35 job_callback for (0, 0, 16) finished
18:14:35 start sampling a new configuration.
18:14:35 done sampling a new configuration.
18:14:35 HBMASTER: schedule new run for iteration 0
18:14:35 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
18:14:35 HBMASTER: submitting job (0, 0, 17) to dispatcher
18:14:35 DISPATCHER: trying to submit job (0, 0, 17)
18:14:35 DISPATCHER: trying to notify the job_runner thread.
18:14:35 HBMASTER: job (0, 0, 17) submitted to dispatcher
18:14:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:14:35 DISPATCHER: Trying to submit another job.
18:14:35 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:14:35 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:14:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:14:35 WORKER: start processing job (0, 0, 17)
18:14:35 WORKER: args: ()
18:14:35 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.01656196383170445, 'num_filters_1': 25, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.02961926385918098}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:15:01 DISPATCHER: Starting worker discovery
18:15:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:15:01 DISPATCHER: Finished worker discovery
18:15:59 WORKER: done with job (0, 0, 17), trying to register it.
18:15:59 WORKER: registered result for job (0, 0, 17) with dispatcher
18:15:59 DISPATCHER: job (0, 0, 17) finished
18:15:59 DISPATCHER: register_result: lock acquired
18:15:59 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:15:59 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.01656196383170445, 'num_filters_1': 25, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.02961926385918098}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3347083882721813, 'info': {'data03': 0.3347083882721813, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.01656196383170445, 'num_filters_1': 25, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.02961926385918098}"}}
exception: None

18:15:59 job_callback for (0, 0, 17) started
18:15:59 job_callback for (0, 0, 17) got condition
18:15:59 DISPATCHER: Trying to submit another job.
18:15:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:15:59 HBMASTER: Trying to run another job!
18:15:59 job_callback for (0, 0, 17) finished
18:15:59 start sampling a new configuration.
18:15:59 done sampling a new configuration.
18:15:59 HBMASTER: schedule new run for iteration 0
18:15:59 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
18:15:59 HBMASTER: submitting job (0, 0, 18) to dispatcher
18:15:59 DISPATCHER: trying to submit job (0, 0, 18)
18:15:59 DISPATCHER: trying to notify the job_runner thread.
18:15:59 HBMASTER: job (0, 0, 18) submitted to dispatcher
18:15:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:15:59 DISPATCHER: Trying to submit another job.
18:15:59 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:15:59 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:15:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:15:59 WORKER: start processing job (0, 0, 18)
18:15:59 WORKER: args: ()
18:15:59 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.05236856156627573, 'num_filters_1': 96, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.014502986585801916, 'kernel_size_2': 7, 'num_filters_2': 74}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:16:01 DISPATCHER: Starting worker discovery
18:16:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:16:01 DISPATCHER: Finished worker discovery
18:17:01 DISPATCHER: Starting worker discovery
18:17:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:17:01 DISPATCHER: Finished worker discovery
18:17:24 WORKER: done with job (0, 0, 18), trying to register it.
18:17:24 WORKER: registered result for job (0, 0, 18) with dispatcher
18:17:24 DISPATCHER: job (0, 0, 18) finished
18:17:24 DISPATCHER: register_result: lock acquired
18:17:24 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:17:24 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.05236856156627573, 'num_filters_1': 96, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.014502986585801916, 'kernel_size_2': 7, 'num_filters_2': 74}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3046916079254979, 'info': {'data03': 0.3046916079254979, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.05236856156627573, 'num_filters_1': 96, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.014502986585801916, 'kernel_size_2': 7, 'num_filters_2': 74}"}}
exception: None

18:17:24 job_callback for (0, 0, 18) started
18:17:24 DISPATCHER: Trying to submit another job.
18:17:24 job_callback for (0, 0, 18) got condition
18:17:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:17:24 HBMASTER: Trying to run another job!
18:17:24 job_callback for (0, 0, 18) finished
18:17:24 start sampling a new configuration.
18:17:24 done sampling a new configuration.
18:17:24 HBMASTER: schedule new run for iteration 0
18:17:24 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
18:17:24 HBMASTER: submitting job (0, 0, 19) to dispatcher
18:17:24 DISPATCHER: trying to submit job (0, 0, 19)
18:17:24 DISPATCHER: trying to notify the job_runner thread.
18:17:24 HBMASTER: job (0, 0, 19) submitted to dispatcher
18:17:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:17:24 DISPATCHER: Trying to submit another job.
18:17:24 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:17:24 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:17:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:17:24 WORKER: start processing job (0, 0, 19)
18:17:24 WORKER: args: ()
18:17:24 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.02506782827214542, 'num_filters_1': 56, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.18197136748248285, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 81, 'num_filters_3': 69}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:18:01 DISPATCHER: Starting worker discovery
18:18:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:18:01 DISPATCHER: Finished worker discovery
18:18:54 WORKER: done with job (0, 0, 19), trying to register it.
18:18:54 WORKER: registered result for job (0, 0, 19) with dispatcher
18:18:54 DISPATCHER: job (0, 0, 19) finished
18:18:54 DISPATCHER: register_result: lock acquired
18:18:54 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:18:54 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.02506782827214542, 'num_filters_1': 56, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.18197136748248285, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 81, 'num_filters_3': 69}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.02506782827214542, 'num_filters_1': 56, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.18197136748248285, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 81, 'num_filters_3': 69}"}}
exception: None

18:18:54 job_callback for (0, 0, 19) started
18:18:54 DISPATCHER: Trying to submit another job.
18:18:54 job_callback for (0, 0, 19) got condition
18:18:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:18:54 HBMASTER: Trying to run another job!
18:18:54 job_callback for (0, 0, 19) finished
18:18:54 start sampling a new configuration.
18:18:54 done sampling a new configuration.
18:18:54 HBMASTER: schedule new run for iteration 0
18:18:54 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
18:18:54 HBMASTER: submitting job (0, 0, 20) to dispatcher
18:18:54 DISPATCHER: trying to submit job (0, 0, 20)
18:18:54 DISPATCHER: trying to notify the job_runner thread.
18:18:54 HBMASTER: job (0, 0, 20) submitted to dispatcher
18:18:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:18:54 DISPATCHER: Trying to submit another job.
18:18:54 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:18:54 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:18:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:18:54 WORKER: start processing job (0, 0, 20)
18:18:54 WORKER: args: ()
18:18:54 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0051399083476422035, 'num_filters_1': 27, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.029330416226218146}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:19:01 DISPATCHER: Starting worker discovery
18:19:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:19:01 DISPATCHER: Finished worker discovery
18:20:01 DISPATCHER: Starting worker discovery
18:20:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:20:01 DISPATCHER: Finished worker discovery
18:20:21 WORKER: done with job (0, 0, 20), trying to register it.
18:20:21 WORKER: registered result for job (0, 0, 20) with dispatcher
18:20:21 DISPATCHER: job (0, 0, 20) finished
18:20:21 DISPATCHER: register_result: lock acquired
18:20:21 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:20:21 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0051399083476422035, 'num_filters_1': 27, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.029330416226218146}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4602608999306766, 'info': {'data03': 0.4602608999306766, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0051399083476422035, 'num_filters_1': 27, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.029330416226218146}"}}
exception: None

18:20:21 job_callback for (0, 0, 20) started
18:20:21 DISPATCHER: Trying to submit another job.
18:20:21 job_callback for (0, 0, 20) got condition
18:20:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:20:21 HBMASTER: Trying to run another job!
18:20:21 job_callback for (0, 0, 20) finished
18:20:21 start sampling a new configuration.
18:20:21 done sampling a new configuration.
18:20:21 HBMASTER: schedule new run for iteration 0
18:20:21 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
18:20:21 HBMASTER: submitting job (0, 0, 21) to dispatcher
18:20:21 DISPATCHER: trying to submit job (0, 0, 21)
18:20:21 DISPATCHER: trying to notify the job_runner thread.
18:20:21 HBMASTER: job (0, 0, 21) submitted to dispatcher
18:20:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:20:21 DISPATCHER: Trying to submit another job.
18:20:21 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:20:21 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:20:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:20:21 WORKER: start processing job (0, 0, 21)
18:20:21 WORKER: args: ()
18:20:21 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.00577609575345829, 'num_filters_1': 106, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.06676812693989026, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 115, 'num_filters_3': 85}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:21:01 DISPATCHER: Starting worker discovery
18:21:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:21:01 DISPATCHER: Finished worker discovery
18:21:50 WORKER: done with job (0, 0, 21), trying to register it.
18:21:50 WORKER: registered result for job (0, 0, 21) with dispatcher
18:21:50 DISPATCHER: job (0, 0, 21) finished
18:21:50 DISPATCHER: register_result: lock acquired
18:21:50 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:21:50 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.00577609575345829, 'num_filters_1': 106, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.06676812693989026, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 115, 'num_filters_3': 85}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.25921253238724484, 'info': {'data03': 0.25921253238724484, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.00577609575345829, 'num_filters_1': 106, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.06676812693989026, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 115, 'num_filters_3': 85}"}}
exception: None

18:21:50 job_callback for (0, 0, 21) started
18:21:50 job_callback for (0, 0, 21) got condition
18:21:50 DISPATCHER: Trying to submit another job.
18:21:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:21:50 HBMASTER: Trying to run another job!
18:21:50 job_callback for (0, 0, 21) finished
18:21:50 start sampling a new configuration.
18:21:50 done sampling a new configuration.
18:21:50 HBMASTER: schedule new run for iteration 0
18:21:50 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
18:21:50 HBMASTER: submitting job (0, 0, 22) to dispatcher
18:21:50 DISPATCHER: trying to submit job (0, 0, 22)
18:21:50 DISPATCHER: trying to notify the job_runner thread.
18:21:50 HBMASTER: job (0, 0, 22) submitted to dispatcher
18:21:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:21:50 DISPATCHER: Trying to submit another job.
18:21:50 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:21:50 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:21:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:21:50 WORKER: start processing job (0, 0, 22)
18:21:50 WORKER: args: ()
18:21:50 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0016014779453128473, 'num_filters_1': 86, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.055002462090170665, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 21, 'num_filters_3': 123, 'num_filters_4': 124, 'num_filters_5': 62}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:22:01 DISPATCHER: Starting worker discovery
18:22:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:22:01 DISPATCHER: Finished worker discovery
18:23:01 DISPATCHER: Starting worker discovery
18:23:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:23:01 DISPATCHER: Finished worker discovery
18:23:17 WORKER: done with job (0, 0, 22), trying to register it.
18:23:17 WORKER: registered result for job (0, 0, 22) with dispatcher
18:23:17 DISPATCHER: job (0, 0, 22) finished
18:23:17 DISPATCHER: register_result: lock acquired
18:23:17 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:23:17 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0016014779453128473, 'num_filters_1': 86, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.055002462090170665, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 21, 'num_filters_3': 123, 'num_filters_4': 124, 'num_filters_5': 62}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.33857021876851184, 'info': {'data03': 0.33857021876851184, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0016014779453128473, 'num_filters_1': 86, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.055002462090170665, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 21, 'num_filters_3': 123, 'num_filters_4': 124, 'num_filters_5': 62}"}}
exception: None

18:23:17 job_callback for (0, 0, 22) started
18:23:17 job_callback for (0, 0, 22) got condition
18:23:17 DISPATCHER: Trying to submit another job.
18:23:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:23:17 HBMASTER: Trying to run another job!
18:23:17 job_callback for (0, 0, 22) finished
18:23:17 start sampling a new configuration.
18:23:17 done sampling a new configuration.
18:23:17 HBMASTER: schedule new run for iteration 0
18:23:17 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
18:23:17 HBMASTER: submitting job (0, 0, 23) to dispatcher
18:23:17 DISPATCHER: trying to submit job (0, 0, 23)
18:23:17 DISPATCHER: trying to notify the job_runner thread.
18:23:17 HBMASTER: job (0, 0, 23) submitted to dispatcher
18:23:17 DISPATCHER: Trying to submit another job.
18:23:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:23:17 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:23:17 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:23:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:23:17 WORKER: start processing job (0, 0, 23)
18:23:17 WORKER: args: ()
18:23:17 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.002371723474103776, 'num_filters_1': 76, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.11512098007128348, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 114, 'num_filters_3': 17, 'num_filters_4': 42}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:24:01 DISPATCHER: Starting worker discovery
18:24:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:24:01 DISPATCHER: Finished worker discovery
18:24:45 WORKER: done with job (0, 0, 23), trying to register it.
18:24:45 WORKER: registered result for job (0, 0, 23) with dispatcher
18:24:45 DISPATCHER: job (0, 0, 23) finished
18:24:45 DISPATCHER: register_result: lock acquired
18:24:45 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:24:45 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.002371723474103776, 'num_filters_1': 76, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.11512098007128348, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 114, 'num_filters_3': 17, 'num_filters_4': 42}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.30601606129796816, 'info': {'data03': 0.30601606129796816, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.002371723474103776, 'num_filters_1': 76, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.11512098007128348, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 114, 'num_filters_3': 17, 'num_filters_4': 42}"}}
exception: None

18:24:45 job_callback for (0, 0, 23) started
18:24:45 DISPATCHER: Trying to submit another job.
18:24:45 job_callback for (0, 0, 23) got condition
18:24:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:24:45 HBMASTER: Trying to run another job!
18:24:45 job_callback for (0, 0, 23) finished
18:24:45 start sampling a new configuration.
18:24:45 done sampling a new configuration.
18:24:45 HBMASTER: schedule new run for iteration 0
18:24:45 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
18:24:45 HBMASTER: submitting job (0, 0, 24) to dispatcher
18:24:45 DISPATCHER: trying to submit job (0, 0, 24)
18:24:45 DISPATCHER: trying to notify the job_runner thread.
18:24:45 HBMASTER: job (0, 0, 24) submitted to dispatcher
18:24:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:24:45 DISPATCHER: Trying to submit another job.
18:24:45 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:24:45 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:24:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:24:45 WORKER: start processing job (0, 0, 24)
18:24:45 WORKER: args: ()
18:24:45 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.022280705695435277, 'num_filters_1': 70, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.049194212042685426, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 80, 'num_filters_3': 32}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:25:01 DISPATCHER: Starting worker discovery
18:25:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:25:01 DISPATCHER: Finished worker discovery
18:26:01 DISPATCHER: Starting worker discovery
18:26:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:26:01 DISPATCHER: Finished worker discovery
18:26:20 WORKER: done with job (0, 0, 24), trying to register it.
18:26:20 WORKER: registered result for job (0, 0, 24) with dispatcher
18:26:20 DISPATCHER: job (0, 0, 24) finished
18:26:20 DISPATCHER: register_result: lock acquired
18:26:20 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:26:20 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.022280705695435277, 'num_filters_1': 70, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.049194212042685426, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 80, 'num_filters_3': 32}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.32958016713297733, 'info': {'data03': 0.32958016713297733, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.022280705695435277, 'num_filters_1': 70, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.049194212042685426, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 80, 'num_filters_3': 32}"}}
exception: None

18:26:20 job_callback for (0, 0, 24) started
18:26:20 job_callback for (0, 0, 24) got condition
18:26:20 DISPATCHER: Trying to submit another job.
18:26:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:26:20 HBMASTER: Trying to run another job!
18:26:20 job_callback for (0, 0, 24) finished
18:26:20 start sampling a new configuration.
18:26:20 done sampling a new configuration.
18:26:20 HBMASTER: schedule new run for iteration 0
18:26:20 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
18:26:20 HBMASTER: submitting job (0, 0, 25) to dispatcher
18:26:20 DISPATCHER: trying to submit job (0, 0, 25)
18:26:20 DISPATCHER: trying to notify the job_runner thread.
18:26:20 HBMASTER: job (0, 0, 25) submitted to dispatcher
18:26:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:26:20 DISPATCHER: Trying to submit another job.
18:26:20 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:26:20 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:26:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:26:20 WORKER: start processing job (0, 0, 25)
18:26:20 WORKER: args: ()
18:26:20 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.005360858243121112, 'num_filters_1': 29, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.17780093322527163, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 121, 'num_filters_3': 16, 'num_filters_4': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:27:01 DISPATCHER: Starting worker discovery
18:27:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:27:01 DISPATCHER: Finished worker discovery
18:27:48 WORKER: done with job (0, 0, 25), trying to register it.
18:27:48 WORKER: registered result for job (0, 0, 25) with dispatcher
18:27:48 DISPATCHER: job (0, 0, 25) finished
18:27:48 DISPATCHER: register_result: lock acquired
18:27:48 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:27:48 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.005360858243121112, 'num_filters_1': 29, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.17780093322527163, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 121, 'num_filters_3': 16, 'num_filters_4': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.006856844012105932, 'info': {'data03': 0.006856844012105932, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.005360858243121112, 'num_filters_1': 29, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.17780093322527163, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 121, 'num_filters_3': 16, 'num_filters_4': 21}"}}
exception: None

18:27:48 job_callback for (0, 0, 25) started
18:27:48 DISPATCHER: Trying to submit another job.
18:27:48 job_callback for (0, 0, 25) got condition
18:27:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:27:48 HBMASTER: Trying to run another job!
18:27:48 job_callback for (0, 0, 25) finished
18:27:48 start sampling a new configuration.
18:27:48 done sampling a new configuration.
18:27:48 HBMASTER: schedule new run for iteration 0
18:27:48 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
18:27:48 HBMASTER: submitting job (0, 0, 26) to dispatcher
18:27:48 DISPATCHER: trying to submit job (0, 0, 26)
18:27:48 DISPATCHER: trying to notify the job_runner thread.
18:27:48 HBMASTER: job (0, 0, 26) submitted to dispatcher
18:27:48 DISPATCHER: Trying to submit another job.
18:27:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:27:48 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:27:48 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:27:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:27:48 WORKER: start processing job (0, 0, 26)
18:27:48 WORKER: args: ()
18:27:48 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0027778986702694476, 'num_filters_1': 83, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.013791944079086018, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 66, 'num_filters_3': 76, 'num_filters_4': 25, 'num_filters_5': 52}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:28:01 DISPATCHER: Starting worker discovery
18:28:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:28:01 DISPATCHER: Finished worker discovery
18:29:01 DISPATCHER: Starting worker discovery
18:29:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:29:01 DISPATCHER: Finished worker discovery
18:29:20 WORKER: done with job (0, 0, 26), trying to register it.
18:29:20 WORKER: registered result for job (0, 0, 26) with dispatcher
18:29:20 DISPATCHER: job (0, 0, 26) finished
18:29:20 DISPATCHER: register_result: lock acquired
18:29:20 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:29:20 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0027778986702694476, 'num_filters_1': 83, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.013791944079086018, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 66, 'num_filters_3': 76, 'num_filters_4': 25, 'num_filters_5': 52}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3355488223203485, 'info': {'data03': 0.3355488223203485, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0027778986702694476, 'num_filters_1': 83, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.013791944079086018, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 66, 'num_filters_3': 76, 'num_filters_4': 25, 'num_filters_5': 52}"}}
exception: None

18:29:20 job_callback for (0, 0, 26) started
18:29:20 DISPATCHER: Trying to submit another job.
18:29:20 job_callback for (0, 0, 26) got condition
18:29:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:29:20 HBMASTER: Trying to run another job!
18:29:20 job_callback for (0, 0, 26) finished
18:29:20 ITERATION: Advancing config (0, 0, 2) to next budget 133.333333
18:29:20 ITERATION: Advancing config (0, 0, 4) to next budget 133.333333
18:29:20 ITERATION: Advancing config (0, 0, 5) to next budget 133.333333
18:29:20 ITERATION: Advancing config (0, 0, 10) to next budget 133.333333
18:29:20 ITERATION: Advancing config (0, 0, 14) to next budget 133.333333
18:29:20 ITERATION: Advancing config (0, 0, 17) to next budget 133.333333
18:29:20 ITERATION: Advancing config (0, 0, 20) to next budget 133.333333
18:29:20 ITERATION: Advancing config (0, 0, 22) to next budget 133.333333
18:29:20 ITERATION: Advancing config (0, 0, 26) to next budget 133.333333
18:29:20 HBMASTER: schedule new run for iteration 0
18:29:20 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
18:29:20 HBMASTER: submitting job (0, 0, 2) to dispatcher
18:29:20 DISPATCHER: trying to submit job (0, 0, 2)
18:29:20 DISPATCHER: trying to notify the job_runner thread.
18:29:20 HBMASTER: job (0, 0, 2) submitted to dispatcher
18:29:20 DISPATCHER: Trying to submit another job.
18:29:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:29:20 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:29:20 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:29:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:29:20 WORKER: start processing job (0, 0, 2)
18:29:20 WORKER: args: ()
18:29:20 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00645974879509834, 'num_filters_1': 87, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.012859992184415444, 'kernel_size_2': 5, 'num_filters_2': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:30:01 DISPATCHER: Starting worker discovery
18:30:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:30:01 DISPATCHER: Finished worker discovery
18:31:01 DISPATCHER: Starting worker discovery
18:31:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:31:01 DISPATCHER: Finished worker discovery
18:32:01 DISPATCHER: Starting worker discovery
18:32:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:32:01 DISPATCHER: Finished worker discovery
18:32:14 WORKER: done with job (0, 0, 2), trying to register it.
18:32:14 WORKER: registered result for job (0, 0, 2) with dispatcher
18:32:14 DISPATCHER: job (0, 0, 2) finished
18:32:14 DISPATCHER: register_result: lock acquired
18:32:14 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:32:14 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00645974879509834, 'num_filters_1': 87, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.012859992184415444, 'kernel_size_2': 5, 'num_filters_2': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.37202411786236594, 'info': {'data03': 0.37202411786236594, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00645974879509834, 'num_filters_1': 87, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.012859992184415444, 'kernel_size_2': 5, 'num_filters_2': 43}"}}
exception: None

18:32:14 job_callback for (0, 0, 2) started
18:32:14 DISPATCHER: Trying to submit another job.
18:32:14 job_callback for (0, 0, 2) got condition
18:32:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:32:14 Only 1 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
18:32:14 HBMASTER: Trying to run another job!
18:32:14 job_callback for (0, 0, 2) finished
18:32:14 HBMASTER: schedule new run for iteration 0
18:32:14 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
18:32:14 HBMASTER: submitting job (0, 0, 4) to dispatcher
18:32:14 DISPATCHER: trying to submit job (0, 0, 4)
18:32:14 DISPATCHER: trying to notify the job_runner thread.
18:32:14 HBMASTER: job (0, 0, 4) submitted to dispatcher
18:32:14 DISPATCHER: Trying to submit another job.
18:32:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:32:14 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:32:14 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:32:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:32:14 WORKER: start processing job (0, 0, 4)
18:32:14 WORKER: args: ()
18:32:14 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.00546782466267872, 'num_filters_1': 81, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.0664785803711794}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:33:01 DISPATCHER: Starting worker discovery
18:33:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:33:01 DISPATCHER: Finished worker discovery
18:34:01 DISPATCHER: Starting worker discovery
18:34:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:34:01 DISPATCHER: Finished worker discovery
18:35:01 DISPATCHER: Starting worker discovery
18:35:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:35:01 DISPATCHER: Finished worker discovery
18:35:12 WORKER: done with job (0, 0, 4), trying to register it.
18:35:12 WORKER: registered result for job (0, 0, 4) with dispatcher
18:35:12 DISPATCHER: job (0, 0, 4) finished
18:35:12 DISPATCHER: register_result: lock acquired
18:35:12 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:35:12 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.00546782466267872, 'num_filters_1': 81, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.0664785803711794}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3642086939623884, 'info': {'data03': 0.3642086939623884, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.00546782466267872, 'num_filters_1': 81, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.0664785803711794}"}}
exception: None

18:35:12 job_callback for (0, 0, 4) started
18:35:12 DISPATCHER: Trying to submit another job.
18:35:12 job_callback for (0, 0, 4) got condition
18:35:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:35:12 Only 2 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
18:35:12 HBMASTER: Trying to run another job!
18:35:12 job_callback for (0, 0, 4) finished
18:35:12 HBMASTER: schedule new run for iteration 0
18:35:12 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
18:35:12 HBMASTER: submitting job (0, 0, 5) to dispatcher
18:35:12 DISPATCHER: trying to submit job (0, 0, 5)
18:35:12 DISPATCHER: trying to notify the job_runner thread.
18:35:12 HBMASTER: job (0, 0, 5) submitted to dispatcher
18:35:12 DISPATCHER: Trying to submit another job.
18:35:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:35:12 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:35:12 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:35:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:35:12 WORKER: start processing job (0, 0, 5)
18:35:12 WORKER: args: ()
18:35:12 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.009209318573638397, 'num_filters_1': 103, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.012103040993522187}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:36:01 DISPATCHER: Starting worker discovery
18:36:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:36:01 DISPATCHER: Finished worker discovery
18:37:01 DISPATCHER: Starting worker discovery
18:37:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:37:01 DISPATCHER: Finished worker discovery
18:38:01 DISPATCHER: Starting worker discovery
18:38:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:38:01 DISPATCHER: Finished worker discovery
18:38:11 WORKER: done with job (0, 0, 5), trying to register it.
18:38:11 WORKER: registered result for job (0, 0, 5) with dispatcher
18:38:11 DISPATCHER: job (0, 0, 5) finished
18:38:11 DISPATCHER: register_result: lock acquired
18:38:11 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:38:11 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.009209318573638397, 'num_filters_1': 103, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.012103040993522187}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.29062861050339717, 'info': {'data03': 0.29062861050339717, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.009209318573638397, 'num_filters_1': 103, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.012103040993522187}"}}
exception: None

18:38:11 job_callback for (0, 0, 5) started
18:38:11 DISPATCHER: Trying to submit another job.
18:38:11 job_callback for (0, 0, 5) got condition
18:38:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:38:11 Only 3 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
18:38:11 HBMASTER: Trying to run another job!
18:38:11 job_callback for (0, 0, 5) finished
18:38:11 HBMASTER: schedule new run for iteration 0
18:38:11 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
18:38:11 HBMASTER: submitting job (0, 0, 10) to dispatcher
18:38:11 DISPATCHER: trying to submit job (0, 0, 10)
18:38:11 DISPATCHER: trying to notify the job_runner thread.
18:38:11 HBMASTER: job (0, 0, 10) submitted to dispatcher
18:38:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:38:11 DISPATCHER: Trying to submit another job.
18:38:11 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:38:11 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:38:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:38:11 WORKER: start processing job (0, 0, 10)
18:38:11 WORKER: args: ()
18:38:11 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.018097005510684487, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.13452499569955198, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 31, 'num_filters_3': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:39:01 DISPATCHER: Starting worker discovery
18:39:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:39:01 DISPATCHER: Finished worker discovery
18:40:01 DISPATCHER: Starting worker discovery
18:40:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:40:01 DISPATCHER: Finished worker discovery
18:41:01 DISPATCHER: Starting worker discovery
18:41:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:41:01 DISPATCHER: Finished worker discovery
18:41:10 WORKER: done with job (0, 0, 10), trying to register it.
18:41:10 WORKER: registered result for job (0, 0, 10) with dispatcher
18:41:10 DISPATCHER: job (0, 0, 10) finished
18:41:10 DISPATCHER: register_result: lock acquired
18:41:10 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:41:10 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.018097005510684487, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.13452499569955198, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 31, 'num_filters_3': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.31792756992906973, 'info': {'data03': 0.31792756992906973, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.018097005510684487, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.13452499569955198, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 31, 'num_filters_3': 17}"}}
exception: None

18:41:10 job_callback for (0, 0, 10) started
18:41:10 job_callback for (0, 0, 10) got condition
18:41:10 DISPATCHER: Trying to submit another job.
18:41:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:41:10 Only 4 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
18:41:10 HBMASTER: Trying to run another job!
18:41:10 job_callback for (0, 0, 10) finished
18:41:10 HBMASTER: schedule new run for iteration 0
18:41:10 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
18:41:10 HBMASTER: submitting job (0, 0, 14) to dispatcher
18:41:10 DISPATCHER: trying to submit job (0, 0, 14)
18:41:10 DISPATCHER: trying to notify the job_runner thread.
18:41:10 HBMASTER: job (0, 0, 14) submitted to dispatcher
18:41:10 DISPATCHER: Trying to submit another job.
18:41:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:41:10 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:41:10 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:41:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:41:10 WORKER: start processing job (0, 0, 14)
18:41:10 WORKER: args: ()
18:41:10 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001514331567671718, 'num_filters_1': 110, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.04424820520548099, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 65, 'num_filters_3': 28, 'num_filters_4': 36, 'num_filters_5': 66}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:42:01 DISPATCHER: Starting worker discovery
18:42:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:42:01 DISPATCHER: Finished worker discovery
18:43:01 DISPATCHER: Starting worker discovery
18:43:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:43:01 DISPATCHER: Finished worker discovery
18:44:01 DISPATCHER: Starting worker discovery
18:44:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:44:01 DISPATCHER: Finished worker discovery
18:44:09 WORKER: done with job (0, 0, 14), trying to register it.
18:44:09 WORKER: registered result for job (0, 0, 14) with dispatcher
18:44:09 DISPATCHER: job (0, 0, 14) finished
18:44:09 DISPATCHER: register_result: lock acquired
18:44:09 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:44:09 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001514331567671718, 'num_filters_1': 110, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.04424820520548099, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 65, 'num_filters_3': 28, 'num_filters_4': 36, 'num_filters_5': 66}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.19536782895376434, 'info': {'data03': 0.19536782895376434, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001514331567671718, 'num_filters_1': 110, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.04424820520548099, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 65, 'num_filters_3': 28, 'num_filters_4': 36, 'num_filters_5': 66}"}}
exception: None

18:44:09 job_callback for (0, 0, 14) started
18:44:09 job_callback for (0, 0, 14) got condition
18:44:09 DISPATCHER: Trying to submit another job.
18:44:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:44:09 Only 5 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
18:44:09 HBMASTER: Trying to run another job!
18:44:09 job_callback for (0, 0, 14) finished
18:44:09 HBMASTER: schedule new run for iteration 0
18:44:09 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
18:44:09 HBMASTER: submitting job (0, 0, 17) to dispatcher
18:44:09 DISPATCHER: trying to submit job (0, 0, 17)
18:44:09 DISPATCHER: trying to notify the job_runner thread.
18:44:09 HBMASTER: job (0, 0, 17) submitted to dispatcher
18:44:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:44:09 DISPATCHER: Trying to submit another job.
18:44:09 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:44:09 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:44:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:44:09 WORKER: start processing job (0, 0, 17)
18:44:09 WORKER: args: ()
18:44:09 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.01656196383170445, 'num_filters_1': 25, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.02961926385918098}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:45:01 DISPATCHER: Starting worker discovery
18:45:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:45:01 DISPATCHER: Finished worker discovery
18:46:01 DISPATCHER: Starting worker discovery
18:46:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:46:01 DISPATCHER: Finished worker discovery
18:47:01 DISPATCHER: Starting worker discovery
18:47:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:47:01 DISPATCHER: Finished worker discovery
18:47:04 WORKER: done with job (0, 0, 17), trying to register it.
18:47:04 WORKER: registered result for job (0, 0, 17) with dispatcher
18:47:04 DISPATCHER: job (0, 0, 17) finished
18:47:04 DISPATCHER: register_result: lock acquired
18:47:04 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:47:04 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.01656196383170445, 'num_filters_1': 25, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.02961926385918098}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3296665720672701, 'info': {'data03': 0.3296665720672701, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.01656196383170445, 'num_filters_1': 25, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.02961926385918098}"}}
exception: None

18:47:04 job_callback for (0, 0, 17) started
18:47:04 job_callback for (0, 0, 17) got condition
18:47:04 DISPATCHER: Trying to submit another job.
18:47:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:47:04 Only 6 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
18:47:04 HBMASTER: Trying to run another job!
18:47:04 job_callback for (0, 0, 17) finished
18:47:04 HBMASTER: schedule new run for iteration 0
18:47:04 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
18:47:04 HBMASTER: submitting job (0, 0, 20) to dispatcher
18:47:04 DISPATCHER: trying to submit job (0, 0, 20)
18:47:04 DISPATCHER: trying to notify the job_runner thread.
18:47:04 HBMASTER: job (0, 0, 20) submitted to dispatcher
18:47:04 DISPATCHER: Trying to submit another job.
18:47:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:47:04 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:47:04 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:47:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:47:04 WORKER: start processing job (0, 0, 20)
18:47:04 WORKER: args: ()
18:47:04 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0051399083476422035, 'num_filters_1': 27, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.029330416226218146}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:48:01 DISPATCHER: Starting worker discovery
18:48:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:48:01 DISPATCHER: Finished worker discovery
18:49:01 DISPATCHER: Starting worker discovery
18:49:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:49:01 DISPATCHER: Finished worker discovery
18:50:00 WORKER: done with job (0, 0, 20), trying to register it.
18:50:00 WORKER: registered result for job (0, 0, 20) with dispatcher
18:50:00 DISPATCHER: job (0, 0, 20) finished
18:50:00 DISPATCHER: register_result: lock acquired
18:50:00 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:50:00 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0051399083476422035, 'num_filters_1': 27, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.029330416226218146}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4125695679916612, 'info': {'data03': 0.4125695679916612, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0051399083476422035, 'num_filters_1': 27, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.029330416226218146}"}}
exception: None

18:50:00 job_callback for (0, 0, 20) started
18:50:00 DISPATCHER: Trying to submit another job.
18:50:00 job_callback for (0, 0, 20) got condition
18:50:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:50:00 Only 7 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
18:50:00 HBMASTER: Trying to run another job!
18:50:00 job_callback for (0, 0, 20) finished
18:50:00 HBMASTER: schedule new run for iteration 0
18:50:00 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
18:50:00 HBMASTER: submitting job (0, 0, 22) to dispatcher
18:50:00 DISPATCHER: trying to submit job (0, 0, 22)
18:50:00 DISPATCHER: trying to notify the job_runner thread.
18:50:00 HBMASTER: job (0, 0, 22) submitted to dispatcher
18:50:00 DISPATCHER: Trying to submit another job.
18:50:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:50:00 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:50:00 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:50:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:50:00 WORKER: start processing job (0, 0, 22)
18:50:00 WORKER: args: ()
18:50:00 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0016014779453128473, 'num_filters_1': 86, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.055002462090170665, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 21, 'num_filters_3': 123, 'num_filters_4': 124, 'num_filters_5': 62}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:50:01 DISPATCHER: Starting worker discovery
18:50:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:50:01 DISPATCHER: Finished worker discovery
18:51:01 DISPATCHER: Starting worker discovery
18:51:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:51:01 DISPATCHER: Finished worker discovery
18:52:01 DISPATCHER: Starting worker discovery
18:52:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:52:01 DISPATCHER: Finished worker discovery
18:52:58 WORKER: done with job (0, 0, 22), trying to register it.
18:52:58 WORKER: registered result for job (0, 0, 22) with dispatcher
18:52:58 DISPATCHER: job (0, 0, 22) finished
18:52:58 DISPATCHER: register_result: lock acquired
18:52:58 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:52:58 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0016014779453128473, 'num_filters_1': 86, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.055002462090170665, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 21, 'num_filters_3': 123, 'num_filters_4': 124, 'num_filters_5': 62}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.15756721431357826, 'info': {'data03': 0.15756721431357826, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0016014779453128473, 'num_filters_1': 86, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.055002462090170665, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 21, 'num_filters_3': 123, 'num_filters_4': 124, 'num_filters_5': 62}"}}
exception: None

18:52:58 job_callback for (0, 0, 22) started
18:52:58 job_callback for (0, 0, 22) got condition
18:52:58 DISPATCHER: Trying to submit another job.
18:52:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:52:58 Only 8 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
18:52:58 HBMASTER: Trying to run another job!
18:52:58 job_callback for (0, 0, 22) finished
18:52:58 HBMASTER: schedule new run for iteration 0
18:52:58 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
18:52:58 HBMASTER: submitting job (0, 0, 26) to dispatcher
18:52:58 DISPATCHER: trying to submit job (0, 0, 26)
18:52:58 DISPATCHER: trying to notify the job_runner thread.
18:52:58 HBMASTER: job (0, 0, 26) submitted to dispatcher
18:52:58 DISPATCHER: Trying to submit another job.
18:52:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:52:58 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:52:58 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:52:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:52:58 WORKER: start processing job (0, 0, 26)
18:52:58 WORKER: args: ()
18:52:58 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0027778986702694476, 'num_filters_1': 83, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.013791944079086018, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 66, 'num_filters_3': 76, 'num_filters_4': 25, 'num_filters_5': 52}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:53:01 DISPATCHER: Starting worker discovery
18:53:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:53:01 DISPATCHER: Finished worker discovery
18:54:01 DISPATCHER: Starting worker discovery
18:54:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:54:01 DISPATCHER: Finished worker discovery
18:55:01 DISPATCHER: Starting worker discovery
18:55:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:55:01 DISPATCHER: Finished worker discovery
18:56:01 DISPATCHER: Starting worker discovery
18:56:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:56:01 DISPATCHER: Finished worker discovery
18:56:05 WORKER: done with job (0, 0, 26), trying to register it.
18:56:05 WORKER: registered result for job (0, 0, 26) with dispatcher
18:56:05 DISPATCHER: job (0, 0, 26) finished
18:56:05 DISPATCHER: register_result: lock acquired
18:56:05 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
18:56:05 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0027778986702694476, 'num_filters_1': 83, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.013791944079086018, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 66, 'num_filters_3': 76, 'num_filters_4': 25, 'num_filters_5': 52}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3247681351640037, 'info': {'data03': 0.3247681351640037, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0027778986702694476, 'num_filters_1': 83, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 93, 'weight_decay': 0.013791944079086018, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 66, 'num_filters_3': 76, 'num_filters_4': 25, 'num_filters_5': 52}"}}
exception: None

18:56:05 job_callback for (0, 0, 26) started
18:56:05 DISPATCHER: Trying to submit another job.
18:56:05 job_callback for (0, 0, 26) got condition
18:56:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:56:05 Only 9 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
18:56:05 HBMASTER: Trying to run another job!
18:56:05 job_callback for (0, 0, 26) finished
18:56:05 ITERATION: Advancing config (0, 0, 2) to next budget 400.000000
18:56:05 ITERATION: Advancing config (0, 0, 4) to next budget 400.000000
18:56:05 ITERATION: Advancing config (0, 0, 20) to next budget 400.000000
18:56:05 HBMASTER: schedule new run for iteration 0
18:56:05 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
18:56:05 HBMASTER: submitting job (0, 0, 2) to dispatcher
18:56:05 DISPATCHER: trying to submit job (0, 0, 2)
18:56:05 DISPATCHER: trying to notify the job_runner thread.
18:56:05 HBMASTER: job (0, 0, 2) submitted to dispatcher
18:56:05 DISPATCHER: Trying to submit another job.
18:56:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:56:05 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
18:56:05 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
18:56:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:56:05 WORKER: start processing job (0, 0, 2)
18:56:05 WORKER: args: ()
18:56:05 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00645974879509834, 'num_filters_1': 87, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.012859992184415444, 'kernel_size_2': 5, 'num_filters_2': 43}, 'budget': 400.0, 'working_directory': '.'}
18:57:01 DISPATCHER: Starting worker discovery
18:57:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:57:01 DISPATCHER: Finished worker discovery
18:58:01 DISPATCHER: Starting worker discovery
18:58:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:58:02 DISPATCHER: Finished worker discovery
18:59:02 DISPATCHER: Starting worker discovery
18:59:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:59:02 DISPATCHER: Finished worker discovery
19:00:02 DISPATCHER: Starting worker discovery
19:00:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:00:02 DISPATCHER: Finished worker discovery
19:01:02 DISPATCHER: Starting worker discovery
19:01:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:01:02 DISPATCHER: Finished worker discovery
19:02:02 DISPATCHER: Starting worker discovery
19:02:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:02:02 DISPATCHER: Finished worker discovery
19:03:02 DISPATCHER: Starting worker discovery
19:03:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:03:02 DISPATCHER: Finished worker discovery
19:03:30 WORKER: done with job (0, 0, 2), trying to register it.
19:03:30 WORKER: registered result for job (0, 0, 2) with dispatcher
19:03:30 DISPATCHER: job (0, 0, 2) finished
19:03:30 DISPATCHER: register_result: lock acquired
19:03:30 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:03:30 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00645974879509834, 'num_filters_1': 87, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.012859992184415444, 'kernel_size_2': 5, 'num_filters_2': 43}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.30593388899671986, 'info': {'data03': 0.30593388899671986, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00645974879509834, 'num_filters_1': 87, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.012859992184415444, 'kernel_size_2': 5, 'num_filters_2': 43}"}}
exception: None

19:03:30 job_callback for (0, 0, 2) started
19:03:30 DISPATCHER: Trying to submit another job.
19:03:30 job_callback for (0, 0, 2) got condition
19:03:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:03:30 Only 1 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
19:03:30 HBMASTER: Trying to run another job!
19:03:30 job_callback for (0, 0, 2) finished
19:03:30 HBMASTER: schedule new run for iteration 0
19:03:30 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
19:03:30 HBMASTER: submitting job (0, 0, 4) to dispatcher
19:03:30 DISPATCHER: trying to submit job (0, 0, 4)
19:03:30 DISPATCHER: trying to notify the job_runner thread.
19:03:30 HBMASTER: job (0, 0, 4) submitted to dispatcher
19:03:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:03:30 DISPATCHER: Trying to submit another job.
19:03:30 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:03:30 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:03:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:03:30 WORKER: start processing job (0, 0, 4)
19:03:30 WORKER: args: ()
19:03:30 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.00546782466267872, 'num_filters_1': 81, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.0664785803711794}, 'budget': 400.0, 'working_directory': '.'}
19:04:02 DISPATCHER: Starting worker discovery
19:04:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:04:02 DISPATCHER: Finished worker discovery
19:05:02 DISPATCHER: Starting worker discovery
19:05:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:05:02 DISPATCHER: Finished worker discovery
19:06:02 DISPATCHER: Starting worker discovery
19:06:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:06:02 DISPATCHER: Finished worker discovery
19:07:02 DISPATCHER: Starting worker discovery
19:07:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:07:02 DISPATCHER: Finished worker discovery
19:08:02 DISPATCHER: Starting worker discovery
19:08:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:08:02 DISPATCHER: Finished worker discovery
19:09:02 DISPATCHER: Starting worker discovery
19:09:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:09:02 DISPATCHER: Finished worker discovery
19:10:02 DISPATCHER: Starting worker discovery
19:10:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:10:02 DISPATCHER: Finished worker discovery
19:10:53 WORKER: done with job (0, 0, 4), trying to register it.
19:10:53 WORKER: registered result for job (0, 0, 4) with dispatcher
19:10:53 DISPATCHER: job (0, 0, 4) finished
19:10:53 DISPATCHER: register_result: lock acquired
19:10:53 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:10:53 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.00546782466267872, 'num_filters_1': 81, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.0664785803711794}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4039659319780218, 'info': {'data03': 0.4039659319780218, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.00546782466267872, 'num_filters_1': 81, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.0664785803711794}"}}
exception: None

19:10:53 job_callback for (0, 0, 4) started
19:10:53 job_callback for (0, 0, 4) got condition
19:10:53 DISPATCHER: Trying to submit another job.
19:10:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:10:54 Only 2 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
19:10:54 HBMASTER: Trying to run another job!
19:10:54 job_callback for (0, 0, 4) finished
19:10:54 HBMASTER: schedule new run for iteration 0
19:10:54 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
19:10:54 HBMASTER: submitting job (0, 0, 20) to dispatcher
19:10:54 DISPATCHER: trying to submit job (0, 0, 20)
19:10:54 DISPATCHER: trying to notify the job_runner thread.
19:10:54 HBMASTER: job (0, 0, 20) submitted to dispatcher
19:10:54 DISPATCHER: Trying to submit another job.
19:10:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:10:54 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:10:54 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:10:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:10:54 WORKER: start processing job (0, 0, 20)
19:10:54 WORKER: args: ()
19:10:54 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0051399083476422035, 'num_filters_1': 27, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.029330416226218146}, 'budget': 400.0, 'working_directory': '.'}
19:11:02 DISPATCHER: Starting worker discovery
19:11:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:11:02 DISPATCHER: Finished worker discovery
19:12:02 DISPATCHER: Starting worker discovery
19:12:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:12:02 DISPATCHER: Finished worker discovery
19:13:02 DISPATCHER: Starting worker discovery
19:13:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:13:02 DISPATCHER: Finished worker discovery
19:14:02 DISPATCHER: Starting worker discovery
19:14:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:14:02 DISPATCHER: Finished worker discovery
19:15:02 DISPATCHER: Starting worker discovery
19:15:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:15:02 DISPATCHER: Finished worker discovery
19:16:02 DISPATCHER: Starting worker discovery
19:16:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:16:02 DISPATCHER: Finished worker discovery
19:17:02 DISPATCHER: Starting worker discovery
19:17:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:17:02 DISPATCHER: Finished worker discovery
19:18:02 DISPATCHER: Starting worker discovery
19:18:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:18:02 DISPATCHER: Finished worker discovery
19:18:18 WORKER: done with job (0, 0, 20), trying to register it.
19:18:18 WORKER: registered result for job (0, 0, 20) with dispatcher
19:18:18 DISPATCHER: job (0, 0, 20) finished
19:18:18 DISPATCHER: register_result: lock acquired
19:18:18 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:18:18 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0051399083476422035, 'num_filters_1': 27, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.029330416226218146}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.36618683658816653, 'info': {'data03': 0.36618683658816653, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0051399083476422035, 'num_filters_1': 27, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.029330416226218146}"}}
exception: None

19:18:18 job_callback for (0, 0, 20) started
19:18:18 DISPATCHER: Trying to submit another job.
19:18:18 job_callback for (0, 0, 20) got condition
19:18:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:18:18 Only 3 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
19:18:18 HBMASTER: Trying to run another job!
19:18:18 job_callback for (0, 0, 20) finished
19:18:18 ITERATION: Advancing config (0, 0, 4) to next budget 1200.000000
19:18:18 HBMASTER: schedule new run for iteration 0
19:18:18 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
19:18:18 HBMASTER: submitting job (0, 0, 4) to dispatcher
19:18:18 DISPATCHER: trying to submit job (0, 0, 4)
19:18:18 DISPATCHER: trying to notify the job_runner thread.
19:18:18 HBMASTER: job (0, 0, 4) submitted to dispatcher
19:18:18 DISPATCHER: Trying to submit another job.
19:18:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:18:18 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:18:18 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:18:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:18:18 WORKER: start processing job (0, 0, 4)
19:18:18 WORKER: args: ()
19:18:18 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.00546782466267872, 'num_filters_1': 81, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.0664785803711794}, 'budget': 1200.0, 'working_directory': '.'}
19:19:02 DISPATCHER: Starting worker discovery
19:19:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:19:02 DISPATCHER: Finished worker discovery
19:20:02 DISPATCHER: Starting worker discovery
19:20:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:20:02 DISPATCHER: Finished worker discovery
19:21:02 DISPATCHER: Starting worker discovery
19:21:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:21:02 DISPATCHER: Finished worker discovery
19:22:02 DISPATCHER: Starting worker discovery
19:22:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:22:02 DISPATCHER: Finished worker discovery
19:23:02 DISPATCHER: Starting worker discovery
19:23:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:23:02 DISPATCHER: Finished worker discovery
19:24:02 DISPATCHER: Starting worker discovery
19:24:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:24:02 DISPATCHER: Finished worker discovery
19:25:02 DISPATCHER: Starting worker discovery
19:25:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:25:02 DISPATCHER: Finished worker discovery
19:26:02 DISPATCHER: Starting worker discovery
19:26:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:26:02 DISPATCHER: Finished worker discovery
19:27:02 DISPATCHER: Starting worker discovery
19:27:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:27:02 DISPATCHER: Finished worker discovery
19:28:02 DISPATCHER: Starting worker discovery
19:28:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:28:02 DISPATCHER: Finished worker discovery
19:29:02 DISPATCHER: Starting worker discovery
19:29:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:29:02 DISPATCHER: Finished worker discovery
19:30:02 DISPATCHER: Starting worker discovery
19:30:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:30:02 DISPATCHER: Finished worker discovery
19:31:02 DISPATCHER: Starting worker discovery
19:31:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:31:02 DISPATCHER: Finished worker discovery
19:32:02 DISPATCHER: Starting worker discovery
19:32:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:32:02 DISPATCHER: Finished worker discovery
19:33:02 DISPATCHER: Starting worker discovery
19:33:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:33:02 DISPATCHER: Finished worker discovery
19:34:02 DISPATCHER: Starting worker discovery
19:34:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:34:02 DISPATCHER: Finished worker discovery
19:35:02 DISPATCHER: Starting worker discovery
19:35:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:35:02 DISPATCHER: Finished worker discovery
19:36:02 DISPATCHER: Starting worker discovery
19:36:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:36:02 DISPATCHER: Finished worker discovery
19:37:02 DISPATCHER: Starting worker discovery
19:37:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:37:02 DISPATCHER: Finished worker discovery
19:38:02 DISPATCHER: Starting worker discovery
19:38:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:38:02 DISPATCHER: Finished worker discovery
19:39:02 DISPATCHER: Starting worker discovery
19:39:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:39:02 DISPATCHER: Finished worker discovery
19:39:03 WORKER: done with job (0, 0, 4), trying to register it.
19:39:03 WORKER: registered result for job (0, 0, 4) with dispatcher
19:39:03 DISPATCHER: job (0, 0, 4) finished
19:39:03 DISPATCHER: register_result: lock acquired
19:39:03 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:39:03 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.00546782466267872, 'num_filters_1': 81, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.0664785803711794}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.3113425730379379, 'info': {'data03': 0.3113425730379379, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.00546782466267872, 'num_filters_1': 81, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.0664785803711794}"}}
exception: None

19:39:03 job_callback for (0, 0, 4) started
19:39:03 DISPATCHER: Trying to submit another job.
19:39:03 job_callback for (0, 0, 4) got condition
19:39:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:39:03 Only 1 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
19:39:03 HBMASTER: Trying to run another job!
19:39:03 job_callback for (0, 0, 4) finished
19:39:03 start sampling a new configuration.
19:39:03 done sampling a new configuration.
19:39:03 HBMASTER: schedule new run for iteration 1
19:39:03 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
19:39:03 HBMASTER: submitting job (1, 0, 0) to dispatcher
19:39:03 DISPATCHER: trying to submit job (1, 0, 0)
19:39:03 DISPATCHER: trying to notify the job_runner thread.
19:39:03 HBMASTER: job (1, 0, 0) submitted to dispatcher
19:39:03 DISPATCHER: Trying to submit another job.
19:39:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:39:03 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:39:03 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:39:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:39:03 WORKER: start processing job (1, 0, 0)
19:39:03 WORKER: args: ()
19:39:03 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.029871517943321622, 'num_filters_1': 74, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.03826089733720603}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:40:02 DISPATCHER: Starting worker discovery
19:40:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:40:02 DISPATCHER: Finished worker discovery
19:41:02 DISPATCHER: Starting worker discovery
19:41:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:41:02 DISPATCHER: Finished worker discovery
19:42:01 WORKER: done with job (1, 0, 0), trying to register it.
19:42:01 WORKER: registered result for job (1, 0, 0) with dispatcher
19:42:01 DISPATCHER: job (1, 0, 0) finished
19:42:01 DISPATCHER: register_result: lock acquired
19:42:01 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:42:01 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.029871517943321622, 'num_filters_1': 74, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.03826089733720603}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3610432572785921, 'info': {'data03': 0.3610432572785921, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.029871517943321622, 'num_filters_1': 74, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.03826089733720603}"}}
exception: None

19:42:01 job_callback for (1, 0, 0) started
19:42:01 DISPATCHER: Trying to submit another job.
19:42:01 job_callback for (1, 0, 0) got condition
19:42:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:42:01 Only 10 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
19:42:01 HBMASTER: Trying to run another job!
19:42:01 job_callback for (1, 0, 0) finished
19:42:01 start sampling a new configuration.
19:42:01 done sampling a new configuration.
19:42:01 HBMASTER: schedule new run for iteration 1
19:42:01 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
19:42:01 HBMASTER: submitting job (1, 0, 1) to dispatcher
19:42:01 DISPATCHER: trying to submit job (1, 0, 1)
19:42:01 DISPATCHER: trying to notify the job_runner thread.
19:42:01 HBMASTER: job (1, 0, 1) submitted to dispatcher
19:42:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:42:01 DISPATCHER: Trying to submit another job.
19:42:01 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:42:01 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:42:01 WORKER: start processing job (1, 0, 1)
19:42:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:42:01 WORKER: args: ()
19:42:01 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.014402728605145309, 'num_filters_1': 60, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.07290567601423027, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 68, 'num_filters_3': 43, 'num_filters_4': 29}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:42:02 DISPATCHER: Starting worker discovery
19:42:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:42:02 DISPATCHER: Finished worker discovery
19:43:02 DISPATCHER: Starting worker discovery
19:43:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:43:02 DISPATCHER: Finished worker discovery
19:44:02 DISPATCHER: Starting worker discovery
19:44:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:44:02 DISPATCHER: Finished worker discovery
19:45:00 WORKER: done with job (1, 0, 1), trying to register it.
19:45:00 WORKER: registered result for job (1, 0, 1) with dispatcher
19:45:00 DISPATCHER: job (1, 0, 1) finished
19:45:00 DISPATCHER: register_result: lock acquired
19:45:00 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:45:00 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.014402728605145309, 'num_filters_1': 60, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.07290567601423027, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 68, 'num_filters_3': 43, 'num_filters_4': 29}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.32290011538747415, 'info': {'data03': 0.32290011538747415, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.014402728605145309, 'num_filters_1': 60, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.07290567601423027, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 68, 'num_filters_3': 43, 'num_filters_4': 29}"}}
exception: None

19:45:00 job_callback for (1, 0, 1) started
19:45:00 DISPATCHER: Trying to submit another job.
19:45:00 job_callback for (1, 0, 1) got condition
19:45:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:45:00 Only 11 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
19:45:00 HBMASTER: Trying to run another job!
19:45:00 job_callback for (1, 0, 1) finished
19:45:00 start sampling a new configuration.
19:45:00 done sampling a new configuration.
19:45:00 HBMASTER: schedule new run for iteration 1
19:45:00 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
19:45:00 HBMASTER: submitting job (1, 0, 2) to dispatcher
19:45:00 DISPATCHER: trying to submit job (1, 0, 2)
19:45:00 DISPATCHER: trying to notify the job_runner thread.
19:45:00 HBMASTER: job (1, 0, 2) submitted to dispatcher
19:45:00 DISPATCHER: Trying to submit another job.
19:45:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:45:00 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:45:00 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:45:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:45:00 WORKER: start processing job (1, 0, 2)
19:45:00 WORKER: args: ()
19:45:00 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005135921723123828, 'num_filters_1': 27, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.012591233473171353}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:45:02 DISPATCHER: Starting worker discovery
19:45:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:45:02 DISPATCHER: Finished worker discovery
19:46:02 DISPATCHER: Starting worker discovery
19:46:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:46:02 DISPATCHER: Finished worker discovery
19:47:02 DISPATCHER: Starting worker discovery
19:47:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:47:02 DISPATCHER: Finished worker discovery
19:47:54 WORKER: done with job (1, 0, 2), trying to register it.
19:47:54 WORKER: registered result for job (1, 0, 2) with dispatcher
19:47:54 DISPATCHER: job (1, 0, 2) finished
19:47:54 DISPATCHER: register_result: lock acquired
19:47:54 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:47:54 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005135921723123828, 'num_filters_1': 27, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.012591233473171353}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2567558071309829, 'info': {'data03': 0.2567558071309829, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005135921723123828, 'num_filters_1': 27, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.012591233473171353}"}}
exception: None

19:47:54 job_callback for (1, 0, 2) started
19:47:54 job_callback for (1, 0, 2) got condition
19:47:54 DISPATCHER: Trying to submit another job.
19:47:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:47:54 Only 12 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
19:47:54 HBMASTER: Trying to run another job!
19:47:54 job_callback for (1, 0, 2) finished
19:47:54 start sampling a new configuration.
19:47:54 done sampling a new configuration.
19:47:54 HBMASTER: schedule new run for iteration 1
19:47:54 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
19:47:54 HBMASTER: submitting job (1, 0, 3) to dispatcher
19:47:54 DISPATCHER: trying to submit job (1, 0, 3)
19:47:54 DISPATCHER: trying to notify the job_runner thread.
19:47:54 HBMASTER: job (1, 0, 3) submitted to dispatcher
19:47:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:47:54 DISPATCHER: Trying to submit another job.
19:47:54 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:47:54 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:47:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:47:54 WORKER: start processing job (1, 0, 3)
19:47:54 WORKER: args: ()
19:47:54 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0022306788460532525, 'num_filters_1': 88, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.18259255239552621, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 49, 'num_filters_3': 94, 'num_filters_4': 127}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:48:02 DISPATCHER: Starting worker discovery
19:48:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:48:02 DISPATCHER: Finished worker discovery
19:49:02 DISPATCHER: Starting worker discovery
19:49:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:49:02 DISPATCHER: Finished worker discovery
19:50:02 DISPATCHER: Starting worker discovery
19:50:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:50:02 DISPATCHER: Finished worker discovery
19:50:50 WORKER: done with job (1, 0, 3), trying to register it.
19:50:50 WORKER: registered result for job (1, 0, 3) with dispatcher
19:50:50 DISPATCHER: job (1, 0, 3) finished
19:50:50 DISPATCHER: register_result: lock acquired
19:50:50 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:50:50 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0022306788460532525, 'num_filters_1': 88, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.18259255239552621, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 49, 'num_filters_3': 94, 'num_filters_4': 127}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.35074947657742894, 'info': {'data03': 0.35074947657742894, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0022306788460532525, 'num_filters_1': 88, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.18259255239552621, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 49, 'num_filters_3': 94, 'num_filters_4': 127}"}}
exception: None

19:50:50 job_callback for (1, 0, 3) started
19:50:50 DISPATCHER: Trying to submit another job.
19:50:50 job_callback for (1, 0, 3) got condition
19:50:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:50:50 Only 13 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
19:50:50 HBMASTER: Trying to run another job!
19:50:50 job_callback for (1, 0, 3) finished
19:50:50 start sampling a new configuration.
19:50:50 done sampling a new configuration.
19:50:50 HBMASTER: schedule new run for iteration 1
19:50:50 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
19:50:50 HBMASTER: submitting job (1, 0, 4) to dispatcher
19:50:50 DISPATCHER: trying to submit job (1, 0, 4)
19:50:50 DISPATCHER: trying to notify the job_runner thread.
19:50:50 HBMASTER: job (1, 0, 4) submitted to dispatcher
19:50:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:50:50 DISPATCHER: Trying to submit another job.
19:50:50 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:50:50 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:50:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:50:50 WORKER: start processing job (1, 0, 4)
19:50:50 WORKER: args: ()
19:50:50 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00473852317563551, 'num_filters_1': 27, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 68, 'weight_decay': 0.01665767993511604, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 83, 'num_filters_3': 34, 'num_filters_4': 83, 'num_filters_5': 71}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:51:02 DISPATCHER: Starting worker discovery
19:51:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:51:02 DISPATCHER: Finished worker discovery
19:52:02 DISPATCHER: Starting worker discovery
19:52:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:52:02 DISPATCHER: Finished worker discovery
19:53:02 DISPATCHER: Starting worker discovery
19:53:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:53:02 DISPATCHER: Finished worker discovery
19:53:46 WORKER: done with job (1, 0, 4), trying to register it.
19:53:46 WORKER: registered result for job (1, 0, 4) with dispatcher
19:53:46 DISPATCHER: job (1, 0, 4) finished
19:53:46 DISPATCHER: register_result: lock acquired
19:53:46 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:53:46 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00473852317563551, 'num_filters_1': 27, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 68, 'weight_decay': 0.01665767993511604, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 83, 'num_filters_3': 34, 'num_filters_4': 83, 'num_filters_5': 71}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2936577232444324, 'info': {'data03': 0.2936577232444324, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00473852317563551, 'num_filters_1': 27, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 68, 'weight_decay': 0.01665767993511604, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 83, 'num_filters_3': 34, 'num_filters_4': 83, 'num_filters_5': 71}"}}
exception: None

19:53:46 job_callback for (1, 0, 4) started
19:53:46 job_callback for (1, 0, 4) got condition
19:53:46 DISPATCHER: Trying to submit another job.
19:53:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:53:46 Only 14 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
19:53:46 HBMASTER: Trying to run another job!
19:53:46 job_callback for (1, 0, 4) finished
19:53:46 start sampling a new configuration.
19:53:46 done sampling a new configuration.
19:53:46 HBMASTER: schedule new run for iteration 1
19:53:46 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
19:53:46 HBMASTER: submitting job (1, 0, 5) to dispatcher
19:53:46 DISPATCHER: trying to submit job (1, 0, 5)
19:53:46 DISPATCHER: trying to notify the job_runner thread.
19:53:46 HBMASTER: job (1, 0, 5) submitted to dispatcher
19:53:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:53:46 DISPATCHER: Trying to submit another job.
19:53:46 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:53:46 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:53:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:53:46 WORKER: start processing job (1, 0, 5)
19:53:46 WORKER: args: ()
19:53:46 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.06594161484084268, 'num_filters_1': 79, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.013151600452685208, 'kernel_size_2': 3, 'num_filters_2': 91}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:54:02 DISPATCHER: Starting worker discovery
19:54:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:54:02 DISPATCHER: Finished worker discovery
19:55:02 DISPATCHER: Starting worker discovery
19:55:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:55:02 DISPATCHER: Finished worker discovery
19:56:02 DISPATCHER: Starting worker discovery
19:56:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:56:02 DISPATCHER: Finished worker discovery
19:56:47 WORKER: done with job (1, 0, 5), trying to register it.
19:56:47 WORKER: registered result for job (1, 0, 5) with dispatcher
19:56:47 DISPATCHER: job (1, 0, 5) finished
19:56:47 DISPATCHER: register_result: lock acquired
19:56:47 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:56:47 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.06594161484084268, 'num_filters_1': 79, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.013151600452685208, 'kernel_size_2': 3, 'num_filters_2': 91}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.20533132393909995, 'info': {'data03': 0.20533132393909995, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.06594161484084268, 'num_filters_1': 79, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 89, 'weight_decay': 0.013151600452685208, 'kernel_size_2': 3, 'num_filters_2': 91}"}}
exception: None

19:56:47 job_callback for (1, 0, 5) started
19:56:47 DISPATCHER: Trying to submit another job.
19:56:47 job_callback for (1, 0, 5) got condition
19:56:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:56:47 Only 15 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
19:56:47 HBMASTER: Trying to run another job!
19:56:47 job_callback for (1, 0, 5) finished
19:56:47 start sampling a new configuration.
19:56:47 done sampling a new configuration.
19:56:47 HBMASTER: schedule new run for iteration 1
19:56:47 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
19:56:47 HBMASTER: submitting job (1, 0, 6) to dispatcher
19:56:47 DISPATCHER: trying to submit job (1, 0, 6)
19:56:47 DISPATCHER: trying to notify the job_runner thread.
19:56:47 HBMASTER: job (1, 0, 6) submitted to dispatcher
19:56:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:56:47 DISPATCHER: Trying to submit another job.
19:56:47 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:56:47 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:56:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:56:47 WORKER: start processing job (1, 0, 6)
19:56:47 WORKER: args: ()
19:56:47 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.001333934711693227, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.021100437553429885, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 88, 'num_filters_3': 125, 'num_filters_4': 127, 'num_filters_5': 21}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:57:02 DISPATCHER: Starting worker discovery
19:57:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:57:02 DISPATCHER: Finished worker discovery
19:58:02 DISPATCHER: Starting worker discovery
19:58:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:58:02 DISPATCHER: Finished worker discovery
19:59:02 DISPATCHER: Starting worker discovery
19:59:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:59:02 DISPATCHER: Finished worker discovery
19:59:41 WORKER: done with job (1, 0, 6), trying to register it.
19:59:41 WORKER: registered result for job (1, 0, 6) with dispatcher
19:59:41 DISPATCHER: job (1, 0, 6) finished
19:59:41 DISPATCHER: register_result: lock acquired
19:59:41 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
19:59:41 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.001333934711693227, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.021100437553429885, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 88, 'num_filters_3': 125, 'num_filters_4': 127, 'num_filters_5': 21}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.37446183636522323, 'info': {'data03': 0.37446183636522323, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.001333934711693227, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.021100437553429885, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 88, 'num_filters_3': 125, 'num_filters_4': 127, 'num_filters_5': 21}"}}
exception: None

19:59:41 job_callback for (1, 0, 6) started
19:59:41 job_callback for (1, 0, 6) got condition
19:59:41 DISPATCHER: Trying to submit another job.
19:59:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:59:41 Only 16 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
19:59:41 HBMASTER: Trying to run another job!
19:59:41 job_callback for (1, 0, 6) finished
19:59:41 start sampling a new configuration.
19:59:41 done sampling a new configuration.
19:59:41 HBMASTER: schedule new run for iteration 1
19:59:41 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
19:59:41 HBMASTER: submitting job (1, 0, 7) to dispatcher
19:59:41 DISPATCHER: trying to submit job (1, 0, 7)
19:59:41 DISPATCHER: trying to notify the job_runner thread.
19:59:41 HBMASTER: job (1, 0, 7) submitted to dispatcher
19:59:41 DISPATCHER: Trying to submit another job.
19:59:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:59:41 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776
19:59:41 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
19:59:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:59:41 WORKER: start processing job (1, 0, 7)
19:59:41 WORKER: args: ()
19:59:41 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.01429006005892596, 'num_filters_1': 103, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.06648116719675393, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 116, 'num_filters_3': 50, 'num_filters_4': 55, 'num_filters_5': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:00:02 DISPATCHER: Starting worker discovery
20:00:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:00:02 DISPATCHER: Finished worker discovery
Exception in thread Thread-649:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 4575657222997987528 is out of bounds for axis 0 with size 3

20:01:02 DISPATCHER: Starting worker discovery
20:01:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:01:02 DISPATCHER: Finished worker discovery
20:02:02 DISPATCHER: Starting worker discovery
20:02:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:02:02 DISPATCHER: Finished worker discovery
20:02:38 WORKER: done with job (1, 0, 7), trying to register it.
20:02:38 WORKER: registered result for job (1, 0, 7) with dispatcher
20:02:38 DISPATCHER: job (1, 0, 7) finished
20:02:38 DISPATCHER: register_result: lock acquired
20:02:38 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
20:02:38 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.01429006005892596, 'num_filters_1': 103, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.06648116719675393, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 116, 'num_filters_3': 50, 'num_filters_4': 55, 'num_filters_5': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.39818606733024525, 'info': {'data03': 0.39818606733024525, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.01429006005892596, 'num_filters_1': 103, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.06648116719675393, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 116, 'num_filters_3': 50, 'num_filters_4': 55, 'num_filters_5': 17}"}}
exception: None

20:02:38 job_callback for (1, 0, 7) started
20:02:38 job_callback for (1, 0, 7) got condition
20:02:38 DISPATCHER: Trying to submit another job.
20:02:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:02:38 HBMASTER: Trying to run another job!
20:02:38 job_callback for (1, 0, 7) finished
20:02:38 start sampling a new configuration.
20:02:38 done sampling a new configuration.
20:02:38 HBMASTER: schedule new run for iteration 1
20:02:38 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
20:02:38 HBMASTER: submitting job (1, 0, 8) to dispatcher
20:02:38 DISPATCHER: trying to submit job (1, 0, 8)
20:02:38 DISPATCHER: trying to notify the job_runner thread.
20:02:38 HBMASTER: job (1, 0, 8) submitted to dispatcher
20:02:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:02:38 DISPATCHER: Trying to submit another job.
20:02:38 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776
20:02:38 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
20:02:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:02:38 WORKER: start processing job (1, 0, 8)
20:02:38 WORKER: args: ()
20:02:38 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.03667034831792444, 'num_filters_1': 99, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.019077835194638904}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:03:02 DISPATCHER: Starting worker discovery
20:03:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:03:02 DISPATCHER: Finished worker discovery
20:04:02 DISPATCHER: Starting worker discovery
20:04:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:04:02 DISPATCHER: Finished worker discovery
20:05:02 DISPATCHER: Starting worker discovery
20:05:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:05:02 DISPATCHER: Finished worker discovery
20:05:36 WORKER: done with job (1, 0, 8), trying to register it.
20:05:36 WORKER: registered result for job (1, 0, 8) with dispatcher
20:05:36 DISPATCHER: job (1, 0, 8) finished
20:05:36 DISPATCHER: register_result: lock acquired
20:05:36 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
20:05:36 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.03667034831792444, 'num_filters_1': 99, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.019077835194638904}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.13067381048349697, 'info': {'data03': 0.13067381048349697, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.03667034831792444, 'num_filters_1': 99, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.019077835194638904}"}}
exception: None

20:05:36 job_callback for (1, 0, 8) started
20:05:36 job_callback for (1, 0, 8) got condition
20:05:36 DISPATCHER: Trying to submit another job.
20:05:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:05:36 HBMASTER: Trying to run another job!
20:05:36 job_callback for (1, 0, 8) finished
20:05:36 ITERATION: Advancing config (1, 0, 0) to next budget 400.000000
20:05:36 ITERATION: Advancing config (1, 0, 6) to next budget 400.000000
20:05:36 ITERATION: Advancing config (1, 0, 7) to next budget 400.000000
20:05:36 HBMASTER: schedule new run for iteration 1
20:05:36 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
20:05:36 HBMASTER: submitting job (1, 0, 0) to dispatcher
20:05:36 DISPATCHER: trying to submit job (1, 0, 0)
20:05:36 DISPATCHER: trying to notify the job_runner thread.
20:05:36 HBMASTER: job (1, 0, 0) submitted to dispatcher
20:05:36 DISPATCHER: Trying to submit another job.
20:05:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:05:36 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
20:05:36 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
20:05:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:05:36 WORKER: start processing job (1, 0, 0)
20:05:36 WORKER: args: ()
20:05:36 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.029871517943321622, 'num_filters_1': 74, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.03826089733720603}, 'budget': 400.0, 'working_directory': '.'}
20:06:02 DISPATCHER: Starting worker discovery
20:06:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:06:02 DISPATCHER: Finished worker discovery
20:07:02 DISPATCHER: Starting worker discovery
20:07:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:07:02 DISPATCHER: Finished worker discovery
20:08:02 DISPATCHER: Starting worker discovery
20:08:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:08:02 DISPATCHER: Finished worker discovery
20:09:02 DISPATCHER: Starting worker discovery
20:09:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:09:02 DISPATCHER: Finished worker discovery
20:10:02 DISPATCHER: Starting worker discovery
20:10:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:10:02 DISPATCHER: Finished worker discovery
20:11:02 DISPATCHER: Starting worker discovery
20:11:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:11:02 DISPATCHER: Finished worker discovery
20:12:02 DISPATCHER: Starting worker discovery
20:12:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:12:02 DISPATCHER: Finished worker discovery
20:12:56 WORKER: done with job (1, 0, 0), trying to register it.
20:12:56 WORKER: registered result for job (1, 0, 0) with dispatcher
20:12:56 DISPATCHER: job (1, 0, 0) finished
20:12:56 DISPATCHER: register_result: lock acquired
20:12:56 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
20:12:56 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.029871517943321622, 'num_filters_1': 74, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.03826089733720603}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.276760332108409, 'info': {'data03': 0.276760332108409, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.029871517943321622, 'num_filters_1': 74, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.03826089733720603}"}}
exception: None

20:12:56 job_callback for (1, 0, 0) started
20:12:56 DISPATCHER: Trying to submit another job.
20:12:56 job_callback for (1, 0, 0) got condition
20:12:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:12:56 Only 4 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
20:12:56 HBMASTER: Trying to run another job!
20:12:56 job_callback for (1, 0, 0) finished
20:12:56 HBMASTER: schedule new run for iteration 1
20:12:56 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
20:12:56 HBMASTER: submitting job (1, 0, 6) to dispatcher
20:12:56 DISPATCHER: trying to submit job (1, 0, 6)
20:12:56 DISPATCHER: trying to notify the job_runner thread.
20:12:56 HBMASTER: job (1, 0, 6) submitted to dispatcher
20:12:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:12:56 DISPATCHER: Trying to submit another job.
20:12:56 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776
20:12:56 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
20:12:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:12:56 WORKER: start processing job (1, 0, 6)
20:12:56 WORKER: args: ()
20:12:56 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.001333934711693227, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.021100437553429885, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 88, 'num_filters_3': 125, 'num_filters_4': 127, 'num_filters_5': 21}, 'budget': 400.0, 'working_directory': '.'}
20:13:02 DISPATCHER: Starting worker discovery
20:13:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:13:02 DISPATCHER: Finished worker discovery
20:14:02 DISPATCHER: Starting worker discovery
20:14:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:14:02 DISPATCHER: Finished worker discovery
20:15:02 DISPATCHER: Starting worker discovery
20:15:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:15:02 DISPATCHER: Finished worker discovery
20:16:02 DISPATCHER: Starting worker discovery
20:16:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:16:02 DISPATCHER: Finished worker discovery
20:17:02 DISPATCHER: Starting worker discovery
20:17:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:17:02 DISPATCHER: Finished worker discovery
20:18:02 DISPATCHER: Starting worker discovery
20:18:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:18:02 DISPATCHER: Finished worker discovery
20:19:02 DISPATCHER: Starting worker discovery
20:19:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:19:02 DISPATCHER: Finished worker discovery
20:20:02 DISPATCHER: Starting worker discovery
20:20:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:20:02 DISPATCHER: Finished worker discovery
20:20:23 WORKER: done with job (1, 0, 6), trying to register it.
20:20:23 WORKER: registered result for job (1, 0, 6) with dispatcher
20:20:23 DISPATCHER: job (1, 0, 6) finished
20:20:23 DISPATCHER: register_result: lock acquired
20:20:23 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
20:20:23 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.001333934711693227, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.021100437553429885, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 88, 'num_filters_3': 125, 'num_filters_4': 127, 'num_filters_5': 21}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.34341137401827715, 'info': {'data03': 0.34341137401827715, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.001333934711693227, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.021100437553429885, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 88, 'num_filters_3': 125, 'num_filters_4': 127, 'num_filters_5': 21}"}}
exception: None

20:20:23 job_callback for (1, 0, 6) started
20:20:23 DISPATCHER: Trying to submit another job.
20:20:23 job_callback for (1, 0, 6) got condition
20:20:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:20:23 Only 5 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
20:20:23 HBMASTER: Trying to run another job!
20:20:23 job_callback for (1, 0, 6) finished
20:20:23 HBMASTER: schedule new run for iteration 1
20:20:23 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
20:20:23 HBMASTER: submitting job (1, 0, 7) to dispatcher
20:20:23 DISPATCHER: trying to submit job (1, 0, 7)
20:20:23 DISPATCHER: trying to notify the job_runner thread.
20:20:23 HBMASTER: job (1, 0, 7) submitted to dispatcher
20:20:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:20:23 DISPATCHER: Trying to submit another job.
20:20:23 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776
20:20:23 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
20:20:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:20:23 WORKER: start processing job (1, 0, 7)
20:20:23 WORKER: args: ()
20:20:23 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.01429006005892596, 'num_filters_1': 103, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.06648116719675393, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 116, 'num_filters_3': 50, 'num_filters_4': 55, 'num_filters_5': 17}, 'budget': 400.0, 'working_directory': '.'}
20:21:02 DISPATCHER: Starting worker discovery
20:21:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:21:02 DISPATCHER: Finished worker discovery
20:22:02 DISPATCHER: Starting worker discovery
20:22:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:22:02 DISPATCHER: Finished worker discovery
20:23:02 DISPATCHER: Starting worker discovery
20:23:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:23:02 DISPATCHER: Finished worker discovery
20:24:02 DISPATCHER: Starting worker discovery
20:24:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:24:03 DISPATCHER: Finished worker discovery
20:25:03 DISPATCHER: Starting worker discovery
20:25:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:25:03 DISPATCHER: Finished worker discovery
20:26:03 DISPATCHER: Starting worker discovery
20:26:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:26:03 DISPATCHER: Finished worker discovery
20:27:03 DISPATCHER: Starting worker discovery
20:27:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:27:03 DISPATCHER: Finished worker discovery
20:28:02 WORKER: done with job (1, 0, 7), trying to register it.
20:28:02 WORKER: registered result for job (1, 0, 7) with dispatcher
20:28:02 DISPATCHER: job (1, 0, 7) finished
20:28:02 DISPATCHER: register_result: lock acquired
20:28:02 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
20:28:02 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.01429006005892596, 'num_filters_1': 103, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.06648116719675393, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 116, 'num_filters_3': 50, 'num_filters_4': 55, 'num_filters_5': 17}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.2734706030158851, 'info': {'data03': 0.2734706030158851, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.01429006005892596, 'num_filters_1': 103, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.06648116719675393, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 116, 'num_filters_3': 50, 'num_filters_4': 55, 'num_filters_5': 17}"}}
exception: None

20:28:02 job_callback for (1, 0, 7) started
20:28:02 job_callback for (1, 0, 7) got condition
20:28:02 DISPATCHER: Trying to submit another job.
20:28:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:28:02 Only 6 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
20:28:02 HBMASTER: Trying to run another job!
20:28:02 job_callback for (1, 0, 7) finished
20:28:02 ITERATION: Advancing config (1, 0, 6) to next budget 1200.000000
20:28:02 HBMASTER: schedule new run for iteration 1
20:28:02 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
20:28:02 HBMASTER: submitting job (1, 0, 6) to dispatcher
20:28:02 DISPATCHER: trying to submit job (1, 0, 6)
20:28:02 DISPATCHER: trying to notify the job_runner thread.
20:28:02 HBMASTER: job (1, 0, 6) submitted to dispatcher
20:28:02 DISPATCHER: Trying to submit another job.
20:28:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:28:02 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776
20:28:02 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
20:28:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:28:02 WORKER: start processing job (1, 0, 6)
20:28:02 WORKER: args: ()
20:28:02 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.001333934711693227, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.021100437553429885, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 88, 'num_filters_3': 125, 'num_filters_4': 127, 'num_filters_5': 21}, 'budget': 1200.0, 'working_directory': '.'}
20:28:03 DISPATCHER: Starting worker discovery
20:28:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:28:03 DISPATCHER: Finished worker discovery
20:29:03 DISPATCHER: Starting worker discovery
20:29:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:29:03 DISPATCHER: Finished worker discovery
20:30:03 DISPATCHER: Starting worker discovery
20:30:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:30:03 DISPATCHER: Finished worker discovery
20:31:03 DISPATCHER: Starting worker discovery
20:31:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:31:03 DISPATCHER: Finished worker discovery
20:32:03 DISPATCHER: Starting worker discovery
20:32:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:32:03 DISPATCHER: Finished worker discovery
20:33:03 DISPATCHER: Starting worker discovery
20:33:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:33:03 DISPATCHER: Finished worker discovery
20:34:03 DISPATCHER: Starting worker discovery
20:34:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:34:03 DISPATCHER: Finished worker discovery
20:35:03 DISPATCHER: Starting worker discovery
20:35:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:35:03 DISPATCHER: Finished worker discovery
20:36:03 DISPATCHER: Starting worker discovery
20:36:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:36:03 DISPATCHER: Finished worker discovery
20:37:03 DISPATCHER: Starting worker discovery
20:37:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:37:03 DISPATCHER: Finished worker discovery
20:38:03 DISPATCHER: Starting worker discovery
20:38:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:38:03 DISPATCHER: Finished worker discovery
20:39:03 DISPATCHER: Starting worker discovery
20:39:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:39:03 DISPATCHER: Finished worker discovery
20:40:03 DISPATCHER: Starting worker discovery
20:40:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:40:03 DISPATCHER: Finished worker discovery
20:41:03 DISPATCHER: Starting worker discovery
20:41:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:41:03 DISPATCHER: Finished worker discovery
20:42:03 DISPATCHER: Starting worker discovery
20:42:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:42:03 DISPATCHER: Finished worker discovery
20:43:03 DISPATCHER: Starting worker discovery
20:43:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:43:03 DISPATCHER: Finished worker discovery
20:44:03 DISPATCHER: Starting worker discovery
20:44:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:44:03 DISPATCHER: Finished worker discovery
20:45:03 DISPATCHER: Starting worker discovery
20:45:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:45:03 DISPATCHER: Finished worker discovery
20:46:03 DISPATCHER: Starting worker discovery
20:46:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:46:03 DISPATCHER: Finished worker discovery
20:47:03 DISPATCHER: Starting worker discovery
20:47:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:47:03 DISPATCHER: Finished worker discovery
20:48:03 DISPATCHER: Starting worker discovery
20:48:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:48:03 DISPATCHER: Finished worker discovery
20:48:53 WORKER: done with job (1, 0, 6), trying to register it.
20:48:53 WORKER: registered result for job (1, 0, 6) with dispatcher
20:48:53 DISPATCHER: job (1, 0, 6) finished
20:48:53 DISPATCHER: register_result: lock acquired
20:48:53 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
20:48:53 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.001333934711693227, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.021100437553429885, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 88, 'num_filters_3': 125, 'num_filters_4': 127, 'num_filters_5': 21}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.32092483881902006, 'info': {'data03': 0.32092483881902006, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.001333934711693227, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.021100437553429885, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 88, 'num_filters_3': 125, 'num_filters_4': 127, 'num_filters_5': 21}"}}
exception: None

20:48:53 job_callback for (1, 0, 6) started
20:48:53 DISPATCHER: Trying to submit another job.
20:48:53 job_callback for (1, 0, 6) got condition
20:48:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:48:53 Only 2 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
20:48:53 HBMASTER: Trying to run another job!
20:48:53 job_callback for (1, 0, 6) finished
20:48:53 start sampling a new configuration.
20:48:53 done sampling a new configuration.
20:48:54 HBMASTER: schedule new run for iteration 2
20:48:54 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
20:48:54 HBMASTER: submitting job (2, 0, 0) to dispatcher
20:48:54 DISPATCHER: trying to submit job (2, 0, 0)
20:48:54 DISPATCHER: trying to notify the job_runner thread.
20:48:54 HBMASTER: job (2, 0, 0) submitted to dispatcher
20:48:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:48:54 DISPATCHER: Trying to submit another job.
20:48:54 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
20:48:54 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
20:48:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:48:54 WORKER: start processing job (2, 0, 0)
20:48:54 WORKER: args: ()
20:48:54 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.01035945561998291, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.046566401798969724, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 22, 'num_filters_3': 96, 'num_filters_4': 57}, 'budget': 400.0, 'working_directory': '.'}
20:49:03 DISPATCHER: Starting worker discovery
20:49:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:49:03 DISPATCHER: Finished worker discovery
20:50:03 DISPATCHER: Starting worker discovery
20:50:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:50:03 DISPATCHER: Finished worker discovery
20:51:03 DISPATCHER: Starting worker discovery
20:51:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:51:03 DISPATCHER: Finished worker discovery
20:52:03 DISPATCHER: Starting worker discovery
20:52:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:52:03 DISPATCHER: Finished worker discovery
20:53:03 DISPATCHER: Starting worker discovery
20:53:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:53:03 DISPATCHER: Finished worker discovery
20:54:03 DISPATCHER: Starting worker discovery
20:54:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:54:03 DISPATCHER: Finished worker discovery
20:55:03 DISPATCHER: Starting worker discovery
20:55:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:55:03 DISPATCHER: Finished worker discovery
20:56:03 DISPATCHER: Starting worker discovery
20:56:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:56:03 DISPATCHER: Finished worker discovery
20:56:24 WORKER: done with job (2, 0, 0), trying to register it.
20:56:24 WORKER: registered result for job (2, 0, 0) with dispatcher
20:56:24 DISPATCHER: job (2, 0, 0) finished
20:56:24 DISPATCHER: register_result: lock acquired
20:56:24 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
20:56:24 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.01035945561998291, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.046566401798969724, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 22, 'num_filters_3': 96, 'num_filters_4': 57}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.027318275150097993, 'info': {'data03': 0.027318275150097993, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.01035945561998291, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.046566401798969724, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 22, 'num_filters_3': 96, 'num_filters_4': 57}"}}
exception: None

20:56:24 job_callback for (2, 0, 0) started
20:56:24 DISPATCHER: Trying to submit another job.
20:56:24 job_callback for (2, 0, 0) got condition
20:56:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:56:24 Only 7 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
20:56:24 HBMASTER: Trying to run another job!
20:56:24 job_callback for (2, 0, 0) finished
20:56:24 start sampling a new configuration.
20:56:24 done sampling a new configuration.
20:56:24 HBMASTER: schedule new run for iteration 2
20:56:24 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
20:56:24 HBMASTER: submitting job (2, 0, 1) to dispatcher
20:56:24 DISPATCHER: trying to submit job (2, 0, 1)
20:56:24 DISPATCHER: trying to notify the job_runner thread.
20:56:24 HBMASTER: job (2, 0, 1) submitted to dispatcher
20:56:24 DISPATCHER: Trying to submit another job.
20:56:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:56:24 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
20:56:24 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
20:56:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:56:24 WORKER: start processing job (2, 0, 1)
20:56:24 WORKER: args: ()
20:56:24 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001386422806860656, 'num_filters_1': 118, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.042326267379201615}, 'budget': 400.0, 'working_directory': '.'}
20:57:03 DISPATCHER: Starting worker discovery
20:57:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:57:03 DISPATCHER: Finished worker discovery
20:58:03 DISPATCHER: Starting worker discovery
20:58:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:58:03 DISPATCHER: Finished worker discovery
20:59:03 DISPATCHER: Starting worker discovery
20:59:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:59:03 DISPATCHER: Finished worker discovery
21:00:03 DISPATCHER: Starting worker discovery
21:00:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:00:03 DISPATCHER: Finished worker discovery
21:01:03 DISPATCHER: Starting worker discovery
21:01:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:01:03 DISPATCHER: Finished worker discovery
21:02:03 DISPATCHER: Starting worker discovery
21:02:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:02:03 DISPATCHER: Finished worker discovery
21:03:03 DISPATCHER: Starting worker discovery
21:03:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:03:03 DISPATCHER: Finished worker discovery
21:03:46 WORKER: done with job (2, 0, 1), trying to register it.
21:03:46 WORKER: registered result for job (2, 0, 1) with dispatcher
21:03:46 DISPATCHER: job (2, 0, 1) finished
21:03:46 DISPATCHER: register_result: lock acquired
21:03:46 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
21:03:46 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001386422806860656, 'num_filters_1': 118, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.042326267379201615}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.36759015749398616, 'info': {'data03': 0.36759015749398616, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001386422806860656, 'num_filters_1': 118, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.042326267379201615}"}}
exception: None

21:03:46 job_callback for (2, 0, 1) started
21:03:46 job_callback for (2, 0, 1) got condition
21:03:46 DISPATCHER: Trying to submit another job.
21:03:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:03:46 Only 8 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
21:03:46 HBMASTER: Trying to run another job!
21:03:46 job_callback for (2, 0, 1) finished
21:03:46 start sampling a new configuration.
21:03:46 done sampling a new configuration.
21:03:46 HBMASTER: schedule new run for iteration 2
21:03:46 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
21:03:46 HBMASTER: submitting job (2, 0, 2) to dispatcher
21:03:46 DISPATCHER: trying to submit job (2, 0, 2)
21:03:46 DISPATCHER: trying to notify the job_runner thread.
21:03:46 HBMASTER: job (2, 0, 2) submitted to dispatcher
21:03:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:03:46 DISPATCHER: Trying to submit another job.
21:03:46 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
21:03:46 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
21:03:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:03:46 WORKER: start processing job (2, 0, 2)
21:03:46 WORKER: args: ()
21:03:46 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.015111411870906952, 'num_filters_1': 29, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.04949794574478917, 'kernel_size_2': 7, 'num_filters_2': 44}, 'budget': 400.0, 'working_directory': '.'}
21:04:03 DISPATCHER: Starting worker discovery
21:04:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:04:03 DISPATCHER: Finished worker discovery
21:05:03 DISPATCHER: Starting worker discovery
21:05:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:05:03 DISPATCHER: Finished worker discovery
21:06:03 DISPATCHER: Starting worker discovery
21:06:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:06:03 DISPATCHER: Finished worker discovery
21:07:03 DISPATCHER: Starting worker discovery
21:07:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:07:03 DISPATCHER: Finished worker discovery
21:08:03 DISPATCHER: Starting worker discovery
21:08:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:08:03 DISPATCHER: Finished worker discovery
21:09:03 DISPATCHER: Starting worker discovery
21:09:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:09:03 DISPATCHER: Finished worker discovery
21:10:03 DISPATCHER: Starting worker discovery
21:10:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:10:03 DISPATCHER: Finished worker discovery
21:11:03 DISPATCHER: Starting worker discovery
21:11:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:11:03 DISPATCHER: Finished worker discovery
21:11:09 WORKER: done with job (2, 0, 2), trying to register it.
21:11:09 WORKER: registered result for job (2, 0, 2) with dispatcher
21:11:09 DISPATCHER: job (2, 0, 2) finished
21:11:09 DISPATCHER: register_result: lock acquired
21:11:09 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
21:11:09 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.015111411870906952, 'num_filters_1': 29, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.04949794574478917, 'kernel_size_2': 7, 'num_filters_2': 44}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3041581753936521, 'info': {'data03': 0.3041581753936521, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.015111411870906952, 'num_filters_1': 29, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.04949794574478917, 'kernel_size_2': 7, 'num_filters_2': 44}"}}
exception: None

21:11:09 job_callback for (2, 0, 2) started
21:11:09 DISPATCHER: Trying to submit another job.
21:11:09 job_callback for (2, 0, 2) got condition
21:11:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:11:09 Only 9 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
21:11:09 HBMASTER: Trying to run another job!
21:11:09 job_callback for (2, 0, 2) finished
21:11:09 start sampling a new configuration.
21:11:09 done sampling a new configuration.
21:11:09 HBMASTER: schedule new run for iteration 2
21:11:09 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
21:11:09 HBMASTER: submitting job (2, 0, 3) to dispatcher
21:11:09 DISPATCHER: trying to submit job (2, 0, 3)
21:11:09 DISPATCHER: trying to notify the job_runner thread.
21:11:09 HBMASTER: job (2, 0, 3) submitted to dispatcher
21:11:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:11:09 DISPATCHER: Trying to submit another job.
21:11:09 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
21:11:09 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
21:11:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:11:09 WORKER: start processing job (2, 0, 3)
21:11:09 WORKER: args: ()
21:11:09 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0424126516569951, 'num_filters_1': 34, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.06520707116426992, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 19, 'num_filters_3': 35}, 'budget': 400.0, 'working_directory': '.'}
21:12:03 DISPATCHER: Starting worker discovery
21:12:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:12:03 DISPATCHER: Finished worker discovery
21:13:03 DISPATCHER: Starting worker discovery
21:13:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:13:03 DISPATCHER: Finished worker discovery
21:14:03 DISPATCHER: Starting worker discovery
21:14:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:14:03 DISPATCHER: Finished worker discovery
21:15:03 DISPATCHER: Starting worker discovery
21:15:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:15:03 DISPATCHER: Finished worker discovery
21:16:03 DISPATCHER: Starting worker discovery
21:16:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:16:03 DISPATCHER: Finished worker discovery
21:17:03 DISPATCHER: Starting worker discovery
21:17:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:17:03 DISPATCHER: Finished worker discovery
21:18:03 DISPATCHER: Starting worker discovery
21:18:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:18:03 DISPATCHER: Finished worker discovery
21:18:30 WORKER: done with job (2, 0, 3), trying to register it.
21:18:30 WORKER: registered result for job (2, 0, 3) with dispatcher
21:18:30 DISPATCHER: job (2, 0, 3) finished
21:18:30 DISPATCHER: register_result: lock acquired
21:18:30 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
21:18:30 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0424126516569951, 'num_filters_1': 34, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.06520707116426992, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 19, 'num_filters_3': 35}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.2755272553164638, 'info': {'data03': 0.2755272553164638, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0424126516569951, 'num_filters_1': 34, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.06520707116426992, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 19, 'num_filters_3': 35}"}}
exception: None

21:18:30 job_callback for (2, 0, 3) started
21:18:30 DISPATCHER: Trying to submit another job.
21:18:30 job_callback for (2, 0, 3) got condition
21:18:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:18:30 Only 10 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
21:18:30 HBMASTER: Trying to run another job!
21:18:30 job_callback for (2, 0, 3) finished
21:18:30 start sampling a new configuration.
21:18:30 done sampling a new configuration.
21:18:30 HBMASTER: schedule new run for iteration 2
21:18:30 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
21:18:30 HBMASTER: submitting job (2, 0, 4) to dispatcher
21:18:30 DISPATCHER: trying to submit job (2, 0, 4)
21:18:30 DISPATCHER: trying to notify the job_runner thread.
21:18:30 HBMASTER: job (2, 0, 4) submitted to dispatcher
21:18:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:18:30 DISPATCHER: Trying to submit another job.
21:18:30 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
21:18:30 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
21:18:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:18:30 WORKER: start processing job (2, 0, 4)
21:18:30 WORKER: args: ()
21:18:30 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.019200475736317984, 'num_filters_1': 51, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.19928758203624555, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 18, 'num_filters_3': 17, 'num_filters_4': 83, 'num_filters_5': 16}, 'budget': 400.0, 'working_directory': '.'}
21:19:03 DISPATCHER: Starting worker discovery
21:19:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:19:03 DISPATCHER: Finished worker discovery
21:20:03 DISPATCHER: Starting worker discovery
21:20:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:20:03 DISPATCHER: Finished worker discovery
21:21:03 DISPATCHER: Starting worker discovery
21:21:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:21:03 DISPATCHER: Finished worker discovery
21:22:03 DISPATCHER: Starting worker discovery
21:22:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:22:03 DISPATCHER: Finished worker discovery
21:23:03 DISPATCHER: Starting worker discovery
21:23:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:23:03 DISPATCHER: Finished worker discovery
21:24:03 DISPATCHER: Starting worker discovery
21:24:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:24:03 DISPATCHER: Finished worker discovery
21:25:03 DISPATCHER: Starting worker discovery
21:25:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:25:03 DISPATCHER: Finished worker discovery
21:25:54 WORKER: done with job (2, 0, 4), trying to register it.
21:25:54 WORKER: registered result for job (2, 0, 4) with dispatcher
21:25:54 DISPATCHER: job (2, 0, 4) finished
21:25:54 DISPATCHER: register_result: lock acquired
21:25:54 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
21:25:54 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.019200475736317984, 'num_filters_1': 51, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.19928758203624555, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 18, 'num_filters_3': 17, 'num_filters_4': 83, 'num_filters_5': 16}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.019200475736317984, 'num_filters_1': 51, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.19928758203624555, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 18, 'num_filters_3': 17, 'num_filters_4': 83, 'num_filters_5': 16}"}}
exception: None

21:25:54 job_callback for (2, 0, 4) started
21:25:54 DISPATCHER: Trying to submit another job.
21:25:54 job_callback for (2, 0, 4) got condition
21:25:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:25:54 Only 11 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
21:25:54 HBMASTER: Trying to run another job!
21:25:54 job_callback for (2, 0, 4) finished
21:25:54 start sampling a new configuration.
21:25:54 done sampling a new configuration.
21:25:54 HBMASTER: schedule new run for iteration 2
21:25:54 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
21:25:54 HBMASTER: submitting job (2, 0, 5) to dispatcher
21:25:54 DISPATCHER: trying to submit job (2, 0, 5)
21:25:54 DISPATCHER: trying to notify the job_runner thread.
21:25:54 HBMASTER: job (2, 0, 5) submitted to dispatcher
21:25:54 DISPATCHER: Trying to submit another job.
21:25:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:25:54 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
21:25:54 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
21:25:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:25:54 WORKER: start processing job (2, 0, 5)
21:25:54 WORKER: args: ()
21:25:54 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0657987951594133, 'num_filters_1': 26, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.18903317618241666, 'kernel_size_2': 3, 'num_filters_2': 34}, 'budget': 400.0, 'working_directory': '.'}
21:26:03 DISPATCHER: Starting worker discovery
21:26:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:26:03 DISPATCHER: Finished worker discovery
21:27:03 DISPATCHER: Starting worker discovery
21:27:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:27:03 DISPATCHER: Finished worker discovery
21:28:03 DISPATCHER: Starting worker discovery
21:28:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:28:03 DISPATCHER: Finished worker discovery
21:29:03 DISPATCHER: Starting worker discovery
21:29:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:29:03 DISPATCHER: Finished worker discovery
21:30:03 DISPATCHER: Starting worker discovery
21:30:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:30:03 DISPATCHER: Finished worker discovery
21:31:03 DISPATCHER: Starting worker discovery
21:31:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:31:03 DISPATCHER: Finished worker discovery
21:32:03 DISPATCHER: Starting worker discovery
21:32:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:32:03 DISPATCHER: Finished worker discovery
21:33:03 DISPATCHER: Starting worker discovery
21:33:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:33:03 DISPATCHER: Finished worker discovery
21:33:22 WORKER: done with job (2, 0, 5), trying to register it.
21:33:22 WORKER: registered result for job (2, 0, 5) with dispatcher
21:33:22 DISPATCHER: job (2, 0, 5) finished
21:33:22 DISPATCHER: register_result: lock acquired
21:33:22 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
21:33:22 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0657987951594133, 'num_filters_1': 26, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.18903317618241666, 'kernel_size_2': 3, 'num_filters_2': 34}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.03077322444851186, 'info': {'data03': 0.03077322444851186, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0657987951594133, 'num_filters_1': 26, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.18903317618241666, 'kernel_size_2': 3, 'num_filters_2': 34}"}}
exception: None

21:33:22 job_callback for (2, 0, 5) started
21:33:22 DISPATCHER: Trying to submit another job.
21:33:22 job_callback for (2, 0, 5) got condition
21:33:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:33:22 Only 12 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
21:33:22 HBMASTER: Trying to run another job!
21:33:22 job_callback for (2, 0, 5) finished
21:33:22 ITERATION: Advancing config (2, 0, 1) to next budget 1200.000000
21:33:22 ITERATION: Advancing config (2, 0, 2) to next budget 1200.000000
21:33:22 HBMASTER: schedule new run for iteration 2
21:33:22 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
21:33:22 HBMASTER: submitting job (2, 0, 1) to dispatcher
21:33:22 DISPATCHER: trying to submit job (2, 0, 1)
21:33:22 DISPATCHER: trying to notify the job_runner thread.
21:33:22 HBMASTER: job (2, 0, 1) submitted to dispatcher
21:33:22 DISPATCHER: Trying to submit another job.
21:33:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:33:22 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
21:33:22 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
21:33:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:33:22 WORKER: start processing job (2, 0, 1)
21:33:22 WORKER: args: ()
21:33:22 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001386422806860656, 'num_filters_1': 118, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.042326267379201615}, 'budget': 1200.0, 'working_directory': '.'}
21:34:03 DISPATCHER: Starting worker discovery
21:34:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:34:03 DISPATCHER: Finished worker discovery
21:35:03 DISPATCHER: Starting worker discovery
21:35:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:35:04 DISPATCHER: Finished worker discovery
21:36:04 DISPATCHER: Starting worker discovery
21:36:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:36:04 DISPATCHER: Finished worker discovery
21:37:04 DISPATCHER: Starting worker discovery
21:37:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:37:04 DISPATCHER: Finished worker discovery
21:38:04 DISPATCHER: Starting worker discovery
21:38:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:38:04 DISPATCHER: Finished worker discovery
21:39:04 DISPATCHER: Starting worker discovery
21:39:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:39:04 DISPATCHER: Finished worker discovery
21:40:04 DISPATCHER: Starting worker discovery
21:40:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:40:04 DISPATCHER: Finished worker discovery
21:41:04 DISPATCHER: Starting worker discovery
21:41:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:41:04 DISPATCHER: Finished worker discovery
21:42:04 DISPATCHER: Starting worker discovery
21:42:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:42:04 DISPATCHER: Finished worker discovery
21:43:04 DISPATCHER: Starting worker discovery
21:43:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:43:04 DISPATCHER: Finished worker discovery
21:44:04 DISPATCHER: Starting worker discovery
21:44:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:44:04 DISPATCHER: Finished worker discovery
21:45:04 DISPATCHER: Starting worker discovery
21:45:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:45:04 DISPATCHER: Finished worker discovery
21:46:04 DISPATCHER: Starting worker discovery
21:46:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:46:04 DISPATCHER: Finished worker discovery
21:47:04 DISPATCHER: Starting worker discovery
21:47:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:47:04 DISPATCHER: Finished worker discovery
21:48:04 DISPATCHER: Starting worker discovery
21:48:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:48:04 DISPATCHER: Finished worker discovery
21:49:04 DISPATCHER: Starting worker discovery
21:49:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:49:04 DISPATCHER: Finished worker discovery
21:50:04 DISPATCHER: Starting worker discovery
21:50:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:50:04 DISPATCHER: Finished worker discovery
21:51:04 DISPATCHER: Starting worker discovery
21:51:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:51:04 DISPATCHER: Finished worker discovery
21:52:04 DISPATCHER: Starting worker discovery
21:52:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:52:04 DISPATCHER: Finished worker discovery
21:53:04 DISPATCHER: Starting worker discovery
21:53:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:53:04 DISPATCHER: Finished worker discovery
21:54:04 DISPATCHER: Starting worker discovery
21:54:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:54:04 DISPATCHER: Finished worker discovery
21:54:13 WORKER: done with job (2, 0, 1), trying to register it.
21:54:13 WORKER: registered result for job (2, 0, 1) with dispatcher
21:54:13 DISPATCHER: job (2, 0, 1) finished
21:54:13 DISPATCHER: register_result: lock acquired
21:54:13 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
21:54:13 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001386422806860656, 'num_filters_1': 118, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.042326267379201615}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.3357394845369494, 'info': {'data03': 0.3357394845369494, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.001386422806860656, 'num_filters_1': 118, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.042326267379201615}"}}
exception: None

21:54:13 job_callback for (2, 0, 1) started
21:54:13 job_callback for (2, 0, 1) got condition
21:54:13 DISPATCHER: Trying to submit another job.
21:54:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:54:13 Only 3 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
21:54:13 HBMASTER: Trying to run another job!
21:54:13 job_callback for (2, 0, 1) finished
21:54:13 HBMASTER: schedule new run for iteration 2
21:54:13 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
21:54:13 HBMASTER: submitting job (2, 0, 2) to dispatcher
21:54:13 DISPATCHER: trying to submit job (2, 0, 2)
21:54:13 DISPATCHER: trying to notify the job_runner thread.
21:54:13 HBMASTER: job (2, 0, 2) submitted to dispatcher
21:54:13 DISPATCHER: Trying to submit another job.
21:54:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:54:13 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
21:54:13 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
21:54:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:54:13 WORKER: start processing job (2, 0, 2)
21:54:13 WORKER: args: ()
21:54:13 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.015111411870906952, 'num_filters_1': 29, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.04949794574478917, 'kernel_size_2': 7, 'num_filters_2': 44}, 'budget': 1200.0, 'working_directory': '.'}
21:55:04 DISPATCHER: Starting worker discovery
21:55:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:55:04 DISPATCHER: Finished worker discovery
21:56:04 DISPATCHER: Starting worker discovery
21:56:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:56:04 DISPATCHER: Finished worker discovery
21:57:04 DISPATCHER: Starting worker discovery
21:57:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:57:04 DISPATCHER: Finished worker discovery
21:58:04 DISPATCHER: Starting worker discovery
21:58:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:58:04 DISPATCHER: Finished worker discovery
21:59:04 DISPATCHER: Starting worker discovery
21:59:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:59:04 DISPATCHER: Finished worker discovery
22:00:04 DISPATCHER: Starting worker discovery
22:00:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:00:04 DISPATCHER: Finished worker discovery
22:01:04 DISPATCHER: Starting worker discovery
22:01:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:01:04 DISPATCHER: Finished worker discovery
22:02:04 DISPATCHER: Starting worker discovery
22:02:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:02:04 DISPATCHER: Finished worker discovery
22:03:04 DISPATCHER: Starting worker discovery
22:03:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:03:04 DISPATCHER: Finished worker discovery
22:04:04 DISPATCHER: Starting worker discovery
22:04:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:04:04 DISPATCHER: Finished worker discovery
22:05:04 DISPATCHER: Starting worker discovery
22:05:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:05:04 DISPATCHER: Finished worker discovery
22:06:04 DISPATCHER: Starting worker discovery
22:06:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:06:04 DISPATCHER: Finished worker discovery
22:07:04 DISPATCHER: Starting worker discovery
22:07:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:07:04 DISPATCHER: Finished worker discovery
22:08:04 DISPATCHER: Starting worker discovery
22:08:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:08:04 DISPATCHER: Finished worker discovery
22:09:04 DISPATCHER: Starting worker discovery
22:09:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:09:04 DISPATCHER: Finished worker discovery
22:10:04 DISPATCHER: Starting worker discovery
22:10:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:10:04 DISPATCHER: Finished worker discovery
22:11:04 DISPATCHER: Starting worker discovery
22:11:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:11:04 DISPATCHER: Finished worker discovery
22:12:04 DISPATCHER: Starting worker discovery
22:12:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:12:04 DISPATCHER: Finished worker discovery
22:13:04 DISPATCHER: Starting worker discovery
22:13:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:13:04 DISPATCHER: Finished worker discovery
22:14:04 DISPATCHER: Starting worker discovery
22:14:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:14:04 DISPATCHER: Finished worker discovery
22:14:58 WORKER: done with job (2, 0, 2), trying to register it.
22:14:58 WORKER: registered result for job (2, 0, 2) with dispatcher
22:14:58 DISPATCHER: job (2, 0, 2) finished
22:14:58 DISPATCHER: register_result: lock acquired
22:14:58 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:14:58 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.015111411870906952, 'num_filters_1': 29, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.04949794574478917, 'kernel_size_2': 7, 'num_filters_2': 44}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.2818340978846967, 'info': {'data03': 0.2818340978846967, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.015111411870906952, 'num_filters_1': 29, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.04949794574478917, 'kernel_size_2': 7, 'num_filters_2': 44}"}}
exception: None

22:14:58 job_callback for (2, 0, 2) started
22:14:58 DISPATCHER: Trying to submit another job.
22:14:58 job_callback for (2, 0, 2) got condition
22:14:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:14:58 Only 4 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
22:14:58 HBMASTER: Trying to run another job!
22:14:58 job_callback for (2, 0, 2) finished
22:14:58 start sampling a new configuration.
22:14:58 done sampling a new configuration.
22:14:58 HBMASTER: schedule new run for iteration 3
22:14:58 HBMASTER: trying submitting job (3, 0, 0) to dispatcher
22:14:58 HBMASTER: submitting job (3, 0, 0) to dispatcher
22:14:58 DISPATCHER: trying to submit job (3, 0, 0)
22:14:58 DISPATCHER: trying to notify the job_runner thread.
22:14:58 HBMASTER: job (3, 0, 0) submitted to dispatcher
22:14:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:14:58 DISPATCHER: Trying to submit another job.
22:14:58 DISPATCHER: starting job (3, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:14:58 DISPATCHER: job (3, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:14:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:14:58 WORKER: start processing job (3, 0, 0)
22:14:58 WORKER: args: ()
22:14:58 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.00800880520250539, 'num_filters_1': 94, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.07394662756503369, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 53, 'num_filters_3': 21}, 'budget': 1200.0, 'working_directory': '.'}
22:15:04 DISPATCHER: Starting worker discovery
22:15:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:15:04 DISPATCHER: Finished worker discovery
22:16:04 DISPATCHER: Starting worker discovery
22:16:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:16:04 DISPATCHER: Finished worker discovery
22:17:04 DISPATCHER: Starting worker discovery
22:17:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:17:04 DISPATCHER: Finished worker discovery
22:18:04 DISPATCHER: Starting worker discovery
22:18:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:18:04 DISPATCHER: Finished worker discovery
22:19:04 DISPATCHER: Starting worker discovery
22:19:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:19:04 DISPATCHER: Finished worker discovery
22:20:04 DISPATCHER: Starting worker discovery
22:20:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:20:04 DISPATCHER: Finished worker discovery
22:21:04 DISPATCHER: Starting worker discovery
22:21:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:21:04 DISPATCHER: Finished worker discovery
22:22:04 DISPATCHER: Starting worker discovery
22:22:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:22:04 DISPATCHER: Finished worker discovery
22:23:04 DISPATCHER: Starting worker discovery
22:23:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:23:04 DISPATCHER: Finished worker discovery
22:24:04 DISPATCHER: Starting worker discovery
22:24:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:24:04 DISPATCHER: Finished worker discovery
22:25:04 DISPATCHER: Starting worker discovery
22:25:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:25:04 DISPATCHER: Finished worker discovery
22:26:04 DISPATCHER: Starting worker discovery
22:26:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:26:04 DISPATCHER: Finished worker discovery
22:27:04 DISPATCHER: Starting worker discovery
22:27:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:27:04 DISPATCHER: Finished worker discovery
22:28:04 DISPATCHER: Starting worker discovery
22:28:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:28:04 DISPATCHER: Finished worker discovery
22:29:04 DISPATCHER: Starting worker discovery
22:29:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:29:04 DISPATCHER: Finished worker discovery
22:30:04 DISPATCHER: Starting worker discovery
22:30:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:30:04 DISPATCHER: Finished worker discovery
22:31:04 DISPATCHER: Starting worker discovery
22:31:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:31:04 DISPATCHER: Finished worker discovery
22:32:04 DISPATCHER: Starting worker discovery
22:32:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:32:04 DISPATCHER: Finished worker discovery
22:33:04 DISPATCHER: Starting worker discovery
22:33:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:33:04 DISPATCHER: Finished worker discovery
22:34:04 DISPATCHER: Starting worker discovery
22:34:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:34:04 DISPATCHER: Finished worker discovery
22:35:04 DISPATCHER: Starting worker discovery
22:35:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:35:04 DISPATCHER: Finished worker discovery
22:35:46 WORKER: done with job (3, 0, 0), trying to register it.
22:35:46 WORKER: registered result for job (3, 0, 0) with dispatcher
22:35:46 DISPATCHER: job (3, 0, 0) finished
22:35:46 DISPATCHER: register_result: lock acquired
22:35:46 DISPATCHER: job (3, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:35:46 job_id: (3, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.00800880520250539, 'num_filters_1': 94, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.07394662756503369, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 53, 'num_filters_3': 21}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.21522904970868512, 'info': {'data03': 0.21522904970868512, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.00800880520250539, 'num_filters_1': 94, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 52, 'weight_decay': 0.07394662756503369, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 53, 'num_filters_3': 21}"}}
exception: None

22:35:46 job_callback for (3, 0, 0) started
22:35:46 job_callback for (3, 0, 0) got condition
22:35:46 DISPATCHER: Trying to submit another job.
22:35:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:35:46 Only 5 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
22:35:46 HBMASTER: Trying to run another job!
22:35:46 job_callback for (3, 0, 0) finished
22:35:46 start sampling a new configuration.
22:35:46 done sampling a new configuration.
22:35:46 HBMASTER: schedule new run for iteration 3
22:35:46 HBMASTER: trying submitting job (3, 0, 1) to dispatcher
22:35:46 HBMASTER: submitting job (3, 0, 1) to dispatcher
22:35:46 DISPATCHER: trying to submit job (3, 0, 1)
22:35:46 DISPATCHER: trying to notify the job_runner thread.
22:35:46 HBMASTER: job (3, 0, 1) submitted to dispatcher
22:35:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:35:46 DISPATCHER: Trying to submit another job.
22:35:46 DISPATCHER: starting job (3, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:35:46 DISPATCHER: job (3, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:35:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:35:46 WORKER: start processing job (3, 0, 1)
22:35:46 WORKER: args: ()
22:35:46 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0946996552401023, 'num_filters_1': 57, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.01887157928102781}, 'budget': 1200.0, 'working_directory': '.'}
22:36:04 DISPATCHER: Starting worker discovery
22:36:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:36:04 DISPATCHER: Finished worker discovery
22:37:04 DISPATCHER: Starting worker discovery
22:37:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:37:05 DISPATCHER: Finished worker discovery
22:38:05 DISPATCHER: Starting worker discovery
22:38:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:38:05 DISPATCHER: Finished worker discovery
22:39:05 DISPATCHER: Starting worker discovery
22:39:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:39:05 DISPATCHER: Finished worker discovery
22:40:05 DISPATCHER: Starting worker discovery
22:40:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:40:05 DISPATCHER: Finished worker discovery
22:41:05 DISPATCHER: Starting worker discovery
22:41:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:41:05 DISPATCHER: Finished worker discovery
22:42:05 DISPATCHER: Starting worker discovery
22:42:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:42:05 DISPATCHER: Finished worker discovery
22:43:05 DISPATCHER: Starting worker discovery
22:43:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:43:05 DISPATCHER: Finished worker discovery
22:44:05 DISPATCHER: Starting worker discovery
22:44:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:44:05 DISPATCHER: Finished worker discovery
22:45:05 DISPATCHER: Starting worker discovery
22:45:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:45:05 DISPATCHER: Finished worker discovery
22:46:05 DISPATCHER: Starting worker discovery
22:46:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:46:05 DISPATCHER: Finished worker discovery
22:47:05 DISPATCHER: Starting worker discovery
22:47:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:47:05 DISPATCHER: Finished worker discovery
22:48:05 DISPATCHER: Starting worker discovery
22:48:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:48:05 DISPATCHER: Finished worker discovery
22:49:05 DISPATCHER: Starting worker discovery
22:49:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:49:05 DISPATCHER: Finished worker discovery
22:50:05 DISPATCHER: Starting worker discovery
22:50:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:50:05 DISPATCHER: Finished worker discovery
22:51:05 DISPATCHER: Starting worker discovery
22:51:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:51:05 DISPATCHER: Finished worker discovery
22:52:05 DISPATCHER: Starting worker discovery
22:52:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:52:05 DISPATCHER: Finished worker discovery
22:53:05 DISPATCHER: Starting worker discovery
22:53:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:53:05 DISPATCHER: Finished worker discovery
22:54:05 DISPATCHER: Starting worker discovery
22:54:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:54:05 DISPATCHER: Finished worker discovery
22:55:05 DISPATCHER: Starting worker discovery
22:55:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:55:05 DISPATCHER: Finished worker discovery
22:56:05 DISPATCHER: Starting worker discovery
22:56:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:56:05 DISPATCHER: Finished worker discovery
22:56:34 WORKER: done with job (3, 0, 1), trying to register it.
22:56:34 WORKER: registered result for job (3, 0, 1) with dispatcher
22:56:34 DISPATCHER: job (3, 0, 1) finished
22:56:34 DISPATCHER: register_result: lock acquired
22:56:34 DISPATCHER: job (3, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
22:56:34 job_id: (3, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0946996552401023, 'num_filters_1': 57, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.01887157928102781}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.24084017136262292, 'info': {'data03': 0.24084017136262292, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0946996552401023, 'num_filters_1': 57, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.01887157928102781}"}}
exception: None

22:56:34 job_callback for (3, 0, 1) started
22:56:34 DISPATCHER: Trying to submit another job.
22:56:34 job_callback for (3, 0, 1) got condition
22:56:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:56:35 Only 6 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
22:56:35 HBMASTER: Trying to run another job!
22:56:35 job_callback for (3, 0, 1) finished
22:56:35 start sampling a new configuration.
22:56:35 done sampling a new configuration.
22:56:35 HBMASTER: schedule new run for iteration 3
22:56:35 HBMASTER: trying submitting job (3, 0, 2) to dispatcher
22:56:35 HBMASTER: submitting job (3, 0, 2) to dispatcher
22:56:35 DISPATCHER: trying to submit job (3, 0, 2)
22:56:35 DISPATCHER: trying to notify the job_runner thread.
22:56:35 HBMASTER: job (3, 0, 2) submitted to dispatcher
22:56:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:56:35 DISPATCHER: Trying to submit another job.
22:56:35 DISPATCHER: starting job (3, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
22:56:35 DISPATCHER: job (3, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
22:56:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:56:35 WORKER: start processing job (3, 0, 2)
22:56:35 WORKER: args: ()
22:56:35 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0013831934798312737, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.0323031862480074, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 32, 'num_filters_3': 24, 'num_filters_4': 28}, 'budget': 1200.0, 'working_directory': '.'}
22:57:05 DISPATCHER: Starting worker discovery
22:57:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:57:05 DISPATCHER: Finished worker discovery
22:58:05 DISPATCHER: Starting worker discovery
22:58:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:58:05 DISPATCHER: Finished worker discovery
22:59:05 DISPATCHER: Starting worker discovery
22:59:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:59:05 DISPATCHER: Finished worker discovery
23:00:05 DISPATCHER: Starting worker discovery
23:00:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:00:05 DISPATCHER: Finished worker discovery
23:01:05 DISPATCHER: Starting worker discovery
23:01:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:01:05 DISPATCHER: Finished worker discovery
23:02:05 DISPATCHER: Starting worker discovery
23:02:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:02:05 DISPATCHER: Finished worker discovery
23:03:05 DISPATCHER: Starting worker discovery
23:03:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:03:05 DISPATCHER: Finished worker discovery
23:04:05 DISPATCHER: Starting worker discovery
23:04:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:04:05 DISPATCHER: Finished worker discovery
23:05:05 DISPATCHER: Starting worker discovery
23:05:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:05:05 DISPATCHER: Finished worker discovery
23:06:05 DISPATCHER: Starting worker discovery
23:06:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:06:05 DISPATCHER: Finished worker discovery
23:07:05 DISPATCHER: Starting worker discovery
23:07:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:07:05 DISPATCHER: Finished worker discovery
23:08:05 DISPATCHER: Starting worker discovery
23:08:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:08:05 DISPATCHER: Finished worker discovery
23:09:05 DISPATCHER: Starting worker discovery
23:09:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:09:05 DISPATCHER: Finished worker discovery
23:10:05 DISPATCHER: Starting worker discovery
23:10:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:10:05 DISPATCHER: Finished worker discovery
23:11:05 DISPATCHER: Starting worker discovery
23:11:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:11:05 DISPATCHER: Finished worker discovery
23:12:05 DISPATCHER: Starting worker discovery
23:12:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:12:05 DISPATCHER: Finished worker discovery
23:13:05 DISPATCHER: Starting worker discovery
23:13:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:13:05 DISPATCHER: Finished worker discovery
23:14:05 DISPATCHER: Starting worker discovery
23:14:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:14:05 DISPATCHER: Finished worker discovery
23:15:05 DISPATCHER: Starting worker discovery
23:15:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:15:05 DISPATCHER: Finished worker discovery
23:16:05 DISPATCHER: Starting worker discovery
23:16:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:16:05 DISPATCHER: Finished worker discovery
23:17:05 DISPATCHER: Starting worker discovery
23:17:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:17:05 DISPATCHER: Finished worker discovery
23:17:26 WORKER: done with job (3, 0, 2), trying to register it.
23:17:26 WORKER: registered result for job (3, 0, 2) with dispatcher
23:17:26 DISPATCHER: job (3, 0, 2) finished
23:17:26 DISPATCHER: register_result: lock acquired
23:17:26 DISPATCHER: job (3, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
23:17:26 job_id: (3, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0013831934798312737, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.0323031862480074, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 32, 'num_filters_3': 24, 'num_filters_4': 28}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.3866111256816192, 'info': {'data03': 0.3866111256816192, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0013831934798312737, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.0323031862480074, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 32, 'num_filters_3': 24, 'num_filters_4': 28}"}}
exception: None

23:17:26 job_callback for (3, 0, 2) started
23:17:26 DISPATCHER: Trying to submit another job.
23:17:26 job_callback for (3, 0, 2) got condition
23:17:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:17:26 Only 7 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
23:17:26 HBMASTER: Trying to run another job!
23:17:26 job_callback for (3, 0, 2) finished
23:17:26 start sampling a new configuration.
23:17:26 done sampling a new configuration.
23:17:26 HBMASTER: schedule new run for iteration 3
23:17:26 HBMASTER: trying submitting job (3, 0, 3) to dispatcher
23:17:26 HBMASTER: submitting job (3, 0, 3) to dispatcher
23:17:26 DISPATCHER: trying to submit job (3, 0, 3)
23:17:26 DISPATCHER: trying to notify the job_runner thread.
23:17:26 HBMASTER: job (3, 0, 3) submitted to dispatcher
23:17:26 DISPATCHER: Trying to submit another job.
23:17:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:17:26 DISPATCHER: starting job (3, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
23:17:26 DISPATCHER: job (3, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
23:17:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:17:26 WORKER: start processing job (3, 0, 3)
23:17:26 WORKER: args: ()
23:17:26 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.02130322420717194, 'num_filters_1': 38, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.030941892645687287, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 112, 'num_filters_3': 33, 'num_filters_4': 52}, 'budget': 1200.0, 'working_directory': '.'}
23:18:05 DISPATCHER: Starting worker discovery
23:18:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:18:05 DISPATCHER: Finished worker discovery
23:19:05 DISPATCHER: Starting worker discovery
23:19:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:19:05 DISPATCHER: Finished worker discovery
23:20:05 DISPATCHER: Starting worker discovery
23:20:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:20:05 DISPATCHER: Finished worker discovery
23:21:05 DISPATCHER: Starting worker discovery
23:21:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:21:05 DISPATCHER: Finished worker discovery
23:22:05 DISPATCHER: Starting worker discovery
23:22:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:22:05 DISPATCHER: Finished worker discovery
23:23:05 DISPATCHER: Starting worker discovery
23:23:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:23:05 DISPATCHER: Finished worker discovery
23:24:05 DISPATCHER: Starting worker discovery
23:24:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:24:05 DISPATCHER: Finished worker discovery
23:25:05 DISPATCHER: Starting worker discovery
23:25:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:25:05 DISPATCHER: Finished worker discovery
23:26:05 DISPATCHER: Starting worker discovery
23:26:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:26:05 DISPATCHER: Finished worker discovery
23:27:05 DISPATCHER: Starting worker discovery
23:27:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:27:05 DISPATCHER: Finished worker discovery
23:28:05 DISPATCHER: Starting worker discovery
23:28:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:28:05 DISPATCHER: Finished worker discovery
23:29:05 DISPATCHER: Starting worker discovery
23:29:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:29:05 DISPATCHER: Finished worker discovery
23:30:05 DISPATCHER: Starting worker discovery
23:30:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:30:05 DISPATCHER: Finished worker discovery
23:31:05 DISPATCHER: Starting worker discovery
23:31:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:31:05 DISPATCHER: Finished worker discovery
23:32:05 DISPATCHER: Starting worker discovery
23:32:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:32:05 DISPATCHER: Finished worker discovery
23:33:05 DISPATCHER: Starting worker discovery
23:33:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:33:05 DISPATCHER: Finished worker discovery
23:34:05 DISPATCHER: Starting worker discovery
23:34:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:34:05 DISPATCHER: Finished worker discovery
23:35:05 DISPATCHER: Starting worker discovery
23:35:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:35:05 DISPATCHER: Finished worker discovery
23:36:05 DISPATCHER: Starting worker discovery
23:36:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:36:05 DISPATCHER: Finished worker discovery
23:37:05 DISPATCHER: Starting worker discovery
23:37:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:37:06 DISPATCHER: Finished worker discovery
23:38:06 DISPATCHER: Starting worker discovery
23:38:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:38:06 DISPATCHER: Finished worker discovery
23:38:25 WORKER: done with job (3, 0, 3), trying to register it.
23:38:25 WORKER: registered result for job (3, 0, 3) with dispatcher
23:38:25 DISPATCHER: job (3, 0, 3) finished
23:38:25 DISPATCHER: register_result: lock acquired
23:38:25 DISPATCHER: job (3, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
23:38:25 job_id: (3, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.02130322420717194, 'num_filters_1': 38, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.030941892645687287, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 112, 'num_filters_3': 33, 'num_filters_4': 52}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0006784701809330396, 'info': {'data03': 0.0006784701809330396, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.02130322420717194, 'num_filters_1': 38, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.030941892645687287, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 112, 'num_filters_3': 33, 'num_filters_4': 52}"}}
exception: None

23:38:25 job_callback for (3, 0, 3) started
23:38:25 DISPATCHER: Trying to submit another job.
23:38:25 job_callback for (3, 0, 3) got condition
23:38:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:38:25 Only 8 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
23:38:25 HBMASTER: Trying to run another job!
23:38:25 job_callback for (3, 0, 3) finished
23:38:25 start sampling a new configuration.
23:38:25 done sampling a new configuration.
23:38:25 HBMASTER: schedule new run for iteration 4
23:38:25 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
23:38:25 HBMASTER: submitting job (4, 0, 0) to dispatcher
23:38:25 DISPATCHER: trying to submit job (4, 0, 0)
23:38:25 DISPATCHER: trying to notify the job_runner thread.
23:38:25 HBMASTER: job (4, 0, 0) submitted to dispatcher
23:38:25 DISPATCHER: Trying to submit another job.
23:38:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:38:25 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
23:38:25 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
23:38:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:38:25 WORKER: start processing job (4, 0, 0)
23:38:25 WORKER: args: ()
23:38:25 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.010966372343185038, 'num_filters_1': 70, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.04851033162350718, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 62, 'num_filters_3': 29, 'num_filters_4': 98, 'num_filters_5': 115}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:39:06 DISPATCHER: Starting worker discovery
23:39:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:39:06 DISPATCHER: Finished worker discovery
23:40:02 WORKER: done with job (4, 0, 0), trying to register it.
23:40:02 WORKER: registered result for job (4, 0, 0) with dispatcher
23:40:02 DISPATCHER: job (4, 0, 0) finished
23:40:02 DISPATCHER: register_result: lock acquired
23:40:02 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
23:40:02 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.010966372343185038, 'num_filters_1': 70, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.04851033162350718, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 62, 'num_filters_3': 29, 'num_filters_4': 98, 'num_filters_5': 115}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.36385708822514684, 'info': {'data03': 0.36385708822514684, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.010966372343185038, 'num_filters_1': 70, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.04851033162350718, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 62, 'num_filters_3': 29, 'num_filters_4': 98, 'num_filters_5': 115}"}}
exception: None

23:40:02 job_callback for (4, 0, 0) started
23:40:02 DISPATCHER: Trying to submit another job.
23:40:02 job_callback for (4, 0, 0) got condition
23:40:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:40:02 HBMASTER: Trying to run another job!
23:40:02 job_callback for (4, 0, 0) finished
23:40:02 start sampling a new configuration.
23:40:02 done sampling a new configuration.
23:40:02 HBMASTER: schedule new run for iteration 4
23:40:02 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
23:40:02 HBMASTER: submitting job (4, 0, 1) to dispatcher
23:40:02 DISPATCHER: trying to submit job (4, 0, 1)
23:40:02 DISPATCHER: trying to notify the job_runner thread.
23:40:02 HBMASTER: job (4, 0, 1) submitted to dispatcher
23:40:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:40:02 DISPATCHER: Trying to submit another job.
23:40:02 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
23:40:02 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
23:40:02 WORKER: start processing job (4, 0, 1)
23:40:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:40:02 WORKER: args: ()
23:40:02 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.061706805097615114, 'num_filters_1': 35, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.035427588212248305, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 60, 'num_filters_3': 69}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:40:06 DISPATCHER: Starting worker discovery
23:40:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:40:06 DISPATCHER: Finished worker discovery
23:41:06 DISPATCHER: Starting worker discovery
23:41:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:41:06 DISPATCHER: Finished worker discovery
23:41:36 WORKER: done with job (4, 0, 1), trying to register it.
23:41:36 WORKER: registered result for job (4, 0, 1) with dispatcher
23:41:36 DISPATCHER: job (4, 0, 1) finished
23:41:36 DISPATCHER: register_result: lock acquired
23:41:36 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
23:41:36 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.061706805097615114, 'num_filters_1': 35, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.035427588212248305, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 60, 'num_filters_3': 69}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.290155613722332, 'info': {'data03': 0.290155613722332, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.061706805097615114, 'num_filters_1': 35, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.035427588212248305, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 60, 'num_filters_3': 69}"}}
exception: None

23:41:36 job_callback for (4, 0, 1) started
23:41:36 job_callback for (4, 0, 1) got condition
23:41:36 DISPATCHER: Trying to submit another job.
23:41:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:41:36 HBMASTER: Trying to run another job!
23:41:36 job_callback for (4, 0, 1) finished
23:41:36 start sampling a new configuration.
23:41:36 done sampling a new configuration.
23:41:36 HBMASTER: schedule new run for iteration 4
23:41:36 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
23:41:36 HBMASTER: submitting job (4, 0, 2) to dispatcher
23:41:36 DISPATCHER: trying to submit job (4, 0, 2)
23:41:36 DISPATCHER: trying to notify the job_runner thread.
23:41:36 HBMASTER: job (4, 0, 2) submitted to dispatcher
23:41:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:41:36 DISPATCHER: Trying to submit another job.
23:41:36 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
23:41:36 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
23:41:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:41:36 WORKER: start processing job (4, 0, 2)
23:41:36 WORKER: args: ()
23:41:36 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004383507818056009, 'num_filters_1': 58, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.038739849792668084, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 31, 'num_filters_3': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:42:06 DISPATCHER: Starting worker discovery
23:42:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:42:06 DISPATCHER: Finished worker discovery
23:43:06 DISPATCHER: Starting worker discovery
23:43:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:43:06 DISPATCHER: Finished worker discovery
23:43:06 WORKER: done with job (4, 0, 2), trying to register it.
23:43:06 WORKER: registered result for job (4, 0, 2) with dispatcher
23:43:06 DISPATCHER: job (4, 0, 2) finished
23:43:06 DISPATCHER: register_result: lock acquired
23:43:06 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
23:43:06 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004383507818056009, 'num_filters_1': 58, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.038739849792668084, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 31, 'num_filters_3': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.41909361897821107, 'info': {'data03': 0.41909361897821107, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004383507818056009, 'num_filters_1': 58, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.038739849792668084, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 31, 'num_filters_3': 19}"}}
exception: None

23:43:06 job_callback for (4, 0, 2) started
23:43:06 DISPATCHER: Trying to submit another job.
23:43:06 job_callback for (4, 0, 2) got condition
23:43:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:43:06 HBMASTER: Trying to run another job!
23:43:06 job_callback for (4, 0, 2) finished
23:43:06 start sampling a new configuration.
23:43:06 done sampling a new configuration.
23:43:06 HBMASTER: schedule new run for iteration 4
23:43:06 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
23:43:06 HBMASTER: submitting job (4, 0, 3) to dispatcher
23:43:06 DISPATCHER: trying to submit job (4, 0, 3)
23:43:06 DISPATCHER: trying to notify the job_runner thread.
23:43:06 HBMASTER: job (4, 0, 3) submitted to dispatcher
23:43:06 DISPATCHER: Trying to submit another job.
23:43:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:43:06 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
23:43:06 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
23:43:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:43:06 WORKER: start processing job (4, 0, 3)
23:43:06 WORKER: args: ()
23:43:06 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0189881875264031, 'num_filters_1': 118, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.02264943446084651, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 19, 'num_filters_3': 91}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:44:06 DISPATCHER: Starting worker discovery
23:44:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:44:06 DISPATCHER: Finished worker discovery
23:44:40 WORKER: done with job (4, 0, 3), trying to register it.
23:44:40 WORKER: registered result for job (4, 0, 3) with dispatcher
23:44:40 DISPATCHER: job (4, 0, 3) finished
23:44:40 DISPATCHER: register_result: lock acquired
23:44:40 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
23:44:40 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0189881875264031, 'num_filters_1': 118, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.02264943446084651, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 19, 'num_filters_3': 91}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.30735665785507216, 'info': {'data03': 0.30735665785507216, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0189881875264031, 'num_filters_1': 118, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.02264943446084651, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 19, 'num_filters_3': 91}"}}
exception: None

23:44:40 job_callback for (4, 0, 3) started
23:44:40 job_callback for (4, 0, 3) got condition
23:44:40 DISPATCHER: Trying to submit another job.
23:44:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:44:40 HBMASTER: Trying to run another job!
23:44:40 job_callback for (4, 0, 3) finished
23:44:40 start sampling a new configuration.
23:44:40 done sampling a new configuration.
23:44:40 HBMASTER: schedule new run for iteration 4
23:44:40 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
23:44:40 HBMASTER: submitting job (4, 0, 4) to dispatcher
23:44:40 DISPATCHER: trying to submit job (4, 0, 4)
23:44:40 DISPATCHER: trying to notify the job_runner thread.
23:44:40 HBMASTER: job (4, 0, 4) submitted to dispatcher
23:44:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:44:40 DISPATCHER: Trying to submit another job.
23:44:40 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
23:44:40 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
23:44:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:44:40 WORKER: start processing job (4, 0, 4)
23:44:40 WORKER: args: ()
23:44:40 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0024810043463368322, 'num_filters_1': 21, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.02645413450645999, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 34, 'num_filters_3': 23, 'num_filters_4': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:45:06 DISPATCHER: Starting worker discovery
23:45:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:45:06 DISPATCHER: Finished worker discovery
23:46:06 DISPATCHER: Starting worker discovery
23:46:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:46:06 DISPATCHER: Finished worker discovery
23:46:09 WORKER: done with job (4, 0, 4), trying to register it.
23:46:09 WORKER: registered result for job (4, 0, 4) with dispatcher
23:46:09 DISPATCHER: job (4, 0, 4) finished
23:46:09 DISPATCHER: register_result: lock acquired
23:46:09 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
23:46:09 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0024810043463368322, 'num_filters_1': 21, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.02645413450645999, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 34, 'num_filters_3': 23, 'num_filters_4': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3477088610157073, 'info': {'data03': 0.3477088610157073, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0024810043463368322, 'num_filters_1': 21, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.02645413450645999, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 34, 'num_filters_3': 23, 'num_filters_4': 23}"}}
exception: None

23:46:09 job_callback for (4, 0, 4) started
23:46:09 job_callback for (4, 0, 4) got condition
23:46:09 DISPATCHER: Trying to submit another job.
23:46:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:46:09 HBMASTER: Trying to run another job!
23:46:09 job_callback for (4, 0, 4) finished
23:46:09 start sampling a new configuration.
23:46:09 done sampling a new configuration.
23:46:09 HBMASTER: schedule new run for iteration 4
23:46:09 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
23:46:09 HBMASTER: submitting job (4, 0, 5) to dispatcher
23:46:09 DISPATCHER: trying to submit job (4, 0, 5)
23:46:09 DISPATCHER: trying to notify the job_runner thread.
23:46:09 HBMASTER: job (4, 0, 5) submitted to dispatcher
23:46:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:46:09 DISPATCHER: Trying to submit another job.
23:46:09 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
23:46:09 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
23:46:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:46:09 WORKER: start processing job (4, 0, 5)
23:46:09 WORKER: args: ()
23:46:09 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.031531191396021084, 'num_filters_1': 37, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.023904500528446122, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 63, 'num_filters_3': 114}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:47:06 DISPATCHER: Starting worker discovery
23:47:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:47:06 DISPATCHER: Finished worker discovery
23:47:36 WORKER: done with job (4, 0, 5), trying to register it.
23:47:36 WORKER: registered result for job (4, 0, 5) with dispatcher
23:47:36 DISPATCHER: job (4, 0, 5) finished
23:47:36 DISPATCHER: register_result: lock acquired
23:47:36 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
23:47:36 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.031531191396021084, 'num_filters_1': 37, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.023904500528446122, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 63, 'num_filters_3': 114}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.34217924520263565, 'info': {'data03': 0.34217924520263565, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.031531191396021084, 'num_filters_1': 37, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.023904500528446122, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 63, 'num_filters_3': 114}"}}
exception: None

23:47:36 job_callback for (4, 0, 5) started
23:47:36 DISPATCHER: Trying to submit another job.
23:47:36 job_callback for (4, 0, 5) got condition
23:47:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:47:36 HBMASTER: Trying to run another job!
23:47:36 job_callback for (4, 0, 5) finished
23:47:36 start sampling a new configuration.
23:47:36 done sampling a new configuration.
23:47:36 HBMASTER: schedule new run for iteration 4
23:47:36 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
23:47:36 HBMASTER: submitting job (4, 0, 6) to dispatcher
23:47:36 DISPATCHER: trying to submit job (4, 0, 6)
23:47:36 DISPATCHER: trying to notify the job_runner thread.
23:47:36 HBMASTER: job (4, 0, 6) submitted to dispatcher
23:47:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:47:36 DISPATCHER: Trying to submit another job.
23:47:36 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776
23:47:36 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
23:47:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:47:36 WORKER: start processing job (4, 0, 6)
23:47:36 WORKER: args: ()
23:47:36 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00858902351505486, 'num_filters_1': 76, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.13176176519858293, 'kernel_size_2': 5, 'num_filters_2': 54}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:48:06 DISPATCHER: Starting worker discovery
23:48:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:48:06 DISPATCHER: Finished worker discovery
23:49:06 DISPATCHER: Starting worker discovery
23:49:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:49:06 DISPATCHER: Finished worker discovery
23:49:09 WORKER: done with job (4, 0, 6), trying to register it.
23:49:09 WORKER: registered result for job (4, 0, 6) with dispatcher
23:49:09 DISPATCHER: job (4, 0, 6) finished
23:49:09 DISPATCHER: register_result: lock acquired
23:49:09 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
23:49:09 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00858902351505486, 'num_filters_1': 76, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.13176176519858293, 'kernel_size_2': 5, 'num_filters_2': 54}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3071929462465972, 'info': {'data03': 0.3071929462465972, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00858902351505486, 'num_filters_1': 76, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.13176176519858293, 'kernel_size_2': 5, 'num_filters_2': 54}"}}
exception: None

23:49:09 job_callback for (4, 0, 6) started
23:49:09 DISPATCHER: Trying to submit another job.
23:49:09 job_callback for (4, 0, 6) got condition
23:49:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:49:09 done building a new model for budget 44.444444 based on 17/28 split
Best loss for this budget:-0.460261





23:49:09 HBMASTER: Trying to run another job!
23:49:09 job_callback for (4, 0, 6) finished
23:49:09 start sampling a new configuration.
23:49:09 done sampling a new configuration.
23:49:10 HBMASTER: schedule new run for iteration 4
23:49:10 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
23:49:10 HBMASTER: submitting job (4, 0, 7) to dispatcher
23:49:10 DISPATCHER: trying to submit job (4, 0, 7)
23:49:10 DISPATCHER: trying to notify the job_runner thread.
23:49:10 HBMASTER: job (4, 0, 7) submitted to dispatcher
23:49:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:49:10 DISPATCHER: Trying to submit another job.
23:49:10 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776
23:49:10 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
23:49:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:49:10 WORKER: start processing job (4, 0, 7)
23:49:10 WORKER: args: ()
23:49:10 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.05506072410795557, 'num_filters_1': 77, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.018568694104627432, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 69, 'num_filters_3': 29, 'num_filters_4': 62, 'num_filters_5': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:50:06 DISPATCHER: Starting worker discovery
23:50:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:50:06 DISPATCHER: Finished worker discovery
23:50:38 WORKER: done with job (4, 0, 7), trying to register it.
23:50:38 WORKER: registered result for job (4, 0, 7) with dispatcher
23:50:38 DISPATCHER: job (4, 0, 7) finished
23:50:38 DISPATCHER: register_result: lock acquired
23:50:38 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
23:50:38 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.05506072410795557, 'num_filters_1': 77, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.018568694104627432, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 69, 'num_filters_3': 29, 'num_filters_4': 62, 'num_filters_5': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.05506072410795557, 'num_filters_1': 77, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.018568694104627432, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 69, 'num_filters_3': 29, 'num_filters_4': 62, 'num_filters_5': 17}"}}
exception: None

23:50:38 job_callback for (4, 0, 7) started
23:50:38 job_callback for (4, 0, 7) got condition
23:50:38 DISPATCHER: Trying to submit another job.
23:50:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:50:38 done building a new model for budget 44.444444 based on 17/29 split
Best loss for this budget:-0.460261





23:50:38 HBMASTER: Trying to run another job!
23:50:38 job_callback for (4, 0, 7) finished
23:50:38 start sampling a new configuration.
23:50:38 best_vector: [0, 0, 0.8398598937414058, 0.5555133078963861, 0.685257536313127, 1, 0.3891392239033109, 0.7637036036929452, 1, 1, 1, 2, 0.19470044043344834, 0.32231228982550797, 0.9701553730149628, 0.09315521455444237], 4.293329635084782e-27, 2.329194552936424e-06, -2.6150599715509885e-08
23:50:38 done sampling a new configuration.
23:50:38 HBMASTER: schedule new run for iteration 4
23:50:38 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
23:50:38 HBMASTER: submitting job (4, 0, 8) to dispatcher
23:50:38 DISPATCHER: trying to submit job (4, 0, 8)
23:50:38 DISPATCHER: trying to notify the job_runner thread.
23:50:38 HBMASTER: job (4, 0, 8) submitted to dispatcher
23:50:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:50:38 DISPATCHER: Trying to submit another job.
23:50:38 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776
23:50:38 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
23:50:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:50:38 WORKER: start processing job (4, 0, 8)
23:50:38 WORKER: args: ()
23:50:38 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.04783213734913687, 'num_filters_1': 50, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.09853744478161675, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 23, 'num_filters_3': 31, 'num_filters_4': 121}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:51:06 DISPATCHER: Starting worker discovery
23:51:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:51:06 DISPATCHER: Finished worker discovery
23:52:05 WORKER: done with job (4, 0, 8), trying to register it.
23:52:05 WORKER: registered result for job (4, 0, 8) with dispatcher
23:52:05 DISPATCHER: job (4, 0, 8) finished
23:52:05 DISPATCHER: register_result: lock acquired
23:52:05 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
23:52:05 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.04783213734913687, 'num_filters_1': 50, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.09853744478161675, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 23, 'num_filters_3': 31, 'num_filters_4': 121}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.006887088221700475, 'info': {'data03': 0.006887088221700475, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.04783213734913687, 'num_filters_1': 50, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.09853744478161675, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 23, 'num_filters_3': 31, 'num_filters_4': 121}"}}
exception: None

23:52:05 job_callback for (4, 0, 8) started
23:52:05 DISPATCHER: Trying to submit another job.
23:52:05 job_callback for (4, 0, 8) got condition
23:52:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:52:05 done building a new model for budget 44.444444 based on 17/30 split
Best loss for this budget:-0.460261





23:52:05 HBMASTER: Trying to run another job!
23:52:05 job_callback for (4, 0, 8) finished
23:52:05 start sampling a new configuration.
23:52:05 best_vector: [0, 0, 0.7817245944629401, 0.445338637200909, 0.6630461512312409, 0, 0.56341912742631, 0.4444389710714567, 2, 1, 1, 2, 0.8720527918088558, 0.762968399775809, 0.2896850468575809, 0.8959815605255654], 1.1265262176955912e-27, 8.876846222412722e-06, -4.1460281251164856e-07
23:52:05 done sampling a new configuration.
23:52:05 HBMASTER: schedule new run for iteration 4
23:52:05 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
23:52:05 HBMASTER: submitting job (4, 0, 9) to dispatcher
23:52:05 DISPATCHER: trying to submit job (4, 0, 9)
23:52:05 DISPATCHER: trying to notify the job_runner thread.
23:52:05 HBMASTER: job (4, 0, 9) submitted to dispatcher
23:52:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:52:05 DISPATCHER: Trying to submit another job.
23:52:05 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpui.1576139975513683776
23:52:05 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
23:52:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:52:05 WORKER: start processing job (4, 0, 9)
23:52:05 WORKER: args: ()
23:52:05 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.03659731203612284, 'num_filters_1': 40, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.037864169239356926, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 98, 'num_filters_3': 78, 'num_filters_4': 29}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:52:06 DISPATCHER: Starting worker discovery
23:52:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:52:06 DISPATCHER: Finished worker discovery
23:53:06 DISPATCHER: Starting worker discovery
23:53:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:53:06 DISPATCHER: Finished worker discovery
23:53:38 WORKER: done with job (4, 0, 9), trying to register it.
23:53:38 WORKER: registered result for job (4, 0, 9) with dispatcher
23:53:38 DISPATCHER: job (4, 0, 9) finished
23:53:38 DISPATCHER: register_result: lock acquired
23:53:38 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
23:53:38 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.03659731203612284, 'num_filters_1': 40, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.037864169239356926, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 98, 'num_filters_3': 78, 'num_filters_4': 29}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.03659731203612284, 'num_filters_1': 40, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 61, 'weight_decay': 0.037864169239356926, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 98, 'num_filters_3': 78, 'num_filters_4': 29}"}}
exception: None

23:53:38 job_callback for (4, 0, 9) started
23:53:38 job_callback for (4, 0, 9) got condition
23:53:38 DISPATCHER: Trying to submit another job.
23:53:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:53:38 done building a new model for budget 44.444444 based on 17/31 split
Best loss for this budget:-0.460261





23:53:38 HBMASTER: Trying to run another job!
23:53:38 job_callback for (4, 0, 9) finished
23:53:38 start sampling a new configuration.
23:53:38 best_vector: [0, 2, 0.5682348298613338, 0.7404492661570339, 0.8509372547928844, 1, 0.4297773820205332, 0.17692305890498278, 1, 2, 2, 1, 0.11526635898041834, 0.3426727618696056, 0.8462227391581797, 0.7588241543478731], 0.002034322884775406, 0.00019913230275359677, 4.050994005896665e-07
23:53:38 done sampling a new configuration.
23:53:38 HBMASTER: schedule new run for iteration 4
23:53:38 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
23:53:38 HBMASTER: submitting job (4, 0, 10) to dispatcher
23:53:38 DISPATCHER: trying to submit job (4, 0, 10)
23:53:38 DISPATCHER: trying to notify the job_runner thread.
23:53:38 HBMASTER: job (4, 0, 10) submitted to dispatcher
23:53:38 DISPATCHER: Trying to submit another job.
23:53:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:53:38 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpui.1576139975513683776
23:53:38 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
23:53:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:53:38 WORKER: start processing job (4, 0, 10)
23:53:38 WORKER: args: ()
23:53:38 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.013692087306624788, 'num_filters_1': 74, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.016989562934605597, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 20, 'num_filters_3': 32, 'num_filters_4': 93, 'num_filters_5': 77}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:54:06 DISPATCHER: Starting worker discovery
23:54:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:54:06 DISPATCHER: Finished worker discovery
23:55:06 DISPATCHER: Starting worker discovery
23:55:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:55:06 DISPATCHER: Finished worker discovery
23:55:11 WORKER: done with job (4, 0, 10), trying to register it.
23:55:11 WORKER: registered result for job (4, 0, 10) with dispatcher
23:55:11 DISPATCHER: job (4, 0, 10) finished
23:55:11 DISPATCHER: register_result: lock acquired
23:55:11 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
23:55:11 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.013692087306624788, 'num_filters_1': 74, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.016989562934605597, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 20, 'num_filters_3': 32, 'num_filters_4': 93, 'num_filters_5': 77}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2813571353240441, 'info': {'data03': 0.2813571353240441, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.013692087306624788, 'num_filters_1': 74, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.016989562934605597, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 20, 'num_filters_3': 32, 'num_filters_4': 93, 'num_filters_5': 77}"}}
exception: None

23:55:11 job_callback for (4, 0, 10) started
23:55:11 DISPATCHER: Trying to submit another job.
23:55:11 job_callback for (4, 0, 10) got condition
23:55:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:55:11 done building a new model for budget 44.444444 based on 17/32 split
Best loss for this budget:-0.460261





23:55:11 HBMASTER: Trying to run another job!
23:55:11 job_callback for (4, 0, 10) finished
23:55:11 start sampling a new configuration.
23:55:11 best_vector: [2, 1, 0.10870750293551987, 0.6042087661860867, 0.1693419487051585, 1, 0.8280034426891891, 0.3458266768228446, 0, 0, 0, 1, 0.3470189072105726, 0.25783386956010845, 0.1879592051926251, 0.9660475614533957], 0.009353417559313413, 0.00010246814795058479, 9.584273743113244e-07
23:55:11 done sampling a new configuration.
23:55:11 HBMASTER: schedule new run for iteration 4
23:55:11 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
23:55:11 HBMASTER: submitting job (4, 0, 11) to dispatcher
23:55:11 DISPATCHER: trying to submit job (4, 0, 11)
23:55:11 DISPATCHER: trying to notify the job_runner thread.
23:55:11 HBMASTER: job (4, 0, 11) submitted to dispatcher
23:55:11 DISPATCHER: Trying to submit another job.
23:55:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:55:11 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776
23:55:11 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
23:55:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:55:11 WORKER: start processing job (4, 0, 11)
23:55:11 WORKER: args: ()
23:55:11 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0016497381057256043, 'num_filters_1': 56, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.028179344071288456}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:56:06 DISPATCHER: Starting worker discovery
23:56:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:56:06 DISPATCHER: Finished worker discovery
23:56:42 WORKER: done with job (4, 0, 11), trying to register it.
23:56:42 WORKER: registered result for job (4, 0, 11) with dispatcher
23:56:42 DISPATCHER: job (4, 0, 11) finished
23:56:42 DISPATCHER: register_result: lock acquired
23:56:42 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
23:56:42 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0016497381057256043, 'num_filters_1': 56, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.028179344071288456}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3911955411238322, 'info': {'data03': 0.3911955411238322, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0016497381057256043, 'num_filters_1': 56, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.028179344071288456}"}}
exception: None

23:56:42 job_callback for (4, 0, 11) started
23:56:42 DISPATCHER: Trying to submit another job.
23:56:42 job_callback for (4, 0, 11) got condition
23:56:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:56:42 done building a new model for budget 44.444444 based on 17/33 split
Best loss for this budget:-0.460261





23:56:42 HBMASTER: Trying to run another job!
23:56:42 job_callback for (4, 0, 11) finished
23:56:42 start sampling a new configuration.
23:56:42 best_vector: [1, 0, 0.8720104716805376, 0.32423348477013736, 0.42117054361563244, 1, 0.9024822354775345, 0.4380513668390198, 1, 1, 2, 0, 0.7717685347261886, 0.12726255728920507, 0.5838508995377323, 0.4176057319741673], 0.03521027530099323, 0.0025213878809763426, 8.877876142976498e-05
23:56:42 done sampling a new configuration.
23:56:42 HBMASTER: schedule new run for iteration 4
23:56:42 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
23:56:42 HBMASTER: submitting job (4, 0, 12) to dispatcher
23:56:42 DISPATCHER: trying to submit job (4, 0, 12)
23:56:42 DISPATCHER: trying to notify the job_runner thread.
23:56:42 HBMASTER: job (4, 0, 12) submitted to dispatcher
23:56:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:56:42 DISPATCHER: Trying to submit another job.
23:56:42 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpui.1576139975513683776
23:56:42 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
23:56:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:56:42 WORKER: start processing job (4, 0, 12)
23:56:42 WORKER: args: ()
23:56:42 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.055465245980166375, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.03714650579612008, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 79, 'num_filters_3': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:57:06 DISPATCHER: Starting worker discovery
23:57:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:57:06 DISPATCHER: Finished worker discovery
23:58:06 DISPATCHER: Starting worker discovery
23:58:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:58:06 DISPATCHER: Finished worker discovery
23:58:10 WORKER: done with job (4, 0, 12), trying to register it.
23:58:10 WORKER: registered result for job (4, 0, 12) with dispatcher
23:58:10 DISPATCHER: job (4, 0, 12) finished
23:58:10 DISPATCHER: register_result: lock acquired
23:58:10 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
23:58:10 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.055465245980166375, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.03714650579612008, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 79, 'num_filters_3': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2151263503297223, 'info': {'data03': 0.2151263503297223, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.055465245980166375, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.03714650579612008, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 79, 'num_filters_3': 20}"}}
exception: None

23:58:10 job_callback for (4, 0, 12) started
23:58:10 DISPATCHER: Trying to submit another job.
23:58:10 job_callback for (4, 0, 12) got condition
23:58:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:58:10 done building a new model for budget 44.444444 based on 17/34 split
Best loss for this budget:-0.460261





23:58:10 HBMASTER: Trying to run another job!
23:58:10 job_callback for (4, 0, 12) finished
23:58:10 start sampling a new configuration.
23:58:10 best_vector: [2, 0, 0.2578126395191723, 0.249412757946611, 0.44738715936905926, 1, 0.6964113939045691, 0.8795843036745677, 1, 1, 2, 2, 0.03444174147927653, 0.3346562162256196, 0.8733402115105883, 0.8566293895984876], 0.020875142225656562, 0.00010120882150541947, 2.11274854341672e-06
23:58:10 done sampling a new configuration.
23:58:10 HBMASTER: schedule new run for iteration 4
23:58:10 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
23:58:10 HBMASTER: submitting job (4, 0, 13) to dispatcher
23:58:10 DISPATCHER: trying to submit job (4, 0, 13)
23:58:10 DISPATCHER: trying to notify the job_runner thread.
23:58:10 HBMASTER: job (4, 0, 13) submitted to dispatcher
23:58:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:58:10 DISPATCHER: Trying to submit another job.
23:58:10 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpui.1576139975513683776
23:58:10 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
23:58:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:58:10 WORKER: start processing job (4, 0, 13)
23:58:10 WORKER: args: ()
23:58:10 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0032781232576182266, 'num_filters_1': 26, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.13943299716602606, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 17, 'num_filters_3': 31}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:59:06 DISPATCHER: Starting worker discovery
23:59:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:59:06 DISPATCHER: Finished worker discovery
23:59:36 WORKER: done with job (4, 0, 13), trying to register it.
23:59:36 WORKER: registered result for job (4, 0, 13) with dispatcher
23:59:36 DISPATCHER: job (4, 0, 13) finished
23:59:36 DISPATCHER: register_result: lock acquired
23:59:36 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
23:59:36 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0032781232576182266, 'num_filters_1': 26, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.13943299716602606, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 17, 'num_filters_3': 31}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4516485498268881, 'info': {'data03': 0.4516485498268881, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0032781232576182266, 'num_filters_1': 26, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.13943299716602606, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 17, 'num_filters_3': 31}"}}
exception: None

23:59:36 job_callback for (4, 0, 13) started
23:59:36 job_callback for (4, 0, 13) got condition
23:59:36 DISPATCHER: Trying to submit another job.
23:59:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:59:36 done building a new model for budget 44.444444 based on 17/34 split
Best loss for this budget:-0.460261





23:59:36 HBMASTER: Trying to run another job!
23:59:36 job_callback for (4, 0, 13) finished
23:59:36 start sampling a new configuration.
23:59:36 done sampling a new configuration.
23:59:36 HBMASTER: schedule new run for iteration 4
23:59:36 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
23:59:36 HBMASTER: submitting job (4, 0, 14) to dispatcher
23:59:36 DISPATCHER: trying to submit job (4, 0, 14)
23:59:36 DISPATCHER: trying to notify the job_runner thread.
23:59:36 HBMASTER: job (4, 0, 14) submitted to dispatcher
23:59:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:59:36 DISPATCHER: Trying to submit another job.
23:59:36 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776
23:59:36 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
23:59:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:59:36 WORKER: start processing job (4, 0, 14)
23:59:36 WORKER: args: ()
23:59:36 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.01102923541661947, 'num_filters_1': 33, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.01666990108868, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 125, 'num_filters_3': 69}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:00:06 DISPATCHER: Starting worker discovery
00:00:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:00:06 DISPATCHER: Finished worker discovery
00:01:06 DISPATCHER: Starting worker discovery
00:01:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:01:06 DISPATCHER: Finished worker discovery
00:01:08 WORKER: done with job (4, 0, 14), trying to register it.
00:01:08 WORKER: registered result for job (4, 0, 14) with dispatcher
00:01:08 DISPATCHER: job (4, 0, 14) finished
00:01:08 DISPATCHER: register_result: lock acquired
00:01:08 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:01:08 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.01102923541661947, 'num_filters_1': 33, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.01666990108868, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 125, 'num_filters_3': 69}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1635522307410349, 'info': {'data03': 0.1635522307410349, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.01102923541661947, 'num_filters_1': 33, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.01666990108868, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 125, 'num_filters_3': 69}"}}
exception: None

00:01:08 job_callback for (4, 0, 14) started
00:01:08 job_callback for (4, 0, 14) got condition
00:01:08 DISPATCHER: Trying to submit another job.
00:01:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:01:08 done building a new model for budget 44.444444 based on 17/35 split
Best loss for this budget:-0.460261





00:01:08 HBMASTER: Trying to run another job!
00:01:08 job_callback for (4, 0, 14) finished
00:01:08 start sampling a new configuration.
00:01:08 best_vector: [3, 2, 0.1400991225712982, 0.9793145649127546, 0.24341439765776585, 1, 0.2828421305794109, 0.16818596153670368, 2, 2, 2, 2, 0.49464933290757496, 0.309165325558761, 0.36959876434873484, 0.766618418842886], 0.0010902011705070838, 0.0026030737309966283, 2.837874028448766e-06
00:01:08 done sampling a new configuration.
00:01:08 HBMASTER: schedule new run for iteration 4
00:01:08 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
00:01:08 HBMASTER: submitting job (4, 0, 15) to dispatcher
00:01:08 DISPATCHER: trying to submit job (4, 0, 15)
00:01:08 DISPATCHER: trying to notify the job_runner thread.
00:01:08 HBMASTER: job (4, 0, 15) submitted to dispatcher
00:01:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:01:08 DISPATCHER: Trying to submit another job.
00:01:08 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:01:08 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:01:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:01:08 WORKER: start processing job (4, 0, 15)
00:01:08 WORKER: args: ()
00:01:08 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.001906330714192054, 'num_filters_1': 123, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.01655064718559458, 'kernel_size_2': 7, 'num_filters_2': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:02:06 DISPATCHER: Starting worker discovery
00:02:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:02:06 DISPATCHER: Finished worker discovery
00:02:35 WORKER: done with job (4, 0, 15), trying to register it.
00:02:35 WORKER: registered result for job (4, 0, 15) with dispatcher
00:02:35 DISPATCHER: job (4, 0, 15) finished
00:02:35 DISPATCHER: register_result: lock acquired
00:02:35 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:02:35 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.001906330714192054, 'num_filters_1': 123, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.01655064718559458, 'kernel_size_2': 7, 'num_filters_2': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4079461809720941, 'info': {'data03': 0.4079461809720941, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.001906330714192054, 'num_filters_1': 123, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.01655064718559458, 'kernel_size_2': 7, 'num_filters_2': 44}"}}
exception: None

00:02:35 job_callback for (4, 0, 15) started
00:02:35 DISPATCHER: Trying to submit another job.
00:02:35 job_callback for (4, 0, 15) got condition
00:02:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:02:35 done building a new model for budget 44.444444 based on 17/36 split
Best loss for this budget:-0.460261





00:02:35 HBMASTER: Trying to run another job!
00:02:35 job_callback for (4, 0, 15) finished
00:02:35 start sampling a new configuration.
00:02:35 done sampling a new configuration.
00:02:35 HBMASTER: schedule new run for iteration 4
00:02:35 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
00:02:35 HBMASTER: submitting job (4, 0, 16) to dispatcher
00:02:35 DISPATCHER: trying to submit job (4, 0, 16)
00:02:35 DISPATCHER: trying to notify the job_runner thread.
00:02:35 HBMASTER: job (4, 0, 16) submitted to dispatcher
00:02:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:02:35 DISPATCHER: Trying to submit another job.
00:02:35 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:02:35 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:02:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:02:35 WORKER: start processing job (4, 0, 16)
00:02:35 WORKER: args: ()
00:02:35 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.025956097660497755, 'num_filters_1': 87, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.011653202744531634, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 26, 'num_filters_3': 47, 'num_filters_4': 22}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:03:06 DISPATCHER: Starting worker discovery
00:03:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:03:06 DISPATCHER: Finished worker discovery
00:04:06 DISPATCHER: Starting worker discovery
00:04:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:04:06 DISPATCHER: Finished worker discovery
00:04:09 WORKER: done with job (4, 0, 16), trying to register it.
00:04:09 WORKER: registered result for job (4, 0, 16) with dispatcher
00:04:09 DISPATCHER: job (4, 0, 16) finished
00:04:09 DISPATCHER: register_result: lock acquired
00:04:09 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:04:09 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.025956097660497755, 'num_filters_1': 87, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.011653202744531634, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 26, 'num_filters_3': 47, 'num_filters_4': 22}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.025956097660497755, 'num_filters_1': 87, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.011653202744531634, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 26, 'num_filters_3': 47, 'num_filters_4': 22}"}}
exception: None

00:04:09 job_callback for (4, 0, 16) started
00:04:09 DISPATCHER: Trying to submit another job.
00:04:09 job_callback for (4, 0, 16) got condition
00:04:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:04:09 done building a new model for budget 44.444444 based on 17/37 split
Best loss for this budget:-0.460261





00:04:09 HBMASTER: Trying to run another job!
00:04:09 job_callback for (4, 0, 16) finished
00:04:09 start sampling a new configuration.
00:04:09 best_vector: [3, 1, 7.327314027916199e-05, 0.2210888561961769, 0.3563053637652249, 1, 0.23558635061664102, 0.8407618582189944, 0, 0, 2, 2, 0.39346356889440803, 0.560433057386504, 0.9009514148364042, 0.6915637142818526], 6.049823200590707e-28, 1.6529408659452388e-05, -3.0325987235655327e-07
00:04:09 done sampling a new configuration.
00:04:09 HBMASTER: schedule new run for iteration 4
00:04:09 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
00:04:09 HBMASTER: submitting job (4, 0, 17) to dispatcher
00:04:09 DISPATCHER: trying to submit job (4, 0, 17)
00:04:09 DISPATCHER: trying to notify the job_runner thread.
00:04:09 HBMASTER: job (4, 0, 17) submitted to dispatcher
00:04:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:04:09 DISPATCHER: Trying to submit another job.
00:04:09 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:04:09 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:04:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:04:09 WORKER: start processing job (4, 0, 17)
00:04:09 WORKER: args: ()
00:04:09 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0010003374922187365, 'num_filters_1': 25, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.12412418123306232, 'kernel_size_2': 3, 'num_filters_2': 36}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:05:06 DISPATCHER: Starting worker discovery
00:05:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:05:06 DISPATCHER: Finished worker discovery
00:05:41 WORKER: done with job (4, 0, 17), trying to register it.
00:05:41 WORKER: registered result for job (4, 0, 17) with dispatcher
00:05:41 DISPATCHER: job (4, 0, 17) finished
00:05:41 DISPATCHER: register_result: lock acquired
00:05:41 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:05:41 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0010003374922187365, 'num_filters_1': 25, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.12412418123306232, 'kernel_size_2': 3, 'num_filters_2': 36}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.326885572145174, 'info': {'data03': 0.326885572145174, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0010003374922187365, 'num_filters_1': 25, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.12412418123306232, 'kernel_size_2': 3, 'num_filters_2': 36}"}}
exception: None

00:05:41 job_callback for (4, 0, 17) started
00:05:41 DISPATCHER: Trying to submit another job.
00:05:41 job_callback for (4, 0, 17) got condition
00:05:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:05:41 done building a new model for budget 44.444444 based on 17/38 split
Best loss for this budget:-0.460261





00:05:41 HBMASTER: Trying to run another job!
00:05:41 job_callback for (4, 0, 17) finished
00:05:41 start sampling a new configuration.
00:05:41 best_vector: [0, 0, 0.1275126455833092, 0.8680836546247239, 0.4178408634770793, 1, 0.5001072319820576, 0.8781781529142128, 0, 1, 0, 2, 0.06353246073318491, 0.5271787985960966, 0.21511415409501233, 0.441999561193974], 2.4443664968585505e-28, 4.091039544541211e-05, -6.325770529870872e-06
00:05:41 done sampling a new configuration.
00:05:41 HBMASTER: schedule new run for iteration 4
00:05:41 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
00:05:41 HBMASTER: submitting job (4, 0, 18) to dispatcher
00:05:41 DISPATCHER: trying to submit job (4, 0, 18)
00:05:41 DISPATCHER: trying to notify the job_runner thread.
00:05:41 HBMASTER: job (4, 0, 18) submitted to dispatcher
00:05:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:05:41 DISPATCHER: Trying to submit another job.
00:05:41 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:05:41 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:05:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:05:41 WORKER: start processing job (4, 0, 18)
00:05:41 WORKER: args: ()
00:05:41 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0017989756755406269, 'num_filters_1': 97, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.13884687783406066, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 18, 'num_filters_3': 47}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:06:06 DISPATCHER: Starting worker discovery
00:06:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:06:06 DISPATCHER: Finished worker discovery
00:07:06 DISPATCHER: Starting worker discovery
00:07:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:07:06 DISPATCHER: Finished worker discovery
00:07:15 WORKER: done with job (4, 0, 18), trying to register it.
00:07:15 WORKER: registered result for job (4, 0, 18) with dispatcher
00:07:15 DISPATCHER: job (4, 0, 18) finished
00:07:15 DISPATCHER: register_result: lock acquired
00:07:15 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:07:15 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0017989756755406269, 'num_filters_1': 97, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.13884687783406066, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 18, 'num_filters_3': 47}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.37506229145146847, 'info': {'data03': 0.37506229145146847, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0017989756755406269, 'num_filters_1': 97, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.13884687783406066, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 18, 'num_filters_3': 47}"}}
exception: None

00:07:15 job_callback for (4, 0, 18) started
00:07:15 DISPATCHER: Trying to submit another job.
00:07:15 job_callback for (4, 0, 18) got condition
00:07:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:07:15 done building a new model for budget 44.444444 based on 17/39 split
Best loss for this budget:-0.460261





00:07:15 HBMASTER: Trying to run another job!
00:07:15 job_callback for (4, 0, 18) finished
00:07:15 start sampling a new configuration.
00:07:15 best_vector: [0, 2, 0.24037139573954808, 0.7819392396671303, 0.9801950754892472, 0, 0.7018440800884139, 0.16985898951721867, 1, 0, 2, 1, 0.47704423839923016, 0.008247449623932222, 0.8556345496137423, 0.7627372381407089], 1.0238968757357815e-29, 0.000976660856867437, -2.6351264962996374e-06
00:07:15 done sampling a new configuration.
00:07:15 HBMASTER: schedule new run for iteration 4
00:07:15 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
00:07:15 HBMASTER: submitting job (4, 0, 19) to dispatcher
00:07:15 DISPATCHER: trying to submit job (4, 0, 19)
00:07:15 DISPATCHER: trying to notify the job_runner thread.
00:07:15 HBMASTER: job (4, 0, 19) submitted to dispatcher
00:07:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:07:15 DISPATCHER: Trying to submit another job.
00:07:15 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:07:15 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:07:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:07:15 WORKER: start processing job (4, 0, 19)
00:07:15 WORKER: args: ()
00:07:15 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.003025121285998844, 'num_filters_1': 81, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.016633806321444435, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 43, 'num_filters_3': 16, 'num_filters_4': 95, 'num_filters_5': 78}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:08:06 DISPATCHER: Starting worker discovery
00:08:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:08:06 DISPATCHER: Finished worker discovery
00:08:49 WORKER: done with job (4, 0, 19), trying to register it.
00:08:49 WORKER: registered result for job (4, 0, 19) with dispatcher
00:08:49 DISPATCHER: job (4, 0, 19) finished
00:08:49 DISPATCHER: register_result: lock acquired
00:08:49 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:08:49 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.003025121285998844, 'num_filters_1': 81, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.016633806321444435, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 43, 'num_filters_3': 16, 'num_filters_4': 95, 'num_filters_5': 78}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3530904679848712, 'info': {'data03': 0.3530904679848712, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.003025121285998844, 'num_filters_1': 81, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 73, 'weight_decay': 0.016633806321444435, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 43, 'num_filters_3': 16, 'num_filters_4': 95, 'num_filters_5': 78}"}}
exception: None

00:08:49 job_callback for (4, 0, 19) started
00:08:49 DISPATCHER: Trying to submit another job.
00:08:49 job_callback for (4, 0, 19) got condition
00:08:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:08:49 done building a new model for budget 44.444444 based on 17/39 split
Best loss for this budget:-0.460261





00:08:49 HBMASTER: Trying to run another job!
00:08:49 job_callback for (4, 0, 19) finished
00:08:49 start sampling a new configuration.
00:08:49 done sampling a new configuration.
00:08:49 HBMASTER: schedule new run for iteration 4
00:08:49 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
00:08:49 HBMASTER: submitting job (4, 0, 20) to dispatcher
00:08:49 DISPATCHER: trying to submit job (4, 0, 20)
00:08:49 DISPATCHER: trying to notify the job_runner thread.
00:08:49 HBMASTER: job (4, 0, 20) submitted to dispatcher
00:08:49 DISPATCHER: Trying to submit another job.
00:08:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:08:49 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:08:49 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:08:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:08:49 WORKER: start processing job (4, 0, 20)
00:08:49 WORKER: args: ()
00:08:49 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.045878469697094165, 'num_filters_1': 18, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.0581945401069892, 'kernel_size_2': 3, 'num_filters_2': 60}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:09:06 DISPATCHER: Starting worker discovery
00:09:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:09:06 DISPATCHER: Finished worker discovery
00:10:06 DISPATCHER: Starting worker discovery
00:10:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:10:06 DISPATCHER: Finished worker discovery
00:10:22 WORKER: done with job (4, 0, 20), trying to register it.
00:10:22 WORKER: registered result for job (4, 0, 20) with dispatcher
00:10:22 DISPATCHER: job (4, 0, 20) finished
00:10:22 DISPATCHER: register_result: lock acquired
00:10:22 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:10:22 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.045878469697094165, 'num_filters_1': 18, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.0581945401069892, 'kernel_size_2': 3, 'num_filters_2': 60}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.045878469697094165, 'num_filters_1': 18, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.0581945401069892, 'kernel_size_2': 3, 'num_filters_2': 60}"}}
exception: None

00:10:22 job_callback for (4, 0, 20) started
00:10:22 DISPATCHER: Trying to submit another job.
00:10:22 job_callback for (4, 0, 20) got condition
00:10:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:10:22 done building a new model for budget 44.444444 based on 17/40 split
Best loss for this budget:-0.460261





00:10:22 HBMASTER: Trying to run another job!
00:10:22 job_callback for (4, 0, 20) finished
00:10:22 start sampling a new configuration.
00:10:22 best_vector: [0, 2, 0.0537562991796606, 0.5823499352691106, 0.7852203923972125, 1, 0.7215984062178551, 0.5912376217182383, 2, 1, 0, 1, 0.32722335111041795, 0.8001064798805837, 0.8627671471731749, 0.912554746981904], 9.665968410626464e-29, 0.00010345574882084564, -1.3392275134850636e-07
00:10:22 done sampling a new configuration.
00:10:22 HBMASTER: schedule new run for iteration 4
00:10:22 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
00:10:22 HBMASTER: submitting job (4, 0, 21) to dispatcher
00:10:22 DISPATCHER: trying to submit job (4, 0, 21)
00:10:22 DISPATCHER: trying to notify the job_runner thread.
00:10:22 HBMASTER: job (4, 0, 21) submitted to dispatcher
00:10:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:10:22 DISPATCHER: Trying to submit another job.
00:10:22 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:10:22 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:10:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:10:22 WORKER: start processing job (4, 0, 21)
00:10:22 WORKER: args: ()
00:10:22 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0012808922511372645, 'num_filters_1': 53, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.058778416295566446, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 31, 'num_filters_3': 84, 'num_filters_4': 96}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:11:06 DISPATCHER: Starting worker discovery
00:11:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:11:06 DISPATCHER: Finished worker discovery
00:11:51 WORKER: done with job (4, 0, 21), trying to register it.
00:11:51 WORKER: registered result for job (4, 0, 21) with dispatcher
00:11:51 DISPATCHER: job (4, 0, 21) finished
00:11:51 DISPATCHER: register_result: lock acquired
00:11:51 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:11:51 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0012808922511372645, 'num_filters_1': 53, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.058778416295566446, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 31, 'num_filters_3': 84, 'num_filters_4': 96}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3786704235470097, 'info': {'data03': 0.3786704235470097, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0012808922511372645, 'num_filters_1': 53, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.058778416295566446, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 31, 'num_filters_3': 84, 'num_filters_4': 96}"}}
exception: None

00:11:51 job_callback for (4, 0, 21) started
00:11:51 DISPATCHER: Trying to submit another job.
00:11:51 job_callback for (4, 0, 21) got condition
00:11:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:11:51 done building a new model for budget 44.444444 based on 17/41 split
Best loss for this budget:-0.460261





00:11:51 HBMASTER: Trying to run another job!
00:11:51 job_callback for (4, 0, 21) finished
00:11:51 start sampling a new configuration.
00:11:51 best_vector: [3, 2, 0.0805670843261153, 0.345432682956882, 0.4004104204308872, 1, 0.15184176499535595, 0.8925348135841671, 2, 1, 1, 2, 0.10075697111563736, 0.885440636136188, 0.24755111155822052, 0.7033685853021504], 0.0016115589901298441, 0.00038045757812780876, 6.131298303948978e-07
00:11:51 done sampling a new configuration.
00:11:51 HBMASTER: schedule new run for iteration 4
00:11:51 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
00:11:51 HBMASTER: submitting job (4, 0, 22) to dispatcher
00:11:51 DISPATCHER: trying to submit job (4, 0, 22)
00:11:51 DISPATCHER: trying to notify the job_runner thread.
00:11:51 HBMASTER: job (4, 0, 22) submitted to dispatcher
00:11:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:11:51 DISPATCHER: Trying to submit another job.
00:11:51 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:11:51 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:11:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:11:51 WORKER: start processing job (4, 0, 22)
00:11:51 WORKER: args: ()
00:11:51 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0014492194986415892, 'num_filters_1': 32, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.14494878009882584, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 19, 'num_filters_3': 101}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:12:06 DISPATCHER: Starting worker discovery
00:12:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:12:06 DISPATCHER: Finished worker discovery
00:13:06 DISPATCHER: Starting worker discovery
00:13:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:13:06 DISPATCHER: Finished worker discovery
00:13:26 WORKER: done with job (4, 0, 22), trying to register it.
00:13:26 WORKER: registered result for job (4, 0, 22) with dispatcher
00:13:26 DISPATCHER: job (4, 0, 22) finished
00:13:26 DISPATCHER: register_result: lock acquired
00:13:26 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:13:26 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0014492194986415892, 'num_filters_1': 32, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.14494878009882584, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 19, 'num_filters_3': 101}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.382013070637801, 'info': {'data03': 0.382013070637801, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0014492194986415892, 'num_filters_1': 32, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.14494878009882584, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 19, 'num_filters_3': 101}"}}
exception: None

00:13:26 job_callback for (4, 0, 22) started
00:13:26 DISPATCHER: Trying to submit another job.
00:13:26 job_callback for (4, 0, 22) got condition
00:13:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:13:26 done building a new model for budget 44.444444 based on 17/42 split
Best loss for this budget:-0.460261





00:13:26 HBMASTER: Trying to run another job!
00:13:26 job_callback for (4, 0, 22) finished
00:13:26 start sampling a new configuration.
00:13:26 best_vector: [3, 2, 0.0024085857400872324, 0.6913639797990965, 0.44122708352316625, 1, 0.3088002338822744, 0.29288850168051866, 0, 2, 1, 0, 0.144852704610425, 0.3610026612976425, 0.3000776391682519, 0.9550187823061602], 0.0016373238172086475, 0.0005295955520643211, 8.671194108826753e-07
00:13:26 done sampling a new configuration.
00:13:26 HBMASTER: schedule new run for iteration 4
00:13:26 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
00:13:26 HBMASTER: submitting job (4, 0, 23) to dispatcher
00:13:26 DISPATCHER: trying to submit job (4, 0, 23)
00:13:26 DISPATCHER: trying to notify the job_runner thread.
00:13:26 HBMASTER: job (4, 0, 23) submitted to dispatcher
00:13:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:13:26 DISPATCHER: Trying to submit another job.
00:13:26 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:13:26 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:13:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:13:26 WORKER: start processing job (4, 0, 23)
00:13:26 WORKER: args: ()
00:13:26 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0010111536909623074, 'num_filters_1': 67, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.024046768702275418, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 21, 'num_filters_3': 33}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:14:06 DISPATCHER: Starting worker discovery
00:14:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:14:06 DISPATCHER: Finished worker discovery
00:14:55 WORKER: done with job (4, 0, 23), trying to register it.
00:14:55 WORKER: registered result for job (4, 0, 23) with dispatcher
00:14:55 DISPATCHER: job (4, 0, 23) finished
00:14:55 DISPATCHER: register_result: lock acquired
00:14:55 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:14:55 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0010111536909623074, 'num_filters_1': 67, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.024046768702275418, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 21, 'num_filters_3': 33}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.41562623203788424, 'info': {'data03': 0.41562623203788424, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0010111536909623074, 'num_filters_1': 67, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.024046768702275418, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 21, 'num_filters_3': 33}"}}
exception: None

00:14:55 job_callback for (4, 0, 23) started
00:14:55 job_callback for (4, 0, 23) got condition
00:14:55 DISPATCHER: Trying to submit another job.
00:14:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:14:55 done building a new model for budget 44.444444 based on 17/43 split
Best loss for this budget:-0.460261





00:14:55 HBMASTER: Trying to run another job!
00:14:55 job_callback for (4, 0, 23) finished
00:14:55 start sampling a new configuration.
00:14:55 best_vector: [3, 1, 0.011698208639300323, 0.3377416724677703, 0.12988909094234066, 1, 0.2768793080260913, 0.5251095942854851, 1, 1, 2, 0, 0.10912187065978665, 0.7893511462096613, 0.2436596890462435, 0.46396402729667197], 3.2384241937102275e-28, 3.087921594528081e-05, -5.576877410617376e-07
00:14:55 done sampling a new configuration.
00:14:55 HBMASTER: schedule new run for iteration 4
00:14:55 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
00:14:55 HBMASTER: submitting job (4, 0, 24) to dispatcher
00:14:55 DISPATCHER: trying to submit job (4, 0, 24)
00:14:55 DISPATCHER: trying to notify the job_runner thread.
00:14:55 HBMASTER: job (4, 0, 24) submitted to dispatcher
00:14:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:14:55 DISPATCHER: Trying to submit another job.
00:14:55 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:14:55 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:14:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:14:55 WORKER: start processing job (4, 0, 24)
00:14:55 WORKER: args: ()
00:14:55 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0010553497638028657, 'num_filters_1': 32, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.04821512901317377}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:15:06 DISPATCHER: Starting worker discovery
00:15:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:15:06 DISPATCHER: Finished worker discovery
00:16:06 DISPATCHER: Starting worker discovery
00:16:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:16:06 DISPATCHER: Finished worker discovery
00:16:22 WORKER: done with job (4, 0, 24), trying to register it.
00:16:22 WORKER: registered result for job (4, 0, 24) with dispatcher
00:16:22 DISPATCHER: job (4, 0, 24) finished
00:16:22 DISPATCHER: register_result: lock acquired
00:16:22 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:16:22 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0010553497638028657, 'num_filters_1': 32, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.04821512901317377}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3943863152380264, 'info': {'data03': 0.3943863152380264, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0010553497638028657, 'num_filters_1': 32, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.04821512901317377}"}}
exception: None

00:16:22 job_callback for (4, 0, 24) started
00:16:22 job_callback for (4, 0, 24) got condition
00:16:22 DISPATCHER: Trying to submit another job.
00:16:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:16:22 done building a new model for budget 44.444444 based on 17/44 split
Best loss for this budget:-0.460261





00:16:22 HBMASTER: Trying to run another job!
00:16:22 job_callback for (4, 0, 24) finished
00:16:22 start sampling a new configuration.
00:16:23 best_vector: [2, 2, 0.10971589783926776, 0.3838237367816236, 0.9039376228125385, 1, 0.8306823287445806, 0.9460917036260386, 0, 0, 2, 0, 0.5472794608557744, 0.9614608945505562, 0.7037488416014853, 0.9655006622637669], 0.0004568115493132672, 0.0015878541841021418, 7.253501299232532e-07
00:16:23 done sampling a new configuration.
00:16:23 HBMASTER: schedule new run for iteration 4
00:16:23 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
00:16:23 HBMASTER: submitting job (4, 0, 25) to dispatcher
00:16:23 DISPATCHER: trying to submit job (4, 0, 25)
00:16:23 DISPATCHER: trying to notify the job_runner thread.
00:16:23 HBMASTER: job (4, 0, 25) submitted to dispatcher
00:16:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:16:23 DISPATCHER: Trying to submit another job.
00:16:23 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:16:23 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:16:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:16:23 WORKER: start processing job (4, 0, 25)
00:16:23 WORKER: args: ()
00:16:23 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0016574170252739975, 'num_filters_1': 35, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.17017418723835223, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 49, 'num_filters_3': 118, 'num_filters_4': 69, 'num_filters_5': 119}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:17:06 DISPATCHER: Starting worker discovery
00:17:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:17:06 DISPATCHER: Finished worker discovery
00:17:52 WORKER: done with job (4, 0, 25), trying to register it.
00:17:52 WORKER: registered result for job (4, 0, 25) with dispatcher
00:17:53 DISPATCHER: job (4, 0, 25) finished
00:17:53 DISPATCHER: register_result: lock acquired
00:17:53 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:17:53 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0016574170252739975, 'num_filters_1': 35, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.17017418723835223, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 49, 'num_filters_3': 118, 'num_filters_4': 69, 'num_filters_5': 119}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3514932975660185, 'info': {'data03': 0.3514932975660185, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0016574170252739975, 'num_filters_1': 35, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.17017418723835223, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 49, 'num_filters_3': 118, 'num_filters_4': 69, 'num_filters_5': 119}"}}
exception: None

00:17:53 job_callback for (4, 0, 25) started
00:17:53 DISPATCHER: Trying to submit another job.
00:17:53 job_callback for (4, 0, 25) got condition
00:17:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:17:53 done building a new model for budget 44.444444 based on 17/45 split
Best loss for this budget:-0.460261





00:17:53 HBMASTER: Trying to run another job!
00:17:53 job_callback for (4, 0, 25) finished
00:17:53 start sampling a new configuration.
00:17:53 best_vector: [3, 0, 0.14472522865531956, 0.7387540352745797, 0.7440177493333902, 1, 0.09938460296626028, 0.7325325308596183, 1, 1, 1, 0, 0.38453314411635364, 0.24099365384403726, 0.8042097409992378, 0.9291762719363311], 1.401880663185941e-30, 0.007133274794784463, -7.38466493325923e-06
00:17:53 done sampling a new configuration.
00:17:53 HBMASTER: schedule new run for iteration 4
00:17:53 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
00:17:53 HBMASTER: submitting job (4, 0, 26) to dispatcher
00:17:53 DISPATCHER: trying to submit job (4, 0, 26)
00:17:53 DISPATCHER: trying to notify the job_runner thread.
00:17:53 HBMASTER: job (4, 0, 26) submitted to dispatcher
00:17:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:17:53 DISPATCHER: Trying to submit another job.
00:17:53 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:17:53 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:17:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:17:53 WORKER: start processing job (4, 0, 26)
00:17:53 WORKER: args: ()
00:17:53 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0019473788875745553, 'num_filters_1': 74, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.08975254981128214, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 35, 'num_filters_3': 26, 'num_filters_4': 85}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:18:06 DISPATCHER: Starting worker discovery
00:18:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:18:06 DISPATCHER: Finished worker discovery
00:19:06 DISPATCHER: Starting worker discovery
00:19:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:19:06 DISPATCHER: Finished worker discovery
00:19:20 WORKER: done with job (4, 0, 26), trying to register it.
00:19:20 WORKER: registered result for job (4, 0, 26) with dispatcher
00:19:20 DISPATCHER: job (4, 0, 26) finished
00:19:20 DISPATCHER: register_result: lock acquired
00:19:20 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:19:20 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0019473788875745553, 'num_filters_1': 74, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.08975254981128214, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 35, 'num_filters_3': 26, 'num_filters_4': 85}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3740835954870394, 'info': {'data03': 0.3740835954870394, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0019473788875745553, 'num_filters_1': 74, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.08975254981128214, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 35, 'num_filters_3': 26, 'num_filters_4': 85}"}}
exception: None

00:19:20 job_callback for (4, 0, 26) started
00:19:20 job_callback for (4, 0, 26) got condition
00:19:20 DISPATCHER: Trying to submit another job.
00:19:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:19:20 done building a new model for budget 44.444444 based on 17/45 split
Best loss for this budget:-0.460261





00:19:20 HBMASTER: Trying to run another job!
00:19:20 job_callback for (4, 0, 26) finished
00:19:20 ITERATION: Advancing config (4, 0, 2) to next budget 133.333333
00:19:20 ITERATION: Advancing config (4, 0, 11) to next budget 133.333333
00:19:20 ITERATION: Advancing config (4, 0, 13) to next budget 133.333333
00:19:20 ITERATION: Advancing config (4, 0, 15) to next budget 133.333333
00:19:20 ITERATION: Advancing config (4, 0, 18) to next budget 133.333333
00:19:20 ITERATION: Advancing config (4, 0, 21) to next budget 133.333333
00:19:20 ITERATION: Advancing config (4, 0, 22) to next budget 133.333333
00:19:20 ITERATION: Advancing config (4, 0, 23) to next budget 133.333333
00:19:20 ITERATION: Advancing config (4, 0, 24) to next budget 133.333333
00:19:20 HBMASTER: schedule new run for iteration 4
00:19:20 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
00:19:20 HBMASTER: submitting job (4, 0, 2) to dispatcher
00:19:20 DISPATCHER: trying to submit job (4, 0, 2)
00:19:20 DISPATCHER: trying to notify the job_runner thread.
00:19:20 HBMASTER: job (4, 0, 2) submitted to dispatcher
00:19:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:19:20 DISPATCHER: Trying to submit another job.
00:19:20 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:19:20 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:19:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:19:20 WORKER: start processing job (4, 0, 2)
00:19:20 WORKER: args: ()
00:19:20 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004383507818056009, 'num_filters_1': 58, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.038739849792668084, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 31, 'num_filters_3': 19}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:20:06 DISPATCHER: Starting worker discovery
00:20:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:20:06 DISPATCHER: Finished worker discovery
00:21:06 DISPATCHER: Starting worker discovery
00:21:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:21:06 DISPATCHER: Finished worker discovery
00:22:06 DISPATCHER: Starting worker discovery
00:22:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:22:06 DISPATCHER: Finished worker discovery
00:22:25 WORKER: done with job (4, 0, 2), trying to register it.
00:22:25 WORKER: registered result for job (4, 0, 2) with dispatcher
00:22:25 DISPATCHER: job (4, 0, 2) finished
00:22:25 DISPATCHER: register_result: lock acquired
00:22:25 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:22:25 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004383507818056009, 'num_filters_1': 58, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.038739849792668084, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 31, 'num_filters_3': 19}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.39366115566238885, 'info': {'data03': 0.39366115566238885, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004383507818056009, 'num_filters_1': 58, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.038739849792668084, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 31, 'num_filters_3': 19}"}}
exception: None

00:22:25 job_callback for (4, 0, 2) started
00:22:25 DISPATCHER: Trying to submit another job.
00:22:25 job_callback for (4, 0, 2) got condition
00:22:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:22:25 HBMASTER: Trying to run another job!
00:22:25 job_callback for (4, 0, 2) finished
00:22:25 HBMASTER: schedule new run for iteration 4
00:22:25 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
00:22:25 HBMASTER: submitting job (4, 0, 11) to dispatcher
00:22:25 DISPATCHER: trying to submit job (4, 0, 11)
00:22:25 DISPATCHER: trying to notify the job_runner thread.
00:22:25 HBMASTER: job (4, 0, 11) submitted to dispatcher
00:22:25 DISPATCHER: Trying to submit another job.
00:22:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:22:25 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:22:25 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:22:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:22:25 WORKER: start processing job (4, 0, 11)
00:22:25 WORKER: args: ()
00:22:25 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0016497381057256043, 'num_filters_1': 56, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.028179344071288456}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:23:06 DISPATCHER: Starting worker discovery
00:23:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:23:06 DISPATCHER: Finished worker discovery
00:24:06 DISPATCHER: Starting worker discovery
00:24:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:24:06 DISPATCHER: Finished worker discovery
00:25:06 DISPATCHER: Starting worker discovery
00:25:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:25:06 DISPATCHER: Finished worker discovery
00:25:24 WORKER: done with job (4, 0, 11), trying to register it.
00:25:24 WORKER: registered result for job (4, 0, 11) with dispatcher
00:25:24 DISPATCHER: job (4, 0, 11) finished
00:25:24 DISPATCHER: register_result: lock acquired
00:25:24 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:25:24 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0016497381057256043, 'num_filters_1': 56, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.028179344071288456}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4021955042571872, 'info': {'data03': 0.4021955042571872, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0016497381057256043, 'num_filters_1': 56, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.028179344071288456}"}}
exception: None

00:25:24 job_callback for (4, 0, 11) started
00:25:24 DISPATCHER: Trying to submit another job.
00:25:24 job_callback for (4, 0, 11) got condition
00:25:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:25:24 HBMASTER: Trying to run another job!
00:25:24 job_callback for (4, 0, 11) finished
00:25:24 HBMASTER: schedule new run for iteration 4
00:25:24 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
00:25:24 HBMASTER: submitting job (4, 0, 13) to dispatcher
00:25:24 DISPATCHER: trying to submit job (4, 0, 13)
00:25:24 DISPATCHER: trying to notify the job_runner thread.
00:25:24 HBMASTER: job (4, 0, 13) submitted to dispatcher
00:25:24 DISPATCHER: Trying to submit another job.
00:25:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:25:24 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:25:24 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:25:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:25:24 WORKER: start processing job (4, 0, 13)
00:25:24 WORKER: args: ()
00:25:24 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0032781232576182266, 'num_filters_1': 26, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.13943299716602606, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 17, 'num_filters_3': 31}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:26:06 DISPATCHER: Starting worker discovery
00:26:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:26:06 DISPATCHER: Finished worker discovery
00:27:06 DISPATCHER: Starting worker discovery
00:27:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:27:06 DISPATCHER: Finished worker discovery
00:28:06 DISPATCHER: Starting worker discovery
00:28:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:28:06 DISPATCHER: Finished worker discovery
00:28:27 WORKER: done with job (4, 0, 13), trying to register it.
00:28:27 WORKER: registered result for job (4, 0, 13) with dispatcher
00:28:27 DISPATCHER: job (4, 0, 13) finished
00:28:27 DISPATCHER: register_result: lock acquired
00:28:27 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:28:27 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0032781232576182266, 'num_filters_1': 26, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.13943299716602606, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 17, 'num_filters_3': 31}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.36697750907804666, 'info': {'data03': 0.36697750907804666, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0032781232576182266, 'num_filters_1': 26, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.13943299716602606, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 17, 'num_filters_3': 31}"}}
exception: None

00:28:27 job_callback for (4, 0, 13) started
00:28:27 DISPATCHER: Trying to submit another job.
00:28:27 job_callback for (4, 0, 13) got condition
00:28:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:28:27 HBMASTER: Trying to run another job!
00:28:27 job_callback for (4, 0, 13) finished
00:28:27 HBMASTER: schedule new run for iteration 4
00:28:27 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
00:28:27 HBMASTER: submitting job (4, 0, 15) to dispatcher
00:28:27 DISPATCHER: trying to submit job (4, 0, 15)
00:28:27 DISPATCHER: trying to notify the job_runner thread.
00:28:27 HBMASTER: job (4, 0, 15) submitted to dispatcher
00:28:27 DISPATCHER: Trying to submit another job.
00:28:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:28:27 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:28:27 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:28:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:28:27 WORKER: start processing job (4, 0, 15)
00:28:27 WORKER: args: ()
00:28:27 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.001906330714192054, 'num_filters_1': 123, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.01655064718559458, 'kernel_size_2': 7, 'num_filters_2': 44}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:29:06 DISPATCHER: Starting worker discovery
00:29:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:29:06 DISPATCHER: Finished worker discovery
00:30:06 DISPATCHER: Starting worker discovery
00:30:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:30:06 DISPATCHER: Finished worker discovery
00:31:06 DISPATCHER: Starting worker discovery
00:31:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:31:06 DISPATCHER: Finished worker discovery
00:31:29 WORKER: done with job (4, 0, 15), trying to register it.
00:31:29 WORKER: registered result for job (4, 0, 15) with dispatcher
00:31:29 DISPATCHER: job (4, 0, 15) finished
00:31:29 DISPATCHER: register_result: lock acquired
00:31:29 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:31:29 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.001906330714192054, 'num_filters_1': 123, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.01655064718559458, 'kernel_size_2': 7, 'num_filters_2': 44}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.41676865356850856, 'info': {'data03': 0.41676865356850856, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.001906330714192054, 'num_filters_1': 123, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.01655064718559458, 'kernel_size_2': 7, 'num_filters_2': 44}"}}
exception: None

00:31:29 job_callback for (4, 0, 15) started
00:31:29 job_callback for (4, 0, 15) got condition
00:31:29 DISPATCHER: Trying to submit another job.
00:31:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:31:29 HBMASTER: Trying to run another job!
00:31:29 job_callback for (4, 0, 15) finished
00:31:29 HBMASTER: schedule new run for iteration 4
00:31:29 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
00:31:29 HBMASTER: submitting job (4, 0, 18) to dispatcher
00:31:29 DISPATCHER: trying to submit job (4, 0, 18)
00:31:29 DISPATCHER: trying to notify the job_runner thread.
00:31:29 HBMASTER: job (4, 0, 18) submitted to dispatcher
00:31:29 DISPATCHER: Trying to submit another job.
00:31:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:31:29 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:31:29 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:31:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:31:29 WORKER: start processing job (4, 0, 18)
00:31:29 WORKER: args: ()
00:31:29 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0017989756755406269, 'num_filters_1': 97, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.13884687783406066, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 18, 'num_filters_3': 47}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:32:06 DISPATCHER: Starting worker discovery
00:32:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:32:06 DISPATCHER: Finished worker discovery
00:33:06 DISPATCHER: Starting worker discovery
00:33:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:33:06 DISPATCHER: Finished worker discovery
00:34:06 DISPATCHER: Starting worker discovery
00:34:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:34:06 DISPATCHER: Finished worker discovery
00:34:33 WORKER: done with job (4, 0, 18), trying to register it.
00:34:33 WORKER: registered result for job (4, 0, 18) with dispatcher
00:34:33 DISPATCHER: job (4, 0, 18) finished
00:34:33 DISPATCHER: register_result: lock acquired
00:34:33 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:34:33 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0017989756755406269, 'num_filters_1': 97, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.13884687783406066, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 18, 'num_filters_3': 47}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2453769814643295, 'info': {'data03': 0.2453769814643295, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0017989756755406269, 'num_filters_1': 97, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.13884687783406066, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 18, 'num_filters_3': 47}"}}
exception: None

00:34:33 job_callback for (4, 0, 18) started
00:34:33 DISPATCHER: Trying to submit another job.
00:34:33 job_callback for (4, 0, 18) got condition
00:34:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:34:33 HBMASTER: Trying to run another job!
00:34:33 job_callback for (4, 0, 18) finished
00:34:33 HBMASTER: schedule new run for iteration 4
00:34:33 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
00:34:33 HBMASTER: submitting job (4, 0, 21) to dispatcher
00:34:33 DISPATCHER: trying to submit job (4, 0, 21)
00:34:33 DISPATCHER: trying to notify the job_runner thread.
00:34:33 HBMASTER: job (4, 0, 21) submitted to dispatcher
00:34:33 DISPATCHER: Trying to submit another job.
00:34:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:34:33 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:34:33 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:34:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:34:33 WORKER: start processing job (4, 0, 21)
00:34:33 WORKER: args: ()
00:34:33 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0012808922511372645, 'num_filters_1': 53, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.058778416295566446, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 31, 'num_filters_3': 84, 'num_filters_4': 96}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:35:06 DISPATCHER: Starting worker discovery
00:35:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:35:06 DISPATCHER: Finished worker discovery
00:36:06 DISPATCHER: Starting worker discovery
00:36:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:36:06 DISPATCHER: Finished worker discovery
00:37:06 DISPATCHER: Starting worker discovery
00:37:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:37:06 DISPATCHER: Finished worker discovery
00:37:30 WORKER: done with job (4, 0, 21), trying to register it.
00:37:30 WORKER: registered result for job (4, 0, 21) with dispatcher
00:37:30 DISPATCHER: job (4, 0, 21) finished
00:37:30 DISPATCHER: register_result: lock acquired
00:37:30 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:37:30 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0012808922511372645, 'num_filters_1': 53, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.058778416295566446, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 31, 'num_filters_3': 84, 'num_filters_4': 96}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.35298991677788183, 'info': {'data03': 0.35298991677788183, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0012808922511372645, 'num_filters_1': 53, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.058778416295566446, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 31, 'num_filters_3': 84, 'num_filters_4': 96}"}}
exception: None

00:37:30 job_callback for (4, 0, 21) started
00:37:30 DISPATCHER: Trying to submit another job.
00:37:30 job_callback for (4, 0, 21) got condition
00:37:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:37:30 HBMASTER: Trying to run another job!
00:37:30 job_callback for (4, 0, 21) finished
00:37:30 HBMASTER: schedule new run for iteration 4
00:37:30 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
00:37:30 HBMASTER: submitting job (4, 0, 22) to dispatcher
00:37:30 DISPATCHER: trying to submit job (4, 0, 22)
00:37:30 DISPATCHER: trying to notify the job_runner thread.
00:37:30 HBMASTER: job (4, 0, 22) submitted to dispatcher
00:37:30 DISPATCHER: Trying to submit another job.
00:37:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:37:30 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:37:30 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:37:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:37:30 WORKER: start processing job (4, 0, 22)
00:37:30 WORKER: args: ()
00:37:30 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0014492194986415892, 'num_filters_1': 32, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.14494878009882584, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 19, 'num_filters_3': 101}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:38:06 DISPATCHER: Starting worker discovery
00:38:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:38:06 DISPATCHER: Finished worker discovery
00:39:06 DISPATCHER: Starting worker discovery
00:39:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:39:06 DISPATCHER: Finished worker discovery
00:40:06 DISPATCHER: Starting worker discovery
00:40:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:40:06 DISPATCHER: Finished worker discovery
00:40:23 WORKER: done with job (4, 0, 22), trying to register it.
00:40:23 WORKER: registered result for job (4, 0, 22) with dispatcher
00:40:23 DISPATCHER: job (4, 0, 22) finished
00:40:23 DISPATCHER: register_result: lock acquired
00:40:23 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:40:23 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0014492194986415892, 'num_filters_1': 32, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.14494878009882584, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 19, 'num_filters_3': 101}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3229375949265483, 'info': {'data03': 0.3229375949265483, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0014492194986415892, 'num_filters_1': 32, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.14494878009882584, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 19, 'num_filters_3': 101}"}}
exception: None

00:40:23 job_callback for (4, 0, 22) started
00:40:23 job_callback for (4, 0, 22) got condition
00:40:23 DISPATCHER: Trying to submit another job.
00:40:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:40:23 HBMASTER: Trying to run another job!
00:40:23 job_callback for (4, 0, 22) finished
00:40:23 HBMASTER: schedule new run for iteration 4
00:40:23 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
00:40:23 HBMASTER: submitting job (4, 0, 23) to dispatcher
00:40:23 DISPATCHER: trying to submit job (4, 0, 23)
00:40:23 DISPATCHER: trying to notify the job_runner thread.
00:40:23 HBMASTER: job (4, 0, 23) submitted to dispatcher
00:40:23 DISPATCHER: Trying to submit another job.
00:40:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:40:23 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:40:23 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:40:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:40:23 WORKER: start processing job (4, 0, 23)
00:40:23 WORKER: args: ()
00:40:23 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0010111536909623074, 'num_filters_1': 67, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.024046768702275418, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 21, 'num_filters_3': 33}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:41:06 DISPATCHER: Starting worker discovery
00:41:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:41:06 DISPATCHER: Finished worker discovery
00:42:06 DISPATCHER: Starting worker discovery
00:42:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:42:06 DISPATCHER: Finished worker discovery
00:43:06 DISPATCHER: Starting worker discovery
00:43:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:43:06 DISPATCHER: Finished worker discovery
00:43:24 WORKER: done with job (4, 0, 23), trying to register it.
00:43:24 WORKER: registered result for job (4, 0, 23) with dispatcher
00:43:24 DISPATCHER: job (4, 0, 23) finished
00:43:24 DISPATCHER: register_result: lock acquired
00:43:24 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:43:24 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0010111536909623074, 'num_filters_1': 67, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.024046768702275418, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 21, 'num_filters_3': 33}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3342549452246201, 'info': {'data03': 0.3342549452246201, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0010111536909623074, 'num_filters_1': 67, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.024046768702275418, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 21, 'num_filters_3': 33}"}}
exception: None

00:43:24 job_callback for (4, 0, 23) started
00:43:24 job_callback for (4, 0, 23) got condition
00:43:24 DISPATCHER: Trying to submit another job.
00:43:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:43:24 HBMASTER: Trying to run another job!
00:43:24 job_callback for (4, 0, 23) finished
00:43:24 HBMASTER: schedule new run for iteration 4
00:43:24 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
00:43:24 HBMASTER: submitting job (4, 0, 24) to dispatcher
00:43:24 DISPATCHER: trying to submit job (4, 0, 24)
00:43:24 DISPATCHER: trying to notify the job_runner thread.
00:43:24 HBMASTER: job (4, 0, 24) submitted to dispatcher
00:43:24 DISPATCHER: Trying to submit another job.
00:43:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:43:24 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:43:24 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:43:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:43:24 WORKER: start processing job (4, 0, 24)
00:43:24 WORKER: args: ()
00:43:24 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0010553497638028657, 'num_filters_1': 32, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.04821512901317377}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:44:06 DISPATCHER: Starting worker discovery
00:44:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:44:06 DISPATCHER: Finished worker discovery
00:45:06 DISPATCHER: Starting worker discovery
00:45:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:45:06 DISPATCHER: Finished worker discovery
00:46:06 DISPATCHER: Starting worker discovery
00:46:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:46:06 DISPATCHER: Finished worker discovery
00:46:26 WORKER: done with job (4, 0, 24), trying to register it.
00:46:26 WORKER: registered result for job (4, 0, 24) with dispatcher
00:46:26 DISPATCHER: job (4, 0, 24) finished
00:46:26 DISPATCHER: register_result: lock acquired
00:46:26 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:46:26 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0010553497638028657, 'num_filters_1': 32, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.04821512901317377}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3451123822788206, 'info': {'data03': 0.3451123822788206, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0010553497638028657, 'num_filters_1': 32, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.04821512901317377}"}}
exception: None

00:46:26 job_callback for (4, 0, 24) started
00:46:26 DISPATCHER: Trying to submit another job.
00:46:26 job_callback for (4, 0, 24) got condition
00:46:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:46:26 HBMASTER: Trying to run another job!
00:46:26 job_callback for (4, 0, 24) finished
00:46:26 ITERATION: Advancing config (4, 0, 2) to next budget 400.000000
00:46:26 ITERATION: Advancing config (4, 0, 11) to next budget 400.000000
00:46:26 ITERATION: Advancing config (4, 0, 15) to next budget 400.000000
00:46:26 HBMASTER: schedule new run for iteration 4
00:46:26 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
00:46:26 HBMASTER: submitting job (4, 0, 2) to dispatcher
00:46:26 DISPATCHER: trying to submit job (4, 0, 2)
00:46:26 DISPATCHER: trying to notify the job_runner thread.
00:46:26 HBMASTER: job (4, 0, 2) submitted to dispatcher
00:46:26 DISPATCHER: Trying to submit another job.
00:46:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:46:26 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:46:26 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:46:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:46:26 WORKER: start processing job (4, 0, 2)
00:46:26 WORKER: args: ()
00:46:26 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004383507818056009, 'num_filters_1': 58, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.038739849792668084, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 31, 'num_filters_3': 19}, 'budget': 400.0, 'working_directory': '.'}
00:47:06 DISPATCHER: Starting worker discovery
00:47:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:47:06 DISPATCHER: Finished worker discovery
00:48:06 DISPATCHER: Starting worker discovery
00:48:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:48:06 DISPATCHER: Finished worker discovery
00:49:06 DISPATCHER: Starting worker discovery
00:49:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:49:06 DISPATCHER: Finished worker discovery
00:50:06 DISPATCHER: Starting worker discovery
00:50:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:50:06 DISPATCHER: Finished worker discovery
00:51:06 DISPATCHER: Starting worker discovery
00:51:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:51:06 DISPATCHER: Finished worker discovery
00:52:06 DISPATCHER: Starting worker discovery
00:52:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:52:06 DISPATCHER: Finished worker discovery
00:53:06 DISPATCHER: Starting worker discovery
00:53:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:53:06 DISPATCHER: Finished worker discovery
00:53:54 WORKER: done with job (4, 0, 2), trying to register it.
00:53:54 WORKER: registered result for job (4, 0, 2) with dispatcher
00:53:54 DISPATCHER: job (4, 0, 2) finished
00:53:54 DISPATCHER: register_result: lock acquired
00:53:54 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
00:53:54 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004383507818056009, 'num_filters_1': 58, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.038739849792668084, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 31, 'num_filters_3': 19}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.362649672692795, 'info': {'data03': 0.362649672692795, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004383507818056009, 'num_filters_1': 58, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.038739849792668084, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 31, 'num_filters_3': 19}"}}
exception: None

00:53:54 job_callback for (4, 0, 2) started
00:53:54 job_callback for (4, 0, 2) got condition
00:53:54 DISPATCHER: Trying to submit another job.
00:53:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:53:54 Only 13 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
00:53:54 HBMASTER: Trying to run another job!
00:53:54 job_callback for (4, 0, 2) finished
00:53:54 HBMASTER: schedule new run for iteration 4
00:53:54 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
00:53:54 HBMASTER: submitting job (4, 0, 11) to dispatcher
00:53:54 DISPATCHER: trying to submit job (4, 0, 11)
00:53:54 DISPATCHER: trying to notify the job_runner thread.
00:53:54 HBMASTER: job (4, 0, 11) submitted to dispatcher
00:53:54 DISPATCHER: Trying to submit another job.
00:53:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:53:54 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776
00:53:54 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
00:53:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:53:54 WORKER: start processing job (4, 0, 11)
00:53:54 WORKER: args: ()
00:53:54 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0016497381057256043, 'num_filters_1': 56, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.028179344071288456}, 'budget': 400.0, 'working_directory': '.'}
00:54:06 DISPATCHER: Starting worker discovery
00:54:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:54:06 DISPATCHER: Finished worker discovery
00:55:06 DISPATCHER: Starting worker discovery
00:55:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:55:06 DISPATCHER: Finished worker discovery
00:56:06 DISPATCHER: Starting worker discovery
00:56:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:56:07 DISPATCHER: Finished worker discovery
00:57:07 DISPATCHER: Starting worker discovery
00:57:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:57:07 DISPATCHER: Finished worker discovery
00:58:07 DISPATCHER: Starting worker discovery
00:58:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:58:07 DISPATCHER: Finished worker discovery
00:59:07 DISPATCHER: Starting worker discovery
00:59:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:59:07 DISPATCHER: Finished worker discovery
01:00:07 DISPATCHER: Starting worker discovery
01:00:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:00:07 DISPATCHER: Finished worker discovery
01:01:07 DISPATCHER: Starting worker discovery
01:01:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:01:07 DISPATCHER: Finished worker discovery
01:01:27 WORKER: done with job (4, 0, 11), trying to register it.
01:01:27 WORKER: registered result for job (4, 0, 11) with dispatcher
01:01:27 DISPATCHER: job (4, 0, 11) finished
01:01:27 DISPATCHER: register_result: lock acquired
01:01:27 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:01:27 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0016497381057256043, 'num_filters_1': 56, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.028179344071288456}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.33945632207208587, 'info': {'data03': 0.33945632207208587, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0016497381057256043, 'num_filters_1': 56, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 85, 'weight_decay': 0.028179344071288456}"}}
exception: None

01:01:27 job_callback for (4, 0, 11) started
01:01:27 job_callback for (4, 0, 11) got condition
01:01:27 DISPATCHER: Trying to submit another job.
01:01:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:01:27 Only 14 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
01:01:27 HBMASTER: Trying to run another job!
01:01:27 job_callback for (4, 0, 11) finished
01:01:27 HBMASTER: schedule new run for iteration 4
01:01:27 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
01:01:27 HBMASTER: submitting job (4, 0, 15) to dispatcher
01:01:27 DISPATCHER: trying to submit job (4, 0, 15)
01:01:27 DISPATCHER: trying to notify the job_runner thread.
01:01:27 HBMASTER: job (4, 0, 15) submitted to dispatcher
01:01:27 DISPATCHER: Trying to submit another job.
01:01:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:01:27 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:01:27 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:01:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:01:27 WORKER: start processing job (4, 0, 15)
01:01:27 WORKER: args: ()
01:01:27 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.001906330714192054, 'num_filters_1': 123, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.01655064718559458, 'kernel_size_2': 7, 'num_filters_2': 44}, 'budget': 400.0, 'working_directory': '.'}
01:02:07 DISPATCHER: Starting worker discovery
01:02:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:02:07 DISPATCHER: Finished worker discovery
01:03:07 DISPATCHER: Starting worker discovery
01:03:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:03:07 DISPATCHER: Finished worker discovery
01:04:07 DISPATCHER: Starting worker discovery
01:04:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:04:07 DISPATCHER: Finished worker discovery
01:05:07 DISPATCHER: Starting worker discovery
01:05:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:05:07 DISPATCHER: Finished worker discovery
01:06:07 DISPATCHER: Starting worker discovery
01:06:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:06:07 DISPATCHER: Finished worker discovery
01:07:07 DISPATCHER: Starting worker discovery
01:07:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:07:07 DISPATCHER: Finished worker discovery
01:08:07 DISPATCHER: Starting worker discovery
01:08:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:08:07 DISPATCHER: Finished worker discovery
01:08:54 WORKER: done with job (4, 0, 15), trying to register it.
01:08:54 WORKER: registered result for job (4, 0, 15) with dispatcher
01:08:54 DISPATCHER: job (4, 0, 15) finished
01:08:54 DISPATCHER: register_result: lock acquired
01:08:54 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:08:54 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.001906330714192054, 'num_filters_1': 123, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.01655064718559458, 'kernel_size_2': 7, 'num_filters_2': 44}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3690762975799883, 'info': {'data03': 0.3690762975799883, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.001906330714192054, 'num_filters_1': 123, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.01655064718559458, 'kernel_size_2': 7, 'num_filters_2': 44}"}}
exception: None

01:08:54 job_callback for (4, 0, 15) started
01:08:54 job_callback for (4, 0, 15) got condition
01:08:54 DISPATCHER: Trying to submit another job.
01:08:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:08:54 Only 15 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
01:08:54 HBMASTER: Trying to run another job!
01:08:54 job_callback for (4, 0, 15) finished
01:08:54 ITERATION: Advancing config (4, 0, 15) to next budget 1200.000000
01:08:54 HBMASTER: schedule new run for iteration 4
01:08:54 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
01:08:54 HBMASTER: submitting job (4, 0, 15) to dispatcher
01:08:54 DISPATCHER: trying to submit job (4, 0, 15)
01:08:54 DISPATCHER: trying to notify the job_runner thread.
01:08:54 HBMASTER: job (4, 0, 15) submitted to dispatcher
01:08:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:08:54 DISPATCHER: Trying to submit another job.
01:08:54 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:08:54 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:08:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:08:54 WORKER: start processing job (4, 0, 15)
01:08:54 WORKER: args: ()
01:08:54 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.001906330714192054, 'num_filters_1': 123, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.01655064718559458, 'kernel_size_2': 7, 'num_filters_2': 44}, 'budget': 1200.0, 'working_directory': '.'}
01:09:07 DISPATCHER: Starting worker discovery
01:09:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:09:07 DISPATCHER: Finished worker discovery
01:10:07 DISPATCHER: Starting worker discovery
01:10:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:10:07 DISPATCHER: Finished worker discovery
01:11:07 DISPATCHER: Starting worker discovery
01:11:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:11:07 DISPATCHER: Finished worker discovery
01:12:07 DISPATCHER: Starting worker discovery
01:12:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:12:07 DISPATCHER: Finished worker discovery
01:13:07 DISPATCHER: Starting worker discovery
01:13:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:13:07 DISPATCHER: Finished worker discovery
01:14:07 DISPATCHER: Starting worker discovery
01:14:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:14:07 DISPATCHER: Finished worker discovery
01:15:07 DISPATCHER: Starting worker discovery
01:15:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:15:07 DISPATCHER: Finished worker discovery
01:16:07 DISPATCHER: Starting worker discovery
01:16:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:16:07 DISPATCHER: Finished worker discovery
01:17:07 DISPATCHER: Starting worker discovery
01:17:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:17:07 DISPATCHER: Finished worker discovery
01:18:07 DISPATCHER: Starting worker discovery
01:18:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:18:07 DISPATCHER: Finished worker discovery
01:19:07 DISPATCHER: Starting worker discovery
01:19:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:19:07 DISPATCHER: Finished worker discovery
01:20:07 DISPATCHER: Starting worker discovery
01:20:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:20:07 DISPATCHER: Finished worker discovery
01:21:07 DISPATCHER: Starting worker discovery
01:21:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:21:07 DISPATCHER: Finished worker discovery
01:22:07 DISPATCHER: Starting worker discovery
01:22:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:22:07 DISPATCHER: Finished worker discovery
01:23:07 DISPATCHER: Starting worker discovery
01:23:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:23:07 DISPATCHER: Finished worker discovery
01:24:07 DISPATCHER: Starting worker discovery
01:24:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:24:07 DISPATCHER: Finished worker discovery
01:25:07 DISPATCHER: Starting worker discovery
01:25:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:25:07 DISPATCHER: Finished worker discovery
01:26:07 DISPATCHER: Starting worker discovery
01:26:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:26:07 DISPATCHER: Finished worker discovery
01:27:07 DISPATCHER: Starting worker discovery
01:27:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:27:07 DISPATCHER: Finished worker discovery
01:28:07 DISPATCHER: Starting worker discovery
01:28:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:28:07 DISPATCHER: Finished worker discovery
01:29:07 DISPATCHER: Starting worker discovery
01:29:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:29:07 DISPATCHER: Finished worker discovery
01:29:46 WORKER: done with job (4, 0, 15), trying to register it.
01:29:46 WORKER: registered result for job (4, 0, 15) with dispatcher
01:29:46 DISPATCHER: job (4, 0, 15) finished
01:29:46 DISPATCHER: register_result: lock acquired
01:29:46 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:29:46 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.001906330714192054, 'num_filters_1': 123, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.01655064718559458, 'kernel_size_2': 7, 'num_filters_2': 44}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.37534720493524776, 'info': {'data03': 0.37534720493524776, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.001906330714192054, 'num_filters_1': 123, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.01655064718559458, 'kernel_size_2': 7, 'num_filters_2': 44}"}}
exception: None

01:29:46 job_callback for (4, 0, 15) started
01:29:46 job_callback for (4, 0, 15) got condition
01:29:46 DISPATCHER: Trying to submit another job.
01:29:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:29:46 Only 9 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
01:29:46 HBMASTER: Trying to run another job!
01:29:46 job_callback for (4, 0, 15) finished
01:29:46 start sampling a new configuration.
01:29:46 best_vector: [0, 2, 0.015502737834499042, 0.23461119979090994, 0.8925939345054063, 1, 0.997462123806163, 0.5688147772890638, 2, 1, 2, 0, 0.1773520363007718, 0.8949842454690168, 0.8022460157238176, 0.9402237894840034], 0.0001653029859564402, 0.0009980942780120252, 1.6498796442142512e-07
01:29:46 done sampling a new configuration.
01:29:46 HBMASTER: schedule new run for iteration 5
01:29:46 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
01:29:46 HBMASTER: submitting job (5, 0, 0) to dispatcher
01:29:46 DISPATCHER: trying to submit job (5, 0, 0)
01:29:46 DISPATCHER: trying to notify the job_runner thread.
01:29:46 HBMASTER: job (5, 0, 0) submitted to dispatcher
01:29:46 DISPATCHER: Trying to submit another job.
01:29:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:29:46 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:29:46 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:29:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:29:46 WORKER: start processing job (5, 0, 0)
01:29:46 WORKER: args: ()
01:29:46 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0010740029534932697, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.05495979286050461, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 23, 'num_filters_3': 103, 'num_filters_4': 85, 'num_filters_5': 113}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:30:07 DISPATCHER: Starting worker discovery
01:30:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:30:07 DISPATCHER: Finished worker discovery
01:31:07 DISPATCHER: Starting worker discovery
01:31:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:31:07 DISPATCHER: Finished worker discovery
01:32:07 DISPATCHER: Starting worker discovery
01:32:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:32:07 DISPATCHER: Finished worker discovery
01:32:51 WORKER: done with job (5, 0, 0), trying to register it.
01:32:51 WORKER: registered result for job (5, 0, 0) with dispatcher
01:32:51 DISPATCHER: job (5, 0, 0) finished
01:32:51 DISPATCHER: register_result: lock acquired
01:32:51 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:32:51 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0010740029534932697, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.05495979286050461, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 23, 'num_filters_3': 103, 'num_filters_4': 85, 'num_filters_5': 113}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3665880486157732, 'info': {'data03': 0.3665880486157732, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0010740029534932697, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.05495979286050461, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 23, 'num_filters_3': 103, 'num_filters_4': 85, 'num_filters_5': 113}"}}
exception: None

01:32:51 job_callback for (5, 0, 0) started
01:32:51 DISPATCHER: Trying to submit another job.
01:32:51 job_callback for (5, 0, 0) got condition
01:32:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:32:51 HBMASTER: Trying to run another job!
01:32:51 job_callback for (5, 0, 0) finished
01:32:51 start sampling a new configuration.
01:32:52 best_vector: [3, 2, 0.28849591084552173, 0.6666596141024436, 0.34650778228726553, 1, 0.13123898441743023, 0.3607117455965956, 2, 2, 2, 2, 0.263467808580537, 0.06333588380726407, 0.797274201864101, 0.8006911559015701], 1.8379517724085247e-29, 0.0005440839172235518, -4.543752741699477e-06
01:32:52 done sampling a new configuration.
01:32:52 HBMASTER: schedule new run for iteration 5
01:32:52 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
01:32:52 HBMASTER: submitting job (5, 0, 1) to dispatcher
01:32:52 DISPATCHER: trying to submit job (5, 0, 1)
01:32:52 DISPATCHER: trying to notify the job_runner thread.
01:32:52 HBMASTER: job (5, 0, 1) submitted to dispatcher
01:32:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:32:52 DISPATCHER: Trying to submit another job.
01:32:52 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:32:52 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:32:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:32:52 WORKER: start processing job (5, 0, 1)
01:32:52 WORKER: args: ()
01:32:52 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.003775650808351774, 'num_filters_1': 63, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.029464345661448007, 'kernel_size_2': 7, 'num_filters_2': 27}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:33:07 DISPATCHER: Starting worker discovery
01:33:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:33:07 DISPATCHER: Finished worker discovery
01:34:07 DISPATCHER: Starting worker discovery
01:34:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:34:07 DISPATCHER: Finished worker discovery
01:35:07 DISPATCHER: Starting worker discovery
01:35:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:35:07 DISPATCHER: Finished worker discovery
01:35:47 WORKER: done with job (5, 0, 1), trying to register it.
01:35:47 WORKER: registered result for job (5, 0, 1) with dispatcher
01:35:47 DISPATCHER: job (5, 0, 1) finished
01:35:47 DISPATCHER: register_result: lock acquired
01:35:47 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:35:47 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.003775650808351774, 'num_filters_1': 63, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.029464345661448007, 'kernel_size_2': 7, 'num_filters_2': 27}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3583703460840669, 'info': {'data03': 0.3583703460840669, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.003775650808351774, 'num_filters_1': 63, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.029464345661448007, 'kernel_size_2': 7, 'num_filters_2': 27}"}}
exception: None

01:35:47 job_callback for (5, 0, 1) started
01:35:47 job_callback for (5, 0, 1) got condition
01:35:47 DISPATCHER: Trying to submit another job.
01:35:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:35:47 HBMASTER: Trying to run another job!
01:35:47 job_callback for (5, 0, 1) finished
01:35:47 start sampling a new configuration.
01:35:47 done sampling a new configuration.
01:35:47 HBMASTER: schedule new run for iteration 5
01:35:47 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
01:35:47 HBMASTER: submitting job (5, 0, 2) to dispatcher
01:35:47 DISPATCHER: trying to submit job (5, 0, 2)
01:35:47 DISPATCHER: trying to notify the job_runner thread.
01:35:47 HBMASTER: job (5, 0, 2) submitted to dispatcher
01:35:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:35:47 DISPATCHER: Trying to submit another job.
01:35:47 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:35:47 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:35:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:35:47 WORKER: start processing job (5, 0, 2)
01:35:47 WORKER: args: ()
01:35:47 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.02918844922245601, 'num_filters_1': 16, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.03146590519379833, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 35, 'num_filters_3': 16}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:36:07 DISPATCHER: Starting worker discovery
01:36:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:36:07 DISPATCHER: Finished worker discovery
01:37:07 DISPATCHER: Starting worker discovery
01:37:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:37:07 DISPATCHER: Finished worker discovery
01:38:07 DISPATCHER: Starting worker discovery
01:38:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:38:07 DISPATCHER: Finished worker discovery
01:38:46 WORKER: done with job (5, 0, 2), trying to register it.
01:38:46 WORKER: registered result for job (5, 0, 2) with dispatcher
01:38:46 DISPATCHER: job (5, 0, 2) finished
01:38:46 DISPATCHER: register_result: lock acquired
01:38:46 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:38:46 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.02918844922245601, 'num_filters_1': 16, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.03146590519379833, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 35, 'num_filters_3': 16}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3116656767630302, 'info': {'data03': 0.3116656767630302, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.02918844922245601, 'num_filters_1': 16, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.03146590519379833, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 35, 'num_filters_3': 16}"}}
exception: None

01:38:46 job_callback for (5, 0, 2) started
01:38:46 job_callback for (5, 0, 2) got condition
01:38:46 DISPATCHER: Trying to submit another job.
01:38:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:38:46 HBMASTER: Trying to run another job!
01:38:46 job_callback for (5, 0, 2) finished
01:38:46 start sampling a new configuration.
01:38:47 best_vector: [3, 2, 0.16136141804430226, 0.809751782937181, 0.20764781839223223, 1, 0.1746066919782076, 0.8395084288377184, 1, 1, 1, 0, 0.05200318041255009, 0.7856332322658139, 0.7432790126323494, 0.5797427847336103], 9.661527223656216e-29, 0.00010350330510392845, -1.1356245406113395e-06
01:38:47 done sampling a new configuration.
01:38:47 HBMASTER: schedule new run for iteration 5
01:38:47 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
01:38:47 HBMASTER: submitting job (5, 0, 3) to dispatcher
01:38:47 DISPATCHER: trying to submit job (5, 0, 3)
01:38:47 DISPATCHER: trying to notify the job_runner thread.
01:38:47 HBMASTER: job (5, 0, 3) submitted to dispatcher
01:38:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:38:47 DISPATCHER: Trying to submit another job.
01:38:47 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:38:47 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:38:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:38:47 WORKER: start processing job (5, 0, 3)
01:38:47 WORKER: args: ()
01:38:47 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0021024362503941677, 'num_filters_1': 86, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.12365897647701676, 'kernel_size_2': 5, 'num_filters_2': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:39:07 DISPATCHER: Starting worker discovery
01:39:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:39:07 DISPATCHER: Finished worker discovery
01:40:07 DISPATCHER: Starting worker discovery
01:40:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:40:07 DISPATCHER: Finished worker discovery
01:41:07 DISPATCHER: Starting worker discovery
01:41:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:41:07 DISPATCHER: Finished worker discovery
01:41:41 WORKER: done with job (5, 0, 3), trying to register it.
01:41:41 WORKER: registered result for job (5, 0, 3) with dispatcher
01:41:41 DISPATCHER: job (5, 0, 3) finished
01:41:41 DISPATCHER: register_result: lock acquired
01:41:41 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:41:41 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0021024362503941677, 'num_filters_1': 86, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.12365897647701676, 'kernel_size_2': 5, 'num_filters_2': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.398839634271861, 'info': {'data03': 0.398839634271861, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0021024362503941677, 'num_filters_1': 86, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.12365897647701676, 'kernel_size_2': 5, 'num_filters_2': 17}"}}
exception: None

01:41:41 job_callback for (5, 0, 3) started
01:41:41 DISPATCHER: Trying to submit another job.
01:41:41 job_callback for (5, 0, 3) got condition
01:41:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:41:41 HBMASTER: Trying to run another job!
01:41:41 job_callback for (5, 0, 3) finished
01:41:41 start sampling a new configuration.
01:41:41 best_vector: [1, 1, 0.09914816173449731, 0.28135718219244155, 0.20923867004927488, 1, 0.6163154894309545, 0.232516530917085, 1, 1, 2, 0, 0.6727724322994153, 0.39891786477365715, 0.9354104485050567, 0.8287308817985413], 0.0016136243290401503, 0.009703560036960525, 1.5657900553941243e-05
01:41:41 done sampling a new configuration.
01:41:41 HBMASTER: schedule new run for iteration 5
01:41:41 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
01:41:41 HBMASTER: submitting job (5, 0, 4) to dispatcher
01:41:41 DISPATCHER: trying to submit job (5, 0, 4)
01:41:41 DISPATCHER: trying to notify the job_runner thread.
01:41:41 HBMASTER: job (5, 0, 4) submitted to dispatcher
01:41:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:41:41 DISPATCHER: Trying to submit another job.
01:41:41 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:41:41 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:41:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:41:41 WORKER: start processing job (5, 0, 4)
01:41:41 WORKER: args: ()
01:41:41 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0015786880569581651, 'num_filters_1': 28, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.020068318324655866, 'kernel_size_2': 5, 'num_filters_2': 64}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:42:07 DISPATCHER: Starting worker discovery
01:42:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:42:07 DISPATCHER: Finished worker discovery
01:43:07 DISPATCHER: Starting worker discovery
01:43:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:43:07 DISPATCHER: Finished worker discovery
01:44:07 DISPATCHER: Starting worker discovery
01:44:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:44:07 DISPATCHER: Finished worker discovery
01:44:39 WORKER: done with job (5, 0, 4), trying to register it.
01:44:39 WORKER: registered result for job (5, 0, 4) with dispatcher
01:44:39 DISPATCHER: job (5, 0, 4) finished
01:44:39 DISPATCHER: register_result: lock acquired
01:44:39 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:44:39 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0015786880569581651, 'num_filters_1': 28, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.020068318324655866, 'kernel_size_2': 5, 'num_filters_2': 64}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3267357797410864, 'info': {'data03': 0.3267357797410864, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0015786880569581651, 'num_filters_1': 28, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 66, 'weight_decay': 0.020068318324655866, 'kernel_size_2': 5, 'num_filters_2': 64}"}}
exception: None

01:44:39 job_callback for (5, 0, 4) started
01:44:39 DISPATCHER: Trying to submit another job.
01:44:39 job_callback for (5, 0, 4) got condition
01:44:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:44:39 HBMASTER: Trying to run another job!
01:44:39 job_callback for (5, 0, 4) finished
01:44:39 start sampling a new configuration.
01:44:39 done sampling a new configuration.
01:44:39 HBMASTER: schedule new run for iteration 5
01:44:39 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
01:44:39 HBMASTER: submitting job (5, 0, 5) to dispatcher
01:44:39 DISPATCHER: trying to submit job (5, 0, 5)
01:44:39 DISPATCHER: trying to notify the job_runner thread.
01:44:39 HBMASTER: job (5, 0, 5) submitted to dispatcher
01:44:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:44:39 DISPATCHER: Trying to submit another job.
01:44:39 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:44:39 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:44:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:44:39 WORKER: start processing job (5, 0, 5)
01:44:39 WORKER: args: ()
01:44:39 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.037427551860580645, 'num_filters_1': 36, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.0172129991329256, 'kernel_size_2': 7, 'num_filters_2': 18}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:45:07 DISPATCHER: Starting worker discovery
01:45:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:45:07 DISPATCHER: Finished worker discovery
01:46:07 DISPATCHER: Starting worker discovery
01:46:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:46:07 DISPATCHER: Finished worker discovery
01:47:07 DISPATCHER: Starting worker discovery
01:47:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:47:07 DISPATCHER: Finished worker discovery
01:47:35 WORKER: done with job (5, 0, 5), trying to register it.
01:47:35 WORKER: registered result for job (5, 0, 5) with dispatcher
01:47:35 DISPATCHER: job (5, 0, 5) finished
01:47:35 DISPATCHER: register_result: lock acquired
01:47:35 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:47:35 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.037427551860580645, 'num_filters_1': 36, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.0172129991329256, 'kernel_size_2': 7, 'num_filters_2': 18}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.037427551860580645, 'num_filters_1': 36, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.0172129991329256, 'kernel_size_2': 7, 'num_filters_2': 18}"}}
exception: None

01:47:35 job_callback for (5, 0, 5) started
01:47:35 DISPATCHER: Trying to submit another job.
01:47:35 job_callback for (5, 0, 5) got condition
01:47:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:47:35 HBMASTER: Trying to run another job!
01:47:35 job_callback for (5, 0, 5) finished
01:47:35 start sampling a new configuration.
01:47:35 best_vector: [3, 0, 0.016472861290369886, 0.5162100221009454, 0.836588613963451, 1, 0.8084560724381943, 0.5125733401733683, 2, 1, 0, 0, 0.23131771527840592, 0.853176566945683, 0.8907746773512785, 0.8831619394233616], 0.00013742970765171118, 0.033516944337021286, 4.606223861615512e-06
01:47:35 done sampling a new configuration.
01:47:35 HBMASTER: schedule new run for iteration 5
01:47:35 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
01:47:35 HBMASTER: submitting job (5, 0, 6) to dispatcher
01:47:35 DISPATCHER: trying to submit job (5, 0, 6)
01:47:35 DISPATCHER: trying to notify the job_runner thread.
01:47:35 HBMASTER: job (5, 0, 6) submitted to dispatcher
01:47:35 DISPATCHER: Trying to submit another job.
01:47:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:47:35 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:47:35 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:47:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:47:35 WORKER: start processing job (5, 0, 6)
01:47:35 WORKER: args: ()
01:47:35 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0010788118856461864, 'num_filters_1': 46, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.04643797683369432, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 25, 'num_filters_3': 94, 'num_filters_4': 102, 'num_filters_5': 100}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:48:07 DISPATCHER: Starting worker discovery
01:48:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:48:07 DISPATCHER: Finished worker discovery
01:49:07 DISPATCHER: Starting worker discovery
01:49:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:49:07 DISPATCHER: Finished worker discovery
01:50:07 DISPATCHER: Starting worker discovery
01:50:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:50:07 DISPATCHER: Finished worker discovery
01:50:40 WORKER: done with job (5, 0, 6), trying to register it.
01:50:40 WORKER: registered result for job (5, 0, 6) with dispatcher
01:50:40 DISPATCHER: job (5, 0, 6) finished
01:50:40 DISPATCHER: register_result: lock acquired
01:50:40 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:50:40 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0010788118856461864, 'num_filters_1': 46, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.04643797683369432, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 25, 'num_filters_3': 94, 'num_filters_4': 102, 'num_filters_5': 100}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4013906214891957, 'info': {'data03': 0.4013906214891957, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0010788118856461864, 'num_filters_1': 46, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.04643797683369432, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 25, 'num_filters_3': 94, 'num_filters_4': 102, 'num_filters_5': 100}"}}
exception: None

01:50:40 job_callback for (5, 0, 6) started
01:50:40 DISPATCHER: Trying to submit another job.
01:50:40 job_callback for (5, 0, 6) got condition
01:50:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:50:40 done building a new model for budget 133.333333 based on 17/28 split
Best loss for this budget:-0.416769





01:50:40 HBMASTER: Trying to run another job!
01:50:40 job_callback for (5, 0, 6) finished
01:50:40 start sampling a new configuration.
01:50:40 best_vector: [0, 1, 0.15925266882956865, 0.5232979015516772, 0.5842001164914741, 1, 0.8399666984922736, 0.8470766248267522, 1, 1, 2, 0, 0.8198601689525729, 0.49796495095822546, 0.8800998623270442, 0.036827471598644745], 7.585883840968843e-29, 0.0001318237954817251, 1.5108863538152906e-39
01:50:40 done sampling a new configuration.
01:50:40 HBMASTER: schedule new run for iteration 5
01:50:40 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
01:50:40 HBMASTER: submitting job (5, 0, 7) to dispatcher
01:50:40 DISPATCHER: trying to submit job (5, 0, 7)
01:50:40 DISPATCHER: trying to notify the job_runner thread.
01:50:40 HBMASTER: job (5, 0, 7) submitted to dispatcher
01:50:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:50:40 DISPATCHER: Trying to submit another job.
01:50:40 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:50:40 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:50:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:50:40 WORKER: start processing job (5, 0, 7)
01:50:40 WORKER: args: ()
01:50:40 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0020821179951557704, 'num_filters_1': 47, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.1264946324650129, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 88, 'num_filters_3': 44}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:51:07 DISPATCHER: Starting worker discovery
01:51:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:51:07 DISPATCHER: Finished worker discovery
01:52:07 DISPATCHER: Starting worker discovery
01:52:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:52:07 DISPATCHER: Finished worker discovery
01:53:07 DISPATCHER: Starting worker discovery
01:53:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:53:07 DISPATCHER: Finished worker discovery
01:53:41 WORKER: done with job (5, 0, 7), trying to register it.
01:53:41 WORKER: registered result for job (5, 0, 7) with dispatcher
01:53:41 DISPATCHER: job (5, 0, 7) finished
01:53:41 DISPATCHER: register_result: lock acquired
01:53:41 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:53:41 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0020821179951557704, 'num_filters_1': 47, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.1264946324650129, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 88, 'num_filters_3': 44}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3286564086582152, 'info': {'data03': 0.3286564086582152, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0020821179951557704, 'num_filters_1': 47, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.1264946324650129, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 88, 'num_filters_3': 44}"}}
exception: None

01:53:41 job_callback for (5, 0, 7) started
01:53:41 DISPATCHER: Trying to submit another job.
01:53:41 job_callback for (5, 0, 7) got condition
01:53:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:53:41 done building a new model for budget 133.333333 based on 17/29 split
Best loss for this budget:-0.416769





01:53:41 HBMASTER: Trying to run another job!
01:53:41 job_callback for (5, 0, 7) finished
01:53:41 start sampling a new configuration.
01:53:41 done sampling a new configuration.
01:53:41 HBMASTER: schedule new run for iteration 5
01:53:41 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
01:53:41 HBMASTER: submitting job (5, 0, 8) to dispatcher
01:53:41 DISPATCHER: trying to submit job (5, 0, 8)
01:53:41 DISPATCHER: trying to notify the job_runner thread.
01:53:41 HBMASTER: job (5, 0, 8) submitted to dispatcher
01:53:41 DISPATCHER: Trying to submit another job.
01:53:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:53:41 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:53:41 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:53:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:53:41 WORKER: start processing job (5, 0, 8)
01:53:41 WORKER: args: ()
01:53:41 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.09742161866089495, 'num_filters_1': 128, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 53, 'weight_decay': 0.04321141054426215, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 59, 'num_filters_3': 44, 'num_filters_4': 42, 'num_filters_5': 22}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:54:07 DISPATCHER: Starting worker discovery
01:54:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:54:07 DISPATCHER: Finished worker discovery
01:55:07 DISPATCHER: Starting worker discovery
01:55:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:55:07 DISPATCHER: Finished worker discovery
01:56:07 DISPATCHER: Starting worker discovery
01:56:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:56:07 DISPATCHER: Finished worker discovery
01:56:43 WORKER: done with job (5, 0, 8), trying to register it.
01:56:43 WORKER: registered result for job (5, 0, 8) with dispatcher
01:56:43 DISPATCHER: job (5, 0, 8) finished
01:56:43 DISPATCHER: register_result: lock acquired
01:56:43 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
01:56:43 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.09742161866089495, 'num_filters_1': 128, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 53, 'weight_decay': 0.04321141054426215, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 59, 'num_filters_3': 44, 'num_filters_4': 42, 'num_filters_5': 22}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.09742161866089495, 'num_filters_1': 128, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 53, 'weight_decay': 0.04321141054426215, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 59, 'num_filters_3': 44, 'num_filters_4': 42, 'num_filters_5': 22}"}}
exception: None

01:56:43 job_callback for (5, 0, 8) started
01:56:43 DISPATCHER: Trying to submit another job.
01:56:43 job_callback for (5, 0, 8) got condition
01:56:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:56:43 done building a new model for budget 133.333333 based on 17/30 split
Best loss for this budget:-0.416769





01:56:43 HBMASTER: Trying to run another job!
01:56:43 job_callback for (5, 0, 8) finished
01:56:43 ITERATION: Advancing config (5, 0, 0) to next budget 400.000000
01:56:43 ITERATION: Advancing config (5, 0, 3) to next budget 400.000000
01:56:43 ITERATION: Advancing config (5, 0, 6) to next budget 400.000000
01:56:43 HBMASTER: schedule new run for iteration 5
01:56:43 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
01:56:43 HBMASTER: submitting job (5, 0, 0) to dispatcher
01:56:43 DISPATCHER: trying to submit job (5, 0, 0)
01:56:43 DISPATCHER: trying to notify the job_runner thread.
01:56:43 HBMASTER: job (5, 0, 0) submitted to dispatcher
01:56:43 DISPATCHER: Trying to submit another job.
01:56:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:56:43 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
01:56:43 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
01:56:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:56:43 WORKER: start processing job (5, 0, 0)
01:56:43 WORKER: args: ()
01:56:43 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0010740029534932697, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.05495979286050461, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 23, 'num_filters_3': 103, 'num_filters_4': 85, 'num_filters_5': 113}, 'budget': 400.0, 'working_directory': '.'}
01:57:07 DISPATCHER: Starting worker discovery
01:57:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:57:07 DISPATCHER: Finished worker discovery
01:58:07 DISPATCHER: Starting worker discovery
01:58:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:58:07 DISPATCHER: Finished worker discovery
01:59:07 DISPATCHER: Starting worker discovery
01:59:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:59:07 DISPATCHER: Finished worker discovery
02:00:07 DISPATCHER: Starting worker discovery
02:00:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:00:07 DISPATCHER: Finished worker discovery
02:01:07 DISPATCHER: Starting worker discovery
02:01:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:01:07 DISPATCHER: Finished worker discovery
02:02:07 DISPATCHER: Starting worker discovery
02:02:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:02:07 DISPATCHER: Finished worker discovery
02:03:07 DISPATCHER: Starting worker discovery
02:03:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:03:07 DISPATCHER: Finished worker discovery
02:04:07 DISPATCHER: Starting worker discovery
02:04:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:04:07 DISPATCHER: Finished worker discovery
02:04:09 WORKER: done with job (5, 0, 0), trying to register it.
02:04:09 WORKER: registered result for job (5, 0, 0) with dispatcher
02:04:09 DISPATCHER: job (5, 0, 0) finished
02:04:09 DISPATCHER: register_result: lock acquired
02:04:09 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
02:04:09 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0010740029534932697, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.05495979286050461, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 23, 'num_filters_3': 103, 'num_filters_4': 85, 'num_filters_5': 113}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3305993550844933, 'info': {'data03': 0.3305993550844933, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0010740029534932697, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.05495979286050461, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 23, 'num_filters_3': 103, 'num_filters_4': 85, 'num_filters_5': 113}"}}
exception: None

02:04:09 job_callback for (5, 0, 0) started
02:04:09 DISPATCHER: Trying to submit another job.
02:04:09 job_callback for (5, 0, 0) got condition
02:04:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:04:09 Only 16 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
02:04:09 HBMASTER: Trying to run another job!
02:04:09 job_callback for (5, 0, 0) finished
02:04:09 HBMASTER: schedule new run for iteration 5
02:04:09 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
02:04:09 HBMASTER: submitting job (5, 0, 3) to dispatcher
02:04:09 DISPATCHER: trying to submit job (5, 0, 3)
02:04:09 DISPATCHER: trying to notify the job_runner thread.
02:04:09 HBMASTER: job (5, 0, 3) submitted to dispatcher
02:04:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:04:09 DISPATCHER: Trying to submit another job.
02:04:09 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
02:04:09 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
02:04:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:04:09 WORKER: start processing job (5, 0, 3)
02:04:09 WORKER: args: ()
02:04:09 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0021024362503941677, 'num_filters_1': 86, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.12365897647701676, 'kernel_size_2': 5, 'num_filters_2': 17}, 'budget': 400.0, 'working_directory': '.'}
02:05:07 DISPATCHER: Starting worker discovery
02:05:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:05:07 DISPATCHER: Finished worker discovery
02:06:07 DISPATCHER: Starting worker discovery
02:06:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:06:07 DISPATCHER: Finished worker discovery
02:07:07 DISPATCHER: Starting worker discovery
02:07:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:07:07 DISPATCHER: Finished worker discovery
02:08:07 DISPATCHER: Starting worker discovery
02:08:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:08:07 DISPATCHER: Finished worker discovery
02:09:07 DISPATCHER: Starting worker discovery
02:09:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:09:07 DISPATCHER: Finished worker discovery
02:10:07 DISPATCHER: Starting worker discovery
02:10:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:10:07 DISPATCHER: Finished worker discovery
02:11:07 DISPATCHER: Starting worker discovery
02:11:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:11:07 DISPATCHER: Finished worker discovery
02:11:34 WORKER: done with job (5, 0, 3), trying to register it.
02:11:34 WORKER: registered result for job (5, 0, 3) with dispatcher
02:11:34 DISPATCHER: job (5, 0, 3) finished
02:11:34 DISPATCHER: register_result: lock acquired
02:11:34 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
02:11:34 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0021024362503941677, 'num_filters_1': 86, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.12365897647701676, 'kernel_size_2': 5, 'num_filters_2': 17}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.34466308132974, 'info': {'data03': 0.34466308132974, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0021024362503941677, 'num_filters_1': 86, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.12365897647701676, 'kernel_size_2': 5, 'num_filters_2': 17}"}}
exception: None

02:11:34 job_callback for (5, 0, 3) started
02:11:34 DISPATCHER: Trying to submit another job.
02:11:34 job_callback for (5, 0, 3) got condition
02:11:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:11:34 HBMASTER: Trying to run another job!
02:11:34 job_callback for (5, 0, 3) finished
02:11:34 HBMASTER: schedule new run for iteration 5
02:11:34 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
02:11:34 HBMASTER: submitting job (5, 0, 6) to dispatcher
02:11:34 DISPATCHER: trying to submit job (5, 0, 6)
02:11:34 DISPATCHER: trying to notify the job_runner thread.
02:11:34 HBMASTER: job (5, 0, 6) submitted to dispatcher
02:11:34 DISPATCHER: Trying to submit another job.
02:11:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:11:34 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776
02:11:34 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
02:11:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:11:34 WORKER: start processing job (5, 0, 6)
02:11:34 WORKER: args: ()
02:11:34 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0010788118856461864, 'num_filters_1': 46, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.04643797683369432, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 25, 'num_filters_3': 94, 'num_filters_4': 102, 'num_filters_5': 100}, 'budget': 400.0, 'working_directory': '.'}
02:12:07 DISPATCHER: Starting worker discovery
02:12:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:12:07 DISPATCHER: Finished worker discovery
02:13:07 DISPATCHER: Starting worker discovery
02:13:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:13:07 DISPATCHER: Finished worker discovery
02:14:07 DISPATCHER: Starting worker discovery
02:14:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:14:07 DISPATCHER: Finished worker discovery
02:15:07 DISPATCHER: Starting worker discovery
02:15:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:15:07 DISPATCHER: Finished worker discovery
02:16:07 DISPATCHER: Starting worker discovery
02:16:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:16:07 DISPATCHER: Finished worker discovery
02:17:07 DISPATCHER: Starting worker discovery
02:17:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:17:07 DISPATCHER: Finished worker discovery
02:18:07 DISPATCHER: Starting worker discovery
02:18:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:18:07 DISPATCHER: Finished worker discovery
02:19:00 WORKER: done with job (5, 0, 6), trying to register it.
02:19:00 WORKER: registered result for job (5, 0, 6) with dispatcher
02:19:00 DISPATCHER: job (5, 0, 6) finished
02:19:00 DISPATCHER: register_result: lock acquired
02:19:00 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
02:19:00 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0010788118856461864, 'num_filters_1': 46, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.04643797683369432, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 25, 'num_filters_3': 94, 'num_filters_4': 102, 'num_filters_5': 100}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.35368329189792413, 'info': {'data03': 0.35368329189792413, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0010788118856461864, 'num_filters_1': 46, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.04643797683369432, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 25, 'num_filters_3': 94, 'num_filters_4': 102, 'num_filters_5': 100}"}}
exception: None

02:19:00 job_callback for (5, 0, 6) started
02:19:00 job_callback for (5, 0, 6) got condition
02:19:00 DISPATCHER: Trying to submit another job.
02:19:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:19:00 HBMASTER: Trying to run another job!
02:19:00 job_callback for (5, 0, 6) finished
02:19:00 ITERATION: Advancing config (5, 0, 6) to next budget 1200.000000
02:19:00 HBMASTER: schedule new run for iteration 5
02:19:00 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
02:19:00 HBMASTER: submitting job (5, 0, 6) to dispatcher
02:19:00 DISPATCHER: trying to submit job (5, 0, 6)
02:19:00 DISPATCHER: trying to notify the job_runner thread.
02:19:00 HBMASTER: job (5, 0, 6) submitted to dispatcher
02:19:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:19:00 DISPATCHER: Trying to submit another job.
02:19:00 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776
02:19:00 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
02:19:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:19:00 WORKER: start processing job (5, 0, 6)
02:19:00 WORKER: args: ()
02:19:00 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0010788118856461864, 'num_filters_1': 46, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.04643797683369432, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 25, 'num_filters_3': 94, 'num_filters_4': 102, 'num_filters_5': 100}, 'budget': 1200.0, 'working_directory': '.'}
02:19:07 DISPATCHER: Starting worker discovery
02:19:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:19:07 DISPATCHER: Finished worker discovery
02:20:07 DISPATCHER: Starting worker discovery
02:20:07 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:20:07 DISPATCHER: Finished worker discovery
02:21:07 DISPATCHER: Starting worker discovery
02:21:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:21:08 DISPATCHER: Finished worker discovery
02:22:08 DISPATCHER: Starting worker discovery
02:22:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:22:08 DISPATCHER: Finished worker discovery
02:23:08 DISPATCHER: Starting worker discovery
02:23:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:23:08 DISPATCHER: Finished worker discovery
02:24:08 DISPATCHER: Starting worker discovery
02:24:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:24:08 DISPATCHER: Finished worker discovery
02:25:08 DISPATCHER: Starting worker discovery
02:25:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:25:08 DISPATCHER: Finished worker discovery
02:26:08 DISPATCHER: Starting worker discovery
02:26:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:26:08 DISPATCHER: Finished worker discovery
02:27:08 DISPATCHER: Starting worker discovery
02:27:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:27:08 DISPATCHER: Finished worker discovery
02:28:08 DISPATCHER: Starting worker discovery
02:28:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:28:08 DISPATCHER: Finished worker discovery
02:29:08 DISPATCHER: Starting worker discovery
02:29:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:29:08 DISPATCHER: Finished worker discovery
02:30:08 DISPATCHER: Starting worker discovery
02:30:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:30:08 DISPATCHER: Finished worker discovery
02:31:08 DISPATCHER: Starting worker discovery
02:31:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:31:08 DISPATCHER: Finished worker discovery
02:32:08 DISPATCHER: Starting worker discovery
02:32:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:32:08 DISPATCHER: Finished worker discovery
02:33:08 DISPATCHER: Starting worker discovery
02:33:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:33:08 DISPATCHER: Finished worker discovery
02:34:08 DISPATCHER: Starting worker discovery
02:34:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:34:08 DISPATCHER: Finished worker discovery
02:35:08 DISPATCHER: Starting worker discovery
02:35:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:35:08 DISPATCHER: Finished worker discovery
02:36:08 DISPATCHER: Starting worker discovery
02:36:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:36:08 DISPATCHER: Finished worker discovery
02:37:08 DISPATCHER: Starting worker discovery
02:37:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:37:08 DISPATCHER: Finished worker discovery
02:38:08 DISPATCHER: Starting worker discovery
02:38:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:38:08 DISPATCHER: Finished worker discovery
02:39:08 DISPATCHER: Starting worker discovery
02:39:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:39:08 DISPATCHER: Finished worker discovery
02:39:51 WORKER: done with job (5, 0, 6), trying to register it.
02:39:51 WORKER: registered result for job (5, 0, 6) with dispatcher
02:39:51 DISPATCHER: job (5, 0, 6) finished
02:39:51 DISPATCHER: register_result: lock acquired
02:39:51 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
02:39:51 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0010788118856461864, 'num_filters_1': 46, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.04643797683369432, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 25, 'num_filters_3': 94, 'num_filters_4': 102, 'num_filters_5': 100}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.36113219470628277, 'info': {'data03': 0.36113219470628277, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0010788118856461864, 'num_filters_1': 46, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.04643797683369432, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 25, 'num_filters_3': 94, 'num_filters_4': 102, 'num_filters_5': 100}"}}
exception: None

02:39:51 job_callback for (5, 0, 6) started
02:39:51 job_callback for (5, 0, 6) got condition
02:39:51 DISPATCHER: Trying to submit another job.
02:39:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:39:51 Only 10 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
02:39:51 HBMASTER: Trying to run another job!
02:39:51 job_callback for (5, 0, 6) finished
02:39:51 start sampling a new configuration.
02:39:51 done sampling a new configuration.
02:39:51 HBMASTER: schedule new run for iteration 6
02:39:51 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
02:39:51 HBMASTER: submitting job (6, 0, 0) to dispatcher
02:39:51 DISPATCHER: trying to submit job (6, 0, 0)
02:39:51 DISPATCHER: trying to notify the job_runner thread.
02:39:51 HBMASTER: job (6, 0, 0) submitted to dispatcher
02:39:51 DISPATCHER: Trying to submit another job.
02:39:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:39:51 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
02:39:51 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
02:39:51 WORKER: start processing job (6, 0, 0)
02:39:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:39:51 WORKER: args: ()
02:39:51 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00266201772129839, 'num_filters_1': 29, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.01086224121632862}, 'budget': 400.0, 'working_directory': '.'}
02:40:08 DISPATCHER: Starting worker discovery
02:40:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:40:08 DISPATCHER: Finished worker discovery
02:41:08 DISPATCHER: Starting worker discovery
02:41:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:41:08 DISPATCHER: Finished worker discovery
02:42:08 DISPATCHER: Starting worker discovery
02:42:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:42:08 DISPATCHER: Finished worker discovery
02:43:08 DISPATCHER: Starting worker discovery
02:43:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:43:08 DISPATCHER: Finished worker discovery
02:44:08 DISPATCHER: Starting worker discovery
02:44:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:44:08 DISPATCHER: Finished worker discovery
02:45:08 DISPATCHER: Starting worker discovery
02:45:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:45:08 DISPATCHER: Finished worker discovery
02:46:08 DISPATCHER: Starting worker discovery
02:46:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:46:08 DISPATCHER: Finished worker discovery
02:47:08 DISPATCHER: Starting worker discovery
02:47:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:47:08 DISPATCHER: Finished worker discovery
02:47:25 WORKER: done with job (6, 0, 0), trying to register it.
02:47:25 WORKER: registered result for job (6, 0, 0) with dispatcher
02:47:25 DISPATCHER: job (6, 0, 0) finished
02:47:25 DISPATCHER: register_result: lock acquired
02:47:25 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
02:47:25 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00266201772129839, 'num_filters_1': 29, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.01086224121632862}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.24217296620679668, 'info': {'data03': 0.24217296620679668, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00266201772129839, 'num_filters_1': 29, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.01086224121632862}"}}
exception: None

02:47:25 job_callback for (6, 0, 0) started
02:47:25 DISPATCHER: Trying to submit another job.
02:47:25 job_callback for (6, 0, 0) got condition
02:47:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:47:25 HBMASTER: Trying to run another job!
02:47:25 job_callback for (6, 0, 0) finished
02:47:25 start sampling a new configuration.
02:47:25 best_vector: [2, 1, 0.2547948282833379, 0.9769576917470905, 0.9125129587496845, 1, 0.9042777741917426, 0.46172407150727746, 0, 1, 1, 1, 0.9682418814446379, 0.630212989495105, 0.5774030743579683, 0.7128521331147082], 3.312493850787598e-29, 0.00030188735286625036, -2.0544660139832674e-06
02:47:25 done sampling a new configuration.
02:47:25 HBMASTER: schedule new run for iteration 6
02:47:25 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
02:47:25 HBMASTER: submitting job (6, 0, 1) to dispatcher
02:47:25 DISPATCHER: trying to submit job (6, 0, 1)
02:47:25 DISPATCHER: trying to notify the job_runner thread.
02:47:25 HBMASTER: job (6, 0, 1) submitted to dispatcher
02:47:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:47:25 DISPATCHER: Trying to submit another job.
02:47:25 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
02:47:25 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
02:47:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:47:25 WORKER: start processing job (6, 0, 1)
02:47:25 WORKER: args: ()
02:47:25 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0032328805364270664, 'num_filters_1': 122, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.03987648474854971, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 120, 'num_filters_3': 59, 'num_filters_4': 53, 'num_filters_5': 70}, 'budget': 400.0, 'working_directory': '.'}
02:48:08 DISPATCHER: Starting worker discovery
02:48:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:48:08 DISPATCHER: Finished worker discovery
Exception in thread Thread-721:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    preds = np.concatenate(preds)
IndexError: index 4607182418800017408 is out of bounds for axis 0 with size 3

02:49:08 DISPATCHER: Starting worker discovery
02:49:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:49:08 DISPATCHER: Finished worker discovery
02:50:08 DISPATCHER: Starting worker discovery
02:50:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:50:08 DISPATCHER: Finished worker discovery
02:51:08 DISPATCHER: Starting worker discovery
02:51:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:51:08 DISPATCHER: Finished worker discovery
02:52:08 DISPATCHER: Starting worker discovery
02:52:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:52:08 DISPATCHER: Finished worker discovery
02:53:08 DISPATCHER: Starting worker discovery
02:53:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:53:08 DISPATCHER: Finished worker discovery
02:54:08 DISPATCHER: Starting worker discovery
02:54:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:54:08 DISPATCHER: Finished worker discovery
02:54:52 WORKER: done with job (6, 0, 1), trying to register it.
02:54:52 WORKER: registered result for job (6, 0, 1) with dispatcher
02:54:52 DISPATCHER: job (6, 0, 1) finished
02:54:52 DISPATCHER: register_result: lock acquired
02:54:52 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
02:54:52 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0032328805364270664, 'num_filters_1': 122, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.03987648474854971, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 120, 'num_filters_3': 59, 'num_filters_4': 53, 'num_filters_5': 70}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3373825532271621, 'info': {'data03': 0.3373825532271621, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0032328805364270664, 'num_filters_1': 122, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.03987648474854971, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 120, 'num_filters_3': 59, 'num_filters_4': 53, 'num_filters_5': 70}"}}
exception: None

02:54:52 job_callback for (6, 0, 1) started
02:54:52 DISPATCHER: Trying to submit another job.
02:54:52 job_callback for (6, 0, 1) got condition
02:54:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:54:52 HBMASTER: Trying to run another job!
02:54:52 job_callback for (6, 0, 1) finished
02:54:52 start sampling a new configuration.
02:54:52 best_vector: [2, 1, 0.8787521320080256, 0.6865832783744363, 0.04921194698428382, 1, 0.07048869623181597, 0.07577512121004154, 0, 0, 1, 0, 0.5327140380414372, 0.8489586740798871, 0.9854337196425037, 0.9892561777926521], 1.1452024953464066e-05, 0.0004972037524501221, 5.693989780014768e-09
02:54:52 done sampling a new configuration.
02:54:52 HBMASTER: schedule new run for iteration 6
02:54:52 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
02:54:52 HBMASTER: submitting job (6, 0, 2) to dispatcher
02:54:52 DISPATCHER: trying to submit job (6, 0, 2)
02:54:52 DISPATCHER: trying to notify the job_runner thread.
02:54:52 HBMASTER: job (6, 0, 2) submitted to dispatcher
02:54:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:54:52 DISPATCHER: Trying to submit another job.
02:54:52 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
02:54:52 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
02:54:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:54:52 WORKER: start processing job (6, 0, 2)
02:54:52 WORKER: args: ()
02:54:52 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0572142572069163, 'num_filters_1': 66, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.012548323476639655}, 'budget': 400.0, 'working_directory': '.'}
02:55:08 DISPATCHER: Starting worker discovery
02:55:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:55:08 DISPATCHER: Finished worker discovery
02:56:08 DISPATCHER: Starting worker discovery
02:56:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:56:08 DISPATCHER: Finished worker discovery
02:57:08 DISPATCHER: Starting worker discovery
02:57:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:57:08 DISPATCHER: Finished worker discovery
02:58:08 DISPATCHER: Starting worker discovery
02:58:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:58:08 DISPATCHER: Finished worker discovery
02:59:08 DISPATCHER: Starting worker discovery
02:59:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:59:08 DISPATCHER: Finished worker discovery
03:00:08 DISPATCHER: Starting worker discovery
03:00:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:00:08 DISPATCHER: Finished worker discovery
03:01:08 DISPATCHER: Starting worker discovery
03:01:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:01:08 DISPATCHER: Finished worker discovery
03:02:08 DISPATCHER: Starting worker discovery
03:02:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:02:08 DISPATCHER: Finished worker discovery
03:02:23 WORKER: done with job (6, 0, 2), trying to register it.
03:02:23 WORKER: registered result for job (6, 0, 2) with dispatcher
03:02:23 DISPATCHER: job (6, 0, 2) finished
03:02:23 DISPATCHER: register_result: lock acquired
03:02:23 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
03:02:23 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0572142572069163, 'num_filters_1': 66, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.012548323476639655}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.2936541872317652, 'info': {'data03': 0.2936541872317652, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0572142572069163, 'num_filters_1': 66, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.012548323476639655}"}}
exception: None

03:02:23 job_callback for (6, 0, 2) started
03:02:23 job_callback for (6, 0, 2) got condition
03:02:23 DISPATCHER: Trying to submit another job.
03:02:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:02:23 HBMASTER: Trying to run another job!
03:02:23 job_callback for (6, 0, 2) finished
03:02:23 start sampling a new configuration.
03:02:24 best_vector: [0, 2, 0.7632225149506322, 0.4623852154687408, 0.3764191216203707, 1, 0.36141605941167143, 0.9478276930004561, 2, 2, 0, 0, 0.10676218337508311, 0.19355793632521648, 0.8062275975268269, 0.8460950127020013], 4.3939512727353656e-29, 0.00022758559163025725, -1.7721830631559386e-06
03:02:24 done sampling a new configuration.
03:02:24 HBMASTER: schedule new run for iteration 6
03:02:24 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
03:02:24 HBMASTER: submitting job (6, 0, 3) to dispatcher
03:02:24 DISPATCHER: trying to submit job (6, 0, 3)
03:02:24 DISPATCHER: trying to notify the job_runner thread.
03:02:24 HBMASTER: job (6, 0, 3) submitted to dispatcher
03:02:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:02:24 DISPATCHER: Trying to submit another job.
03:02:24 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
03:02:24 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
03:02:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:02:24 WORKER: start processing job (6, 0, 3)
03:02:24 WORKER: args: ()
03:02:24 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.033608182735877824, 'num_filters_1': 41, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.17106149345116933, 'kernel_size_2': 7, 'num_filters_2': 19}, 'budget': 400.0, 'working_directory': '.'}
03:03:08 DISPATCHER: Starting worker discovery
03:03:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:03:08 DISPATCHER: Finished worker discovery
03:04:08 DISPATCHER: Starting worker discovery
03:04:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:04:08 DISPATCHER: Finished worker discovery
03:05:08 DISPATCHER: Starting worker discovery
03:05:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:05:08 DISPATCHER: Finished worker discovery
03:06:08 DISPATCHER: Starting worker discovery
03:06:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:06:08 DISPATCHER: Finished worker discovery
03:07:08 DISPATCHER: Starting worker discovery
03:07:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:07:08 DISPATCHER: Finished worker discovery
03:08:08 DISPATCHER: Starting worker discovery
03:08:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:08:08 DISPATCHER: Finished worker discovery
03:09:08 DISPATCHER: Starting worker discovery
03:09:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:09:08 DISPATCHER: Finished worker discovery
03:09:53 WORKER: done with job (6, 0, 3), trying to register it.
03:09:53 WORKER: registered result for job (6, 0, 3) with dispatcher
03:09:53 DISPATCHER: job (6, 0, 3) finished
03:09:53 DISPATCHER: register_result: lock acquired
03:09:53 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
03:09:53 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.033608182735877824, 'num_filters_1': 41, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.17106149345116933, 'kernel_size_2': 7, 'num_filters_2': 19}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.23432067643100657, 'info': {'data03': 0.23432067643100657, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.033608182735877824, 'num_filters_1': 41, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.17106149345116933, 'kernel_size_2': 7, 'num_filters_2': 19}"}}
exception: None

03:09:53 job_callback for (6, 0, 3) started
03:09:53 job_callback for (6, 0, 3) got condition
03:09:53 DISPATCHER: Trying to submit another job.
03:09:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:09:53 HBMASTER: Trying to run another job!
03:09:53 job_callback for (6, 0, 3) finished
03:09:53 start sampling a new configuration.
03:09:53 done sampling a new configuration.
03:09:53 HBMASTER: schedule new run for iteration 6
03:09:53 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
03:09:53 HBMASTER: submitting job (6, 0, 4) to dispatcher
03:09:53 DISPATCHER: trying to submit job (6, 0, 4)
03:09:53 DISPATCHER: trying to notify the job_runner thread.
03:09:53 HBMASTER: job (6, 0, 4) submitted to dispatcher
03:09:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:09:53 DISPATCHER: Trying to submit another job.
03:09:53 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
03:09:53 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
03:09:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:09:53 WORKER: start processing job (6, 0, 4)
03:09:53 WORKER: args: ()
03:09:53 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.06555692044498318, 'num_filters_1': 66, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.023031405445172865, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 61, 'num_filters_3': 67, 'num_filters_4': 48, 'num_filters_5': 44}, 'budget': 400.0, 'working_directory': '.'}
03:10:08 DISPATCHER: Starting worker discovery
03:10:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:10:08 DISPATCHER: Finished worker discovery
03:11:08 DISPATCHER: Starting worker discovery
03:11:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:11:08 DISPATCHER: Finished worker discovery
03:12:08 DISPATCHER: Starting worker discovery
03:12:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:12:08 DISPATCHER: Finished worker discovery
03:13:08 DISPATCHER: Starting worker discovery
03:13:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:13:08 DISPATCHER: Finished worker discovery
03:14:08 DISPATCHER: Starting worker discovery
03:14:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:14:08 DISPATCHER: Finished worker discovery
03:15:08 DISPATCHER: Starting worker discovery
03:15:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:15:08 DISPATCHER: Finished worker discovery
03:16:08 DISPATCHER: Starting worker discovery
03:16:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:16:08 DISPATCHER: Finished worker discovery
03:17:08 DISPATCHER: Starting worker discovery
03:17:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:17:08 DISPATCHER: Finished worker discovery
03:17:27 WORKER: done with job (6, 0, 4), trying to register it.
03:17:27 WORKER: registered result for job (6, 0, 4) with dispatcher
03:17:27 DISPATCHER: job (6, 0, 4) finished
03:17:27 DISPATCHER: register_result: lock acquired
03:17:27 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
03:17:27 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.06555692044498318, 'num_filters_1': 66, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.023031405445172865, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 61, 'num_filters_3': 67, 'num_filters_4': 48, 'num_filters_5': 44}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.06555692044498318, 'num_filters_1': 66, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.023031405445172865, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 61, 'num_filters_3': 67, 'num_filters_4': 48, 'num_filters_5': 44}"}}
exception: None

03:17:27 job_callback for (6, 0, 4) started
03:17:27 job_callback for (6, 0, 4) got condition
03:17:27 DISPATCHER: Trying to submit another job.
03:17:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:17:27 HBMASTER: Trying to run another job!
03:17:27 job_callback for (6, 0, 4) finished
03:17:27 start sampling a new configuration.
03:17:27 done sampling a new configuration.
03:17:27 HBMASTER: schedule new run for iteration 6
03:17:27 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
03:17:27 HBMASTER: submitting job (6, 0, 5) to dispatcher
03:17:27 DISPATCHER: trying to submit job (6, 0, 5)
03:17:27 DISPATCHER: trying to notify the job_runner thread.
03:17:27 HBMASTER: job (6, 0, 5) submitted to dispatcher
03:17:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:17:27 DISPATCHER: Trying to submit another job.
03:17:27 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
03:17:27 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
03:17:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:17:27 WORKER: start processing job (6, 0, 5)
03:17:27 WORKER: args: ()
03:17:27 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004650912593957847, 'num_filters_1': 97, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.021673381189140035, 'kernel_size_2': 3, 'num_filters_2': 46}, 'budget': 400.0, 'working_directory': '.'}
03:18:08 DISPATCHER: Starting worker discovery
03:18:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:18:08 DISPATCHER: Finished worker discovery
03:19:08 DISPATCHER: Starting worker discovery
03:19:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:19:08 DISPATCHER: Finished worker discovery
03:20:08 DISPATCHER: Starting worker discovery
03:20:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:20:08 DISPATCHER: Finished worker discovery
03:21:08 DISPATCHER: Starting worker discovery
03:21:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:21:08 DISPATCHER: Finished worker discovery
03:22:08 DISPATCHER: Starting worker discovery
03:22:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:22:08 DISPATCHER: Finished worker discovery
03:23:08 DISPATCHER: Starting worker discovery
03:23:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:23:08 DISPATCHER: Finished worker discovery
03:24:08 DISPATCHER: Starting worker discovery
03:24:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:24:09 DISPATCHER: Finished worker discovery
03:24:56 WORKER: done with job (6, 0, 5), trying to register it.
03:24:56 WORKER: registered result for job (6, 0, 5) with dispatcher
03:24:56 DISPATCHER: job (6, 0, 5) finished
03:24:56 DISPATCHER: register_result: lock acquired
03:24:56 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
03:24:56 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004650912593957847, 'num_filters_1': 97, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.021673381189140035, 'kernel_size_2': 3, 'num_filters_2': 46}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.2841236423626947, 'info': {'data03': 0.2841236423626947, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004650912593957847, 'num_filters_1': 97, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.021673381189140035, 'kernel_size_2': 3, 'num_filters_2': 46}"}}
exception: None

03:24:56 job_callback for (6, 0, 5) started
03:24:56 DISPATCHER: Trying to submit another job.
03:24:56 job_callback for (6, 0, 5) got condition
03:24:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:24:56 HBMASTER: Trying to run another job!
03:24:56 job_callback for (6, 0, 5) finished
03:24:56 ITERATION: Advancing config (6, 0, 1) to next budget 1200.000000
03:24:56 ITERATION: Advancing config (6, 0, 2) to next budget 1200.000000
03:24:56 HBMASTER: schedule new run for iteration 6
03:24:56 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
03:24:56 HBMASTER: submitting job (6, 0, 1) to dispatcher
03:24:56 DISPATCHER: trying to submit job (6, 0, 1)
03:24:56 DISPATCHER: trying to notify the job_runner thread.
03:24:56 HBMASTER: job (6, 0, 1) submitted to dispatcher
03:24:56 DISPATCHER: Trying to submit another job.
03:24:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:24:56 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
03:24:56 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
03:24:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:24:56 WORKER: start processing job (6, 0, 1)
03:24:56 WORKER: args: ()
03:24:56 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0032328805364270664, 'num_filters_1': 122, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.03987648474854971, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 120, 'num_filters_3': 59, 'num_filters_4': 53, 'num_filters_5': 70}, 'budget': 1200.0, 'working_directory': '.'}
03:25:09 DISPATCHER: Starting worker discovery
03:25:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:25:09 DISPATCHER: Finished worker discovery
Exception in thread Thread-726:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    preds = np.concatenate(preds)
IndexError: index 4607182418800017408 is out of bounds for axis 0 with size 3

03:26:09 DISPATCHER: Starting worker discovery
03:26:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:26:09 DISPATCHER: Finished worker discovery
03:27:09 DISPATCHER: Starting worker discovery
03:27:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:27:09 DISPATCHER: Finished worker discovery
03:28:09 DISPATCHER: Starting worker discovery
03:28:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:28:09 DISPATCHER: Finished worker discovery
03:29:09 DISPATCHER: Starting worker discovery
03:29:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:29:09 DISPATCHER: Finished worker discovery
03:30:09 DISPATCHER: Starting worker discovery
03:30:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:30:09 DISPATCHER: Finished worker discovery
03:31:09 DISPATCHER: Starting worker discovery
03:31:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:31:09 DISPATCHER: Finished worker discovery
03:32:09 DISPATCHER: Starting worker discovery
03:32:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:32:09 DISPATCHER: Finished worker discovery
03:33:09 DISPATCHER: Starting worker discovery
03:33:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:33:09 DISPATCHER: Finished worker discovery
03:34:09 DISPATCHER: Starting worker discovery
03:34:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:34:09 DISPATCHER: Finished worker discovery
03:35:09 DISPATCHER: Starting worker discovery
03:35:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:35:09 DISPATCHER: Finished worker discovery
03:36:09 DISPATCHER: Starting worker discovery
03:36:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:36:09 DISPATCHER: Finished worker discovery
03:37:09 DISPATCHER: Starting worker discovery
03:37:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:37:09 DISPATCHER: Finished worker discovery
03:38:09 DISPATCHER: Starting worker discovery
03:38:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:38:09 DISPATCHER: Finished worker discovery
03:39:09 DISPATCHER: Starting worker discovery
03:39:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:39:09 DISPATCHER: Finished worker discovery
03:40:09 DISPATCHER: Starting worker discovery
03:40:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:40:09 DISPATCHER: Finished worker discovery
03:41:09 DISPATCHER: Starting worker discovery
03:41:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:41:09 DISPATCHER: Finished worker discovery
03:42:09 DISPATCHER: Starting worker discovery
03:42:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:42:09 DISPATCHER: Finished worker discovery
03:43:09 DISPATCHER: Starting worker discovery
03:43:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:43:09 DISPATCHER: Finished worker discovery
03:44:09 DISPATCHER: Starting worker discovery
03:44:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:44:09 DISPATCHER: Finished worker discovery
03:45:09 DISPATCHER: Starting worker discovery
03:45:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:45:09 DISPATCHER: Finished worker discovery
03:45:42 WORKER: done with job (6, 0, 1), trying to register it.
03:45:42 WORKER: registered result for job (6, 0, 1) with dispatcher
03:45:42 DISPATCHER: job (6, 0, 1) finished
03:45:42 DISPATCHER: register_result: lock acquired
03:45:42 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
03:45:42 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0032328805364270664, 'num_filters_1': 122, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.03987648474854971, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 120, 'num_filters_3': 59, 'num_filters_4': 53, 'num_filters_5': 70}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.3483470794175309, 'info': {'data03': 0.3483470794175309, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0032328805364270664, 'num_filters_1': 122, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.03987648474854971, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 120, 'num_filters_3': 59, 'num_filters_4': 53, 'num_filters_5': 70}"}}
exception: None

03:45:42 job_callback for (6, 0, 1) started
03:45:42 job_callback for (6, 0, 1) got condition
03:45:42 DISPATCHER: Trying to submit another job.
03:45:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:45:42 Only 11 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
03:45:42 HBMASTER: Trying to run another job!
03:45:42 job_callback for (6, 0, 1) finished
03:45:42 HBMASTER: schedule new run for iteration 6
03:45:42 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
03:45:42 HBMASTER: submitting job (6, 0, 2) to dispatcher
03:45:42 DISPATCHER: trying to submit job (6, 0, 2)
03:45:42 DISPATCHER: trying to notify the job_runner thread.
03:45:42 HBMASTER: job (6, 0, 2) submitted to dispatcher
03:45:42 DISPATCHER: Trying to submit another job.
03:45:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:45:42 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
03:45:42 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
03:45:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:45:42 WORKER: start processing job (6, 0, 2)
03:45:42 WORKER: args: ()
03:45:42 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0572142572069163, 'num_filters_1': 66, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.012548323476639655}, 'budget': 1200.0, 'working_directory': '.'}
03:46:09 DISPATCHER: Starting worker discovery
03:46:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:46:09 DISPATCHER: Finished worker discovery
03:47:09 DISPATCHER: Starting worker discovery
03:47:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:47:09 DISPATCHER: Finished worker discovery
03:48:09 DISPATCHER: Starting worker discovery
03:48:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:48:09 DISPATCHER: Finished worker discovery
03:49:09 DISPATCHER: Starting worker discovery
03:49:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:49:09 DISPATCHER: Finished worker discovery
03:50:09 DISPATCHER: Starting worker discovery
03:50:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:50:09 DISPATCHER: Finished worker discovery
03:51:09 DISPATCHER: Starting worker discovery
03:51:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:51:09 DISPATCHER: Finished worker discovery
03:52:09 DISPATCHER: Starting worker discovery
03:52:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:52:09 DISPATCHER: Finished worker discovery
03:53:09 DISPATCHER: Starting worker discovery
03:53:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:53:09 DISPATCHER: Finished worker discovery
03:54:09 DISPATCHER: Starting worker discovery
03:54:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:54:09 DISPATCHER: Finished worker discovery
03:55:09 DISPATCHER: Starting worker discovery
03:55:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:55:09 DISPATCHER: Finished worker discovery
03:56:09 DISPATCHER: Starting worker discovery
03:56:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:56:09 DISPATCHER: Finished worker discovery
03:57:09 DISPATCHER: Starting worker discovery
03:57:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:57:09 DISPATCHER: Finished worker discovery
03:58:09 DISPATCHER: Starting worker discovery
03:58:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:58:09 DISPATCHER: Finished worker discovery
03:59:09 DISPATCHER: Starting worker discovery
03:59:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:59:09 DISPATCHER: Finished worker discovery
04:00:09 DISPATCHER: Starting worker discovery
04:00:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:00:09 DISPATCHER: Finished worker discovery
04:01:09 DISPATCHER: Starting worker discovery
04:01:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:01:09 DISPATCHER: Finished worker discovery
04:02:09 DISPATCHER: Starting worker discovery
04:02:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:02:09 DISPATCHER: Finished worker discovery
04:03:09 DISPATCHER: Starting worker discovery
04:03:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:03:09 DISPATCHER: Finished worker discovery
04:04:09 DISPATCHER: Starting worker discovery
04:04:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:04:09 DISPATCHER: Finished worker discovery
04:05:09 DISPATCHER: Starting worker discovery
04:05:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:05:09 DISPATCHER: Finished worker discovery
04:06:09 DISPATCHER: Starting worker discovery
04:06:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:06:09 DISPATCHER: Finished worker discovery
04:06:38 WORKER: done with job (6, 0, 2), trying to register it.
04:06:38 WORKER: registered result for job (6, 0, 2) with dispatcher
04:06:38 DISPATCHER: job (6, 0, 2) finished
04:06:38 DISPATCHER: register_result: lock acquired
04:06:38 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:06:38 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0572142572069163, 'num_filters_1': 66, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.012548323476639655}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.27571645848669785, 'info': {'data03': 0.27571645848669785, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0572142572069163, 'num_filters_1': 66, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.012548323476639655}"}}
exception: None

04:06:38 job_callback for (6, 0, 2) started
04:06:38 DISPATCHER: Trying to submit another job.
04:06:38 job_callback for (6, 0, 2) got condition
04:06:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:06:38 Only 12 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
04:06:38 HBMASTER: Trying to run another job!
04:06:38 job_callback for (6, 0, 2) finished
04:06:38 start sampling a new configuration.
04:06:38 best_vector: [0, 2, 0.24952295971031502, 0.9851527205235856, 0.4605187876668904, 1, 0.9063475686331701, 0.9993839149959486, 1, 1, 0, 1, 0.6960484614819833, 0.4318895052005909, 0.806788886321097, 0.5030158795932946], 8.536005547983972e-28, 1.1715081420444712e-05, -2.7287723423871316e-06
04:06:38 done sampling a new configuration.
04:06:38 HBMASTER: schedule new run for iteration 7
04:06:38 HBMASTER: trying submitting job (7, 0, 0) to dispatcher
04:06:38 HBMASTER: submitting job (7, 0, 0) to dispatcher
04:06:38 DISPATCHER: trying to submit job (7, 0, 0)
04:06:38 DISPATCHER: trying to notify the job_runner thread.
04:06:38 HBMASTER: job (7, 0, 0) submitted to dispatcher
04:06:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:06:38 DISPATCHER: Trying to submit another job.
04:06:38 DISPATCHER: starting job (7, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:06:38 DISPATCHER: job (7, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:06:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:06:38 WORKER: start processing job (7, 0, 0)
04:06:38 WORKER: args: ()
04:06:38 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.003155338230293, 'num_filters_1': 125, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.1996312152779916, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 68, 'num_filters_3': 39}, 'budget': 1200.0, 'working_directory': '.'}
04:07:09 DISPATCHER: Starting worker discovery
04:07:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:07:09 DISPATCHER: Finished worker discovery
04:08:09 DISPATCHER: Starting worker discovery
04:08:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:08:09 DISPATCHER: Finished worker discovery
04:09:09 DISPATCHER: Starting worker discovery
04:09:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:09:09 DISPATCHER: Finished worker discovery
04:10:09 DISPATCHER: Starting worker discovery
04:10:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:10:09 DISPATCHER: Finished worker discovery
04:11:09 DISPATCHER: Starting worker discovery
04:11:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:11:09 DISPATCHER: Finished worker discovery
04:12:09 DISPATCHER: Starting worker discovery
04:12:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:12:09 DISPATCHER: Finished worker discovery
04:13:09 DISPATCHER: Starting worker discovery
04:13:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:13:09 DISPATCHER: Finished worker discovery
04:14:09 DISPATCHER: Starting worker discovery
04:14:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:14:09 DISPATCHER: Finished worker discovery
04:15:09 DISPATCHER: Starting worker discovery
04:15:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:15:09 DISPATCHER: Finished worker discovery
04:16:09 DISPATCHER: Starting worker discovery
04:16:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:16:09 DISPATCHER: Finished worker discovery
04:17:09 DISPATCHER: Starting worker discovery
04:17:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:17:09 DISPATCHER: Finished worker discovery
04:18:09 DISPATCHER: Starting worker discovery
04:18:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:18:09 DISPATCHER: Finished worker discovery
04:19:09 DISPATCHER: Starting worker discovery
04:19:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:19:09 DISPATCHER: Finished worker discovery
04:20:09 DISPATCHER: Starting worker discovery
04:20:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:20:09 DISPATCHER: Finished worker discovery
04:21:09 DISPATCHER: Starting worker discovery
04:21:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:21:09 DISPATCHER: Finished worker discovery
04:22:09 DISPATCHER: Starting worker discovery
04:22:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:22:09 DISPATCHER: Finished worker discovery
04:23:09 DISPATCHER: Starting worker discovery
04:23:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:23:09 DISPATCHER: Finished worker discovery
04:24:09 DISPATCHER: Starting worker discovery
04:24:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:24:09 DISPATCHER: Finished worker discovery
04:25:09 DISPATCHER: Starting worker discovery
04:25:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:25:09 DISPATCHER: Finished worker discovery
04:26:09 DISPATCHER: Starting worker discovery
04:26:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:26:09 DISPATCHER: Finished worker discovery
04:27:09 DISPATCHER: Starting worker discovery
04:27:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:27:09 DISPATCHER: Finished worker discovery
04:27:29 WORKER: done with job (7, 0, 0), trying to register it.
04:27:29 WORKER: registered result for job (7, 0, 0) with dispatcher
04:27:29 DISPATCHER: job (7, 0, 0) finished
04:27:29 DISPATCHER: register_result: lock acquired
04:27:29 DISPATCHER: job (7, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:27:29 job_id: (7, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.003155338230293, 'num_filters_1': 125, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.1996312152779916, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 68, 'num_filters_3': 39}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.3103901499138352, 'info': {'data03': 0.3103901499138352, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.003155338230293, 'num_filters_1': 125, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 92, 'weight_decay': 0.1996312152779916, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 68, 'num_filters_3': 39}"}}
exception: None

04:27:29 job_callback for (7, 0, 0) started
04:27:29 DISPATCHER: Trying to submit another job.
04:27:29 job_callback for (7, 0, 0) got condition
04:27:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:27:29 Only 13 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
04:27:29 HBMASTER: Trying to run another job!
04:27:29 job_callback for (7, 0, 0) finished
04:27:29 start sampling a new configuration.
04:27:29 best_vector: [0, 1, 0.14349683570813238, 0.3825531102566661, 0.7630103510561724, 1, 0.7439895162327507, 0.6503250819386516, 0, 2, 1, 0, 0.2759624055135596, 0.6650744372459076, 0.8578027099853159, 0.8466100351156813], 1.4117376872300403e-30, 0.007083468898263192, -4.864783478536514e-06
04:27:29 done sampling a new configuration.
04:27:29 HBMASTER: schedule new run for iteration 7
04:27:29 HBMASTER: trying submitting job (7, 0, 1) to dispatcher
04:27:29 HBMASTER: submitting job (7, 0, 1) to dispatcher
04:27:29 DISPATCHER: trying to submit job (7, 0, 1)
04:27:29 DISPATCHER: trying to notify the job_runner thread.
04:27:29 HBMASTER: job (7, 0, 1) submitted to dispatcher
04:27:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:27:29 DISPATCHER: Trying to submit another job.
04:27:29 DISPATCHER: starting job (7, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:27:29 DISPATCHER: job (7, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:27:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:27:29 WORKER: start processing job (7, 0, 1)
04:27:29 WORKER: args: ()
04:27:29 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0019363937464127279, 'num_filters_1': 35, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.07016046173818727, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 28, 'num_filters_3': 63, 'num_filters_4': 95}, 'budget': 1200.0, 'working_directory': '.'}
04:28:09 DISPATCHER: Starting worker discovery
04:28:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:28:09 DISPATCHER: Finished worker discovery
04:29:09 DISPATCHER: Starting worker discovery
04:29:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:29:09 DISPATCHER: Finished worker discovery
04:30:09 DISPATCHER: Starting worker discovery
04:30:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:30:09 DISPATCHER: Finished worker discovery
04:31:09 DISPATCHER: Starting worker discovery
04:31:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:31:09 DISPATCHER: Finished worker discovery
04:32:09 DISPATCHER: Starting worker discovery
04:32:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:32:09 DISPATCHER: Finished worker discovery
04:33:09 DISPATCHER: Starting worker discovery
04:33:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:33:09 DISPATCHER: Finished worker discovery
04:34:09 DISPATCHER: Starting worker discovery
04:34:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:34:09 DISPATCHER: Finished worker discovery
04:35:09 DISPATCHER: Starting worker discovery
04:35:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:35:09 DISPATCHER: Finished worker discovery
04:36:09 DISPATCHER: Starting worker discovery
04:36:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:36:09 DISPATCHER: Finished worker discovery
04:37:09 DISPATCHER: Starting worker discovery
04:37:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:37:09 DISPATCHER: Finished worker discovery
04:38:09 DISPATCHER: Starting worker discovery
04:38:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:38:09 DISPATCHER: Finished worker discovery
04:39:09 DISPATCHER: Starting worker discovery
04:39:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:39:09 DISPATCHER: Finished worker discovery
04:40:09 DISPATCHER: Starting worker discovery
04:40:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:40:09 DISPATCHER: Finished worker discovery
04:41:09 DISPATCHER: Starting worker discovery
04:41:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:41:09 DISPATCHER: Finished worker discovery
04:42:09 DISPATCHER: Starting worker discovery
04:42:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:42:09 DISPATCHER: Finished worker discovery
04:43:09 DISPATCHER: Starting worker discovery
04:43:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:43:09 DISPATCHER: Finished worker discovery
04:44:09 DISPATCHER: Starting worker discovery
04:44:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:44:09 DISPATCHER: Finished worker discovery
04:45:09 DISPATCHER: Starting worker discovery
04:45:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:45:09 DISPATCHER: Finished worker discovery
04:46:09 DISPATCHER: Starting worker discovery
04:46:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:46:09 DISPATCHER: Finished worker discovery
04:47:09 DISPATCHER: Starting worker discovery
04:47:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:47:09 DISPATCHER: Finished worker discovery
04:48:09 DISPATCHER: Starting worker discovery
04:48:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:48:09 DISPATCHER: Finished worker discovery
04:48:20 WORKER: done with job (7, 0, 1), trying to register it.
04:48:20 WORKER: registered result for job (7, 0, 1) with dispatcher
04:48:20 DISPATCHER: job (7, 0, 1) finished
04:48:20 DISPATCHER: register_result: lock acquired
04:48:20 DISPATCHER: job (7, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
04:48:20 job_id: (7, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0019363937464127279, 'num_filters_1': 35, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.07016046173818727, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 28, 'num_filters_3': 63, 'num_filters_4': 95}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.2913833769660702, 'info': {'data03': 0.2913833769660702, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0019363937464127279, 'num_filters_1': 35, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.07016046173818727, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 28, 'num_filters_3': 63, 'num_filters_4': 95}"}}
exception: None

04:48:20 job_callback for (7, 0, 1) started
04:48:20 job_callback for (7, 0, 1) got condition
04:48:20 DISPATCHER: Trying to submit another job.
04:48:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:48:20 Only 14 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
04:48:20 HBMASTER: Trying to run another job!
04:48:20 job_callback for (7, 0, 1) finished
04:48:20 start sampling a new configuration.
04:48:20 done sampling a new configuration.
04:48:20 HBMASTER: schedule new run for iteration 7
04:48:20 HBMASTER: trying submitting job (7, 0, 2) to dispatcher
04:48:20 HBMASTER: submitting job (7, 0, 2) to dispatcher
04:48:20 DISPATCHER: trying to submit job (7, 0, 2)
04:48:20 DISPATCHER: trying to notify the job_runner thread.
04:48:20 HBMASTER: job (7, 0, 2) submitted to dispatcher
04:48:20 DISPATCHER: Trying to submit another job.
04:48:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:48:20 DISPATCHER: starting job (7, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
04:48:20 DISPATCHER: job (7, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
04:48:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:48:20 WORKER: start processing job (7, 0, 2)
04:48:20 WORKER: args: ()
04:48:20 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.002995440096425608, 'num_filters_1': 17, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.018464956990643804, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 70, 'num_filters_3': 46, 'num_filters_4': 46, 'num_filters_5': 72}, 'budget': 1200.0, 'working_directory': '.'}
04:49:09 DISPATCHER: Starting worker discovery
04:49:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:49:09 DISPATCHER: Finished worker discovery
04:50:09 DISPATCHER: Starting worker discovery
04:50:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:50:09 DISPATCHER: Finished worker discovery
04:51:09 DISPATCHER: Starting worker discovery
04:51:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:51:09 DISPATCHER: Finished worker discovery
04:52:09 DISPATCHER: Starting worker discovery
04:52:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:52:09 DISPATCHER: Finished worker discovery
04:53:09 DISPATCHER: Starting worker discovery
04:53:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:53:09 DISPATCHER: Finished worker discovery
04:54:09 DISPATCHER: Starting worker discovery
04:54:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:54:09 DISPATCHER: Finished worker discovery
04:55:09 DISPATCHER: Starting worker discovery
04:55:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:55:09 DISPATCHER: Finished worker discovery
04:56:09 DISPATCHER: Starting worker discovery
04:56:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:56:09 DISPATCHER: Finished worker discovery
04:57:09 DISPATCHER: Starting worker discovery
04:57:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:57:09 DISPATCHER: Finished worker discovery
04:58:09 DISPATCHER: Starting worker discovery
04:58:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:58:10 DISPATCHER: Finished worker discovery
04:59:10 DISPATCHER: Starting worker discovery
04:59:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:59:10 DISPATCHER: Finished worker discovery
05:00:10 DISPATCHER: Starting worker discovery
05:00:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:00:10 DISPATCHER: Finished worker discovery
05:01:10 DISPATCHER: Starting worker discovery
05:01:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:01:10 DISPATCHER: Finished worker discovery
05:02:10 DISPATCHER: Starting worker discovery
05:02:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:02:10 DISPATCHER: Finished worker discovery
05:03:10 DISPATCHER: Starting worker discovery
05:03:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:03:10 DISPATCHER: Finished worker discovery
05:04:10 DISPATCHER: Starting worker discovery
05:04:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:04:10 DISPATCHER: Finished worker discovery
05:05:10 DISPATCHER: Starting worker discovery
05:05:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:05:10 DISPATCHER: Finished worker discovery
05:06:10 DISPATCHER: Starting worker discovery
05:06:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:06:10 DISPATCHER: Finished worker discovery
05:07:10 DISPATCHER: Starting worker discovery
05:07:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:07:10 DISPATCHER: Finished worker discovery
05:08:10 DISPATCHER: Starting worker discovery
05:08:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:08:10 DISPATCHER: Finished worker discovery
05:09:10 DISPATCHER: Starting worker discovery
05:09:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:09:10 DISPATCHER: Finished worker discovery
05:09:10 WORKER: done with job (7, 0, 2), trying to register it.
05:09:10 WORKER: registered result for job (7, 0, 2) with dispatcher
05:09:10 DISPATCHER: job (7, 0, 2) finished
05:09:10 DISPATCHER: register_result: lock acquired
05:09:10 DISPATCHER: job (7, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:09:10 job_id: (7, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.002995440096425608, 'num_filters_1': 17, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.018464956990643804, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 70, 'num_filters_3': 46, 'num_filters_4': 46, 'num_filters_5': 72}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.307409940211385, 'info': {'data03': 0.307409940211385, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.002995440096425608, 'num_filters_1': 17, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.018464956990643804, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 70, 'num_filters_3': 46, 'num_filters_4': 46, 'num_filters_5': 72}"}}
exception: None

05:09:10 job_callback for (7, 0, 2) started
05:09:10 DISPATCHER: Trying to submit another job.
05:09:10 job_callback for (7, 0, 2) got condition
05:09:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:09:10 Only 15 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
05:09:10 HBMASTER: Trying to run another job!
05:09:10 job_callback for (7, 0, 2) finished
05:09:10 start sampling a new configuration.
05:09:10 done sampling a new configuration.
05:09:10 HBMASTER: schedule new run for iteration 7
05:09:10 HBMASTER: trying submitting job (7, 0, 3) to dispatcher
05:09:10 HBMASTER: submitting job (7, 0, 3) to dispatcher
05:09:10 DISPATCHER: trying to submit job (7, 0, 3)
05:09:10 DISPATCHER: trying to notify the job_runner thread.
05:09:10 HBMASTER: job (7, 0, 3) submitted to dispatcher
05:09:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:09:10 DISPATCHER: Trying to submit another job.
05:09:10 DISPATCHER: starting job (7, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:09:10 DISPATCHER: job (7, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:09:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:09:10 WORKER: start processing job (7, 0, 3)
05:09:10 WORKER: args: ()
05:09:10 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.023568649715636974, 'num_filters_1': 57, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.10305256032710021, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 18, 'num_filters_3': 47, 'num_filters_4': 127}, 'budget': 1200.0, 'working_directory': '.'}
05:10:10 DISPATCHER: Starting worker discovery
05:10:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:10:10 DISPATCHER: Finished worker discovery
05:11:10 DISPATCHER: Starting worker discovery
05:11:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:11:10 DISPATCHER: Finished worker discovery
05:12:10 DISPATCHER: Starting worker discovery
05:12:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:12:10 DISPATCHER: Finished worker discovery
05:13:10 DISPATCHER: Starting worker discovery
05:13:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:13:10 DISPATCHER: Finished worker discovery
05:14:10 DISPATCHER: Starting worker discovery
05:14:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:14:10 DISPATCHER: Finished worker discovery
05:15:10 DISPATCHER: Starting worker discovery
05:15:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:15:10 DISPATCHER: Finished worker discovery
05:16:10 DISPATCHER: Starting worker discovery
05:16:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:16:10 DISPATCHER: Finished worker discovery
05:17:10 DISPATCHER: Starting worker discovery
05:17:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:17:10 DISPATCHER: Finished worker discovery
05:18:10 DISPATCHER: Starting worker discovery
05:18:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:18:10 DISPATCHER: Finished worker discovery
05:19:10 DISPATCHER: Starting worker discovery
05:19:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:19:10 DISPATCHER: Finished worker discovery
05:20:10 DISPATCHER: Starting worker discovery
05:20:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:20:10 DISPATCHER: Finished worker discovery
05:21:10 DISPATCHER: Starting worker discovery
05:21:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:21:10 DISPATCHER: Finished worker discovery
05:22:10 DISPATCHER: Starting worker discovery
05:22:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:22:10 DISPATCHER: Finished worker discovery
05:23:10 DISPATCHER: Starting worker discovery
05:23:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:23:10 DISPATCHER: Finished worker discovery
05:24:10 DISPATCHER: Starting worker discovery
05:24:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:24:10 DISPATCHER: Finished worker discovery
05:25:10 DISPATCHER: Starting worker discovery
05:25:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:25:10 DISPATCHER: Finished worker discovery
05:26:10 DISPATCHER: Starting worker discovery
05:26:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:26:10 DISPATCHER: Finished worker discovery
05:27:10 DISPATCHER: Starting worker discovery
05:27:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:27:10 DISPATCHER: Finished worker discovery
05:28:10 DISPATCHER: Starting worker discovery
05:28:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:28:10 DISPATCHER: Finished worker discovery
05:29:10 DISPATCHER: Starting worker discovery
05:29:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:29:10 DISPATCHER: Finished worker discovery
05:29:57 WORKER: done with job (7, 0, 3), trying to register it.
05:29:57 WORKER: registered result for job (7, 0, 3) with dispatcher
05:29:57 DISPATCHER: job (7, 0, 3) finished
05:29:57 DISPATCHER: register_result: lock acquired
05:29:57 DISPATCHER: job (7, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:29:57 job_id: (7, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.023568649715636974, 'num_filters_1': 57, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.10305256032710021, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 18, 'num_filters_3': 47, 'num_filters_4': 127}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.2888092570412758, 'info': {'data03': 0.2888092570412758, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.023568649715636974, 'num_filters_1': 57, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.10305256032710021, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 18, 'num_filters_3': 47, 'num_filters_4': 127}"}}
exception: None

05:29:57 job_callback for (7, 0, 3) started
05:29:57 DISPATCHER: Trying to submit another job.
05:29:57 job_callback for (7, 0, 3) got condition
05:29:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:29:57 Only 16 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
05:29:57 HBMASTER: Trying to run another job!
05:29:57 job_callback for (7, 0, 3) finished
05:29:57 start sampling a new configuration.
05:29:57 best_vector: [0, 1, 0.7514199886008701, 0.230431720391846, 0.3372358280615362, 1, 0.949005282186578, 0.8045002852462011, 0, 0, 0, 1, 0.6439046628305373, 0.849420194530163, 0.6094554284654538, 0.8563564793460112], 3.567760279864115e-26, 2.802878897564516e-07, -2.2711038271377993e-07
05:29:57 done sampling a new configuration.
05:29:57 HBMASTER: schedule new run for iteration 8
05:29:57 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
05:29:57 HBMASTER: submitting job (8, 0, 0) to dispatcher
05:29:57 DISPATCHER: trying to submit job (8, 0, 0)
05:29:57 DISPATCHER: trying to notify the job_runner thread.
05:29:57 HBMASTER: job (8, 0, 0) submitted to dispatcher
05:29:57 DISPATCHER: Trying to submit another job.
05:29:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:29:57 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:29:57 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:29:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:29:57 WORKER: start processing job (8, 0, 0)
05:29:57 WORKER: args: ()
05:29:57 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.03183024468980785, 'num_filters_1': 25, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.11134712363126935, 'kernel_size_2': 3, 'num_filters_2': 61}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:30:10 DISPATCHER: Starting worker discovery
05:30:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:30:10 DISPATCHER: Finished worker discovery
05:31:10 DISPATCHER: Starting worker discovery
05:31:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:31:10 DISPATCHER: Finished worker discovery
05:31:25 WORKER: done with job (8, 0, 0), trying to register it.
05:31:25 WORKER: registered result for job (8, 0, 0) with dispatcher
05:31:25 DISPATCHER: job (8, 0, 0) finished
05:31:25 DISPATCHER: register_result: lock acquired
05:31:25 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:31:25 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.03183024468980785, 'num_filters_1': 25, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.11134712363126935, 'kernel_size_2': 3, 'num_filters_2': 61}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3617791614400095, 'info': {'data03': 0.3617791614400095, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.03183024468980785, 'num_filters_1': 25, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.11134712363126935, 'kernel_size_2': 3, 'num_filters_2': 61}"}}
exception: None

05:31:25 job_callback for (8, 0, 0) started
05:31:25 DISPATCHER: Trying to submit another job.
05:31:25 job_callback for (8, 0, 0) got condition
05:31:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:31:25 HBMASTER: Trying to run another job!
05:31:25 job_callback for (8, 0, 0) finished
05:31:25 start sampling a new configuration.
05:31:25 best_vector: [3, 2, 0.31104911778604427, 0.4544282072116536, 0.8063597455274563, 1, 0.21002086135814282, 0.10304791191055035, 2, 2, 2, 2, 0.3524320293879739, 0.7504039552906916, 0.9632159407567865, 0.6399274779840036], 1.0080467652622903e-28, 9.920174682965263e-05, -7.229996469104453e-06
05:31:25 done sampling a new configuration.
05:31:25 HBMASTER: schedule new run for iteration 8
05:31:25 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
05:31:25 HBMASTER: submitting job (8, 0, 1) to dispatcher
05:31:25 DISPATCHER: trying to submit job (8, 0, 1)
05:31:25 DISPATCHER: trying to notify the job_runner thread.
05:31:25 HBMASTER: job (8, 0, 1) submitted to dispatcher
05:31:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:31:25 DISPATCHER: Trying to submit another job.
05:31:25 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:31:25 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:31:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:31:25 WORKER: start processing job (8, 0, 1)
05:31:25 WORKER: args: ()
05:31:25 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004188883051627881, 'num_filters_1': 41, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.01361659199019734, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 33, 'num_filters_3': 76, 'num_filters_4': 119, 'num_filters_5': 60}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:32:10 DISPATCHER: Starting worker discovery
05:32:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:32:10 DISPATCHER: Finished worker discovery
05:32:57 WORKER: done with job (8, 0, 1), trying to register it.
05:32:57 WORKER: registered result for job (8, 0, 1) with dispatcher
05:32:57 DISPATCHER: job (8, 0, 1) finished
05:32:57 DISPATCHER: register_result: lock acquired
05:32:57 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:32:57 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004188883051627881, 'num_filters_1': 41, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.01361659199019734, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 33, 'num_filters_3': 76, 'num_filters_4': 119, 'num_filters_5': 60}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.34028099199660833, 'info': {'data03': 0.34028099199660833, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004188883051627881, 'num_filters_1': 41, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.01361659199019734, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 33, 'num_filters_3': 76, 'num_filters_4': 119, 'num_filters_5': 60}"}}
exception: None

05:32:57 job_callback for (8, 0, 1) started
05:32:57 DISPATCHER: Trying to submit another job.
05:32:57 job_callback for (8, 0, 1) got condition
05:32:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:32:57 HBMASTER: Trying to run another job!
05:32:57 job_callback for (8, 0, 1) finished
05:32:57 start sampling a new configuration.
05:32:57 best_vector: [0, 2, 0.03244888086502998, 0.9234737024542796, 0.035717215855238904, 1, 0.5235524312186862, 0.811318405056357, 1, 2, 0, 0, 0.7000807956105258, 0.5388683758782893, 0.9579952339719017, 0.2428542751443422], 2.6448836743652806e-29, 0.0003780884617694879, -1.7597724919917026e-07
05:32:57 done sampling a new configuration.
05:32:57 HBMASTER: schedule new run for iteration 8
05:32:57 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
05:32:57 HBMASTER: submitting job (8, 0, 2) to dispatcher
05:32:57 DISPATCHER: trying to submit job (8, 0, 2)
05:32:57 DISPATCHER: trying to notify the job_runner thread.
05:32:57 HBMASTER: job (8, 0, 2) submitted to dispatcher
05:32:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:32:57 DISPATCHER: Trying to submit another job.
05:32:57 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:32:57 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:32:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:32:57 WORKER: start processing job (8, 0, 2)
05:32:57 WORKER: args: ()
05:32:57 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0011611752267125096, 'num_filters_1': 109, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.11364480322835335}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:33:10 DISPATCHER: Starting worker discovery
05:33:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:33:10 DISPATCHER: Finished worker discovery
05:34:10 DISPATCHER: Starting worker discovery
05:34:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:34:10 DISPATCHER: Finished worker discovery
05:34:25 WORKER: done with job (8, 0, 2), trying to register it.
05:34:25 WORKER: registered result for job (8, 0, 2) with dispatcher
05:34:25 DISPATCHER: job (8, 0, 2) finished
05:34:25 DISPATCHER: register_result: lock acquired
05:34:25 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:34:25 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0011611752267125096, 'num_filters_1': 109, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.11364480322835335}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4058552887067447, 'info': {'data03': 0.4058552887067447, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0011611752267125096, 'num_filters_1': 109, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.11364480322835335}"}}
exception: None

05:34:25 job_callback for (8, 0, 2) started
05:34:25 DISPATCHER: Trying to submit another job.
05:34:25 job_callback for (8, 0, 2) got condition
05:34:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:34:25 HBMASTER: Trying to run another job!
05:34:25 job_callback for (8, 0, 2) finished
05:34:25 start sampling a new configuration.
05:34:25 done sampling a new configuration.
05:34:25 HBMASTER: schedule new run for iteration 8
05:34:25 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
05:34:25 HBMASTER: submitting job (8, 0, 3) to dispatcher
05:34:25 DISPATCHER: trying to submit job (8, 0, 3)
05:34:25 DISPATCHER: trying to notify the job_runner thread.
05:34:25 HBMASTER: job (8, 0, 3) submitted to dispatcher
05:34:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:34:25 DISPATCHER: Trying to submit another job.
05:34:25 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:34:25 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:34:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:34:25 WORKER: start processing job (8, 0, 3)
05:34:25 WORKER: args: ()
05:34:25 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.05595513225836458, 'num_filters_1': 47, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.10265520881596389, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 24, 'num_filters_3': 18, 'num_filters_4': 29}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:35:10 DISPATCHER: Starting worker discovery
05:35:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:35:10 DISPATCHER: Finished worker discovery
05:35:52 WORKER: done with job (8, 0, 3), trying to register it.
05:35:52 WORKER: registered result for job (8, 0, 3) with dispatcher
05:35:52 DISPATCHER: job (8, 0, 3) finished
05:35:52 DISPATCHER: register_result: lock acquired
05:35:52 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:35:52 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.05595513225836458, 'num_filters_1': 47, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.10265520881596389, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 24, 'num_filters_3': 18, 'num_filters_4': 29}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'data03': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.05595513225836458, 'num_filters_1': 47, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.10265520881596389, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 24, 'num_filters_3': 18, 'num_filters_4': 29}"}}
exception: None

05:35:52 job_callback for (8, 0, 3) started
05:35:52 DISPATCHER: Trying to submit another job.
05:35:52 job_callback for (8, 0, 3) got condition
05:35:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:35:52 HBMASTER: Trying to run another job!
05:35:52 job_callback for (8, 0, 3) finished
05:35:52 start sampling a new configuration.
05:35:52 done sampling a new configuration.
05:35:52 HBMASTER: schedule new run for iteration 8
05:35:52 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
05:35:52 HBMASTER: submitting job (8, 0, 4) to dispatcher
05:35:52 DISPATCHER: trying to submit job (8, 0, 4)
05:35:52 DISPATCHER: trying to notify the job_runner thread.
05:35:52 HBMASTER: job (8, 0, 4) submitted to dispatcher
05:35:52 DISPATCHER: Trying to submit another job.
05:35:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:35:52 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:35:52 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:35:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:35:52 WORKER: start processing job (8, 0, 4)
05:35:52 WORKER: args: ()
05:35:52 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005508132410317398, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.18209739036071512, 'kernel_size_2': 7, 'num_filters_2': 80}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:36:10 DISPATCHER: Starting worker discovery
05:36:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:36:10 DISPATCHER: Finished worker discovery
05:37:10 DISPATCHER: Starting worker discovery
05:37:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:37:10 DISPATCHER: Finished worker discovery
05:37:15 WORKER: done with job (8, 0, 4), trying to register it.
05:37:15 WORKER: registered result for job (8, 0, 4) with dispatcher
05:37:15 DISPATCHER: job (8, 0, 4) finished
05:37:15 DISPATCHER: register_result: lock acquired
05:37:15 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:37:15 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005508132410317398, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.18209739036071512, 'kernel_size_2': 7, 'num_filters_2': 80}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2488344753076383, 'info': {'data03': 0.2488344753076383, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005508132410317398, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.18209739036071512, 'kernel_size_2': 7, 'num_filters_2': 80}"}}
exception: None

05:37:15 job_callback for (8, 0, 4) started
05:37:15 job_callback for (8, 0, 4) got condition
05:37:15 DISPATCHER: Trying to submit another job.
05:37:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:37:15 HBMASTER: Trying to run another job!
05:37:15 job_callback for (8, 0, 4) finished
05:37:15 start sampling a new configuration.
05:37:15 best_vector: [0, 2, 0.6930649523596898, 0.02058932978591277, 0.473968587698442, 1, 0.8912902983077929, 0.7059555665850421, 1, 1, 1, 0, 0.168865577658878, 0.2090089283766342, 0.7324665161478243, 0.5064887846759802], 0.0030361621118992423, 0.0002929650526626099, 8.894893930047824e-07
05:37:15 done sampling a new configuration.
05:37:15 HBMASTER: schedule new run for iteration 8
05:37:15 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
05:37:15 HBMASTER: submitting job (8, 0, 5) to dispatcher
05:37:15 DISPATCHER: trying to submit job (8, 0, 5)
05:37:15 DISPATCHER: trying to notify the job_runner thread.
05:37:15 HBMASTER: job (8, 0, 5) submitted to dispatcher
05:37:15 DISPATCHER: Trying to submit another job.
05:37:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:37:15 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:37:15 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:37:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:37:15 WORKER: start processing job (8, 0, 5)
05:37:15 WORKER: args: ()
05:37:15 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.02432931630655077, 'num_filters_1': 16, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.0828837453486765, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 22, 'num_filters_3': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:38:10 DISPATCHER: Starting worker discovery
05:38:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:38:10 DISPATCHER: Finished worker discovery
05:38:35 WORKER: done with job (8, 0, 5), trying to register it.
05:38:35 WORKER: registered result for job (8, 0, 5) with dispatcher
05:38:35 DISPATCHER: job (8, 0, 5) finished
05:38:35 DISPATCHER: register_result: lock acquired
05:38:35 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:38:35 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.02432931630655077, 'num_filters_1': 16, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.0828837453486765, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 22, 'num_filters_3': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2543713669875761, 'info': {'data03': 0.2543713669875761, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.02432931630655077, 'num_filters_1': 16, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.0828837453486765, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 22, 'num_filters_3': 24}"}}
exception: None

05:38:35 job_callback for (8, 0, 5) started
05:38:35 job_callback for (8, 0, 5) got condition
05:38:35 DISPATCHER: Trying to submit another job.
05:38:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:38:35 HBMASTER: Trying to run another job!
05:38:35 job_callback for (8, 0, 5) finished
05:38:35 start sampling a new configuration.
05:38:35 best_vector: [3, 0, 0.23128916165485713, 0.3505881484406948, 0.6278200909632088, 1, 0.004848153026217994, 0.7851416768732575, 2, 1, 0, 0, 0.10203219891914081, 0.9784950037383174, 0.6522226455189952, 0.767666978754872], 9.081766962441949e-26, 1.1011073110943548e-07, -3.1547162830795096e-06
05:38:35 done sampling a new configuration.
05:38:35 HBMASTER: schedule new run for iteration 8
05:38:35 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
05:38:35 HBMASTER: submitting job (8, 0, 6) to dispatcher
05:38:35 DISPATCHER: trying to submit job (8, 0, 6)
05:38:35 DISPATCHER: trying to notify the job_runner thread.
05:38:35 HBMASTER: job (8, 0, 6) submitted to dispatcher
05:38:35 DISPATCHER: Trying to submit another job.
05:38:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:38:35 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:38:35 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:38:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:38:35 WORKER: start processing job (8, 0, 6)
05:38:35 WORKER: args: ()
05:38:35 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.002901204372367024, 'num_filters_1': 33, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.1050734210313857, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 19, 'num_filters_3': 123, 'num_filters_4': 62}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:39:10 DISPATCHER: Starting worker discovery
05:39:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:39:10 DISPATCHER: Finished worker discovery
05:39:58 WORKER: done with job (8, 0, 6), trying to register it.
05:39:58 WORKER: registered result for job (8, 0, 6) with dispatcher
05:39:58 DISPATCHER: job (8, 0, 6) finished
05:39:58 DISPATCHER: register_result: lock acquired
05:39:58 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:39:58 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.002901204372367024, 'num_filters_1': 33, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.1050734210313857, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 19, 'num_filters_3': 123, 'num_filters_4': 62}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3277437000299055, 'info': {'data03': 0.3277437000299055, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.002901204372367024, 'num_filters_1': 33, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.1050734210313857, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 19, 'num_filters_3': 123, 'num_filters_4': 62}"}}
exception: None

05:39:58 job_callback for (8, 0, 6) started
05:39:58 job_callback for (8, 0, 6) got condition
05:39:58 DISPATCHER: Trying to submit another job.
05:39:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:39:58 HBMASTER: Trying to run another job!
05:39:58 job_callback for (8, 0, 6) finished
05:39:58 start sampling a new configuration.
05:39:58 done sampling a new configuration.
05:39:58 HBMASTER: schedule new run for iteration 8
05:39:58 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
05:39:58 HBMASTER: submitting job (8, 0, 7) to dispatcher
05:39:58 DISPATCHER: trying to submit job (8, 0, 7)
05:39:58 DISPATCHER: trying to notify the job_runner thread.
05:39:58 HBMASTER: job (8, 0, 7) submitted to dispatcher
05:39:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:39:58 DISPATCHER: Trying to submit another job.
05:39:58 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:39:58 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:39:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:39:58 WORKER: start processing job (8, 0, 7)
05:39:58 WORKER: args: ()
05:39:58 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.032868100872656576, 'num_filters_1': 114, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.023126149970531265, 'kernel_size_2': 5, 'num_filters_2': 48}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:40:10 DISPATCHER: Starting worker discovery
05:40:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:40:10 DISPATCHER: Finished worker discovery
05:41:10 DISPATCHER: Starting worker discovery
05:41:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:41:10 DISPATCHER: Finished worker discovery
05:41:22 WORKER: done with job (8, 0, 7), trying to register it.
05:41:22 WORKER: registered result for job (8, 0, 7) with dispatcher
05:41:22 DISPATCHER: job (8, 0, 7) finished
05:41:22 DISPATCHER: register_result: lock acquired
05:41:22 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:41:22 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.032868100872656576, 'num_filters_1': 114, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.023126149970531265, 'kernel_size_2': 5, 'num_filters_2': 48}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.37826345574044046, 'info': {'data03': 0.37826345574044046, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.032868100872656576, 'num_filters_1': 114, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.023126149970531265, 'kernel_size_2': 5, 'num_filters_2': 48}"}}
exception: None

05:41:22 job_callback for (8, 0, 7) started
05:41:22 DISPATCHER: Trying to submit another job.
05:41:22 job_callback for (8, 0, 7) got condition
05:41:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:41:22 HBMASTER: Trying to run another job!
05:41:22 job_callback for (8, 0, 7) finished
05:41:22 start sampling a new configuration.
05:41:22 best_vector: [2, 0, 0.7870270803070092, 0.09003927441513115, 0.2612963619604858, 1, 0.09820950933542949, 0.6361686033354104, 1, 2, 2, 2, 0.22561365988236598, 0.8618404342345616, 0.8855754119737849, 0.9772919262983794], 1.330267132293135e-28, 7.517287135225124e-05, -1.94050814504285e-07
05:41:22 done sampling a new configuration.
05:41:22 HBMASTER: schedule new run for iteration 8
05:41:22 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
05:41:22 HBMASTER: submitting job (8, 0, 8) to dispatcher
05:41:22 DISPATCHER: trying to submit job (8, 0, 8)
05:41:22 DISPATCHER: trying to notify the job_runner thread.
05:41:22 HBMASTER: job (8, 0, 8) submitted to dispatcher
05:41:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:41:22 DISPATCHER: Trying to submit another job.
05:41:22 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:41:22 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:41:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:41:22 WORKER: start processing job (8, 0, 8)
05:41:22 WORKER: args: ()
05:41:22 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.03750197678280279, 'num_filters_1': 19, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.06724723547292583, 'kernel_size_2': 5, 'num_filters_2': 25}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:42:10 DISPATCHER: Starting worker discovery
05:42:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:42:10 DISPATCHER: Finished worker discovery
05:42:46 WORKER: done with job (8, 0, 8), trying to register it.
05:42:46 WORKER: registered result for job (8, 0, 8) with dispatcher
05:42:46 DISPATCHER: job (8, 0, 8) finished
05:42:46 DISPATCHER: register_result: lock acquired
05:42:46 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:42:46 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.03750197678280279, 'num_filters_1': 19, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.06724723547292583, 'kernel_size_2': 5, 'num_filters_2': 25}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.367487995842963, 'info': {'data03': 0.367487995842963, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.03750197678280279, 'num_filters_1': 19, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.06724723547292583, 'kernel_size_2': 5, 'num_filters_2': 25}"}}
exception: None

05:42:46 job_callback for (8, 0, 8) started
05:42:46 job_callback for (8, 0, 8) got condition
05:42:46 DISPATCHER: Trying to submit another job.
05:42:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:42:46 HBMASTER: Trying to run another job!
05:42:46 job_callback for (8, 0, 8) finished
05:42:46 start sampling a new configuration.
05:42:46 done sampling a new configuration.
05:42:46 HBMASTER: schedule new run for iteration 8
05:42:46 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
05:42:46 HBMASTER: submitting job (8, 0, 9) to dispatcher
05:42:46 DISPATCHER: trying to submit job (8, 0, 9)
05:42:46 DISPATCHER: trying to notify the job_runner thread.
05:42:46 HBMASTER: job (8, 0, 9) submitted to dispatcher
05:42:46 DISPATCHER: Trying to submit another job.
05:42:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:42:46 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:42:46 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:42:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:42:46 WORKER: start processing job (8, 0, 9)
05:42:46 WORKER: args: ()
05:42:46 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0010929969191702505, 'num_filters_1': 56, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.02867340203504986, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 35, 'num_filters_3': 113}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:43:10 DISPATCHER: Starting worker discovery
05:43:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:43:10 DISPATCHER: Finished worker discovery
05:44:09 WORKER: done with job (8, 0, 9), trying to register it.
05:44:09 WORKER: registered result for job (8, 0, 9) with dispatcher
05:44:09 DISPATCHER: job (8, 0, 9) finished
05:44:09 DISPATCHER: register_result: lock acquired
05:44:09 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:44:09 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0010929969191702505, 'num_filters_1': 56, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.02867340203504986, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 35, 'num_filters_3': 113}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3159006880520631, 'info': {'data03': 0.3159006880520631, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0010929969191702505, 'num_filters_1': 56, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.02867340203504986, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 35, 'num_filters_3': 113}"}}
exception: None

05:44:09 job_callback for (8, 0, 9) started
05:44:09 DISPATCHER: Trying to submit another job.
05:44:09 job_callback for (8, 0, 9) got condition
05:44:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:44:09 HBMASTER: Trying to run another job!
05:44:09 job_callback for (8, 0, 9) finished
05:44:09 start sampling a new configuration.
05:44:09 best_vector: [0, 2, 0.2316006758269869, 0.6465648781139489, 0.16599933450122956, 1, 0.8823881421034712, 0.7155842961814024, 2, 0, 2, 1, 0.5565331149774038, 0.7527902132514974, 0.9438625388426102, 0.6367810488374344], 2.9452815627535195e-30, 0.0033952611276495694, -6.700421401992813e-05
05:44:09 done sampling a new configuration.
05:44:09 HBMASTER: schedule new run for iteration 8
05:44:09 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
05:44:09 HBMASTER: submitting job (8, 0, 10) to dispatcher
05:44:09 DISPATCHER: trying to submit job (8, 0, 10)
05:44:09 DISPATCHER: trying to notify the job_runner thread.
05:44:09 HBMASTER: job (8, 0, 10) submitted to dispatcher
05:44:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:44:09 DISPATCHER: Trying to submit another job.
05:44:09 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:44:09 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:44:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:44:09 WORKER: start processing job (8, 0, 10)
05:44:09 WORKER: args: ()
05:44:09 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00290536935666516, 'num_filters_1': 61, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.08530935016144016}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:44:10 DISPATCHER: Starting worker discovery
05:44:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:44:10 DISPATCHER: Finished worker discovery
05:45:10 DISPATCHER: Starting worker discovery
05:45:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:45:10 DISPATCHER: Finished worker discovery
05:45:35 WORKER: done with job (8, 0, 10), trying to register it.
05:45:35 WORKER: registered result for job (8, 0, 10) with dispatcher
05:45:35 DISPATCHER: job (8, 0, 10) finished
05:45:35 DISPATCHER: register_result: lock acquired
05:45:35 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:45:35 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00290536935666516, 'num_filters_1': 61, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.08530935016144016}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3524880737285759, 'info': {'data03': 0.3524880737285759, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00290536935666516, 'num_filters_1': 61, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.08530935016144016}"}}
exception: None

05:45:35 job_callback for (8, 0, 10) started
05:45:35 job_callback for (8, 0, 10) got condition
05:45:35 DISPATCHER: Trying to submit another job.
05:45:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:45:35 HBMASTER: Trying to run another job!
05:45:35 job_callback for (8, 0, 10) finished
05:45:35 start sampling a new configuration.
05:45:35 done sampling a new configuration.
05:45:36 HBMASTER: schedule new run for iteration 8
05:45:36 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
05:45:36 HBMASTER: submitting job (8, 0, 11) to dispatcher
05:45:36 DISPATCHER: trying to submit job (8, 0, 11)
05:45:36 DISPATCHER: trying to notify the job_runner thread.
05:45:36 HBMASTER: job (8, 0, 11) submitted to dispatcher
05:45:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:45:36 DISPATCHER: Trying to submit another job.
05:45:36 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:45:36 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:45:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:45:36 WORKER: start processing job (8, 0, 11)
05:45:36 WORKER: args: ()
05:45:36 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.016692807734237473, 'num_filters_1': 86, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.07941907111466331, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 27, 'num_filters_3': 60, 'num_filters_4': 58, 'num_filters_5': 57}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:46:10 DISPATCHER: Starting worker discovery
05:46:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:46:10 DISPATCHER: Finished worker discovery
05:47:07 WORKER: done with job (8, 0, 11), trying to register it.
05:47:07 WORKER: registered result for job (8, 0, 11) with dispatcher
05:47:07 DISPATCHER: job (8, 0, 11) finished
05:47:07 DISPATCHER: register_result: lock acquired
05:47:07 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:47:07 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.016692807734237473, 'num_filters_1': 86, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.07941907111466331, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 27, 'num_filters_3': 60, 'num_filters_4': 58, 'num_filters_5': 57}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.015457232270097123, 'info': {'data03': 0.015457232270097123, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.016692807734237473, 'num_filters_1': 86, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.07941907111466331, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 27, 'num_filters_3': 60, 'num_filters_4': 58, 'num_filters_5': 57}"}}
exception: None

05:47:07 job_callback for (8, 0, 11) started
05:47:07 DISPATCHER: Trying to submit another job.
05:47:07 job_callback for (8, 0, 11) got condition
05:47:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:47:07 HBMASTER: Trying to run another job!
05:47:07 job_callback for (8, 0, 11) finished
05:47:07 start sampling a new configuration.
05:47:07 done sampling a new configuration.
05:47:07 HBMASTER: schedule new run for iteration 8
05:47:07 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
05:47:07 HBMASTER: submitting job (8, 0, 12) to dispatcher
05:47:07 DISPATCHER: trying to submit job (8, 0, 12)
05:47:07 DISPATCHER: trying to notify the job_runner thread.
05:47:07 HBMASTER: job (8, 0, 12) submitted to dispatcher
05:47:07 DISPATCHER: Trying to submit another job.
05:47:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:47:07 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:47:07 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:47:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:47:07 WORKER: start processing job (8, 0, 12)
05:47:07 WORKER: args: ()
05:47:07 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0053125523140521765, 'num_filters_1': 59, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.0917581990490793, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 44, 'num_filters_3': 106, 'num_filters_4': 33}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:47:10 DISPATCHER: Starting worker discovery
05:47:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:47:10 DISPATCHER: Finished worker discovery
05:48:10 DISPATCHER: Starting worker discovery
05:48:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:48:10 DISPATCHER: Finished worker discovery
05:48:30 WORKER: done with job (8, 0, 12), trying to register it.
05:48:30 WORKER: registered result for job (8, 0, 12) with dispatcher
05:48:30 DISPATCHER: job (8, 0, 12) finished
05:48:30 DISPATCHER: register_result: lock acquired
05:48:30 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:48:30 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0053125523140521765, 'num_filters_1': 59, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.0917581990490793, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 44, 'num_filters_3': 106, 'num_filters_4': 33}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.39865215567476575, 'info': {'data03': 0.39865215567476575, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0053125523140521765, 'num_filters_1': 59, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.0917581990490793, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 44, 'num_filters_3': 106, 'num_filters_4': 33}"}}
exception: None

05:48:30 job_callback for (8, 0, 12) started
05:48:30 job_callback for (8, 0, 12) got condition
05:48:30 DISPATCHER: Trying to submit another job.
05:48:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:48:30 HBMASTER: Trying to run another job!
05:48:30 job_callback for (8, 0, 12) finished
05:48:30 start sampling a new configuration.
05:48:30 done sampling a new configuration.
05:48:30 HBMASTER: schedule new run for iteration 8
05:48:30 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
05:48:30 HBMASTER: submitting job (8, 0, 13) to dispatcher
05:48:30 DISPATCHER: trying to submit job (8, 0, 13)
05:48:30 DISPATCHER: trying to notify the job_runner thread.
05:48:30 HBMASTER: job (8, 0, 13) submitted to dispatcher
05:48:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:48:30 DISPATCHER: Trying to submit another job.
05:48:30 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:48:30 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:48:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:48:30 WORKER: start processing job (8, 0, 13)
05:48:30 WORKER: args: ()
05:48:30 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0042968513644823115, 'num_filters_1': 23, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.019574862511330594, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 89, 'num_filters_3': 23, 'num_filters_4': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:49:10 DISPATCHER: Starting worker discovery
05:49:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:49:10 DISPATCHER: Finished worker discovery
05:49:52 WORKER: done with job (8, 0, 13), trying to register it.
05:49:52 WORKER: registered result for job (8, 0, 13) with dispatcher
05:49:52 DISPATCHER: job (8, 0, 13) finished
05:49:52 DISPATCHER: register_result: lock acquired
05:49:52 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:49:52 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0042968513644823115, 'num_filters_1': 23, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.019574862511330594, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 89, 'num_filters_3': 23, 'num_filters_4': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.327133551576126, 'info': {'data03': 0.327133551576126, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0042968513644823115, 'num_filters_1': 23, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.019574862511330594, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 89, 'num_filters_3': 23, 'num_filters_4': 20}"}}
exception: None

05:49:52 job_callback for (8, 0, 13) started
05:49:52 job_callback for (8, 0, 13) got condition
05:49:52 DISPATCHER: Trying to submit another job.
05:49:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:49:52 HBMASTER: Trying to run another job!
05:49:52 job_callback for (8, 0, 13) finished
05:49:52 start sampling a new configuration.
05:49:52 best_vector: [0, 2, 0.48629927138046436, 0.5864136483374002, 0.06119639269201299, 1, 0.9887413557087894, 0.47472940130765967, 1, 2, 2, 2, 0.23512296148128276, 0.9179063492575178, 0.9364459337475615, 0.9514233114602169], 6.668987847709125e-06, 0.005160797686866999, 3.4417297058201376e-08
05:49:52 done sampling a new configuration.
05:49:52 HBMASTER: schedule new run for iteration 8
05:49:52 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
05:49:52 HBMASTER: submitting job (8, 0, 14) to dispatcher
05:49:52 DISPATCHER: trying to submit job (8, 0, 14)
05:49:52 DISPATCHER: trying to notify the job_runner thread.
05:49:52 HBMASTER: job (8, 0, 14) submitted to dispatcher
05:49:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:49:52 DISPATCHER: Trying to submit another job.
05:49:52 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:49:52 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:49:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:49:52 WORKER: start processing job (8, 0, 14)
05:49:52 WORKER: args: ()
05:49:52 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.009388550416176804, 'num_filters_1': 54, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.0414607535294424}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:50:10 DISPATCHER: Starting worker discovery
05:50:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:50:10 DISPATCHER: Finished worker discovery
05:51:10 DISPATCHER: Starting worker discovery
05:51:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:51:10 DISPATCHER: Finished worker discovery
05:51:15 WORKER: done with job (8, 0, 14), trying to register it.
05:51:15 WORKER: registered result for job (8, 0, 14) with dispatcher
05:51:15 DISPATCHER: job (8, 0, 14) finished
05:51:15 DISPATCHER: register_result: lock acquired
05:51:15 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:51:15 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.009388550416176804, 'num_filters_1': 54, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.0414607535294424}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.28894573359376174, 'info': {'data03': 0.28894573359376174, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.009388550416176804, 'num_filters_1': 54, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 99, 'weight_decay': 0.0414607535294424}"}}
exception: None

05:51:15 job_callback for (8, 0, 14) started
05:51:15 DISPATCHER: Trying to submit another job.
05:51:15 job_callback for (8, 0, 14) got condition
05:51:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:51:15 HBMASTER: Trying to run another job!
05:51:15 job_callback for (8, 0, 14) finished
05:51:15 start sampling a new configuration.
05:51:15 done sampling a new configuration.
05:51:15 HBMASTER: schedule new run for iteration 8
05:51:15 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
05:51:15 HBMASTER: submitting job (8, 0, 15) to dispatcher
05:51:15 DISPATCHER: trying to submit job (8, 0, 15)
05:51:15 DISPATCHER: trying to notify the job_runner thread.
05:51:15 HBMASTER: job (8, 0, 15) submitted to dispatcher
05:51:15 DISPATCHER: Trying to submit another job.
05:51:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:51:15 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:51:15 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:51:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:51:15 WORKER: start processing job (8, 0, 15)
05:51:15 WORKER: args: ()
05:51:15 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0015338276286961186, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.012898006404696878}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:52:10 DISPATCHER: Starting worker discovery
05:52:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:52:10 DISPATCHER: Finished worker discovery
05:52:42 WORKER: done with job (8, 0, 15), trying to register it.
05:52:42 WORKER: registered result for job (8, 0, 15) with dispatcher
05:52:42 DISPATCHER: job (8, 0, 15) finished
05:52:42 DISPATCHER: register_result: lock acquired
05:52:42 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:52:42 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0015338276286961186, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.012898006404696878}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3902039312454655, 'info': {'data03': 0.3902039312454655, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0015338276286961186, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.012898006404696878}"}}
exception: None

05:52:42 job_callback for (8, 0, 15) started
05:52:42 job_callback for (8, 0, 15) got condition
05:52:42 DISPATCHER: Trying to submit another job.
05:52:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:52:42 HBMASTER: Trying to run another job!
05:52:42 job_callback for (8, 0, 15) finished
05:52:42 start sampling a new configuration.
05:52:42 done sampling a new configuration.
05:52:42 HBMASTER: schedule new run for iteration 8
05:52:42 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
05:52:42 HBMASTER: submitting job (8, 0, 16) to dispatcher
05:52:42 DISPATCHER: trying to submit job (8, 0, 16)
05:52:42 DISPATCHER: trying to notify the job_runner thread.
05:52:42 HBMASTER: job (8, 0, 16) submitted to dispatcher
05:52:42 DISPATCHER: Trying to submit another job.
05:52:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:52:42 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:52:42 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:52:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:52:42 WORKER: start processing job (8, 0, 16)
05:52:42 WORKER: args: ()
05:52:42 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0025652199554816427, 'num_filters_1': 58, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.10748097001082799, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 26, 'num_filters_3': 93, 'num_filters_4': 30, 'num_filters_5': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:53:10 DISPATCHER: Starting worker discovery
05:53:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:53:10 DISPATCHER: Finished worker discovery
05:54:08 WORKER: done with job (8, 0, 16), trying to register it.
05:54:08 WORKER: registered result for job (8, 0, 16) with dispatcher
05:54:08 DISPATCHER: job (8, 0, 16) finished
05:54:08 DISPATCHER: register_result: lock acquired
05:54:08 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:54:08 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0025652199554816427, 'num_filters_1': 58, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.10748097001082799, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 26, 'num_filters_3': 93, 'num_filters_4': 30, 'num_filters_5': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.28968765070235786, 'info': {'data03': 0.28968765070235786, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0025652199554816427, 'num_filters_1': 58, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.10748097001082799, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 26, 'num_filters_3': 93, 'num_filters_4': 30, 'num_filters_5': 24}"}}
exception: None

05:54:08 job_callback for (8, 0, 16) started
05:54:08 DISPATCHER: Trying to submit another job.
05:54:08 job_callback for (8, 0, 16) got condition
05:54:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:54:08 HBMASTER: Trying to run another job!
05:54:08 job_callback for (8, 0, 16) finished
05:54:08 start sampling a new configuration.
05:54:08 done sampling a new configuration.
05:54:08 HBMASTER: schedule new run for iteration 8
05:54:08 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
05:54:08 HBMASTER: submitting job (8, 0, 17) to dispatcher
05:54:08 DISPATCHER: trying to submit job (8, 0, 17)
05:54:08 DISPATCHER: trying to notify the job_runner thread.
05:54:08 HBMASTER: job (8, 0, 17) submitted to dispatcher
05:54:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:54:08 DISPATCHER: Trying to submit another job.
05:54:08 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:54:08 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:54:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:54:08 WORKER: start processing job (8, 0, 17)
05:54:08 WORKER: args: ()
05:54:08 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.007012475341379629, 'num_filters_1': 96, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.012853666819933565, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 113, 'num_filters_3': 29, 'num_filters_4': 64, 'num_filters_5': 115}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:54:10 DISPATCHER: Starting worker discovery
05:54:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:54:10 DISPATCHER: Finished worker discovery
05:55:10 DISPATCHER: Starting worker discovery
05:55:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:55:10 DISPATCHER: Finished worker discovery
05:55:33 WORKER: done with job (8, 0, 17), trying to register it.
05:55:33 WORKER: registered result for job (8, 0, 17) with dispatcher
05:55:33 DISPATCHER: job (8, 0, 17) finished
05:55:33 DISPATCHER: register_result: lock acquired
05:55:33 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:55:33 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.007012475341379629, 'num_filters_1': 96, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.012853666819933565, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 113, 'num_filters_3': 29, 'num_filters_4': 64, 'num_filters_5': 115}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3440443978546349, 'info': {'data03': 0.3440443978546349, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.007012475341379629, 'num_filters_1': 96, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.012853666819933565, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 113, 'num_filters_3': 29, 'num_filters_4': 64, 'num_filters_5': 115}"}}
exception: None

05:55:33 job_callback for (8, 0, 17) started
05:55:33 job_callback for (8, 0, 17) got condition
05:55:33 DISPATCHER: Trying to submit another job.
05:55:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:55:33 HBMASTER: Trying to run another job!
05:55:33 job_callback for (8, 0, 17) finished
05:55:33 start sampling a new configuration.
05:55:33 best_vector: [0, 0, 0.4536215037141971, 0.3508826652512641, 0.6808697250186851, 1, 0.9643781853001352, 0.9151571628500048, 0, 0, 2, 0, 0.7974456730249293, 0.371083984854685, 0.9124688225694584, 0.4559553617673274], 2.1883953021012665e-27, 4.5695583382024905e-06, -1.548855787197802e-05
05:55:33 done sampling a new configuration.
05:55:33 HBMASTER: schedule new run for iteration 8
05:55:33 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
05:55:33 HBMASTER: submitting job (8, 0, 18) to dispatcher
05:55:33 DISPATCHER: trying to submit job (8, 0, 18)
05:55:33 DISPATCHER: trying to notify the job_runner thread.
05:55:33 HBMASTER: job (8, 0, 18) submitted to dispatcher
05:55:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:55:33 DISPATCHER: Trying to submit another job.
05:55:33 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:55:33 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:55:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:55:33 WORKER: start processing job (8, 0, 18)
05:55:33 WORKER: args: ()
05:55:33 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.008076868411941199, 'num_filters_1': 33, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.1551125435892823, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 84, 'num_filters_3': 34, 'num_filters_4': 107}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:56:10 DISPATCHER: Starting worker discovery
05:56:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:56:10 DISPATCHER: Finished worker discovery
Exception in thread Thread-750:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    preds = np.concatenate(preds)
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 3

05:56:54 WORKER: done with job (8, 0, 18), trying to register it.
05:56:54 WORKER: registered result for job (8, 0, 18) with dispatcher
05:56:54 DISPATCHER: job (8, 0, 18) finished
05:56:54 DISPATCHER: register_result: lock acquired
05:56:54 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:56:54 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.008076868411941199, 'num_filters_1': 33, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.1551125435892823, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 84, 'num_filters_3': 34, 'num_filters_4': 107}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.04951625140260102, 'info': {'data03': 0.04951625140260102, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.008076868411941199, 'num_filters_1': 33, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.1551125435892823, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 84, 'num_filters_3': 34, 'num_filters_4': 107}"}}
exception: None

05:56:54 job_callback for (8, 0, 18) started
05:56:54 job_callback for (8, 0, 18) got condition
05:56:54 DISPATCHER: Trying to submit another job.
05:56:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:56:54 HBMASTER: Trying to run another job!
05:56:54 job_callback for (8, 0, 18) finished
05:56:54 start sampling a new configuration.
05:56:54 best_vector: [0, 2, 0.18108222042994926, 0.24324331060893847, 0.8514316005813505, 1, 0.41836148223079894, 0.23759397852266095, 0, 2, 1, 0, 0.2914362244747551, 0.27231862675217827, 0.881157533037775, 0.3906151523997693], 7.18017288567337e-29, 0.00013927241250629276, -1.187106385775432e-06
05:56:54 done sampling a new configuration.
05:56:54 HBMASTER: schedule new run for iteration 8
05:56:54 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
05:56:54 HBMASTER: submitting job (8, 0, 19) to dispatcher
05:56:54 DISPATCHER: trying to submit job (8, 0, 19)
05:56:54 DISPATCHER: trying to notify the job_runner thread.
05:56:54 HBMASTER: job (8, 0, 19) submitted to dispatcher
05:56:54 DISPATCHER: Trying to submit another job.
05:56:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:56:54 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:56:54 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:56:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:56:54 WORKER: start processing job (8, 0, 19)
05:56:54 WORKER: args: ()
05:56:54 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.002302313398200941, 'num_filters_1': 26, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.020375904330408007, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 29, 'num_filters_3': 28, 'num_filters_4': 100, 'num_filters_5': 35}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:57:10 DISPATCHER: Starting worker discovery
05:57:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:57:10 DISPATCHER: Finished worker discovery
05:58:10 DISPATCHER: Starting worker discovery
05:58:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:58:10 DISPATCHER: Finished worker discovery
05:58:15 WORKER: done with job (8, 0, 19), trying to register it.
05:58:15 WORKER: registered result for job (8, 0, 19) with dispatcher
05:58:15 DISPATCHER: job (8, 0, 19) finished
05:58:15 DISPATCHER: register_result: lock acquired
05:58:15 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:58:15 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.002302313398200941, 'num_filters_1': 26, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.020375904330408007, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 29, 'num_filters_3': 28, 'num_filters_4': 100, 'num_filters_5': 35}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3573290735930671, 'info': {'data03': 0.3573290735930671, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.002302313398200941, 'num_filters_1': 26, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.020375904330408007, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 29, 'num_filters_3': 28, 'num_filters_4': 100, 'num_filters_5': 35}"}}
exception: None

05:58:15 job_callback for (8, 0, 19) started
05:58:15 DISPATCHER: Trying to submit another job.
05:58:15 job_callback for (8, 0, 19) got condition
05:58:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:58:15 HBMASTER: Trying to run another job!
05:58:15 job_callback for (8, 0, 19) finished
05:58:15 start sampling a new configuration.
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/numpy/core/_methods.py:38: RuntimeWarning: invalid value encountered in reduce
  return umr_sum(a, axis, dtype, out, keepdims, initial, where)
05:58:15 sampled vector: [1, 0, 0.10079009453494038, 0.5713621572186953, 0.09022096287870358, 0, 0.8856121567670837, 0.07631628743483798, 1, 1, 2, 0, 0.6443226538170574, 0.7279162757172031, 0.7507616283599282, 0.011243654217286014] has EI value nan
05:58:15 data in the KDEs:
[[3.         2.         0.14009912 0.9793179  0.2999992  1.
  0.28021973 0.16818596 2.         0.         2.         1.
  0.49328864 0.98694376 0.99444858 0.14357878]
 [3.         2.         0.35547769 0.26239861 0.0999984  1.
  0.31318677 0.35919097 1.         2.         2.         0.
  0.54417572 0.85218865 0.99444858 0.93922664]
 [2.         1.         0.1087075  0.6073085  0.0999984  1.
  0.8296704  0.34582668 1.         2.         2.         0.
  0.54417572 0.85218865 0.99444858 0.93922664]
 [3.         0.         0.01647286 0.51430515 0.9000016  1.
  0.80769238 0.51257334 2.         1.         0.         0.
  0.22601193 0.85218865 0.89080549 0.88144294]
 [3.         2.         0.16136142 0.81013485 0.2999992  1.
  0.1703296  0.83950843 1.         1.         0.         0.
  0.0436732  0.85218865 0.89080549 0.88144294]
 [3.         0.         0.57751703 0.89541815 0.9000016  1.
  0.70879125 0.6323441  2.         1.         1.         0.
  0.95161496 0.55372743 0.59878947 0.0436732 ]
 [2.         0.         0.32091089 0.62389945 0.5        1.
  0.0054944  0.452071   2.         1.         2.         0.
  0.3277152  0.09625996 0.99444858 0.88144294]
 [0.         2.         0.06256729 0.22601193 0.9000016  1.
  0.45604395 0.24925748 0.         0.         2.         1.
  0.82100415 0.98694376 0.99444858 0.14357878]
 [0.         2.         0.40510781 0.81560073 0.2999992  1.
  0.41208789 0.08396479 1.         2.         2.         0.
  0.48241935 0.85218865 0.99444858 0.88144294]
 [2.         0.         0.25781264 0.24455523 0.5        1.
  0.69780224 0.8795843  1.         1.         2.         0.
  0.0436732  0.3277152  0.80460504 0.93922664]
 [0.         2.         0.01550274 0.22601193 0.9000016  1.
  0.9945056  0.56881478 2.         1.         2.         0.
  0.18658964 0.89541815 0.80460504 0.93922664]
 [3.         0.         0.36890729 0.7818154  0.0999984  1.
  0.65384619 0.63233111 0.         0.         2.         1.
  0.82100415 0.98694376 0.99444858 0.14357878]
 [2.         0.         0.73762865 0.7390824  0.0999984  1.
  0.86263744 0.44791831 2.         2.         2.         0.
  0.26239861 0.85218865 0.99444858 0.88144294]
 [3.         2.         0.28849591 0.66299556 0.2999992  1.
  0.12637354 0.36071175 2.         2.         2.         0.
  0.26239861 0.85218865 0.99444858 0.88144294]
 [0.         2.         0.0537563  0.5812766  0.7000008  1.
  0.71978027 0.59123762 2.         1.         0.         0.
  0.3277152  0.79900978 0.86214256 0.88144294]
 [1.         1.         0.17421852 0.82100415 0.7000008  1.
  0.04945045 0.96960336 1.         2.         2.         0.
  0.54417572 0.85218865 0.99444858 0.93922664]
 [3.         1.         0.01169821 0.34272578 0.0999984  1.
  0.28021973 0.52510959 1.         2.         2.         0.
  0.54417572 0.85218865 0.99444858 0.0436732 ]]
[[3.00000000e+00 2.00000000e+00 2.40858574e-03 6.92099734e-01
  5.00000000e-01 1.00000000e+00 3.13186772e-01 2.92888502e-01
  0.00000000e+00 2.00000000e+00 1.00000000e+00 0.00000000e+00
  1.43578776e-01 3.57274419e-01 3.98412835e-01 6.84989922e-01]
 [2.00000000e+00 1.00000000e+00 6.09555916e-01 2.26011930e-01
  9.99984000e-02 1.00000000e+00 8.24174906e-02 3.62462251e-01
  2.00000000e+00 2.00000000e+00 1.00000000e+00 0.00000000e+00
  7.06973316e-02 2.79592999e-01 3.98412835e-01 6.84989922e-01]
 [0.00000000e+00 1.00000000e+00 1.59252669e-01 5.24473143e-01
  5.00000000e-01 1.00000000e+00 8.40659416e-01 8.47076625e-01
  1.00000000e+00 1.00000000e+00 2.00000000e+00 0.00000000e+00
  8.21004146e-01 4.93288642e-01 9.83146206e-01 6.55430702e-01]
 [1.00000000e+00 1.00000000e+00 9.91481617e-02 2.79592999e-01
  2.99999200e-01 1.00000000e+00 6.20879147e-01 2.32516531e-01
  1.00000000e+00 2.00000000e+00 2.00000000e+00 0.00000000e+00
  6.70441281e-01 1.50102742e-02 9.83146206e-01 6.55430702e-01]
 [2.00000000e+00 0.00000000e+00 2.21858200e-01 7.93347517e-01
  9.00001600e-01 1.00000000e+00 9.17582509e-01 1.07319192e-01
  0.00000000e+00 0.00000000e+00 2.00000000e+00 2.00000000e+00
  6.84989922e-01 7.51690971e-01 2.26011930e-01 5.72270733e-01]
 [3.00000000e+00 2.00000000e+00 8.05670843e-02 3.42725778e-01
  5.00000000e-01 1.00000000e+00 1.48351571e-01 8.92534814e-01
  2.00000000e+00 1.00000000e+00 1.00000000e+00 2.00000000e+00
  9.62599641e-02 8.86147389e-01 2.96183948e-01 5.72270733e-01]
 [1.00000000e+00 1.00000000e+00 5.79222389e-01 6.39927886e-01
  7.00000800e-01 1.00000000e+00 6.64835201e-01 6.63137164e-01
  0.00000000e+00 1.00000000e+00 1.00000000e+00 0.00000000e+00
  6.99104210e-01 4.82419346e-01 2.96183948e-01 1.65573138e-01]
 [2.00000000e+00 2.00000000e+00 6.28803359e-01 1.86589644e-01
  5.00000000e-01 1.00000000e+00 3.68131839e-01 8.67622569e-01
  1.00000000e+00 1.00000000e+00 1.00000000e+00 0.00000000e+00
  3.27715199e-01 4.36732032e-02 2.96183948e-01 1.65573138e-01]
 [0.00000000e+00 1.00000000e+00 7.32605511e-01 1.50102742e-02
  5.00000000e-01 1.00000000e+00 9.61538563e-01 3.82650847e-01
  2.00000000e+00 2.00000000e+00 1.00000000e+00 0.00000000e+00
  3.85093827e-01 1.50102742e-02 2.96183948e-01 6.84989922e-01]
 [0.00000000e+00 2.00000000e+00 3.37821505e-01 2.62398612e-01
  9.00001600e-01 1.00000000e+00 6.42857174e-01 1.70337743e-01
  2.00000000e+00 0.00000000e+00 1.00000000e+00 2.00000000e+00
  7.93347517e-01 3.71388707e-01 7.93347517e-01 7.19515734e-01]
 [3.00000000e+00 0.00000000e+00 4.82113748e-01 8.95418147e-01
  9.99984000e-02 0.00000000e+00 7.52747308e-01 6.37145220e-02
  0.00000000e+00 2.00000000e+00 0.00000000e+00 0.00000000e+00
  1.43578776e-01 3.57274419e-01 4.71294279e-01 1.65573138e-01]
 [1.00000000e+00 2.00000000e+00 3.55309198e-01 2.62398612e-01
  9.99984000e-02 0.00000000e+00 7.96703362e-01 7.69146578e-02
  0.00000000e+00 0.00000000e+00 2.00000000e+00 2.00000000e+00
  6.84989922e-01 7.51690971e-01 2.26011930e-01 5.72270733e-01]
 [0.00000000e+00 0.00000000e+00 1.27512646e-01 8.67042020e-01
  5.00000000e-01 1.00000000e+00 5.00000000e-01 8.78178153e-01
  0.00000000e+00 1.00000000e+00 1.00000000e+00 2.00000000e+00
  7.06973316e-02 5.24473143e-01 7.93347517e-01 7.19515734e-01]
 [3.00000000e+00 2.00000000e+00 9.09579789e-01 7.69994942e-01
  2.99999200e-01 1.00000000e+00 8.73626456e-01 9.14495491e-02
  0.00000000e+00 2.00000000e+00 1.00000000e+00 0.00000000e+00
  8.36853457e-01 1.50102742e-02 3.98412835e-01 6.84989922e-01]
 [2.00000000e+00 1.00000000e+00 9.01104879e-02 9.26504973e-01
  9.00001600e-01 0.00000000e+00 7.30769281e-01 4.96449476e-01
  1.00000000e+00 2.00000000e+00 1.00000000e+00 0.00000000e+00
  6.77771560e-01 2.79592999e-01 3.98412835e-01 6.84989922e-01]
 [3.00000000e+00 1.00000000e+00 1.02260481e-01 8.10134850e-01
  9.00001600e-01 0.00000000e+00 2.03296638e-01 5.69073836e-01
  0.00000000e+00 0.00000000e+00 2.00000000e+00 0.00000000e+00
  1.43578776e-01 9.79317897e-01 9.83146206e-01 6.55430702e-01]
 [2.00000000e+00 2.00000000e+00 7.82157518e-01 8.76691203e-01
  9.99984000e-02 0.00000000e+00 4.01098879e-01 2.15620773e-01
  2.00000000e+00 2.00000000e+00 2.00000000e+00 2.00000000e+00
  3.85093827e-01 1.50102742e-02 2.26011930e-01 5.72270733e-01]
 [2.00000000e+00 2.00000000e+00 7.86595710e-01 3.98412835e-01
  2.99999200e-01 0.00000000e+00 8.29670402e-01 1.81284480e-01
  2.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00
  7.06973316e-02 4.93288642e-01 4.71294279e-01 1.65573138e-01]
 [3.00000000e+00 2.00000000e+00 9.94327671e-01 9.98156785e-01
  9.00001600e-01 0.00000000e+00 4.78021973e-01 4.88534811e-01
  2.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00
  6.31981589e-01 4.93288642e-01 4.71294279e-01 1.65573138e-01]]
05:58:15 bandwidth of the KDEs:
[1.11433925e+00 8.27832412e-01 1.84583105e-01 2.25495172e-01
 2.85952529e-01 1.00000000e-03 2.79585654e-01 2.16562528e-01
 6.26450697e-01 6.71575522e-01 7.09739083e-01 3.50718878e-01
 2.35338195e-01 2.13111820e-01 9.84036251e-02 3.37753433e-01]
[1.02145877 0.66721407 0.2852556  0.27332676 0.26549302 0.44132063
 0.24191861 0.26339207 0.8114724  0.70110411 0.61287526 0.8505344
 0.26304979 0.26723004 0.23996014 0.2001703 ]
05:58:15 l(x) = nan
05:58:15 g(x) = 5.622008350957988e-06
05:58:15 best_vector: [0, 0, 0.409900931653724, 0.5938161783301903, 0.35260556651394853, 1, 0.40096048434625475, 0.8110416509864176, 2, 0, 0, 0, 0.21426665623498733, 0.5650057562734068, 0.6998515521036632, 0.9643309748738798], 1.3254342534702405e-29, 0.0007544697123843062, -3.114464183682508e-05
05:58:15 done sampling a new configuration.
05:58:15 HBMASTER: schedule new run for iteration 8
05:58:15 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
05:58:15 HBMASTER: submitting job (8, 0, 20) to dispatcher
05:58:15 DISPATCHER: trying to submit job (8, 0, 20)
05:58:15 DISPATCHER: trying to notify the job_runner thread.
05:58:15 HBMASTER: job (8, 0, 20) submitted to dispatcher
05:58:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:58:15 DISPATCHER: Trying to submit another job.
05:58:15 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:58:15 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:58:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:58:15 WORKER: start processing job (8, 0, 20)
05:58:15 WORKER: args: ()
05:58:15 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.006603920908345124, 'num_filters_1': 54, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.11355062151751256, 'kernel_size_2': 7, 'num_filters_2': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:59:10 DISPATCHER: Starting worker discovery
05:59:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:59:10 DISPATCHER: Finished worker discovery
05:59:35 WORKER: done with job (8, 0, 20), trying to register it.
05:59:35 WORKER: registered result for job (8, 0, 20) with dispatcher
05:59:35 DISPATCHER: job (8, 0, 20) finished
05:59:35 DISPATCHER: register_result: lock acquired
05:59:35 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
05:59:35 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.006603920908345124, 'num_filters_1': 54, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.11355062151751256, 'kernel_size_2': 7, 'num_filters_2': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.31833889051412134, 'info': {'data03': 0.31833889051412134, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.006603920908345124, 'num_filters_1': 54, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.11355062151751256, 'kernel_size_2': 7, 'num_filters_2': 24}"}}
exception: None

05:59:35 job_callback for (8, 0, 20) started
05:59:35 job_callback for (8, 0, 20) got condition
05:59:35 DISPATCHER: Trying to submit another job.
05:59:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:59:35 HBMASTER: Trying to run another job!
05:59:35 job_callback for (8, 0, 20) finished
05:59:35 start sampling a new configuration.
05:59:35 done sampling a new configuration.
05:59:35 HBMASTER: schedule new run for iteration 8
05:59:35 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
05:59:35 HBMASTER: submitting job (8, 0, 21) to dispatcher
05:59:35 DISPATCHER: trying to submit job (8, 0, 21)
05:59:35 DISPATCHER: trying to notify the job_runner thread.
05:59:35 HBMASTER: job (8, 0, 21) submitted to dispatcher
05:59:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:59:35 DISPATCHER: Trying to submit another job.
05:59:35 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776
05:59:35 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
05:59:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:59:35 WORKER: start processing job (8, 0, 21)
05:59:35 WORKER: args: ()
05:59:35 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.001942831190041424, 'num_filters_1': 75, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.03738062891908018}, 'budget': 44.44444444444444, 'working_directory': '.'}
06:00:10 DISPATCHER: Starting worker discovery
06:00:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:00:10 DISPATCHER: Finished worker discovery
06:00:56 WORKER: done with job (8, 0, 21), trying to register it.
06:00:56 WORKER: registered result for job (8, 0, 21) with dispatcher
06:00:56 DISPATCHER: job (8, 0, 21) finished
06:00:56 DISPATCHER: register_result: lock acquired
06:00:56 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
06:00:56 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.001942831190041424, 'num_filters_1': 75, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.03738062891908018}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.40343735238221895, 'info': {'data03': 0.40343735238221895, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.001942831190041424, 'num_filters_1': 75, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.03738062891908018}"}}
exception: None

06:00:56 job_callback for (8, 0, 21) started
06:00:56 job_callback for (8, 0, 21) got condition
06:00:56 DISPATCHER: Trying to submit another job.
06:00:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:00:56 HBMASTER: Trying to run another job!
06:00:56 job_callback for (8, 0, 21) finished
06:00:56 start sampling a new configuration.
06:00:56 done sampling a new configuration.
06:00:56 HBMASTER: schedule new run for iteration 8
06:00:56 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
06:00:56 HBMASTER: submitting job (8, 0, 22) to dispatcher
06:00:56 DISPATCHER: trying to submit job (8, 0, 22)
06:00:56 DISPATCHER: trying to notify the job_runner thread.
06:00:56 HBMASTER: job (8, 0, 22) submitted to dispatcher
06:00:56 DISPATCHER: Trying to submit another job.
06:00:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:00:56 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776
06:00:56 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
06:00:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:00:56 WORKER: start processing job (8, 0, 22)
06:00:56 WORKER: args: ()
06:00:56 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005986964626425833, 'num_filters_1': 27, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.03936387097971105, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 25, 'num_filters_3': 56, 'num_filters_4': 87, 'num_filters_5': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
06:01:10 DISPATCHER: Starting worker discovery
06:01:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:01:10 DISPATCHER: Finished worker discovery
06:02:10 DISPATCHER: Starting worker discovery
06:02:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:02:10 DISPATCHER: Finished worker discovery
06:02:18 WORKER: done with job (8, 0, 22), trying to register it.
06:02:18 WORKER: registered result for job (8, 0, 22) with dispatcher
06:02:18 DISPATCHER: job (8, 0, 22) finished
06:02:18 DISPATCHER: register_result: lock acquired
06:02:18 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
06:02:18 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005986964626425833, 'num_filters_1': 27, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.03936387097971105, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 25, 'num_filters_3': 56, 'num_filters_4': 87, 'num_filters_5': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3966926141130512, 'info': {'data03': 0.3966926141130512, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005986964626425833, 'num_filters_1': 27, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.03936387097971105, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 25, 'num_filters_3': 56, 'num_filters_4': 87, 'num_filters_5': 16}"}}
exception: None

06:02:18 job_callback for (8, 0, 22) started
06:02:18 job_callback for (8, 0, 22) got condition
06:02:18 DISPATCHER: Trying to submit another job.
06:02:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:02:18 HBMASTER: Trying to run another job!
06:02:18 job_callback for (8, 0, 22) finished
06:02:18 start sampling a new configuration.
06:02:18 best_vector: [1, 1, 0.1346094011524024, 0.22608949355522684, 0.05856629659442272, 1, 0.3660294653412819, 0.5300564276244788, 2, 2, 2, 0, 0.5335503542372966, 0.5200144631378316, 0.9668321662018243, 0.23588504737042792], 0.0004696942330526371, 0.0030144287594102135, 1.4158598042429925e-06
06:02:18 done sampling a new configuration.
06:02:18 HBMASTER: schedule new run for iteration 8
06:02:18 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
06:02:18 HBMASTER: submitting job (8, 0, 23) to dispatcher
06:02:18 DISPATCHER: trying to submit job (8, 0, 23)
06:02:18 DISPATCHER: trying to notify the job_runner thread.
06:02:18 HBMASTER: job (8, 0, 23) submitted to dispatcher
06:02:18 DISPATCHER: Trying to submit another job.
06:02:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:02:18 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpui.1576139975513683776
06:02:18 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
06:02:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:02:18 WORKER: start processing job (8, 0, 23)
06:02:18 WORKER: args: ()
06:02:18 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0018587406730919758, 'num_filters_1': 25, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.048934968346681935}, 'budget': 44.44444444444444, 'working_directory': '.'}
06:03:10 DISPATCHER: Starting worker discovery
06:03:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:03:10 DISPATCHER: Finished worker discovery
06:03:36 WORKER: done with job (8, 0, 23), trying to register it.
06:03:36 WORKER: registered result for job (8, 0, 23) with dispatcher
06:03:36 DISPATCHER: job (8, 0, 23) finished
06:03:36 DISPATCHER: register_result: lock acquired
06:03:36 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
06:03:36 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0018587406730919758, 'num_filters_1': 25, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.048934968346681935}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3657234727011864, 'info': {'data03': 0.3657234727011864, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0018587406730919758, 'num_filters_1': 25, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.048934968346681935}"}}
exception: None

06:03:36 job_callback for (8, 0, 23) started
06:03:36 job_callback for (8, 0, 23) got condition
06:03:36 DISPATCHER: Trying to submit another job.
06:03:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:03:36 HBMASTER: Trying to run another job!
06:03:36 job_callback for (8, 0, 23) finished
06:03:36 start sampling a new configuration.
06:03:36 done sampling a new configuration.
06:03:36 HBMASTER: schedule new run for iteration 8
06:03:36 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
06:03:36 HBMASTER: submitting job (8, 0, 24) to dispatcher
06:03:36 DISPATCHER: trying to submit job (8, 0, 24)
06:03:36 DISPATCHER: trying to notify the job_runner thread.
06:03:36 HBMASTER: job (8, 0, 24) submitted to dispatcher
06:03:36 DISPATCHER: Trying to submit another job.
06:03:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:03:36 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776
06:03:36 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
06:03:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:03:36 WORKER: start processing job (8, 0, 24)
06:03:36 WORKER: args: ()
06:03:36 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004939110157057794, 'num_filters_1': 49, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.04293193654666642, 'kernel_size_2': 7, 'num_filters_2': 121}, 'budget': 44.44444444444444, 'working_directory': '.'}
06:04:10 DISPATCHER: Starting worker discovery
06:04:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:04:10 DISPATCHER: Finished worker discovery
06:05:01 WORKER: done with job (8, 0, 24), trying to register it.
06:05:01 WORKER: registered result for job (8, 0, 24) with dispatcher
06:05:01 DISPATCHER: job (8, 0, 24) finished
06:05:01 DISPATCHER: register_result: lock acquired
06:05:01 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
06:05:01 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004939110157057794, 'num_filters_1': 49, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.04293193654666642, 'kernel_size_2': 7, 'num_filters_2': 121}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.45275892812238117, 'info': {'data03': 0.45275892812238117, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004939110157057794, 'num_filters_1': 49, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.04293193654666642, 'kernel_size_2': 7, 'num_filters_2': 121}"}}
exception: None

06:05:01 job_callback for (8, 0, 24) started
06:05:01 DISPATCHER: Trying to submit another job.
06:05:01 job_callback for (8, 0, 24) got condition
06:05:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:05:01 HBMASTER: Trying to run another job!
06:05:01 job_callback for (8, 0, 24) finished
06:05:01 start sampling a new configuration.
06:05:01 done sampling a new configuration.
06:05:01 HBMASTER: schedule new run for iteration 8
06:05:01 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
06:05:01 HBMASTER: submitting job (8, 0, 25) to dispatcher
06:05:01 DISPATCHER: trying to submit job (8, 0, 25)
06:05:01 DISPATCHER: trying to notify the job_runner thread.
06:05:01 HBMASTER: job (8, 0, 25) submitted to dispatcher
06:05:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:05:01 DISPATCHER: Trying to submit another job.
06:05:01 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpui.1576139975513683776
06:05:01 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
06:05:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:05:01 WORKER: start processing job (8, 0, 25)
06:05:01 WORKER: args: ()
06:05:01 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.03506758180824028, 'num_filters_1': 43, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.06337796231838984}, 'budget': 44.44444444444444, 'working_directory': '.'}
06:05:10 DISPATCHER: Starting worker discovery
06:05:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:05:10 DISPATCHER: Finished worker discovery
06:06:10 DISPATCHER: Starting worker discovery
06:06:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:06:10 DISPATCHER: Finished worker discovery
06:06:22 WORKER: done with job (8, 0, 25), trying to register it.
06:06:22 WORKER: registered result for job (8, 0, 25) with dispatcher
06:06:22 DISPATCHER: job (8, 0, 25) finished
06:06:22 DISPATCHER: register_result: lock acquired
06:06:22 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
06:06:22 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.03506758180824028, 'num_filters_1': 43, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.06337796231838984}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3479652663989279, 'info': {'data03': 0.3479652663989279, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.03506758180824028, 'num_filters_1': 43, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.06337796231838984}"}}
exception: None

06:06:22 job_callback for (8, 0, 25) started
06:06:22 DISPATCHER: Trying to submit another job.
06:06:22 job_callback for (8, 0, 25) got condition
06:06:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:06:22 HBMASTER: Trying to run another job!
06:06:22 job_callback for (8, 0, 25) finished
06:06:22 start sampling a new configuration.
06:06:22 best_vector: [0, 1, 0.18767972604520627, 0.525681643556404, 0.42842213014451397, 1, 0.8860778476117344, 0.9805661468807632, 1, 2, 0, 1, 0.6066508142969886, 0.5413377532808721, 0.7913562252709314, 0.8470028560384639], 4.4183210088716936e-29, 0.00022633031823447567, -5.695238468387677e-05
06:06:22 done sampling a new configuration.
06:06:22 HBMASTER: schedule new run for iteration 8
06:06:22 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
06:06:22 HBMASTER: submitting job (8, 0, 26) to dispatcher
06:06:22 DISPATCHER: trying to submit job (8, 0, 26)
06:06:22 DISPATCHER: trying to notify the job_runner thread.
06:06:22 HBMASTER: job (8, 0, 26) submitted to dispatcher
06:06:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:06:22 DISPATCHER: Trying to submit another job.
06:06:22 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpui.1576139975513683776
06:06:22 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
06:06:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:06:22 WORKER: start processing job (8, 0, 26)
06:06:22 WORKER: args: ()
06:06:22 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002373337230686932, 'num_filters_1': 47, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.1886887336602998, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 56, 'num_filters_3': 49}, 'budget': 44.44444444444444, 'working_directory': '.'}
06:07:10 DISPATCHER: Starting worker discovery
06:07:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:07:10 DISPATCHER: Finished worker discovery
06:07:40 WORKER: done with job (8, 0, 26), trying to register it.
06:07:40 WORKER: registered result for job (8, 0, 26) with dispatcher
06:07:40 DISPATCHER: job (8, 0, 26) finished
06:07:40 DISPATCHER: register_result: lock acquired
06:07:40 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
06:07:40 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002373337230686932, 'num_filters_1': 47, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.1886887336602998, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 56, 'num_filters_3': 49}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.38870212415281435, 'info': {'data03': 0.38870212415281435, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002373337230686932, 'num_filters_1': 47, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.1886887336602998, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 56, 'num_filters_3': 49}"}}
exception: None

06:07:40 job_callback for (8, 0, 26) started
06:07:40 DISPATCHER: Trying to submit another job.
06:07:40 job_callback for (8, 0, 26) got condition
06:07:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:07:40 HBMASTER: Trying to run another job!
06:07:40 job_callback for (8, 0, 26) finished
06:07:40 ITERATION: Advancing config (8, 0, 2) to next budget 133.333333
06:07:40 ITERATION: Advancing config (8, 0, 7) to next budget 133.333333
06:07:40 ITERATION: Advancing config (8, 0, 8) to next budget 133.333333
06:07:40 ITERATION: Advancing config (8, 0, 12) to next budget 133.333333
06:07:40 ITERATION: Advancing config (8, 0, 15) to next budget 133.333333
06:07:40 ITERATION: Advancing config (8, 0, 21) to next budget 133.333333
06:07:40 ITERATION: Advancing config (8, 0, 22) to next budget 133.333333
06:07:40 ITERATION: Advancing config (8, 0, 24) to next budget 133.333333
06:07:40 ITERATION: Advancing config (8, 0, 26) to next budget 133.333333
06:07:40 HBMASTER: schedule new run for iteration 8
06:07:40 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
06:07:40 HBMASTER: submitting job (8, 0, 2) to dispatcher
06:07:40 DISPATCHER: trying to submit job (8, 0, 2)
06:07:40 DISPATCHER: trying to notify the job_runner thread.
06:07:40 HBMASTER: job (8, 0, 2) submitted to dispatcher
06:07:40 DISPATCHER: Trying to submit another job.
06:07:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:07:40 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
06:07:40 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
06:07:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:07:40 WORKER: start processing job (8, 0, 2)
06:07:40 WORKER: args: ()
06:07:40 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0011611752267125096, 'num_filters_1': 109, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.11364480322835335}, 'budget': 133.33333333333331, 'working_directory': '.'}
06:08:10 DISPATCHER: Starting worker discovery
06:08:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:08:10 DISPATCHER: Finished worker discovery
06:09:10 DISPATCHER: Starting worker discovery
06:09:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:09:10 DISPATCHER: Finished worker discovery
06:10:10 DISPATCHER: Starting worker discovery
06:10:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:10:10 DISPATCHER: Finished worker discovery
06:10:27 WORKER: done with job (8, 0, 2), trying to register it.
06:10:27 WORKER: registered result for job (8, 0, 2) with dispatcher
06:10:27 DISPATCHER: job (8, 0, 2) finished
06:10:27 DISPATCHER: register_result: lock acquired
06:10:27 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
06:10:27 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0011611752267125096, 'num_filters_1': 109, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.11364480322835335}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.43622190942042316, 'info': {'data03': 0.43622190942042316, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0011611752267125096, 'num_filters_1': 109, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.11364480322835335}"}}
exception: None

06:10:27 job_callback for (8, 0, 2) started
06:10:27 DISPATCHER: Trying to submit another job.
06:10:27 job_callback for (8, 0, 2) got condition
06:10:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:10:27 done building a new model for budget 133.333333 based on 17/31 split
Best loss for this budget:-0.436222





06:10:27 HBMASTER: Trying to run another job!
06:10:27 job_callback for (8, 0, 2) finished
06:10:27 HBMASTER: schedule new run for iteration 8
06:10:27 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
06:10:27 HBMASTER: submitting job (8, 0, 7) to dispatcher
06:10:27 DISPATCHER: trying to submit job (8, 0, 7)
06:10:27 DISPATCHER: trying to notify the job_runner thread.
06:10:27 HBMASTER: job (8, 0, 7) submitted to dispatcher
06:10:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:10:27 DISPATCHER: Trying to submit another job.
06:10:27 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776
06:10:27 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
06:10:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:10:27 WORKER: start processing job (8, 0, 7)
06:10:27 WORKER: args: ()
06:10:27 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.032868100872656576, 'num_filters_1': 114, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.023126149970531265, 'kernel_size_2': 5, 'num_filters_2': 48}, 'budget': 133.33333333333331, 'working_directory': '.'}
06:11:10 DISPATCHER: Starting worker discovery
06:11:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:11:10 DISPATCHER: Finished worker discovery
06:12:10 DISPATCHER: Starting worker discovery
06:12:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:12:10 DISPATCHER: Finished worker discovery
06:13:10 DISPATCHER: Starting worker discovery
06:13:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:13:10 DISPATCHER: Finished worker discovery
06:13:25 WORKER: done with job (8, 0, 7), trying to register it.
06:13:25 WORKER: registered result for job (8, 0, 7) with dispatcher
06:13:25 DISPATCHER: job (8, 0, 7) finished
06:13:25 DISPATCHER: register_result: lock acquired
06:13:25 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
06:13:25 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.032868100872656576, 'num_filters_1': 114, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.023126149970531265, 'kernel_size_2': 5, 'num_filters_2': 48}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.321048719783526, 'info': {'data03': 0.321048719783526, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.032868100872656576, 'num_filters_1': 114, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 80, 'weight_decay': 0.023126149970531265, 'kernel_size_2': 5, 'num_filters_2': 48}"}}
exception: None

06:13:25 job_callback for (8, 0, 7) started
06:13:25 job_callback for (8, 0, 7) got condition
06:13:25 DISPATCHER: Trying to submit another job.
06:13:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:13:25 done building a new model for budget 133.333333 based on 17/32 split
Best loss for this budget:-0.436222





06:13:25 HBMASTER: Trying to run another job!
06:13:25 job_callback for (8, 0, 7) finished
06:13:25 HBMASTER: schedule new run for iteration 8
06:13:25 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
06:13:25 HBMASTER: submitting job (8, 0, 8) to dispatcher
06:13:25 DISPATCHER: trying to submit job (8, 0, 8)
06:13:25 DISPATCHER: trying to notify the job_runner thread.
06:13:25 HBMASTER: job (8, 0, 8) submitted to dispatcher
06:13:25 DISPATCHER: Trying to submit another job.
06:13:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:13:25 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776
06:13:25 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
06:13:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:13:25 WORKER: start processing job (8, 0, 8)
06:13:25 WORKER: args: ()
06:13:25 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.03750197678280279, 'num_filters_1': 19, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.06724723547292583, 'kernel_size_2': 5, 'num_filters_2': 25}, 'budget': 133.33333333333331, 'working_directory': '.'}
06:14:10 DISPATCHER: Starting worker discovery
06:14:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:14:10 DISPATCHER: Finished worker discovery
06:15:10 DISPATCHER: Starting worker discovery
06:15:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:15:10 DISPATCHER: Finished worker discovery
06:16:10 DISPATCHER: Starting worker discovery
06:16:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:16:10 DISPATCHER: Finished worker discovery
06:16:17 WORKER: done with job (8, 0, 8), trying to register it.
06:16:17 WORKER: registered result for job (8, 0, 8) with dispatcher
06:16:17 DISPATCHER: job (8, 0, 8) finished
06:16:17 DISPATCHER: register_result: lock acquired
06:16:17 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
06:16:17 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.03750197678280279, 'num_filters_1': 19, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.06724723547292583, 'kernel_size_2': 5, 'num_filters_2': 25}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.347680899908817, 'info': {'data03': 0.347680899908817, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.03750197678280279, 'num_filters_1': 19, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.06724723547292583, 'kernel_size_2': 5, 'num_filters_2': 25}"}}
exception: None

06:16:17 job_callback for (8, 0, 8) started
06:16:17 job_callback for (8, 0, 8) got condition
06:16:17 DISPATCHER: Trying to submit another job.
06:16:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:16:17 done building a new model for budget 133.333333 based on 17/33 split
Best loss for this budget:-0.436222





06:16:17 HBMASTER: Trying to run another job!
06:16:17 job_callback for (8, 0, 8) finished
06:16:17 HBMASTER: schedule new run for iteration 8
06:16:17 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
06:16:17 HBMASTER: submitting job (8, 0, 12) to dispatcher
06:16:17 DISPATCHER: trying to submit job (8, 0, 12)
06:16:17 DISPATCHER: trying to notify the job_runner thread.
06:16:17 HBMASTER: job (8, 0, 12) submitted to dispatcher
06:16:17 DISPATCHER: Trying to submit another job.
06:16:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:16:17 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpui.1576139975513683776
06:16:17 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
06:16:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:16:17 WORKER: start processing job (8, 0, 12)
06:16:17 WORKER: args: ()
06:16:17 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0053125523140521765, 'num_filters_1': 59, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.0917581990490793, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 44, 'num_filters_3': 106, 'num_filters_4': 33}, 'budget': 133.33333333333331, 'working_directory': '.'}
06:17:10 DISPATCHER: Starting worker discovery
06:17:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:17:10 DISPATCHER: Finished worker discovery
06:18:10 DISPATCHER: Starting worker discovery
06:18:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:18:10 DISPATCHER: Finished worker discovery
06:19:09 WORKER: done with job (8, 0, 12), trying to register it.
06:19:09 WORKER: registered result for job (8, 0, 12) with dispatcher
06:19:09 DISPATCHER: job (8, 0, 12) finished
06:19:09 DISPATCHER: register_result: lock acquired
06:19:09 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
06:19:09 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0053125523140521765, 'num_filters_1': 59, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.0917581990490793, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 44, 'num_filters_3': 106, 'num_filters_4': 33}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.31184939250083216, 'info': {'data03': 0.31184939250083216, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0053125523140521765, 'num_filters_1': 59, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.0917581990490793, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 44, 'num_filters_3': 106, 'num_filters_4': 33}"}}
exception: None

06:19:09 job_callback for (8, 0, 12) started
06:19:09 DISPATCHER: Trying to submit another job.
06:19:09 job_callback for (8, 0, 12) got condition
06:19:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:19:09 done building a new model for budget 133.333333 based on 17/34 split
Best loss for this budget:-0.436222





06:19:09 HBMASTER: Trying to run another job!
06:19:09 job_callback for (8, 0, 12) finished
06:19:09 HBMASTER: schedule new run for iteration 8
06:19:09 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
06:19:09 HBMASTER: submitting job (8, 0, 15) to dispatcher
06:19:09 DISPATCHER: trying to submit job (8, 0, 15)
06:19:09 DISPATCHER: trying to notify the job_runner thread.
06:19:09 HBMASTER: job (8, 0, 15) submitted to dispatcher
06:19:09 DISPATCHER: Trying to submit another job.
06:19:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:19:09 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776
06:19:09 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
06:19:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:19:09 WORKER: start processing job (8, 0, 15)
06:19:09 WORKER: args: ()
06:19:09 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0015338276286961186, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.012898006404696878}, 'budget': 133.33333333333331, 'working_directory': '.'}
06:19:10 DISPATCHER: Starting worker discovery
06:19:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:19:10 DISPATCHER: Finished worker discovery
06:20:10 DISPATCHER: Starting worker discovery
06:20:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:20:10 DISPATCHER: Finished worker discovery
06:21:10 DISPATCHER: Starting worker discovery
06:21:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:21:10 DISPATCHER: Finished worker discovery
06:21:59 WORKER: done with job (8, 0, 15), trying to register it.
06:21:59 WORKER: registered result for job (8, 0, 15) with dispatcher
06:21:59 DISPATCHER: job (8, 0, 15) finished
06:21:59 DISPATCHER: register_result: lock acquired
06:21:59 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
06:21:59 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0015338276286961186, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.012898006404696878}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.35801530061960696, 'info': {'data03': 0.35801530061960696, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0015338276286961186, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.012898006404696878}"}}
exception: None

06:21:59 job_callback for (8, 0, 15) started
06:21:59 job_callback for (8, 0, 15) got condition
06:21:59 DISPATCHER: Trying to submit another job.
06:21:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:21:59 done building a new model for budget 133.333333 based on 17/34 split
Best loss for this budget:-0.436222





06:21:59 HBMASTER: Trying to run another job!
06:21:59 job_callback for (8, 0, 15) finished
06:21:59 HBMASTER: schedule new run for iteration 8
06:21:59 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
06:21:59 HBMASTER: submitting job (8, 0, 21) to dispatcher
06:21:59 DISPATCHER: trying to submit job (8, 0, 21)
06:21:59 DISPATCHER: trying to notify the job_runner thread.
06:21:59 HBMASTER: job (8, 0, 21) submitted to dispatcher
06:21:59 DISPATCHER: Trying to submit another job.
06:21:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:21:59 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776
06:21:59 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
06:21:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:21:59 WORKER: start processing job (8, 0, 21)
06:21:59 WORKER: args: ()
06:21:59 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.001942831190041424, 'num_filters_1': 75, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.03738062891908018}, 'budget': 133.33333333333331, 'working_directory': '.'}
06:22:10 DISPATCHER: Starting worker discovery
06:22:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:22:10 DISPATCHER: Finished worker discovery
06:23:10 DISPATCHER: Starting worker discovery
06:23:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:23:10 DISPATCHER: Finished worker discovery
06:24:10 DISPATCHER: Starting worker discovery
06:24:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:24:10 DISPATCHER: Finished worker discovery
06:24:49 WORKER: done with job (8, 0, 21), trying to register it.
06:24:49 WORKER: registered result for job (8, 0, 21) with dispatcher
06:24:49 DISPATCHER: job (8, 0, 21) finished
06:24:49 DISPATCHER: register_result: lock acquired
06:24:49 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
06:24:49 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.001942831190041424, 'num_filters_1': 75, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.03738062891908018}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3932693546402887, 'info': {'data03': 0.3932693546402887, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.001942831190041424, 'num_filters_1': 75, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.03738062891908018}"}}
exception: None

06:24:49 job_callback for (8, 0, 21) started
06:24:49 job_callback for (8, 0, 21) got condition
06:24:49 DISPATCHER: Trying to submit another job.
06:24:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:24:49 done building a new model for budget 133.333333 based on 17/35 split
Best loss for this budget:-0.436222





06:24:49 HBMASTER: Trying to run another job!
06:24:49 job_callback for (8, 0, 21) finished
06:24:49 HBMASTER: schedule new run for iteration 8
06:24:49 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
06:24:49 HBMASTER: submitting job (8, 0, 22) to dispatcher
06:24:49 DISPATCHER: trying to submit job (8, 0, 22)
06:24:49 DISPATCHER: trying to notify the job_runner thread.
06:24:49 HBMASTER: job (8, 0, 22) submitted to dispatcher
06:24:49 DISPATCHER: Trying to submit another job.
06:24:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:24:49 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776
06:24:49 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
06:24:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:24:49 WORKER: start processing job (8, 0, 22)
06:24:49 WORKER: args: ()
06:24:49 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005986964626425833, 'num_filters_1': 27, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.03936387097971105, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 25, 'num_filters_3': 56, 'num_filters_4': 87, 'num_filters_5': 16}, 'budget': 133.33333333333331, 'working_directory': '.'}
06:25:10 DISPATCHER: Starting worker discovery
06:25:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:25:10 DISPATCHER: Finished worker discovery
06:26:10 DISPATCHER: Starting worker discovery
06:26:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:26:10 DISPATCHER: Finished worker discovery
06:27:10 DISPATCHER: Starting worker discovery
06:27:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:27:10 DISPATCHER: Finished worker discovery
06:27:40 WORKER: done with job (8, 0, 22), trying to register it.
06:27:40 WORKER: registered result for job (8, 0, 22) with dispatcher
06:27:40 DISPATCHER: job (8, 0, 22) finished
06:27:40 DISPATCHER: register_result: lock acquired
06:27:40 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
06:27:40 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005986964626425833, 'num_filters_1': 27, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.03936387097971105, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 25, 'num_filters_3': 56, 'num_filters_4': 87, 'num_filters_5': 16}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3233167304666285, 'info': {'data03': 0.3233167304666285, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.005986964626425833, 'num_filters_1': 27, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.03936387097971105, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 25, 'num_filters_3': 56, 'num_filters_4': 87, 'num_filters_5': 16}"}}
exception: None

06:27:40 job_callback for (8, 0, 22) started
06:27:40 DISPATCHER: Trying to submit another job.
06:27:40 job_callback for (8, 0, 22) got condition
06:27:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:27:40 done building a new model for budget 133.333333 based on 17/36 split
Best loss for this budget:-0.436222





06:27:40 HBMASTER: Trying to run another job!
06:27:40 job_callback for (8, 0, 22) finished
06:27:40 HBMASTER: schedule new run for iteration 8
06:27:40 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
06:27:40 HBMASTER: submitting job (8, 0, 24) to dispatcher
06:27:40 DISPATCHER: trying to submit job (8, 0, 24)
06:27:40 DISPATCHER: trying to notify the job_runner thread.
06:27:40 HBMASTER: job (8, 0, 24) submitted to dispatcher
06:27:40 DISPATCHER: Trying to submit another job.
06:27:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:27:40 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776
06:27:40 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
06:27:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:27:40 WORKER: start processing job (8, 0, 24)
06:27:40 WORKER: args: ()
06:27:40 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004939110157057794, 'num_filters_1': 49, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.04293193654666642, 'kernel_size_2': 7, 'num_filters_2': 121}, 'budget': 133.33333333333331, 'working_directory': '.'}
06:28:10 DISPATCHER: Starting worker discovery
06:28:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:28:10 DISPATCHER: Finished worker discovery
06:29:10 DISPATCHER: Starting worker discovery
06:29:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:29:10 DISPATCHER: Finished worker discovery
06:30:10 DISPATCHER: Starting worker discovery
06:30:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:30:10 DISPATCHER: Finished worker discovery
06:30:33 WORKER: done with job (8, 0, 24), trying to register it.
06:30:33 WORKER: registered result for job (8, 0, 24) with dispatcher
06:30:33 DISPATCHER: job (8, 0, 24) finished
06:30:33 DISPATCHER: register_result: lock acquired
06:30:33 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
06:30:33 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004939110157057794, 'num_filters_1': 49, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.04293193654666642, 'kernel_size_2': 7, 'num_filters_2': 121}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4356495696240483, 'info': {'data03': 0.4356495696240483, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004939110157057794, 'num_filters_1': 49, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.04293193654666642, 'kernel_size_2': 7, 'num_filters_2': 121}"}}
exception: None

06:30:33 job_callback for (8, 0, 24) started
06:30:33 DISPATCHER: Trying to submit another job.
06:30:33 job_callback for (8, 0, 24) got condition
06:30:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:30:33 done building a new model for budget 133.333333 based on 17/37 split
Best loss for this budget:-0.436222





06:30:33 HBMASTER: Trying to run another job!
06:30:33 job_callback for (8, 0, 24) finished
06:30:33 HBMASTER: schedule new run for iteration 8
06:30:33 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
06:30:33 HBMASTER: submitting job (8, 0, 26) to dispatcher
06:30:33 DISPATCHER: trying to submit job (8, 0, 26)
06:30:33 DISPATCHER: trying to notify the job_runner thread.
06:30:33 HBMASTER: job (8, 0, 26) submitted to dispatcher
06:30:33 DISPATCHER: Trying to submit another job.
06:30:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:30:33 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpui.1576139975513683776
06:30:33 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
06:30:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:30:33 WORKER: start processing job (8, 0, 26)
06:30:33 WORKER: args: ()
06:30:33 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002373337230686932, 'num_filters_1': 47, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.1886887336602998, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 56, 'num_filters_3': 49}, 'budget': 133.33333333333331, 'working_directory': '.'}
06:31:10 DISPATCHER: Starting worker discovery
06:31:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:31:10 DISPATCHER: Finished worker discovery
06:32:10 DISPATCHER: Starting worker discovery
06:32:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:32:11 DISPATCHER: Finished worker discovery
06:33:11 DISPATCHER: Starting worker discovery
06:33:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:33:11 DISPATCHER: Finished worker discovery
06:33:26 WORKER: done with job (8, 0, 26), trying to register it.
06:33:26 WORKER: registered result for job (8, 0, 26) with dispatcher
06:33:26 DISPATCHER: job (8, 0, 26) finished
06:33:26 DISPATCHER: register_result: lock acquired
06:33:26 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
06:33:26 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002373337230686932, 'num_filters_1': 47, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.1886887336602998, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 56, 'num_filters_3': 49}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3126476694617103, 'info': {'data03': 0.3126476694617103, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.002373337230686932, 'num_filters_1': 47, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.1886887336602998, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 56, 'num_filters_3': 49}"}}
exception: None

06:33:26 job_callback for (8, 0, 26) started
06:33:26 DISPATCHER: Trying to submit another job.
06:33:26 job_callback for (8, 0, 26) got condition
06:33:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:33:26 done building a new model for budget 133.333333 based on 17/38 split
Best loss for this budget:-0.436222





06:33:26 HBMASTER: Trying to run another job!
06:33:26 job_callback for (8, 0, 26) finished
06:33:26 ITERATION: Advancing config (8, 0, 2) to next budget 400.000000
06:33:26 ITERATION: Advancing config (8, 0, 21) to next budget 400.000000
06:33:26 ITERATION: Advancing config (8, 0, 24) to next budget 400.000000
06:33:26 HBMASTER: schedule new run for iteration 8
06:33:26 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
06:33:26 HBMASTER: submitting job (8, 0, 2) to dispatcher
06:33:26 DISPATCHER: trying to submit job (8, 0, 2)
06:33:26 DISPATCHER: trying to notify the job_runner thread.
06:33:26 HBMASTER: job (8, 0, 2) submitted to dispatcher
06:33:26 DISPATCHER: Trying to submit another job.
06:33:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:33:26 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
06:33:26 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
06:33:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:33:26 WORKER: start processing job (8, 0, 2)
06:33:26 WORKER: args: ()
06:33:26 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0011611752267125096, 'num_filters_1': 109, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.11364480322835335}, 'budget': 400.0, 'working_directory': '.'}
06:34:11 DISPATCHER: Starting worker discovery
06:34:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:34:11 DISPATCHER: Finished worker discovery
06:35:11 DISPATCHER: Starting worker discovery
06:35:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:35:11 DISPATCHER: Finished worker discovery
06:36:11 DISPATCHER: Starting worker discovery
06:36:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:36:11 DISPATCHER: Finished worker discovery
06:37:11 DISPATCHER: Starting worker discovery
06:37:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:37:11 DISPATCHER: Finished worker discovery
06:38:11 DISPATCHER: Starting worker discovery
06:38:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:38:11 DISPATCHER: Finished worker discovery
06:39:11 DISPATCHER: Starting worker discovery
06:39:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:39:11 DISPATCHER: Finished worker discovery
06:40:11 DISPATCHER: Starting worker discovery
06:40:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:40:11 DISPATCHER: Finished worker discovery
06:40:48 WORKER: done with job (8, 0, 2), trying to register it.
06:40:48 WORKER: registered result for job (8, 0, 2) with dispatcher
06:40:48 DISPATCHER: job (8, 0, 2) finished
06:40:48 DISPATCHER: register_result: lock acquired
06:40:48 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
06:40:48 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0011611752267125096, 'num_filters_1': 109, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.11364480322835335}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3306523381358123, 'info': {'data03': 0.3306523381358123, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0011611752267125096, 'num_filters_1': 109, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.11364480322835335}"}}
exception: None

06:40:48 job_callback for (8, 0, 2) started
06:40:48 DISPATCHER: Trying to submit another job.
06:40:48 job_callback for (8, 0, 2) got condition
06:40:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:40:48 HBMASTER: Trying to run another job!
06:40:48 job_callback for (8, 0, 2) finished
06:40:48 HBMASTER: schedule new run for iteration 8
06:40:48 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
06:40:48 HBMASTER: submitting job (8, 0, 21) to dispatcher
06:40:48 DISPATCHER: trying to submit job (8, 0, 21)
06:40:48 DISPATCHER: trying to notify the job_runner thread.
06:40:48 HBMASTER: job (8, 0, 21) submitted to dispatcher
06:40:48 DISPATCHER: Trying to submit another job.
06:40:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:40:48 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776
06:40:48 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
06:40:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:40:48 WORKER: start processing job (8, 0, 21)
06:40:48 WORKER: args: ()
06:40:48 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.001942831190041424, 'num_filters_1': 75, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.03738062891908018}, 'budget': 400.0, 'working_directory': '.'}
06:41:11 DISPATCHER: Starting worker discovery
06:41:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:41:11 DISPATCHER: Finished worker discovery
06:42:11 DISPATCHER: Starting worker discovery
06:42:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:42:11 DISPATCHER: Finished worker discovery
06:43:11 DISPATCHER: Starting worker discovery
06:43:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:43:11 DISPATCHER: Finished worker discovery
06:44:11 DISPATCHER: Starting worker discovery
06:44:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:44:11 DISPATCHER: Finished worker discovery
06:45:11 DISPATCHER: Starting worker discovery
06:45:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:45:11 DISPATCHER: Finished worker discovery
06:46:11 DISPATCHER: Starting worker discovery
06:46:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:46:11 DISPATCHER: Finished worker discovery
06:47:11 DISPATCHER: Starting worker discovery
06:47:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:47:11 DISPATCHER: Finished worker discovery
06:48:08 WORKER: done with job (8, 0, 21), trying to register it.
06:48:08 WORKER: registered result for job (8, 0, 21) with dispatcher
06:48:08 DISPATCHER: job (8, 0, 21) finished
06:48:08 DISPATCHER: register_result: lock acquired
06:48:08 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
06:48:08 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.001942831190041424, 'num_filters_1': 75, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.03738062891908018}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.27348542251637276, 'info': {'data03': 0.27348542251637276, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.001942831190041424, 'num_filters_1': 75, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.03738062891908018}"}}
exception: None

06:48:08 job_callback for (8, 0, 21) started
06:48:08 job_callback for (8, 0, 21) got condition
06:48:08 DISPATCHER: Trying to submit another job.
06:48:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:48:08 HBMASTER: Trying to run another job!
06:48:08 job_callback for (8, 0, 21) finished
06:48:08 HBMASTER: schedule new run for iteration 8
06:48:08 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
06:48:08 HBMASTER: submitting job (8, 0, 24) to dispatcher
06:48:08 DISPATCHER: trying to submit job (8, 0, 24)
06:48:08 DISPATCHER: trying to notify the job_runner thread.
06:48:08 HBMASTER: job (8, 0, 24) submitted to dispatcher
06:48:08 DISPATCHER: Trying to submit another job.
06:48:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:48:08 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776
06:48:08 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
06:48:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:48:08 WORKER: start processing job (8, 0, 24)
06:48:08 WORKER: args: ()
06:48:08 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004939110157057794, 'num_filters_1': 49, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.04293193654666642, 'kernel_size_2': 7, 'num_filters_2': 121}, 'budget': 400.0, 'working_directory': '.'}
06:48:11 DISPATCHER: Starting worker discovery
06:48:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:48:11 DISPATCHER: Finished worker discovery
06:49:11 DISPATCHER: Starting worker discovery
06:49:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:49:11 DISPATCHER: Finished worker discovery
06:50:11 DISPATCHER: Starting worker discovery
06:50:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:50:11 DISPATCHER: Finished worker discovery
06:51:11 DISPATCHER: Starting worker discovery
06:51:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:51:11 DISPATCHER: Finished worker discovery
06:52:11 DISPATCHER: Starting worker discovery
06:52:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:52:11 DISPATCHER: Finished worker discovery
06:53:11 DISPATCHER: Starting worker discovery
06:53:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:53:11 DISPATCHER: Finished worker discovery
06:54:11 DISPATCHER: Starting worker discovery
06:54:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:54:11 DISPATCHER: Finished worker discovery
06:55:11 DISPATCHER: Starting worker discovery
06:55:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:55:11 DISPATCHER: Finished worker discovery
06:55:27 WORKER: done with job (8, 0, 24), trying to register it.
06:55:27 WORKER: registered result for job (8, 0, 24) with dispatcher
06:55:27 DISPATCHER: job (8, 0, 24) finished
06:55:27 DISPATCHER: register_result: lock acquired
06:55:27 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
06:55:27 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004939110157057794, 'num_filters_1': 49, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.04293193654666642, 'kernel_size_2': 7, 'num_filters_2': 121}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.37429337643009497, 'info': {'data03': 0.37429337643009497, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004939110157057794, 'num_filters_1': 49, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.04293193654666642, 'kernel_size_2': 7, 'num_filters_2': 121}"}}
exception: None

06:55:27 job_callback for (8, 0, 24) started
06:55:27 DISPATCHER: Trying to submit another job.
06:55:27 job_callback for (8, 0, 24) got condition
06:55:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:55:27 HBMASTER: Trying to run another job!
06:55:27 job_callback for (8, 0, 24) finished
06:55:27 ITERATION: Advancing config (8, 0, 24) to next budget 1200.000000
06:55:27 HBMASTER: schedule new run for iteration 8
06:55:27 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
06:55:27 HBMASTER: submitting job (8, 0, 24) to dispatcher
06:55:27 DISPATCHER: trying to submit job (8, 0, 24)
06:55:27 DISPATCHER: trying to notify the job_runner thread.
06:55:27 HBMASTER: job (8, 0, 24) submitted to dispatcher
06:55:27 DISPATCHER: Trying to submit another job.
06:55:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:55:27 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776
06:55:27 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
06:55:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:55:27 WORKER: start processing job (8, 0, 24)
06:55:27 WORKER: args: ()
06:55:27 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004939110157057794, 'num_filters_1': 49, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.04293193654666642, 'kernel_size_2': 7, 'num_filters_2': 121}, 'budget': 1200.0, 'working_directory': '.'}
06:56:11 DISPATCHER: Starting worker discovery
06:56:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:56:11 DISPATCHER: Finished worker discovery
06:57:11 DISPATCHER: Starting worker discovery
06:57:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:57:11 DISPATCHER: Finished worker discovery
06:58:11 DISPATCHER: Starting worker discovery
06:58:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:58:11 DISPATCHER: Finished worker discovery
06:59:11 DISPATCHER: Starting worker discovery
06:59:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:59:11 DISPATCHER: Finished worker discovery
07:00:11 DISPATCHER: Starting worker discovery
07:00:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:00:11 DISPATCHER: Finished worker discovery
07:01:11 DISPATCHER: Starting worker discovery
07:01:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:01:11 DISPATCHER: Finished worker discovery
07:02:11 DISPATCHER: Starting worker discovery
07:02:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:02:11 DISPATCHER: Finished worker discovery
07:03:11 DISPATCHER: Starting worker discovery
07:03:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:03:11 DISPATCHER: Finished worker discovery
07:04:11 DISPATCHER: Starting worker discovery
07:04:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:04:11 DISPATCHER: Finished worker discovery
07:05:11 DISPATCHER: Starting worker discovery
07:05:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:05:11 DISPATCHER: Finished worker discovery
07:06:11 DISPATCHER: Starting worker discovery
07:06:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:06:11 DISPATCHER: Finished worker discovery
07:07:11 DISPATCHER: Starting worker discovery
07:07:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:07:11 DISPATCHER: Finished worker discovery
07:08:11 DISPATCHER: Starting worker discovery
07:08:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:08:11 DISPATCHER: Finished worker discovery
07:09:11 DISPATCHER: Starting worker discovery
07:09:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:09:11 DISPATCHER: Finished worker discovery
07:10:11 DISPATCHER: Starting worker discovery
07:10:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:10:11 DISPATCHER: Finished worker discovery
07:11:11 DISPATCHER: Starting worker discovery
07:11:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:11:11 DISPATCHER: Finished worker discovery
07:12:11 DISPATCHER: Starting worker discovery
07:12:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:12:11 DISPATCHER: Finished worker discovery
07:13:11 DISPATCHER: Starting worker discovery
07:13:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:13:11 DISPATCHER: Finished worker discovery
07:14:11 DISPATCHER: Starting worker discovery
07:14:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:14:11 DISPATCHER: Finished worker discovery
07:15:11 DISPATCHER: Starting worker discovery
07:15:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:15:11 DISPATCHER: Finished worker discovery
07:16:08 WORKER: done with job (8, 0, 24), trying to register it.
07:16:08 WORKER: registered result for job (8, 0, 24) with dispatcher
07:16:08 DISPATCHER: job (8, 0, 24) finished
07:16:08 DISPATCHER: register_result: lock acquired
07:16:08 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
07:16:08 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004939110157057794, 'num_filters_1': 49, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.04293193654666642, 'kernel_size_2': 7, 'num_filters_2': 121}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.3116153732384428, 'info': {'data03': 0.3116153732384428, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.004939110157057794, 'num_filters_1': 49, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.04293193654666642, 'kernel_size_2': 7, 'num_filters_2': 121}"}}
exception: None

07:16:08 job_callback for (8, 0, 24) started
07:16:08 DISPATCHER: Trying to submit another job.
07:16:08 job_callback for (8, 0, 24) got condition
07:16:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:16:08 HBMASTER: Trying to run another job!
07:16:08 job_callback for (8, 0, 24) finished
07:16:08 start sampling a new configuration.
07:16:08 best_vector: [1, 1, 0.7438065114078236, 0.9045990034547555, 0.14262302741365374, 1, 0.7627588379111796, 0.7766618454026524, 0, 1, 2, 0, 0.19977787303361902, 0.0511367818991154, 0.840611423824434, 0.022367368253356848], 0.0010641644308634229, 0.0012281897637466538, 1.3069958609297397e-06
07:16:08 done sampling a new configuration.
07:16:08 HBMASTER: schedule new run for iteration 9
07:16:08 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
07:16:08 HBMASTER: submitting job (9, 0, 0) to dispatcher
07:16:08 DISPATCHER: trying to submit job (9, 0, 0)
07:16:08 DISPATCHER: trying to notify the job_runner thread.
07:16:08 HBMASTER: job (9, 0, 0) submitted to dispatcher
07:16:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:16:08 DISPATCHER: Trying to submit another job.
07:16:08 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776
07:16:08 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
07:16:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:16:08 WORKER: start processing job (9, 0, 0)
07:16:08 WORKER: args: ()
07:16:08 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.030733570859420453, 'num_filters_1': 105, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.10243782702207109}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:16:11 DISPATCHER: Starting worker discovery
07:16:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:16:11 DISPATCHER: Finished worker discovery
07:17:11 DISPATCHER: Starting worker discovery
07:17:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:17:11 DISPATCHER: Finished worker discovery
07:18:11 DISPATCHER: Starting worker discovery
07:18:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:18:11 DISPATCHER: Finished worker discovery
07:19:03 WORKER: done with job (9, 0, 0), trying to register it.
07:19:03 WORKER: registered result for job (9, 0, 0) with dispatcher
07:19:03 DISPATCHER: job (9, 0, 0) finished
07:19:03 DISPATCHER: register_result: lock acquired
07:19:03 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
07:19:03 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.030733570859420453, 'num_filters_1': 105, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.10243782702207109}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.30238748400731863, 'info': {'data03': 0.30238748400731863, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.030733570859420453, 'num_filters_1': 105, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.10243782702207109}"}}
exception: None

07:19:03 job_callback for (9, 0, 0) started
07:19:03 job_callback for (9, 0, 0) got condition
07:19:03 DISPATCHER: Trying to submit another job.
07:19:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:19:03 done building a new model for budget 133.333333 based on 17/39 split
Best loss for this budget:-0.436222





07:19:03 HBMASTER: Trying to run another job!
07:19:03 job_callback for (9, 0, 0) finished
07:19:03 start sampling a new configuration.
07:19:03 best_vector: [1, 2, 0.46184901263466277, 0.9152994164431703, 0.22732315345895623, 1, 0.25179875864946055, 0.01893264590234911, 1, 1, 1, 0, 0.21896534707464058, 0.5753100693083141, 0.8525443989423085, 0.9406182213514095], 0.01315834624515887, 0.004662239258354229, 6.134735843919764e-05
07:19:03 done sampling a new configuration.
07:19:03 HBMASTER: schedule new run for iteration 9
07:19:03 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
07:19:03 HBMASTER: submitting job (9, 0, 1) to dispatcher
07:19:03 DISPATCHER: trying to submit job (9, 0, 1)
07:19:03 DISPATCHER: trying to notify the job_runner thread.
07:19:03 HBMASTER: job (9, 0, 1) submitted to dispatcher
07:19:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:19:03 DISPATCHER: Trying to submit another job.
07:19:03 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776
07:19:03 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
07:19:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:19:03 WORKER: start processing job (9, 0, 1)
07:19:03 WORKER: args: ()
07:19:03 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.008388764939730073, 'num_filters_1': 107, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.010583563996177377, 'kernel_size_2': 5, 'num_filters_2': 25}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:19:11 DISPATCHER: Starting worker discovery
07:19:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:19:11 DISPATCHER: Finished worker discovery
07:20:11 DISPATCHER: Starting worker discovery
07:20:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:20:11 DISPATCHER: Finished worker discovery
07:21:11 DISPATCHER: Starting worker discovery
07:21:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:21:11 DISPATCHER: Finished worker discovery
07:21:58 WORKER: done with job (9, 0, 1), trying to register it.
07:21:58 WORKER: registered result for job (9, 0, 1) with dispatcher
07:21:58 DISPATCHER: job (9, 0, 1) finished
07:21:58 DISPATCHER: register_result: lock acquired
07:21:58 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
07:21:58 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.008388764939730073, 'num_filters_1': 107, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.010583563996177377, 'kernel_size_2': 5, 'num_filters_2': 25}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.33046911285876734, 'info': {'data03': 0.33046911285876734, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.008388764939730073, 'num_filters_1': 107, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.010583563996177377, 'kernel_size_2': 5, 'num_filters_2': 25}"}}
exception: None

07:21:58 job_callback for (9, 0, 1) started
07:21:58 job_callback for (9, 0, 1) got condition
07:21:58 DISPATCHER: Trying to submit another job.
07:21:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:21:58 done building a new model for budget 133.333333 based on 17/39 split
Best loss for this budget:-0.436222





07:21:58 HBMASTER: Trying to run another job!
07:21:58 job_callback for (9, 0, 1) finished
07:21:58 start sampling a new configuration.
07:21:59 best_vector: [0, 1, 0.12611779124621778, 0.9176248945457119, 0.8631812746126961, 1, 0.12841512714566658, 0.05334541267626475, 1, 1, 2, 0, 0.6757129295706947, 0.026623682156531547, 0.6723282480209691, 0.7388179939311775], 0.013459643964554298, 0.00028466551505692167, 3.831496481652636e-06
07:21:59 done sampling a new configuration.
07:21:59 HBMASTER: schedule new run for iteration 9
07:21:59 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
07:21:59 HBMASTER: submitting job (9, 0, 2) to dispatcher
07:21:59 DISPATCHER: trying to submit job (9, 0, 2)
07:21:59 DISPATCHER: trying to notify the job_runner thread.
07:21:59 HBMASTER: job (9, 0, 2) submitted to dispatcher
07:21:59 DISPATCHER: Trying to submit another job.
07:21:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:21:59 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776
07:21:59 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
07:21:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:21:59 WORKER: start processing job (9, 0, 2)
07:21:59 WORKER: args: ()
07:21:59 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0017874569156626535, 'num_filters_1': 108, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.0117328625246918, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 65, 'num_filters_3': 16, 'num_filters_4': 64, 'num_filters_5': 74}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:22:11 DISPATCHER: Starting worker discovery
07:22:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:22:11 DISPATCHER: Finished worker discovery
07:23:11 DISPATCHER: Starting worker discovery
07:23:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:23:11 DISPATCHER: Finished worker discovery
07:24:11 DISPATCHER: Starting worker discovery
07:24:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:24:11 DISPATCHER: Finished worker discovery
07:24:54 WORKER: done with job (9, 0, 2), trying to register it.
07:24:54 WORKER: registered result for job (9, 0, 2) with dispatcher
07:24:54 DISPATCHER: job (9, 0, 2) finished
07:24:54 DISPATCHER: register_result: lock acquired
07:24:54 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
07:24:54 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0017874569156626535, 'num_filters_1': 108, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.0117328625246918, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 65, 'num_filters_3': 16, 'num_filters_4': 64, 'num_filters_5': 74}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3433405419748194, 'info': {'data03': 0.3433405419748194, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0017874569156626535, 'num_filters_1': 108, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.0117328625246918, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 65, 'num_filters_3': 16, 'num_filters_4': 64, 'num_filters_5': 74}"}}
exception: None

07:24:54 job_callback for (9, 0, 2) started
07:24:54 job_callback for (9, 0, 2) got condition
07:24:54 DISPATCHER: Trying to submit another job.
07:24:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:24:54 done building a new model for budget 133.333333 based on 17/40 split
Best loss for this budget:-0.436222





07:24:54 HBMASTER: Trying to run another job!
07:24:54 job_callback for (9, 0, 2) finished
07:24:54 start sampling a new configuration.
07:24:54 best_vector: [0, 0, 0.0752133550433772, 0.6722810018428866, 0.40089602286186604, 1, 0.22753060738975173, 0.18008021731716584, 1, 2, 2, 0, 0.9508652506194516, 0.5434507490575332, 0.7266334981729671, 0.48677214579898825], 0.04681240222958655, 0.00044188518018219175, 2.0685706793982085e-05
07:24:54 done sampling a new configuration.
07:24:54 HBMASTER: schedule new run for iteration 9
07:24:54 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
07:24:54 HBMASTER: submitting job (9, 0, 3) to dispatcher
07:24:54 DISPATCHER: trying to submit job (9, 0, 3)
07:24:54 DISPATCHER: trying to notify the job_runner thread.
07:24:54 HBMASTER: job (9, 0, 3) submitted to dispatcher
07:24:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:24:54 DISPATCHER: Trying to submit another job.
07:24:54 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776
07:24:54 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
07:24:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:24:54 WORKER: start processing job (9, 0, 3)
07:24:54 WORKER: args: ()
07:24:54 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0014139260960533513, 'num_filters_1': 64, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.017151012535494715, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 116, 'num_filters_3': 49}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:25:11 DISPATCHER: Starting worker discovery
07:25:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:25:11 DISPATCHER: Finished worker discovery
07:26:11 DISPATCHER: Starting worker discovery
07:26:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:26:11 DISPATCHER: Finished worker discovery
07:27:11 DISPATCHER: Starting worker discovery
07:27:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:27:11 DISPATCHER: Finished worker discovery
07:27:50 WORKER: done with job (9, 0, 3), trying to register it.
07:27:50 WORKER: registered result for job (9, 0, 3) with dispatcher
07:27:50 DISPATCHER: job (9, 0, 3) finished
07:27:50 DISPATCHER: register_result: lock acquired
07:27:50 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
07:27:50 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0014139260960533513, 'num_filters_1': 64, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.017151012535494715, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 116, 'num_filters_3': 49}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3262904591065556, 'info': {'data03': 0.3262904591065556, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0014139260960533513, 'num_filters_1': 64, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.017151012535494715, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 116, 'num_filters_3': 49}"}}
exception: None

07:27:50 job_callback for (9, 0, 3) started
07:27:50 job_callback for (9, 0, 3) got condition
07:27:50 DISPATCHER: Trying to submit another job.
07:27:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:27:50 done building a new model for budget 133.333333 based on 17/41 split
Best loss for this budget:-0.436222





07:27:50 HBMASTER: Trying to run another job!
07:27:50 job_callback for (9, 0, 3) finished
07:27:50 start sampling a new configuration.
07:27:50 best_vector: [0, 1, 0.06115082745921189, 0.33112062810439336, 0.5740721860632667, 1, 0.8390558866927651, 0.4321208348302949, 0, 1, 2, 1, 0.26423552161310193, 0.6871449702111767, 0.7691902793966638, 0.8543218549706639], 2.2927834616189573e-30, 0.004361510874183862, -2.842488455910795e-05
07:27:50 done sampling a new configuration.
07:27:50 HBMASTER: schedule new run for iteration 9
07:27:50 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
07:27:50 HBMASTER: submitting job (9, 0, 4) to dispatcher
07:27:50 DISPATCHER: trying to submit job (9, 0, 4)
07:27:50 DISPATCHER: trying to notify the job_runner thread.
07:27:50 HBMASTER: job (9, 0, 4) submitted to dispatcher
07:27:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:27:50 DISPATCHER: Trying to submit another job.
07:27:50 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
07:27:50 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
07:27:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:27:50 WORKER: start processing job (9, 0, 4)
07:27:50 WORKER: args: ()
07:27:50 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001325261723979202, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.03649237825931296, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 27, 'num_filters_3': 66}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:28:11 DISPATCHER: Starting worker discovery
07:28:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:28:11 DISPATCHER: Finished worker discovery
07:29:11 DISPATCHER: Starting worker discovery
07:29:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:29:11 DISPATCHER: Finished worker discovery
07:30:11 DISPATCHER: Starting worker discovery
07:30:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:30:11 DISPATCHER: Finished worker discovery
07:30:48 WORKER: done with job (9, 0, 4), trying to register it.
07:30:48 WORKER: registered result for job (9, 0, 4) with dispatcher
07:30:48 DISPATCHER: job (9, 0, 4) finished
07:30:48 DISPATCHER: register_result: lock acquired
07:30:48 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
07:30:48 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001325261723979202, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.03649237825931296, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 27, 'num_filters_3': 66}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.39573304845340773, 'info': {'data03': 0.39573304845340773, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001325261723979202, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.03649237825931296, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 27, 'num_filters_3': 66}"}}
exception: None

07:30:48 job_callback for (9, 0, 4) started
07:30:48 job_callback for (9, 0, 4) got condition
07:30:48 DISPATCHER: Trying to submit another job.
07:30:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:30:48 done building a new model for budget 133.333333 based on 17/42 split
Best loss for this budget:-0.436222





07:30:48 HBMASTER: Trying to run another job!
07:30:48 job_callback for (9, 0, 4) finished
07:30:48 start sampling a new configuration.
07:30:48 done sampling a new configuration.
07:30:48 HBMASTER: schedule new run for iteration 9
07:30:48 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
07:30:48 HBMASTER: submitting job (9, 0, 5) to dispatcher
07:30:48 DISPATCHER: trying to submit job (9, 0, 5)
07:30:48 DISPATCHER: trying to notify the job_runner thread.
07:30:48 HBMASTER: job (9, 0, 5) submitted to dispatcher
07:30:48 DISPATCHER: Trying to submit another job.
07:30:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:30:48 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776
07:30:48 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
07:30:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:30:48 WORKER: start processing job (9, 0, 5)
07:30:48 WORKER: args: ()
07:30:48 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.09330141879524455, 'num_filters_1': 65, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.08847534347554765, 'kernel_size_2': 5, 'num_filters_2': 16}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:31:11 DISPATCHER: Starting worker discovery
07:31:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:31:11 DISPATCHER: Finished worker discovery
07:32:11 DISPATCHER: Starting worker discovery
07:32:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:32:11 DISPATCHER: Finished worker discovery
07:33:11 DISPATCHER: Starting worker discovery
07:33:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:33:11 DISPATCHER: Finished worker discovery
07:33:45 WORKER: done with job (9, 0, 5), trying to register it.
07:33:45 WORKER: registered result for job (9, 0, 5) with dispatcher
07:33:45 DISPATCHER: job (9, 0, 5) finished
07:33:45 DISPATCHER: register_result: lock acquired
07:33:45 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
07:33:45 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.09330141879524455, 'num_filters_1': 65, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.08847534347554765, 'kernel_size_2': 5, 'num_filters_2': 16}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3454384340750129, 'info': {'data03': 0.3454384340750129, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.09330141879524455, 'num_filters_1': 65, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.08847534347554765, 'kernel_size_2': 5, 'num_filters_2': 16}"}}
exception: None

07:33:45 job_callback for (9, 0, 5) started
07:33:45 job_callback for (9, 0, 5) got condition
07:33:45 DISPATCHER: Trying to submit another job.
07:33:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:33:45 done building a new model for budget 133.333333 based on 17/43 split
Best loss for this budget:-0.436222





07:33:45 HBMASTER: Trying to run another job!
07:33:45 job_callback for (9, 0, 5) finished
07:33:45 start sampling a new configuration.
07:33:45 best_vector: [0, 0, 0.6987115296393556, 0.15403072233184978, 0.782974945824026, 1, 0.7971531914769253, 0.10467836400943609, 2, 2, 0, 0, 0.8383447695564963, 0.7003378499947099, 0.9701522485812775, 0.8181277269238476], 5.4181224467336426e-27, 1.8456578082742627e-06, -9.984514945084635e-06
07:33:45 done sampling a new configuration.
07:33:45 HBMASTER: schedule new run for iteration 9
07:33:45 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
07:33:45 HBMASTER: submitting job (9, 0, 6) to dispatcher
07:33:45 DISPATCHER: trying to submit job (9, 0, 6)
07:33:45 DISPATCHER: trying to notify the job_runner thread.
07:33:45 HBMASTER: job (9, 0, 6) submitted to dispatcher
07:33:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:33:45 DISPATCHER: Trying to submit another job.
07:33:45 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776
07:33:45 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
07:33:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:33:45 WORKER: start processing job (9, 0, 6)
07:33:45 WORKER: args: ()
07:33:45 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.024970259704572596, 'num_filters_1': 21, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.013683263537148962, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 91, 'num_filters_3': 68, 'num_filters_4': 121}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:34:11 DISPATCHER: Starting worker discovery
07:34:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:34:11 DISPATCHER: Finished worker discovery
07:35:11 DISPATCHER: Starting worker discovery
07:35:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:35:11 DISPATCHER: Finished worker discovery
07:36:11 DISPATCHER: Starting worker discovery
07:36:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:36:11 DISPATCHER: Finished worker discovery
07:36:40 WORKER: done with job (9, 0, 6), trying to register it.
07:36:40 WORKER: registered result for job (9, 0, 6) with dispatcher
07:36:40 DISPATCHER: job (9, 0, 6) finished
07:36:40 DISPATCHER: register_result: lock acquired
07:36:40 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
07:36:40 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.024970259704572596, 'num_filters_1': 21, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.013683263537148962, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 91, 'num_filters_3': 68, 'num_filters_4': 121}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3384399603866742, 'info': {'data03': 0.3384399603866742, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.024970259704572596, 'num_filters_1': 21, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 82, 'weight_decay': 0.013683263537148962, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 91, 'num_filters_3': 68, 'num_filters_4': 121}"}}
exception: None

07:36:40 job_callback for (9, 0, 6) started
07:36:40 DISPATCHER: Trying to submit another job.
07:36:40 job_callback for (9, 0, 6) got condition
07:36:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:36:40 done building a new model for budget 133.333333 based on 17/44 split
Best loss for this budget:-0.436222





07:36:40 HBMASTER: Trying to run another job!
07:36:40 job_callback for (9, 0, 6) finished
07:36:40 start sampling a new configuration.
07:36:40 best_vector: [1, 1, 0.26357412779653644, 0.41472644808214787, 0.3586222689772168, 1, 0.1559946820547139, 0.4792241673691031, 0, 1, 1, 0, 0.8210755699613983, 0.5376904892385548, 0.7345301207549628, 0.003826605592872956], 0.0016013180875788654, 0.0048838981305725, 7.820674414378352e-06
07:36:40 done sampling a new configuration.
07:36:40 HBMASTER: schedule new run for iteration 9
07:36:40 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
07:36:40 HBMASTER: submitting job (9, 0, 7) to dispatcher
07:36:40 DISPATCHER: trying to submit job (9, 0, 7)
07:36:40 DISPATCHER: trying to notify the job_runner thread.
07:36:40 HBMASTER: job (9, 0, 7) submitted to dispatcher
07:36:40 DISPATCHER: Trying to submit another job.
07:36:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:36:40 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776
07:36:40 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
07:36:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:36:40 WORKER: start processing job (9, 0, 7)
07:36:40 WORKER: args: ()
07:36:40 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0033662646431612906, 'num_filters_1': 37, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.04202280291285742, 'kernel_size_2': 3, 'num_filters_2': 88}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:37:11 DISPATCHER: Starting worker discovery
07:37:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:37:11 DISPATCHER: Finished worker discovery
07:38:11 DISPATCHER: Starting worker discovery
07:38:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:38:11 DISPATCHER: Finished worker discovery
07:39:11 DISPATCHER: Starting worker discovery
07:39:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:39:11 DISPATCHER: Finished worker discovery
07:39:32 WORKER: done with job (9, 0, 7), trying to register it.
07:39:32 WORKER: registered result for job (9, 0, 7) with dispatcher
07:39:32 DISPATCHER: job (9, 0, 7) finished
07:39:32 DISPATCHER: register_result: lock acquired
07:39:32 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
07:39:32 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0033662646431612906, 'num_filters_1': 37, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.04202280291285742, 'kernel_size_2': 3, 'num_filters_2': 88}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.42016603278355147, 'info': {'data03': 0.42016603278355147, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0033662646431612906, 'num_filters_1': 37, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.04202280291285742, 'kernel_size_2': 3, 'num_filters_2': 88}"}}
exception: None

07:39:32 job_callback for (9, 0, 7) started
07:39:32 job_callback for (9, 0, 7) got condition
07:39:32 DISPATCHER: Trying to submit another job.
07:39:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:39:32 done building a new model for budget 133.333333 based on 17/45 split
Best loss for this budget:-0.436222





07:39:32 HBMASTER: Trying to run another job!
07:39:32 job_callback for (9, 0, 7) finished
07:39:32 start sampling a new configuration.
07:39:32 best_vector: [2, 2, 0.47888001176947226, 0.12811677068857952, 0.2096888661045614, 1, 0.22421388352496407, 0.3305454043943814, 1, 1, 0, 0, 0.946406853390091, 0.6086741333686627, 0.8777511193918569, 0.09094000058069329], 2.2686127022084383e-29, 0.0004407980256068058, -9.308019133384602e-06
07:39:32 done sampling a new configuration.
07:39:32 HBMASTER: schedule new run for iteration 9
07:39:32 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
07:39:32 HBMASTER: submitting job (9, 0, 8) to dispatcher
07:39:32 DISPATCHER: trying to submit job (9, 0, 8)
07:39:32 DISPATCHER: trying to notify the job_runner thread.
07:39:32 HBMASTER: job (9, 0, 8) submitted to dispatcher
07:39:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:39:32 DISPATCHER: Trying to submit another job.
07:39:32 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776
07:39:32 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
07:39:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:39:32 WORKER: start processing job (9, 0, 8)
07:39:32 WORKER: args: ()
07:39:32 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.009073190377843047, 'num_filters_1': 20, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.026918415105725114, 'kernel_size_2': 5, 'num_filters_2': 115}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:40:11 DISPATCHER: Starting worker discovery
07:40:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:40:11 DISPATCHER: Finished worker discovery
07:41:11 DISPATCHER: Starting worker discovery
07:41:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:41:11 DISPATCHER: Finished worker discovery
07:42:11 DISPATCHER: Starting worker discovery
07:42:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:42:11 DISPATCHER: Finished worker discovery
07:42:26 WORKER: done with job (9, 0, 8), trying to register it.
07:42:26 WORKER: registered result for job (9, 0, 8) with dispatcher
07:42:26 DISPATCHER: job (9, 0, 8) finished
07:42:26 DISPATCHER: register_result: lock acquired
07:42:26 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
07:42:26 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.009073190377843047, 'num_filters_1': 20, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.026918415105725114, 'kernel_size_2': 5, 'num_filters_2': 115}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4286335115129566, 'info': {'data03': 0.4286335115129566, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.009073190377843047, 'num_filters_1': 20, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.026918415105725114, 'kernel_size_2': 5, 'num_filters_2': 115}"}}
exception: None

07:42:26 job_callback for (9, 0, 8) started
07:42:26 DISPATCHER: Trying to submit another job.
07:42:26 job_callback for (9, 0, 8) got condition
07:42:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:42:26 done building a new model for budget 133.333333 based on 17/45 split
Best loss for this budget:-0.436222





07:42:26 HBMASTER: Trying to run another job!
07:42:26 job_callback for (9, 0, 8) finished
07:42:26 ITERATION: Advancing config (9, 0, 4) to next budget 400.000000
07:42:26 ITERATION: Advancing config (9, 0, 7) to next budget 400.000000
07:42:26 ITERATION: Advancing config (9, 0, 8) to next budget 400.000000
07:42:26 HBMASTER: schedule new run for iteration 9
07:42:26 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
07:42:26 HBMASTER: submitting job (9, 0, 4) to dispatcher
07:42:26 DISPATCHER: trying to submit job (9, 0, 4)
07:42:26 DISPATCHER: trying to notify the job_runner thread.
07:42:26 HBMASTER: job (9, 0, 4) submitted to dispatcher
07:42:26 DISPATCHER: Trying to submit another job.
07:42:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:42:26 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776
07:42:26 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
07:42:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:42:26 WORKER: start processing job (9, 0, 4)
07:42:26 WORKER: args: ()
07:42:26 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001325261723979202, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.03649237825931296, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 27, 'num_filters_3': 66}, 'budget': 400.0, 'working_directory': '.'}
07:43:11 DISPATCHER: Starting worker discovery
07:43:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:43:11 DISPATCHER: Finished worker discovery
07:44:11 DISPATCHER: Starting worker discovery
07:44:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:44:11 DISPATCHER: Finished worker discovery
07:45:11 DISPATCHER: Starting worker discovery
07:45:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:45:11 DISPATCHER: Finished worker discovery
07:46:11 DISPATCHER: Starting worker discovery
07:46:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:46:11 DISPATCHER: Finished worker discovery
07:47:11 DISPATCHER: Starting worker discovery
07:47:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:47:11 DISPATCHER: Finished worker discovery
07:48:11 DISPATCHER: Starting worker discovery
07:48:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:48:11 DISPATCHER: Finished worker discovery
07:49:11 DISPATCHER: Starting worker discovery
07:49:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:49:11 DISPATCHER: Finished worker discovery
07:49:49 WORKER: done with job (9, 0, 4), trying to register it.
07:49:49 WORKER: registered result for job (9, 0, 4) with dispatcher
07:49:49 DISPATCHER: job (9, 0, 4) finished
07:49:49 DISPATCHER: register_result: lock acquired
07:49:49 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
07:49:49 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001325261723979202, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.03649237825931296, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 27, 'num_filters_3': 66}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3133093606133376, 'info': {'data03': 0.3133093606133376, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.001325261723979202, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.03649237825931296, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 27, 'num_filters_3': 66}"}}
exception: None

07:49:49 job_callback for (9, 0, 4) started
07:49:49 job_callback for (9, 0, 4) got condition
07:49:49 DISPATCHER: Trying to submit another job.
07:49:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:49:49 HBMASTER: Trying to run another job!
07:49:49 job_callback for (9, 0, 4) finished
07:49:49 HBMASTER: schedule new run for iteration 9
07:49:49 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
07:49:49 HBMASTER: submitting job (9, 0, 7) to dispatcher
07:49:49 DISPATCHER: trying to submit job (9, 0, 7)
07:49:49 DISPATCHER: trying to notify the job_runner thread.
07:49:49 HBMASTER: job (9, 0, 7) submitted to dispatcher
07:49:49 DISPATCHER: Trying to submit another job.
07:49:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:49:49 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776
07:49:49 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
07:49:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:49:49 WORKER: start processing job (9, 0, 7)
07:49:49 WORKER: args: ()
07:49:49 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0033662646431612906, 'num_filters_1': 37, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.04202280291285742, 'kernel_size_2': 3, 'num_filters_2': 88}, 'budget': 400.0, 'working_directory': '.'}
07:50:11 DISPATCHER: Starting worker discovery
07:50:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:50:11 DISPATCHER: Finished worker discovery
07:51:11 DISPATCHER: Starting worker discovery
07:51:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:51:11 DISPATCHER: Finished worker discovery
07:52:11 DISPATCHER: Starting worker discovery
07:52:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:52:11 DISPATCHER: Finished worker discovery
07:53:11 DISPATCHER: Starting worker discovery
07:53:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:53:11 DISPATCHER: Finished worker discovery
07:54:11 DISPATCHER: Starting worker discovery
07:54:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:54:11 DISPATCHER: Finished worker discovery
07:55:11 DISPATCHER: Starting worker discovery
07:55:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:55:12 DISPATCHER: Finished worker discovery
07:56:12 DISPATCHER: Starting worker discovery
07:56:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:56:12 DISPATCHER: Finished worker discovery
07:57:12 DISPATCHER: Starting worker discovery
07:57:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:57:12 DISPATCHER: Finished worker discovery
07:57:14 WORKER: done with job (9, 0, 7), trying to register it.
07:57:14 WORKER: registered result for job (9, 0, 7) with dispatcher
07:57:14 DISPATCHER: job (9, 0, 7) finished
07:57:14 DISPATCHER: register_result: lock acquired
07:57:14 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
07:57:14 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0033662646431612906, 'num_filters_1': 37, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.04202280291285742, 'kernel_size_2': 3, 'num_filters_2': 88}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3794003031086828, 'info': {'data03': 0.3794003031086828, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0033662646431612906, 'num_filters_1': 37, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.04202280291285742, 'kernel_size_2': 3, 'num_filters_2': 88}"}}
exception: None

07:57:14 job_callback for (9, 0, 7) started
07:57:14 DISPATCHER: Trying to submit another job.
07:57:14 job_callback for (9, 0, 7) got condition
07:57:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:57:14 HBMASTER: Trying to run another job!
07:57:14 job_callback for (9, 0, 7) finished
07:57:14 HBMASTER: schedule new run for iteration 9
07:57:14 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
07:57:14 HBMASTER: submitting job (9, 0, 8) to dispatcher
07:57:14 DISPATCHER: trying to submit job (9, 0, 8)
07:57:14 DISPATCHER: trying to notify the job_runner thread.
07:57:14 HBMASTER: job (9, 0, 8) submitted to dispatcher
07:57:14 DISPATCHER: Trying to submit another job.
07:57:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:57:14 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776
07:57:14 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
07:57:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:57:14 WORKER: start processing job (9, 0, 8)
07:57:14 WORKER: args: ()
07:57:14 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.009073190377843047, 'num_filters_1': 20, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.026918415105725114, 'kernel_size_2': 5, 'num_filters_2': 115}, 'budget': 400.0, 'working_directory': '.'}
07:58:12 DISPATCHER: Starting worker discovery
07:58:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:58:12 DISPATCHER: Finished worker discovery
07:59:12 DISPATCHER: Starting worker discovery
07:59:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:59:12 DISPATCHER: Finished worker discovery
08:00:12 DISPATCHER: Starting worker discovery
08:00:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:00:12 DISPATCHER: Finished worker discovery
08:01:12 DISPATCHER: Starting worker discovery
08:01:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:01:12 DISPATCHER: Finished worker discovery
08:02:12 DISPATCHER: Starting worker discovery
08:02:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:02:12 DISPATCHER: Finished worker discovery
08:03:12 DISPATCHER: Starting worker discovery
08:03:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:03:12 DISPATCHER: Finished worker discovery
08:04:12 DISPATCHER: Starting worker discovery
08:04:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:04:12 DISPATCHER: Finished worker discovery
08:04:31 WORKER: done with job (9, 0, 8), trying to register it.
08:04:31 WORKER: registered result for job (9, 0, 8) with dispatcher
08:04:31 DISPATCHER: job (9, 0, 8) finished
08:04:31 DISPATCHER: register_result: lock acquired
08:04:31 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
08:04:31 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.009073190377843047, 'num_filters_1': 20, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.026918415105725114, 'kernel_size_2': 5, 'num_filters_2': 115}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3205087013790896, 'info': {'data03': 0.3205087013790896, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.009073190377843047, 'num_filters_1': 20, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.026918415105725114, 'kernel_size_2': 5, 'num_filters_2': 115}"}}
exception: None

08:04:31 job_callback for (9, 0, 8) started
08:04:31 job_callback for (9, 0, 8) got condition
08:04:31 DISPATCHER: Trying to submit another job.
08:04:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:04:31 HBMASTER: Trying to run another job!
08:04:31 job_callback for (9, 0, 8) finished
08:04:31 ITERATION: Advancing config (9, 0, 7) to next budget 1200.000000
08:04:31 HBMASTER: schedule new run for iteration 9
08:04:31 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
08:04:31 HBMASTER: submitting job (9, 0, 7) to dispatcher
08:04:31 DISPATCHER: trying to submit job (9, 0, 7)
08:04:31 DISPATCHER: trying to notify the job_runner thread.
08:04:31 HBMASTER: job (9, 0, 7) submitted to dispatcher
08:04:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:04:31 DISPATCHER: Trying to submit another job.
08:04:31 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776
08:04:31 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpui.1576139975513683776
08:04:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:04:31 WORKER: start processing job (9, 0, 7)
08:04:31 WORKER: args: ()
08:04:31 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0033662646431612906, 'num_filters_1': 37, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.04202280291285742, 'kernel_size_2': 3, 'num_filters_2': 88}, 'budget': 1200.0, 'working_directory': '.'}
08:05:12 DISPATCHER: Starting worker discovery
08:05:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:05:12 DISPATCHER: Finished worker discovery
08:06:12 DISPATCHER: Starting worker discovery
08:06:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:06:12 DISPATCHER: Finished worker discovery
08:07:12 DISPATCHER: Starting worker discovery
08:07:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:07:12 DISPATCHER: Finished worker discovery
08:08:12 DISPATCHER: Starting worker discovery
08:08:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:08:12 DISPATCHER: Finished worker discovery
08:09:12 DISPATCHER: Starting worker discovery
08:09:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:09:12 DISPATCHER: Finished worker discovery
08:10:12 DISPATCHER: Starting worker discovery
08:10:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:10:12 DISPATCHER: Finished worker discovery
08:11:12 DISPATCHER: Starting worker discovery
08:11:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:11:12 DISPATCHER: Finished worker discovery
08:12:12 DISPATCHER: Starting worker discovery
08:12:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:12:12 DISPATCHER: Finished worker discovery
08:13:12 DISPATCHER: Starting worker discovery
08:13:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:13:12 DISPATCHER: Finished worker discovery
08:14:12 DISPATCHER: Starting worker discovery
08:14:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:14:12 DISPATCHER: Finished worker discovery
08:15:12 DISPATCHER: Starting worker discovery
08:15:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:15:12 DISPATCHER: Finished worker discovery
08:16:12 DISPATCHER: Starting worker discovery
08:16:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:16:12 DISPATCHER: Finished worker discovery
08:17:12 DISPATCHER: Starting worker discovery
08:17:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:17:12 DISPATCHER: Finished worker discovery
08:18:12 DISPATCHER: Starting worker discovery
08:18:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:18:12 DISPATCHER: Finished worker discovery
08:19:12 DISPATCHER: Starting worker discovery
08:19:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:19:12 DISPATCHER: Finished worker discovery
08:20:12 DISPATCHER: Starting worker discovery
08:20:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:20:12 DISPATCHER: Finished worker discovery
08:21:12 DISPATCHER: Starting worker discovery
08:21:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:21:12 DISPATCHER: Finished worker discovery
08:22:12 DISPATCHER: Starting worker discovery
08:22:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:22:12 DISPATCHER: Finished worker discovery
08:23:12 DISPATCHER: Starting worker discovery
08:23:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:23:12 DISPATCHER: Finished worker discovery
08:24:12 DISPATCHER: Starting worker discovery
08:24:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:24:12 DISPATCHER: Finished worker discovery
08:25:12 DISPATCHER: Starting worker discovery
08:25:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:25:12 DISPATCHER: Finished worker discovery
08:25:18 WORKER: done with job (9, 0, 7), trying to register it.
08:25:18 WORKER: registered result for job (9, 0, 7) with dispatcher
08:25:18 DISPATCHER: job (9, 0, 7) finished
08:25:18 DISPATCHER: register_result: lock acquired
08:25:18 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpui.1576139975513683776 finished
08:25:18 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0033662646431612906, 'num_filters_1': 37, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.04202280291285742, 'kernel_size_2': 3, 'num_filters_2': 88}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.3058888385992995, 'info': {'data03': 0.3058888385992995, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0033662646431612906, 'num_filters_1': 37, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.04202280291285742, 'kernel_size_2': 3, 'num_filters_2': 88}"}}
exception: None

08:25:18 job_callback for (9, 0, 7) started
08:25:18 DISPATCHER: Trying to submit another job.
08:25:18 job_callback for (9, 0, 7) got condition
08:25:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:25:18 HBMASTER: Trying to run another job!
08:25:18 job_callback for (9, 0, 7) finished
08:25:18 HBMASTER: shutdown initiated, shutdown_workers = True
08:25:18 WORKER: shutting down now!
08:25:19 DISPATCHER: Dispatcher shutting down
08:25:19 DISPATCHER: discover_workers shutting down
08:25:19 DISPATCHER: Trying to submit another job.
08:25:19 DISPATCHER: 'discover_worker' thread exited
08:25:19 DISPATCHER: job_runner shutting down
08:25:19 DISPATCHER: 'job_runner' thread exited
08:25:19 DISPATCHER: shut down complete
