/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
WARNING:tensorflow:From /home/ahnj/repo/autodl/AutoDL/model.py:27: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /home/ahnj/repo/autodl/AutoDL/model.py:31: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-03-09 18:39:35.239097: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-03-09 18:39:35.243504: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300120000 Hz
2020-03-09 18:39:35.243819: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56316156f4b0 executing computations on platform Host. Devices:
2020-03-09 18:39:35.243843: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-03-09 18:39:35.244459: I tensorflow/core/common_runtime/direct_session.cc:296] Device mapping:
/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device

18:39:35 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7f1400f2b630; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:33502>
18:39:35 WORKER: No dispatcher found. Waiting for one to initiate contact.
18:39:35 WORKER: start listening for jobs
18:39:35 wait_for_workers trying to get the condition
18:39:35 DISPATCHER: started the 'discover_worker' thread
18:39:35 DISPATCHER: started the 'job_runner' thread
18:39:35 DISPATCHER: Pyro daemon running on localhost:42269
18:39:35 DISPATCHER: Starting worker discovery
18:39:35 DISPATCHER: Found 1 potential workers, 0 currently in the pool.
18:39:35 DISPATCHER: discovered new worker, hpbandster.run_0.worker.metagpul.22021139727314577216
18:39:35 HBMASTER: number of workers changed to 1
18:39:35 Enough workers to start this run!
18:39:35 adjust_queue_size: lock accquired
18:39:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:39:35 HBMASTER: starting run at 1583775575.3486524
18:39:35 HBMASTER: adjusted queue size to (0, 1)
18:39:35 DISPATCHER: Finished worker discovery
18:39:35 start sampling a new configuration.
18:39:35 DISPATCHER: Trying to submit another job.
18:39:35 done sampling a new configuration.
18:39:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:39:35 HBMASTER: schedule new run for iteration 0
18:39:35 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
18:39:35 HBMASTER: submitting job (0, 0, 0) to dispatcher
18:39:35 DISPATCHER: trying to submit job (0, 0, 0)
18:39:35 DISPATCHER: trying to notify the job_runner thread.
18:39:35 HBMASTER: job (0, 0, 0) submitted to dispatcher
18:39:35 DISPATCHER: Trying to submit another job.
18:39:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:39:35 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:39:35 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:39:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:39:35 WORKER: start processing job (0, 0, 0)
18:39:35 WORKER: args: ()
18:39:35 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 759, 'last_n_outputs': 33, 'leak_rate': 0.7590672983245007, 'lr': 0.06718435256563829, 'optimizer': 'Adam', 'sparsity': 0.8743458897605779, 'steps_to_train': 61, 'weight_decay': 0.02858172757654736}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:40:35 DISPATCHER: Starting worker discovery
18:40:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:40:35 DISPATCHER: Finished worker discovery
18:40:41 WORKER: done with job (0, 0, 0), trying to register it.
18:40:41 WORKER: registered result for job (0, 0, 0) with dispatcher
18:40:41 DISPATCHER: job (0, 0, 0) finished
18:40:41 DISPATCHER: register_result: lock acquired
18:40:41 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:40:41 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 759, 'last_n_outputs': 33, 'leak_rate': 0.7590672983245007, 'lr': 0.06718435256563829, 'optimizer': 'Adam', 'sparsity': 0.8743458897605779, 'steps_to_train': 61, 'weight_decay': 0.02858172757654736}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5455625680628217, 'info': {'music-speech': 0.5455625680628217, 'config': "{'batch_size': 128, 'hidden_dim': 759, 'last_n_outputs': 33, 'leak_rate': 0.7590672983245007, 'lr': 0.06718435256563829, 'optimizer': 'Adam', 'sparsity': 0.8743458897605779, 'steps_to_train': 61, 'weight_decay': 0.02858172757654736}"}}
exception: None

18:40:41 job_callback for (0, 0, 0) started
18:40:41 DISPATCHER: Trying to submit another job.
18:40:41 job_callback for (0, 0, 0) got condition
18:40:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:40:41 Only 1 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
18:40:41 HBMASTER: Trying to run another job!
18:40:41 job_callback for (0, 0, 0) finished
18:40:41 start sampling a new configuration.
18:40:41 done sampling a new configuration.
18:40:41 HBMASTER: schedule new run for iteration 0
18:40:41 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
18:40:41 HBMASTER: submitting job (0, 0, 1) to dispatcher
18:40:41 DISPATCHER: trying to submit job (0, 0, 1)
18:40:41 DISPATCHER: trying to notify the job_runner thread.
18:40:41 HBMASTER: job (0, 0, 1) submitted to dispatcher
18:40:41 DISPATCHER: Trying to submit another job.
18:40:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:40:41 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:40:41 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:40:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:40:41 WORKER: start processing job (0, 0, 1)
18:40:41 WORKER: args: ()
18:40:41 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 534, 'last_n_outputs': 38, 'leak_rate': 0.7826415910874612, 'lr': 0.012550675274649956, 'optimizer': 'SGD', 'sparsity': 0.9185491080546172, 'steps_to_train': 93, 'weight_decay': 0.02123335130485016}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:41:35 DISPATCHER: Starting worker discovery
18:41:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:41:35 DISPATCHER: Finished worker discovery
18:41:51 WORKER: done with job (0, 0, 1), trying to register it.
18:41:51 WORKER: registered result for job (0, 0, 1) with dispatcher
18:41:51 DISPATCHER: job (0, 0, 1) finished
18:41:51 DISPATCHER: register_result: lock acquired
18:41:51 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:41:51 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 534, 'last_n_outputs': 38, 'leak_rate': 0.7826415910874612, 'lr': 0.012550675274649956, 'optimizer': 'SGD', 'sparsity': 0.9185491080546172, 'steps_to_train': 93, 'weight_decay': 0.02123335130485016}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.40459933231110085, 'info': {'music-speech': 0.40459933231110085, 'config': "{'batch_size': 16, 'hidden_dim': 534, 'last_n_outputs': 38, 'leak_rate': 0.7826415910874612, 'lr': 0.012550675274649956, 'optimizer': 'SGD', 'sparsity': 0.9185491080546172, 'steps_to_train': 93, 'weight_decay': 0.02123335130485016}"}}
exception: None

18:41:51 job_callback for (0, 0, 1) started
18:41:51 job_callback for (0, 0, 1) got condition
18:41:51 DISPATCHER: Trying to submit another job.
18:41:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:41:51 Only 2 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
18:41:51 HBMASTER: Trying to run another job!
18:41:51 job_callback for (0, 0, 1) finished
18:41:51 start sampling a new configuration.
18:41:51 done sampling a new configuration.
18:41:51 HBMASTER: schedule new run for iteration 0
18:41:51 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
18:41:51 HBMASTER: submitting job (0, 0, 2) to dispatcher
18:41:51 DISPATCHER: trying to submit job (0, 0, 2)
18:41:51 DISPATCHER: trying to notify the job_runner thread.
18:41:51 HBMASTER: job (0, 0, 2) submitted to dispatcher
18:41:51 DISPATCHER: Trying to submit another job.
18:41:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:41:51 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:41:51 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:41:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:41:51 WORKER: start processing job (0, 0, 2)
18:41:51 WORKER: args: ()
18:41:51 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 682, 'last_n_outputs': 24, 'leak_rate': 0.8547940739508247, 'lr': 0.0019662737620393346, 'optimizer': 'SGD', 'sparsity': 0.8655422976535881, 'steps_to_train': 49, 'weight_decay': 0.06442544195191753}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:42:35 DISPATCHER: Starting worker discovery
18:42:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:42:35 DISPATCHER: Finished worker discovery
18:42:52 WORKER: done with job (0, 0, 2), trying to register it.
18:42:52 DISPATCHER: job (0, 0, 2) finished
18:42:52 WORKER: registered result for job (0, 0, 2) with dispatcher
18:42:52 DISPATCHER: register_result: lock acquired
18:42:52 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:42:52 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 682, 'last_n_outputs': 24, 'leak_rate': 0.8547940739508247, 'lr': 0.0019662737620393346, 'optimizer': 'SGD', 'sparsity': 0.8655422976535881, 'steps_to_train': 49, 'weight_decay': 0.06442544195191753}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6102212868019843, 'info': {'music-speech': 0.6102212868019843, 'config': "{'batch_size': 16, 'hidden_dim': 682, 'last_n_outputs': 24, 'leak_rate': 0.8547940739508247, 'lr': 0.0019662737620393346, 'optimizer': 'SGD', 'sparsity': 0.8655422976535881, 'steps_to_train': 49, 'weight_decay': 0.06442544195191753}"}}
exception: None

18:42:52 job_callback for (0, 0, 2) started
18:42:52 job_callback for (0, 0, 2) got condition
18:42:52 DISPATCHER: Trying to submit another job.
18:42:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:42:52 Only 3 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
18:42:52 HBMASTER: Trying to run another job!
18:42:52 job_callback for (0, 0, 2) finished
18:42:52 start sampling a new configuration.
18:42:52 done sampling a new configuration.
18:42:52 HBMASTER: schedule new run for iteration 0
18:42:52 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
18:42:52 HBMASTER: submitting job (0, 0, 3) to dispatcher
18:42:52 DISPATCHER: trying to submit job (0, 0, 3)
18:42:52 DISPATCHER: trying to notify the job_runner thread.
18:42:52 HBMASTER: job (0, 0, 3) submitted to dispatcher
18:42:52 DISPATCHER: Trying to submit another job.
18:42:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:42:52 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:42:52 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:42:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:42:52 WORKER: start processing job (0, 0, 3)
18:42:52 WORKER: args: ()
18:42:52 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 948, 'last_n_outputs': 29, 'leak_rate': 0.7588188081999508, 'lr': 0.0013742623478159215, 'optimizer': 'Adam', 'sparsity': 0.9542197536035023, 'steps_to_train': 31, 'weight_decay': 0.16616323438655572}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:43:35 DISPATCHER: Starting worker discovery
18:43:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:43:35 DISPATCHER: Finished worker discovery
18:43:53 WORKER: done with job (0, 0, 3), trying to register it.
18:43:53 WORKER: registered result for job (0, 0, 3) with dispatcher
18:43:53 DISPATCHER: job (0, 0, 3) finished
18:43:53 DISPATCHER: register_result: lock acquired
18:43:53 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:43:53 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 948, 'last_n_outputs': 29, 'leak_rate': 0.7588188081999508, 'lr': 0.0013742623478159215, 'optimizer': 'Adam', 'sparsity': 0.9542197536035023, 'steps_to_train': 31, 'weight_decay': 0.16616323438655572}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5828084852994175, 'info': {'music-speech': 0.5828084852994175, 'config': "{'batch_size': 32, 'hidden_dim': 948, 'last_n_outputs': 29, 'leak_rate': 0.7588188081999508, 'lr': 0.0013742623478159215, 'optimizer': 'Adam', 'sparsity': 0.9542197536035023, 'steps_to_train': 31, 'weight_decay': 0.16616323438655572}"}}
exception: None

18:43:53 job_callback for (0, 0, 3) started
18:43:53 DISPATCHER: Trying to submit another job.
18:43:53 job_callback for (0, 0, 3) got condition
18:43:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:43:53 Only 4 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
18:43:53 HBMASTER: Trying to run another job!
18:43:53 job_callback for (0, 0, 3) finished
18:43:53 start sampling a new configuration.
18:43:53 done sampling a new configuration.
18:43:53 HBMASTER: schedule new run for iteration 0
18:43:53 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
18:43:53 HBMASTER: submitting job (0, 0, 4) to dispatcher
18:43:53 DISPATCHER: trying to submit job (0, 0, 4)
18:43:53 DISPATCHER: trying to notify the job_runner thread.
18:43:53 HBMASTER: job (0, 0, 4) submitted to dispatcher
18:43:53 DISPATCHER: Trying to submit another job.
18:43:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:43:53 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:43:53 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:43:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:43:53 WORKER: start processing job (0, 0, 4)
18:43:53 WORKER: args: ()
18:43:53 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 280, 'last_n_outputs': 23, 'leak_rate': 0.9704807110565556, 'lr': 0.056855819352071235, 'optimizer': 'SGD', 'sparsity': 0.8006770217286137, 'steps_to_train': 50, 'weight_decay': 0.16068250529781855}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:44:35 DISPATCHER: Starting worker discovery
18:44:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:44:35 DISPATCHER: Finished worker discovery
18:44:58 WORKER: done with job (0, 0, 4), trying to register it.
18:44:58 DISPATCHER: job (0, 0, 4) finished
18:44:58 WORKER: registered result for job (0, 0, 4) with dispatcher
18:44:58 DISPATCHER: register_result: lock acquired
18:44:58 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:44:58 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 280, 'last_n_outputs': 23, 'leak_rate': 0.9704807110565556, 'lr': 0.056855819352071235, 'optimizer': 'SGD', 'sparsity': 0.8006770217286137, 'steps_to_train': 50, 'weight_decay': 0.16068250529781855}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4503674124183372, 'info': {'music-speech': 0.4503674124183372, 'config': "{'batch_size': 32, 'hidden_dim': 280, 'last_n_outputs': 23, 'leak_rate': 0.9704807110565556, 'lr': 0.056855819352071235, 'optimizer': 'SGD', 'sparsity': 0.8006770217286137, 'steps_to_train': 50, 'weight_decay': 0.16068250529781855}"}}
exception: None

18:44:58 job_callback for (0, 0, 4) started
18:44:58 job_callback for (0, 0, 4) got condition
18:44:58 DISPATCHER: Trying to submit another job.
18:44:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:44:58 Only 5 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
18:44:58 HBMASTER: Trying to run another job!
18:44:58 job_callback for (0, 0, 4) finished
18:44:58 start sampling a new configuration.
18:44:58 done sampling a new configuration.
18:44:58 HBMASTER: schedule new run for iteration 0
18:44:58 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
18:44:58 HBMASTER: submitting job (0, 0, 5) to dispatcher
18:44:58 DISPATCHER: trying to submit job (0, 0, 5)
18:44:58 DISPATCHER: trying to notify the job_runner thread.
18:44:58 HBMASTER: job (0, 0, 5) submitted to dispatcher
18:44:58 DISPATCHER: Trying to submit another job.
18:44:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:44:58 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:44:58 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:44:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:44:58 WORKER: start processing job (0, 0, 5)
18:44:58 WORKER: args: ()
18:44:58 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 463, 'last_n_outputs': 26, 'leak_rate': 0.7648011194820221, 'lr': 0.08687133589538402, 'optimizer': 'Adam', 'sparsity': 0.9577419085849884, 'steps_to_train': 35, 'weight_decay': 0.0360585900169472}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:45:35 DISPATCHER: Starting worker discovery
18:45:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:45:35 DISPATCHER: Finished worker discovery
18:45:52 WORKER: done with job (0, 0, 5), trying to register it.
18:45:52 WORKER: registered result for job (0, 0, 5) with dispatcher
18:45:52 DISPATCHER: job (0, 0, 5) finished
18:45:52 DISPATCHER: register_result: lock acquired
18:45:52 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:45:52 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 463, 'last_n_outputs': 26, 'leak_rate': 0.7648011194820221, 'lr': 0.08687133589538402, 'optimizer': 'Adam', 'sparsity': 0.9577419085849884, 'steps_to_train': 35, 'weight_decay': 0.0360585900169472}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5003284287359129, 'info': {'music-speech': 0.5003284287359129, 'config': "{'batch_size': 32, 'hidden_dim': 463, 'last_n_outputs': 26, 'leak_rate': 0.7648011194820221, 'lr': 0.08687133589538402, 'optimizer': 'Adam', 'sparsity': 0.9577419085849884, 'steps_to_train': 35, 'weight_decay': 0.0360585900169472}"}}
exception: None

18:45:52 job_callback for (0, 0, 5) started
18:45:52 DISPATCHER: Trying to submit another job.
18:45:52 job_callback for (0, 0, 5) got condition
18:45:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:45:52 Only 6 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
18:45:52 HBMASTER: Trying to run another job!
18:45:52 job_callback for (0, 0, 5) finished
18:45:52 start sampling a new configuration.
18:45:52 done sampling a new configuration.
18:45:52 HBMASTER: schedule new run for iteration 0
18:45:52 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
18:45:52 HBMASTER: submitting job (0, 0, 6) to dispatcher
18:45:52 DISPATCHER: trying to submit job (0, 0, 6)
18:45:52 DISPATCHER: trying to notify the job_runner thread.
18:45:52 HBMASTER: job (0, 0, 6) submitted to dispatcher
18:45:52 DISPATCHER: Trying to submit another job.
18:45:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:45:52 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:45:52 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:45:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:45:52 WORKER: start processing job (0, 0, 6)
18:45:52 WORKER: args: ()
18:45:52 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 366, 'last_n_outputs': 17, 'leak_rate': 0.8972161351935315, 'lr': 0.06206636791775242, 'optimizer': 'SGD', 'sparsity': 0.9799661572316949, 'steps_to_train': 93, 'weight_decay': 0.1288135126446217}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:46:35 DISPATCHER: Starting worker discovery
18:46:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:46:35 DISPATCHER: Finished worker discovery
18:46:54 WORKER: done with job (0, 0, 6), trying to register it.
18:46:54 DISPATCHER: job (0, 0, 6) finished
18:46:54 WORKER: registered result for job (0, 0, 6) with dispatcher
18:46:54 DISPATCHER: register_result: lock acquired
18:46:54 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:46:54 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 366, 'last_n_outputs': 17, 'leak_rate': 0.8972161351935315, 'lr': 0.06206636791775242, 'optimizer': 'SGD', 'sparsity': 0.9799661572316949, 'steps_to_train': 93, 'weight_decay': 0.1288135126446217}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.045307652240960776, 'info': {'music-speech': 0.045307652240960776, 'config': "{'batch_size': 64, 'hidden_dim': 366, 'last_n_outputs': 17, 'leak_rate': 0.8972161351935315, 'lr': 0.06206636791775242, 'optimizer': 'SGD', 'sparsity': 0.9799661572316949, 'steps_to_train': 93, 'weight_decay': 0.1288135126446217}"}}
exception: None

18:46:54 job_callback for (0, 0, 6) started
18:46:54 DISPATCHER: Trying to submit another job.
18:46:54 job_callback for (0, 0, 6) got condition
18:46:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:46:54 Only 7 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
18:46:54 HBMASTER: Trying to run another job!
18:46:54 job_callback for (0, 0, 6) finished
18:46:54 start sampling a new configuration.
18:46:54 done sampling a new configuration.
18:46:54 HBMASTER: schedule new run for iteration 0
18:46:54 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
18:46:54 HBMASTER: submitting job (0, 0, 7) to dispatcher
18:46:54 DISPATCHER: trying to submit job (0, 0, 7)
18:46:54 DISPATCHER: trying to notify the job_runner thread.
18:46:54 HBMASTER: job (0, 0, 7) submitted to dispatcher
18:46:54 DISPATCHER: Trying to submit another job.
18:46:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:46:54 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:46:54 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:46:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:46:54 WORKER: start processing job (0, 0, 7)
18:46:54 WORKER: args: ()
18:46:54 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 429, 'last_n_outputs': 31, 'leak_rate': 0.9953355099864967, 'lr': 0.07205922774232673, 'optimizer': 'SGD', 'sparsity': 0.8425403239881654, 'steps_to_train': 68, 'weight_decay': 0.0211237246220775}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:47:35 DISPATCHER: Starting worker discovery
18:47:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:47:35 DISPATCHER: Finished worker discovery
18:48:07 WORKER: done with job (0, 0, 7), trying to register it.
18:48:07 WORKER: registered result for job (0, 0, 7) with dispatcher
18:48:07 DISPATCHER: job (0, 0, 7) finished
18:48:07 DISPATCHER: register_result: lock acquired
18:48:07 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:48:07 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 429, 'last_n_outputs': 31, 'leak_rate': 0.9953355099864967, 'lr': 0.07205922774232673, 'optimizer': 'SGD', 'sparsity': 0.8425403239881654, 'steps_to_train': 68, 'weight_decay': 0.0211237246220775}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4991229900173765, 'info': {'music-speech': 0.4991229900173765, 'config': "{'batch_size': 64, 'hidden_dim': 429, 'last_n_outputs': 31, 'leak_rate': 0.9953355099864967, 'lr': 0.07205922774232673, 'optimizer': 'SGD', 'sparsity': 0.8425403239881654, 'steps_to_train': 68, 'weight_decay': 0.0211237246220775}"}}
exception: None

18:48:07 job_callback for (0, 0, 7) started
18:48:07 DISPATCHER: Trying to submit another job.
18:48:07 job_callback for (0, 0, 7) got condition
18:48:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:48:07 Only 8 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
18:48:07 HBMASTER: Trying to run another job!
18:48:07 job_callback for (0, 0, 7) finished
18:48:07 start sampling a new configuration.
18:48:07 done sampling a new configuration.
18:48:07 HBMASTER: schedule new run for iteration 0
18:48:07 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
18:48:07 HBMASTER: submitting job (0, 0, 8) to dispatcher
18:48:07 DISPATCHER: trying to submit job (0, 0, 8)
18:48:07 DISPATCHER: trying to notify the job_runner thread.
18:48:07 HBMASTER: job (0, 0, 8) submitted to dispatcher
18:48:07 DISPATCHER: Trying to submit another job.
18:48:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:48:07 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:48:07 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:48:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:48:07 WORKER: start processing job (0, 0, 8)
18:48:07 WORKER: args: ()
18:48:07 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 782, 'last_n_outputs': 23, 'leak_rate': 0.7729694224201737, 'lr': 0.005385465847778193, 'optimizer': 'Adam', 'sparsity': 0.7820449901168178, 'steps_to_train': 32, 'weight_decay': 0.01798322586300438}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:48:35 DISPATCHER: Starting worker discovery
18:48:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:48:35 DISPATCHER: Finished worker discovery
18:49:04 WORKER: done with job (0, 0, 8), trying to register it.
18:49:04 WORKER: registered result for job (0, 0, 8) with dispatcher
18:49:04 DISPATCHER: job (0, 0, 8) finished
18:49:04 DISPATCHER: register_result: lock acquired
18:49:04 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:49:04 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 782, 'last_n_outputs': 23, 'leak_rate': 0.7729694224201737, 'lr': 0.005385465847778193, 'optimizer': 'Adam', 'sparsity': 0.7820449901168178, 'steps_to_train': 32, 'weight_decay': 0.01798322586300438}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5134256338825507, 'info': {'music-speech': 0.5134256338825507, 'config': "{'batch_size': 32, 'hidden_dim': 782, 'last_n_outputs': 23, 'leak_rate': 0.7729694224201737, 'lr': 0.005385465847778193, 'optimizer': 'Adam', 'sparsity': 0.7820449901168178, 'steps_to_train': 32, 'weight_decay': 0.01798322586300438}"}}
exception: None

18:49:04 job_callback for (0, 0, 8) started
18:49:04 DISPATCHER: Trying to submit another job.
18:49:04 job_callback for (0, 0, 8) got condition
18:49:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:49:04 Only 9 run(s) for budget 44.444444 available, need more than 11 -> can't build model!
18:49:04 HBMASTER: Trying to run another job!
18:49:04 job_callback for (0, 0, 8) finished
18:49:04 start sampling a new configuration.
18:49:04 done sampling a new configuration.
18:49:04 HBMASTER: schedule new run for iteration 0
18:49:04 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
18:49:04 HBMASTER: submitting job (0, 0, 9) to dispatcher
18:49:04 DISPATCHER: trying to submit job (0, 0, 9)
18:49:04 DISPATCHER: trying to notify the job_runner thread.
18:49:04 HBMASTER: job (0, 0, 9) submitted to dispatcher
18:49:04 DISPATCHER: Trying to submit another job.
18:49:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:49:04 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:49:04 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:49:04 WORKER: start processing job (0, 0, 9)
18:49:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:49:04 WORKER: args: ()
18:49:04 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 860, 'last_n_outputs': 24, 'leak_rate': 0.9602044369761024, 'lr': 0.08912233851906133, 'optimizer': 'SGD', 'sparsity': 0.9003913122485484, 'steps_to_train': 28, 'weight_decay': 0.1446600511551618}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:49:35 DISPATCHER: Starting worker discovery
18:49:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:49:35 DISPATCHER: Finished worker discovery
18:50:20 WORKER: done with job (0, 0, 9), trying to register it.
18:50:21 DISPATCHER: job (0, 0, 9) finished
18:50:21 WORKER: registered result for job (0, 0, 9) with dispatcher
18:50:21 DISPATCHER: register_result: lock acquired
18:50:21 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:50:21 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 860, 'last_n_outputs': 24, 'leak_rate': 0.9602044369761024, 'lr': 0.08912233851906133, 'optimizer': 'SGD', 'sparsity': 0.9003913122485484, 'steps_to_train': 28, 'weight_decay': 0.1446600511551618}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3709203721985372, 'info': {'music-speech': 0.3709203721985372, 'config': "{'batch_size': 32, 'hidden_dim': 860, 'last_n_outputs': 24, 'leak_rate': 0.9602044369761024, 'lr': 0.08912233851906133, 'optimizer': 'SGD', 'sparsity': 0.9003913122485484, 'steps_to_train': 28, 'weight_decay': 0.1446600511551618}"}}
exception: None

18:50:21 job_callback for (0, 0, 9) started
18:50:21 job_callback for (0, 0, 9) got condition
18:50:21 DISPATCHER: Trying to submit another job.
18:50:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:50:21 HBMASTER: Trying to run another job!
18:50:21 job_callback for (0, 0, 9) finished
18:50:21 start sampling a new configuration.
18:50:21 done sampling a new configuration.
18:50:21 HBMASTER: schedule new run for iteration 0
18:50:21 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
18:50:21 HBMASTER: submitting job (0, 0, 10) to dispatcher
18:50:21 DISPATCHER: trying to submit job (0, 0, 10)
18:50:21 DISPATCHER: trying to notify the job_runner thread.
18:50:21 HBMASTER: job (0, 0, 10) submitted to dispatcher
18:50:21 DISPATCHER: Trying to submit another job.
18:50:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:50:21 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:50:21 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:50:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:50:21 WORKER: start processing job (0, 0, 10)
18:50:21 WORKER: args: ()
18:50:21 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 860, 'last_n_outputs': 47, 'leak_rate': 0.998747431901295, 'lr': 0.08707086742420518, 'optimizer': 'Adam', 'sparsity': 0.845726132316973, 'steps_to_train': 58, 'weight_decay': 0.022701124760730357}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:50:35 DISPATCHER: Starting worker discovery
18:50:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:50:35 DISPATCHER: Finished worker discovery
18:51:35 DISPATCHER: Starting worker discovery
18:51:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:51:35 DISPATCHER: Finished worker discovery
18:51:51 WORKER: done with job (0, 0, 10), trying to register it.
18:51:51 DISPATCHER: job (0, 0, 10) finished
18:51:51 WORKER: registered result for job (0, 0, 10) with dispatcher
18:51:51 DISPATCHER: register_result: lock acquired
18:51:51 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:51:51 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 860, 'last_n_outputs': 47, 'leak_rate': 0.998747431901295, 'lr': 0.08707086742420518, 'optimizer': 'Adam', 'sparsity': 0.845726132316973, 'steps_to_train': 58, 'weight_decay': 0.022701124760730357}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.18789585933148706, 'info': {'music-speech': 0.18789585933148706, 'config': "{'batch_size': 16, 'hidden_dim': 860, 'last_n_outputs': 47, 'leak_rate': 0.998747431901295, 'lr': 0.08707086742420518, 'optimizer': 'Adam', 'sparsity': 0.845726132316973, 'steps_to_train': 58, 'weight_decay': 0.022701124760730357}"}}
exception: None

18:51:51 job_callback for (0, 0, 10) started
18:51:51 DISPATCHER: Trying to submit another job.
18:51:51 job_callback for (0, 0, 10) got condition
18:51:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:51:51 HBMASTER: Trying to run another job!
18:51:51 job_callback for (0, 0, 10) finished
18:51:51 start sampling a new configuration.
18:51:51 done sampling a new configuration.
18:51:51 HBMASTER: schedule new run for iteration 0
18:51:51 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
18:51:51 HBMASTER: submitting job (0, 0, 11) to dispatcher
18:51:51 DISPATCHER: trying to submit job (0, 0, 11)
18:51:51 DISPATCHER: trying to notify the job_runner thread.
18:51:51 HBMASTER: job (0, 0, 11) submitted to dispatcher
18:51:51 DISPATCHER: Trying to submit another job.
18:51:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:51:51 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:51:51 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:51:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:51:51 WORKER: start processing job (0, 0, 11)
18:51:51 WORKER: args: ()
18:51:51 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 241, 'last_n_outputs': 50, 'leak_rate': 0.788497227597846, 'lr': 0.009889687880358738, 'optimizer': 'Adam', 'sparsity': 0.8640437882031746, 'steps_to_train': 99, 'weight_decay': 0.045852092993784545}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:52:35 DISPATCHER: Starting worker discovery
18:52:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:52:35 DISPATCHER: Finished worker discovery
18:52:55 WORKER: done with job (0, 0, 11), trying to register it.
18:52:55 DISPATCHER: job (0, 0, 11) finished
18:52:55 WORKER: registered result for job (0, 0, 11) with dispatcher
18:52:55 DISPATCHER: register_result: lock acquired
18:52:55 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:52:55 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 241, 'last_n_outputs': 50, 'leak_rate': 0.788497227597846, 'lr': 0.009889687880358738, 'optimizer': 'Adam', 'sparsity': 0.8640437882031746, 'steps_to_train': 99, 'weight_decay': 0.045852092993784545}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4689754347402733, 'info': {'music-speech': 0.4689754347402733, 'config': "{'batch_size': 32, 'hidden_dim': 241, 'last_n_outputs': 50, 'leak_rate': 0.788497227597846, 'lr': 0.009889687880358738, 'optimizer': 'Adam', 'sparsity': 0.8640437882031746, 'steps_to_train': 99, 'weight_decay': 0.045852092993784545}"}}
exception: None

18:52:55 job_callback for (0, 0, 11) started
18:52:55 DISPATCHER: Trying to submit another job.
18:52:55 job_callback for (0, 0, 11) got condition
18:52:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:52:55 HBMASTER: Trying to run another job!
18:52:55 job_callback for (0, 0, 11) finished
18:52:55 start sampling a new configuration.
18:52:55 done sampling a new configuration.
18:52:55 HBMASTER: schedule new run for iteration 0
18:52:55 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
18:52:55 HBMASTER: submitting job (0, 0, 12) to dispatcher
18:52:55 DISPATCHER: trying to submit job (0, 0, 12)
18:52:55 DISPATCHER: trying to notify the job_runner thread.
18:52:55 HBMASTER: job (0, 0, 12) submitted to dispatcher
18:52:55 DISPATCHER: Trying to submit another job.
18:52:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:52:55 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:52:55 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:52:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:52:55 WORKER: start processing job (0, 0, 12)
18:52:55 WORKER: args: ()
18:52:55 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 773, 'last_n_outputs': 16, 'leak_rate': 0.808479291314532, 'lr': 0.010133880529185122, 'optimizer': 'Adam', 'sparsity': 0.8393520319374131, 'steps_to_train': 56, 'weight_decay': 0.15049791328775372}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:53:35 DISPATCHER: Starting worker discovery
18:53:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:53:35 DISPATCHER: Finished worker discovery
18:53:50 WORKER: done with job (0, 0, 12), trying to register it.
18:53:50 WORKER: registered result for job (0, 0, 12) with dispatcher
18:53:50 DISPATCHER: job (0, 0, 12) finished
18:53:50 DISPATCHER: register_result: lock acquired
18:53:50 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:53:50 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 773, 'last_n_outputs': 16, 'leak_rate': 0.808479291314532, 'lr': 0.010133880529185122, 'optimizer': 'Adam', 'sparsity': 0.8393520319374131, 'steps_to_train': 56, 'weight_decay': 0.15049791328775372}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5165800422983664, 'info': {'music-speech': 0.5165800422983664, 'config': "{'batch_size': 16, 'hidden_dim': 773, 'last_n_outputs': 16, 'leak_rate': 0.808479291314532, 'lr': 0.010133880529185122, 'optimizer': 'Adam', 'sparsity': 0.8393520319374131, 'steps_to_train': 56, 'weight_decay': 0.15049791328775372}"}}
exception: None

18:53:50 job_callback for (0, 0, 12) started
18:53:50 job_callback for (0, 0, 12) got condition
18:53:50 DISPATCHER: Trying to submit another job.
18:53:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:53:50 HBMASTER: Trying to run another job!
18:53:50 job_callback for (0, 0, 12) finished
18:53:50 start sampling a new configuration.
18:53:50 done sampling a new configuration.
18:53:50 HBMASTER: schedule new run for iteration 0
18:53:50 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
18:53:50 HBMASTER: submitting job (0, 0, 13) to dispatcher
18:53:50 DISPATCHER: trying to submit job (0, 0, 13)
18:53:50 DISPATCHER: trying to notify the job_runner thread.
18:53:50 HBMASTER: job (0, 0, 13) submitted to dispatcher
18:53:50 DISPATCHER: Trying to submit another job.
18:53:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:53:50 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:53:50 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:53:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:53:50 WORKER: start processing job (0, 0, 13)
18:53:50 WORKER: args: ()
18:53:50 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 267, 'last_n_outputs': 34, 'leak_rate': 0.993546243262065, 'lr': 0.09001728484031703, 'optimizer': 'SGD', 'sparsity': 0.8671402544059263, 'steps_to_train': 31, 'weight_decay': 0.06820508564184176}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:54:35 DISPATCHER: Starting worker discovery
18:54:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:54:35 DISPATCHER: Finished worker discovery
18:54:49 WORKER: done with job (0, 0, 13), trying to register it.
18:54:49 DISPATCHER: job (0, 0, 13) finished
18:54:49 WORKER: registered result for job (0, 0, 13) with dispatcher
18:54:49 DISPATCHER: register_result: lock acquired
18:54:49 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:54:49 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 267, 'last_n_outputs': 34, 'leak_rate': 0.993546243262065, 'lr': 0.09001728484031703, 'optimizer': 'SGD', 'sparsity': 0.8671402544059263, 'steps_to_train': 31, 'weight_decay': 0.06820508564184176}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4998568472603737, 'info': {'music-speech': 0.4998568472603737, 'config': "{'batch_size': 64, 'hidden_dim': 267, 'last_n_outputs': 34, 'leak_rate': 0.993546243262065, 'lr': 0.09001728484031703, 'optimizer': 'SGD', 'sparsity': 0.8671402544059263, 'steps_to_train': 31, 'weight_decay': 0.06820508564184176}"}}
exception: None

18:54:49 job_callback for (0, 0, 13) started
18:54:49 job_callback for (0, 0, 13) got condition
18:54:49 DISPATCHER: Trying to submit another job.
18:54:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:54:49 HBMASTER: Trying to run another job!
18:54:49 job_callback for (0, 0, 13) finished
18:54:49 start sampling a new configuration.
18:54:49 done sampling a new configuration.
18:54:49 HBMASTER: schedule new run for iteration 0
18:54:49 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
18:54:49 HBMASTER: submitting job (0, 0, 14) to dispatcher
18:54:49 DISPATCHER: trying to submit job (0, 0, 14)
18:54:49 DISPATCHER: trying to notify the job_runner thread.
18:54:49 HBMASTER: job (0, 0, 14) submitted to dispatcher
18:54:49 DISPATCHER: Trying to submit another job.
18:54:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:54:49 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:54:49 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:54:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:54:49 WORKER: start processing job (0, 0, 14)
18:54:49 WORKER: args: ()
18:54:49 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 980, 'last_n_outputs': 12, 'leak_rate': 0.8740652858922278, 'lr': 0.004444184429530302, 'optimizer': 'SGD', 'sparsity': 0.9250842904923042, 'steps_to_train': 85, 'weight_decay': 0.15809377048789633}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:55:35 DISPATCHER: Starting worker discovery
18:55:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:55:35 DISPATCHER: Finished worker discovery
18:55:49 WORKER: done with job (0, 0, 14), trying to register it.
18:55:49 WORKER: registered result for job (0, 0, 14) with dispatcher
18:55:49 DISPATCHER: job (0, 0, 14) finished
18:55:49 DISPATCHER: register_result: lock acquired
18:55:49 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:55:49 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 980, 'last_n_outputs': 12, 'leak_rate': 0.8740652858922278, 'lr': 0.004444184429530302, 'optimizer': 'SGD', 'sparsity': 0.9250842904923042, 'steps_to_train': 85, 'weight_decay': 0.15809377048789633}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.476685813081577, 'info': {'music-speech': 0.476685813081577, 'config': "{'batch_size': 32, 'hidden_dim': 980, 'last_n_outputs': 12, 'leak_rate': 0.8740652858922278, 'lr': 0.004444184429530302, 'optimizer': 'SGD', 'sparsity': 0.9250842904923042, 'steps_to_train': 85, 'weight_decay': 0.15809377048789633}"}}
exception: None

18:55:49 job_callback for (0, 0, 14) started
18:55:49 DISPATCHER: Trying to submit another job.
18:55:49 job_callback for (0, 0, 14) got condition
18:55:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:55:49 HBMASTER: Trying to run another job!
18:55:49 job_callback for (0, 0, 14) finished
18:55:49 start sampling a new configuration.
18:55:49 done sampling a new configuration.
18:55:49 HBMASTER: schedule new run for iteration 0
18:55:49 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
18:55:49 HBMASTER: submitting job (0, 0, 15) to dispatcher
18:55:49 DISPATCHER: trying to submit job (0, 0, 15)
18:55:49 DISPATCHER: trying to notify the job_runner thread.
18:55:49 HBMASTER: job (0, 0, 15) submitted to dispatcher
18:55:49 DISPATCHER: Trying to submit another job.
18:55:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:55:49 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:55:49 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:55:49 WORKER: start processing job (0, 0, 15)
18:55:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:55:49 WORKER: args: ()
18:55:49 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 405, 'last_n_outputs': 36, 'leak_rate': 0.881309571855841, 'lr': 0.0036357138471190013, 'optimizer': 'Adam', 'sparsity': 0.7891723346014415, 'steps_to_train': 80, 'weight_decay': 0.18198274386307842}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:56:35 DISPATCHER: Starting worker discovery
18:56:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:56:35 DISPATCHER: Finished worker discovery
18:56:43 WORKER: done with job (0, 0, 15), trying to register it.
18:56:43 DISPATCHER: job (0, 0, 15) finished
18:56:43 WORKER: registered result for job (0, 0, 15) with dispatcher
18:56:43 DISPATCHER: register_result: lock acquired
18:56:43 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:56:43 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 405, 'last_n_outputs': 36, 'leak_rate': 0.881309571855841, 'lr': 0.0036357138471190013, 'optimizer': 'Adam', 'sparsity': 0.7891723346014415, 'steps_to_train': 80, 'weight_decay': 0.18198274386307842}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5817723428421359, 'info': {'music-speech': 0.5817723428421359, 'config': "{'batch_size': 64, 'hidden_dim': 405, 'last_n_outputs': 36, 'leak_rate': 0.881309571855841, 'lr': 0.0036357138471190013, 'optimizer': 'Adam', 'sparsity': 0.7891723346014415, 'steps_to_train': 80, 'weight_decay': 0.18198274386307842}"}}
exception: None

18:56:43 DISPATCHER: Trying to submit another job.
18:56:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:56:43 job_callback for (0, 0, 15) started
18:56:43 job_callback for (0, 0, 15) got condition
18:56:43 HBMASTER: Trying to run another job!
18:56:43 job_callback for (0, 0, 15) finished
18:56:43 start sampling a new configuration.
18:56:43 done sampling a new configuration.
18:56:43 HBMASTER: schedule new run for iteration 0
18:56:43 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
18:56:43 HBMASTER: submitting job (0, 0, 16) to dispatcher
18:56:43 DISPATCHER: trying to submit job (0, 0, 16)
18:56:43 DISPATCHER: trying to notify the job_runner thread.
18:56:43 HBMASTER: job (0, 0, 16) submitted to dispatcher
18:56:43 DISPATCHER: Trying to submit another job.
18:56:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:56:43 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:56:43 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:56:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:56:43 WORKER: start processing job (0, 0, 16)
18:56:43 WORKER: args: ()
18:56:43 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 402, 'last_n_outputs': 33, 'leak_rate': 0.9804055781865003, 'lr': 0.017015912430201036, 'optimizer': 'SGD', 'sparsity': 0.8100020534127551, 'steps_to_train': 30, 'weight_decay': 0.011546016390295679}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:57:35 DISPATCHER: Starting worker discovery
18:57:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:57:35 DISPATCHER: Finished worker discovery
18:57:42 WORKER: done with job (0, 0, 16), trying to register it.
18:57:42 DISPATCHER: job (0, 0, 16) finished
18:57:42 WORKER: registered result for job (0, 0, 16) with dispatcher
18:57:42 DISPATCHER: register_result: lock acquired
18:57:42 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:57:42 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 402, 'last_n_outputs': 33, 'leak_rate': 0.9804055781865003, 'lr': 0.017015912430201036, 'optimizer': 'SGD', 'sparsity': 0.8100020534127551, 'steps_to_train': 30, 'weight_decay': 0.011546016390295679}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4269352563791546, 'info': {'music-speech': 0.4269352563791546, 'config': "{'batch_size': 16, 'hidden_dim': 402, 'last_n_outputs': 33, 'leak_rate': 0.9804055781865003, 'lr': 0.017015912430201036, 'optimizer': 'SGD', 'sparsity': 0.8100020534127551, 'steps_to_train': 30, 'weight_decay': 0.011546016390295679}"}}
exception: None

18:57:42 job_callback for (0, 0, 16) started
18:57:42 DISPATCHER: Trying to submit another job.
18:57:42 job_callback for (0, 0, 16) got condition
18:57:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:57:42 HBMASTER: Trying to run another job!
18:57:42 job_callback for (0, 0, 16) finished
18:57:42 start sampling a new configuration.
18:57:42 done sampling a new configuration.
18:57:42 HBMASTER: schedule new run for iteration 0
18:57:42 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
18:57:42 HBMASTER: submitting job (0, 0, 17) to dispatcher
18:57:42 DISPATCHER: trying to submit job (0, 0, 17)
18:57:42 DISPATCHER: trying to notify the job_runner thread.
18:57:42 HBMASTER: job (0, 0, 17) submitted to dispatcher
18:57:42 DISPATCHER: Trying to submit another job.
18:57:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:57:42 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:57:42 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:57:42 WORKER: start processing job (0, 0, 17)
18:57:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:57:42 WORKER: args: ()
18:57:42 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 992, 'last_n_outputs': 20, 'leak_rate': 0.9524954348812857, 'lr': 0.004152514653245124, 'optimizer': 'Adam', 'sparsity': 0.9527600748561019, 'steps_to_train': 61, 'weight_decay': 0.019058670533373494}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:58:35 DISPATCHER: Starting worker discovery
18:58:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:58:35 DISPATCHER: Finished worker discovery
18:58:40 WORKER: done with job (0, 0, 17), trying to register it.
18:58:40 DISPATCHER: job (0, 0, 17) finished
18:58:40 WORKER: registered result for job (0, 0, 17) with dispatcher
18:58:40 DISPATCHER: register_result: lock acquired
18:58:40 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:58:40 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 992, 'last_n_outputs': 20, 'leak_rate': 0.9524954348812857, 'lr': 0.004152514653245124, 'optimizer': 'Adam', 'sparsity': 0.9527600748561019, 'steps_to_train': 61, 'weight_decay': 0.019058670533373494}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.515201614779918, 'info': {'music-speech': 0.515201614779918, 'config': "{'batch_size': 16, 'hidden_dim': 992, 'last_n_outputs': 20, 'leak_rate': 0.9524954348812857, 'lr': 0.004152514653245124, 'optimizer': 'Adam', 'sparsity': 0.9527600748561019, 'steps_to_train': 61, 'weight_decay': 0.019058670533373494}"}}
exception: None

18:58:40 job_callback for (0, 0, 17) started
18:58:40 job_callback for (0, 0, 17) got condition
18:58:40 DISPATCHER: Trying to submit another job.
18:58:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:58:40 HBMASTER: Trying to run another job!
18:58:40 job_callback for (0, 0, 17) finished
18:58:40 start sampling a new configuration.
18:58:40 done sampling a new configuration.
18:58:40 HBMASTER: schedule new run for iteration 0
18:58:40 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
18:58:40 HBMASTER: submitting job (0, 0, 18) to dispatcher
18:58:40 DISPATCHER: trying to submit job (0, 0, 18)
18:58:40 DISPATCHER: trying to notify the job_runner thread.
18:58:40 HBMASTER: job (0, 0, 18) submitted to dispatcher
18:58:40 DISPATCHER: Trying to submit another job.
18:58:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:58:40 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:58:40 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:58:40 WORKER: start processing job (0, 0, 18)
18:58:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:58:40 WORKER: args: ()
18:58:40 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 261, 'last_n_outputs': 19, 'leak_rate': 0.7959567194313922, 'lr': 0.004511440158970412, 'optimizer': 'Adam', 'sparsity': 0.9663159179279627, 'steps_to_train': 67, 'weight_decay': 0.03907489867035811}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:59:35 DISPATCHER: Starting worker discovery
18:59:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:59:35 DISPATCHER: Finished worker discovery
18:59:36 WORKER: done with job (0, 0, 18), trying to register it.
18:59:36 WORKER: registered result for job (0, 0, 18) with dispatcher
18:59:36 DISPATCHER: job (0, 0, 18) finished
18:59:36 DISPATCHER: register_result: lock acquired
18:59:36 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:59:36 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 261, 'last_n_outputs': 19, 'leak_rate': 0.7959567194313922, 'lr': 0.004511440158970412, 'optimizer': 'Adam', 'sparsity': 0.9663159179279627, 'steps_to_train': 67, 'weight_decay': 0.03907489867035811}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.47244005152361784, 'info': {'music-speech': 0.47244005152361784, 'config': "{'batch_size': 64, 'hidden_dim': 261, 'last_n_outputs': 19, 'leak_rate': 0.7959567194313922, 'lr': 0.004511440158970412, 'optimizer': 'Adam', 'sparsity': 0.9663159179279627, 'steps_to_train': 67, 'weight_decay': 0.03907489867035811}"}}
exception: None

18:59:36 job_callback for (0, 0, 18) started
18:59:36 DISPATCHER: Trying to submit another job.
18:59:36 job_callback for (0, 0, 18) got condition
18:59:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:59:36 HBMASTER: Trying to run another job!
18:59:36 job_callback for (0, 0, 18) finished
18:59:36 start sampling a new configuration.
18:59:36 done sampling a new configuration.
18:59:36 HBMASTER: schedule new run for iteration 0
18:59:36 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
18:59:36 HBMASTER: submitting job (0, 0, 19) to dispatcher
18:59:36 DISPATCHER: trying to submit job (0, 0, 19)
18:59:36 DISPATCHER: trying to notify the job_runner thread.
18:59:36 HBMASTER: job (0, 0, 19) submitted to dispatcher
18:59:36 DISPATCHER: Trying to submit another job.
18:59:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:59:36 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:59:36 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:59:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:59:36 WORKER: start processing job (0, 0, 19)
18:59:36 WORKER: args: ()
18:59:36 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 244, 'last_n_outputs': 14, 'leak_rate': 0.9566050327844864, 'lr': 0.007579898621780117, 'optimizer': 'Adam', 'sparsity': 0.9759738658720625, 'steps_to_train': 56, 'weight_decay': 0.1349236227636857}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:00:35 WORKER: done with job (0, 0, 19), trying to register it.
19:00:35 WORKER: registered result for job (0, 0, 19) with dispatcher
19:00:35 DISPATCHER: job (0, 0, 19) finished
19:00:35 DISPATCHER: register_result: lock acquired
19:00:35 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
19:00:35 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 244, 'last_n_outputs': 14, 'leak_rate': 0.9566050327844864, 'lr': 0.007579898621780117, 'optimizer': 'Adam', 'sparsity': 0.9759738658720625, 'steps_to_train': 56, 'weight_decay': 0.1349236227636857}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5016338377243378, 'info': {'music-speech': 0.5016338377243378, 'config': "{'batch_size': 128, 'hidden_dim': 244, 'last_n_outputs': 14, 'leak_rate': 0.9566050327844864, 'lr': 0.007579898621780117, 'optimizer': 'Adam', 'sparsity': 0.9759738658720625, 'steps_to_train': 56, 'weight_decay': 0.1349236227636857}"}}
exception: None

19:00:35 job_callback for (0, 0, 19) started
19:00:35 DISPATCHER: Trying to submit another job.
19:00:35 job_callback for (0, 0, 19) got condition
19:00:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:00:35 done building a new model for budget 44.444444 based on 10/17 split
Best loss for this budget:-0.610221





19:00:35 HBMASTER: Trying to run another job!
19:00:35 job_callback for (0, 0, 19) finished
19:00:35 start sampling a new configuration.
19:00:35 best_vector: [2, 0.8188913745856005, 0.5381033788434417, 0.18361239949248742, 0.6130909638780699, 0, 0.1262565714999131, 0.24482245152450605, 0.3891337236083243], 0.007265721561716661, 0.18773821285792341, 0.0013640535811199662
19:00:35 done sampling a new configuration.
19:00:35 HBMASTER: schedule new run for iteration 0
19:00:35 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
19:00:35 HBMASTER: submitting job (0, 0, 20) to dispatcher
19:00:35 DISPATCHER: trying to submit job (0, 0, 20)
19:00:35 DISPATCHER: trying to notify the job_runner thread.
19:00:35 HBMASTER: job (0, 0, 20) submitted to dispatcher
19:00:35 DISPATCHER: Trying to submit another job.
19:00:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:00:35 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216
19:00:35 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
19:00:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:00:35 WORKER: start processing job (0, 0, 20)
19:00:35 WORKER: args: ()
19:00:35 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 855, 'last_n_outputs': 32, 'leak_rate': 0.7959030998731218, 'lr': 0.016833790878587364, 'optimizer': 'Adam', 'sparsity': 0.7803015771599792, 'steps_to_train': 32, 'weight_decay': 0.03208297602439331}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:00:35 DISPATCHER: Starting worker discovery
19:00:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:00:35 DISPATCHER: Finished worker discovery
19:01:32 WORKER: done with job (0, 0, 20), trying to register it.
19:01:32 WORKER: registered result for job (0, 0, 20) with dispatcher
19:01:32 DISPATCHER: job (0, 0, 20) finished
19:01:32 DISPATCHER: register_result: lock acquired
19:01:32 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
19:01:32 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 855, 'last_n_outputs': 32, 'leak_rate': 0.7959030998731218, 'lr': 0.016833790878587364, 'optimizer': 'Adam', 'sparsity': 0.7803015771599792, 'steps_to_train': 32, 'weight_decay': 0.03208297602439331}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3210103752150984, 'info': {'music-speech': 0.3210103752150984, 'config': "{'batch_size': 64, 'hidden_dim': 855, 'last_n_outputs': 32, 'leak_rate': 0.7959030998731218, 'lr': 0.016833790878587364, 'optimizer': 'Adam', 'sparsity': 0.7803015771599792, 'steps_to_train': 32, 'weight_decay': 0.03208297602439331}"}}
exception: None

19:01:32 job_callback for (0, 0, 20) started
19:01:32 DISPATCHER: Trying to submit another job.
19:01:32 job_callback for (0, 0, 20) got condition
19:01:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:01:32 done building a new model for budget 44.444444 based on 10/17 split
Best loss for this budget:-0.610221





19:01:32 HBMASTER: Trying to run another job!
19:01:32 job_callback for (0, 0, 20) finished
19:01:32 start sampling a new configuration.
19:01:32 best_vector: [0, 0.8419549043535735, 0.958568359716303, 0.9411234286318684, 0.11966066427916502, 0, 0.28745023895333255, 0.7849718323684596, 0.8684282952859264], 0.011067556753404317, 0.003909136000372627, 4.326458454090001e-05
19:01:32 done sampling a new configuration.
19:01:32 HBMASTER: schedule new run for iteration 0
19:01:32 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
19:01:32 HBMASTER: submitting job (0, 0, 21) to dispatcher
19:01:32 DISPATCHER: trying to submit job (0, 0, 21)
19:01:32 DISPATCHER: trying to notify the job_runner thread.
19:01:32 HBMASTER: job (0, 0, 21) submitted to dispatcher
19:01:32 DISPATCHER: Trying to submit another job.
19:01:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:01:32 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216
19:01:32 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
19:01:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:01:32 WORKER: start processing job (0, 0, 21)
19:01:32 WORKER: args: ()
19:01:32 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 874, 'last_n_outputs': 49, 'leak_rate': 0.9852808571579671, 'lr': 0.0017350872903496095, 'optimizer': 'Adam', 'sparsity': 0.8189880573487998, 'steps_to_train': 81, 'weight_decay': 0.13485009639942216}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:01:35 DISPATCHER: Starting worker discovery
19:01:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:01:35 DISPATCHER: Finished worker discovery
19:02:30 WORKER: done with job (0, 0, 21), trying to register it.
19:02:30 WORKER: registered result for job (0, 0, 21) with dispatcher
19:02:30 DISPATCHER: job (0, 0, 21) finished
19:02:30 DISPATCHER: register_result: lock acquired
19:02:30 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
19:02:30 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 874, 'last_n_outputs': 49, 'leak_rate': 0.9852808571579671, 'lr': 0.0017350872903496095, 'optimizer': 'Adam', 'sparsity': 0.8189880573487998, 'steps_to_train': 81, 'weight_decay': 0.13485009639942216}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.1534254848958671, 'info': {'music-speech': 0.1534254848958671, 'config': "{'batch_size': 16, 'hidden_dim': 874, 'last_n_outputs': 49, 'leak_rate': 0.9852808571579671, 'lr': 0.0017350872903496095, 'optimizer': 'Adam', 'sparsity': 0.8189880573487998, 'steps_to_train': 81, 'weight_decay': 0.13485009639942216}"}}
exception: None

19:02:30 job_callback for (0, 0, 21) started
19:02:30 job_callback for (0, 0, 21) got condition
19:02:30 DISPATCHER: Trying to submit another job.
19:02:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:02:30 done building a new model for budget 44.444444 based on 10/18 split
Best loss for this budget:-0.610221





19:02:30 HBMASTER: Trying to run another job!
19:02:30 job_callback for (0, 0, 21) finished
19:02:30 start sampling a new configuration.
19:02:31 best_vector: [1, 0.9587154235096645, 0.3314871849333828, 0.5575400987919767, 0.041827340306760774, 0, 0.9232956876857448, 0.4248250776498982, 0.3536472639456303], 0.00747664517098956, 0.2196158264373401, 0.0016419896082056201
19:02:31 done sampling a new configuration.
19:02:31 HBMASTER: schedule new run for iteration 0
19:02:31 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
19:02:31 HBMASTER: submitting job (0, 0, 22) to dispatcher
19:02:31 DISPATCHER: trying to submit job (0, 0, 22)
19:02:31 DISPATCHER: trying to notify the job_runner thread.
19:02:31 HBMASTER: job (0, 0, 22) submitted to dispatcher
19:02:31 DISPATCHER: Trying to submit another job.
19:02:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:02:31 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpul.22021139727314577216
19:02:31 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
19:02:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:02:31 WORKER: start processing job (0, 0, 22)
19:02:31 WORKER: args: ()
19:02:31 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 967, 'last_n_outputs': 23, 'leak_rate': 0.8893850246979942, 'lr': 0.0012124244353660689, 'optimizer': 'Adam', 'sparsity': 0.9715909650445788, 'steps_to_train': 48, 'weight_decay': 0.028847335020562057}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:02:35 DISPATCHER: Starting worker discovery
19:02:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:02:35 DISPATCHER: Finished worker discovery
19:03:33 WORKER: done with job (0, 0, 22), trying to register it.
19:03:33 WORKER: registered result for job (0, 0, 22) with dispatcher
19:03:33 DISPATCHER: job (0, 0, 22) finished
19:03:33 DISPATCHER: register_result: lock acquired
19:03:33 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
19:03:33 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 967, 'last_n_outputs': 23, 'leak_rate': 0.8893850246979942, 'lr': 0.0012124244353660689, 'optimizer': 'Adam', 'sparsity': 0.9715909650445788, 'steps_to_train': 48, 'weight_decay': 0.028847335020562057}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.48313887375234293, 'info': {'music-speech': 0.48313887375234293, 'config': "{'batch_size': 32, 'hidden_dim': 967, 'last_n_outputs': 23, 'leak_rate': 0.8893850246979942, 'lr': 0.0012124244353660689, 'optimizer': 'Adam', 'sparsity': 0.9715909650445788, 'steps_to_train': 48, 'weight_decay': 0.028847335020562057}"}}
exception: None

19:03:33 job_callback for (0, 0, 22) started
19:03:33 job_callback for (0, 0, 22) got condition
19:03:33 DISPATCHER: Trying to submit another job.
19:03:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:03:33 done building a new model for budget 44.444444 based on 10/19 split
Best loss for this budget:-0.610221





19:03:33 HBMASTER: Trying to run another job!
19:03:33 job_callback for (0, 0, 22) finished
19:03:33 start sampling a new configuration.
19:03:34 best_vector: [2, 0.11453656319022448, 0.4677211870692324, 0.3109760218031993, 0.04194085211128132, 1, 0.2249158044117217, 0.5431950327941745, 0.8111041453188934], 0.025218517859695932, 0.05147229539007364, 0.0012980550005741167
19:03:34 done sampling a new configuration.
19:03:34 HBMASTER: schedule new run for iteration 0
19:03:34 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
19:03:34 HBMASTER: submitting job (0, 0, 23) to dispatcher
19:03:34 DISPATCHER: trying to submit job (0, 0, 23)
19:03:34 DISPATCHER: trying to notify the job_runner thread.
19:03:34 HBMASTER: job (0, 0, 23) submitted to dispatcher
19:03:34 DISPATCHER: Trying to submit another job.
19:03:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:03:34 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216
19:03:34 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
19:03:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:03:34 WORKER: start processing job (0, 0, 23)
19:03:34 WORKER: args: ()
19:03:34 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 291, 'last_n_outputs': 29, 'leak_rate': 0.8277440054507998, 'lr': 0.0012130583852249814, 'optimizer': 'SGD', 'sparsity': 0.8039797930588132, 'steps_to_train': 59, 'weight_decay': 0.11357188203354934}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:03:35 DISPATCHER: Starting worker discovery
19:03:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:03:35 DISPATCHER: Finished worker discovery
19:04:35 DISPATCHER: Starting worker discovery
19:04:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:04:35 DISPATCHER: Finished worker discovery
19:04:47 WORKER: done with job (0, 0, 23), trying to register it.
19:04:48 DISPATCHER: job (0, 0, 23) finished
19:04:48 WORKER: registered result for job (0, 0, 23) with dispatcher
19:04:48 DISPATCHER: register_result: lock acquired
19:04:48 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
19:04:48 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 291, 'last_n_outputs': 29, 'leak_rate': 0.8277440054507998, 'lr': 0.0012130583852249814, 'optimizer': 'SGD', 'sparsity': 0.8039797930588132, 'steps_to_train': 59, 'weight_decay': 0.11357188203354934}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5830511452198959, 'info': {'music-speech': 0.5830511452198959, 'config': "{'batch_size': 64, 'hidden_dim': 291, 'last_n_outputs': 29, 'leak_rate': 0.8277440054507998, 'lr': 0.0012130583852249814, 'optimizer': 'SGD', 'sparsity': 0.8039797930588132, 'steps_to_train': 59, 'weight_decay': 0.11357188203354934}"}}
exception: None

19:04:48 job_callback for (0, 0, 23) started
19:04:48 job_callback for (0, 0, 23) got condition
19:04:48 DISPATCHER: Trying to submit another job.
19:04:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:04:48 done building a new model for budget 44.444444 based on 10/20 split
Best loss for this budget:-0.610221





19:04:48 HBMASTER: Trying to run another job!
19:04:48 job_callback for (0, 0, 23) finished
19:04:48 start sampling a new configuration.
19:04:48 best_vector: [3, 0.14355544165587347, 0.4107265494436787, 0.2684544854233008, 0.08502247566184748, 1, 0.16853030623932325, 0.8696203848764528, 0.759457180420276], 0.011316105482029628, 0.12360451476869835, 0.0013987217271776795
19:04:48 done sampling a new configuration.
19:04:48 HBMASTER: schedule new run for iteration 0
19:04:48 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
19:04:48 HBMASTER: submitting job (0, 0, 24) to dispatcher
19:04:48 DISPATCHER: trying to submit job (0, 0, 24)
19:04:48 DISPATCHER: trying to notify the job_runner thread.
19:04:48 HBMASTER: job (0, 0, 24) submitted to dispatcher
19:04:48 DISPATCHER: Trying to submit another job.
19:04:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:04:48 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpul.22021139727314577216
19:04:48 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
19:04:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:04:48 WORKER: start processing job (0, 0, 24)
19:04:48 WORKER: args: ()
19:04:48 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 314, 'last_n_outputs': 26, 'leak_rate': 0.8171136213558252, 'lr': 0.0014792614900926268, 'optimizer': 'SGD', 'sparsity': 0.7904472734974376, 'steps_to_train': 89, 'weight_decay': 0.09729187477438016}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:05:35 DISPATCHER: Starting worker discovery
19:05:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:05:35 DISPATCHER: Finished worker discovery
19:05:48 WORKER: done with job (0, 0, 24), trying to register it.
19:05:48 DISPATCHER: job (0, 0, 24) finished
19:05:48 WORKER: registered result for job (0, 0, 24) with dispatcher
19:05:48 DISPATCHER: register_result: lock acquired
19:05:48 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
19:05:48 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 314, 'last_n_outputs': 26, 'leak_rate': 0.8171136213558252, 'lr': 0.0014792614900926268, 'optimizer': 'SGD', 'sparsity': 0.7904472734974376, 'steps_to_train': 89, 'weight_decay': 0.09729187477438016}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6405815696903917, 'info': {'music-speech': 0.6405815696903917, 'config': "{'batch_size': 128, 'hidden_dim': 314, 'last_n_outputs': 26, 'leak_rate': 0.8171136213558252, 'lr': 0.0014792614900926268, 'optimizer': 'SGD', 'sparsity': 0.7904472734974376, 'steps_to_train': 89, 'weight_decay': 0.09729187477438016}"}}
exception: None

19:05:48 job_callback for (0, 0, 24) started
19:05:48 DISPATCHER: Trying to submit another job.
19:05:48 job_callback for (0, 0, 24) got condition
19:05:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:05:48 done building a new model for budget 44.444444 based on 10/21 split
Best loss for this budget:-0.640582





19:05:48 HBMASTER: Trying to run another job!
19:05:48 job_callback for (0, 0, 24) finished
19:05:48 start sampling a new configuration.
19:05:48 done sampling a new configuration.
19:05:48 HBMASTER: schedule new run for iteration 0
19:05:48 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
19:05:48 HBMASTER: submitting job (0, 0, 25) to dispatcher
19:05:48 DISPATCHER: trying to submit job (0, 0, 25)
19:05:48 DISPATCHER: trying to notify the job_runner thread.
19:05:48 HBMASTER: job (0, 0, 25) submitted to dispatcher
19:05:48 DISPATCHER: Trying to submit another job.
19:05:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:05:48 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216
19:05:48 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
19:05:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:05:48 WORKER: start processing job (0, 0, 25)
19:05:48 WORKER: args: ()
19:05:48 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 232, 'last_n_outputs': 12, 'leak_rate': 0.7551799028902098, 'lr': 0.030242619194227743, 'optimizer': 'Adam', 'sparsity': 0.9454754102253358, 'steps_to_train': 30, 'weight_decay': 0.05605537618586869}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:06:35 DISPATCHER: Starting worker discovery
19:06:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:06:35 DISPATCHER: Finished worker discovery
19:06:47 WORKER: done with job (0, 0, 25), trying to register it.
19:06:47 WORKER: registered result for job (0, 0, 25) with dispatcher
19:06:47 DISPATCHER: job (0, 0, 25) finished
19:06:47 DISPATCHER: register_result: lock acquired
19:06:47 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
19:06:47 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 232, 'last_n_outputs': 12, 'leak_rate': 0.7551799028902098, 'lr': 0.030242619194227743, 'optimizer': 'Adam', 'sparsity': 0.9454754102253358, 'steps_to_train': 30, 'weight_decay': 0.05605537618586869}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5458565630543416, 'info': {'music-speech': 0.5458565630543416, 'config': "{'batch_size': 16, 'hidden_dim': 232, 'last_n_outputs': 12, 'leak_rate': 0.7551799028902098, 'lr': 0.030242619194227743, 'optimizer': 'Adam', 'sparsity': 0.9454754102253358, 'steps_to_train': 30, 'weight_decay': 0.05605537618586869}"}}
exception: None

19:06:47 job_callback for (0, 0, 25) started
19:06:47 job_callback for (0, 0, 25) got condition
19:06:47 DISPATCHER: Trying to submit another job.
19:06:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:06:47 done building a new model for budget 44.444444 based on 10/22 split
Best loss for this budget:-0.640582





19:06:47 HBMASTER: Trying to run another job!
19:06:47 job_callback for (0, 0, 25) finished
19:06:47 start sampling a new configuration.
19:06:47 best_vector: [2, 0.04508789489299547, 0.35607374249882534, 0.22465151170115266, 0.2793583324266493, 0, 0.13840362555453467, 0.7182289491536344, 0.7851010807139982], 0.0037347061679196655, 0.3635798538528199, 0.001357863922715457
19:06:47 done sampling a new configuration.
19:06:47 HBMASTER: schedule new run for iteration 0
19:06:47 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
19:06:47 HBMASTER: submitting job (0, 0, 26) to dispatcher
19:06:47 DISPATCHER: trying to submit job (0, 0, 26)
19:06:47 DISPATCHER: trying to notify the job_runner thread.
19:06:47 HBMASTER: job (0, 0, 26) submitted to dispatcher
19:06:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:06:47 DISPATCHER: Trying to submit another job.
19:06:47 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpul.22021139727314577216
19:06:47 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
19:06:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:06:47 WORKER: start processing job (0, 0, 26)
19:06:47 WORKER: args: ()
19:06:47 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 236, 'last_n_outputs': 24, 'leak_rate': 0.8061628779252882, 'lr': 0.0036200674696851153, 'optimizer': 'Adam', 'sparsity': 0.7832168701330883, 'steps_to_train': 75, 'weight_decay': 0.10506064328070083}, 'budget': 44.44444444444444, 'working_directory': '.'}
19:07:35 DISPATCHER: Starting worker discovery
19:07:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:07:35 DISPATCHER: Finished worker discovery
19:08:00 WORKER: done with job (0, 0, 26), trying to register it.
19:08:00 WORKER: registered result for job (0, 0, 26) with dispatcher
19:08:00 DISPATCHER: job (0, 0, 26) finished
19:08:00 DISPATCHER: register_result: lock acquired
19:08:00 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
19:08:00 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 236, 'last_n_outputs': 24, 'leak_rate': 0.8061628779252882, 'lr': 0.0036200674696851153, 'optimizer': 'Adam', 'sparsity': 0.7832168701330883, 'steps_to_train': 75, 'weight_decay': 0.10506064328070083}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.49261584452462936, 'info': {'music-speech': 0.49261584452462936, 'config': "{'batch_size': 64, 'hidden_dim': 236, 'last_n_outputs': 24, 'leak_rate': 0.8061628779252882, 'lr': 0.0036200674696851153, 'optimizer': 'Adam', 'sparsity': 0.7832168701330883, 'steps_to_train': 75, 'weight_decay': 0.10506064328070083}"}}
exception: None

19:08:00 job_callback for (0, 0, 26) started
19:08:00 DISPATCHER: Trying to submit another job.
19:08:00 job_callback for (0, 0, 26) got condition
19:08:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:08:00 done building a new model for budget 44.444444 based on 10/22 split
Best loss for this budget:-0.640582





19:08:00 HBMASTER: Trying to run another job!
19:08:00 job_callback for (0, 0, 26) finished
19:08:00 ITERATION: Advancing config (0, 0, 0) to next budget 133.333333
19:08:00 ITERATION: Advancing config (0, 0, 2) to next budget 133.333333
19:08:00 ITERATION: Advancing config (0, 0, 3) to next budget 133.333333
19:08:00 ITERATION: Advancing config (0, 0, 12) to next budget 133.333333
19:08:00 ITERATION: Advancing config (0, 0, 15) to next budget 133.333333
19:08:00 ITERATION: Advancing config (0, 0, 17) to next budget 133.333333
19:08:00 ITERATION: Advancing config (0, 0, 23) to next budget 133.333333
19:08:00 ITERATION: Advancing config (0, 0, 24) to next budget 133.333333
19:08:00 ITERATION: Advancing config (0, 0, 25) to next budget 133.333333
19:08:00 HBMASTER: schedule new run for iteration 0
19:08:00 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
19:08:00 HBMASTER: submitting job (0, 0, 0) to dispatcher
19:08:00 DISPATCHER: trying to submit job (0, 0, 0)
19:08:00 DISPATCHER: trying to notify the job_runner thread.
19:08:00 HBMASTER: job (0, 0, 0) submitted to dispatcher
19:08:00 DISPATCHER: Trying to submit another job.
19:08:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:08:00 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
19:08:00 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
19:08:00 WORKER: start processing job (0, 0, 0)
19:08:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:08:00 WORKER: args: ()
19:08:00 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 759, 'last_n_outputs': 33, 'leak_rate': 0.7590672983245007, 'lr': 0.06718435256563829, 'optimizer': 'Adam', 'sparsity': 0.8743458897605779, 'steps_to_train': 61, 'weight_decay': 0.02858172757654736}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:08:35 DISPATCHER: Starting worker discovery
19:08:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:08:35 DISPATCHER: Finished worker discovery
19:09:35 DISPATCHER: Starting worker discovery
19:09:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:09:35 DISPATCHER: Finished worker discovery
19:10:27 WORKER: done with job (0, 0, 0), trying to register it.
19:10:27 WORKER: registered result for job (0, 0, 0) with dispatcher
19:10:27 DISPATCHER: job (0, 0, 0) finished
19:10:27 DISPATCHER: register_result: lock acquired
19:10:27 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
19:10:27 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 759, 'last_n_outputs': 33, 'leak_rate': 0.7590672983245007, 'lr': 0.06718435256563829, 'optimizer': 'Adam', 'sparsity': 0.8743458897605779, 'steps_to_train': 61, 'weight_decay': 0.02858172757654736}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5365464463929966, 'info': {'music-speech': 0.5365464463929966, 'config': "{'batch_size': 128, 'hidden_dim': 759, 'last_n_outputs': 33, 'leak_rate': 0.7590672983245007, 'lr': 0.06718435256563829, 'optimizer': 'Adam', 'sparsity': 0.8743458897605779, 'steps_to_train': 61, 'weight_decay': 0.02858172757654736}"}}
exception: None

19:10:27 job_callback for (0, 0, 0) started
19:10:27 DISPATCHER: Trying to submit another job.
19:10:27 job_callback for (0, 0, 0) got condition
19:10:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:10:27 Only 1 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
19:10:27 HBMASTER: Trying to run another job!
19:10:27 job_callback for (0, 0, 0) finished
19:10:27 HBMASTER: schedule new run for iteration 0
19:10:27 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
19:10:27 HBMASTER: submitting job (0, 0, 2) to dispatcher
19:10:27 DISPATCHER: trying to submit job (0, 0, 2)
19:10:27 DISPATCHER: trying to notify the job_runner thread.
19:10:27 HBMASTER: job (0, 0, 2) submitted to dispatcher
19:10:27 DISPATCHER: Trying to submit another job.
19:10:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:10:27 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
19:10:27 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
19:10:27 WORKER: start processing job (0, 0, 2)
19:10:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:10:27 WORKER: args: ()
19:10:27 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 682, 'last_n_outputs': 24, 'leak_rate': 0.8547940739508247, 'lr': 0.0019662737620393346, 'optimizer': 'SGD', 'sparsity': 0.8655422976535881, 'steps_to_train': 49, 'weight_decay': 0.06442544195191753}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:10:35 DISPATCHER: Starting worker discovery
19:10:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:10:35 DISPATCHER: Finished worker discovery
19:11:35 DISPATCHER: Starting worker discovery
19:11:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:11:35 DISPATCHER: Finished worker discovery
19:12:35 DISPATCHER: Starting worker discovery
19:12:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:12:35 DISPATCHER: Finished worker discovery
19:12:59 WORKER: done with job (0, 0, 2), trying to register it.
19:12:59 WORKER: registered result for job (0, 0, 2) with dispatcher
19:12:59 DISPATCHER: job (0, 0, 2) finished
19:12:59 DISPATCHER: register_result: lock acquired
19:12:59 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
19:12:59 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 682, 'last_n_outputs': 24, 'leak_rate': 0.8547940739508247, 'lr': 0.0019662737620393346, 'optimizer': 'SGD', 'sparsity': 0.8655422976535881, 'steps_to_train': 49, 'weight_decay': 0.06442544195191753}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5847812765075314, 'info': {'music-speech': 0.5847812765075314, 'config': "{'batch_size': 16, 'hidden_dim': 682, 'last_n_outputs': 24, 'leak_rate': 0.8547940739508247, 'lr': 0.0019662737620393346, 'optimizer': 'SGD', 'sparsity': 0.8655422976535881, 'steps_to_train': 49, 'weight_decay': 0.06442544195191753}"}}
exception: None

19:12:59 job_callback for (0, 0, 2) started
19:12:59 DISPATCHER: Trying to submit another job.
19:12:59 job_callback for (0, 0, 2) got condition
19:12:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:12:59 Only 2 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
19:12:59 HBMASTER: Trying to run another job!
19:12:59 job_callback for (0, 0, 2) finished
19:12:59 HBMASTER: schedule new run for iteration 0
19:12:59 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
19:12:59 HBMASTER: submitting job (0, 0, 3) to dispatcher
19:12:59 DISPATCHER: trying to submit job (0, 0, 3)
19:12:59 DISPATCHER: trying to notify the job_runner thread.
19:12:59 HBMASTER: job (0, 0, 3) submitted to dispatcher
19:12:59 DISPATCHER: Trying to submit another job.
19:12:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:12:59 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
19:12:59 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
19:12:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:12:59 WORKER: start processing job (0, 0, 3)
19:12:59 WORKER: args: ()
19:12:59 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 948, 'last_n_outputs': 29, 'leak_rate': 0.7588188081999508, 'lr': 0.0013742623478159215, 'optimizer': 'Adam', 'sparsity': 0.9542197536035023, 'steps_to_train': 31, 'weight_decay': 0.16616323438655572}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:13:35 DISPATCHER: Starting worker discovery
19:13:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:13:35 DISPATCHER: Finished worker discovery
19:14:35 DISPATCHER: Starting worker discovery
19:14:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:14:35 DISPATCHER: Finished worker discovery
19:15:29 WORKER: done with job (0, 0, 3), trying to register it.
19:15:29 WORKER: registered result for job (0, 0, 3) with dispatcher
19:15:29 DISPATCHER: job (0, 0, 3) finished
19:15:29 DISPATCHER: register_result: lock acquired
19:15:29 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
19:15:29 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 948, 'last_n_outputs': 29, 'leak_rate': 0.7588188081999508, 'lr': 0.0013742623478159215, 'optimizer': 'Adam', 'sparsity': 0.9542197536035023, 'steps_to_train': 31, 'weight_decay': 0.16616323438655572}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6538497710778883, 'info': {'music-speech': 0.6538497710778883, 'config': "{'batch_size': 32, 'hidden_dim': 948, 'last_n_outputs': 29, 'leak_rate': 0.7588188081999508, 'lr': 0.0013742623478159215, 'optimizer': 'Adam', 'sparsity': 0.9542197536035023, 'steps_to_train': 31, 'weight_decay': 0.16616323438655572}"}}
exception: None

19:15:29 job_callback for (0, 0, 3) started
19:15:29 job_callback for (0, 0, 3) got condition
19:15:29 DISPATCHER: Trying to submit another job.
19:15:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:15:29 Only 3 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
19:15:29 HBMASTER: Trying to run another job!
19:15:29 job_callback for (0, 0, 3) finished
19:15:29 HBMASTER: schedule new run for iteration 0
19:15:29 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
19:15:29 HBMASTER: submitting job (0, 0, 12) to dispatcher
19:15:29 DISPATCHER: trying to submit job (0, 0, 12)
19:15:29 DISPATCHER: trying to notify the job_runner thread.
19:15:29 HBMASTER: job (0, 0, 12) submitted to dispatcher
19:15:29 DISPATCHER: Trying to submit another job.
19:15:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:15:29 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216
19:15:29 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
19:15:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:15:29 WORKER: start processing job (0, 0, 12)
19:15:29 WORKER: args: ()
19:15:29 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 773, 'last_n_outputs': 16, 'leak_rate': 0.808479291314532, 'lr': 0.010133880529185122, 'optimizer': 'Adam', 'sparsity': 0.8393520319374131, 'steps_to_train': 56, 'weight_decay': 0.15049791328775372}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:15:35 DISPATCHER: Starting worker discovery
19:15:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:15:35 DISPATCHER: Finished worker discovery
19:16:35 DISPATCHER: Starting worker discovery
19:16:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:16:35 DISPATCHER: Finished worker discovery
19:17:35 DISPATCHER: Starting worker discovery
19:17:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:17:35 DISPATCHER: Finished worker discovery
19:18:00 WORKER: done with job (0, 0, 12), trying to register it.
19:18:00 WORKER: registered result for job (0, 0, 12) with dispatcher
19:18:00 DISPATCHER: job (0, 0, 12) finished
19:18:00 DISPATCHER: register_result: lock acquired
19:18:00 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
19:18:00 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 773, 'last_n_outputs': 16, 'leak_rate': 0.808479291314532, 'lr': 0.010133880529185122, 'optimizer': 'Adam', 'sparsity': 0.8393520319374131, 'steps_to_train': 56, 'weight_decay': 0.15049791328775372}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.29322005301506476, 'info': {'music-speech': 0.29322005301506476, 'config': "{'batch_size': 16, 'hidden_dim': 773, 'last_n_outputs': 16, 'leak_rate': 0.808479291314532, 'lr': 0.010133880529185122, 'optimizer': 'Adam', 'sparsity': 0.8393520319374131, 'steps_to_train': 56, 'weight_decay': 0.15049791328775372}"}}
exception: None

19:18:00 job_callback for (0, 0, 12) started
19:18:00 DISPATCHER: Trying to submit another job.
19:18:00 job_callback for (0, 0, 12) got condition
19:18:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:18:00 Only 4 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
19:18:00 HBMASTER: Trying to run another job!
19:18:00 job_callback for (0, 0, 12) finished
19:18:00 HBMASTER: schedule new run for iteration 0
19:18:00 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
19:18:00 HBMASTER: submitting job (0, 0, 15) to dispatcher
19:18:00 DISPATCHER: trying to submit job (0, 0, 15)
19:18:00 DISPATCHER: trying to notify the job_runner thread.
19:18:00 HBMASTER: job (0, 0, 15) submitted to dispatcher
19:18:00 DISPATCHER: Trying to submit another job.
19:18:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:18:00 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216
19:18:00 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
19:18:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:18:00 WORKER: start processing job (0, 0, 15)
19:18:00 WORKER: args: ()
19:18:00 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 405, 'last_n_outputs': 36, 'leak_rate': 0.881309571855841, 'lr': 0.0036357138471190013, 'optimizer': 'Adam', 'sparsity': 0.7891723346014415, 'steps_to_train': 80, 'weight_decay': 0.18198274386307842}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:18:35 DISPATCHER: Starting worker discovery
19:18:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:18:35 DISPATCHER: Finished worker discovery
19:19:35 DISPATCHER: Starting worker discovery
19:19:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:19:35 DISPATCHER: Finished worker discovery
19:20:23 WORKER: done with job (0, 0, 15), trying to register it.
19:20:23 WORKER: registered result for job (0, 0, 15) with dispatcher
19:20:23 DISPATCHER: job (0, 0, 15) finished
19:20:23 DISPATCHER: register_result: lock acquired
19:20:23 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
19:20:23 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 405, 'last_n_outputs': 36, 'leak_rate': 0.881309571855841, 'lr': 0.0036357138471190013, 'optimizer': 'Adam', 'sparsity': 0.7891723346014415, 'steps_to_train': 80, 'weight_decay': 0.18198274386307842}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5602508695290557, 'info': {'music-speech': 0.5602508695290557, 'config': "{'batch_size': 64, 'hidden_dim': 405, 'last_n_outputs': 36, 'leak_rate': 0.881309571855841, 'lr': 0.0036357138471190013, 'optimizer': 'Adam', 'sparsity': 0.7891723346014415, 'steps_to_train': 80, 'weight_decay': 0.18198274386307842}"}}
exception: None

19:20:23 job_callback for (0, 0, 15) started
19:20:23 job_callback for (0, 0, 15) got condition
19:20:23 DISPATCHER: Trying to submit another job.
19:20:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:20:23 Only 5 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
19:20:23 HBMASTER: Trying to run another job!
19:20:23 job_callback for (0, 0, 15) finished
19:20:23 HBMASTER: schedule new run for iteration 0
19:20:23 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
19:20:23 HBMASTER: submitting job (0, 0, 17) to dispatcher
19:20:23 DISPATCHER: trying to submit job (0, 0, 17)
19:20:23 DISPATCHER: trying to notify the job_runner thread.
19:20:23 HBMASTER: job (0, 0, 17) submitted to dispatcher
19:20:23 DISPATCHER: Trying to submit another job.
19:20:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:20:23 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpul.22021139727314577216
19:20:23 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
19:20:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:20:23 WORKER: start processing job (0, 0, 17)
19:20:23 WORKER: args: ()
19:20:23 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 992, 'last_n_outputs': 20, 'leak_rate': 0.9524954348812857, 'lr': 0.004152514653245124, 'optimizer': 'Adam', 'sparsity': 0.9527600748561019, 'steps_to_train': 61, 'weight_decay': 0.019058670533373494}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:20:35 DISPATCHER: Starting worker discovery
19:20:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:20:35 DISPATCHER: Finished worker discovery
19:21:35 DISPATCHER: Starting worker discovery
19:21:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:21:35 DISPATCHER: Finished worker discovery
19:22:35 DISPATCHER: Starting worker discovery
19:22:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:22:35 DISPATCHER: Finished worker discovery
19:22:47 WORKER: done with job (0, 0, 17), trying to register it.
19:22:47 WORKER: registered result for job (0, 0, 17) with dispatcher
19:22:47 DISPATCHER: job (0, 0, 17) finished
19:22:47 DISPATCHER: register_result: lock acquired
19:22:47 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
19:22:47 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 992, 'last_n_outputs': 20, 'leak_rate': 0.9524954348812857, 'lr': 0.004152514653245124, 'optimizer': 'Adam', 'sparsity': 0.9527600748561019, 'steps_to_train': 61, 'weight_decay': 0.019058670533373494}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5314177211795644, 'info': {'music-speech': 0.5314177211795644, 'config': "{'batch_size': 16, 'hidden_dim': 992, 'last_n_outputs': 20, 'leak_rate': 0.9524954348812857, 'lr': 0.004152514653245124, 'optimizer': 'Adam', 'sparsity': 0.9527600748561019, 'steps_to_train': 61, 'weight_decay': 0.019058670533373494}"}}
exception: None

19:22:47 job_callback for (0, 0, 17) started
19:22:47 DISPATCHER: Trying to submit another job.
19:22:47 job_callback for (0, 0, 17) got condition
19:22:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:22:47 Only 6 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
19:22:47 HBMASTER: Trying to run another job!
19:22:47 job_callback for (0, 0, 17) finished
19:22:47 HBMASTER: schedule new run for iteration 0
19:22:47 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
19:22:47 HBMASTER: submitting job (0, 0, 23) to dispatcher
19:22:47 DISPATCHER: trying to submit job (0, 0, 23)
19:22:47 DISPATCHER: trying to notify the job_runner thread.
19:22:47 HBMASTER: job (0, 0, 23) submitted to dispatcher
19:22:47 DISPATCHER: Trying to submit another job.
19:22:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:22:47 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216
19:22:47 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
19:22:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:22:47 WORKER: start processing job (0, 0, 23)
19:22:47 WORKER: args: ()
19:22:47 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 291, 'last_n_outputs': 29, 'leak_rate': 0.8277440054507998, 'lr': 0.0012130583852249814, 'optimizer': 'SGD', 'sparsity': 0.8039797930588132, 'steps_to_train': 59, 'weight_decay': 0.11357188203354934}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:23:36 DISPATCHER: Starting worker discovery
19:23:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:23:36 DISPATCHER: Finished worker discovery
19:24:36 DISPATCHER: Starting worker discovery
19:24:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:24:36 DISPATCHER: Finished worker discovery
19:25:11 WORKER: done with job (0, 0, 23), trying to register it.
19:25:11 DISPATCHER: job (0, 0, 23) finished
19:25:11 WORKER: registered result for job (0, 0, 23) with dispatcher
19:25:11 DISPATCHER: register_result: lock acquired
19:25:11 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
19:25:11 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 291, 'last_n_outputs': 29, 'leak_rate': 0.8277440054507998, 'lr': 0.0012130583852249814, 'optimizer': 'SGD', 'sparsity': 0.8039797930588132, 'steps_to_train': 59, 'weight_decay': 0.11357188203354934}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.41620350297376074, 'info': {'music-speech': 0.41620350297376074, 'config': "{'batch_size': 64, 'hidden_dim': 291, 'last_n_outputs': 29, 'leak_rate': 0.8277440054507998, 'lr': 0.0012130583852249814, 'optimizer': 'SGD', 'sparsity': 0.8039797930588132, 'steps_to_train': 59, 'weight_decay': 0.11357188203354934}"}}
exception: None

19:25:11 job_callback for (0, 0, 23) started
19:25:11 DISPATCHER: Trying to submit another job.
19:25:11 job_callback for (0, 0, 23) got condition
19:25:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:25:11 Only 7 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
19:25:11 HBMASTER: Trying to run another job!
19:25:11 job_callback for (0, 0, 23) finished
19:25:11 HBMASTER: schedule new run for iteration 0
19:25:11 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
19:25:11 HBMASTER: submitting job (0, 0, 24) to dispatcher
19:25:11 DISPATCHER: trying to submit job (0, 0, 24)
19:25:11 DISPATCHER: trying to notify the job_runner thread.
19:25:11 HBMASTER: job (0, 0, 24) submitted to dispatcher
19:25:11 DISPATCHER: Trying to submit another job.
19:25:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:25:11 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpul.22021139727314577216
19:25:11 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
19:25:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:25:11 WORKER: start processing job (0, 0, 24)
19:25:11 WORKER: args: ()
19:25:11 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 314, 'last_n_outputs': 26, 'leak_rate': 0.8171136213558252, 'lr': 0.0014792614900926268, 'optimizer': 'SGD', 'sparsity': 0.7904472734974376, 'steps_to_train': 89, 'weight_decay': 0.09729187477438016}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:25:36 DISPATCHER: Starting worker discovery
19:25:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:25:36 DISPATCHER: Finished worker discovery
19:26:36 DISPATCHER: Starting worker discovery
19:26:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:26:36 DISPATCHER: Finished worker discovery
19:27:36 DISPATCHER: Starting worker discovery
19:27:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:27:36 DISPATCHER: Finished worker discovery
19:27:54 WORKER: done with job (0, 0, 24), trying to register it.
19:27:54 WORKER: registered result for job (0, 0, 24) with dispatcher
19:27:54 DISPATCHER: job (0, 0, 24) finished
19:27:54 DISPATCHER: register_result: lock acquired
19:27:54 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
19:27:54 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 314, 'last_n_outputs': 26, 'leak_rate': 0.8171136213558252, 'lr': 0.0014792614900926268, 'optimizer': 'SGD', 'sparsity': 0.7904472734974376, 'steps_to_train': 89, 'weight_decay': 0.09729187477438016}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.49839084065399325, 'info': {'music-speech': 0.49839084065399325, 'config': "{'batch_size': 128, 'hidden_dim': 314, 'last_n_outputs': 26, 'leak_rate': 0.8171136213558252, 'lr': 0.0014792614900926268, 'optimizer': 'SGD', 'sparsity': 0.7904472734974376, 'steps_to_train': 89, 'weight_decay': 0.09729187477438016}"}}
exception: None

19:27:54 job_callback for (0, 0, 24) started
19:27:54 job_callback for (0, 0, 24) got condition
19:27:54 DISPATCHER: Trying to submit another job.
19:27:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:27:54 Only 8 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
19:27:54 HBMASTER: Trying to run another job!
19:27:54 job_callback for (0, 0, 24) finished
19:27:54 HBMASTER: schedule new run for iteration 0
19:27:54 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
19:27:54 HBMASTER: submitting job (0, 0, 25) to dispatcher
19:27:54 DISPATCHER: trying to submit job (0, 0, 25)
19:27:54 DISPATCHER: trying to notify the job_runner thread.
19:27:54 HBMASTER: job (0, 0, 25) submitted to dispatcher
19:27:54 DISPATCHER: Trying to submit another job.
19:27:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:27:54 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216
19:27:54 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
19:27:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:27:54 WORKER: start processing job (0, 0, 25)
19:27:54 WORKER: args: ()
19:27:54 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 232, 'last_n_outputs': 12, 'leak_rate': 0.7551799028902098, 'lr': 0.030242619194227743, 'optimizer': 'Adam', 'sparsity': 0.9454754102253358, 'steps_to_train': 30, 'weight_decay': 0.05605537618586869}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:28:36 DISPATCHER: Starting worker discovery
19:28:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:28:36 DISPATCHER: Finished worker discovery
19:29:36 DISPATCHER: Starting worker discovery
19:29:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:29:36 DISPATCHER: Finished worker discovery
19:30:18 WORKER: done with job (0, 0, 25), trying to register it.
19:30:18 WORKER: registered result for job (0, 0, 25) with dispatcher
19:30:18 DISPATCHER: job (0, 0, 25) finished
19:30:18 DISPATCHER: register_result: lock acquired
19:30:18 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
19:30:18 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 232, 'last_n_outputs': 12, 'leak_rate': 0.7551799028902098, 'lr': 0.030242619194227743, 'optimizer': 'Adam', 'sparsity': 0.9454754102253358, 'steps_to_train': 30, 'weight_decay': 0.05605537618586869}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4163360580080229, 'info': {'music-speech': 0.4163360580080229, 'config': "{'batch_size': 16, 'hidden_dim': 232, 'last_n_outputs': 12, 'leak_rate': 0.7551799028902098, 'lr': 0.030242619194227743, 'optimizer': 'Adam', 'sparsity': 0.9454754102253358, 'steps_to_train': 30, 'weight_decay': 0.05605537618586869}"}}
exception: None

19:30:18 job_callback for (0, 0, 25) started
19:30:18 job_callback for (0, 0, 25) got condition
19:30:18 DISPATCHER: Trying to submit another job.
19:30:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:30:18 Only 9 run(s) for budget 133.333333 available, need more than 11 -> can't build model!
19:30:18 HBMASTER: Trying to run another job!
19:30:18 job_callback for (0, 0, 25) finished
19:30:18 ITERATION: Advancing config (0, 0, 2) to next budget 400.000000
19:30:18 ITERATION: Advancing config (0, 0, 3) to next budget 400.000000
19:30:18 ITERATION: Advancing config (0, 0, 15) to next budget 400.000000
19:30:18 HBMASTER: schedule new run for iteration 0
19:30:18 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
19:30:18 HBMASTER: submitting job (0, 0, 2) to dispatcher
19:30:18 DISPATCHER: trying to submit job (0, 0, 2)
19:30:18 DISPATCHER: trying to notify the job_runner thread.
19:30:18 HBMASTER: job (0, 0, 2) submitted to dispatcher
19:30:18 DISPATCHER: Trying to submit another job.
19:30:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:30:18 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
19:30:18 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
19:30:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:30:18 WORKER: start processing job (0, 0, 2)
19:30:18 WORKER: args: ()
19:30:18 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 682, 'last_n_outputs': 24, 'leak_rate': 0.8547940739508247, 'lr': 0.0019662737620393346, 'optimizer': 'SGD', 'sparsity': 0.8655422976535881, 'steps_to_train': 49, 'weight_decay': 0.06442544195191753}, 'budget': 400.0, 'working_directory': '.'}
19:30:36 DISPATCHER: Starting worker discovery
19:30:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:30:36 DISPATCHER: Finished worker discovery
19:31:36 DISPATCHER: Starting worker discovery
19:31:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:31:36 DISPATCHER: Finished worker discovery
19:32:36 DISPATCHER: Starting worker discovery
19:32:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:32:36 DISPATCHER: Finished worker discovery
19:33:36 DISPATCHER: Starting worker discovery
19:33:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:33:36 DISPATCHER: Finished worker discovery
19:34:36 DISPATCHER: Starting worker discovery
19:34:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:34:36 DISPATCHER: Finished worker discovery
19:35:36 DISPATCHER: Starting worker discovery
19:35:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:35:36 DISPATCHER: Finished worker discovery
19:36:36 DISPATCHER: Starting worker discovery
19:36:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:36:36 DISPATCHER: Finished worker discovery
19:37:12 WORKER: done with job (0, 0, 2), trying to register it.
19:37:12 WORKER: registered result for job (0, 0, 2) with dispatcher
19:37:12 DISPATCHER: job (0, 0, 2) finished
19:37:12 DISPATCHER: register_result: lock acquired
19:37:12 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
19:37:12 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 682, 'last_n_outputs': 24, 'leak_rate': 0.8547940739508247, 'lr': 0.0019662737620393346, 'optimizer': 'SGD', 'sparsity': 0.8655422976535881, 'steps_to_train': 49, 'weight_decay': 0.06442544195191753}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5794018040599385, 'info': {'music-speech': 0.5794018040599385, 'config': "{'batch_size': 16, 'hidden_dim': 682, 'last_n_outputs': 24, 'leak_rate': 0.8547940739508247, 'lr': 0.0019662737620393346, 'optimizer': 'SGD', 'sparsity': 0.8655422976535881, 'steps_to_train': 49, 'weight_decay': 0.06442544195191753}"}}
exception: None

19:37:12 job_callback for (0, 0, 2) started
19:37:12 job_callback for (0, 0, 2) got condition
19:37:12 DISPATCHER: Trying to submit another job.
19:37:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:37:12 Only 1 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
19:37:12 HBMASTER: Trying to run another job!
19:37:12 job_callback for (0, 0, 2) finished
19:37:12 HBMASTER: schedule new run for iteration 0
19:37:12 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
19:37:12 HBMASTER: submitting job (0, 0, 3) to dispatcher
19:37:12 DISPATCHER: trying to submit job (0, 0, 3)
19:37:12 DISPATCHER: trying to notify the job_runner thread.
19:37:12 HBMASTER: job (0, 0, 3) submitted to dispatcher
19:37:12 DISPATCHER: Trying to submit another job.
19:37:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:37:12 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
19:37:12 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
19:37:12 WORKER: start processing job (0, 0, 3)
19:37:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:37:12 WORKER: args: ()
19:37:12 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 948, 'last_n_outputs': 29, 'leak_rate': 0.7588188081999508, 'lr': 0.0013742623478159215, 'optimizer': 'Adam', 'sparsity': 0.9542197536035023, 'steps_to_train': 31, 'weight_decay': 0.16616323438655572}, 'budget': 400.0, 'working_directory': '.'}
19:37:36 DISPATCHER: Starting worker discovery
19:37:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:37:36 DISPATCHER: Finished worker discovery
19:38:36 DISPATCHER: Starting worker discovery
19:38:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:38:36 DISPATCHER: Finished worker discovery
19:39:36 DISPATCHER: Starting worker discovery
19:39:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:39:36 DISPATCHER: Finished worker discovery
19:40:36 DISPATCHER: Starting worker discovery
19:40:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:40:36 DISPATCHER: Finished worker discovery
19:41:36 DISPATCHER: Starting worker discovery
19:41:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:41:36 DISPATCHER: Finished worker discovery
19:42:36 DISPATCHER: Starting worker discovery
19:42:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:42:36 DISPATCHER: Finished worker discovery
19:43:36 DISPATCHER: Starting worker discovery
19:43:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:43:36 DISPATCHER: Finished worker discovery
19:44:08 WORKER: done with job (0, 0, 3), trying to register it.
19:44:08 DISPATCHER: job (0, 0, 3) finished
19:44:08 WORKER: registered result for job (0, 0, 3) with dispatcher
19:44:08 DISPATCHER: register_result: lock acquired
19:44:08 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
19:44:08 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 948, 'last_n_outputs': 29, 'leak_rate': 0.7588188081999508, 'lr': 0.0013742623478159215, 'optimizer': 'Adam', 'sparsity': 0.9542197536035023, 'steps_to_train': 31, 'weight_decay': 0.16616323438655572}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.47510377481909016, 'info': {'music-speech': 0.47510377481909016, 'config': "{'batch_size': 32, 'hidden_dim': 948, 'last_n_outputs': 29, 'leak_rate': 0.7588188081999508, 'lr': 0.0013742623478159215, 'optimizer': 'Adam', 'sparsity': 0.9542197536035023, 'steps_to_train': 31, 'weight_decay': 0.16616323438655572}"}}
exception: None

19:44:08 job_callback for (0, 0, 3) started
19:44:08 DISPATCHER: Trying to submit another job.
19:44:08 job_callback for (0, 0, 3) got condition
19:44:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:44:08 Only 2 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
19:44:08 HBMASTER: Trying to run another job!
19:44:08 job_callback for (0, 0, 3) finished
19:44:08 HBMASTER: schedule new run for iteration 0
19:44:08 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
19:44:08 HBMASTER: submitting job (0, 0, 15) to dispatcher
19:44:08 DISPATCHER: trying to submit job (0, 0, 15)
19:44:08 DISPATCHER: trying to notify the job_runner thread.
19:44:08 HBMASTER: job (0, 0, 15) submitted to dispatcher
19:44:08 DISPATCHER: Trying to submit another job.
19:44:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:44:08 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216
19:44:08 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
19:44:08 WORKER: start processing job (0, 0, 15)
19:44:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:44:08 WORKER: args: ()
19:44:08 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 405, 'last_n_outputs': 36, 'leak_rate': 0.881309571855841, 'lr': 0.0036357138471190013, 'optimizer': 'Adam', 'sparsity': 0.7891723346014415, 'steps_to_train': 80, 'weight_decay': 0.18198274386307842}, 'budget': 400.0, 'working_directory': '.'}
19:44:36 DISPATCHER: Starting worker discovery
19:44:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:44:36 DISPATCHER: Finished worker discovery
19:45:36 DISPATCHER: Starting worker discovery
19:45:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:45:36 DISPATCHER: Finished worker discovery
19:46:36 DISPATCHER: Starting worker discovery
19:46:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:46:36 DISPATCHER: Finished worker discovery
19:47:36 DISPATCHER: Starting worker discovery
19:47:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:47:36 DISPATCHER: Finished worker discovery
19:48:36 DISPATCHER: Starting worker discovery
19:48:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:48:36 DISPATCHER: Finished worker discovery
19:49:36 DISPATCHER: Starting worker discovery
19:49:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:49:36 DISPATCHER: Finished worker discovery
19:50:36 DISPATCHER: Starting worker discovery
19:50:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:50:36 DISPATCHER: Finished worker discovery
19:51:10 WORKER: done with job (0, 0, 15), trying to register it.
19:51:10 WORKER: registered result for job (0, 0, 15) with dispatcher
19:51:10 DISPATCHER: job (0, 0, 15) finished
19:51:10 DISPATCHER: register_result: lock acquired
19:51:10 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
19:51:10 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 405, 'last_n_outputs': 36, 'leak_rate': 0.881309571855841, 'lr': 0.0036357138471190013, 'optimizer': 'Adam', 'sparsity': 0.7891723346014415, 'steps_to_train': 80, 'weight_decay': 0.18198274386307842}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.47942492795957664, 'info': {'music-speech': 0.47942492795957664, 'config': "{'batch_size': 64, 'hidden_dim': 405, 'last_n_outputs': 36, 'leak_rate': 0.881309571855841, 'lr': 0.0036357138471190013, 'optimizer': 'Adam', 'sparsity': 0.7891723346014415, 'steps_to_train': 80, 'weight_decay': 0.18198274386307842}"}}
exception: None

19:51:10 job_callback for (0, 0, 15) started
19:51:10 DISPATCHER: Trying to submit another job.
19:51:10 job_callback for (0, 0, 15) got condition
19:51:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:51:10 Only 3 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
19:51:10 HBMASTER: Trying to run another job!
19:51:10 job_callback for (0, 0, 15) finished
19:51:10 ITERATION: Advancing config (0, 0, 2) to next budget 1200.000000
19:51:10 HBMASTER: schedule new run for iteration 0
19:51:10 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
19:51:10 HBMASTER: submitting job (0, 0, 2) to dispatcher
19:51:10 DISPATCHER: trying to submit job (0, 0, 2)
19:51:10 DISPATCHER: trying to notify the job_runner thread.
19:51:10 HBMASTER: job (0, 0, 2) submitted to dispatcher
19:51:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:51:10 DISPATCHER: Trying to submit another job.
19:51:10 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
19:51:10 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
19:51:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:51:10 WORKER: start processing job (0, 0, 2)
19:51:10 WORKER: args: ()
19:51:10 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 682, 'last_n_outputs': 24, 'leak_rate': 0.8547940739508247, 'lr': 0.0019662737620393346, 'optimizer': 'SGD', 'sparsity': 0.8655422976535881, 'steps_to_train': 49, 'weight_decay': 0.06442544195191753}, 'budget': 1200.0, 'working_directory': '.'}
19:51:36 DISPATCHER: Starting worker discovery
19:51:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:51:36 DISPATCHER: Finished worker discovery
19:52:36 DISPATCHER: Starting worker discovery
19:52:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:52:36 DISPATCHER: Finished worker discovery
19:53:36 DISPATCHER: Starting worker discovery
19:53:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:53:36 DISPATCHER: Finished worker discovery
19:54:36 DISPATCHER: Starting worker discovery
19:54:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:54:36 DISPATCHER: Finished worker discovery
19:55:36 DISPATCHER: Starting worker discovery
19:55:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:55:36 DISPATCHER: Finished worker discovery
19:56:36 DISPATCHER: Starting worker discovery
19:56:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:56:36 DISPATCHER: Finished worker discovery
19:57:36 DISPATCHER: Starting worker discovery
19:57:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:57:36 DISPATCHER: Finished worker discovery
19:58:36 DISPATCHER: Starting worker discovery
19:58:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:58:36 DISPATCHER: Finished worker discovery
19:59:36 DISPATCHER: Starting worker discovery
19:59:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:59:36 DISPATCHER: Finished worker discovery
20:00:36 DISPATCHER: Starting worker discovery
20:00:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:00:36 DISPATCHER: Finished worker discovery
20:01:36 DISPATCHER: Starting worker discovery
20:01:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:01:36 DISPATCHER: Finished worker discovery
20:02:36 DISPATCHER: Starting worker discovery
20:02:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:02:36 DISPATCHER: Finished worker discovery
20:03:36 DISPATCHER: Starting worker discovery
20:03:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:03:36 DISPATCHER: Finished worker discovery
20:04:36 DISPATCHER: Starting worker discovery
20:04:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:04:36 DISPATCHER: Finished worker discovery
20:05:36 DISPATCHER: Starting worker discovery
20:05:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:05:36 DISPATCHER: Finished worker discovery
20:06:36 DISPATCHER: Starting worker discovery
20:06:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:06:36 DISPATCHER: Finished worker discovery
20:07:36 DISPATCHER: Starting worker discovery
20:07:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:07:36 DISPATCHER: Finished worker discovery
20:08:36 DISPATCHER: Starting worker discovery
20:08:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:08:36 DISPATCHER: Finished worker discovery
20:09:36 DISPATCHER: Starting worker discovery
20:09:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:09:36 DISPATCHER: Finished worker discovery
20:10:36 DISPATCHER: Starting worker discovery
20:10:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:10:36 DISPATCHER: Finished worker discovery
20:11:28 WORKER: done with job (0, 0, 2), trying to register it.
20:11:28 WORKER: registered result for job (0, 0, 2) with dispatcher
20:11:28 DISPATCHER: job (0, 0, 2) finished
20:11:28 DISPATCHER: register_result: lock acquired
20:11:28 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:11:28 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 682, 'last_n_outputs': 24, 'leak_rate': 0.8547940739508247, 'lr': 0.0019662737620393346, 'optimizer': 'SGD', 'sparsity': 0.8655422976535881, 'steps_to_train': 49, 'weight_decay': 0.06442544195191753}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5080400070687494, 'info': {'music-speech': 0.5080400070687494, 'config': "{'batch_size': 16, 'hidden_dim': 682, 'last_n_outputs': 24, 'leak_rate': 0.8547940739508247, 'lr': 0.0019662737620393346, 'optimizer': 'SGD', 'sparsity': 0.8655422976535881, 'steps_to_train': 49, 'weight_decay': 0.06442544195191753}"}}
exception: None

20:11:28 job_callback for (0, 0, 2) started
20:11:28 DISPATCHER: Trying to submit another job.
20:11:28 job_callback for (0, 0, 2) got condition
20:11:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:11:28 Only 1 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
20:11:28 HBMASTER: Trying to run another job!
20:11:28 job_callback for (0, 0, 2) finished
20:11:28 start sampling a new configuration.
20:11:28 best_vector: [2, 0.8557386009774548, 0.460682031127873, 0.229451334639592, 0.1934223801405246, 1, 0.5487412758686281, 0.12068114453448701, 0.7869386501765523], 0.01464776435073374, 0.2374482404790375, 0.0034780858720332977
20:11:28 done sampling a new configuration.
20:11:28 HBMASTER: schedule new run for iteration 1
20:11:28 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
20:11:28 HBMASTER: submitting job (1, 0, 0) to dispatcher
20:11:28 DISPATCHER: trying to submit job (1, 0, 0)
20:11:28 DISPATCHER: trying to notify the job_runner thread.
20:11:28 HBMASTER: job (1, 0, 0) submitted to dispatcher
20:11:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:11:28 DISPATCHER: Trying to submit another job.
20:11:28 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:11:28 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:11:28 WORKER: start processing job (1, 0, 0)
20:11:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:11:28 WORKER: args: ()
20:11:28 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 885, 'last_n_outputs': 28, 'leak_rate': 0.807362833659898, 'lr': 0.0024369395721244988, 'optimizer': 'SGD', 'sparsity': 0.8816979062084708, 'steps_to_train': 20, 'weight_decay': 0.10564058283925239}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:11:36 DISPATCHER: Starting worker discovery
20:11:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:11:36 DISPATCHER: Finished worker discovery
20:12:36 DISPATCHER: Starting worker discovery
20:12:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:12:36 DISPATCHER: Finished worker discovery
20:13:36 DISPATCHER: Starting worker discovery
20:13:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:13:36 DISPATCHER: Finished worker discovery
20:13:55 WORKER: done with job (1, 0, 0), trying to register it.
20:13:55 WORKER: registered result for job (1, 0, 0) with dispatcher
20:13:55 DISPATCHER: job (1, 0, 0) finished
20:13:55 DISPATCHER: register_result: lock acquired
20:13:55 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:13:55 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 885, 'last_n_outputs': 28, 'leak_rate': 0.807362833659898, 'lr': 0.0024369395721244988, 'optimizer': 'SGD', 'sparsity': 0.8816979062084708, 'steps_to_train': 20, 'weight_decay': 0.10564058283925239}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.43115898108331385, 'info': {'music-speech': 0.43115898108331385, 'config': "{'batch_size': 64, 'hidden_dim': 885, 'last_n_outputs': 28, 'leak_rate': 0.807362833659898, 'lr': 0.0024369395721244988, 'optimizer': 'SGD', 'sparsity': 0.8816979062084708, 'steps_to_train': 20, 'weight_decay': 0.10564058283925239}"}}
exception: None

20:13:55 job_callback for (1, 0, 0) started
20:13:55 DISPATCHER: Trying to submit another job.
20:13:55 job_callback for (1, 0, 0) got condition
20:13:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:13:55 HBMASTER: Trying to run another job!
20:13:55 job_callback for (1, 0, 0) finished
20:13:55 start sampling a new configuration.
20:13:55 best_vector: [2, 0.9988084620058741, 0.19702739852801826, 0.7894863785304145, 0.4944146421739585, 1, 0.7005303559273522, 0.864848865135634, 0.03427637223920332], 0.011848345393416787, 0.1018886312943063, 0.0012072116952374355
20:13:55 done sampling a new configuration.
20:13:55 HBMASTER: schedule new run for iteration 1
20:13:55 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
20:13:55 HBMASTER: submitting job (1, 0, 1) to dispatcher
20:13:55 DISPATCHER: trying to submit job (1, 0, 1)
20:13:55 DISPATCHER: trying to notify the job_runner thread.
20:13:55 HBMASTER: job (1, 0, 1) submitted to dispatcher
20:13:55 DISPATCHER: Trying to submit another job.
20:13:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:13:55 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:13:55 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:13:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:13:55 WORKER: start processing job (1, 0, 1)
20:13:55 WORKER: args: ()
20:13:55 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 1000, 'last_n_outputs': 18, 'leak_rate': 0.9473715946326036, 'lr': 0.009746064569746115, 'optimizer': 'SGD', 'sparsity': 0.9181272854225645, 'steps_to_train': 88, 'weight_decay': 0.01108139889633244}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:14:36 DISPATCHER: Starting worker discovery
20:14:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:14:36 DISPATCHER: Finished worker discovery
20:15:36 DISPATCHER: Starting worker discovery
20:15:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:15:36 DISPATCHER: Finished worker discovery
20:16:36 DISPATCHER: Starting worker discovery
20:16:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:16:36 DISPATCHER: Finished worker discovery
20:16:45 WORKER: done with job (1, 0, 1), trying to register it.
20:16:45 DISPATCHER: job (1, 0, 1) finished
20:16:45 WORKER: registered result for job (1, 0, 1) with dispatcher
20:16:45 DISPATCHER: register_result: lock acquired
20:16:45 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:16:45 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 1000, 'last_n_outputs': 18, 'leak_rate': 0.9473715946326036, 'lr': 0.009746064569746115, 'optimizer': 'SGD', 'sparsity': 0.9181272854225645, 'steps_to_train': 88, 'weight_decay': 0.01108139889633244}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.494230955860228, 'info': {'music-speech': 0.494230955860228, 'config': "{'batch_size': 64, 'hidden_dim': 1000, 'last_n_outputs': 18, 'leak_rate': 0.9473715946326036, 'lr': 0.009746064569746115, 'optimizer': 'SGD', 'sparsity': 0.9181272854225645, 'steps_to_train': 88, 'weight_decay': 0.01108139889633244}"}}
exception: None

20:16:45 job_callback for (1, 0, 1) started
20:16:45 DISPATCHER: Trying to submit another job.
20:16:45 job_callback for (1, 0, 1) got condition
20:16:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:16:45 HBMASTER: Trying to run another job!
20:16:45 job_callback for (1, 0, 1) finished
20:16:45 start sampling a new configuration.
20:16:45 done sampling a new configuration.
20:16:45 HBMASTER: schedule new run for iteration 1
20:16:45 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
20:16:45 HBMASTER: submitting job (1, 0, 2) to dispatcher
20:16:45 DISPATCHER: trying to submit job (1, 0, 2)
20:16:45 DISPATCHER: trying to notify the job_runner thread.
20:16:45 HBMASTER: job (1, 0, 2) submitted to dispatcher
20:16:45 DISPATCHER: Trying to submit another job.
20:16:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:16:45 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:16:45 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:16:45 WORKER: start processing job (1, 0, 2)
20:16:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:16:45 WORKER: args: ()
20:16:45 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 205, 'last_n_outputs': 12, 'leak_rate': 0.8162784118852913, 'lr': 0.0071310438560569, 'optimizer': 'Adam', 'sparsity': 0.7739100528898684, 'steps_to_train': 96, 'weight_decay': 0.16110361475421703}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:17:36 DISPATCHER: Starting worker discovery
20:17:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:17:36 DISPATCHER: Finished worker discovery
20:18:36 DISPATCHER: Starting worker discovery
20:18:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:18:36 DISPATCHER: Finished worker discovery
20:19:28 WORKER: done with job (1, 0, 2), trying to register it.
20:19:28 WORKER: registered result for job (1, 0, 2) with dispatcher
20:19:28 DISPATCHER: job (1, 0, 2) finished
20:19:28 DISPATCHER: register_result: lock acquired
20:19:28 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:19:28 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 205, 'last_n_outputs': 12, 'leak_rate': 0.8162784118852913, 'lr': 0.0071310438560569, 'optimizer': 'Adam', 'sparsity': 0.7739100528898684, 'steps_to_train': 96, 'weight_decay': 0.16110361475421703}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.451348665402842, 'info': {'music-speech': 0.451348665402842, 'config': "{'batch_size': 128, 'hidden_dim': 205, 'last_n_outputs': 12, 'leak_rate': 0.8162784118852913, 'lr': 0.0071310438560569, 'optimizer': 'Adam', 'sparsity': 0.7739100528898684, 'steps_to_train': 96, 'weight_decay': 0.16110361475421703}"}}
exception: None

20:19:28 job_callback for (1, 0, 2) started
20:19:28 job_callback for (1, 0, 2) got condition
20:19:28 DISPATCHER: Trying to submit another job.
20:19:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:19:28 HBMASTER: Trying to run another job!
20:19:28 job_callback for (1, 0, 2) finished
20:19:28 start sampling a new configuration.
20:19:28 best_vector: [0, 0.48751367331036977, 0.22215144065702466, 0.22478383018860368, 0.05393856441949996, 0, 0.3252618906029579, 0.07611867455076687, 0.12693701665774132], 0.014706604956455064, 0.11801470401439176, 0.0017355956309926313
20:19:28 done sampling a new configuration.
20:19:28 HBMASTER: schedule new run for iteration 1
20:19:28 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
20:19:28 HBMASTER: submitting job (1, 0, 3) to dispatcher
20:19:28 DISPATCHER: trying to submit job (1, 0, 3)
20:19:28 DISPATCHER: trying to notify the job_runner thread.
20:19:28 HBMASTER: job (1, 0, 3) submitted to dispatcher
20:19:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:19:28 DISPATCHER: Trying to submit another job.
20:19:28 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:19:28 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:19:28 WORKER: start processing job (1, 0, 3)
20:19:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:19:28 WORKER: args: ()
20:19:28 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 590, 'last_n_outputs': 19, 'leak_rate': 0.8061959575471509, 'lr': 0.001281967835332723, 'optimizer': 'Adam', 'sparsity': 0.8280628537447099, 'steps_to_train': 16, 'weight_decay': 0.014626784613150545}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:19:36 DISPATCHER: Starting worker discovery
20:19:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:19:36 DISPATCHER: Finished worker discovery
20:20:36 DISPATCHER: Starting worker discovery
20:20:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:20:36 DISPATCHER: Finished worker discovery
20:21:36 DISPATCHER: Starting worker discovery
20:21:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:21:36 DISPATCHER: Finished worker discovery
20:21:51 WORKER: done with job (1, 0, 3), trying to register it.
20:21:51 WORKER: registered result for job (1, 0, 3) with dispatcher
20:21:51 DISPATCHER: job (1, 0, 3) finished
20:21:51 DISPATCHER: register_result: lock acquired
20:21:51 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:21:51 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 590, 'last_n_outputs': 19, 'leak_rate': 0.8061959575471509, 'lr': 0.001281967835332723, 'optimizer': 'Adam', 'sparsity': 0.8280628537447099, 'steps_to_train': 16, 'weight_decay': 0.014626784613150545}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.46857243268074134, 'info': {'music-speech': 0.46857243268074134, 'config': "{'batch_size': 16, 'hidden_dim': 590, 'last_n_outputs': 19, 'leak_rate': 0.8061959575471509, 'lr': 0.001281967835332723, 'optimizer': 'Adam', 'sparsity': 0.8280628537447099, 'steps_to_train': 16, 'weight_decay': 0.014626784613150545}"}}
exception: None

20:21:51 job_callback for (1, 0, 3) started
20:21:51 DISPATCHER: Trying to submit another job.
20:21:51 job_callback for (1, 0, 3) got condition
20:21:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:21:51 HBMASTER: Trying to run another job!
20:21:51 job_callback for (1, 0, 3) finished
20:21:51 start sampling a new configuration.
20:21:51 best_vector: [3, 0.5098341022942973, 0.46268703322253785, 0.6247371867647427, 0.15601678408651928, 1, 0.5529683003676444, 0.4198483994884836, 0.9361589233884964], 0.02182215985002976, 0.2987645072798022, 0.006519686835375223
20:21:51 done sampling a new configuration.
20:21:51 HBMASTER: schedule new run for iteration 1
20:21:51 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
20:21:51 HBMASTER: submitting job (1, 0, 4) to dispatcher
20:21:51 DISPATCHER: trying to submit job (1, 0, 4)
20:21:51 DISPATCHER: trying to notify the job_runner thread.
20:21:51 HBMASTER: job (1, 0, 4) submitted to dispatcher
20:21:51 DISPATCHER: Trying to submit another job.
20:21:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:21:51 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:21:51 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:21:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:21:51 WORKER: start processing job (1, 0, 4)
20:21:51 WORKER: args: ()
20:21:51 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 608, 'last_n_outputs': 28, 'leak_rate': 0.9061842966911857, 'lr': 0.0020513207266102227, 'optimizer': 'SGD', 'sparsity': 0.8827123920882347, 'steps_to_train': 48, 'weight_decay': 0.16518508837921902}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:22:36 DISPATCHER: Starting worker discovery
20:22:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:22:36 DISPATCHER: Finished worker discovery
20:23:36 DISPATCHER: Starting worker discovery
20:23:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:23:36 DISPATCHER: Finished worker discovery
20:24:31 WORKER: done with job (1, 0, 4), trying to register it.
20:24:31 WORKER: registered result for job (1, 0, 4) with dispatcher
20:24:31 DISPATCHER: job (1, 0, 4) finished
20:24:31 DISPATCHER: register_result: lock acquired
20:24:31 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:24:31 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 608, 'last_n_outputs': 28, 'leak_rate': 0.9061842966911857, 'lr': 0.0020513207266102227, 'optimizer': 'SGD', 'sparsity': 0.8827123920882347, 'steps_to_train': 48, 'weight_decay': 0.16518508837921902}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4457502138273456, 'info': {'music-speech': 0.4457502138273456, 'config': "{'batch_size': 128, 'hidden_dim': 608, 'last_n_outputs': 28, 'leak_rate': 0.9061842966911857, 'lr': 0.0020513207266102227, 'optimizer': 'SGD', 'sparsity': 0.8827123920882347, 'steps_to_train': 48, 'weight_decay': 0.16518508837921902}"}}
exception: None

20:24:31 job_callback for (1, 0, 4) started
20:24:31 job_callback for (1, 0, 4) got condition
20:24:31 DISPATCHER: Trying to submit another job.
20:24:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:24:31 HBMASTER: Trying to run another job!
20:24:31 job_callback for (1, 0, 4) finished
20:24:31 start sampling a new configuration.
20:24:31 best_vector: [2, 0.9751143059898011, 0.4994788122887572, 0.08204215956811406, 0.41301678846599416, 0, 0.9442266565102603, 0.10010111468908597, 0.8431198514847046], 0.004074385061908408, 0.29208311905498857, 0.0011900590971132604
20:24:31 done sampling a new configuration.
20:24:31 HBMASTER: schedule new run for iteration 1
20:24:31 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
20:24:31 HBMASTER: submitting job (1, 0, 5) to dispatcher
20:24:31 DISPATCHER: trying to submit job (1, 0, 5)
20:24:31 DISPATCHER: trying to notify the job_runner thread.
20:24:31 HBMASTER: job (1, 0, 5) submitted to dispatcher
20:24:31 DISPATCHER: Trying to submit another job.
20:24:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:24:31 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:24:31 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:24:31 WORKER: start processing job (1, 0, 5)
20:24:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:24:31 WORKER: args: ()
20:24:31 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 981, 'last_n_outputs': 30, 'leak_rate': 0.7705105398920286, 'lr': 0.006699364027052426, 'optimizer': 'Adam', 'sparsity': 0.9766143975624625, 'steps_to_train': 19, 'weight_decay': 0.12500408822416811}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:24:36 DISPATCHER: Starting worker discovery
20:24:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:24:36 DISPATCHER: Finished worker discovery
20:25:36 DISPATCHER: Starting worker discovery
20:25:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:25:36 DISPATCHER: Finished worker discovery
20:26:36 DISPATCHER: Starting worker discovery
20:26:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:26:36 DISPATCHER: Finished worker discovery
20:26:57 WORKER: done with job (1, 0, 5), trying to register it.
20:26:57 DISPATCHER: job (1, 0, 5) finished
20:26:57 WORKER: registered result for job (1, 0, 5) with dispatcher
20:26:57 DISPATCHER: register_result: lock acquired
20:26:57 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:26:57 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 981, 'last_n_outputs': 30, 'leak_rate': 0.7705105398920286, 'lr': 0.006699364027052426, 'optimizer': 'Adam', 'sparsity': 0.9766143975624625, 'steps_to_train': 19, 'weight_decay': 0.12500408822416811}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4932580991646566, 'info': {'music-speech': 0.4932580991646566, 'config': "{'batch_size': 64, 'hidden_dim': 981, 'last_n_outputs': 30, 'leak_rate': 0.7705105398920286, 'lr': 0.006699364027052426, 'optimizer': 'Adam', 'sparsity': 0.9766143975624625, 'steps_to_train': 19, 'weight_decay': 0.12500408822416811}"}}
exception: None

20:26:57 job_callback for (1, 0, 5) started
20:26:57 DISPATCHER: Trying to submit another job.
20:26:57 job_callback for (1, 0, 5) got condition
20:26:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:26:57 HBMASTER: Trying to run another job!
20:26:57 job_callback for (1, 0, 5) finished
20:26:57 start sampling a new configuration.
20:26:57 best_vector: [2, 0.6134981936408089, 0.17909479044160137, 0.1272266337098575, 0.08399748812222718, 0, 0.20859892205294195, 0.3130699514425463, 0.03927473744664711], 0.008011677905916581, 0.2662893692042612, 0.002133424655834243
20:26:57 done sampling a new configuration.
20:26:57 HBMASTER: schedule new run for iteration 1
20:26:57 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
20:26:57 HBMASTER: submitting job (1, 0, 6) to dispatcher
20:26:57 DISPATCHER: trying to submit job (1, 0, 6)
20:26:57 DISPATCHER: trying to notify the job_runner thread.
20:26:57 HBMASTER: job (1, 0, 6) submitted to dispatcher
20:26:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:26:57 DISPATCHER: Trying to submit another job.
20:26:57 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:26:57 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:26:57 WORKER: start processing job (1, 0, 6)
20:26:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:26:57 WORKER: args: ()
20:26:57 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 691, 'last_n_outputs': 17, 'leak_rate': 0.7818066584274643, 'lr': 0.0014722954713728576, 'optimizer': 'Adam', 'sparsity': 0.8000637412927061, 'steps_to_train': 38, 'weight_decay': 0.01124857767195829}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:27:36 DISPATCHER: Starting worker discovery
20:27:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:27:36 DISPATCHER: Finished worker discovery
20:28:36 DISPATCHER: Starting worker discovery
20:28:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:28:36 DISPATCHER: Finished worker discovery
20:29:19 WORKER: done with job (1, 0, 6), trying to register it.
20:29:19 WORKER: registered result for job (1, 0, 6) with dispatcher
20:29:19 DISPATCHER: job (1, 0, 6) finished
20:29:19 DISPATCHER: register_result: lock acquired
20:29:19 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:29:19 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 691, 'last_n_outputs': 17, 'leak_rate': 0.7818066584274643, 'lr': 0.0014722954713728576, 'optimizer': 'Adam', 'sparsity': 0.8000637412927061, 'steps_to_train': 38, 'weight_decay': 0.01124857767195829}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6015918137498298, 'info': {'music-speech': 0.6015918137498298, 'config': "{'batch_size': 64, 'hidden_dim': 691, 'last_n_outputs': 17, 'leak_rate': 0.7818066584274643, 'lr': 0.0014722954713728576, 'optimizer': 'Adam', 'sparsity': 0.8000637412927061, 'steps_to_train': 38, 'weight_decay': 0.01124857767195829}"}}
exception: None

20:29:19 job_callback for (1, 0, 6) started
20:29:19 DISPATCHER: Trying to submit another job.
20:29:19 job_callback for (1, 0, 6) got condition
20:29:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:29:19 HBMASTER: Trying to run another job!
20:29:19 job_callback for (1, 0, 6) finished
20:29:19 start sampling a new configuration.
20:29:19 best_vector: [2, 0.4684917664610154, 0.040865653461756635, 0.20480094343632882, 0.09724267530890388, 0, 0.5742692395387332, 0.20040570193335872, 0.8564193058178868], 0.03799760155304546, 0.04922708114810966, 0.0018705110150853068
20:29:19 done sampling a new configuration.
20:29:19 HBMASTER: schedule new run for iteration 1
20:29:19 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
20:29:19 HBMASTER: submitting job (1, 0, 7) to dispatcher
20:29:19 DISPATCHER: trying to submit job (1, 0, 7)
20:29:19 DISPATCHER: trying to notify the job_runner thread.
20:29:19 HBMASTER: job (1, 0, 7) submitted to dispatcher
20:29:19 DISPATCHER: Trying to submit another job.
20:29:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:29:19 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:29:19 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:29:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:29:19 WORKER: start processing job (1, 0, 7)
20:29:19 WORKER: args: ()
20:29:19 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 575, 'last_n_outputs': 11, 'leak_rate': 0.8012002358590822, 'lr': 0.0015648955321406603, 'optimizer': 'Adam', 'sparsity': 0.887824617489296, 'steps_to_train': 28, 'weight_decay': 0.13008499534064571}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:29:36 DISPATCHER: Starting worker discovery
20:29:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:29:36 DISPATCHER: Finished worker discovery
20:30:36 DISPATCHER: Starting worker discovery
20:30:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:30:36 DISPATCHER: Finished worker discovery
20:31:36 DISPATCHER: Starting worker discovery
20:31:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:31:36 DISPATCHER: Finished worker discovery
20:31:49 WORKER: done with job (1, 0, 7), trying to register it.
20:31:49 DISPATCHER: job (1, 0, 7) finished
20:31:49 WORKER: registered result for job (1, 0, 7) with dispatcher
20:31:49 DISPATCHER: register_result: lock acquired
20:31:49 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:31:49 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 575, 'last_n_outputs': 11, 'leak_rate': 0.8012002358590822, 'lr': 0.0015648955321406603, 'optimizer': 'Adam', 'sparsity': 0.887824617489296, 'steps_to_train': 28, 'weight_decay': 0.13008499534064571}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.475650797137868, 'info': {'music-speech': 0.475650797137868, 'config': "{'batch_size': 64, 'hidden_dim': 575, 'last_n_outputs': 11, 'leak_rate': 0.8012002358590822, 'lr': 0.0015648955321406603, 'optimizer': 'Adam', 'sparsity': 0.887824617489296, 'steps_to_train': 28, 'weight_decay': 0.13008499534064571}"}}
exception: None

20:31:49 job_callback for (1, 0, 7) started
20:31:49 DISPATCHER: Trying to submit another job.
20:31:49 job_callback for (1, 0, 7) got condition
20:31:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:31:49 HBMASTER: Trying to run another job!
20:31:49 job_callback for (1, 0, 7) finished
20:31:49 start sampling a new configuration.
20:31:49 done sampling a new configuration.
20:31:49 HBMASTER: schedule new run for iteration 1
20:31:49 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
20:31:49 HBMASTER: submitting job (1, 0, 8) to dispatcher
20:31:49 DISPATCHER: trying to submit job (1, 0, 8)
20:31:49 DISPATCHER: trying to notify the job_runner thread.
20:31:49 HBMASTER: job (1, 0, 8) submitted to dispatcher
20:31:49 DISPATCHER: Trying to submit another job.
20:31:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:31:49 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:31:49 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:31:49 WORKER: start processing job (1, 0, 8)
20:31:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:31:49 WORKER: args: ()
20:31:49 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 789, 'last_n_outputs': 19, 'leak_rate': 0.7884990420615097, 'lr': 0.020842459813042474, 'optimizer': 'SGD', 'sparsity': 0.8610405911051642, 'steps_to_train': 59, 'weight_decay': 0.07999441137483941}, 'budget': 133.33333333333331, 'working_directory': '.'}
20:32:36 DISPATCHER: Starting worker discovery
20:32:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:32:36 DISPATCHER: Finished worker discovery
20:33:36 DISPATCHER: Starting worker discovery
20:33:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:33:36 DISPATCHER: Finished worker discovery
20:34:18 WORKER: done with job (1, 0, 8), trying to register it.
20:34:18 DISPATCHER: job (1, 0, 8) finished
20:34:18 WORKER: registered result for job (1, 0, 8) with dispatcher
20:34:18 DISPATCHER: register_result: lock acquired
20:34:18 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:34:18 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 789, 'last_n_outputs': 19, 'leak_rate': 0.7884990420615097, 'lr': 0.020842459813042474, 'optimizer': 'SGD', 'sparsity': 0.8610405911051642, 'steps_to_train': 59, 'weight_decay': 0.07999441137483941}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.36952825573045833, 'info': {'music-speech': 0.36952825573045833, 'config': "{'batch_size': 32, 'hidden_dim': 789, 'last_n_outputs': 19, 'leak_rate': 0.7884990420615097, 'lr': 0.020842459813042474, 'optimizer': 'SGD', 'sparsity': 0.8610405911051642, 'steps_to_train': 59, 'weight_decay': 0.07999441137483941}"}}
exception: None

20:34:18 job_callback for (1, 0, 8) started
20:34:18 job_callback for (1, 0, 8) got condition
20:34:18 DISPATCHER: Trying to submit another job.
20:34:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:34:18 HBMASTER: Trying to run another job!
20:34:18 job_callback for (1, 0, 8) finished
20:34:18 ITERATION: Advancing config (1, 0, 1) to next budget 400.000000
20:34:18 ITERATION: Advancing config (1, 0, 5) to next budget 400.000000
20:34:18 ITERATION: Advancing config (1, 0, 6) to next budget 400.000000
20:34:18 HBMASTER: schedule new run for iteration 1
20:34:18 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
20:34:18 HBMASTER: submitting job (1, 0, 1) to dispatcher
20:34:18 DISPATCHER: trying to submit job (1, 0, 1)
20:34:18 DISPATCHER: trying to notify the job_runner thread.
20:34:18 HBMASTER: job (1, 0, 1) submitted to dispatcher
20:34:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:34:18 DISPATCHER: Trying to submit another job.
20:34:18 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:34:18 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:34:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:34:18 WORKER: start processing job (1, 0, 1)
20:34:18 WORKER: args: ()
20:34:18 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 1000, 'last_n_outputs': 18, 'leak_rate': 0.9473715946326036, 'lr': 0.009746064569746115, 'optimizer': 'SGD', 'sparsity': 0.9181272854225645, 'steps_to_train': 88, 'weight_decay': 0.01108139889633244}, 'budget': 400.0, 'working_directory': '.'}
20:34:36 DISPATCHER: Starting worker discovery
20:34:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:34:36 DISPATCHER: Finished worker discovery
20:35:36 DISPATCHER: Starting worker discovery
20:35:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:35:36 DISPATCHER: Finished worker discovery
20:36:36 DISPATCHER: Starting worker discovery
20:36:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:36:36 DISPATCHER: Finished worker discovery
20:37:36 DISPATCHER: Starting worker discovery
20:37:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:37:36 DISPATCHER: Finished worker discovery
20:38:36 DISPATCHER: Starting worker discovery
20:38:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:38:36 DISPATCHER: Finished worker discovery
20:39:36 DISPATCHER: Starting worker discovery
20:39:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:39:36 DISPATCHER: Finished worker discovery
20:40:36 DISPATCHER: Starting worker discovery
20:40:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:40:36 DISPATCHER: Finished worker discovery
20:41:15 WORKER: done with job (1, 0, 1), trying to register it.
20:41:15 WORKER: registered result for job (1, 0, 1) with dispatcher
20:41:15 DISPATCHER: job (1, 0, 1) finished
20:41:15 DISPATCHER: register_result: lock acquired
20:41:15 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:41:15 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 1000, 'last_n_outputs': 18, 'leak_rate': 0.9473715946326036, 'lr': 0.009746064569746115, 'optimizer': 'SGD', 'sparsity': 0.9181272854225645, 'steps_to_train': 88, 'weight_decay': 0.01108139889633244}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4774695131926291, 'info': {'music-speech': 0.4774695131926291, 'config': "{'batch_size': 64, 'hidden_dim': 1000, 'last_n_outputs': 18, 'leak_rate': 0.9473715946326036, 'lr': 0.009746064569746115, 'optimizer': 'SGD', 'sparsity': 0.9181272854225645, 'steps_to_train': 88, 'weight_decay': 0.01108139889633244}"}}
exception: None

20:41:15 job_callback for (1, 0, 1) started
20:41:15 DISPATCHER: Trying to submit another job.
20:41:15 job_callback for (1, 0, 1) got condition
20:41:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:41:15 Only 4 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
20:41:15 HBMASTER: Trying to run another job!
20:41:15 job_callback for (1, 0, 1) finished
20:41:15 HBMASTER: schedule new run for iteration 1
20:41:15 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
20:41:15 HBMASTER: submitting job (1, 0, 5) to dispatcher
20:41:15 DISPATCHER: trying to submit job (1, 0, 5)
20:41:15 DISPATCHER: trying to notify the job_runner thread.
20:41:15 HBMASTER: job (1, 0, 5) submitted to dispatcher
20:41:15 DISPATCHER: Trying to submit another job.
20:41:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:41:15 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:41:15 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:41:15 WORKER: start processing job (1, 0, 5)
20:41:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:41:15 WORKER: args: ()
20:41:15 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 981, 'last_n_outputs': 30, 'leak_rate': 0.7705105398920286, 'lr': 0.006699364027052426, 'optimizer': 'Adam', 'sparsity': 0.9766143975624625, 'steps_to_train': 19, 'weight_decay': 0.12500408822416811}, 'budget': 400.0, 'working_directory': '.'}
20:41:36 DISPATCHER: Starting worker discovery
20:41:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:41:36 DISPATCHER: Finished worker discovery
20:42:36 DISPATCHER: Starting worker discovery
20:42:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:42:36 DISPATCHER: Finished worker discovery
20:43:36 DISPATCHER: Starting worker discovery
20:43:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:43:36 DISPATCHER: Finished worker discovery
20:44:36 DISPATCHER: Starting worker discovery
20:44:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:44:36 DISPATCHER: Finished worker discovery
20:45:36 DISPATCHER: Starting worker discovery
20:45:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:45:36 DISPATCHER: Finished worker discovery
20:46:36 DISPATCHER: Starting worker discovery
20:46:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:46:36 DISPATCHER: Finished worker discovery
20:47:36 DISPATCHER: Starting worker discovery
20:47:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:47:36 DISPATCHER: Finished worker discovery
20:48:08 WORKER: done with job (1, 0, 5), trying to register it.
20:48:08 WORKER: registered result for job (1, 0, 5) with dispatcher
20:48:08 DISPATCHER: job (1, 0, 5) finished
20:48:08 DISPATCHER: register_result: lock acquired
20:48:08 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:48:08 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 981, 'last_n_outputs': 30, 'leak_rate': 0.7705105398920286, 'lr': 0.006699364027052426, 'optimizer': 'Adam', 'sparsity': 0.9766143975624625, 'steps_to_train': 19, 'weight_decay': 0.12500408822416811}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4331418250913535, 'info': {'music-speech': 0.4331418250913535, 'config': "{'batch_size': 64, 'hidden_dim': 981, 'last_n_outputs': 30, 'leak_rate': 0.7705105398920286, 'lr': 0.006699364027052426, 'optimizer': 'Adam', 'sparsity': 0.9766143975624625, 'steps_to_train': 19, 'weight_decay': 0.12500408822416811}"}}
exception: None

20:48:08 job_callback for (1, 0, 5) started
20:48:08 job_callback for (1, 0, 5) got condition
20:48:08 DISPATCHER: Trying to submit another job.
20:48:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:48:08 Only 5 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
20:48:08 HBMASTER: Trying to run another job!
20:48:08 job_callback for (1, 0, 5) finished
20:48:08 HBMASTER: schedule new run for iteration 1
20:48:08 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
20:48:08 HBMASTER: submitting job (1, 0, 6) to dispatcher
20:48:08 DISPATCHER: trying to submit job (1, 0, 6)
20:48:08 DISPATCHER: trying to notify the job_runner thread.
20:48:08 HBMASTER: job (1, 0, 6) submitted to dispatcher
20:48:08 DISPATCHER: Trying to submit another job.
20:48:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:48:08 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:48:08 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:48:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:48:08 WORKER: start processing job (1, 0, 6)
20:48:08 WORKER: args: ()
20:48:08 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 691, 'last_n_outputs': 17, 'leak_rate': 0.7818066584274643, 'lr': 0.0014722954713728576, 'optimizer': 'Adam', 'sparsity': 0.8000637412927061, 'steps_to_train': 38, 'weight_decay': 0.01124857767195829}, 'budget': 400.0, 'working_directory': '.'}
20:48:36 DISPATCHER: Starting worker discovery
20:48:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:48:36 DISPATCHER: Finished worker discovery
20:49:36 DISPATCHER: Starting worker discovery
20:49:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:49:36 DISPATCHER: Finished worker discovery
20:50:36 DISPATCHER: Starting worker discovery
20:50:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:50:36 DISPATCHER: Finished worker discovery
20:51:36 DISPATCHER: Starting worker discovery
20:51:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:51:36 DISPATCHER: Finished worker discovery
20:52:36 DISPATCHER: Starting worker discovery
20:52:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:52:36 DISPATCHER: Finished worker discovery
20:53:36 DISPATCHER: Starting worker discovery
20:53:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:53:36 DISPATCHER: Finished worker discovery
20:54:36 DISPATCHER: Starting worker discovery
20:54:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:54:36 DISPATCHER: Finished worker discovery
20:55:02 WORKER: done with job (1, 0, 6), trying to register it.
20:55:02 WORKER: registered result for job (1, 0, 6) with dispatcher
20:55:02 DISPATCHER: job (1, 0, 6) finished
20:55:02 DISPATCHER: register_result: lock acquired
20:55:02 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:55:02 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 691, 'last_n_outputs': 17, 'leak_rate': 0.7818066584274643, 'lr': 0.0014722954713728576, 'optimizer': 'Adam', 'sparsity': 0.8000637412927061, 'steps_to_train': 38, 'weight_decay': 0.01124857767195829}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3718763538374987, 'info': {'music-speech': 0.3718763538374987, 'config': "{'batch_size': 64, 'hidden_dim': 691, 'last_n_outputs': 17, 'leak_rate': 0.7818066584274643, 'lr': 0.0014722954713728576, 'optimizer': 'Adam', 'sparsity': 0.8000637412927061, 'steps_to_train': 38, 'weight_decay': 0.01124857767195829}"}}
exception: None

20:55:02 job_callback for (1, 0, 6) started
20:55:02 DISPATCHER: Trying to submit another job.
20:55:02 job_callback for (1, 0, 6) got condition
20:55:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:55:02 Only 6 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
20:55:02 HBMASTER: Trying to run another job!
20:55:02 job_callback for (1, 0, 6) finished
20:55:02 ITERATION: Advancing config (1, 0, 1) to next budget 1200.000000
20:55:02 HBMASTER: schedule new run for iteration 1
20:55:02 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
20:55:02 HBMASTER: submitting job (1, 0, 1) to dispatcher
20:55:02 DISPATCHER: trying to submit job (1, 0, 1)
20:55:02 DISPATCHER: trying to notify the job_runner thread.
20:55:02 HBMASTER: job (1, 0, 1) submitted to dispatcher
20:55:02 DISPATCHER: Trying to submit another job.
20:55:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:55:02 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:55:02 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:55:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:55:02 WORKER: start processing job (1, 0, 1)
20:55:02 WORKER: args: ()
20:55:02 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 1000, 'last_n_outputs': 18, 'leak_rate': 0.9473715946326036, 'lr': 0.009746064569746115, 'optimizer': 'SGD', 'sparsity': 0.9181272854225645, 'steps_to_train': 88, 'weight_decay': 0.01108139889633244}, 'budget': 1200.0, 'working_directory': '.'}
20:55:36 DISPATCHER: Starting worker discovery
20:55:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:55:36 DISPATCHER: Finished worker discovery
20:56:36 DISPATCHER: Starting worker discovery
20:56:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:56:36 DISPATCHER: Finished worker discovery
20:57:36 DISPATCHER: Starting worker discovery
20:57:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:57:36 DISPATCHER: Finished worker discovery
20:58:36 DISPATCHER: Starting worker discovery
20:58:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:58:36 DISPATCHER: Finished worker discovery
20:59:36 DISPATCHER: Starting worker discovery
20:59:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:59:36 DISPATCHER: Finished worker discovery
21:00:36 DISPATCHER: Starting worker discovery
21:00:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:00:36 DISPATCHER: Finished worker discovery
21:01:36 DISPATCHER: Starting worker discovery
21:01:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:01:36 DISPATCHER: Finished worker discovery
21:02:36 DISPATCHER: Starting worker discovery
21:02:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:02:36 DISPATCHER: Finished worker discovery
21:03:36 DISPATCHER: Starting worker discovery
21:03:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:03:36 DISPATCHER: Finished worker discovery
21:04:36 DISPATCHER: Starting worker discovery
21:04:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:04:36 DISPATCHER: Finished worker discovery
21:05:36 DISPATCHER: Starting worker discovery
21:05:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:05:36 DISPATCHER: Finished worker discovery
21:06:36 DISPATCHER: Starting worker discovery
21:06:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:06:37 DISPATCHER: Finished worker discovery
21:07:37 DISPATCHER: Starting worker discovery
21:07:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:07:37 DISPATCHER: Finished worker discovery
21:08:37 DISPATCHER: Starting worker discovery
21:08:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:08:37 DISPATCHER: Finished worker discovery
21:09:37 DISPATCHER: Starting worker discovery
21:09:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:09:37 DISPATCHER: Finished worker discovery
21:10:37 DISPATCHER: Starting worker discovery
21:10:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:10:37 DISPATCHER: Finished worker discovery
21:11:37 DISPATCHER: Starting worker discovery
21:11:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:11:37 DISPATCHER: Finished worker discovery
21:12:37 DISPATCHER: Starting worker discovery
21:12:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:12:37 DISPATCHER: Finished worker discovery
21:13:37 DISPATCHER: Starting worker discovery
21:13:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:13:37 DISPATCHER: Finished worker discovery
21:14:37 DISPATCHER: Starting worker discovery
21:14:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:14:37 DISPATCHER: Finished worker discovery
21:15:37 WORKER: done with job (1, 0, 1), trying to register it.
21:15:37 WORKER: registered result for job (1, 0, 1) with dispatcher
21:15:37 DISPATCHER: job (1, 0, 1) finished
21:15:37 DISPATCHER: register_result: lock acquired
21:15:37 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
21:15:37 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 1000, 'last_n_outputs': 18, 'leak_rate': 0.9473715946326036, 'lr': 0.009746064569746115, 'optimizer': 'SGD', 'sparsity': 0.9181272854225645, 'steps_to_train': 88, 'weight_decay': 0.01108139889633244}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.43060048289930297, 'info': {'music-speech': 0.43060048289930297, 'config': "{'batch_size': 64, 'hidden_dim': 1000, 'last_n_outputs': 18, 'leak_rate': 0.9473715946326036, 'lr': 0.009746064569746115, 'optimizer': 'SGD', 'sparsity': 0.9181272854225645, 'steps_to_train': 88, 'weight_decay': 0.01108139889633244}"}}
exception: None

21:15:37 job_callback for (1, 0, 1) started
21:15:37 DISPATCHER: Trying to submit another job.
21:15:37 job_callback for (1, 0, 1) got condition
21:15:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:15:37 Only 2 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
21:15:37 HBMASTER: Trying to run another job!
21:15:37 job_callback for (1, 0, 1) finished
21:15:37 start sampling a new configuration.
21:15:37 done sampling a new configuration.
21:15:37 HBMASTER: schedule new run for iteration 2
21:15:37 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
21:15:37 HBMASTER: submitting job (2, 0, 0) to dispatcher
21:15:37 DISPATCHER: trying to submit job (2, 0, 0)
21:15:37 DISPATCHER: trying to notify the job_runner thread.
21:15:37 HBMASTER: job (2, 0, 0) submitted to dispatcher
21:15:37 DISPATCHER: Trying to submit another job.
21:15:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:15:37 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
21:15:37 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
21:15:37 WORKER: start processing job (2, 0, 0)
21:15:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:15:37 WORKER: args: ()
21:15:37 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 309, 'last_n_outputs': 49, 'leak_rate': 0.823676323770884, 'lr': 0.0026432772950619444, 'optimizer': 'Adam', 'sparsity': 0.8755900591171255, 'steps_to_train': 50, 'weight_decay': 0.014651356531093453}, 'budget': 400.0, 'working_directory': '.'}
21:15:37 DISPATCHER: Starting worker discovery
21:15:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:15:37 DISPATCHER: Finished worker discovery
21:16:37 DISPATCHER: Starting worker discovery
21:16:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:16:37 DISPATCHER: Finished worker discovery
21:17:37 DISPATCHER: Starting worker discovery
21:17:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:17:37 DISPATCHER: Finished worker discovery
21:18:37 DISPATCHER: Starting worker discovery
21:18:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:18:37 DISPATCHER: Finished worker discovery
21:19:37 DISPATCHER: Starting worker discovery
21:19:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:19:37 DISPATCHER: Finished worker discovery
21:20:37 DISPATCHER: Starting worker discovery
21:20:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:20:37 DISPATCHER: Finished worker discovery
21:21:37 DISPATCHER: Starting worker discovery
21:21:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:21:37 DISPATCHER: Finished worker discovery
21:22:27 WORKER: done with job (2, 0, 0), trying to register it.
21:22:27 DISPATCHER: job (2, 0, 0) finished
21:22:27 WORKER: registered result for job (2, 0, 0) with dispatcher
21:22:27 DISPATCHER: register_result: lock acquired
21:22:27 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
21:22:27 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 309, 'last_n_outputs': 49, 'leak_rate': 0.823676323770884, 'lr': 0.0026432772950619444, 'optimizer': 'Adam', 'sparsity': 0.8755900591171255, 'steps_to_train': 50, 'weight_decay': 0.014651356531093453}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5329147592093032, 'info': {'music-speech': 0.5329147592093032, 'config': "{'batch_size': 32, 'hidden_dim': 309, 'last_n_outputs': 49, 'leak_rate': 0.823676323770884, 'lr': 0.0026432772950619444, 'optimizer': 'Adam', 'sparsity': 0.8755900591171255, 'steps_to_train': 50, 'weight_decay': 0.014651356531093453}"}}
exception: None

21:22:27 job_callback for (2, 0, 0) started
21:22:27 job_callback for (2, 0, 0) got condition
21:22:27 DISPATCHER: Trying to submit another job.
21:22:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:22:27 Only 7 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
21:22:27 HBMASTER: Trying to run another job!
21:22:27 job_callback for (2, 0, 0) finished
21:22:27 start sampling a new configuration.
21:22:27 best_vector: [3, 0.7075366185839729, 0.5437933126827923, 0.3922225088450302, 0.08304858460953388, 0, 0.5429459662718688, 0.144935182191821, 0.7868753791082952], 0.02184991451053811, 0.15378776373733472, 0.003360249490427596
21:22:27 done sampling a new configuration.
21:22:27 HBMASTER: schedule new run for iteration 2
21:22:27 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
21:22:27 HBMASTER: submitting job (2, 0, 1) to dispatcher
21:22:27 DISPATCHER: trying to submit job (2, 0, 1)
21:22:27 DISPATCHER: trying to notify the job_runner thread.
21:22:27 HBMASTER: job (2, 0, 1) submitted to dispatcher
21:22:27 DISPATCHER: Trying to submit another job.
21:22:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:22:27 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
21:22:27 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
21:22:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:22:27 WORKER: start processing job (2, 0, 1)
21:22:27 WORKER: args: ()
21:22:27 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 766, 'last_n_outputs': 32, 'leak_rate': 0.8480556272112576, 'lr': 0.0014658757798944378, 'optimizer': 'Adam', 'sparsity': 0.8803070319052485, 'steps_to_train': 23, 'weight_decay': 0.10562056128465597}, 'budget': 400.0, 'working_directory': '.'}
21:22:37 DISPATCHER: Starting worker discovery
21:22:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:22:37 DISPATCHER: Finished worker discovery
21:23:37 DISPATCHER: Starting worker discovery
21:23:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:23:37 DISPATCHER: Finished worker discovery
21:24:37 DISPATCHER: Starting worker discovery
21:24:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:24:37 DISPATCHER: Finished worker discovery
21:25:37 DISPATCHER: Starting worker discovery
21:25:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:25:37 DISPATCHER: Finished worker discovery
21:26:37 DISPATCHER: Starting worker discovery
21:26:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:26:37 DISPATCHER: Finished worker discovery
21:27:37 DISPATCHER: Starting worker discovery
21:27:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:27:37 DISPATCHER: Finished worker discovery
21:28:37 DISPATCHER: Starting worker discovery
21:28:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:28:37 DISPATCHER: Finished worker discovery
21:29:21 WORKER: done with job (2, 0, 1), trying to register it.
21:29:21 WORKER: registered result for job (2, 0, 1) with dispatcher
21:29:21 DISPATCHER: job (2, 0, 1) finished
21:29:21 DISPATCHER: register_result: lock acquired
21:29:21 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
21:29:21 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 766, 'last_n_outputs': 32, 'leak_rate': 0.8480556272112576, 'lr': 0.0014658757798944378, 'optimizer': 'Adam', 'sparsity': 0.8803070319052485, 'steps_to_train': 23, 'weight_decay': 0.10562056128465597}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3898794077259691, 'info': {'music-speech': 0.3898794077259691, 'config': "{'batch_size': 128, 'hidden_dim': 766, 'last_n_outputs': 32, 'leak_rate': 0.8480556272112576, 'lr': 0.0014658757798944378, 'optimizer': 'Adam', 'sparsity': 0.8803070319052485, 'steps_to_train': 23, 'weight_decay': 0.10562056128465597}"}}
exception: None

21:29:21 job_callback for (2, 0, 1) started
21:29:21 DISPATCHER: Trying to submit another job.
21:29:21 job_callback for (2, 0, 1) got condition
21:29:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:29:21 Only 8 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
21:29:21 HBMASTER: Trying to run another job!
21:29:21 job_callback for (2, 0, 1) finished
21:29:21 start sampling a new configuration.
21:29:21 done sampling a new configuration.
21:29:21 HBMASTER: schedule new run for iteration 2
21:29:21 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
21:29:21 HBMASTER: submitting job (2, 0, 2) to dispatcher
21:29:21 DISPATCHER: trying to submit job (2, 0, 2)
21:29:21 DISPATCHER: trying to notify the job_runner thread.
21:29:21 HBMASTER: job (2, 0, 2) submitted to dispatcher
21:29:21 DISPATCHER: Trying to submit another job.
21:29:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:29:21 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
21:29:21 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
21:29:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:29:21 WORKER: start processing job (2, 0, 2)
21:29:21 WORKER: args: ()
21:29:21 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 544, 'last_n_outputs': 24, 'leak_rate': 0.8685713702595363, 'lr': 0.0067158769040697175, 'optimizer': 'Adam', 'sparsity': 0.7739678284217361, 'steps_to_train': 28, 'weight_decay': 0.029516162300165676}, 'budget': 400.0, 'working_directory': '.'}
21:29:37 DISPATCHER: Starting worker discovery
21:29:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:29:37 DISPATCHER: Finished worker discovery
21:30:37 DISPATCHER: Starting worker discovery
21:30:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:30:37 DISPATCHER: Finished worker discovery
21:31:37 DISPATCHER: Starting worker discovery
21:31:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:31:37 DISPATCHER: Finished worker discovery
21:32:37 DISPATCHER: Starting worker discovery
21:32:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:32:37 DISPATCHER: Finished worker discovery
21:33:37 DISPATCHER: Starting worker discovery
21:33:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:33:37 DISPATCHER: Finished worker discovery
21:34:37 DISPATCHER: Starting worker discovery
21:34:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:34:37 DISPATCHER: Finished worker discovery
21:35:37 DISPATCHER: Starting worker discovery
21:35:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:35:37 DISPATCHER: Finished worker discovery
21:36:14 WORKER: done with job (2, 0, 2), trying to register it.
21:36:14 WORKER: registered result for job (2, 0, 2) with dispatcher
21:36:14 DISPATCHER: job (2, 0, 2) finished
21:36:14 DISPATCHER: register_result: lock acquired
21:36:14 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
21:36:14 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 544, 'last_n_outputs': 24, 'leak_rate': 0.8685713702595363, 'lr': 0.0067158769040697175, 'optimizer': 'Adam', 'sparsity': 0.7739678284217361, 'steps_to_train': 28, 'weight_decay': 0.029516162300165676}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5614881776360232, 'info': {'music-speech': 0.5614881776360232, 'config': "{'batch_size': 64, 'hidden_dim': 544, 'last_n_outputs': 24, 'leak_rate': 0.8685713702595363, 'lr': 0.0067158769040697175, 'optimizer': 'Adam', 'sparsity': 0.7739678284217361, 'steps_to_train': 28, 'weight_decay': 0.029516162300165676}"}}
exception: None

21:36:14 job_callback for (2, 0, 2) started
21:36:14 DISPATCHER: Trying to submit another job.
21:36:14 job_callback for (2, 0, 2) got condition
21:36:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:36:14 Only 9 run(s) for budget 400.000000 available, need more than 11 -> can't build model!
21:36:14 HBMASTER: Trying to run another job!
21:36:14 job_callback for (2, 0, 2) finished
21:36:14 start sampling a new configuration.
21:36:14 best_vector: [2, 0.953608312011161, 0.08365182865151127, 0.020424063196822606, 0.1797987820251901, 1, 0.21662199780035812, 0.5662973907404083, 0.813750631308374], 0.026991857805799897, 0.11041939520746616, 0.002980424614442349
21:36:14 done sampling a new configuration.
21:36:14 HBMASTER: schedule new run for iteration 2
21:36:14 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
21:36:14 HBMASTER: submitting job (2, 0, 3) to dispatcher
21:36:14 DISPATCHER: trying to submit job (2, 0, 3)
21:36:14 DISPATCHER: trying to notify the job_runner thread.
21:36:14 HBMASTER: job (2, 0, 3) submitted to dispatcher
21:36:14 DISPATCHER: Trying to submit another job.
21:36:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:36:14 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
21:36:14 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
21:36:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:36:14 WORKER: start processing job (2, 0, 3)
21:36:14 WORKER: args: ()
21:36:14 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 963, 'last_n_outputs': 13, 'leak_rate': 0.7551060157992057, 'lr': 0.0022887458194939007, 'optimizer': 'SGD', 'sparsity': 0.801989279472086, 'steps_to_train': 61, 'weight_decay': 0.11447587725806252}, 'budget': 400.0, 'working_directory': '.'}
21:36:37 DISPATCHER: Starting worker discovery
21:36:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:36:37 DISPATCHER: Finished worker discovery
21:37:37 DISPATCHER: Starting worker discovery
21:37:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:37:37 DISPATCHER: Finished worker discovery
21:38:37 DISPATCHER: Starting worker discovery
21:38:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:38:38 DISPATCHER: Finished worker discovery
21:39:38 DISPATCHER: Starting worker discovery
21:39:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:39:38 DISPATCHER: Finished worker discovery
21:40:38 DISPATCHER: Starting worker discovery
21:40:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:40:38 DISPATCHER: Finished worker discovery
21:41:38 DISPATCHER: Starting worker discovery
21:41:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:41:38 DISPATCHER: Finished worker discovery
21:42:38 DISPATCHER: Starting worker discovery
21:42:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:42:38 DISPATCHER: Finished worker discovery
21:43:14 WORKER: done with job (2, 0, 3), trying to register it.
21:43:14 DISPATCHER: job (2, 0, 3) finished
21:43:14 WORKER: registered result for job (2, 0, 3) with dispatcher
21:43:14 DISPATCHER: register_result: lock acquired
21:43:14 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
21:43:14 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 963, 'last_n_outputs': 13, 'leak_rate': 0.7551060157992057, 'lr': 0.0022887458194939007, 'optimizer': 'SGD', 'sparsity': 0.801989279472086, 'steps_to_train': 61, 'weight_decay': 0.11447587725806252}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.44429735600075104, 'info': {'music-speech': 0.44429735600075104, 'config': "{'batch_size': 64, 'hidden_dim': 963, 'last_n_outputs': 13, 'leak_rate': 0.7551060157992057, 'lr': 0.0022887458194939007, 'optimizer': 'SGD', 'sparsity': 0.801989279472086, 'steps_to_train': 61, 'weight_decay': 0.11447587725806252}"}}
exception: None

21:43:14 job_callback for (2, 0, 3) started
21:43:14 DISPATCHER: Trying to submit another job.
21:43:14 job_callback for (2, 0, 3) got condition
21:43:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:43:14 HBMASTER: Trying to run another job!
21:43:14 job_callback for (2, 0, 3) finished
21:43:14 start sampling a new configuration.
21:43:14 best_vector: [3, 0.5048215884715078, 0.23290373232661304, 0.739651985168202, 0.05318477232244227, 1, 0.18311428967643534, 0.2835160184556139, 0.7826504941534264], 0.019866678702063288, 0.08097557841618705, 0.001608715799108119
21:43:14 done sampling a new configuration.
21:43:14 HBMASTER: schedule new run for iteration 2
21:43:14 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
21:43:14 HBMASTER: submitting job (2, 0, 4) to dispatcher
21:43:14 DISPATCHER: trying to submit job (2, 0, 4)
21:43:14 DISPATCHER: trying to notify the job_runner thread.
21:43:14 HBMASTER: job (2, 0, 4) submitted to dispatcher
21:43:14 DISPATCHER: Trying to submit another job.
21:43:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:43:14 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
21:43:14 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
21:43:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:43:14 WORKER: start processing job (2, 0, 4)
21:43:14 WORKER: args: ()
21:43:14 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 604, 'last_n_outputs': 19, 'leak_rate': 0.9349129962920505, 'lr': 0.0012775254030234422, 'optimizer': 'SGD', 'sparsity': 0.7939474295223444, 'steps_to_train': 35, 'weight_decay': 0.10429218563983354}, 'budget': 400.0, 'working_directory': '.'}
21:43:38 DISPATCHER: Starting worker discovery
21:43:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:43:38 DISPATCHER: Finished worker discovery
21:44:38 DISPATCHER: Starting worker discovery
21:44:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:44:38 DISPATCHER: Finished worker discovery
21:45:38 DISPATCHER: Starting worker discovery
21:45:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:45:38 DISPATCHER: Finished worker discovery
21:46:38 DISPATCHER: Starting worker discovery
21:46:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:46:38 DISPATCHER: Finished worker discovery
21:47:38 DISPATCHER: Starting worker discovery
21:47:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:47:38 DISPATCHER: Finished worker discovery
21:48:38 DISPATCHER: Starting worker discovery
21:48:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:48:38 DISPATCHER: Finished worker discovery
21:49:38 DISPATCHER: Starting worker discovery
21:49:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:49:38 DISPATCHER: Finished worker discovery
21:50:05 WORKER: done with job (2, 0, 4), trying to register it.
21:50:05 WORKER: registered result for job (2, 0, 4) with dispatcher
21:50:05 DISPATCHER: job (2, 0, 4) finished
21:50:05 DISPATCHER: register_result: lock acquired
21:50:05 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
21:50:05 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 604, 'last_n_outputs': 19, 'leak_rate': 0.9349129962920505, 'lr': 0.0012775254030234422, 'optimizer': 'SGD', 'sparsity': 0.7939474295223444, 'steps_to_train': 35, 'weight_decay': 0.10429218563983354}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5138662490541548, 'info': {'music-speech': 0.5138662490541548, 'config': "{'batch_size': 128, 'hidden_dim': 604, 'last_n_outputs': 19, 'leak_rate': 0.9349129962920505, 'lr': 0.0012775254030234422, 'optimizer': 'SGD', 'sparsity': 0.7939474295223444, 'steps_to_train': 35, 'weight_decay': 0.10429218563983354}"}}
exception: None

21:50:05 job_callback for (2, 0, 4) started
21:50:05 job_callback for (2, 0, 4) got condition
21:50:05 DISPATCHER: Trying to submit another job.
21:50:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:50:05 HBMASTER: Trying to run another job!
21:50:05 job_callback for (2, 0, 4) finished
21:50:05 start sampling a new configuration.
21:50:05 best_vector: [3, 0.9093339463664593, 0.3747453397949214, 0.10317993582437457, 0.11429246914590971, 0, 0.8417225877512439, 0.380956674189203, 0.7167822670776434], 0.03582366093539443, 0.5023719381063705, 0.017996801974179574
21:50:05 done sampling a new configuration.
21:50:05 HBMASTER: schedule new run for iteration 2
21:50:05 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
21:50:05 HBMASTER: submitting job (2, 0, 5) to dispatcher
21:50:05 DISPATCHER: trying to submit job (2, 0, 5)
21:50:05 DISPATCHER: trying to notify the job_runner thread.
21:50:05 HBMASTER: job (2, 0, 5) submitted to dispatcher
21:50:05 DISPATCHER: Trying to submit another job.
21:50:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:50:05 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
21:50:05 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
21:50:05 WORKER: start processing job (2, 0, 5)
21:50:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:50:05 WORKER: args: ()
21:50:05 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 928, 'last_n_outputs': 25, 'leak_rate': 0.7757949839560936, 'lr': 0.0016927192701125153, 'optimizer': 'Adam', 'sparsity': 0.9520134210602985, 'steps_to_train': 44, 'weight_decay': 0.08561605839191182}, 'budget': 400.0, 'working_directory': '.'}
21:50:38 DISPATCHER: Starting worker discovery
21:50:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:50:38 DISPATCHER: Finished worker discovery
21:51:38 DISPATCHER: Starting worker discovery
21:51:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:51:38 DISPATCHER: Finished worker discovery
21:52:38 DISPATCHER: Starting worker discovery
21:52:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:52:38 DISPATCHER: Finished worker discovery
21:53:38 DISPATCHER: Starting worker discovery
21:53:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:53:38 DISPATCHER: Finished worker discovery
21:54:38 DISPATCHER: Starting worker discovery
21:54:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:54:38 DISPATCHER: Finished worker discovery
21:55:38 DISPATCHER: Starting worker discovery
21:55:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:55:38 DISPATCHER: Finished worker discovery
21:56:38 DISPATCHER: Starting worker discovery
21:56:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:56:38 DISPATCHER: Finished worker discovery
21:57:04 WORKER: done with job (2, 0, 5), trying to register it.
21:57:04 WORKER: registered result for job (2, 0, 5) with dispatcher
21:57:04 DISPATCHER: job (2, 0, 5) finished
21:57:04 DISPATCHER: register_result: lock acquired
21:57:04 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
21:57:04 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 928, 'last_n_outputs': 25, 'leak_rate': 0.7757949839560936, 'lr': 0.0016927192701125153, 'optimizer': 'Adam', 'sparsity': 0.9520134210602985, 'steps_to_train': 44, 'weight_decay': 0.08561605839191182}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.461664262341848, 'info': {'music-speech': 0.461664262341848, 'config': "{'batch_size': 128, 'hidden_dim': 928, 'last_n_outputs': 25, 'leak_rate': 0.7757949839560936, 'lr': 0.0016927192701125153, 'optimizer': 'Adam', 'sparsity': 0.9520134210602985, 'steps_to_train': 44, 'weight_decay': 0.08561605839191182}"}}
exception: None

21:57:04 job_callback for (2, 0, 5) started
21:57:04 job_callback for (2, 0, 5) got condition
21:57:04 DISPATCHER: Trying to submit another job.
21:57:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:57:04 HBMASTER: Trying to run another job!
21:57:04 job_callback for (2, 0, 5) finished
21:57:04 ITERATION: Advancing config (2, 0, 0) to next budget 1200.000000
21:57:04 ITERATION: Advancing config (2, 0, 2) to next budget 1200.000000
21:57:04 HBMASTER: schedule new run for iteration 2
21:57:04 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
21:57:04 HBMASTER: submitting job (2, 0, 0) to dispatcher
21:57:04 DISPATCHER: trying to submit job (2, 0, 0)
21:57:04 DISPATCHER: trying to notify the job_runner thread.
21:57:04 HBMASTER: job (2, 0, 0) submitted to dispatcher
21:57:04 DISPATCHER: Trying to submit another job.
21:57:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:57:04 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
21:57:04 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
21:57:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:57:04 WORKER: start processing job (2, 0, 0)
21:57:04 WORKER: args: ()
21:57:04 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 309, 'last_n_outputs': 49, 'leak_rate': 0.823676323770884, 'lr': 0.0026432772950619444, 'optimizer': 'Adam', 'sparsity': 0.8755900591171255, 'steps_to_train': 50, 'weight_decay': 0.014651356531093453}, 'budget': 1200.0, 'working_directory': '.'}
21:57:38 DISPATCHER: Starting worker discovery
21:57:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:57:38 DISPATCHER: Finished worker discovery
21:58:38 DISPATCHER: Starting worker discovery
21:58:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:58:38 DISPATCHER: Finished worker discovery
21:59:38 DISPATCHER: Starting worker discovery
21:59:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:59:38 DISPATCHER: Finished worker discovery
22:00:38 DISPATCHER: Starting worker discovery
22:00:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:00:38 DISPATCHER: Finished worker discovery
22:01:38 DISPATCHER: Starting worker discovery
22:01:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:01:38 DISPATCHER: Finished worker discovery
22:02:38 DISPATCHER: Starting worker discovery
22:02:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:02:38 DISPATCHER: Finished worker discovery
22:03:38 DISPATCHER: Starting worker discovery
22:03:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:03:38 DISPATCHER: Finished worker discovery
22:04:38 DISPATCHER: Starting worker discovery
22:04:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:04:38 DISPATCHER: Finished worker discovery
22:05:38 DISPATCHER: Starting worker discovery
22:05:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:05:38 DISPATCHER: Finished worker discovery
22:06:38 DISPATCHER: Starting worker discovery
22:06:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:06:38 DISPATCHER: Finished worker discovery
22:07:38 DISPATCHER: Starting worker discovery
22:07:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:07:38 DISPATCHER: Finished worker discovery
22:08:38 DISPATCHER: Starting worker discovery
22:08:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:08:38 DISPATCHER: Finished worker discovery
22:09:38 DISPATCHER: Starting worker discovery
22:09:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:09:38 DISPATCHER: Finished worker discovery
22:10:38 DISPATCHER: Starting worker discovery
22:10:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:10:38 DISPATCHER: Finished worker discovery
22:11:38 DISPATCHER: Starting worker discovery
22:11:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:11:38 DISPATCHER: Finished worker discovery
22:12:38 DISPATCHER: Starting worker discovery
22:12:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:12:38 DISPATCHER: Finished worker discovery
22:13:38 DISPATCHER: Starting worker discovery
22:13:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:13:38 DISPATCHER: Finished worker discovery
22:14:38 DISPATCHER: Starting worker discovery
22:14:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:14:38 DISPATCHER: Finished worker discovery
22:15:38 DISPATCHER: Starting worker discovery
22:15:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:15:38 DISPATCHER: Finished worker discovery
22:16:38 DISPATCHER: Starting worker discovery
22:16:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:16:38 DISPATCHER: Finished worker discovery
22:17:15 WORKER: done with job (2, 0, 0), trying to register it.
22:17:15 WORKER: registered result for job (2, 0, 0) with dispatcher
22:17:15 DISPATCHER: job (2, 0, 0) finished
22:17:15 DISPATCHER: register_result: lock acquired
22:17:15 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
22:17:15 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 309, 'last_n_outputs': 49, 'leak_rate': 0.823676323770884, 'lr': 0.0026432772950619444, 'optimizer': 'Adam', 'sparsity': 0.8755900591171255, 'steps_to_train': 50, 'weight_decay': 0.014651356531093453}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.2637163144177719, 'info': {'music-speech': 0.2637163144177719, 'config': "{'batch_size': 32, 'hidden_dim': 309, 'last_n_outputs': 49, 'leak_rate': 0.823676323770884, 'lr': 0.0026432772950619444, 'optimizer': 'Adam', 'sparsity': 0.8755900591171255, 'steps_to_train': 50, 'weight_decay': 0.014651356531093453}"}}
exception: None

22:17:15 job_callback for (2, 0, 0) started
22:17:15 DISPATCHER: Trying to submit another job.
22:17:15 job_callback for (2, 0, 0) got condition
22:17:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:17:15 Only 3 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
22:17:15 HBMASTER: Trying to run another job!
22:17:15 job_callback for (2, 0, 0) finished
22:17:15 HBMASTER: schedule new run for iteration 2
22:17:15 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
22:17:15 HBMASTER: submitting job (2, 0, 2) to dispatcher
22:17:15 DISPATCHER: trying to submit job (2, 0, 2)
22:17:15 DISPATCHER: trying to notify the job_runner thread.
22:17:15 HBMASTER: job (2, 0, 2) submitted to dispatcher
22:17:15 DISPATCHER: Trying to submit another job.
22:17:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:17:15 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
22:17:15 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
22:17:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:17:15 WORKER: start processing job (2, 0, 2)
22:17:15 WORKER: args: ()
22:17:15 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 544, 'last_n_outputs': 24, 'leak_rate': 0.8685713702595363, 'lr': 0.0067158769040697175, 'optimizer': 'Adam', 'sparsity': 0.7739678284217361, 'steps_to_train': 28, 'weight_decay': 0.029516162300165676}, 'budget': 1200.0, 'working_directory': '.'}
22:17:38 DISPATCHER: Starting worker discovery
22:17:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:17:38 DISPATCHER: Finished worker discovery
22:18:38 DISPATCHER: Starting worker discovery
22:18:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:18:38 DISPATCHER: Finished worker discovery
22:19:38 DISPATCHER: Starting worker discovery
22:19:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:19:38 DISPATCHER: Finished worker discovery
22:20:38 DISPATCHER: Starting worker discovery
22:20:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:20:38 DISPATCHER: Finished worker discovery
22:21:38 DISPATCHER: Starting worker discovery
22:21:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:21:38 DISPATCHER: Finished worker discovery
22:22:38 DISPATCHER: Starting worker discovery
22:22:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:22:38 DISPATCHER: Finished worker discovery
22:23:38 DISPATCHER: Starting worker discovery
22:23:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:23:38 DISPATCHER: Finished worker discovery
22:24:38 DISPATCHER: Starting worker discovery
22:24:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:24:38 DISPATCHER: Finished worker discovery
22:25:38 DISPATCHER: Starting worker discovery
22:25:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:25:38 DISPATCHER: Finished worker discovery
22:26:38 DISPATCHER: Starting worker discovery
22:26:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:26:38 DISPATCHER: Finished worker discovery
22:27:38 DISPATCHER: Starting worker discovery
22:27:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:27:38 DISPATCHER: Finished worker discovery
22:28:38 DISPATCHER: Starting worker discovery
22:28:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:28:38 DISPATCHER: Finished worker discovery
22:29:38 DISPATCHER: Starting worker discovery
22:29:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:29:38 DISPATCHER: Finished worker discovery
22:30:38 DISPATCHER: Starting worker discovery
22:30:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:30:38 DISPATCHER: Finished worker discovery
22:31:38 DISPATCHER: Starting worker discovery
22:31:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:31:38 DISPATCHER: Finished worker discovery
22:32:38 DISPATCHER: Starting worker discovery
22:32:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:32:38 DISPATCHER: Finished worker discovery
22:33:38 DISPATCHER: Starting worker discovery
22:33:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:33:38 DISPATCHER: Finished worker discovery
22:34:38 DISPATCHER: Starting worker discovery
22:34:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:34:38 DISPATCHER: Finished worker discovery
22:35:38 DISPATCHER: Starting worker discovery
22:35:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:35:38 DISPATCHER: Finished worker discovery
22:36:38 DISPATCHER: Starting worker discovery
22:36:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:36:38 DISPATCHER: Finished worker discovery
22:37:30 WORKER: done with job (2, 0, 2), trying to register it.
22:37:30 WORKER: registered result for job (2, 0, 2) with dispatcher
22:37:30 DISPATCHER: job (2, 0, 2) finished
22:37:30 DISPATCHER: register_result: lock acquired
22:37:30 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
22:37:30 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 544, 'last_n_outputs': 24, 'leak_rate': 0.8685713702595363, 'lr': 0.0067158769040697175, 'optimizer': 'Adam', 'sparsity': 0.7739678284217361, 'steps_to_train': 28, 'weight_decay': 0.029516162300165676}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.535138988702357, 'info': {'music-speech': 0.535138988702357, 'config': "{'batch_size': 64, 'hidden_dim': 544, 'last_n_outputs': 24, 'leak_rate': 0.8685713702595363, 'lr': 0.0067158769040697175, 'optimizer': 'Adam', 'sparsity': 0.7739678284217361, 'steps_to_train': 28, 'weight_decay': 0.029516162300165676}"}}
exception: None

22:37:30 job_callback for (2, 0, 2) started
22:37:30 DISPATCHER: Trying to submit another job.
22:37:30 job_callback for (2, 0, 2) got condition
22:37:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:37:30 Only 4 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
22:37:30 HBMASTER: Trying to run another job!
22:37:30 job_callback for (2, 0, 2) finished
22:37:30 start sampling a new configuration.
22:37:31 best_vector: [2, 0.441869130295946, 0.09314794817099847, 0.32697796218179764, 0.2987687161332959, 0, 0.20755533175559682, 0.4238167336765626, 0.7971349236130751], 0.050781970927653707, 0.36044084742532545, 0.018303896635091743
22:37:31 done sampling a new configuration.
22:37:31 HBMASTER: schedule new run for iteration 3
22:37:31 HBMASTER: trying submitting job (3, 0, 0) to dispatcher
22:37:31 HBMASTER: submitting job (3, 0, 0) to dispatcher
22:37:31 DISPATCHER: trying to submit job (3, 0, 0)
22:37:31 DISPATCHER: trying to notify the job_runner thread.
22:37:31 HBMASTER: job (3, 0, 0) submitted to dispatcher
22:37:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:37:31 DISPATCHER: Trying to submit another job.
22:37:31 DISPATCHER: starting job (3, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
22:37:31 DISPATCHER: job (3, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
22:37:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:37:31 WORKER: start processing job (3, 0, 0)
22:37:31 WORKER: args: ()
22:37:31 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 553, 'last_n_outputs': 13, 'leak_rate': 0.8317444905454494, 'lr': 0.0039585618259732145, 'optimizer': 'Adam', 'sparsity': 0.7998132796213432, 'steps_to_train': 48, 'weight_decay': 0.10891719450016889}, 'budget': 1200.0, 'working_directory': '.'}
22:37:38 DISPATCHER: Starting worker discovery
22:37:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:37:38 DISPATCHER: Finished worker discovery
22:38:38 DISPATCHER: Starting worker discovery
22:38:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:38:38 DISPATCHER: Finished worker discovery
22:39:38 DISPATCHER: Starting worker discovery
22:39:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:39:38 DISPATCHER: Finished worker discovery
22:40:38 DISPATCHER: Starting worker discovery
22:40:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:40:38 DISPATCHER: Finished worker discovery
22:41:38 DISPATCHER: Starting worker discovery
22:41:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:41:38 DISPATCHER: Finished worker discovery
22:42:38 DISPATCHER: Starting worker discovery
22:42:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:42:38 DISPATCHER: Finished worker discovery
22:43:38 DISPATCHER: Starting worker discovery
22:43:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:43:38 DISPATCHER: Finished worker discovery
22:44:38 DISPATCHER: Starting worker discovery
22:44:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:44:39 DISPATCHER: Finished worker discovery
22:45:39 DISPATCHER: Starting worker discovery
22:45:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:45:39 DISPATCHER: Finished worker discovery
22:46:39 DISPATCHER: Starting worker discovery
22:46:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:46:39 DISPATCHER: Finished worker discovery
22:47:39 DISPATCHER: Starting worker discovery
22:47:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:47:39 DISPATCHER: Finished worker discovery
22:48:39 DISPATCHER: Starting worker discovery
22:48:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:48:39 DISPATCHER: Finished worker discovery
22:49:39 DISPATCHER: Starting worker discovery
22:49:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:49:39 DISPATCHER: Finished worker discovery
22:50:39 DISPATCHER: Starting worker discovery
22:50:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:50:39 DISPATCHER: Finished worker discovery
22:51:39 DISPATCHER: Starting worker discovery
22:51:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:51:39 DISPATCHER: Finished worker discovery
22:52:39 DISPATCHER: Starting worker discovery
22:52:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:52:39 DISPATCHER: Finished worker discovery
22:53:39 DISPATCHER: Starting worker discovery
22:53:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:53:39 DISPATCHER: Finished worker discovery
22:54:39 DISPATCHER: Starting worker discovery
22:54:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:54:39 DISPATCHER: Finished worker discovery
22:55:39 DISPATCHER: Starting worker discovery
22:55:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:55:39 DISPATCHER: Finished worker discovery
22:56:39 DISPATCHER: Starting worker discovery
22:56:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:56:39 DISPATCHER: Finished worker discovery
22:57:39 DISPATCHER: Starting worker discovery
22:57:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:57:39 DISPATCHER: Finished worker discovery
22:57:48 WORKER: done with job (3, 0, 0), trying to register it.
22:57:48 WORKER: registered result for job (3, 0, 0) with dispatcher
22:57:48 DISPATCHER: job (3, 0, 0) finished
22:57:48 DISPATCHER: register_result: lock acquired
22:57:48 DISPATCHER: job (3, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
22:57:48 job_id: (3, 0, 0)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 553, 'last_n_outputs': 13, 'leak_rate': 0.8317444905454494, 'lr': 0.0039585618259732145, 'optimizer': 'Adam', 'sparsity': 0.7998132796213432, 'steps_to_train': 48, 'weight_decay': 0.10891719450016889}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.26425863783284476, 'info': {'music-speech': 0.26425863783284476, 'config': "{'batch_size': 64, 'hidden_dim': 553, 'last_n_outputs': 13, 'leak_rate': 0.8317444905454494, 'lr': 0.0039585618259732145, 'optimizer': 'Adam', 'sparsity': 0.7998132796213432, 'steps_to_train': 48, 'weight_decay': 0.10891719450016889}"}}
exception: None

22:57:48 job_callback for (3, 0, 0) started
22:57:48 DISPATCHER: Trying to submit another job.
22:57:48 job_callback for (3, 0, 0) got condition
22:57:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:57:48 Only 5 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
22:57:48 HBMASTER: Trying to run another job!
22:57:48 job_callback for (3, 0, 0) finished
22:57:48 start sampling a new configuration.
22:57:49 best_vector: [0, 0.4943990719534691, 0.21021985237238844, 0.07779651024257694, 0.11632820215912083, 1, 0.407875574454737, 0.15431042699730635, 0.47524654617127887], 0.05037398448025805, 0.06559459704774592, 0.0033042612136719336
22:57:49 done sampling a new configuration.
22:57:49 HBMASTER: schedule new run for iteration 3
22:57:49 HBMASTER: trying submitting job (3, 0, 1) to dispatcher
22:57:49 HBMASTER: submitting job (3, 0, 1) to dispatcher
22:57:49 DISPATCHER: trying to submit job (3, 0, 1)
22:57:49 DISPATCHER: trying to notify the job_runner thread.
22:57:49 HBMASTER: job (3, 0, 1) submitted to dispatcher
22:57:49 DISPATCHER: Trying to submit another job.
22:57:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:57:49 DISPATCHER: starting job (3, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
22:57:49 DISPATCHER: job (3, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
22:57:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:57:49 WORKER: start processing job (3, 0, 1)
22:57:49 WORKER: args: ()
22:57:49 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 596, 'last_n_outputs': 18, 'leak_rate': 0.7694491275606442, 'lr': 0.0017086629573245338, 'optimizer': 'SGD', 'sparsity': 0.8478901378691369, 'steps_to_train': 24, 'weight_decay': 0.041525035452193756}, 'budget': 1200.0, 'working_directory': '.'}
22:58:39 DISPATCHER: Starting worker discovery
22:58:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:58:39 DISPATCHER: Finished worker discovery
22:59:39 DISPATCHER: Starting worker discovery
22:59:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:59:39 DISPATCHER: Finished worker discovery
23:00:39 DISPATCHER: Starting worker discovery
23:00:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:00:39 DISPATCHER: Finished worker discovery
23:01:39 DISPATCHER: Starting worker discovery
23:01:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:01:39 DISPATCHER: Finished worker discovery
23:02:39 DISPATCHER: Starting worker discovery
23:02:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:02:39 DISPATCHER: Finished worker discovery
23:03:39 DISPATCHER: Starting worker discovery
23:03:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:03:39 DISPATCHER: Finished worker discovery
23:04:39 DISPATCHER: Starting worker discovery
23:04:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:04:39 DISPATCHER: Finished worker discovery
23:05:39 DISPATCHER: Starting worker discovery
23:05:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:05:39 DISPATCHER: Finished worker discovery
23:06:39 DISPATCHER: Starting worker discovery
23:06:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:06:39 DISPATCHER: Finished worker discovery
23:07:39 DISPATCHER: Starting worker discovery
23:07:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:07:39 DISPATCHER: Finished worker discovery
23:08:39 DISPATCHER: Starting worker discovery
23:08:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:08:39 DISPATCHER: Finished worker discovery
23:09:39 DISPATCHER: Starting worker discovery
23:09:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:09:39 DISPATCHER: Finished worker discovery
23:10:39 DISPATCHER: Starting worker discovery
23:10:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:10:39 DISPATCHER: Finished worker discovery
23:11:39 DISPATCHER: Starting worker discovery
23:11:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:11:39 DISPATCHER: Finished worker discovery
23:12:39 DISPATCHER: Starting worker discovery
23:12:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:12:39 DISPATCHER: Finished worker discovery
23:13:39 DISPATCHER: Starting worker discovery
23:13:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:13:39 DISPATCHER: Finished worker discovery
23:14:39 DISPATCHER: Starting worker discovery
23:14:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:14:39 DISPATCHER: Finished worker discovery
23:15:39 DISPATCHER: Starting worker discovery
23:15:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:15:39 DISPATCHER: Finished worker discovery
23:16:39 DISPATCHER: Starting worker discovery
23:16:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:16:39 DISPATCHER: Finished worker discovery
23:17:39 DISPATCHER: Starting worker discovery
23:17:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:17:39 DISPATCHER: Finished worker discovery
23:18:03 WORKER: done with job (3, 0, 1), trying to register it.
23:18:03 WORKER: registered result for job (3, 0, 1) with dispatcher
23:18:03 DISPATCHER: job (3, 0, 1) finished
23:18:03 DISPATCHER: register_result: lock acquired
23:18:03 DISPATCHER: job (3, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
23:18:03 job_id: (3, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 596, 'last_n_outputs': 18, 'leak_rate': 0.7694491275606442, 'lr': 0.0017086629573245338, 'optimizer': 'SGD', 'sparsity': 0.8478901378691369, 'steps_to_train': 24, 'weight_decay': 0.041525035452193756}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.45878424866589806, 'info': {'music-speech': 0.45878424866589806, 'config': "{'batch_size': 16, 'hidden_dim': 596, 'last_n_outputs': 18, 'leak_rate': 0.7694491275606442, 'lr': 0.0017086629573245338, 'optimizer': 'SGD', 'sparsity': 0.8478901378691369, 'steps_to_train': 24, 'weight_decay': 0.041525035452193756}"}}
exception: None

23:18:03 job_callback for (3, 0, 1) started
23:18:03 DISPATCHER: Trying to submit another job.
23:18:03 job_callback for (3, 0, 1) got condition
23:18:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:18:03 Only 6 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
23:18:03 HBMASTER: Trying to run another job!
23:18:03 job_callback for (3, 0, 1) finished
23:18:03 start sampling a new configuration.
23:18:03 best_vector: [1, 0.8822715343260428, 0.2234033778314181, 0.8458522242008044, 0.7749324356733831, 0, 0.7684497828812004, 0.7934345279731785, 0.16916424911968753], 0.02981556812971546, 0.08309625672654168, 0.00247756210375453
23:18:03 done sampling a new configuration.
23:18:03 HBMASTER: schedule new run for iteration 3
23:18:03 HBMASTER: trying submitting job (3, 0, 2) to dispatcher
23:18:03 HBMASTER: submitting job (3, 0, 2) to dispatcher
23:18:03 DISPATCHER: trying to submit job (3, 0, 2)
23:18:03 DISPATCHER: trying to notify the job_runner thread.
23:18:03 HBMASTER: job (3, 0, 2) submitted to dispatcher
23:18:03 DISPATCHER: Trying to submit another job.
23:18:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:18:03 DISPATCHER: starting job (3, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
23:18:03 DISPATCHER: job (3, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
23:18:03 WORKER: start processing job (3, 0, 2)
23:18:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:18:03 WORKER: args: ()
23:18:03 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 906, 'last_n_outputs': 19, 'leak_rate': 0.9614630560502011, 'lr': 0.035470300791581116, 'optimizer': 'Adam', 'sparsity': 0.9344279478914881, 'steps_to_train': 82, 'weight_decay': 0.016599223109145408}, 'budget': 1200.0, 'working_directory': '.'}
23:18:39 DISPATCHER: Starting worker discovery
23:18:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:18:39 DISPATCHER: Finished worker discovery
23:19:39 DISPATCHER: Starting worker discovery
23:19:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:19:39 DISPATCHER: Finished worker discovery
23:20:39 DISPATCHER: Starting worker discovery
23:20:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:20:39 DISPATCHER: Finished worker discovery
23:21:39 DISPATCHER: Starting worker discovery
23:21:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:21:39 DISPATCHER: Finished worker discovery
23:22:39 DISPATCHER: Starting worker discovery
23:22:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:22:39 DISPATCHER: Finished worker discovery
23:23:39 DISPATCHER: Starting worker discovery
23:23:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:23:39 DISPATCHER: Finished worker discovery
23:24:39 DISPATCHER: Starting worker discovery
23:24:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:24:39 DISPATCHER: Finished worker discovery
23:25:39 DISPATCHER: Starting worker discovery
23:25:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:25:39 DISPATCHER: Finished worker discovery
23:26:39 DISPATCHER: Starting worker discovery
23:26:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:26:39 DISPATCHER: Finished worker discovery
23:27:39 DISPATCHER: Starting worker discovery
23:27:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:27:39 DISPATCHER: Finished worker discovery
23:28:39 DISPATCHER: Starting worker discovery
23:28:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:28:39 DISPATCHER: Finished worker discovery
23:29:39 DISPATCHER: Starting worker discovery
23:29:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:29:39 DISPATCHER: Finished worker discovery
23:30:39 DISPATCHER: Starting worker discovery
23:30:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:30:39 DISPATCHER: Finished worker discovery
23:31:39 DISPATCHER: Starting worker discovery
23:31:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:31:39 DISPATCHER: Finished worker discovery
23:32:39 DISPATCHER: Starting worker discovery
23:32:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:32:39 DISPATCHER: Finished worker discovery
23:33:39 DISPATCHER: Starting worker discovery
23:33:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:33:39 DISPATCHER: Finished worker discovery
23:34:39 DISPATCHER: Starting worker discovery
23:34:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:34:39 DISPATCHER: Finished worker discovery
23:35:39 DISPATCHER: Starting worker discovery
23:35:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:35:39 DISPATCHER: Finished worker discovery
23:36:39 DISPATCHER: Starting worker discovery
23:36:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:36:39 DISPATCHER: Finished worker discovery
23:37:39 DISPATCHER: Starting worker discovery
23:37:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:37:39 DISPATCHER: Finished worker discovery
23:38:28 WORKER: done with job (3, 0, 2), trying to register it.
23:38:28 DISPATCHER: job (3, 0, 2) finished
23:38:28 WORKER: registered result for job (3, 0, 2) with dispatcher
23:38:28 DISPATCHER: register_result: lock acquired
23:38:28 DISPATCHER: job (3, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
23:38:28 job_id: (3, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 906, 'last_n_outputs': 19, 'leak_rate': 0.9614630560502011, 'lr': 0.035470300791581116, 'optimizer': 'Adam', 'sparsity': 0.9344279478914881, 'steps_to_train': 82, 'weight_decay': 0.016599223109145408}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.39246067863045025, 'info': {'music-speech': 0.39246067863045025, 'config': "{'batch_size': 32, 'hidden_dim': 906, 'last_n_outputs': 19, 'leak_rate': 0.9614630560502011, 'lr': 0.035470300791581116, 'optimizer': 'Adam', 'sparsity': 0.9344279478914881, 'steps_to_train': 82, 'weight_decay': 0.016599223109145408}"}}
exception: None

23:38:28 job_callback for (3, 0, 2) started
23:38:28 DISPATCHER: Trying to submit another job.
23:38:28 job_callback for (3, 0, 2) got condition
23:38:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:38:28 Only 7 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
23:38:28 HBMASTER: Trying to run another job!
23:38:28 job_callback for (3, 0, 2) finished
23:38:28 start sampling a new configuration.
23:38:28 done sampling a new configuration.
23:38:28 HBMASTER: schedule new run for iteration 3
23:38:28 HBMASTER: trying submitting job (3, 0, 3) to dispatcher
23:38:28 HBMASTER: submitting job (3, 0, 3) to dispatcher
23:38:28 DISPATCHER: trying to submit job (3, 0, 3)
23:38:28 DISPATCHER: trying to notify the job_runner thread.
23:38:28 HBMASTER: job (3, 0, 3) submitted to dispatcher
23:38:28 DISPATCHER: Trying to submit another job.
23:38:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:38:28 DISPATCHER: starting job (3, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
23:38:28 DISPATCHER: job (3, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
23:38:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:38:28 WORKER: start processing job (3, 0, 3)
23:38:28 WORKER: args: ()
23:38:28 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 352, 'last_n_outputs': 18, 'leak_rate': 0.992593697174398, 'lr': 0.034014260878788435, 'optimizer': 'SGD', 'sparsity': 0.9317769878863371, 'steps_to_train': 34, 'weight_decay': 0.07531207168005082}, 'budget': 1200.0, 'working_directory': '.'}
23:38:39 DISPATCHER: Starting worker discovery
23:38:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:38:39 DISPATCHER: Finished worker discovery
23:39:39 DISPATCHER: Starting worker discovery
23:39:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:39:39 DISPATCHER: Finished worker discovery
23:40:39 DISPATCHER: Starting worker discovery
23:40:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:40:39 DISPATCHER: Finished worker discovery
23:41:39 DISPATCHER: Starting worker discovery
23:41:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:41:39 DISPATCHER: Finished worker discovery
23:42:39 DISPATCHER: Starting worker discovery
23:42:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:42:39 DISPATCHER: Finished worker discovery
23:43:39 DISPATCHER: Starting worker discovery
23:43:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:43:39 DISPATCHER: Finished worker discovery
23:44:39 DISPATCHER: Starting worker discovery
23:44:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:44:39 DISPATCHER: Finished worker discovery
23:45:39 DISPATCHER: Starting worker discovery
23:45:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:45:39 DISPATCHER: Finished worker discovery
23:46:39 DISPATCHER: Starting worker discovery
23:46:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:46:39 DISPATCHER: Finished worker discovery
23:47:39 DISPATCHER: Starting worker discovery
23:47:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:47:39 DISPATCHER: Finished worker discovery
23:48:39 DISPATCHER: Starting worker discovery
23:48:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:48:39 DISPATCHER: Finished worker discovery
23:49:39 DISPATCHER: Starting worker discovery
23:49:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:49:39 DISPATCHER: Finished worker discovery
23:50:39 DISPATCHER: Starting worker discovery
23:50:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:50:40 DISPATCHER: Finished worker discovery
23:51:40 DISPATCHER: Starting worker discovery
23:51:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:51:40 DISPATCHER: Finished worker discovery
23:52:40 DISPATCHER: Starting worker discovery
23:52:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:52:40 DISPATCHER: Finished worker discovery
23:53:40 DISPATCHER: Starting worker discovery
23:53:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:53:40 DISPATCHER: Finished worker discovery
23:54:40 DISPATCHER: Starting worker discovery
23:54:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:54:40 DISPATCHER: Finished worker discovery
23:55:40 DISPATCHER: Starting worker discovery
23:55:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:55:40 DISPATCHER: Finished worker discovery
23:56:40 DISPATCHER: Starting worker discovery
23:56:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:56:40 DISPATCHER: Finished worker discovery
23:57:40 DISPATCHER: Starting worker discovery
23:57:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:57:40 DISPATCHER: Finished worker discovery
23:58:40 DISPATCHER: Starting worker discovery
23:58:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:58:40 DISPATCHER: Finished worker discovery
23:58:46 WORKER: done with job (3, 0, 3), trying to register it.
23:58:46 WORKER: registered result for job (3, 0, 3) with dispatcher
23:58:46 DISPATCHER: job (3, 0, 3) finished
23:58:46 DISPATCHER: register_result: lock acquired
23:58:46 DISPATCHER: job (3, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
23:58:46 job_id: (3, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 352, 'last_n_outputs': 18, 'leak_rate': 0.992593697174398, 'lr': 0.034014260878788435, 'optimizer': 'SGD', 'sparsity': 0.9317769878863371, 'steps_to_train': 34, 'weight_decay': 0.07531207168005082}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5151293255166751, 'info': {'music-speech': 0.5151293255166751, 'config': "{'batch_size': 128, 'hidden_dim': 352, 'last_n_outputs': 18, 'leak_rate': 0.992593697174398, 'lr': 0.034014260878788435, 'optimizer': 'SGD', 'sparsity': 0.9317769878863371, 'steps_to_train': 34, 'weight_decay': 0.07531207168005082}"}}
exception: None

23:58:46 job_callback for (3, 0, 3) started
23:58:46 DISPATCHER: Trying to submit another job.
23:58:46 job_callback for (3, 0, 3) got condition
23:58:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:58:46 Only 8 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
23:58:46 HBMASTER: Trying to run another job!
23:58:46 job_callback for (3, 0, 3) finished
23:58:46 start sampling a new configuration.
23:58:46 best_vector: [3, 0.9411496942310326, 0.39814261194393163, 0.42733922278421876, 0.1647617493981091, 1, 0.09449060354971478, 0.36252246730860677, 0.9752735134853797], 0.01702490642486119, 0.08582225338286523, 0.0014611158330140072
23:58:46 done sampling a new configuration.
23:58:46 HBMASTER: schedule new run for iteration 4
23:58:46 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
23:58:46 HBMASTER: submitting job (4, 0, 0) to dispatcher
23:58:46 DISPATCHER: trying to submit job (4, 0, 0)
23:58:46 DISPATCHER: trying to notify the job_runner thread.
23:58:46 HBMASTER: job (4, 0, 0) submitted to dispatcher
23:58:46 DISPATCHER: Trying to submit another job.
23:58:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:58:46 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
23:58:46 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
23:58:46 WORKER: start processing job (4, 0, 0)
23:58:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:58:46 WORKER: args: ()
23:58:46 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 953, 'last_n_outputs': 26, 'leak_rate': 0.8568348056960546, 'lr': 0.0021356176368731456, 'optimizer': 'SGD', 'sparsity': 0.7726777448519315, 'steps_to_train': 42, 'weight_decay': 0.1857206072557814}, 'budget': 44.44444444444444, 'working_directory': '.'}
23:59:40 DISPATCHER: Starting worker discovery
23:59:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:59:40 DISPATCHER: Finished worker discovery
23:59:46 WORKER: done with job (4, 0, 0), trying to register it.
23:59:46 WORKER: registered result for job (4, 0, 0) with dispatcher
23:59:46 DISPATCHER: job (4, 0, 0) finished
23:59:46 DISPATCHER: register_result: lock acquired
23:59:46 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
23:59:46 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 953, 'last_n_outputs': 26, 'leak_rate': 0.8568348056960546, 'lr': 0.0021356176368731456, 'optimizer': 'SGD', 'sparsity': 0.7726777448519315, 'steps_to_train': 42, 'weight_decay': 0.1857206072557814}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.602655578660958, 'info': {'music-speech': 0.602655578660958, 'config': "{'batch_size': 128, 'hidden_dim': 953, 'last_n_outputs': 26, 'leak_rate': 0.8568348056960546, 'lr': 0.0021356176368731456, 'optimizer': 'SGD', 'sparsity': 0.7726777448519315, 'steps_to_train': 42, 'weight_decay': 0.1857206072557814}"}}
exception: None

23:59:46 job_callback for (4, 0, 0) started
23:59:46 DISPATCHER: Trying to submit another job.
23:59:46 job_callback for (4, 0, 0) got condition
23:59:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:59:46 done building a new model for budget 44.444444 based on 10/23 split
Best loss for this budget:-0.640582





23:59:46 HBMASTER: Trying to run another job!
23:59:46 job_callback for (4, 0, 0) finished
23:59:46 start sampling a new configuration.
23:59:46 best_vector: [0, 0.9437846697631774, 0.8895145403993281, 0.00021221222988775101, 0.13346193758977187, 0, 0.7240079723141124, 0.2049569043656007, 0.8180649245621454], 0.009854562552870207, 0.024317839639695343, 0.00023964167188004443
23:59:46 done sampling a new configuration.
23:59:46 HBMASTER: schedule new run for iteration 4
23:59:46 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
23:59:46 HBMASTER: submitting job (4, 0, 1) to dispatcher
23:59:46 DISPATCHER: trying to submit job (4, 0, 1)
23:59:46 DISPATCHER: trying to notify the job_runner thread.
23:59:46 HBMASTER: job (4, 0, 1) submitted to dispatcher
23:59:46 DISPATCHER: Trying to submit another job.
23:59:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:59:46 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
23:59:46 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
23:59:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:59:46 WORKER: start processing job (4, 0, 1)
23:59:46 WORKER: args: ()
23:59:46 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 955, 'last_n_outputs': 46, 'leak_rate': 0.7500530530574719, 'lr': 0.0018489445004125282, 'optimizer': 'Adam', 'sparsity': 0.9237619133553869, 'steps_to_train': 28, 'weight_decay': 0.11596501947363622}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:00:40 DISPATCHER: Starting worker discovery
00:00:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:00:40 DISPATCHER: Finished worker discovery
00:00:43 WORKER: done with job (4, 0, 1), trying to register it.
00:00:43 WORKER: registered result for job (4, 0, 1) with dispatcher
00:00:43 DISPATCHER: job (4, 0, 1) finished
00:00:43 DISPATCHER: register_result: lock acquired
00:00:43 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:00:43 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 955, 'last_n_outputs': 46, 'leak_rate': 0.7500530530574719, 'lr': 0.0018489445004125282, 'optimizer': 'Adam', 'sparsity': 0.9237619133553869, 'steps_to_train': 28, 'weight_decay': 0.11596501947363622}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.09202527240322622, 'info': {'music-speech': 0.09202527240322622, 'config': "{'batch_size': 16, 'hidden_dim': 955, 'last_n_outputs': 46, 'leak_rate': 0.7500530530574719, 'lr': 0.0018489445004125282, 'optimizer': 'Adam', 'sparsity': 0.9237619133553869, 'steps_to_train': 28, 'weight_decay': 0.11596501947363622}"}}
exception: None

00:00:43 job_callback for (4, 0, 1) started
00:00:43 DISPATCHER: Trying to submit another job.
00:00:43 job_callback for (4, 0, 1) got condition
00:00:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:00:43 done building a new model for budget 44.444444 based on 10/24 split
Best loss for this budget:-0.640582





00:00:43 HBMASTER: Trying to run another job!
00:00:43 job_callback for (4, 0, 1) finished
00:00:43 start sampling a new configuration.
00:00:43 done sampling a new configuration.
00:00:43 HBMASTER: schedule new run for iteration 4
00:00:43 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
00:00:43 HBMASTER: submitting job (4, 0, 2) to dispatcher
00:00:43 DISPATCHER: trying to submit job (4, 0, 2)
00:00:43 DISPATCHER: trying to notify the job_runner thread.
00:00:43 HBMASTER: job (4, 0, 2) submitted to dispatcher
00:00:43 DISPATCHER: Trying to submit another job.
00:00:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:00:43 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:00:43 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:00:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:00:43 WORKER: start processing job (4, 0, 2)
00:00:43 WORKER: args: ()
00:00:43 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 672, 'last_n_outputs': 48, 'leak_rate': 0.9310874691068665, 'lr': 0.0574142400810185, 'optimizer': 'Adam', 'sparsity': 0.8207560065535712, 'steps_to_train': 30, 'weight_decay': 0.09688742016101012}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:01:40 DISPATCHER: Starting worker discovery
00:01:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:01:40 DISPATCHER: Finished worker discovery
00:01:44 WORKER: done with job (4, 0, 2), trying to register it.
00:01:44 DISPATCHER: job (4, 0, 2) finished
00:01:44 WORKER: registered result for job (4, 0, 2) with dispatcher
00:01:44 DISPATCHER: register_result: lock acquired
00:01:44 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:01:44 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 672, 'last_n_outputs': 48, 'leak_rate': 0.9310874691068665, 'lr': 0.0574142400810185, 'optimizer': 'Adam', 'sparsity': 0.8207560065535712, 'steps_to_train': 30, 'weight_decay': 0.09688742016101012}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4957991468116649, 'info': {'music-speech': 0.4957991468116649, 'config': "{'batch_size': 32, 'hidden_dim': 672, 'last_n_outputs': 48, 'leak_rate': 0.9310874691068665, 'lr': 0.0574142400810185, 'optimizer': 'Adam', 'sparsity': 0.8207560065535712, 'steps_to_train': 30, 'weight_decay': 0.09688742016101012}"}}
exception: None

00:01:44 job_callback for (4, 0, 2) started
00:01:44 DISPATCHER: Trying to submit another job.
00:01:44 job_callback for (4, 0, 2) got condition
00:01:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:01:44 done building a new model for budget 44.444444 based on 10/25 split
Best loss for this budget:-0.640582





00:01:44 HBMASTER: Trying to run another job!
00:01:44 job_callback for (4, 0, 2) finished
00:01:44 start sampling a new configuration.
00:01:44 best_vector: [1, 0.7087250581969504, 0.5966998379848252, 0.30945012613873546, 0.12184732720617487, 0, 0.26708188223754015, 0.6259393336749992, 0.8242703301902914], 0.03035097111129683, 0.3758653292435668, 0.011407877749609567
00:01:44 done sampling a new configuration.
00:01:44 HBMASTER: schedule new run for iteration 4
00:01:44 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
00:01:44 HBMASTER: submitting job (4, 0, 3) to dispatcher
00:01:44 DISPATCHER: trying to submit job (4, 0, 3)
00:01:44 DISPATCHER: trying to notify the job_runner thread.
00:01:44 HBMASTER: job (4, 0, 3) submitted to dispatcher
00:01:44 DISPATCHER: Trying to submit another job.
00:01:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:01:44 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:01:44 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:01:44 WORKER: start processing job (4, 0, 3)
00:01:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:01:44 WORKER: args: ()
00:01:44 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 767, 'last_n_outputs': 34, 'leak_rate': 0.8273625315346839, 'lr': 0.0017526478095691582, 'optimizer': 'Adam', 'sparsity': 0.8140996517370096, 'steps_to_train': 66, 'weight_decay': 0.11814094056342399}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:02:40 DISPATCHER: Starting worker discovery
00:02:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:02:40 DISPATCHER: Finished worker discovery
00:02:48 WORKER: done with job (4, 0, 3), trying to register it.
00:02:48 DISPATCHER: job (4, 0, 3) finished
00:02:48 WORKER: registered result for job (4, 0, 3) with dispatcher
00:02:48 DISPATCHER: register_result: lock acquired
00:02:48 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:02:48 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 767, 'last_n_outputs': 34, 'leak_rate': 0.8273625315346839, 'lr': 0.0017526478095691582, 'optimizer': 'Adam', 'sparsity': 0.8140996517370096, 'steps_to_train': 66, 'weight_decay': 0.11814094056342399}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4146244244682414, 'info': {'music-speech': 0.4146244244682414, 'config': "{'batch_size': 32, 'hidden_dim': 767, 'last_n_outputs': 34, 'leak_rate': 0.8273625315346839, 'lr': 0.0017526478095691582, 'optimizer': 'Adam', 'sparsity': 0.8140996517370096, 'steps_to_train': 66, 'weight_decay': 0.11814094056342399}"}}
exception: None

00:02:48 job_callback for (4, 0, 3) started
00:02:48 DISPATCHER: Trying to submit another job.
00:02:48 job_callback for (4, 0, 3) got condition
00:02:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:02:48 done building a new model for budget 44.444444 based on 10/26 split
Best loss for this budget:-0.640582





00:02:48 HBMASTER: Trying to run another job!
00:02:48 job_callback for (4, 0, 3) finished
00:02:48 start sampling a new configuration.
00:02:48 done sampling a new configuration.
00:02:48 HBMASTER: schedule new run for iteration 4
00:02:48 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
00:02:48 HBMASTER: submitting job (4, 0, 4) to dispatcher
00:02:48 DISPATCHER: trying to submit job (4, 0, 4)
00:02:48 DISPATCHER: trying to notify the job_runner thread.
00:02:48 HBMASTER: job (4, 0, 4) submitted to dispatcher
00:02:48 DISPATCHER: Trying to submit another job.
00:02:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:02:48 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:02:48 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:02:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:02:48 WORKER: start processing job (4, 0, 4)
00:02:48 WORKER: args: ()
00:02:48 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 359, 'last_n_outputs': 48, 'leak_rate': 0.9676753402428905, 'lr': 0.0010081443350067588, 'optimizer': 'SGD', 'sparsity': 0.7717024243800034, 'steps_to_train': 45, 'weight_decay': 0.01773977948987325}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:03:40 DISPATCHER: Starting worker discovery
00:03:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:03:40 DISPATCHER: Finished worker discovery
00:03:44 WORKER: done with job (4, 0, 4), trying to register it.
00:03:44 WORKER: registered result for job (4, 0, 4) with dispatcher
00:03:44 DISPATCHER: job (4, 0, 4) finished
00:03:44 DISPATCHER: register_result: lock acquired
00:03:44 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:03:44 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 359, 'last_n_outputs': 48, 'leak_rate': 0.9676753402428905, 'lr': 0.0010081443350067588, 'optimizer': 'SGD', 'sparsity': 0.7717024243800034, 'steps_to_train': 45, 'weight_decay': 0.01773977948987325}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.416746747602309, 'info': {'music-speech': 0.416746747602309, 'config': "{'batch_size': 16, 'hidden_dim': 359, 'last_n_outputs': 48, 'leak_rate': 0.9676753402428905, 'lr': 0.0010081443350067588, 'optimizer': 'SGD', 'sparsity': 0.7717024243800034, 'steps_to_train': 45, 'weight_decay': 0.01773977948987325}"}}
exception: None

00:03:44 job_callback for (4, 0, 4) started
00:03:44 DISPATCHER: Trying to submit another job.
00:03:44 job_callback for (4, 0, 4) got condition
00:03:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:03:44 done building a new model for budget 44.444444 based on 10/27 split
Best loss for this budget:-0.640582





00:03:44 HBMASTER: Trying to run another job!
00:03:44 job_callback for (4, 0, 4) finished
00:03:44 start sampling a new configuration.
00:03:44 done sampling a new configuration.
00:03:44 HBMASTER: schedule new run for iteration 4
00:03:44 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
00:03:44 HBMASTER: submitting job (4, 0, 5) to dispatcher
00:03:44 DISPATCHER: trying to submit job (4, 0, 5)
00:03:44 DISPATCHER: trying to notify the job_runner thread.
00:03:44 HBMASTER: job (4, 0, 5) submitted to dispatcher
00:03:44 DISPATCHER: Trying to submit another job.
00:03:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:03:44 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:03:44 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:03:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:03:44 WORKER: start processing job (4, 0, 5)
00:03:44 WORKER: args: ()
00:03:44 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 765, 'last_n_outputs': 18, 'leak_rate': 0.8404744540296243, 'lr': 0.03682103243779866, 'optimizer': 'SGD', 'sparsity': 0.986473154142282, 'steps_to_train': 43, 'weight_decay': 0.010832081526036697}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:04:40 DISPATCHER: Starting worker discovery
00:04:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:04:40 DISPATCHER: Finished worker discovery
00:04:44 WORKER: done with job (4, 0, 5), trying to register it.
00:04:44 WORKER: registered result for job (4, 0, 5) with dispatcher
00:04:44 DISPATCHER: job (4, 0, 5) finished
00:04:44 DISPATCHER: register_result: lock acquired
00:04:44 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:04:44 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 765, 'last_n_outputs': 18, 'leak_rate': 0.8404744540296243, 'lr': 0.03682103243779866, 'optimizer': 'SGD', 'sparsity': 0.986473154142282, 'steps_to_train': 43, 'weight_decay': 0.010832081526036697}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.47777320317568656, 'info': {'music-speech': 0.47777320317568656, 'config': "{'batch_size': 128, 'hidden_dim': 765, 'last_n_outputs': 18, 'leak_rate': 0.8404744540296243, 'lr': 0.03682103243779866, 'optimizer': 'SGD', 'sparsity': 0.986473154142282, 'steps_to_train': 43, 'weight_decay': 0.010832081526036697}"}}
exception: None

00:04:44 job_callback for (4, 0, 5) started
00:04:44 DISPATCHER: Trying to submit another job.
00:04:44 job_callback for (4, 0, 5) got condition
00:04:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:04:44 done building a new model for budget 44.444444 based on 10/28 split
Best loss for this budget:-0.640582





00:04:44 HBMASTER: Trying to run another job!
00:04:44 job_callback for (4, 0, 5) finished
00:04:44 start sampling a new configuration.
00:04:44 best_vector: [2, 0.5813843028352794, 0.0048694044660751445, 0.47486491490070537, 0.5926749163715426, 0, 0.07768960608438166, 0.4329321100524751, 0.962349078671189], 0.023892562561637434, 0.16562099288075985, 0.0039571099339240625
00:04:44 done sampling a new configuration.
00:04:44 HBMASTER: schedule new run for iteration 4
00:04:44 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
00:04:44 HBMASTER: submitting job (4, 0, 6) to dispatcher
00:04:44 DISPATCHER: trying to submit job (4, 0, 6)
00:04:44 DISPATCHER: trying to notify the job_runner thread.
00:04:44 HBMASTER: job (4, 0, 6) submitted to dispatcher
00:04:44 DISPATCHER: Trying to submit another job.
00:04:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:04:44 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:04:44 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:04:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:04:44 WORKER: start processing job (4, 0, 6)
00:04:44 WORKER: args: ()
00:04:44 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 665, 'last_n_outputs': 10, 'leak_rate': 0.8687162287251764, 'lr': 0.01532321279598055, 'optimizer': 'Adam', 'sparsity': 0.7686455054602516, 'steps_to_train': 49, 'weight_decay': 0.17866727663420406}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:05:40 DISPATCHER: Starting worker discovery
00:05:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:05:40 DISPATCHER: Finished worker discovery
00:05:49 WORKER: done with job (4, 0, 6), trying to register it.
00:05:49 WORKER: registered result for job (4, 0, 6) with dispatcher
00:05:49 DISPATCHER: job (4, 0, 6) finished
00:05:49 DISPATCHER: register_result: lock acquired
00:05:49 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:05:49 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 665, 'last_n_outputs': 10, 'leak_rate': 0.8687162287251764, 'lr': 0.01532321279598055, 'optimizer': 'Adam', 'sparsity': 0.7686455054602516, 'steps_to_train': 49, 'weight_decay': 0.17866727663420406}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4667405566432003, 'info': {'music-speech': 0.4667405566432003, 'config': "{'batch_size': 64, 'hidden_dim': 665, 'last_n_outputs': 10, 'leak_rate': 0.8687162287251764, 'lr': 0.01532321279598055, 'optimizer': 'Adam', 'sparsity': 0.7686455054602516, 'steps_to_train': 49, 'weight_decay': 0.17866727663420406}"}}
exception: None

00:05:49 job_callback for (4, 0, 6) started
00:05:49 job_callback for (4, 0, 6) got condition
00:05:49 DISPATCHER: Trying to submit another job.
00:05:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:05:49 done building a new model for budget 44.444444 based on 10/28 split
Best loss for this budget:-0.640582





00:05:49 HBMASTER: Trying to run another job!
00:05:49 job_callback for (4, 0, 6) finished
00:05:49 start sampling a new configuration.
00:05:49 done sampling a new configuration.
00:05:49 HBMASTER: schedule new run for iteration 4
00:05:49 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
00:05:49 HBMASTER: submitting job (4, 0, 7) to dispatcher
00:05:49 DISPATCHER: trying to submit job (4, 0, 7)
00:05:49 DISPATCHER: trying to notify the job_runner thread.
00:05:49 HBMASTER: job (4, 0, 7) submitted to dispatcher
00:05:49 DISPATCHER: Trying to submit another job.
00:05:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:05:49 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:05:49 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:05:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:05:49 WORKER: start processing job (4, 0, 7)
00:05:49 WORKER: args: ()
00:05:49 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 794, 'last_n_outputs': 17, 'leak_rate': 0.9329222373518887, 'lr': 0.03205419421750973, 'optimizer': 'Adam', 'sparsity': 0.9509974841063106, 'steps_to_train': 15, 'weight_decay': 0.08268364498150611}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:06:40 DISPATCHER: Starting worker discovery
00:06:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:06:40 DISPATCHER: Finished worker discovery
00:06:44 WORKER: done with job (4, 0, 7), trying to register it.
00:06:44 DISPATCHER: job (4, 0, 7) finished
00:06:44 WORKER: registered result for job (4, 0, 7) with dispatcher
00:06:44 DISPATCHER: register_result: lock acquired
00:06:44 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:06:44 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 794, 'last_n_outputs': 17, 'leak_rate': 0.9329222373518887, 'lr': 0.03205419421750973, 'optimizer': 'Adam', 'sparsity': 0.9509974841063106, 'steps_to_train': 15, 'weight_decay': 0.08268364498150611}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.33364783976695983, 'info': {'music-speech': 0.33364783976695983, 'config': "{'batch_size': 64, 'hidden_dim': 794, 'last_n_outputs': 17, 'leak_rate': 0.9329222373518887, 'lr': 0.03205419421750973, 'optimizer': 'Adam', 'sparsity': 0.9509974841063106, 'steps_to_train': 15, 'weight_decay': 0.08268364498150611}"}}
exception: None

00:06:44 job_callback for (4, 0, 7) started
00:06:44 DISPATCHER: Trying to submit another job.
00:06:44 job_callback for (4, 0, 7) got condition
00:06:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:06:44 done building a new model for budget 44.444444 based on 10/29 split
Best loss for this budget:-0.640582





00:06:44 HBMASTER: Trying to run another job!
00:06:44 job_callback for (4, 0, 7) finished
00:06:44 start sampling a new configuration.
00:06:44 done sampling a new configuration.
00:06:44 HBMASTER: schedule new run for iteration 4
00:06:44 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
00:06:44 HBMASTER: submitting job (4, 0, 8) to dispatcher
00:06:44 DISPATCHER: trying to submit job (4, 0, 8)
00:06:44 DISPATCHER: trying to notify the job_runner thread.
00:06:44 HBMASTER: job (4, 0, 8) submitted to dispatcher
00:06:44 DISPATCHER: Trying to submit another job.
00:06:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:06:44 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:06:44 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:06:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:06:44 WORKER: start processing job (4, 0, 8)
00:06:44 WORKER: args: ()
00:06:44 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 200, 'last_n_outputs': 36, 'leak_rate': 0.9578174285573076, 'lr': 0.008013313171241477, 'optimizer': 'SGD', 'sparsity': 0.8699852566179787, 'steps_to_train': 66, 'weight_decay': 0.05090763007989355}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:07:40 DISPATCHER: Starting worker discovery
00:07:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:07:40 DISPATCHER: Finished worker discovery
00:07:48 WORKER: done with job (4, 0, 8), trying to register it.
00:07:48 WORKER: registered result for job (4, 0, 8) with dispatcher
00:07:48 DISPATCHER: job (4, 0, 8) finished
00:07:48 DISPATCHER: register_result: lock acquired
00:07:48 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:07:48 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 200, 'last_n_outputs': 36, 'leak_rate': 0.9578174285573076, 'lr': 0.008013313171241477, 'optimizer': 'SGD', 'sparsity': 0.8699852566179787, 'steps_to_train': 66, 'weight_decay': 0.05090763007989355}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5871077905501809, 'info': {'music-speech': 0.5871077905501809, 'config': "{'batch_size': 64, 'hidden_dim': 200, 'last_n_outputs': 36, 'leak_rate': 0.9578174285573076, 'lr': 0.008013313171241477, 'optimizer': 'SGD', 'sparsity': 0.8699852566179787, 'steps_to_train': 66, 'weight_decay': 0.05090763007989355}"}}
exception: None

00:07:48 job_callback for (4, 0, 8) started
00:07:48 DISPATCHER: Trying to submit another job.
00:07:48 job_callback for (4, 0, 8) got condition
00:07:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:07:48 done building a new model for budget 44.444444 based on 10/30 split
Best loss for this budget:-0.640582





00:07:48 HBMASTER: Trying to run another job!
00:07:48 job_callback for (4, 0, 8) finished
00:07:48 start sampling a new configuration.
00:07:48 best_vector: [1, 0.14848841480168384, 0.6359200908267882, 0.9271646087861923, 0.2125225902479601, 0, 0.2668472953183216, 0.5821955805673724, 0.7736337440877251], 0.03102404019340359, 0.2468719245557205, 0.007658964510039571
00:07:48 done sampling a new configuration.
00:07:48 HBMASTER: schedule new run for iteration 4
00:07:48 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
00:07:48 HBMASTER: submitting job (4, 0, 9) to dispatcher
00:07:48 DISPATCHER: trying to submit job (4, 0, 9)
00:07:48 DISPATCHER: trying to notify the job_runner thread.
00:07:48 HBMASTER: job (4, 0, 9) submitted to dispatcher
00:07:48 DISPATCHER: Trying to submit another job.
00:07:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:07:48 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:07:48 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:07:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:07:48 WORKER: start processing job (4, 0, 9)
00:07:48 WORKER: args: ()
00:07:48 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 318, 'last_n_outputs': 36, 'leak_rate': 0.9817911521965481, 'lr': 0.002661001874577548, 'optimizer': 'Adam', 'sparsity': 0.8140433508763971, 'steps_to_train': 62, 'weight_decay': 0.10151277656707412}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:08:40 DISPATCHER: Starting worker discovery
00:08:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:08:40 DISPATCHER: Finished worker discovery
00:08:45 WORKER: done with job (4, 0, 9), trying to register it.
00:08:45 WORKER: registered result for job (4, 0, 9) with dispatcher
00:08:45 DISPATCHER: job (4, 0, 9) finished
00:08:45 DISPATCHER: register_result: lock acquired
00:08:45 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:08:45 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 318, 'last_n_outputs': 36, 'leak_rate': 0.9817911521965481, 'lr': 0.002661001874577548, 'optimizer': 'Adam', 'sparsity': 0.8140433508763971, 'steps_to_train': 62, 'weight_decay': 0.10151277656707412}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4944657477041751, 'info': {'music-speech': 0.4944657477041751, 'config': "{'batch_size': 32, 'hidden_dim': 318, 'last_n_outputs': 36, 'leak_rate': 0.9817911521965481, 'lr': 0.002661001874577548, 'optimizer': 'Adam', 'sparsity': 0.8140433508763971, 'steps_to_train': 62, 'weight_decay': 0.10151277656707412}"}}
exception: None

00:08:45 job_callback for (4, 0, 9) started
00:08:45 DISPATCHER: Trying to submit another job.
00:08:45 job_callback for (4, 0, 9) got condition
00:08:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:08:45 done building a new model for budget 44.444444 based on 10/31 split
Best loss for this budget:-0.640582





00:08:45 HBMASTER: Trying to run another job!
00:08:45 job_callback for (4, 0, 9) finished
00:08:45 start sampling a new configuration.
00:08:46 best_vector: [1, 0.5755061869053156, 0.24917315206804516, 0.25939437713790836, 0.14575654878103284, 1, 0.5803623931338655, 0.005306539642590813, 0.8572016977152742], 0.07047800592716613, 0.025338892102184207, 0.0017858345877655617
00:08:46 done sampling a new configuration.
00:08:46 HBMASTER: schedule new run for iteration 4
00:08:46 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
00:08:46 HBMASTER: submitting job (4, 0, 10) to dispatcher
00:08:46 DISPATCHER: trying to submit job (4, 0, 10)
00:08:46 DISPATCHER: trying to notify the job_runner thread.
00:08:46 HBMASTER: job (4, 0, 10) submitted to dispatcher
00:08:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:08:46 DISPATCHER: Trying to submit another job.
00:08:46 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:08:46 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:08:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:08:46 WORKER: start processing job (4, 0, 10)
00:08:46 WORKER: args: ()
00:08:46 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 660, 'last_n_outputs': 20, 'leak_rate': 0.8148485942844771, 'lr': 0.0019566497761805374, 'optimizer': 'SGD', 'sparsity': 0.8892869743521277, 'steps_to_train': 10, 'weight_decay': 0.13039025091618373}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:09:40 DISPATCHER: Starting worker discovery
00:09:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:09:40 DISPATCHER: Finished worker discovery
00:09:44 WORKER: done with job (4, 0, 10), trying to register it.
00:09:44 WORKER: registered result for job (4, 0, 10) with dispatcher
00:09:44 DISPATCHER: job (4, 0, 10) finished
00:09:44 DISPATCHER: register_result: lock acquired
00:09:44 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:09:44 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 660, 'last_n_outputs': 20, 'leak_rate': 0.8148485942844771, 'lr': 0.0019566497761805374, 'optimizer': 'SGD', 'sparsity': 0.8892869743521277, 'steps_to_train': 10, 'weight_decay': 0.13039025091618373}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5535917727912514, 'info': {'music-speech': 0.5535917727912514, 'config': "{'batch_size': 32, 'hidden_dim': 660, 'last_n_outputs': 20, 'leak_rate': 0.8148485942844771, 'lr': 0.0019566497761805374, 'optimizer': 'SGD', 'sparsity': 0.8892869743521277, 'steps_to_train': 10, 'weight_decay': 0.13039025091618373}"}}
exception: None

00:09:44 job_callback for (4, 0, 10) started
00:09:44 DISPATCHER: Trying to submit another job.
00:09:44 job_callback for (4, 0, 10) got condition
00:09:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:09:44 done building a new model for budget 44.444444 based on 10/32 split
Best loss for this budget:-0.640582





00:09:44 HBMASTER: Trying to run another job!
00:09:44 job_callback for (4, 0, 10) finished
00:09:44 start sampling a new configuration.
00:09:44 best_vector: [2, 0.5628956674670449, 0.42821876623310906, 0.07756038834869461, 0.9660786146842812, 0, 0.6100866003072019, 0.7590347125469585, 0.2167009266991179], 0.03669417971293719, 0.3409497099013899, 0.012510869928195402
00:09:44 done sampling a new configuration.
00:09:44 HBMASTER: schedule new run for iteration 4
00:09:44 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
00:09:44 HBMASTER: submitting job (4, 0, 11) to dispatcher
00:09:44 DISPATCHER: trying to submit job (4, 0, 11)
00:09:44 DISPATCHER: trying to notify the job_runner thread.
00:09:44 HBMASTER: job (4, 0, 11) submitted to dispatcher
00:09:44 DISPATCHER: Trying to submit another job.
00:09:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:09:44 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:09:44 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:09:44 WORKER: start processing job (4, 0, 11)
00:09:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:09:44 WORKER: args: ()
00:09:44 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 650, 'last_n_outputs': 27, 'leak_rate': 0.7693900970871737, 'lr': 0.08553763321501845, 'optimizer': 'Adam', 'sparsity': 0.8964207840737284, 'steps_to_train': 79, 'weight_decay': 0.019139668245251932}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:10:40 DISPATCHER: Starting worker discovery
00:10:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:10:40 DISPATCHER: Finished worker discovery
00:11:02 WORKER: done with job (4, 0, 11), trying to register it.
00:11:02 DISPATCHER: job (4, 0, 11) finished
00:11:02 WORKER: registered result for job (4, 0, 11) with dispatcher
00:11:02 DISPATCHER: register_result: lock acquired
00:11:02 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:11:02 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 650, 'last_n_outputs': 27, 'leak_rate': 0.7693900970871737, 'lr': 0.08553763321501845, 'optimizer': 'Adam', 'sparsity': 0.8964207840737284, 'steps_to_train': 79, 'weight_decay': 0.019139668245251932}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.40762803229274575, 'info': {'music-speech': 0.40762803229274575, 'config': "{'batch_size': 64, 'hidden_dim': 650, 'last_n_outputs': 27, 'leak_rate': 0.7693900970871737, 'lr': 0.08553763321501845, 'optimizer': 'Adam', 'sparsity': 0.8964207840737284, 'steps_to_train': 79, 'weight_decay': 0.019139668245251932}"}}
exception: None

00:11:02 job_callback for (4, 0, 11) started
00:11:02 DISPATCHER: Trying to submit another job.
00:11:02 job_callback for (4, 0, 11) got condition
00:11:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:11:02 done building a new model for budget 44.444444 based on 10/33 split
Best loss for this budget:-0.640582





00:11:02 HBMASTER: Trying to run another job!
00:11:02 job_callback for (4, 0, 11) finished
00:11:02 start sampling a new configuration.
00:11:02 best_vector: [1, 0.01037779549888912, 0.3741947127333962, 0.226360439994352, 0.17988626134068447, 1, 0.2210150343714536, 0.05471719756709825, 0.8550518417961941], 0.00817936695151113, 0.08361384692283438, 0.0006839083362093422
00:11:02 done sampling a new configuration.
00:11:02 HBMASTER: schedule new run for iteration 4
00:11:02 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
00:11:02 HBMASTER: submitting job (4, 0, 12) to dispatcher
00:11:02 DISPATCHER: trying to submit job (4, 0, 12)
00:11:02 DISPATCHER: trying to notify the job_runner thread.
00:11:02 HBMASTER: job (4, 0, 12) submitted to dispatcher
00:11:02 DISPATCHER: Trying to submit another job.
00:11:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:11:02 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:11:02 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:11:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:11:02 WORKER: start processing job (4, 0, 12)
00:11:02 WORKER: args: ()
00:11:02 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 208, 'last_n_outputs': 25, 'leak_rate': 0.806590109998588, 'lr': 0.002289668042828522, 'optimizer': 'SGD', 'sparsity': 0.8030436082491489, 'steps_to_train': 14, 'weight_decay': 0.12955318489849488}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:11:40 DISPATCHER: Starting worker discovery
00:11:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:11:40 DISPATCHER: Finished worker discovery
00:11:55 WORKER: done with job (4, 0, 12), trying to register it.
00:11:55 WORKER: registered result for job (4, 0, 12) with dispatcher
00:11:55 DISPATCHER: job (4, 0, 12) finished
00:11:55 DISPATCHER: register_result: lock acquired
00:11:55 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:11:55 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 208, 'last_n_outputs': 25, 'leak_rate': 0.806590109998588, 'lr': 0.002289668042828522, 'optimizer': 'SGD', 'sparsity': 0.8030436082491489, 'steps_to_train': 14, 'weight_decay': 0.12955318489849488}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6708488692622079, 'info': {'music-speech': 0.6708488692622079, 'config': "{'batch_size': 32, 'hidden_dim': 208, 'last_n_outputs': 25, 'leak_rate': 0.806590109998588, 'lr': 0.002289668042828522, 'optimizer': 'SGD', 'sparsity': 0.8030436082491489, 'steps_to_train': 14, 'weight_decay': 0.12955318489849488}"}}
exception: None

00:11:55 job_callback for (4, 0, 12) started
00:11:55 DISPATCHER: Trying to submit another job.
00:11:55 job_callback for (4, 0, 12) got condition
00:11:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:11:55 done building a new model for budget 44.444444 based on 10/34 split
Best loss for this budget:-0.670849





00:11:55 HBMASTER: Trying to run another job!
00:11:55 job_callback for (4, 0, 12) finished
00:11:55 start sampling a new configuration.
00:11:55 done sampling a new configuration.
00:11:55 HBMASTER: schedule new run for iteration 4
00:11:55 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
00:11:55 HBMASTER: submitting job (4, 0, 13) to dispatcher
00:11:55 DISPATCHER: trying to submit job (4, 0, 13)
00:11:55 DISPATCHER: trying to notify the job_runner thread.
00:11:55 HBMASTER: job (4, 0, 13) submitted to dispatcher
00:11:55 DISPATCHER: Trying to submit another job.
00:11:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:11:55 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:11:55 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:11:55 WORKER: start processing job (4, 0, 13)
00:11:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:11:55 WORKER: args: ()
00:11:55 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 624, 'last_n_outputs': 44, 'leak_rate': 0.7620243996818423, 'lr': 0.001265865440192964, 'optimizer': 'Adam', 'sparsity': 0.8305389308821292, 'steps_to_train': 16, 'weight_decay': 0.02357101498770184}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:12:40 DISPATCHER: Starting worker discovery
00:12:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:12:40 DISPATCHER: Finished worker discovery
00:12:53 WORKER: done with job (4, 0, 13), trying to register it.
00:12:53 DISPATCHER: job (4, 0, 13) finished
00:12:53 WORKER: registered result for job (4, 0, 13) with dispatcher
00:12:53 DISPATCHER: register_result: lock acquired
00:12:53 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:12:53 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 624, 'last_n_outputs': 44, 'leak_rate': 0.7620243996818423, 'lr': 0.001265865440192964, 'optimizer': 'Adam', 'sparsity': 0.8305389308821292, 'steps_to_train': 16, 'weight_decay': 0.02357101498770184}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6225343287066984, 'info': {'music-speech': 0.6225343287066984, 'config': "{'batch_size': 32, 'hidden_dim': 624, 'last_n_outputs': 44, 'leak_rate': 0.7620243996818423, 'lr': 0.001265865440192964, 'optimizer': 'Adam', 'sparsity': 0.8305389308821292, 'steps_to_train': 16, 'weight_decay': 0.02357101498770184}"}}
exception: None

00:12:53 job_callback for (4, 0, 13) started
00:12:53 DISPATCHER: Trying to submit another job.
00:12:53 job_callback for (4, 0, 13) got condition
00:12:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:12:53 done building a new model for budget 44.444444 based on 10/34 split
Best loss for this budget:-0.670849





00:12:53 HBMASTER: Trying to run another job!
00:12:53 job_callback for (4, 0, 13) finished
00:12:53 start sampling a new configuration.
00:12:53 best_vector: [1, 0.4946513753848049, 0.3890890779347879, 0.3765839266691987, 0.054722068258391154, 1, 0.16883977575967937, 0.23431539106218546, 0.914994301212075], 0.00823762569081733, 1.2103042001801638, 0.009970032973108238
00:12:53 done sampling a new configuration.
00:12:53 HBMASTER: schedule new run for iteration 4
00:12:53 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
00:12:53 HBMASTER: submitting job (4, 0, 14) to dispatcher
00:12:53 DISPATCHER: trying to submit job (4, 0, 14)
00:12:53 DISPATCHER: trying to notify the job_runner thread.
00:12:53 HBMASTER: job (4, 0, 14) submitted to dispatcher
00:12:53 DISPATCHER: Trying to submit another job.
00:12:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:12:53 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:12:53 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:12:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:12:53 WORKER: start processing job (4, 0, 14)
00:12:53 WORKER: args: ()
00:12:53 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 596, 'last_n_outputs': 25, 'leak_rate': 0.8441459816672997, 'lr': 0.0012866017462575437, 'optimizer': 'SGD', 'sparsity': 0.7905215461823231, 'steps_to_train': 31, 'weight_decay': 0.15503688420957393}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:13:40 DISPATCHER: Starting worker discovery
00:13:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:13:40 DISPATCHER: Finished worker discovery
00:13:54 WORKER: done with job (4, 0, 14), trying to register it.
00:13:54 WORKER: registered result for job (4, 0, 14) with dispatcher
00:13:54 DISPATCHER: job (4, 0, 14) finished
00:13:54 DISPATCHER: register_result: lock acquired
00:13:54 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:13:54 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 596, 'last_n_outputs': 25, 'leak_rate': 0.8441459816672997, 'lr': 0.0012866017462575437, 'optimizer': 'SGD', 'sparsity': 0.7905215461823231, 'steps_to_train': 31, 'weight_decay': 0.15503688420957393}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6829592505790002, 'info': {'music-speech': 0.6829592505790002, 'config': "{'batch_size': 32, 'hidden_dim': 596, 'last_n_outputs': 25, 'leak_rate': 0.8441459816672997, 'lr': 0.0012866017462575437, 'optimizer': 'SGD', 'sparsity': 0.7905215461823231, 'steps_to_train': 31, 'weight_decay': 0.15503688420957393}"}}
exception: None

00:13:54 job_callback for (4, 0, 14) started
00:13:54 job_callback for (4, 0, 14) got condition
00:13:54 DISPATCHER: Trying to submit another job.
00:13:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:13:54 done building a new model for budget 44.444444 based on 10/35 split
Best loss for this budget:-0.682959





00:13:54 HBMASTER: Trying to run another job!
00:13:54 job_callback for (4, 0, 14) finished
00:13:54 start sampling a new configuration.
00:13:54 best_vector: [0, 0.2953047205173715, 0.7888988713688623, 0.1015186192740995, 0.03561230647256109, 0, 0.6162523949898737, 0.1903631618605322, 0.47229249633410625], 0.007381708723029013, 0.4309992237412449, 0.003181510729509481
00:13:54 done sampling a new configuration.
00:13:54 HBMASTER: schedule new run for iteration 4
00:13:54 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
00:13:54 HBMASTER: submitting job (4, 0, 15) to dispatcher
00:13:54 DISPATCHER: trying to submit job (4, 0, 15)
00:13:54 DISPATCHER: trying to notify the job_runner thread.
00:13:54 HBMASTER: job (4, 0, 15) submitted to dispatcher
00:13:54 DISPATCHER: Trying to submit another job.
00:13:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:13:54 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:13:54 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:13:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:13:54 WORKER: start processing job (4, 0, 15)
00:13:54 WORKER: args: ()
00:13:54 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 436, 'last_n_outputs': 42, 'leak_rate': 0.7753796548185249, 'lr': 0.0011782151775714942, 'optimizer': 'Adam', 'sparsity': 0.8979005747975697, 'steps_to_train': 27, 'weight_decay': 0.04115917910712264}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:14:40 DISPATCHER: Starting worker discovery
00:14:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:14:40 DISPATCHER: Finished worker discovery
00:14:51 WORKER: done with job (4, 0, 15), trying to register it.
00:14:51 DISPATCHER: job (4, 0, 15) finished
00:14:51 WORKER: registered result for job (4, 0, 15) with dispatcher
00:14:51 DISPATCHER: register_result: lock acquired
00:14:51 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:14:51 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 436, 'last_n_outputs': 42, 'leak_rate': 0.7753796548185249, 'lr': 0.0011782151775714942, 'optimizer': 'Adam', 'sparsity': 0.8979005747975697, 'steps_to_train': 27, 'weight_decay': 0.04115917910712264}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.49350021706570096, 'info': {'music-speech': 0.49350021706570096, 'config': "{'batch_size': 16, 'hidden_dim': 436, 'last_n_outputs': 42, 'leak_rate': 0.7753796548185249, 'lr': 0.0011782151775714942, 'optimizer': 'Adam', 'sparsity': 0.8979005747975697, 'steps_to_train': 27, 'weight_decay': 0.04115917910712264}"}}
exception: None

00:14:51 job_callback for (4, 0, 15) started
00:14:51 DISPATCHER: Trying to submit another job.
00:14:51 job_callback for (4, 0, 15) got condition
00:14:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:14:51 done building a new model for budget 44.444444 based on 10/36 split
Best loss for this budget:-0.682959





00:14:51 HBMASTER: Trying to run another job!
00:14:51 job_callback for (4, 0, 15) finished
00:14:51 start sampling a new configuration.
00:14:51 best_vector: [2, 0.11316208816680302, 0.35055485040534784, 0.6160727364458582, 0.021036980949419387, 1, 0.5350942234955749, 0.5850593702151902, 0.5067198775034916], 0.04978197767774857, 0.238358966183761, 0.011865980733851218
00:14:51 done sampling a new configuration.
00:14:51 HBMASTER: schedule new run for iteration 4
00:14:51 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
00:14:51 HBMASTER: submitting job (4, 0, 16) to dispatcher
00:14:51 DISPATCHER: trying to submit job (4, 0, 16)
00:14:51 DISPATCHER: trying to notify the job_runner thread.
00:14:51 HBMASTER: job (4, 0, 16) submitted to dispatcher
00:14:51 DISPATCHER: Trying to submit another job.
00:14:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:14:51 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:14:51 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:14:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:14:51 WORKER: start processing job (4, 0, 16)
00:14:51 WORKER: args: ()
00:14:51 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 290, 'last_n_outputs': 24, 'leak_rate': 0.9040181841114645, 'lr': 0.001101726921588653, 'optimizer': 'SGD', 'sparsity': 0.8784226136389379, 'steps_to_train': 63, 'weight_decay': 0.04563076607678609}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:15:40 DISPATCHER: Starting worker discovery
00:15:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:15:40 DISPATCHER: Finished worker discovery
00:15:52 WORKER: done with job (4, 0, 16), trying to register it.
00:15:52 WORKER: registered result for job (4, 0, 16) with dispatcher
00:15:52 DISPATCHER: job (4, 0, 16) finished
00:15:52 DISPATCHER: register_result: lock acquired
00:15:52 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:15:52 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 290, 'last_n_outputs': 24, 'leak_rate': 0.9040181841114645, 'lr': 0.001101726921588653, 'optimizer': 'SGD', 'sparsity': 0.8784226136389379, 'steps_to_train': 63, 'weight_decay': 0.04563076607678609}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5869067370331603, 'info': {'music-speech': 0.5869067370331603, 'config': "{'batch_size': 64, 'hidden_dim': 290, 'last_n_outputs': 24, 'leak_rate': 0.9040181841114645, 'lr': 0.001101726921588653, 'optimizer': 'SGD', 'sparsity': 0.8784226136389379, 'steps_to_train': 63, 'weight_decay': 0.04563076607678609}"}}
exception: None

00:15:52 job_callback for (4, 0, 16) started
00:15:52 DISPATCHER: Trying to submit another job.
00:15:52 job_callback for (4, 0, 16) got condition
00:15:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:15:52 done building a new model for budget 44.444444 based on 10/37 split
Best loss for this budget:-0.682959





00:15:52 HBMASTER: Trying to run another job!
00:15:52 job_callback for (4, 0, 16) finished
00:15:52 start sampling a new configuration.
00:15:52 best_vector: [1, 0.42733137087313533, 0.3345175493832697, 0.49441623244912636, 0.08199129332076184, 1, 0.7481835764281449, 0.682763046289082, 0.49861599540125706], 0.013765677656396542, 1.2593847207050222, 0.017336284110616322
00:15:52 done sampling a new configuration.
00:15:52 HBMASTER: schedule new run for iteration 4
00:15:52 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
00:15:52 HBMASTER: submitting job (4, 0, 17) to dispatcher
00:15:52 DISPATCHER: trying to submit job (4, 0, 17)
00:15:52 DISPATCHER: trying to notify the job_runner thread.
00:15:52 HBMASTER: job (4, 0, 17) submitted to dispatcher
00:15:52 DISPATCHER: Trying to submit another job.
00:15:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:15:52 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:15:52 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:15:52 WORKER: start processing job (4, 0, 17)
00:15:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:15:52 WORKER: args: ()
00:15:52 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 542, 'last_n_outputs': 23, 'leak_rate': 0.8736040581122816, 'lr': 0.0014587557692112055, 'optimizer': 'SGD', 'sparsity': 0.9295640583427548, 'steps_to_train': 72, 'weight_decay': 0.04453632385123193}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:16:40 DISPATCHER: Starting worker discovery
00:16:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:16:40 DISPATCHER: Finished worker discovery
00:16:54 WORKER: done with job (4, 0, 17), trying to register it.
00:16:54 WORKER: registered result for job (4, 0, 17) with dispatcher
00:16:54 DISPATCHER: job (4, 0, 17) finished
00:16:54 DISPATCHER: register_result: lock acquired
00:16:54 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:16:54 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 542, 'last_n_outputs': 23, 'leak_rate': 0.8736040581122816, 'lr': 0.0014587557692112055, 'optimizer': 'SGD', 'sparsity': 0.9295640583427548, 'steps_to_train': 72, 'weight_decay': 0.04453632385123193}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5550044878102767, 'info': {'music-speech': 0.5550044878102767, 'config': "{'batch_size': 32, 'hidden_dim': 542, 'last_n_outputs': 23, 'leak_rate': 0.8736040581122816, 'lr': 0.0014587557692112055, 'optimizer': 'SGD', 'sparsity': 0.9295640583427548, 'steps_to_train': 72, 'weight_decay': 0.04453632385123193}"}}
exception: None

00:16:54 job_callback for (4, 0, 17) started
00:16:54 DISPATCHER: Trying to submit another job.
00:16:54 job_callback for (4, 0, 17) got condition
00:16:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:16:54 done building a new model for budget 44.444444 based on 10/38 split
Best loss for this budget:-0.682959





00:16:54 HBMASTER: Trying to run another job!
00:16:54 job_callback for (4, 0, 17) finished
00:16:54 start sampling a new configuration.
00:16:54 done sampling a new configuration.
00:16:54 HBMASTER: schedule new run for iteration 4
00:16:54 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
00:16:54 HBMASTER: submitting job (4, 0, 18) to dispatcher
00:16:54 DISPATCHER: trying to submit job (4, 0, 18)
00:16:54 DISPATCHER: trying to notify the job_runner thread.
00:16:54 HBMASTER: job (4, 0, 18) submitted to dispatcher
00:16:54 DISPATCHER: Trying to submit another job.
00:16:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:16:54 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:16:54 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:16:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:16:54 WORKER: start processing job (4, 0, 18)
00:16:54 WORKER: args: ()
00:16:54 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 659, 'last_n_outputs': 14, 'leak_rate': 0.7766370020638539, 'lr': 0.008951542105298034, 'optimizer': 'SGD', 'sparsity': 0.8379044785746246, 'steps_to_train': 14, 'weight_decay': 0.17696984685307807}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:17:40 DISPATCHER: Starting worker discovery
00:17:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:17:40 DISPATCHER: Finished worker discovery
00:17:50 WORKER: done with job (4, 0, 18), trying to register it.
00:17:50 DISPATCHER: job (4, 0, 18) finished
00:17:50 WORKER: registered result for job (4, 0, 18) with dispatcher
00:17:50 DISPATCHER: register_result: lock acquired
00:17:50 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:17:50 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 659, 'last_n_outputs': 14, 'leak_rate': 0.7766370020638539, 'lr': 0.008951542105298034, 'optimizer': 'SGD', 'sparsity': 0.8379044785746246, 'steps_to_train': 14, 'weight_decay': 0.17696984685307807}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3979127281379893, 'info': {'music-speech': 0.3979127281379893, 'config': "{'batch_size': 128, 'hidden_dim': 659, 'last_n_outputs': 14, 'leak_rate': 0.7766370020638539, 'lr': 0.008951542105298034, 'optimizer': 'SGD', 'sparsity': 0.8379044785746246, 'steps_to_train': 14, 'weight_decay': 0.17696984685307807}"}}
exception: None

00:17:50 job_callback for (4, 0, 18) started
00:17:50 DISPATCHER: Trying to submit another job.
00:17:50 job_callback for (4, 0, 18) got condition
00:17:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:17:50 done building a new model for budget 44.444444 based on 10/39 split
Best loss for this budget:-0.682959





00:17:50 HBMASTER: Trying to run another job!
00:17:50 job_callback for (4, 0, 18) finished
00:17:50 start sampling a new configuration.
00:17:50 best_vector: [0, 0.020712470891390562, 0.48900631138631506, 0.0020319307472977666, 0.07237646139825206, 1, 0.3174652810947532, 0.3028015928704544, 0.5979198222169695], 0.019548080478523966, 0.5288032784932867, 0.010337089045294089
00:17:50 done sampling a new configuration.
00:17:50 HBMASTER: schedule new run for iteration 4
00:17:50 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
00:17:50 HBMASTER: submitting job (4, 0, 19) to dispatcher
00:17:50 DISPATCHER: trying to submit job (4, 0, 19)
00:17:50 DISPATCHER: trying to notify the job_runner thread.
00:17:50 HBMASTER: job (4, 0, 19) submitted to dispatcher
00:17:50 DISPATCHER: Trying to submit another job.
00:17:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:17:50 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:17:50 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:17:50 WORKER: start processing job (4, 0, 19)
00:17:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:17:50 WORKER: args: ()
00:17:50 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 216, 'last_n_outputs': 30, 'leak_rate': 0.7505079826868244, 'lr': 0.0013955741702901038, 'optimizer': 'SGD', 'sparsity': 0.8261916674627408, 'steps_to_train': 37, 'weight_decay': 0.059966903482619474}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:18:40 DISPATCHER: Starting worker discovery
00:18:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:18:40 DISPATCHER: Finished worker discovery
00:18:50 WORKER: done with job (4, 0, 19), trying to register it.
00:18:50 WORKER: registered result for job (4, 0, 19) with dispatcher
00:18:50 DISPATCHER: job (4, 0, 19) finished
00:18:50 DISPATCHER: register_result: lock acquired
00:18:50 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:18:50 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 216, 'last_n_outputs': 30, 'leak_rate': 0.7505079826868244, 'lr': 0.0013955741702901038, 'optimizer': 'SGD', 'sparsity': 0.8261916674627408, 'steps_to_train': 37, 'weight_decay': 0.059966903482619474}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6789639858432379, 'info': {'music-speech': 0.6789639858432379, 'config': "{'batch_size': 16, 'hidden_dim': 216, 'last_n_outputs': 30, 'leak_rate': 0.7505079826868244, 'lr': 0.0013955741702901038, 'optimizer': 'SGD', 'sparsity': 0.8261916674627408, 'steps_to_train': 37, 'weight_decay': 0.059966903482619474}"}}
exception: None

00:18:50 job_callback for (4, 0, 19) started
00:18:50 DISPATCHER: Trying to submit another job.
00:18:50 job_callback for (4, 0, 19) got condition
00:18:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:18:50 done building a new model for budget 44.444444 based on 10/39 split
Best loss for this budget:-0.682959





00:18:50 HBMASTER: Trying to run another job!
00:18:50 job_callback for (4, 0, 19) finished
00:18:50 start sampling a new configuration.
00:18:50 done sampling a new configuration.
00:18:50 HBMASTER: schedule new run for iteration 4
00:18:50 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
00:18:50 HBMASTER: submitting job (4, 0, 20) to dispatcher
00:18:50 DISPATCHER: trying to submit job (4, 0, 20)
00:18:50 DISPATCHER: trying to notify the job_runner thread.
00:18:50 HBMASTER: job (4, 0, 20) submitted to dispatcher
00:18:50 DISPATCHER: Trying to submit another job.
00:18:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:18:50 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:18:50 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:18:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:18:50 WORKER: start processing job (4, 0, 20)
00:18:50 WORKER: args: ()
00:18:50 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 815, 'last_n_outputs': 23, 'leak_rate': 0.7768628227316634, 'lr': 0.004577861465866563, 'optimizer': 'SGD', 'sparsity': 0.9370593670854791, 'steps_to_train': 59, 'weight_decay': 0.01697233145447776}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:19:40 DISPATCHER: Starting worker discovery
00:19:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:19:40 DISPATCHER: Finished worker discovery
00:19:48 WORKER: done with job (4, 0, 20), trying to register it.
00:19:48 WORKER: registered result for job (4, 0, 20) with dispatcher
00:19:48 DISPATCHER: job (4, 0, 20) finished
00:19:48 DISPATCHER: register_result: lock acquired
00:19:48 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:19:48 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 815, 'last_n_outputs': 23, 'leak_rate': 0.7768628227316634, 'lr': 0.004577861465866563, 'optimizer': 'SGD', 'sparsity': 0.9370593670854791, 'steps_to_train': 59, 'weight_decay': 0.01697233145447776}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.38049413412870187, 'info': {'music-speech': 0.38049413412870187, 'config': "{'batch_size': 16, 'hidden_dim': 815, 'last_n_outputs': 23, 'leak_rate': 0.7768628227316634, 'lr': 0.004577861465866563, 'optimizer': 'SGD', 'sparsity': 0.9370593670854791, 'steps_to_train': 59, 'weight_decay': 0.01697233145447776}"}}
exception: None

00:19:48 job_callback for (4, 0, 20) started
00:19:48 DISPATCHER: Trying to submit another job.
00:19:48 job_callback for (4, 0, 20) got condition
00:19:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:19:48 done building a new model for budget 44.444444 based on 10/40 split
Best loss for this budget:-0.682959





00:19:48 HBMASTER: Trying to run another job!
00:19:48 job_callback for (4, 0, 20) finished
00:19:48 start sampling a new configuration.
00:19:48 done sampling a new configuration.
00:19:48 HBMASTER: schedule new run for iteration 4
00:19:48 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
00:19:48 HBMASTER: submitting job (4, 0, 21) to dispatcher
00:19:48 DISPATCHER: trying to submit job (4, 0, 21)
00:19:48 DISPATCHER: trying to notify the job_runner thread.
00:19:48 HBMASTER: job (4, 0, 21) submitted to dispatcher
00:19:48 DISPATCHER: Trying to submit another job.
00:19:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:19:48 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:19:48 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:19:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:19:48 WORKER: start processing job (4, 0, 21)
00:19:48 WORKER: args: ()
00:19:48 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 575, 'last_n_outputs': 31, 'leak_rate': 0.7570948661207749, 'lr': 0.0787962972029559, 'optimizer': 'SGD', 'sparsity': 0.8692860211464639, 'steps_to_train': 57, 'weight_decay': 0.03677010399630621}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:20:40 DISPATCHER: Starting worker discovery
00:20:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:20:40 DISPATCHER: Finished worker discovery
00:20:58 WORKER: done with job (4, 0, 21), trying to register it.
00:20:58 WORKER: registered result for job (4, 0, 21) with dispatcher
00:20:58 DISPATCHER: job (4, 0, 21) finished
00:20:58 DISPATCHER: register_result: lock acquired
00:20:58 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:20:58 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 575, 'last_n_outputs': 31, 'leak_rate': 0.7570948661207749, 'lr': 0.0787962972029559, 'optimizer': 'SGD', 'sparsity': 0.8692860211464639, 'steps_to_train': 57, 'weight_decay': 0.03677010399630621}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5055627142146013, 'info': {'music-speech': 0.5055627142146013, 'config': "{'batch_size': 16, 'hidden_dim': 575, 'last_n_outputs': 31, 'leak_rate': 0.7570948661207749, 'lr': 0.0787962972029559, 'optimizer': 'SGD', 'sparsity': 0.8692860211464639, 'steps_to_train': 57, 'weight_decay': 0.03677010399630621}"}}
exception: None

00:20:58 job_callback for (4, 0, 21) started
00:20:58 job_callback for (4, 0, 21) got condition
00:20:58 DISPATCHER: Trying to submit another job.
00:20:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:20:58 done building a new model for budget 44.444444 based on 10/41 split
Best loss for this budget:-0.682959





00:20:58 HBMASTER: Trying to run another job!
00:20:58 job_callback for (4, 0, 21) finished
00:20:58 start sampling a new configuration.
00:20:58 done sampling a new configuration.
00:20:58 HBMASTER: schedule new run for iteration 4
00:20:58 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
00:20:58 HBMASTER: submitting job (4, 0, 22) to dispatcher
00:20:58 DISPATCHER: trying to submit job (4, 0, 22)
00:20:58 DISPATCHER: trying to notify the job_runner thread.
00:20:58 HBMASTER: job (4, 0, 22) submitted to dispatcher
00:20:58 DISPATCHER: Trying to submit another job.
00:20:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:20:58 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:20:58 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:20:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:20:58 WORKER: start processing job (4, 0, 22)
00:20:58 WORKER: args: ()
00:20:58 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 651, 'last_n_outputs': 31, 'leak_rate': 0.9077310393616953, 'lr': 0.0166790387627067, 'optimizer': 'Adam', 'sparsity': 0.914095108935093, 'steps_to_train': 16, 'weight_decay': 0.036904995004314184}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:21:40 DISPATCHER: Starting worker discovery
00:21:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:21:40 DISPATCHER: Finished worker discovery
00:21:55 WORKER: done with job (4, 0, 22), trying to register it.
00:21:55 WORKER: registered result for job (4, 0, 22) with dispatcher
00:21:55 DISPATCHER: job (4, 0, 22) finished
00:21:55 DISPATCHER: register_result: lock acquired
00:21:55 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:21:55 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 651, 'last_n_outputs': 31, 'leak_rate': 0.9077310393616953, 'lr': 0.0166790387627067, 'optimizer': 'Adam', 'sparsity': 0.914095108935093, 'steps_to_train': 16, 'weight_decay': 0.036904995004314184}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.10683055716858224, 'info': {'music-speech': 0.10683055716858224, 'config': "{'batch_size': 64, 'hidden_dim': 651, 'last_n_outputs': 31, 'leak_rate': 0.9077310393616953, 'lr': 0.0166790387627067, 'optimizer': 'Adam', 'sparsity': 0.914095108935093, 'steps_to_train': 16, 'weight_decay': 0.036904995004314184}"}}
exception: None

00:21:55 job_callback for (4, 0, 22) started
00:21:55 DISPATCHER: Trying to submit another job.
00:21:55 job_callback for (4, 0, 22) got condition
00:21:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:21:55 done building a new model for budget 44.444444 based on 10/42 split
Best loss for this budget:-0.682959





00:21:55 HBMASTER: Trying to run another job!
00:21:55 job_callback for (4, 0, 22) finished
00:21:55 start sampling a new configuration.
00:21:55 done sampling a new configuration.
00:21:55 HBMASTER: schedule new run for iteration 4
00:21:55 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
00:21:55 HBMASTER: submitting job (4, 0, 23) to dispatcher
00:21:55 DISPATCHER: trying to submit job (4, 0, 23)
00:21:55 DISPATCHER: trying to notify the job_runner thread.
00:21:55 HBMASTER: job (4, 0, 23) submitted to dispatcher
00:21:55 DISPATCHER: Trying to submit another job.
00:21:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:21:55 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:21:55 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:21:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:21:55 WORKER: start processing job (4, 0, 23)
00:21:55 WORKER: args: ()
00:21:55 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 842, 'last_n_outputs': 28, 'leak_rate': 0.8053989173967842, 'lr': 0.02825792331150201, 'optimizer': 'SGD', 'sparsity': 0.9414044705535471, 'steps_to_train': 48, 'weight_decay': 0.012845338518940326}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:22:40 DISPATCHER: Starting worker discovery
00:22:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:22:40 DISPATCHER: Finished worker discovery
00:22:57 WORKER: done with job (4, 0, 23), trying to register it.
00:22:57 DISPATCHER: job (4, 0, 23) finished
00:22:57 WORKER: registered result for job (4, 0, 23) with dispatcher
00:22:57 DISPATCHER: register_result: lock acquired
00:22:57 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:22:57 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 842, 'last_n_outputs': 28, 'leak_rate': 0.8053989173967842, 'lr': 0.02825792331150201, 'optimizer': 'SGD', 'sparsity': 0.9414044705535471, 'steps_to_train': 48, 'weight_decay': 0.012845338518940326}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.43414002488891773, 'info': {'music-speech': 0.43414002488891773, 'config': "{'batch_size': 16, 'hidden_dim': 842, 'last_n_outputs': 28, 'leak_rate': 0.8053989173967842, 'lr': 0.02825792331150201, 'optimizer': 'SGD', 'sparsity': 0.9414044705535471, 'steps_to_train': 48, 'weight_decay': 0.012845338518940326}"}}
exception: None

00:22:57 job_callback for (4, 0, 23) started
00:22:57 DISPATCHER: Trying to submit another job.
00:22:57 job_callback for (4, 0, 23) got condition
00:22:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:22:57 done building a new model for budget 44.444444 based on 10/43 split
Best loss for this budget:-0.682959





00:22:57 HBMASTER: Trying to run another job!
00:22:57 job_callback for (4, 0, 23) finished
00:22:57 start sampling a new configuration.
00:22:57 done sampling a new configuration.
00:22:57 HBMASTER: schedule new run for iteration 4
00:22:57 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
00:22:57 HBMASTER: submitting job (4, 0, 24) to dispatcher
00:22:57 DISPATCHER: trying to submit job (4, 0, 24)
00:22:57 DISPATCHER: trying to notify the job_runner thread.
00:22:57 HBMASTER: job (4, 0, 24) submitted to dispatcher
00:22:57 DISPATCHER: Trying to submit another job.
00:22:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:22:57 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:22:57 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:22:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:22:57 WORKER: start processing job (4, 0, 24)
00:22:57 WORKER: args: ()
00:22:57 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 898, 'last_n_outputs': 17, 'leak_rate': 0.9538608018985277, 'lr': 0.026279825050080505, 'optimizer': 'SGD', 'sparsity': 0.8785281023322501, 'steps_to_train': 65, 'weight_decay': 0.0987993646011477}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:23:40 DISPATCHER: Starting worker discovery
00:23:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:23:40 DISPATCHER: Finished worker discovery
00:24:01 WORKER: done with job (4, 0, 24), trying to register it.
00:24:01 WORKER: registered result for job (4, 0, 24) with dispatcher
00:24:01 DISPATCHER: job (4, 0, 24) finished
00:24:01 DISPATCHER: register_result: lock acquired
00:24:01 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:24:01 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 898, 'last_n_outputs': 17, 'leak_rate': 0.9538608018985277, 'lr': 0.026279825050080505, 'optimizer': 'SGD', 'sparsity': 0.8785281023322501, 'steps_to_train': 65, 'weight_decay': 0.0987993646011477}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4208906446593047, 'info': {'music-speech': 0.4208906446593047, 'config': "{'batch_size': 32, 'hidden_dim': 898, 'last_n_outputs': 17, 'leak_rate': 0.9538608018985277, 'lr': 0.026279825050080505, 'optimizer': 'SGD', 'sparsity': 0.8785281023322501, 'steps_to_train': 65, 'weight_decay': 0.0987993646011477}"}}
exception: None

00:24:01 job_callback for (4, 0, 24) started
00:24:01 DISPATCHER: Trying to submit another job.
00:24:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:24:01 job_callback for (4, 0, 24) got condition
00:24:01 done building a new model for budget 44.444444 based on 10/44 split
Best loss for this budget:-0.682959





00:24:01 HBMASTER: Trying to run another job!
00:24:01 job_callback for (4, 0, 24) finished
00:24:01 start sampling a new configuration.
00:24:01 done sampling a new configuration.
00:24:01 HBMASTER: schedule new run for iteration 4
00:24:01 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
00:24:01 HBMASTER: submitting job (4, 0, 25) to dispatcher
00:24:01 DISPATCHER: trying to submit job (4, 0, 25)
00:24:01 DISPATCHER: trying to notify the job_runner thread.
00:24:01 HBMASTER: job (4, 0, 25) submitted to dispatcher
00:24:01 DISPATCHER: Trying to submit another job.
00:24:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:24:01 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:24:01 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:24:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:24:01 WORKER: start processing job (4, 0, 25)
00:24:01 WORKER: args: ()
00:24:01 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 986, 'last_n_outputs': 19, 'leak_rate': 0.9628615284643612, 'lr': 0.06663281069532566, 'optimizer': 'SGD', 'sparsity': 0.916574355253241, 'steps_to_train': 76, 'weight_decay': 0.13695899445774287}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:24:40 DISPATCHER: Starting worker discovery
00:24:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:24:40 DISPATCHER: Finished worker discovery
00:25:09 WORKER: done with job (4, 0, 25), trying to register it.
00:25:09 WORKER: registered result for job (4, 0, 25) with dispatcher
00:25:09 DISPATCHER: job (4, 0, 25) finished
00:25:09 DISPATCHER: register_result: lock acquired
00:25:09 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:25:09 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 986, 'last_n_outputs': 19, 'leak_rate': 0.9628615284643612, 'lr': 0.06663281069532566, 'optimizer': 'SGD', 'sparsity': 0.916574355253241, 'steps_to_train': 76, 'weight_decay': 0.13695899445774287}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4897594865657759, 'info': {'music-speech': 0.4897594865657759, 'config': "{'batch_size': 128, 'hidden_dim': 986, 'last_n_outputs': 19, 'leak_rate': 0.9628615284643612, 'lr': 0.06663281069532566, 'optimizer': 'SGD', 'sparsity': 0.916574355253241, 'steps_to_train': 76, 'weight_decay': 0.13695899445774287}"}}
exception: None

00:25:09 job_callback for (4, 0, 25) started
00:25:09 job_callback for (4, 0, 25) got condition
00:25:09 DISPATCHER: Trying to submit another job.
00:25:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:25:09 done building a new model for budget 44.444444 based on 10/45 split
Best loss for this budget:-0.682959





00:25:09 HBMASTER: Trying to run another job!
00:25:09 job_callback for (4, 0, 25) finished
00:25:09 start sampling a new configuration.
00:25:09 done sampling a new configuration.
00:25:09 HBMASTER: schedule new run for iteration 4
00:25:09 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
00:25:09 HBMASTER: submitting job (4, 0, 26) to dispatcher
00:25:09 DISPATCHER: trying to submit job (4, 0, 26)
00:25:09 DISPATCHER: trying to notify the job_runner thread.
00:25:09 HBMASTER: job (4, 0, 26) submitted to dispatcher
00:25:09 DISPATCHER: Trying to submit another job.
00:25:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:25:09 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:25:09 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:25:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:25:09 WORKER: start processing job (4, 0, 26)
00:25:09 WORKER: args: ()
00:25:09 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 553, 'last_n_outputs': 28, 'leak_rate': 0.9449819078554309, 'lr': 0.04667807590812066, 'optimizer': 'Adam', 'sparsity': 0.8143547990129085, 'steps_to_train': 29, 'weight_decay': 0.014796968720055146}, 'budget': 44.44444444444444, 'working_directory': '.'}
00:25:40 DISPATCHER: Starting worker discovery
00:25:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:25:40 DISPATCHER: Finished worker discovery
00:26:13 WORKER: done with job (4, 0, 26), trying to register it.
00:26:13 WORKER: registered result for job (4, 0, 26) with dispatcher
00:26:13 DISPATCHER: job (4, 0, 26) finished
00:26:13 DISPATCHER: register_result: lock acquired
00:26:13 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:26:13 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 553, 'last_n_outputs': 28, 'leak_rate': 0.9449819078554309, 'lr': 0.04667807590812066, 'optimizer': 'Adam', 'sparsity': 0.8143547990129085, 'steps_to_train': 29, 'weight_decay': 0.014796968720055146}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.40516992416839986, 'info': {'music-speech': 0.40516992416839986, 'config': "{'batch_size': 128, 'hidden_dim': 553, 'last_n_outputs': 28, 'leak_rate': 0.9449819078554309, 'lr': 0.04667807590812066, 'optimizer': 'Adam', 'sparsity': 0.8143547990129085, 'steps_to_train': 29, 'weight_decay': 0.014796968720055146}"}}
exception: None

00:26:13 job_callback for (4, 0, 26) started
00:26:13 DISPATCHER: Trying to submit another job.
00:26:13 job_callback for (4, 0, 26) got condition
00:26:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:26:13 done building a new model for budget 44.444444 based on 10/45 split
Best loss for this budget:-0.682959





00:26:13 HBMASTER: Trying to run another job!
00:26:13 job_callback for (4, 0, 26) finished
00:26:13 ITERATION: Advancing config (4, 0, 0) to next budget 133.333333
00:26:13 ITERATION: Advancing config (4, 0, 8) to next budget 133.333333
00:26:13 ITERATION: Advancing config (4, 0, 10) to next budget 133.333333
00:26:13 ITERATION: Advancing config (4, 0, 12) to next budget 133.333333
00:26:13 ITERATION: Advancing config (4, 0, 13) to next budget 133.333333
00:26:13 ITERATION: Advancing config (4, 0, 14) to next budget 133.333333
00:26:13 ITERATION: Advancing config (4, 0, 16) to next budget 133.333333
00:26:13 ITERATION: Advancing config (4, 0, 17) to next budget 133.333333
00:26:13 ITERATION: Advancing config (4, 0, 19) to next budget 133.333333
00:26:13 HBMASTER: schedule new run for iteration 4
00:26:13 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
00:26:13 HBMASTER: submitting job (4, 0, 0) to dispatcher
00:26:13 DISPATCHER: trying to submit job (4, 0, 0)
00:26:13 DISPATCHER: trying to notify the job_runner thread.
00:26:13 HBMASTER: job (4, 0, 0) submitted to dispatcher
00:26:13 DISPATCHER: Trying to submit another job.
00:26:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:26:13 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:26:13 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:26:13 WORKER: start processing job (4, 0, 0)
00:26:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:26:13 WORKER: args: ()
00:26:13 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 953, 'last_n_outputs': 26, 'leak_rate': 0.8568348056960546, 'lr': 0.0021356176368731456, 'optimizer': 'SGD', 'sparsity': 0.7726777448519315, 'steps_to_train': 42, 'weight_decay': 0.1857206072557814}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:26:40 DISPATCHER: Starting worker discovery
00:26:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:26:40 DISPATCHER: Finished worker discovery
00:27:40 DISPATCHER: Starting worker discovery
00:27:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:27:40 DISPATCHER: Finished worker discovery
00:28:40 DISPATCHER: Starting worker discovery
00:28:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:28:40 DISPATCHER: Finished worker discovery
00:28:47 WORKER: done with job (4, 0, 0), trying to register it.
00:28:47 WORKER: registered result for job (4, 0, 0) with dispatcher
00:28:47 DISPATCHER: job (4, 0, 0) finished
00:28:47 DISPATCHER: register_result: lock acquired
00:28:47 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:28:47 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 953, 'last_n_outputs': 26, 'leak_rate': 0.8568348056960546, 'lr': 0.0021356176368731456, 'optimizer': 'SGD', 'sparsity': 0.7726777448519315, 'steps_to_train': 42, 'weight_decay': 0.1857206072557814}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5056785518177875, 'info': {'music-speech': 0.5056785518177875, 'config': "{'batch_size': 128, 'hidden_dim': 953, 'last_n_outputs': 26, 'leak_rate': 0.8568348056960546, 'lr': 0.0021356176368731456, 'optimizer': 'SGD', 'sparsity': 0.7726777448519315, 'steps_to_train': 42, 'weight_decay': 0.1857206072557814}"}}
exception: None

00:28:47 job_callback for (4, 0, 0) started
00:28:47 DISPATCHER: Trying to submit another job.
00:28:47 job_callback for (4, 0, 0) got condition
00:28:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:28:47 HBMASTER: Trying to run another job!
00:28:47 job_callback for (4, 0, 0) finished
00:28:47 HBMASTER: schedule new run for iteration 4
00:28:47 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
00:28:47 HBMASTER: submitting job (4, 0, 8) to dispatcher
00:28:47 DISPATCHER: trying to submit job (4, 0, 8)
00:28:47 DISPATCHER: trying to notify the job_runner thread.
00:28:47 HBMASTER: job (4, 0, 8) submitted to dispatcher
00:28:47 DISPATCHER: Trying to submit another job.
00:28:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:28:47 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:28:47 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:28:47 WORKER: start processing job (4, 0, 8)
00:28:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:28:47 WORKER: args: ()
00:28:47 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 200, 'last_n_outputs': 36, 'leak_rate': 0.9578174285573076, 'lr': 0.008013313171241477, 'optimizer': 'SGD', 'sparsity': 0.8699852566179787, 'steps_to_train': 66, 'weight_decay': 0.05090763007989355}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:29:40 DISPATCHER: Starting worker discovery
00:29:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:29:40 DISPATCHER: Finished worker discovery
00:30:40 DISPATCHER: Starting worker discovery
00:30:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:30:40 DISPATCHER: Finished worker discovery
00:31:09 WORKER: done with job (4, 0, 8), trying to register it.
00:31:09 WORKER: registered result for job (4, 0, 8) with dispatcher
00:31:09 DISPATCHER: job (4, 0, 8) finished
00:31:09 DISPATCHER: register_result: lock acquired
00:31:09 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:31:09 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 200, 'last_n_outputs': 36, 'leak_rate': 0.9578174285573076, 'lr': 0.008013313171241477, 'optimizer': 'SGD', 'sparsity': 0.8699852566179787, 'steps_to_train': 66, 'weight_decay': 0.05090763007989355}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6656900331753778, 'info': {'music-speech': 0.6656900331753778, 'config': "{'batch_size': 64, 'hidden_dim': 200, 'last_n_outputs': 36, 'leak_rate': 0.9578174285573076, 'lr': 0.008013313171241477, 'optimizer': 'SGD', 'sparsity': 0.8699852566179787, 'steps_to_train': 66, 'weight_decay': 0.05090763007989355}"}}
exception: None

00:31:09 job_callback for (4, 0, 8) started
00:31:09 DISPATCHER: Trying to submit another job.
00:31:09 job_callback for (4, 0, 8) got condition
00:31:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:31:09 done building a new model for budget 133.333333 based on 10/17 split
Best loss for this budget:-0.665690





00:31:09 HBMASTER: Trying to run another job!
00:31:09 job_callback for (4, 0, 8) finished
00:31:09 HBMASTER: schedule new run for iteration 4
00:31:09 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
00:31:09 HBMASTER: submitting job (4, 0, 10) to dispatcher
00:31:09 DISPATCHER: trying to submit job (4, 0, 10)
00:31:09 DISPATCHER: trying to notify the job_runner thread.
00:31:09 HBMASTER: job (4, 0, 10) submitted to dispatcher
00:31:09 DISPATCHER: Trying to submit another job.
00:31:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:31:09 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:31:09 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:31:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:31:09 WORKER: start processing job (4, 0, 10)
00:31:09 WORKER: args: ()
00:31:09 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 660, 'last_n_outputs': 20, 'leak_rate': 0.8148485942844771, 'lr': 0.0019566497761805374, 'optimizer': 'SGD', 'sparsity': 0.8892869743521277, 'steps_to_train': 10, 'weight_decay': 0.13039025091618373}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:31:40 DISPATCHER: Starting worker discovery
00:31:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:31:40 DISPATCHER: Finished worker discovery
00:32:40 DISPATCHER: Starting worker discovery
00:32:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:32:40 DISPATCHER: Finished worker discovery
00:33:32 WORKER: done with job (4, 0, 10), trying to register it.
00:33:32 WORKER: registered result for job (4, 0, 10) with dispatcher
00:33:32 DISPATCHER: job (4, 0, 10) finished
00:33:32 DISPATCHER: register_result: lock acquired
00:33:32 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:33:32 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 660, 'last_n_outputs': 20, 'leak_rate': 0.8148485942844771, 'lr': 0.0019566497761805374, 'optimizer': 'SGD', 'sparsity': 0.8892869743521277, 'steps_to_train': 10, 'weight_decay': 0.13039025091618373}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.3749968276213104, 'info': {'music-speech': 0.3749968276213104, 'config': "{'batch_size': 32, 'hidden_dim': 660, 'last_n_outputs': 20, 'leak_rate': 0.8148485942844771, 'lr': 0.0019566497761805374, 'optimizer': 'SGD', 'sparsity': 0.8892869743521277, 'steps_to_train': 10, 'weight_decay': 0.13039025091618373}"}}
exception: None

00:33:32 job_callback for (4, 0, 10) started
00:33:32 job_callback for (4, 0, 10) got condition
00:33:32 DISPATCHER: Trying to submit another job.
00:33:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:33:32 done building a new model for budget 133.333333 based on 10/17 split
Best loss for this budget:-0.665690





00:33:32 HBMASTER: Trying to run another job!
00:33:32 job_callback for (4, 0, 10) finished
00:33:32 HBMASTER: schedule new run for iteration 4
00:33:32 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
00:33:32 HBMASTER: submitting job (4, 0, 12) to dispatcher
00:33:32 DISPATCHER: trying to submit job (4, 0, 12)
00:33:32 DISPATCHER: trying to notify the job_runner thread.
00:33:32 HBMASTER: job (4, 0, 12) submitted to dispatcher
00:33:32 DISPATCHER: Trying to submit another job.
00:33:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:33:32 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:33:32 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:33:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:33:32 WORKER: start processing job (4, 0, 12)
00:33:32 WORKER: args: ()
00:33:32 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 208, 'last_n_outputs': 25, 'leak_rate': 0.806590109998588, 'lr': 0.002289668042828522, 'optimizer': 'SGD', 'sparsity': 0.8030436082491489, 'steps_to_train': 14, 'weight_decay': 0.12955318489849488}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:33:40 DISPATCHER: Starting worker discovery
00:33:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:33:40 DISPATCHER: Finished worker discovery
00:34:40 DISPATCHER: Starting worker discovery
00:34:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:34:40 DISPATCHER: Finished worker discovery
00:35:40 DISPATCHER: Starting worker discovery
00:35:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:35:40 DISPATCHER: Finished worker discovery
00:35:56 WORKER: done with job (4, 0, 12), trying to register it.
00:35:56 WORKER: registered result for job (4, 0, 12) with dispatcher
00:35:56 DISPATCHER: job (4, 0, 12) finished
00:35:56 DISPATCHER: register_result: lock acquired
00:35:56 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:35:56 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 208, 'last_n_outputs': 25, 'leak_rate': 0.806590109998588, 'lr': 0.002289668042828522, 'optimizer': 'SGD', 'sparsity': 0.8030436082491489, 'steps_to_train': 14, 'weight_decay': 0.12955318489849488}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.533737882154091, 'info': {'music-speech': 0.533737882154091, 'config': "{'batch_size': 32, 'hidden_dim': 208, 'last_n_outputs': 25, 'leak_rate': 0.806590109998588, 'lr': 0.002289668042828522, 'optimizer': 'SGD', 'sparsity': 0.8030436082491489, 'steps_to_train': 14, 'weight_decay': 0.12955318489849488}"}}
exception: None

00:35:56 job_callback for (4, 0, 12) started
00:35:56 DISPATCHER: Trying to submit another job.
00:35:56 job_callback for (4, 0, 12) got condition
00:35:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:35:56 done building a new model for budget 133.333333 based on 10/18 split
Best loss for this budget:-0.665690





00:35:56 HBMASTER: Trying to run another job!
00:35:56 job_callback for (4, 0, 12) finished
00:35:56 HBMASTER: schedule new run for iteration 4
00:35:56 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
00:35:56 HBMASTER: submitting job (4, 0, 13) to dispatcher
00:35:56 DISPATCHER: trying to submit job (4, 0, 13)
00:35:56 DISPATCHER: trying to notify the job_runner thread.
00:35:56 HBMASTER: job (4, 0, 13) submitted to dispatcher
00:35:56 DISPATCHER: Trying to submit another job.
00:35:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:35:56 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:35:56 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:35:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:35:56 WORKER: start processing job (4, 0, 13)
00:35:56 WORKER: args: ()
00:35:56 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 624, 'last_n_outputs': 44, 'leak_rate': 0.7620243996818423, 'lr': 0.001265865440192964, 'optimizer': 'Adam', 'sparsity': 0.8305389308821292, 'steps_to_train': 16, 'weight_decay': 0.02357101498770184}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:36:40 DISPATCHER: Starting worker discovery
00:36:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:36:40 DISPATCHER: Finished worker discovery
00:37:40 DISPATCHER: Starting worker discovery
00:37:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:37:40 DISPATCHER: Finished worker discovery
00:38:22 WORKER: done with job (4, 0, 13), trying to register it.
00:38:22 WORKER: registered result for job (4, 0, 13) with dispatcher
00:38:22 DISPATCHER: job (4, 0, 13) finished
00:38:22 DISPATCHER: register_result: lock acquired
00:38:22 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:38:22 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 624, 'last_n_outputs': 44, 'leak_rate': 0.7620243996818423, 'lr': 0.001265865440192964, 'optimizer': 'Adam', 'sparsity': 0.8305389308821292, 'steps_to_train': 16, 'weight_decay': 0.02357101498770184}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.33320544239170025, 'info': {'music-speech': 0.33320544239170025, 'config': "{'batch_size': 32, 'hidden_dim': 624, 'last_n_outputs': 44, 'leak_rate': 0.7620243996818423, 'lr': 0.001265865440192964, 'optimizer': 'Adam', 'sparsity': 0.8305389308821292, 'steps_to_train': 16, 'weight_decay': 0.02357101498770184}"}}
exception: None

00:38:22 job_callback for (4, 0, 13) started
00:38:22 job_callback for (4, 0, 13) got condition
00:38:22 DISPATCHER: Trying to submit another job.
00:38:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:38:22 done building a new model for budget 133.333333 based on 10/19 split
Best loss for this budget:-0.665690





00:38:22 HBMASTER: Trying to run another job!
00:38:22 job_callback for (4, 0, 13) finished
00:38:22 HBMASTER: schedule new run for iteration 4
00:38:22 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
00:38:22 HBMASTER: submitting job (4, 0, 14) to dispatcher
00:38:22 DISPATCHER: trying to submit job (4, 0, 14)
00:38:22 DISPATCHER: trying to notify the job_runner thread.
00:38:22 HBMASTER: job (4, 0, 14) submitted to dispatcher
00:38:22 DISPATCHER: Trying to submit another job.
00:38:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:38:22 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:38:22 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:38:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:38:22 WORKER: start processing job (4, 0, 14)
00:38:22 WORKER: args: ()
00:38:22 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 596, 'last_n_outputs': 25, 'leak_rate': 0.8441459816672997, 'lr': 0.0012866017462575437, 'optimizer': 'SGD', 'sparsity': 0.7905215461823231, 'steps_to_train': 31, 'weight_decay': 0.15503688420957393}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:38:40 DISPATCHER: Starting worker discovery
00:38:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:38:40 DISPATCHER: Finished worker discovery
00:39:40 DISPATCHER: Starting worker discovery
00:39:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:39:40 DISPATCHER: Finished worker discovery
00:40:40 DISPATCHER: Starting worker discovery
00:40:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:40:40 DISPATCHER: Finished worker discovery
00:40:46 WORKER: done with job (4, 0, 14), trying to register it.
00:40:46 WORKER: registered result for job (4, 0, 14) with dispatcher
00:40:46 DISPATCHER: job (4, 0, 14) finished
00:40:46 DISPATCHER: register_result: lock acquired
00:40:46 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:40:46 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 596, 'last_n_outputs': 25, 'leak_rate': 0.8441459816672997, 'lr': 0.0012866017462575437, 'optimizer': 'SGD', 'sparsity': 0.7905215461823231, 'steps_to_train': 31, 'weight_decay': 0.15503688420957393}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5821837103946297, 'info': {'music-speech': 0.5821837103946297, 'config': "{'batch_size': 32, 'hidden_dim': 596, 'last_n_outputs': 25, 'leak_rate': 0.8441459816672997, 'lr': 0.0012866017462575437, 'optimizer': 'SGD', 'sparsity': 0.7905215461823231, 'steps_to_train': 31, 'weight_decay': 0.15503688420957393}"}}
exception: None

00:40:46 job_callback for (4, 0, 14) started
00:40:46 DISPATCHER: Trying to submit another job.
00:40:46 job_callback for (4, 0, 14) got condition
00:40:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:40:46 done building a new model for budget 133.333333 based on 10/20 split
Best loss for this budget:-0.665690





00:40:46 HBMASTER: Trying to run another job!
00:40:46 job_callback for (4, 0, 14) finished
00:40:46 HBMASTER: schedule new run for iteration 4
00:40:46 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
00:40:46 HBMASTER: submitting job (4, 0, 16) to dispatcher
00:40:46 DISPATCHER: trying to submit job (4, 0, 16)
00:40:46 DISPATCHER: trying to notify the job_runner thread.
00:40:46 HBMASTER: job (4, 0, 16) submitted to dispatcher
00:40:46 DISPATCHER: Trying to submit another job.
00:40:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:40:46 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:40:46 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:40:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:40:46 WORKER: start processing job (4, 0, 16)
00:40:46 WORKER: args: ()
00:40:46 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 290, 'last_n_outputs': 24, 'leak_rate': 0.9040181841114645, 'lr': 0.001101726921588653, 'optimizer': 'SGD', 'sparsity': 0.8784226136389379, 'steps_to_train': 63, 'weight_decay': 0.04563076607678609}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:41:40 DISPATCHER: Starting worker discovery
00:41:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:41:40 DISPATCHER: Finished worker discovery
00:42:40 DISPATCHER: Starting worker discovery
00:42:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:42:40 DISPATCHER: Finished worker discovery
00:43:18 WORKER: done with job (4, 0, 16), trying to register it.
00:43:18 WORKER: registered result for job (4, 0, 16) with dispatcher
00:43:18 DISPATCHER: job (4, 0, 16) finished
00:43:18 DISPATCHER: register_result: lock acquired
00:43:18 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:43:18 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 290, 'last_n_outputs': 24, 'leak_rate': 0.9040181841114645, 'lr': 0.001101726921588653, 'optimizer': 'SGD', 'sparsity': 0.8784226136389379, 'steps_to_train': 63, 'weight_decay': 0.04563076607678609}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6379820931502654, 'info': {'music-speech': 0.6379820931502654, 'config': "{'batch_size': 64, 'hidden_dim': 290, 'last_n_outputs': 24, 'leak_rate': 0.9040181841114645, 'lr': 0.001101726921588653, 'optimizer': 'SGD', 'sparsity': 0.8784226136389379, 'steps_to_train': 63, 'weight_decay': 0.04563076607678609}"}}
exception: None

00:43:18 job_callback for (4, 0, 16) started
00:43:18 DISPATCHER: Trying to submit another job.
00:43:18 job_callback for (4, 0, 16) got condition
00:43:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:43:18 done building a new model for budget 133.333333 based on 10/21 split
Best loss for this budget:-0.665690





00:43:18 HBMASTER: Trying to run another job!
00:43:18 job_callback for (4, 0, 16) finished
00:43:18 HBMASTER: schedule new run for iteration 4
00:43:18 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
00:43:18 HBMASTER: submitting job (4, 0, 17) to dispatcher
00:43:18 DISPATCHER: trying to submit job (4, 0, 17)
00:43:18 DISPATCHER: trying to notify the job_runner thread.
00:43:18 HBMASTER: job (4, 0, 17) submitted to dispatcher
00:43:18 DISPATCHER: Trying to submit another job.
00:43:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:43:18 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:43:18 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:43:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:43:18 WORKER: start processing job (4, 0, 17)
00:43:18 WORKER: args: ()
00:43:18 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 542, 'last_n_outputs': 23, 'leak_rate': 0.8736040581122816, 'lr': 0.0014587557692112055, 'optimizer': 'SGD', 'sparsity': 0.9295640583427548, 'steps_to_train': 72, 'weight_decay': 0.04453632385123193}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:43:40 DISPATCHER: Starting worker discovery
00:43:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:43:40 DISPATCHER: Finished worker discovery
00:44:40 DISPATCHER: Starting worker discovery
00:44:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:44:40 DISPATCHER: Finished worker discovery
00:45:40 DISPATCHER: Starting worker discovery
00:45:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:45:40 DISPATCHER: Finished worker discovery
00:46:08 WORKER: done with job (4, 0, 17), trying to register it.
00:46:08 WORKER: registered result for job (4, 0, 17) with dispatcher
00:46:08 DISPATCHER: job (4, 0, 17) finished
00:46:08 DISPATCHER: register_result: lock acquired
00:46:08 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:46:08 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 542, 'last_n_outputs': 23, 'leak_rate': 0.8736040581122816, 'lr': 0.0014587557692112055, 'optimizer': 'SGD', 'sparsity': 0.9295640583427548, 'steps_to_train': 72, 'weight_decay': 0.04453632385123193}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4317957128567838, 'info': {'music-speech': 0.4317957128567838, 'config': "{'batch_size': 32, 'hidden_dim': 542, 'last_n_outputs': 23, 'leak_rate': 0.8736040581122816, 'lr': 0.0014587557692112055, 'optimizer': 'SGD', 'sparsity': 0.9295640583427548, 'steps_to_train': 72, 'weight_decay': 0.04453632385123193}"}}
exception: None

00:46:08 job_callback for (4, 0, 17) started
00:46:08 job_callback for (4, 0, 17) got condition
00:46:08 DISPATCHER: Trying to submit another job.
00:46:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:46:08 done building a new model for budget 133.333333 based on 10/22 split
Best loss for this budget:-0.665690





00:46:08 HBMASTER: Trying to run another job!
00:46:08 job_callback for (4, 0, 17) finished
00:46:08 HBMASTER: schedule new run for iteration 4
00:46:08 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
00:46:08 HBMASTER: submitting job (4, 0, 19) to dispatcher
00:46:08 DISPATCHER: trying to submit job (4, 0, 19)
00:46:08 DISPATCHER: trying to notify the job_runner thread.
00:46:08 HBMASTER: job (4, 0, 19) submitted to dispatcher
00:46:08 DISPATCHER: Trying to submit another job.
00:46:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:46:08 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:46:08 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:46:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:46:08 WORKER: start processing job (4, 0, 19)
00:46:08 WORKER: args: ()
00:46:08 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 216, 'last_n_outputs': 30, 'leak_rate': 0.7505079826868244, 'lr': 0.0013955741702901038, 'optimizer': 'SGD', 'sparsity': 0.8261916674627408, 'steps_to_train': 37, 'weight_decay': 0.059966903482619474}, 'budget': 133.33333333333331, 'working_directory': '.'}
00:46:40 DISPATCHER: Starting worker discovery
00:46:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:46:40 DISPATCHER: Finished worker discovery
00:47:40 DISPATCHER: Starting worker discovery
00:47:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:47:41 DISPATCHER: Finished worker discovery
00:48:38 WORKER: done with job (4, 0, 19), trying to register it.
00:48:38 WORKER: registered result for job (4, 0, 19) with dispatcher
00:48:38 DISPATCHER: job (4, 0, 19) finished
00:48:38 DISPATCHER: register_result: lock acquired
00:48:38 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:48:38 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 216, 'last_n_outputs': 30, 'leak_rate': 0.7505079826868244, 'lr': 0.0013955741702901038, 'optimizer': 'SGD', 'sparsity': 0.8261916674627408, 'steps_to_train': 37, 'weight_decay': 0.059966903482619474}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6067101810256835, 'info': {'music-speech': 0.6067101810256835, 'config': "{'batch_size': 16, 'hidden_dim': 216, 'last_n_outputs': 30, 'leak_rate': 0.7505079826868244, 'lr': 0.0013955741702901038, 'optimizer': 'SGD', 'sparsity': 0.8261916674627408, 'steps_to_train': 37, 'weight_decay': 0.059966903482619474}"}}
exception: None

00:48:38 job_callback for (4, 0, 19) started
00:48:38 DISPATCHER: Trying to submit another job.
00:48:38 job_callback for (4, 0, 19) got condition
00:48:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:48:38 done building a new model for budget 133.333333 based on 10/22 split
Best loss for this budget:-0.665690





00:48:38 HBMASTER: Trying to run another job!
00:48:38 job_callback for (4, 0, 19) finished
00:48:38 ITERATION: Advancing config (4, 0, 8) to next budget 400.000000
00:48:38 ITERATION: Advancing config (4, 0, 16) to next budget 400.000000
00:48:38 ITERATION: Advancing config (4, 0, 19) to next budget 400.000000
00:48:38 HBMASTER: schedule new run for iteration 4
00:48:38 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
00:48:38 HBMASTER: submitting job (4, 0, 8) to dispatcher
00:48:38 DISPATCHER: trying to submit job (4, 0, 8)
00:48:38 DISPATCHER: trying to notify the job_runner thread.
00:48:38 HBMASTER: job (4, 0, 8) submitted to dispatcher
00:48:38 DISPATCHER: Trying to submit another job.
00:48:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:48:38 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:48:38 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:48:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:48:38 WORKER: start processing job (4, 0, 8)
00:48:38 WORKER: args: ()
00:48:38 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 200, 'last_n_outputs': 36, 'leak_rate': 0.9578174285573076, 'lr': 0.008013313171241477, 'optimizer': 'SGD', 'sparsity': 0.8699852566179787, 'steps_to_train': 66, 'weight_decay': 0.05090763007989355}, 'budget': 400.0, 'working_directory': '.'}
00:48:41 DISPATCHER: Starting worker discovery
00:48:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:48:41 DISPATCHER: Finished worker discovery
00:49:41 DISPATCHER: Starting worker discovery
00:49:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:49:41 DISPATCHER: Finished worker discovery
00:50:41 DISPATCHER: Starting worker discovery
00:50:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:50:41 DISPATCHER: Finished worker discovery
00:51:41 DISPATCHER: Starting worker discovery
00:51:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:51:41 DISPATCHER: Finished worker discovery
00:52:41 DISPATCHER: Starting worker discovery
00:52:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:52:41 DISPATCHER: Finished worker discovery
00:53:41 DISPATCHER: Starting worker discovery
00:53:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:53:41 DISPATCHER: Finished worker discovery
00:54:41 DISPATCHER: Starting worker discovery
00:54:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:54:41 DISPATCHER: Finished worker discovery
00:55:28 WORKER: done with job (4, 0, 8), trying to register it.
00:55:28 WORKER: registered result for job (4, 0, 8) with dispatcher
00:55:28 DISPATCHER: job (4, 0, 8) finished
00:55:28 DISPATCHER: register_result: lock acquired
00:55:28 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:55:28 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 200, 'last_n_outputs': 36, 'leak_rate': 0.9578174285573076, 'lr': 0.008013313171241477, 'optimizer': 'SGD', 'sparsity': 0.8699852566179787, 'steps_to_train': 66, 'weight_decay': 0.05090763007989355}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5690314717813354, 'info': {'music-speech': 0.5690314717813354, 'config': "{'batch_size': 64, 'hidden_dim': 200, 'last_n_outputs': 36, 'leak_rate': 0.9578174285573076, 'lr': 0.008013313171241477, 'optimizer': 'SGD', 'sparsity': 0.8699852566179787, 'steps_to_train': 66, 'weight_decay': 0.05090763007989355}"}}
exception: None

00:55:28 job_callback for (4, 0, 8) started
00:55:28 DISPATCHER: Trying to submit another job.
00:55:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:55:28 job_callback for (4, 0, 8) got condition
00:55:28 HBMASTER: Trying to run another job!
00:55:28 job_callback for (4, 0, 8) finished
00:55:28 HBMASTER: schedule new run for iteration 4
00:55:28 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
00:55:28 HBMASTER: submitting job (4, 0, 16) to dispatcher
00:55:28 DISPATCHER: trying to submit job (4, 0, 16)
00:55:28 DISPATCHER: trying to notify the job_runner thread.
00:55:28 HBMASTER: job (4, 0, 16) submitted to dispatcher
00:55:28 DISPATCHER: Trying to submit another job.
00:55:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:55:28 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:55:28 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:55:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:55:28 WORKER: start processing job (4, 0, 16)
00:55:28 WORKER: args: ()
00:55:28 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 290, 'last_n_outputs': 24, 'leak_rate': 0.9040181841114645, 'lr': 0.001101726921588653, 'optimizer': 'SGD', 'sparsity': 0.8784226136389379, 'steps_to_train': 63, 'weight_decay': 0.04563076607678609}, 'budget': 400.0, 'working_directory': '.'}
00:55:41 DISPATCHER: Starting worker discovery
00:55:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:55:41 DISPATCHER: Finished worker discovery
00:56:41 DISPATCHER: Starting worker discovery
00:56:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:56:41 DISPATCHER: Finished worker discovery
00:57:41 DISPATCHER: Starting worker discovery
00:57:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:57:41 DISPATCHER: Finished worker discovery
00:58:41 DISPATCHER: Starting worker discovery
00:58:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:58:41 DISPATCHER: Finished worker discovery
00:59:41 DISPATCHER: Starting worker discovery
00:59:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:59:41 DISPATCHER: Finished worker discovery
01:00:41 DISPATCHER: Starting worker discovery
01:00:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:00:41 DISPATCHER: Finished worker discovery
01:01:41 DISPATCHER: Starting worker discovery
01:01:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:01:41 DISPATCHER: Finished worker discovery
01:02:27 WORKER: done with job (4, 0, 16), trying to register it.
01:02:27 WORKER: registered result for job (4, 0, 16) with dispatcher
01:02:27 DISPATCHER: job (4, 0, 16) finished
01:02:27 DISPATCHER: register_result: lock acquired
01:02:27 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
01:02:27 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 290, 'last_n_outputs': 24, 'leak_rate': 0.9040181841114645, 'lr': 0.001101726921588653, 'optimizer': 'SGD', 'sparsity': 0.8784226136389379, 'steps_to_train': 63, 'weight_decay': 0.04563076607678609}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.43522077794424086, 'info': {'music-speech': 0.43522077794424086, 'config': "{'batch_size': 64, 'hidden_dim': 290, 'last_n_outputs': 24, 'leak_rate': 0.9040181841114645, 'lr': 0.001101726921588653, 'optimizer': 'SGD', 'sparsity': 0.8784226136389379, 'steps_to_train': 63, 'weight_decay': 0.04563076607678609}"}}
exception: None

01:02:27 job_callback for (4, 0, 16) started
01:02:27 DISPATCHER: Trying to submit another job.
01:02:27 job_callback for (4, 0, 16) got condition
01:02:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:02:27 HBMASTER: Trying to run another job!
01:02:27 job_callback for (4, 0, 16) finished
01:02:27 HBMASTER: schedule new run for iteration 4
01:02:27 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
01:02:27 HBMASTER: submitting job (4, 0, 19) to dispatcher
01:02:27 DISPATCHER: trying to submit job (4, 0, 19)
01:02:27 DISPATCHER: trying to notify the job_runner thread.
01:02:27 HBMASTER: job (4, 0, 19) submitted to dispatcher
01:02:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:02:27 DISPATCHER: Trying to submit another job.
01:02:27 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpul.22021139727314577216
01:02:27 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
01:02:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:02:27 WORKER: start processing job (4, 0, 19)
01:02:27 WORKER: args: ()
01:02:27 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 216, 'last_n_outputs': 30, 'leak_rate': 0.7505079826868244, 'lr': 0.0013955741702901038, 'optimizer': 'SGD', 'sparsity': 0.8261916674627408, 'steps_to_train': 37, 'weight_decay': 0.059966903482619474}, 'budget': 400.0, 'working_directory': '.'}
01:02:41 DISPATCHER: Starting worker discovery
01:02:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:02:41 DISPATCHER: Finished worker discovery
01:03:41 DISPATCHER: Starting worker discovery
01:03:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:03:41 DISPATCHER: Finished worker discovery
01:04:41 DISPATCHER: Starting worker discovery
01:04:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:04:41 DISPATCHER: Finished worker discovery
01:05:41 DISPATCHER: Starting worker discovery
01:05:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:05:41 DISPATCHER: Finished worker discovery
01:06:41 DISPATCHER: Starting worker discovery
01:06:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:06:41 DISPATCHER: Finished worker discovery
01:07:41 DISPATCHER: Starting worker discovery
01:07:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:07:41 DISPATCHER: Finished worker discovery
01:08:41 DISPATCHER: Starting worker discovery
01:08:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:08:41 DISPATCHER: Finished worker discovery
01:09:25 WORKER: done with job (4, 0, 19), trying to register it.
01:09:25 WORKER: registered result for job (4, 0, 19) with dispatcher
01:09:25 DISPATCHER: job (4, 0, 19) finished
01:09:25 DISPATCHER: register_result: lock acquired
01:09:25 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
01:09:25 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 216, 'last_n_outputs': 30, 'leak_rate': 0.7505079826868244, 'lr': 0.0013955741702901038, 'optimizer': 'SGD', 'sparsity': 0.8261916674627408, 'steps_to_train': 37, 'weight_decay': 0.059966903482619474}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4235364076598227, 'info': {'music-speech': 0.4235364076598227, 'config': "{'batch_size': 16, 'hidden_dim': 216, 'last_n_outputs': 30, 'leak_rate': 0.7505079826868244, 'lr': 0.0013955741702901038, 'optimizer': 'SGD', 'sparsity': 0.8261916674627408, 'steps_to_train': 37, 'weight_decay': 0.059966903482619474}"}}
exception: None

01:09:25 job_callback for (4, 0, 19) started
01:09:25 job_callback for (4, 0, 19) got condition
01:09:25 DISPATCHER: Trying to submit another job.
01:09:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:09:25 HBMASTER: Trying to run another job!
01:09:25 job_callback for (4, 0, 19) finished
01:09:25 ITERATION: Advancing config (4, 0, 8) to next budget 1200.000000
01:09:25 HBMASTER: schedule new run for iteration 4
01:09:25 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
01:09:25 HBMASTER: submitting job (4, 0, 8) to dispatcher
01:09:25 DISPATCHER: trying to submit job (4, 0, 8)
01:09:25 DISPATCHER: trying to notify the job_runner thread.
01:09:25 HBMASTER: job (4, 0, 8) submitted to dispatcher
01:09:25 DISPATCHER: Trying to submit another job.
01:09:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:09:25 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216
01:09:25 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
01:09:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:09:25 WORKER: start processing job (4, 0, 8)
01:09:25 WORKER: args: ()
01:09:25 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 200, 'last_n_outputs': 36, 'leak_rate': 0.9578174285573076, 'lr': 0.008013313171241477, 'optimizer': 'SGD', 'sparsity': 0.8699852566179787, 'steps_to_train': 66, 'weight_decay': 0.05090763007989355}, 'budget': 1200.0, 'working_directory': '.'}
01:09:41 DISPATCHER: Starting worker discovery
01:09:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:09:41 DISPATCHER: Finished worker discovery
01:10:41 DISPATCHER: Starting worker discovery
01:10:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:10:41 DISPATCHER: Finished worker discovery
01:11:41 DISPATCHER: Starting worker discovery
01:11:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:11:41 DISPATCHER: Finished worker discovery
01:12:41 DISPATCHER: Starting worker discovery
01:12:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:12:41 DISPATCHER: Finished worker discovery
01:13:41 DISPATCHER: Starting worker discovery
01:13:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:13:41 DISPATCHER: Finished worker discovery
01:14:41 DISPATCHER: Starting worker discovery
01:14:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:14:41 DISPATCHER: Finished worker discovery
01:15:41 DISPATCHER: Starting worker discovery
01:15:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:15:41 DISPATCHER: Finished worker discovery
01:16:41 DISPATCHER: Starting worker discovery
01:16:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:16:41 DISPATCHER: Finished worker discovery
01:17:41 DISPATCHER: Starting worker discovery
01:17:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:17:41 DISPATCHER: Finished worker discovery
01:18:41 DISPATCHER: Starting worker discovery
01:18:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:18:41 DISPATCHER: Finished worker discovery
01:19:41 DISPATCHER: Starting worker discovery
01:19:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:19:41 DISPATCHER: Finished worker discovery
01:20:41 DISPATCHER: Starting worker discovery
01:20:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:20:41 DISPATCHER: Finished worker discovery
01:21:41 DISPATCHER: Starting worker discovery
01:21:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:21:41 DISPATCHER: Finished worker discovery
01:22:41 DISPATCHER: Starting worker discovery
01:22:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:22:41 DISPATCHER: Finished worker discovery
01:23:41 DISPATCHER: Starting worker discovery
01:23:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:23:41 DISPATCHER: Finished worker discovery
01:24:41 DISPATCHER: Starting worker discovery
01:24:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:24:41 DISPATCHER: Finished worker discovery
01:25:41 DISPATCHER: Starting worker discovery
01:25:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:25:41 DISPATCHER: Finished worker discovery
01:26:41 DISPATCHER: Starting worker discovery
01:26:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:26:41 DISPATCHER: Finished worker discovery
01:27:41 DISPATCHER: Starting worker discovery
01:27:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:27:41 DISPATCHER: Finished worker discovery
01:28:41 DISPATCHER: Starting worker discovery
01:28:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:28:41 DISPATCHER: Finished worker discovery
01:29:41 DISPATCHER: Starting worker discovery
01:29:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:29:41 DISPATCHER: Finished worker discovery
01:29:50 WORKER: done with job (4, 0, 8), trying to register it.
01:29:50 DISPATCHER: job (4, 0, 8) finished
01:29:50 WORKER: registered result for job (4, 0, 8) with dispatcher
01:29:50 DISPATCHER: register_result: lock acquired
01:29:50 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
01:29:50 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 200, 'last_n_outputs': 36, 'leak_rate': 0.9578174285573076, 'lr': 0.008013313171241477, 'optimizer': 'SGD', 'sparsity': 0.8699852566179787, 'steps_to_train': 66, 'weight_decay': 0.05090763007989355}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.6677148877434742, 'info': {'music-speech': 0.6677148877434742, 'config': "{'batch_size': 64, 'hidden_dim': 200, 'last_n_outputs': 36, 'leak_rate': 0.9578174285573076, 'lr': 0.008013313171241477, 'optimizer': 'SGD', 'sparsity': 0.8699852566179787, 'steps_to_train': 66, 'weight_decay': 0.05090763007989355}"}}
exception: None

01:29:50 job_callback for (4, 0, 8) started
01:29:50 DISPATCHER: Trying to submit another job.
01:29:50 job_callback for (4, 0, 8) got condition
01:29:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:29:50 Only 9 run(s) for budget 1200.000000 available, need more than 11 -> can't build model!
01:29:50 HBMASTER: Trying to run another job!
01:29:50 job_callback for (4, 0, 8) finished
01:29:50 start sampling a new configuration.
01:29:50 done sampling a new configuration.
01:29:50 HBMASTER: schedule new run for iteration 5
01:29:50 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
01:29:50 HBMASTER: submitting job (5, 0, 0) to dispatcher
01:29:50 DISPATCHER: trying to submit job (5, 0, 0)
01:29:50 DISPATCHER: trying to notify the job_runner thread.
01:29:50 HBMASTER: job (5, 0, 0) submitted to dispatcher
01:29:50 DISPATCHER: Trying to submit another job.
01:29:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:29:50 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
01:29:50 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
01:29:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:29:50 WORKER: start processing job (5, 0, 0)
01:29:50 WORKER: args: ()
01:29:50 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 928, 'last_n_outputs': 39, 'leak_rate': 0.7672831712418302, 'lr': 0.0621568804638585, 'optimizer': 'SGD', 'sparsity': 0.8153675356510144, 'steps_to_train': 80, 'weight_decay': 0.02877437304958334}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:30:41 DISPATCHER: Starting worker discovery
01:30:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:30:41 DISPATCHER: Finished worker discovery
01:31:41 DISPATCHER: Starting worker discovery
01:31:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:31:41 DISPATCHER: Finished worker discovery
01:32:30 WORKER: done with job (5, 0, 0), trying to register it.
01:32:30 WORKER: registered result for job (5, 0, 0) with dispatcher
01:32:30 DISPATCHER: job (5, 0, 0) finished
01:32:30 DISPATCHER: register_result: lock acquired
01:32:30 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
01:32:30 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 928, 'last_n_outputs': 39, 'leak_rate': 0.7672831712418302, 'lr': 0.0621568804638585, 'optimizer': 'SGD', 'sparsity': 0.8153675356510144, 'steps_to_train': 80, 'weight_decay': 0.02877437304958334}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.42559206053665033, 'info': {'music-speech': 0.42559206053665033, 'config': "{'batch_size': 16, 'hidden_dim': 928, 'last_n_outputs': 39, 'leak_rate': 0.7672831712418302, 'lr': 0.0621568804638585, 'optimizer': 'SGD', 'sparsity': 0.8153675356510144, 'steps_to_train': 80, 'weight_decay': 0.02877437304958334}"}}
exception: None

01:32:30 job_callback for (5, 0, 0) started
01:32:30 DISPATCHER: Trying to submit another job.
01:32:30 job_callback for (5, 0, 0) got condition
01:32:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:32:30 done building a new model for budget 133.333333 based on 10/23 split
Best loss for this budget:-0.665690





01:32:30 HBMASTER: Trying to run another job!
01:32:30 job_callback for (5, 0, 0) finished
01:32:30 start sampling a new configuration.
01:32:30 done sampling a new configuration.
01:32:30 HBMASTER: schedule new run for iteration 5
01:32:30 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
01:32:30 HBMASTER: submitting job (5, 0, 1) to dispatcher
01:32:30 DISPATCHER: trying to submit job (5, 0, 1)
01:32:30 DISPATCHER: trying to notify the job_runner thread.
01:32:30 HBMASTER: job (5, 0, 1) submitted to dispatcher
01:32:30 DISPATCHER: Trying to submit another job.
01:32:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:32:30 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
01:32:30 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
01:32:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:32:30 WORKER: start processing job (5, 0, 1)
01:32:30 WORKER: args: ()
01:32:30 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 791, 'last_n_outputs': 26, 'leak_rate': 0.7552212154370255, 'lr': 0.029190145880519554, 'optimizer': 'SGD', 'sparsity': 0.9757446120478186, 'steps_to_train': 89, 'weight_decay': 0.06545121199105317}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:32:41 DISPATCHER: Starting worker discovery
01:32:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:32:41 DISPATCHER: Finished worker discovery
01:33:41 DISPATCHER: Starting worker discovery
01:33:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:33:41 DISPATCHER: Finished worker discovery
01:34:41 DISPATCHER: Starting worker discovery
01:34:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:34:41 DISPATCHER: Finished worker discovery
01:35:05 WORKER: done with job (5, 0, 1), trying to register it.
01:35:05 DISPATCHER: job (5, 0, 1) finished
01:35:05 WORKER: registered result for job (5, 0, 1) with dispatcher
01:35:05 DISPATCHER: register_result: lock acquired
01:35:05 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
01:35:05 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 791, 'last_n_outputs': 26, 'leak_rate': 0.7552212154370255, 'lr': 0.029190145880519554, 'optimizer': 'SGD', 'sparsity': 0.9757446120478186, 'steps_to_train': 89, 'weight_decay': 0.06545121199105317}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5054768598682534, 'info': {'music-speech': 0.5054768598682534, 'config': "{'batch_size': 16, 'hidden_dim': 791, 'last_n_outputs': 26, 'leak_rate': 0.7552212154370255, 'lr': 0.029190145880519554, 'optimizer': 'SGD', 'sparsity': 0.9757446120478186, 'steps_to_train': 89, 'weight_decay': 0.06545121199105317}"}}
exception: None

01:35:05 job_callback for (5, 0, 1) started
01:35:05 DISPATCHER: Trying to submit another job.
01:35:05 job_callback for (5, 0, 1) got condition
01:35:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:35:05 done building a new model for budget 133.333333 based on 10/24 split
Best loss for this budget:-0.665690





01:35:05 HBMASTER: Trying to run another job!
01:35:05 job_callback for (5, 0, 1) finished
01:35:05 start sampling a new configuration.
01:35:05 best_vector: [0, 0.07872165393184616, 0.6133605709553903, 0.621941835996926, 0.9489053059178552, 0, 0.6202248433653124, 0.6114984995525847, 0.6280985349559949], 0.0019292690218571885, 0.05645299773100019, 0.00010891301971339282
01:35:05 done sampling a new configuration.
01:35:05 HBMASTER: schedule new run for iteration 5
01:35:05 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
01:35:05 HBMASTER: submitting job (5, 0, 2) to dispatcher
01:35:05 DISPATCHER: trying to submit job (5, 0, 2)
01:35:05 DISPATCHER: trying to notify the job_runner thread.
01:35:05 HBMASTER: job (5, 0, 2) submitted to dispatcher
01:35:05 DISPATCHER: Trying to submit another job.
01:35:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:35:05 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
01:35:05 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
01:35:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:35:05 WORKER: start processing job (5, 0, 2)
01:35:05 WORKER: args: ()
01:35:05 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 263, 'last_n_outputs': 35, 'leak_rate': 0.9054854589992315, 'lr': 0.07903339021645472, 'optimizer': 'Adam', 'sparsity': 0.898853962407675, 'steps_to_train': 65, 'weight_decay': 0.06564097665903694}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:35:41 DISPATCHER: Starting worker discovery
01:35:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:35:41 DISPATCHER: Finished worker discovery
01:36:41 DISPATCHER: Starting worker discovery
01:36:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:36:41 DISPATCHER: Finished worker discovery
01:37:32 WORKER: done with job (5, 0, 2), trying to register it.
01:37:32 WORKER: registered result for job (5, 0, 2) with dispatcher
01:37:32 DISPATCHER: job (5, 0, 2) finished
01:37:32 DISPATCHER: register_result: lock acquired
01:37:32 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
01:37:32 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 263, 'last_n_outputs': 35, 'leak_rate': 0.9054854589992315, 'lr': 0.07903339021645472, 'optimizer': 'Adam', 'sparsity': 0.898853962407675, 'steps_to_train': 65, 'weight_decay': 0.06564097665903694}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1748517802067726, 'info': {'music-speech': 0.1748517802067726, 'config': "{'batch_size': 16, 'hidden_dim': 263, 'last_n_outputs': 35, 'leak_rate': 0.9054854589992315, 'lr': 0.07903339021645472, 'optimizer': 'Adam', 'sparsity': 0.898853962407675, 'steps_to_train': 65, 'weight_decay': 0.06564097665903694}"}}
exception: None

01:37:32 job_callback for (5, 0, 2) started
01:37:32 DISPATCHER: Trying to submit another job.
01:37:32 job_callback for (5, 0, 2) got condition
01:37:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:37:32 done building a new model for budget 133.333333 based on 10/25 split
Best loss for this budget:-0.665690





01:37:32 HBMASTER: Trying to run another job!
01:37:32 job_callback for (5, 0, 2) finished
01:37:32 start sampling a new configuration.
01:37:32 done sampling a new configuration.
01:37:32 HBMASTER: schedule new run for iteration 5
01:37:32 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
01:37:32 HBMASTER: submitting job (5, 0, 3) to dispatcher
01:37:32 DISPATCHER: trying to submit job (5, 0, 3)
01:37:32 DISPATCHER: trying to notify the job_runner thread.
01:37:32 HBMASTER: job (5, 0, 3) submitted to dispatcher
01:37:32 DISPATCHER: Trying to submit another job.
01:37:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:37:32 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
01:37:32 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
01:37:32 WORKER: start processing job (5, 0, 3)
01:37:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:37:32 WORKER: args: ()
01:37:32 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 214, 'last_n_outputs': 24, 'leak_rate': 0.9670560525290943, 'lr': 0.01500188873485806, 'optimizer': 'Adam', 'sparsity': 0.9529275499446519, 'steps_to_train': 18, 'weight_decay': 0.10394350281362989}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:37:41 DISPATCHER: Starting worker discovery
01:37:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:37:41 DISPATCHER: Finished worker discovery
01:38:41 DISPATCHER: Starting worker discovery
01:38:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:38:41 DISPATCHER: Finished worker discovery
01:39:41 DISPATCHER: Starting worker discovery
01:39:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:39:41 DISPATCHER: Finished worker discovery
01:39:59 WORKER: done with job (5, 0, 3), trying to register it.
01:39:59 DISPATCHER: job (5, 0, 3) finished
01:39:59 WORKER: registered result for job (5, 0, 3) with dispatcher
01:39:59 DISPATCHER: register_result: lock acquired
01:39:59 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
01:39:59 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 214, 'last_n_outputs': 24, 'leak_rate': 0.9670560525290943, 'lr': 0.01500188873485806, 'optimizer': 'Adam', 'sparsity': 0.9529275499446519, 'steps_to_train': 18, 'weight_decay': 0.10394350281362989}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2539567356055205, 'info': {'music-speech': 0.2539567356055205, 'config': "{'batch_size': 64, 'hidden_dim': 214, 'last_n_outputs': 24, 'leak_rate': 0.9670560525290943, 'lr': 0.01500188873485806, 'optimizer': 'Adam', 'sparsity': 0.9529275499446519, 'steps_to_train': 18, 'weight_decay': 0.10394350281362989}"}}
exception: None

01:39:59 job_callback for (5, 0, 3) started
01:39:59 DISPATCHER: Trying to submit another job.
01:39:59 job_callback for (5, 0, 3) got condition
01:39:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:39:59 done building a new model for budget 133.333333 based on 10/26 split
Best loss for this budget:-0.665690





01:39:59 HBMASTER: Trying to run another job!
01:39:59 job_callback for (5, 0, 3) finished
01:39:59 start sampling a new configuration.
01:39:59 done sampling a new configuration.
01:39:59 HBMASTER: schedule new run for iteration 5
01:39:59 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
01:39:59 HBMASTER: submitting job (5, 0, 4) to dispatcher
01:39:59 DISPATCHER: trying to submit job (5, 0, 4)
01:39:59 DISPATCHER: trying to notify the job_runner thread.
01:39:59 HBMASTER: job (5, 0, 4) submitted to dispatcher
01:39:59 DISPATCHER: Trying to submit another job.
01:39:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:39:59 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
01:39:59 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
01:39:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:39:59 WORKER: start processing job (5, 0, 4)
01:39:59 WORKER: args: ()
01:39:59 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 496, 'last_n_outputs': 48, 'leak_rate': 0.9307570875910607, 'lr': 0.09222568135329982, 'optimizer': 'Adam', 'sparsity': 0.8082874658653784, 'steps_to_train': 58, 'weight_decay': 0.08401948032567517}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:40:41 DISPATCHER: Starting worker discovery
01:40:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:40:41 DISPATCHER: Finished worker discovery
01:41:41 DISPATCHER: Starting worker discovery
01:41:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:41:42 DISPATCHER: Finished worker discovery
01:42:40 WORKER: done with job (5, 0, 4), trying to register it.
01:42:40 WORKER: registered result for job (5, 0, 4) with dispatcher
01:42:40 DISPATCHER: job (5, 0, 4) finished
01:42:40 DISPATCHER: register_result: lock acquired
01:42:40 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
01:42:40 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 496, 'last_n_outputs': 48, 'leak_rate': 0.9307570875910607, 'lr': 0.09222568135329982, 'optimizer': 'Adam', 'sparsity': 0.8082874658653784, 'steps_to_train': 58, 'weight_decay': 0.08401948032567517}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2877178103402054, 'info': {'music-speech': 0.2877178103402054, 'config': "{'batch_size': 16, 'hidden_dim': 496, 'last_n_outputs': 48, 'leak_rate': 0.9307570875910607, 'lr': 0.09222568135329982, 'optimizer': 'Adam', 'sparsity': 0.8082874658653784, 'steps_to_train': 58, 'weight_decay': 0.08401948032567517}"}}
exception: None

01:42:40 job_callback for (5, 0, 4) started
01:42:40 DISPATCHER: Trying to submit another job.
01:42:40 job_callback for (5, 0, 4) got condition
01:42:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:42:40 done building a new model for budget 133.333333 based on 10/27 split
Best loss for this budget:-0.665690





01:42:40 HBMASTER: Trying to run another job!
01:42:40 job_callback for (5, 0, 4) finished
01:42:40 start sampling a new configuration.
01:42:40 best_vector: [2, 0.1711054231820632, 0.3338113455538315, 0.031306672892222526, 0.5206423309218222, 1, 0.049486606096618674, 0.11945792818934131, 0.7242312082805862], 0.029088597083756874, 0.1814828940929804, 0.005279082783864827
01:42:40 done sampling a new configuration.
01:42:40 HBMASTER: schedule new run for iteration 5
01:42:40 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
01:42:40 HBMASTER: submitting job (5, 0, 5) to dispatcher
01:42:40 DISPATCHER: trying to submit job (5, 0, 5)
01:42:40 DISPATCHER: trying to notify the job_runner thread.
01:42:40 HBMASTER: job (5, 0, 5) submitted to dispatcher
01:42:40 DISPATCHER: Trying to submit another job.
01:42:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:42:40 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
01:42:40 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
01:42:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:42:40 WORKER: start processing job (5, 0, 5)
01:42:40 WORKER: args: ()
01:42:40 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 337, 'last_n_outputs': 23, 'leak_rate': 0.7578266682230557, 'lr': 0.010997264278633682, 'optimizer': 'SGD', 'sparsity': 0.7618767854631885, 'steps_to_train': 20, 'weight_decay': 0.08754805977546265}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:42:42 DISPATCHER: Starting worker discovery
01:42:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:42:42 DISPATCHER: Finished worker discovery
01:43:42 DISPATCHER: Starting worker discovery
01:43:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:43:42 DISPATCHER: Finished worker discovery
01:44:42 DISPATCHER: Starting worker discovery
01:44:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:44:42 DISPATCHER: Finished worker discovery
01:45:03 WORKER: done with job (5, 0, 5), trying to register it.
01:45:03 WORKER: registered result for job (5, 0, 5) with dispatcher
01:45:03 DISPATCHER: job (5, 0, 5) finished
01:45:03 DISPATCHER: register_result: lock acquired
01:45:03 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
01:45:03 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 337, 'last_n_outputs': 23, 'leak_rate': 0.7578266682230557, 'lr': 0.010997264278633682, 'optimizer': 'SGD', 'sparsity': 0.7618767854631885, 'steps_to_train': 20, 'weight_decay': 0.08754805977546265}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.37992525985663866, 'info': {'music-speech': 0.37992525985663866, 'config': "{'batch_size': 64, 'hidden_dim': 337, 'last_n_outputs': 23, 'leak_rate': 0.7578266682230557, 'lr': 0.010997264278633682, 'optimizer': 'SGD', 'sparsity': 0.7618767854631885, 'steps_to_train': 20, 'weight_decay': 0.08754805977546265}"}}
exception: None

01:45:03 job_callback for (5, 0, 5) started
01:45:03 DISPATCHER: Trying to submit another job.
01:45:03 job_callback for (5, 0, 5) got condition
01:45:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:45:03 done building a new model for budget 133.333333 based on 10/28 split
Best loss for this budget:-0.665690





01:45:03 HBMASTER: Trying to run another job!
01:45:03 job_callback for (5, 0, 5) finished
01:45:03 start sampling a new configuration.
01:45:03 best_vector: [0, 0.06264367272156147, 0.7586013390823602, 0.8655923299810471, 0.5549507990333541, 1, 0.27062557722484304, 0.8629224584660837, 0.14956571828649817], 0.0040529722704277845, 0.05042699256613311, 0.00020437920255160554
01:45:03 done sampling a new configuration.
01:45:03 HBMASTER: schedule new run for iteration 5
01:45:03 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
01:45:03 HBMASTER: submitting job (5, 0, 6) to dispatcher
01:45:03 DISPATCHER: trying to submit job (5, 0, 6)
01:45:03 DISPATCHER: trying to notify the job_runner thread.
01:45:03 HBMASTER: job (5, 0, 6) submitted to dispatcher
01:45:03 DISPATCHER: Trying to submit another job.
01:45:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:45:03 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216
01:45:03 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
01:45:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:45:03 WORKER: start processing job (5, 0, 6)
01:45:03 WORKER: args: ()
01:45:03 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 250, 'last_n_outputs': 41, 'leak_rate': 0.9663980824952618, 'lr': 0.012879576946893236, 'optimizer': 'SGD', 'sparsity': 0.8149501385339624, 'steps_to_train': 88, 'weight_decay': 0.015652708080159315}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:45:42 DISPATCHER: Starting worker discovery
01:45:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:45:42 DISPATCHER: Finished worker discovery
01:46:42 DISPATCHER: Starting worker discovery
01:46:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:46:42 DISPATCHER: Finished worker discovery
01:47:31 WORKER: done with job (5, 0, 6), trying to register it.
01:47:31 WORKER: registered result for job (5, 0, 6) with dispatcher
01:47:31 DISPATCHER: job (5, 0, 6) finished
01:47:31 DISPATCHER: register_result: lock acquired
01:47:31 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
01:47:31 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 250, 'last_n_outputs': 41, 'leak_rate': 0.9663980824952618, 'lr': 0.012879576946893236, 'optimizer': 'SGD', 'sparsity': 0.8149501385339624, 'steps_to_train': 88, 'weight_decay': 0.015652708080159315}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5103093727721618, 'info': {'music-speech': 0.5103093727721618, 'config': "{'batch_size': 16, 'hidden_dim': 250, 'last_n_outputs': 41, 'leak_rate': 0.9663980824952618, 'lr': 0.012879576946893236, 'optimizer': 'SGD', 'sparsity': 0.8149501385339624, 'steps_to_train': 88, 'weight_decay': 0.015652708080159315}"}}
exception: None

01:47:31 job_callback for (5, 0, 6) started
01:47:31 DISPATCHER: Trying to submit another job.
01:47:31 job_callback for (5, 0, 6) got condition
01:47:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:47:31 done building a new model for budget 133.333333 based on 10/28 split
Best loss for this budget:-0.665690





01:47:31 HBMASTER: Trying to run another job!
01:47:31 job_callback for (5, 0, 6) finished
01:47:31 start sampling a new configuration.
01:47:31 done sampling a new configuration.
01:47:31 HBMASTER: schedule new run for iteration 5
01:47:31 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
01:47:31 HBMASTER: submitting job (5, 0, 7) to dispatcher
01:47:31 DISPATCHER: trying to submit job (5, 0, 7)
01:47:31 DISPATCHER: trying to notify the job_runner thread.
01:47:31 HBMASTER: job (5, 0, 7) submitted to dispatcher
01:47:31 DISPATCHER: Trying to submit another job.
01:47:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:47:31 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
01:47:31 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
01:47:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:47:31 WORKER: start processing job (5, 0, 7)
01:47:31 WORKER: args: ()
01:47:31 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 767, 'last_n_outputs': 46, 'leak_rate': 0.8683772898424809, 'lr': 0.0060671407182333595, 'optimizer': 'SGD', 'sparsity': 0.8821658769977078, 'steps_to_train': 38, 'weight_decay': 0.05632649133268306}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:47:42 DISPATCHER: Starting worker discovery
01:47:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:47:42 DISPATCHER: Finished worker discovery
01:48:42 DISPATCHER: Starting worker discovery
01:48:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:48:42 DISPATCHER: Finished worker discovery
01:49:42 DISPATCHER: Starting worker discovery
01:49:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:49:42 DISPATCHER: Finished worker discovery
01:50:07 WORKER: done with job (5, 0, 7), trying to register it.
01:50:07 WORKER: registered result for job (5, 0, 7) with dispatcher
01:50:07 DISPATCHER: job (5, 0, 7) finished
01:50:07 DISPATCHER: register_result: lock acquired
01:50:07 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
01:50:07 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 767, 'last_n_outputs': 46, 'leak_rate': 0.8683772898424809, 'lr': 0.0060671407182333595, 'optimizer': 'SGD', 'sparsity': 0.8821658769977078, 'steps_to_train': 38, 'weight_decay': 0.05632649133268306}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.25033419929185596, 'info': {'music-speech': 0.25033419929185596, 'config': "{'batch_size': 128, 'hidden_dim': 767, 'last_n_outputs': 46, 'leak_rate': 0.8683772898424809, 'lr': 0.0060671407182333595, 'optimizer': 'SGD', 'sparsity': 0.8821658769977078, 'steps_to_train': 38, 'weight_decay': 0.05632649133268306}"}}
exception: None

01:50:07 job_callback for (5, 0, 7) started
01:50:07 job_callback for (5, 0, 7) got condition
01:50:07 DISPATCHER: Trying to submit another job.
01:50:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:50:07 done building a new model for budget 133.333333 based on 10/29 split
Best loss for this budget:-0.665690





01:50:07 HBMASTER: Trying to run another job!
01:50:07 job_callback for (5, 0, 7) finished
01:50:07 start sampling a new configuration.
01:50:08 best_vector: [3, 0.03143333769905003, 0.4375291319220935, 0.6923865629932527, 0.24775373965690337, 1, 0.4650844644006936, 0.3898023591485635, 0.7203552429085804], 0.10150039484918472, 0.41930521015609645, 0.04255964439316417
01:50:08 done sampling a new configuration.
01:50:08 HBMASTER: schedule new run for iteration 5
01:50:08 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
01:50:08 HBMASTER: submitting job (5, 0, 8) to dispatcher
01:50:08 DISPATCHER: trying to submit job (5, 0, 8)
01:50:08 DISPATCHER: trying to notify the job_runner thread.
01:50:08 HBMASTER: job (5, 0, 8) submitted to dispatcher
01:50:08 DISPATCHER: Trying to submit another job.
01:50:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:50:08 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216
01:50:08 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
01:50:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:50:08 WORKER: start processing job (5, 0, 8)
01:50:08 WORKER: args: ()
01:50:08 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 225, 'last_n_outputs': 27, 'leak_rate': 0.9230966407483132, 'lr': 0.0031297343706227186, 'optimizer': 'SGD', 'sparsity': 0.8616202714561665, 'steps_to_train': 45, 'weight_decay': 0.08653738720665993}, 'budget': 133.33333333333331, 'working_directory': '.'}
01:50:42 DISPATCHER: Starting worker discovery
01:50:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:50:42 DISPATCHER: Finished worker discovery
01:51:42 DISPATCHER: Starting worker discovery
01:51:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:51:42 DISPATCHER: Finished worker discovery
01:52:42 DISPATCHER: Starting worker discovery
01:52:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:52:42 DISPATCHER: Finished worker discovery
01:52:45 WORKER: done with job (5, 0, 8), trying to register it.
01:52:45 WORKER: registered result for job (5, 0, 8) with dispatcher
01:52:45 DISPATCHER: job (5, 0, 8) finished
01:52:45 DISPATCHER: register_result: lock acquired
01:52:45 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
01:52:45 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 225, 'last_n_outputs': 27, 'leak_rate': 0.9230966407483132, 'lr': 0.0031297343706227186, 'optimizer': 'SGD', 'sparsity': 0.8616202714561665, 'steps_to_train': 45, 'weight_decay': 0.08653738720665993}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5239509429482577, 'info': {'music-speech': 0.5239509429482577, 'config': "{'batch_size': 128, 'hidden_dim': 225, 'last_n_outputs': 27, 'leak_rate': 0.9230966407483132, 'lr': 0.0031297343706227186, 'optimizer': 'SGD', 'sparsity': 0.8616202714561665, 'steps_to_train': 45, 'weight_decay': 0.08653738720665993}"}}
exception: None

01:52:45 job_callback for (5, 0, 8) started
01:52:45 DISPATCHER: Trying to submit another job.
01:52:45 job_callback for (5, 0, 8) got condition
01:52:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:52:45 done building a new model for budget 133.333333 based on 10/30 split
Best loss for this budget:-0.665690





01:52:45 HBMASTER: Trying to run another job!
01:52:45 job_callback for (5, 0, 8) finished
01:52:45 ITERATION: Advancing config (5, 0, 1) to next budget 400.000000
01:52:45 ITERATION: Advancing config (5, 0, 6) to next budget 400.000000
01:52:45 ITERATION: Advancing config (5, 0, 8) to next budget 400.000000
01:52:45 HBMASTER: schedule new run for iteration 5
01:52:45 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
01:52:45 HBMASTER: submitting job (5, 0, 1) to dispatcher
01:52:45 DISPATCHER: trying to submit job (5, 0, 1)
01:52:45 DISPATCHER: trying to notify the job_runner thread.
01:52:45 HBMASTER: job (5, 0, 1) submitted to dispatcher
01:52:45 DISPATCHER: Trying to submit another job.
01:52:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:52:45 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
01:52:45 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
01:52:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:52:45 WORKER: start processing job (5, 0, 1)
01:52:45 WORKER: args: ()
01:52:45 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 791, 'last_n_outputs': 26, 'leak_rate': 0.7552212154370255, 'lr': 0.029190145880519554, 'optimizer': 'SGD', 'sparsity': 0.9757446120478186, 'steps_to_train': 89, 'weight_decay': 0.06545121199105317}, 'budget': 400.0, 'working_directory': '.'}
01:53:42 DISPATCHER: Starting worker discovery
01:53:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:53:42 DISPATCHER: Finished worker discovery
01:54:42 DISPATCHER: Starting worker discovery
01:54:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:54:42 DISPATCHER: Finished worker discovery
01:55:42 DISPATCHER: Starting worker discovery
01:55:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:55:42 DISPATCHER: Finished worker discovery
01:56:42 DISPATCHER: Starting worker discovery
01:56:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:56:42 DISPATCHER: Finished worker discovery
01:57:42 DISPATCHER: Starting worker discovery
01:57:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:57:42 DISPATCHER: Finished worker discovery
01:58:42 DISPATCHER: Starting worker discovery
01:58:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:58:42 DISPATCHER: Finished worker discovery
01:59:35 WORKER: done with job (5, 0, 1), trying to register it.
01:59:35 WORKER: registered result for job (5, 0, 1) with dispatcher
01:59:35 DISPATCHER: job (5, 0, 1) finished
01:59:35 DISPATCHER: register_result: lock acquired
01:59:35 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
01:59:35 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 791, 'last_n_outputs': 26, 'leak_rate': 0.7552212154370255, 'lr': 0.029190145880519554, 'optimizer': 'SGD', 'sparsity': 0.9757446120478186, 'steps_to_train': 89, 'weight_decay': 0.06545121199105317}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3412853609268228, 'info': {'music-speech': 0.3412853609268228, 'config': "{'batch_size': 16, 'hidden_dim': 791, 'last_n_outputs': 26, 'leak_rate': 0.7552212154370255, 'lr': 0.029190145880519554, 'optimizer': 'SGD', 'sparsity': 0.9757446120478186, 'steps_to_train': 89, 'weight_decay': 0.06545121199105317}"}}
exception: None

01:59:35 job_callback for (5, 0, 1) started
01:59:35 DISPATCHER: Trying to submit another job.
01:59:35 job_callback for (5, 0, 1) got condition
01:59:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:59:35 HBMASTER: Trying to run another job!
01:59:35 job_callback for (5, 0, 1) finished
01:59:35 HBMASTER: schedule new run for iteration 5
01:59:35 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
01:59:35 HBMASTER: submitting job (5, 0, 6) to dispatcher
01:59:35 DISPATCHER: trying to submit job (5, 0, 6)
01:59:35 DISPATCHER: trying to notify the job_runner thread.
01:59:35 HBMASTER: job (5, 0, 6) submitted to dispatcher
01:59:35 DISPATCHER: Trying to submit another job.
01:59:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:59:35 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216
01:59:35 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
01:59:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:59:35 WORKER: start processing job (5, 0, 6)
01:59:35 WORKER: args: ()
01:59:35 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 250, 'last_n_outputs': 41, 'leak_rate': 0.9663980824952618, 'lr': 0.012879576946893236, 'optimizer': 'SGD', 'sparsity': 0.8149501385339624, 'steps_to_train': 88, 'weight_decay': 0.015652708080159315}, 'budget': 400.0, 'working_directory': '.'}
01:59:42 DISPATCHER: Starting worker discovery
01:59:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:59:42 DISPATCHER: Finished worker discovery
02:00:42 DISPATCHER: Starting worker discovery
02:00:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:00:42 DISPATCHER: Finished worker discovery
02:01:42 DISPATCHER: Starting worker discovery
02:01:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:01:42 DISPATCHER: Finished worker discovery
02:02:42 DISPATCHER: Starting worker discovery
02:02:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:02:42 DISPATCHER: Finished worker discovery
02:03:42 DISPATCHER: Starting worker discovery
02:03:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:03:42 DISPATCHER: Finished worker discovery
02:04:42 DISPATCHER: Starting worker discovery
02:04:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:04:42 DISPATCHER: Finished worker discovery
02:05:42 DISPATCHER: Starting worker discovery
02:05:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:05:42 DISPATCHER: Finished worker discovery
02:06:42 DISPATCHER: Starting worker discovery
02:06:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:06:42 DISPATCHER: Finished worker discovery
02:06:49 WORKER: done with job (5, 0, 6), trying to register it.
02:06:49 WORKER: registered result for job (5, 0, 6) with dispatcher
02:06:49 DISPATCHER: job (5, 0, 6) finished
02:06:49 DISPATCHER: register_result: lock acquired
02:06:49 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
02:06:49 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 250, 'last_n_outputs': 41, 'leak_rate': 0.9663980824952618, 'lr': 0.012879576946893236, 'optimizer': 'SGD', 'sparsity': 0.8149501385339624, 'steps_to_train': 88, 'weight_decay': 0.015652708080159315}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3909369772304302, 'info': {'music-speech': 0.3909369772304302, 'config': "{'batch_size': 16, 'hidden_dim': 250, 'last_n_outputs': 41, 'leak_rate': 0.9663980824952618, 'lr': 0.012879576946893236, 'optimizer': 'SGD', 'sparsity': 0.8149501385339624, 'steps_to_train': 88, 'weight_decay': 0.015652708080159315}"}}
exception: None

02:06:49 job_callback for (5, 0, 6) started
02:06:49 DISPATCHER: Trying to submit another job.
02:06:49 job_callback for (5, 0, 6) got condition
02:06:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:06:49 HBMASTER: Trying to run another job!
02:06:49 job_callback for (5, 0, 6) finished
02:06:49 HBMASTER: schedule new run for iteration 5
02:06:49 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
02:06:49 HBMASTER: submitting job (5, 0, 8) to dispatcher
02:06:49 DISPATCHER: trying to submit job (5, 0, 8)
02:06:49 DISPATCHER: trying to notify the job_runner thread.
02:06:49 HBMASTER: job (5, 0, 8) submitted to dispatcher
02:06:49 DISPATCHER: Trying to submit another job.
02:06:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:06:49 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216
02:06:49 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
02:06:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:06:49 WORKER: start processing job (5, 0, 8)
02:06:49 WORKER: args: ()
02:06:49 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 225, 'last_n_outputs': 27, 'leak_rate': 0.9230966407483132, 'lr': 0.0031297343706227186, 'optimizer': 'SGD', 'sparsity': 0.8616202714561665, 'steps_to_train': 45, 'weight_decay': 0.08653738720665993}, 'budget': 400.0, 'working_directory': '.'}
02:07:42 DISPATCHER: Starting worker discovery
02:07:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:07:42 DISPATCHER: Finished worker discovery
02:08:42 DISPATCHER: Starting worker discovery
02:08:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:08:42 DISPATCHER: Finished worker discovery
02:09:42 DISPATCHER: Starting worker discovery
02:09:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:09:42 DISPATCHER: Finished worker discovery
02:10:42 DISPATCHER: Starting worker discovery
02:10:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:10:42 DISPATCHER: Finished worker discovery
02:11:42 DISPATCHER: Starting worker discovery
02:11:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:11:42 DISPATCHER: Finished worker discovery
02:12:42 DISPATCHER: Starting worker discovery
02:12:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:12:42 DISPATCHER: Finished worker discovery
02:13:42 DISPATCHER: Starting worker discovery
02:13:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:13:42 DISPATCHER: Finished worker discovery
02:13:47 WORKER: done with job (5, 0, 8), trying to register it.
02:13:47 DISPATCHER: job (5, 0, 8) finished
02:13:47 WORKER: registered result for job (5, 0, 8) with dispatcher
02:13:47 DISPATCHER: register_result: lock acquired
02:13:47 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
02:13:47 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 225, 'last_n_outputs': 27, 'leak_rate': 0.9230966407483132, 'lr': 0.0031297343706227186, 'optimizer': 'SGD', 'sparsity': 0.8616202714561665, 'steps_to_train': 45, 'weight_decay': 0.08653738720665993}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.38363331026629177, 'info': {'music-speech': 0.38363331026629177, 'config': "{'batch_size': 128, 'hidden_dim': 225, 'last_n_outputs': 27, 'leak_rate': 0.9230966407483132, 'lr': 0.0031297343706227186, 'optimizer': 'SGD', 'sparsity': 0.8616202714561665, 'steps_to_train': 45, 'weight_decay': 0.08653738720665993}"}}
exception: None

02:13:47 DISPATCHER: Trying to submit another job.
02:13:47 job_callback for (5, 0, 8) started
02:13:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:13:47 job_callback for (5, 0, 8) got condition
02:13:47 HBMASTER: Trying to run another job!
02:13:47 job_callback for (5, 0, 8) finished
02:13:47 ITERATION: Advancing config (5, 0, 6) to next budget 1200.000000
02:13:47 HBMASTER: schedule new run for iteration 5
02:13:47 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
02:13:47 HBMASTER: submitting job (5, 0, 6) to dispatcher
02:13:47 DISPATCHER: trying to submit job (5, 0, 6)
02:13:47 DISPATCHER: trying to notify the job_runner thread.
02:13:47 HBMASTER: job (5, 0, 6) submitted to dispatcher
02:13:47 DISPATCHER: Trying to submit another job.
02:13:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:13:47 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216
02:13:47 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
02:13:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:13:47 WORKER: start processing job (5, 0, 6)
02:13:47 WORKER: args: ()
02:13:47 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 250, 'last_n_outputs': 41, 'leak_rate': 0.9663980824952618, 'lr': 0.012879576946893236, 'optimizer': 'SGD', 'sparsity': 0.8149501385339624, 'steps_to_train': 88, 'weight_decay': 0.015652708080159315}, 'budget': 1200.0, 'working_directory': '.'}
02:14:42 DISPATCHER: Starting worker discovery
02:14:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:14:42 DISPATCHER: Finished worker discovery
02:15:42 DISPATCHER: Starting worker discovery
02:15:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:15:42 DISPATCHER: Finished worker discovery
02:16:42 DISPATCHER: Starting worker discovery
02:16:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:16:42 DISPATCHER: Finished worker discovery
02:17:42 DISPATCHER: Starting worker discovery
02:17:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:17:42 DISPATCHER: Finished worker discovery
02:18:42 DISPATCHER: Starting worker discovery
02:18:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:18:42 DISPATCHER: Finished worker discovery
02:19:42 DISPATCHER: Starting worker discovery
02:19:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:19:42 DISPATCHER: Finished worker discovery
02:20:42 DISPATCHER: Starting worker discovery
02:20:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:20:42 DISPATCHER: Finished worker discovery
02:21:42 DISPATCHER: Starting worker discovery
02:21:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:21:42 DISPATCHER: Finished worker discovery
02:22:42 DISPATCHER: Starting worker discovery
02:22:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:22:42 DISPATCHER: Finished worker discovery
02:23:42 DISPATCHER: Starting worker discovery
02:23:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:23:42 DISPATCHER: Finished worker discovery
02:24:42 DISPATCHER: Starting worker discovery
02:24:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:24:42 DISPATCHER: Finished worker discovery
02:25:42 DISPATCHER: Starting worker discovery
02:25:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:25:42 DISPATCHER: Finished worker discovery
02:26:42 DISPATCHER: Starting worker discovery
02:26:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:26:42 DISPATCHER: Finished worker discovery
02:27:42 DISPATCHER: Starting worker discovery
02:27:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:27:42 DISPATCHER: Finished worker discovery
02:28:42 DISPATCHER: Starting worker discovery
02:28:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:28:42 DISPATCHER: Finished worker discovery
02:29:42 DISPATCHER: Starting worker discovery
02:29:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:29:42 DISPATCHER: Finished worker discovery
02:30:42 DISPATCHER: Starting worker discovery
02:30:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:30:42 DISPATCHER: Finished worker discovery
02:31:42 DISPATCHER: Starting worker discovery
02:31:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:31:42 DISPATCHER: Finished worker discovery
02:32:42 DISPATCHER: Starting worker discovery
02:32:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:32:42 DISPATCHER: Finished worker discovery
02:33:42 DISPATCHER: Starting worker discovery
02:33:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:33:42 DISPATCHER: Finished worker discovery
02:34:10 WORKER: done with job (5, 0, 6), trying to register it.
02:34:10 DISPATCHER: job (5, 0, 6) finished
02:34:10 WORKER: registered result for job (5, 0, 6) with dispatcher
02:34:10 DISPATCHER: register_result: lock acquired
02:34:10 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
02:34:10 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 250, 'last_n_outputs': 41, 'leak_rate': 0.9663980824952618, 'lr': 0.012879576946893236, 'optimizer': 'SGD', 'sparsity': 0.8149501385339624, 'steps_to_train': 88, 'weight_decay': 0.015652708080159315}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.4515646951648338, 'info': {'music-speech': 0.4515646951648338, 'config': "{'batch_size': 16, 'hidden_dim': 250, 'last_n_outputs': 41, 'leak_rate': 0.9663980824952618, 'lr': 0.012879576946893236, 'optimizer': 'SGD', 'sparsity': 0.8149501385339624, 'steps_to_train': 88, 'weight_decay': 0.015652708080159315}"}}
exception: None

02:34:10 job_callback for (5, 0, 6) started
02:34:10 job_callback for (5, 0, 6) got condition
02:34:10 DISPATCHER: Trying to submit another job.
02:34:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:34:10 HBMASTER: Trying to run another job!
02:34:10 job_callback for (5, 0, 6) finished
02:34:10 start sampling a new configuration.
02:34:10 best_vector: [3, 0.7636662958708966, 0.23678849172911426, 0.9891687911363958, 0.08219274613035021, 0, 0.06095941644126318, 0.42671890021203485, 0.7281831119942002], 0.08118337582941182, 0.007713300098260568, 0.0006261917407621268
02:34:10 done sampling a new configuration.
02:34:10 HBMASTER: schedule new run for iteration 6
02:34:10 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
02:34:10 HBMASTER: submitting job (6, 0, 0) to dispatcher
02:34:10 DISPATCHER: trying to submit job (6, 0, 0)
02:34:10 DISPATCHER: trying to notify the job_runner thread.
02:34:10 HBMASTER: job (6, 0, 0) submitted to dispatcher
02:34:10 DISPATCHER: Trying to submit another job.
02:34:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:34:10 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
02:34:10 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
02:34:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:34:10 WORKER: start processing job (6, 0, 0)
02:34:10 WORKER: args: ()
02:34:10 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 811, 'last_n_outputs': 19, 'leak_rate': 0.9972921977840989, 'lr': 0.0014601097205876536, 'optimizer': 'Adam', 'sparsity': 0.7646302599459032, 'steps_to_train': 48, 'weight_decay': 0.08859068730409442}, 'budget': 400.0, 'working_directory': '.'}
02:34:42 DISPATCHER: Starting worker discovery
02:34:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:34:42 DISPATCHER: Finished worker discovery
02:35:42 DISPATCHER: Starting worker discovery
02:35:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:35:42 DISPATCHER: Finished worker discovery
02:36:42 DISPATCHER: Starting worker discovery
02:36:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:36:42 DISPATCHER: Finished worker discovery
02:37:42 DISPATCHER: Starting worker discovery
02:37:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:37:42 DISPATCHER: Finished worker discovery
02:38:42 DISPATCHER: Starting worker discovery
02:38:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:38:42 DISPATCHER: Finished worker discovery
02:39:42 DISPATCHER: Starting worker discovery
02:39:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:39:42 DISPATCHER: Finished worker discovery
02:40:42 DISPATCHER: Starting worker discovery
02:40:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:40:42 DISPATCHER: Finished worker discovery
02:41:05 WORKER: done with job (6, 0, 0), trying to register it.
02:41:05 WORKER: registered result for job (6, 0, 0) with dispatcher
02:41:05 DISPATCHER: job (6, 0, 0) finished
02:41:05 DISPATCHER: register_result: lock acquired
02:41:05 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
02:41:05 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 811, 'last_n_outputs': 19, 'leak_rate': 0.9972921977840989, 'lr': 0.0014601097205876536, 'optimizer': 'Adam', 'sparsity': 0.7646302599459032, 'steps_to_train': 48, 'weight_decay': 0.08859068730409442}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.35188951909875166, 'info': {'music-speech': 0.35188951909875166, 'config': "{'batch_size': 128, 'hidden_dim': 811, 'last_n_outputs': 19, 'leak_rate': 0.9972921977840989, 'lr': 0.0014601097205876536, 'optimizer': 'Adam', 'sparsity': 0.7646302599459032, 'steps_to_train': 48, 'weight_decay': 0.08859068730409442}"}}
exception: None

02:41:05 job_callback for (6, 0, 0) started
02:41:05 DISPATCHER: Trying to submit another job.
02:41:05 job_callback for (6, 0, 0) got condition
02:41:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:41:05 HBMASTER: Trying to run another job!
02:41:05 job_callback for (6, 0, 0) finished
02:41:05 start sampling a new configuration.
02:41:05 done sampling a new configuration.
02:41:05 HBMASTER: schedule new run for iteration 6
02:41:05 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
02:41:05 HBMASTER: submitting job (6, 0, 1) to dispatcher
02:41:05 DISPATCHER: trying to submit job (6, 0, 1)
02:41:05 DISPATCHER: trying to notify the job_runner thread.
02:41:05 HBMASTER: job (6, 0, 1) submitted to dispatcher
02:41:05 DISPATCHER: Trying to submit another job.
02:41:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:41:05 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
02:41:05 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
02:41:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:41:05 WORKER: start processing job (6, 0, 1)
02:41:05 WORKER: args: ()
02:41:05 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 645, 'last_n_outputs': 43, 'leak_rate': 0.9831029341152169, 'lr': 0.0011959355725092273, 'optimizer': 'Adam', 'sparsity': 0.8362476488570079, 'steps_to_train': 18, 'weight_decay': 0.09177301645311634}, 'budget': 400.0, 'working_directory': '.'}
02:41:42 DISPATCHER: Starting worker discovery
02:41:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:41:42 DISPATCHER: Finished worker discovery
02:42:42 DISPATCHER: Starting worker discovery
02:42:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:42:42 DISPATCHER: Finished worker discovery
02:43:42 DISPATCHER: Starting worker discovery
02:43:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:43:42 DISPATCHER: Finished worker discovery
02:44:42 DISPATCHER: Starting worker discovery
02:44:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:44:42 DISPATCHER: Finished worker discovery
02:45:42 DISPATCHER: Starting worker discovery
02:45:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:45:42 DISPATCHER: Finished worker discovery
02:46:42 DISPATCHER: Starting worker discovery
02:46:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:46:42 DISPATCHER: Finished worker discovery
02:47:42 DISPATCHER: Starting worker discovery
02:47:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:47:42 DISPATCHER: Finished worker discovery
02:47:58 WORKER: done with job (6, 0, 1), trying to register it.
02:47:58 WORKER: registered result for job (6, 0, 1) with dispatcher
02:47:58 DISPATCHER: job (6, 0, 1) finished
02:47:58 DISPATCHER: register_result: lock acquired
02:47:58 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
02:47:58 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 645, 'last_n_outputs': 43, 'leak_rate': 0.9831029341152169, 'lr': 0.0011959355725092273, 'optimizer': 'Adam', 'sparsity': 0.8362476488570079, 'steps_to_train': 18, 'weight_decay': 0.09177301645311634}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5998778618079492, 'info': {'music-speech': 0.5998778618079492, 'config': "{'batch_size': 128, 'hidden_dim': 645, 'last_n_outputs': 43, 'leak_rate': 0.9831029341152169, 'lr': 0.0011959355725092273, 'optimizer': 'Adam', 'sparsity': 0.8362476488570079, 'steps_to_train': 18, 'weight_decay': 0.09177301645311634}"}}
exception: None

02:47:58 job_callback for (6, 0, 1) started
02:47:58 DISPATCHER: Trying to submit another job.
02:47:58 job_callback for (6, 0, 1) got condition
02:47:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:47:58 done building a new model for budget 400.000000 based on 10/17 split
Best loss for this budget:-0.599878





02:47:58 HBMASTER: Trying to run another job!
02:47:58 job_callback for (6, 0, 1) finished
02:47:58 start sampling a new configuration.
02:47:58 best_vector: [3, 0.5866232043068434, 0.7302525837870367, 0.5288063260813001, 0.2021413199383601, 0, 0.4397281523370275, 0.35578357677130507, 0.7034527877097457], 5.791560809524143e-32, 0.17266502638727607, -0.006389136417576616
02:47:58 done sampling a new configuration.
02:47:58 HBMASTER: schedule new run for iteration 6
02:47:58 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
02:47:58 HBMASTER: submitting job (6, 0, 2) to dispatcher
02:47:58 DISPATCHER: trying to submit job (6, 0, 2)
02:47:58 DISPATCHER: trying to notify the job_runner thread.
02:47:58 HBMASTER: job (6, 0, 2) submitted to dispatcher
02:47:58 DISPATCHER: Trying to submit another job.
02:47:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:47:58 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
02:47:58 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
02:47:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:47:58 WORKER: start processing job (6, 0, 2)
02:47:58 WORKER: args: ()
02:47:58 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 669, 'last_n_outputs': 39, 'leak_rate': 0.882201581520325, 'lr': 0.0025367790351962247, 'optimizer': 'Adam', 'sparsity': 0.8555347565608866, 'steps_to_train': 42, 'weight_decay': 0.08226463542034736}, 'budget': 400.0, 'working_directory': '.'}
02:48:42 DISPATCHER: Starting worker discovery
02:48:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:48:42 DISPATCHER: Finished worker discovery
02:49:42 DISPATCHER: Starting worker discovery
02:49:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:49:42 DISPATCHER: Finished worker discovery
02:50:42 DISPATCHER: Starting worker discovery
02:50:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:50:42 DISPATCHER: Finished worker discovery
02:51:42 DISPATCHER: Starting worker discovery
02:51:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:51:42 DISPATCHER: Finished worker discovery
02:52:42 DISPATCHER: Starting worker discovery
02:52:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:52:42 DISPATCHER: Finished worker discovery
02:53:42 DISPATCHER: Starting worker discovery
02:53:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:53:43 DISPATCHER: Finished worker discovery
02:54:43 DISPATCHER: Starting worker discovery
02:54:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:54:43 DISPATCHER: Finished worker discovery
02:54:47 WORKER: done with job (6, 0, 2), trying to register it.
02:54:47 DISPATCHER: job (6, 0, 2) finished
02:54:47 WORKER: registered result for job (6, 0, 2) with dispatcher
02:54:47 DISPATCHER: register_result: lock acquired
02:54:47 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
02:54:47 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 669, 'last_n_outputs': 39, 'leak_rate': 0.882201581520325, 'lr': 0.0025367790351962247, 'optimizer': 'Adam', 'sparsity': 0.8555347565608866, 'steps_to_train': 42, 'weight_decay': 0.08226463542034736}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4904586058354514, 'info': {'music-speech': 0.4904586058354514, 'config': "{'batch_size': 128, 'hidden_dim': 669, 'last_n_outputs': 39, 'leak_rate': 0.882201581520325, 'lr': 0.0025367790351962247, 'optimizer': 'Adam', 'sparsity': 0.8555347565608866, 'steps_to_train': 42, 'weight_decay': 0.08226463542034736}"}}
exception: None

02:54:47 job_callback for (6, 0, 2) started
02:54:47 DISPATCHER: Trying to submit another job.
02:54:47 job_callback for (6, 0, 2) got condition
02:54:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:54:47 done building a new model for budget 400.000000 based on 10/17 split
Best loss for this budget:-0.599878





02:54:47 HBMASTER: Trying to run another job!
02:54:47 job_callback for (6, 0, 2) finished
02:54:47 start sampling a new configuration.
02:54:47 done sampling a new configuration.
02:54:47 HBMASTER: schedule new run for iteration 6
02:54:47 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
02:54:47 HBMASTER: submitting job (6, 0, 3) to dispatcher
02:54:47 DISPATCHER: trying to submit job (6, 0, 3)
02:54:47 DISPATCHER: trying to notify the job_runner thread.
02:54:47 HBMASTER: job (6, 0, 3) submitted to dispatcher
02:54:47 DISPATCHER: Trying to submit another job.
02:54:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:54:47 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
02:54:47 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
02:54:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:54:47 WORKER: start processing job (6, 0, 3)
02:54:47 WORKER: args: ()
02:54:47 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 457, 'last_n_outputs': 30, 'leak_rate': 0.8835521116105931, 'lr': 0.03193458329918202, 'optimizer': 'Adam', 'sparsity': 0.7927389069147958, 'steps_to_train': 26, 'weight_decay': 0.02522112672974514}, 'budget': 400.0, 'working_directory': '.'}
02:55:43 DISPATCHER: Starting worker discovery
02:55:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:55:43 DISPATCHER: Finished worker discovery
02:56:43 DISPATCHER: Starting worker discovery
02:56:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:56:43 DISPATCHER: Finished worker discovery
02:57:43 DISPATCHER: Starting worker discovery
02:57:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:57:43 DISPATCHER: Finished worker discovery
02:58:43 DISPATCHER: Starting worker discovery
02:58:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:58:43 DISPATCHER: Finished worker discovery
02:59:43 DISPATCHER: Starting worker discovery
02:59:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:59:43 DISPATCHER: Finished worker discovery
03:00:43 DISPATCHER: Starting worker discovery
03:00:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:00:43 DISPATCHER: Finished worker discovery
03:01:43 DISPATCHER: Starting worker discovery
03:01:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:01:43 DISPATCHER: Finished worker discovery
03:01:43 WORKER: done with job (6, 0, 3), trying to register it.
03:01:43 WORKER: registered result for job (6, 0, 3) with dispatcher
03:01:43 DISPATCHER: job (6, 0, 3) finished
03:01:43 DISPATCHER: register_result: lock acquired
03:01:43 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
03:01:43 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 457, 'last_n_outputs': 30, 'leak_rate': 0.8835521116105931, 'lr': 0.03193458329918202, 'optimizer': 'Adam', 'sparsity': 0.7927389069147958, 'steps_to_train': 26, 'weight_decay': 0.02522112672974514}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5452854858175082, 'info': {'music-speech': 0.5452854858175082, 'config': "{'batch_size': 16, 'hidden_dim': 457, 'last_n_outputs': 30, 'leak_rate': 0.8835521116105931, 'lr': 0.03193458329918202, 'optimizer': 'Adam', 'sparsity': 0.7927389069147958, 'steps_to_train': 26, 'weight_decay': 0.02522112672974514}"}}
exception: None

03:01:43 job_callback for (6, 0, 3) started
03:01:43 DISPATCHER: Trying to submit another job.
03:01:43 job_callback for (6, 0, 3) got condition
03:01:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:01:43 done building a new model for budget 400.000000 based on 10/18 split
Best loss for this budget:-0.599878





03:01:43 HBMASTER: Trying to run another job!
03:01:43 job_callback for (6, 0, 3) finished
03:01:43 start sampling a new configuration.
03:01:43 best_vector: [0, 0.8427816414508054, 0.8179941124830985, 0.37498686935038306, 0.9147442385480161, 0, 0.04304191979816366, 0.04574823135012815, 0.05979295057508924], 6.11645390988401e-30, 0.0016349342523190266, -3.162207415678401e-09
03:01:43 done sampling a new configuration.
03:01:43 HBMASTER: schedule new run for iteration 6
03:01:43 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
03:01:43 HBMASTER: submitting job (6, 0, 4) to dispatcher
03:01:43 DISPATCHER: trying to submit job (6, 0, 4)
03:01:43 DISPATCHER: trying to notify the job_runner thread.
03:01:43 HBMASTER: job (6, 0, 4) submitted to dispatcher
03:01:43 DISPATCHER: Trying to submit another job.
03:01:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:01:43 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
03:01:43 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
03:01:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:01:43 WORKER: start processing job (6, 0, 4)
03:01:43 WORKER: args: ()
03:01:43 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 875, 'last_n_outputs': 43, 'leak_rate': 0.8437467173375958, 'lr': 0.06752871367237796, 'optimizer': 'Adam', 'sparsity': 0.7603300607515593, 'steps_to_train': 14, 'weight_decay': 0.011961686673156233}, 'budget': 400.0, 'working_directory': '.'}
03:02:43 DISPATCHER: Starting worker discovery
03:02:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:02:43 DISPATCHER: Finished worker discovery
03:03:43 DISPATCHER: Starting worker discovery
03:03:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:03:43 DISPATCHER: Finished worker discovery
03:04:43 DISPATCHER: Starting worker discovery
03:04:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:04:43 DISPATCHER: Finished worker discovery
03:05:43 DISPATCHER: Starting worker discovery
03:05:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:05:43 DISPATCHER: Finished worker discovery
03:06:43 DISPATCHER: Starting worker discovery
03:06:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:06:43 DISPATCHER: Finished worker discovery
03:07:43 DISPATCHER: Starting worker discovery
03:07:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:07:43 DISPATCHER: Finished worker discovery
03:08:36 WORKER: done with job (6, 0, 4), trying to register it.
03:08:36 WORKER: registered result for job (6, 0, 4) with dispatcher
03:08:36 DISPATCHER: job (6, 0, 4) finished
03:08:36 DISPATCHER: register_result: lock acquired
03:08:36 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
03:08:36 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 875, 'last_n_outputs': 43, 'leak_rate': 0.8437467173375958, 'lr': 0.06752871367237796, 'optimizer': 'Adam', 'sparsity': 0.7603300607515593, 'steps_to_train': 14, 'weight_decay': 0.011961686673156233}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.408776061965304, 'info': {'music-speech': 0.408776061965304, 'config': "{'batch_size': 16, 'hidden_dim': 875, 'last_n_outputs': 43, 'leak_rate': 0.8437467173375958, 'lr': 0.06752871367237796, 'optimizer': 'Adam', 'sparsity': 0.7603300607515593, 'steps_to_train': 14, 'weight_decay': 0.011961686673156233}"}}
exception: None

03:08:36 job_callback for (6, 0, 4) started
03:08:36 job_callback for (6, 0, 4) got condition
03:08:36 DISPATCHER: Trying to submit another job.
03:08:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:08:36 done building a new model for budget 400.000000 based on 10/19 split
Best loss for this budget:-0.599878





03:08:36 HBMASTER: Trying to run another job!
03:08:36 job_callback for (6, 0, 4) finished
03:08:36 start sampling a new configuration.
03:08:37 best_vector: [3, 0.8354432407636205, 0.7388152019440337, 0.4349993675667991, 0.2521689549381085, 1, 0.3030052110506485, 0.47819656806505983, 0.7155852029452616], 5.648480272596594e-32, 0.17703877003013807, -0.0007434430690975435
03:08:37 done sampling a new configuration.
03:08:37 HBMASTER: schedule new run for iteration 6
03:08:37 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
03:08:37 HBMASTER: submitting job (6, 0, 5) to dispatcher
03:08:37 DISPATCHER: trying to submit job (6, 0, 5)
03:08:37 DISPATCHER: trying to notify the job_runner thread.
03:08:37 HBMASTER: job (6, 0, 5) submitted to dispatcher
03:08:37 DISPATCHER: Trying to submit another job.
03:08:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:08:37 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
03:08:37 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
03:08:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:08:37 WORKER: start processing job (6, 0, 5)
03:08:37 WORKER: args: ()
03:08:37 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 869, 'last_n_outputs': 40, 'leak_rate': 0.8587498418916998, 'lr': 0.0031940220492799676, 'optimizer': 'SGD', 'sparsity': 0.8227212506521556, 'steps_to_train': 53, 'weight_decay': 0.08530958189792978}, 'budget': 400.0, 'working_directory': '.'}
03:08:43 DISPATCHER: Starting worker discovery
03:08:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:08:43 DISPATCHER: Finished worker discovery
03:09:43 DISPATCHER: Starting worker discovery
03:09:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:09:43 DISPATCHER: Finished worker discovery
03:10:43 DISPATCHER: Starting worker discovery
03:10:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:10:43 DISPATCHER: Finished worker discovery
03:11:43 DISPATCHER: Starting worker discovery
03:11:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:11:43 DISPATCHER: Finished worker discovery
03:12:43 DISPATCHER: Starting worker discovery
03:12:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:12:43 DISPATCHER: Finished worker discovery
03:13:43 DISPATCHER: Starting worker discovery
03:13:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:13:43 DISPATCHER: Finished worker discovery
03:14:43 DISPATCHER: Starting worker discovery
03:14:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:14:43 DISPATCHER: Finished worker discovery
03:15:39 WORKER: done with job (6, 0, 5), trying to register it.
03:15:39 WORKER: registered result for job (6, 0, 5) with dispatcher
03:15:39 DISPATCHER: job (6, 0, 5) finished
03:15:39 DISPATCHER: register_result: lock acquired
03:15:39 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
03:15:39 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 869, 'last_n_outputs': 40, 'leak_rate': 0.8587498418916998, 'lr': 0.0031940220492799676, 'optimizer': 'SGD', 'sparsity': 0.8227212506521556, 'steps_to_train': 53, 'weight_decay': 0.08530958189792978}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4225693383333632, 'info': {'music-speech': 0.4225693383333632, 'config': "{'batch_size': 128, 'hidden_dim': 869, 'last_n_outputs': 40, 'leak_rate': 0.8587498418916998, 'lr': 0.0031940220492799676, 'optimizer': 'SGD', 'sparsity': 0.8227212506521556, 'steps_to_train': 53, 'weight_decay': 0.08530958189792978}"}}
exception: None

03:15:39 job_callback for (6, 0, 5) started
03:15:39 DISPATCHER: Trying to submit another job.
03:15:39 job_callback for (6, 0, 5) got condition
03:15:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:15:39 done building a new model for budget 400.000000 based on 10/20 split
Best loss for this budget:-0.599878





03:15:39 HBMASTER: Trying to run another job!
03:15:39 job_callback for (6, 0, 5) finished
03:15:39 ITERATION: Advancing config (6, 0, 1) to next budget 1200.000000
03:15:39 ITERATION: Advancing config (6, 0, 3) to next budget 1200.000000
03:15:39 HBMASTER: schedule new run for iteration 6
03:15:39 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
03:15:39 HBMASTER: submitting job (6, 0, 1) to dispatcher
03:15:39 DISPATCHER: trying to submit job (6, 0, 1)
03:15:39 DISPATCHER: trying to notify the job_runner thread.
03:15:39 HBMASTER: job (6, 0, 1) submitted to dispatcher
03:15:39 DISPATCHER: Trying to submit another job.
03:15:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:15:39 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
03:15:39 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
03:15:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:15:39 WORKER: start processing job (6, 0, 1)
03:15:39 WORKER: args: ()
03:15:39 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 645, 'last_n_outputs': 43, 'leak_rate': 0.9831029341152169, 'lr': 0.0011959355725092273, 'optimizer': 'Adam', 'sparsity': 0.8362476488570079, 'steps_to_train': 18, 'weight_decay': 0.09177301645311634}, 'budget': 1200.0, 'working_directory': '.'}
03:15:43 DISPATCHER: Starting worker discovery
03:15:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:15:43 DISPATCHER: Finished worker discovery
03:16:43 DISPATCHER: Starting worker discovery
03:16:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:16:43 DISPATCHER: Finished worker discovery
03:17:43 DISPATCHER: Starting worker discovery
03:17:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:17:43 DISPATCHER: Finished worker discovery
03:18:43 DISPATCHER: Starting worker discovery
03:18:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:18:43 DISPATCHER: Finished worker discovery
03:19:43 DISPATCHER: Starting worker discovery
03:19:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:19:43 DISPATCHER: Finished worker discovery
03:20:43 DISPATCHER: Starting worker discovery
03:20:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:20:43 DISPATCHER: Finished worker discovery
03:21:43 DISPATCHER: Starting worker discovery
03:21:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:21:43 DISPATCHER: Finished worker discovery
03:22:43 DISPATCHER: Starting worker discovery
03:22:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:22:43 DISPATCHER: Finished worker discovery
03:23:43 DISPATCHER: Starting worker discovery
03:23:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:23:43 DISPATCHER: Finished worker discovery
03:24:43 DISPATCHER: Starting worker discovery
03:24:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:24:43 DISPATCHER: Finished worker discovery
03:25:43 DISPATCHER: Starting worker discovery
03:25:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:25:43 DISPATCHER: Finished worker discovery
03:26:43 DISPATCHER: Starting worker discovery
03:26:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:26:43 DISPATCHER: Finished worker discovery
03:27:43 DISPATCHER: Starting worker discovery
03:27:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:27:43 DISPATCHER: Finished worker discovery
03:28:43 DISPATCHER: Starting worker discovery
03:28:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:28:43 DISPATCHER: Finished worker discovery
03:29:43 DISPATCHER: Starting worker discovery
03:29:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:29:43 DISPATCHER: Finished worker discovery
03:30:43 DISPATCHER: Starting worker discovery
03:30:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:30:43 DISPATCHER: Finished worker discovery
03:31:43 DISPATCHER: Starting worker discovery
03:31:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:31:43 DISPATCHER: Finished worker discovery
03:32:43 DISPATCHER: Starting worker discovery
03:32:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:32:43 DISPATCHER: Finished worker discovery
03:33:43 DISPATCHER: Starting worker discovery
03:33:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:33:43 DISPATCHER: Finished worker discovery
03:34:43 DISPATCHER: Starting worker discovery
03:34:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:34:43 DISPATCHER: Finished worker discovery
03:35:43 DISPATCHER: Starting worker discovery
03:35:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:35:43 DISPATCHER: Finished worker discovery
03:35:49 WORKER: done with job (6, 0, 1), trying to register it.
03:35:49 WORKER: registered result for job (6, 0, 1) with dispatcher
03:35:49 DISPATCHER: job (6, 0, 1) finished
03:35:49 DISPATCHER: register_result: lock acquired
03:35:49 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
03:35:49 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 645, 'last_n_outputs': 43, 'leak_rate': 0.9831029341152169, 'lr': 0.0011959355725092273, 'optimizer': 'Adam', 'sparsity': 0.8362476488570079, 'steps_to_train': 18, 'weight_decay': 0.09177301645311634}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.44476713701950876, 'info': {'music-speech': 0.44476713701950876, 'config': "{'batch_size': 128, 'hidden_dim': 645, 'last_n_outputs': 43, 'leak_rate': 0.9831029341152169, 'lr': 0.0011959355725092273, 'optimizer': 'Adam', 'sparsity': 0.8362476488570079, 'steps_to_train': 18, 'weight_decay': 0.09177301645311634}"}}
exception: None

03:35:49 job_callback for (6, 0, 1) started
03:35:49 DISPATCHER: Trying to submit another job.
03:35:49 job_callback for (6, 0, 1) got condition
03:35:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:35:49 HBMASTER: Trying to run another job!
03:35:49 job_callback for (6, 0, 1) finished
03:35:49 HBMASTER: schedule new run for iteration 6
03:35:49 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
03:35:49 HBMASTER: submitting job (6, 0, 3) to dispatcher
03:35:49 DISPATCHER: trying to submit job (6, 0, 3)
03:35:49 DISPATCHER: trying to notify the job_runner thread.
03:35:49 HBMASTER: job (6, 0, 3) submitted to dispatcher
03:35:49 DISPATCHER: Trying to submit another job.
03:35:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:35:49 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
03:35:49 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
03:35:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:35:49 WORKER: start processing job (6, 0, 3)
03:35:49 WORKER: args: ()
03:35:49 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 457, 'last_n_outputs': 30, 'leak_rate': 0.8835521116105931, 'lr': 0.03193458329918202, 'optimizer': 'Adam', 'sparsity': 0.7927389069147958, 'steps_to_train': 26, 'weight_decay': 0.02522112672974514}, 'budget': 1200.0, 'working_directory': '.'}
03:36:43 DISPATCHER: Starting worker discovery
03:36:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:36:43 DISPATCHER: Finished worker discovery
03:37:43 DISPATCHER: Starting worker discovery
03:37:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:37:43 DISPATCHER: Finished worker discovery
03:38:43 DISPATCHER: Starting worker discovery
03:38:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:38:43 DISPATCHER: Finished worker discovery
03:39:43 DISPATCHER: Starting worker discovery
03:39:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:39:43 DISPATCHER: Finished worker discovery
03:40:43 DISPATCHER: Starting worker discovery
03:40:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:40:43 DISPATCHER: Finished worker discovery
03:41:43 DISPATCHER: Starting worker discovery
03:41:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:41:43 DISPATCHER: Finished worker discovery
03:42:43 DISPATCHER: Starting worker discovery
03:42:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:42:43 DISPATCHER: Finished worker discovery
03:43:43 DISPATCHER: Starting worker discovery
03:43:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:43:43 DISPATCHER: Finished worker discovery
03:44:43 DISPATCHER: Starting worker discovery
03:44:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:44:43 DISPATCHER: Finished worker discovery
03:45:43 DISPATCHER: Starting worker discovery
03:45:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:45:43 DISPATCHER: Finished worker discovery
03:46:43 DISPATCHER: Starting worker discovery
03:46:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:46:43 DISPATCHER: Finished worker discovery
03:47:43 DISPATCHER: Starting worker discovery
03:47:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:47:43 DISPATCHER: Finished worker discovery
03:48:43 DISPATCHER: Starting worker discovery
03:48:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:48:43 DISPATCHER: Finished worker discovery
03:49:43 DISPATCHER: Starting worker discovery
03:49:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:49:43 DISPATCHER: Finished worker discovery
03:50:43 DISPATCHER: Starting worker discovery
03:50:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:50:44 DISPATCHER: Finished worker discovery
03:51:44 DISPATCHER: Starting worker discovery
03:51:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:51:44 DISPATCHER: Finished worker discovery
03:52:44 DISPATCHER: Starting worker discovery
03:52:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:52:44 DISPATCHER: Finished worker discovery
03:53:44 DISPATCHER: Starting worker discovery
03:53:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:53:44 DISPATCHER: Finished worker discovery
03:54:44 DISPATCHER: Starting worker discovery
03:54:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:54:44 DISPATCHER: Finished worker discovery
03:55:44 DISPATCHER: Starting worker discovery
03:55:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:55:44 DISPATCHER: Finished worker discovery
03:55:59 WORKER: done with job (6, 0, 3), trying to register it.
03:55:59 WORKER: registered result for job (6, 0, 3) with dispatcher
03:55:59 DISPATCHER: job (6, 0, 3) finished
03:55:59 DISPATCHER: register_result: lock acquired
03:55:59 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
03:55:59 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 457, 'last_n_outputs': 30, 'leak_rate': 0.8835521116105931, 'lr': 0.03193458329918202, 'optimizer': 'Adam', 'sparsity': 0.7927389069147958, 'steps_to_train': 26, 'weight_decay': 0.02522112672974514}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.406678955750082, 'info': {'music-speech': 0.406678955750082, 'config': "{'batch_size': 16, 'hidden_dim': 457, 'last_n_outputs': 30, 'leak_rate': 0.8835521116105931, 'lr': 0.03193458329918202, 'optimizer': 'Adam', 'sparsity': 0.7927389069147958, 'steps_to_train': 26, 'weight_decay': 0.02522112672974514}"}}
exception: None

03:55:59 job_callback for (6, 0, 3) started
03:55:59 DISPATCHER: Trying to submit another job.
03:55:59 job_callback for (6, 0, 3) got condition
03:55:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:55:59 HBMASTER: Trying to run another job!
03:55:59 job_callback for (6, 0, 3) finished
03:55:59 start sampling a new configuration.
03:55:59 best_vector: [3, 0.34002102918624694, 0.9382281435729077, 0.49767720968802415, 0.7091854051765349, 1, 0.354398575288303, 0.8258610071472985, 0.9859593095224353], 4.549418631783735e-31, 0.02198083053983362, -1.5029511844470445e-05
03:55:59 done sampling a new configuration.
03:55:59 HBMASTER: schedule new run for iteration 7
03:55:59 HBMASTER: trying submitting job (7, 0, 0) to dispatcher
03:55:59 HBMASTER: submitting job (7, 0, 0) to dispatcher
03:55:59 DISPATCHER: trying to submit job (7, 0, 0)
03:55:59 DISPATCHER: trying to notify the job_runner thread.
03:55:59 HBMASTER: job (7, 0, 0) submitted to dispatcher
03:55:59 DISPATCHER: Trying to submit another job.
03:55:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:55:59 DISPATCHER: starting job (7, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
03:55:59 DISPATCHER: job (7, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
03:55:59 WORKER: start processing job (7, 0, 0)
03:55:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:55:59 WORKER: args: ()
03:55:59 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 472, 'last_n_outputs': 48, 'leak_rate': 0.874419302422006, 'lr': 0.026204194261119147, 'optimizer': 'SGD', 'sparsity': 0.8350556580691927, 'steps_to_train': 85, 'weight_decay': 0.19176203780892673}, 'budget': 1200.0, 'working_directory': '.'}
03:56:44 DISPATCHER: Starting worker discovery
03:56:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:56:44 DISPATCHER: Finished worker discovery
03:57:44 DISPATCHER: Starting worker discovery
03:57:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:57:44 DISPATCHER: Finished worker discovery
03:58:44 DISPATCHER: Starting worker discovery
03:58:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:58:44 DISPATCHER: Finished worker discovery
03:59:44 DISPATCHER: Starting worker discovery
03:59:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:59:44 DISPATCHER: Finished worker discovery
04:00:44 DISPATCHER: Starting worker discovery
04:00:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:00:44 DISPATCHER: Finished worker discovery
04:01:44 DISPATCHER: Starting worker discovery
04:01:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:01:44 DISPATCHER: Finished worker discovery
04:02:44 DISPATCHER: Starting worker discovery
04:02:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:02:44 DISPATCHER: Finished worker discovery
04:03:44 DISPATCHER: Starting worker discovery
04:03:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:03:44 DISPATCHER: Finished worker discovery
04:04:44 DISPATCHER: Starting worker discovery
04:04:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:04:44 DISPATCHER: Finished worker discovery
04:05:44 DISPATCHER: Starting worker discovery
04:05:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:05:44 DISPATCHER: Finished worker discovery
04:06:44 DISPATCHER: Starting worker discovery
04:06:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:06:44 DISPATCHER: Finished worker discovery
04:07:44 DISPATCHER: Starting worker discovery
04:07:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:07:44 DISPATCHER: Finished worker discovery
04:08:44 DISPATCHER: Starting worker discovery
04:08:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:08:44 DISPATCHER: Finished worker discovery
04:09:44 DISPATCHER: Starting worker discovery
04:09:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:09:44 DISPATCHER: Finished worker discovery
04:10:44 DISPATCHER: Starting worker discovery
04:10:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:10:44 DISPATCHER: Finished worker discovery
04:11:44 DISPATCHER: Starting worker discovery
04:11:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:11:44 DISPATCHER: Finished worker discovery
04:12:44 DISPATCHER: Starting worker discovery
04:12:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:12:44 DISPATCHER: Finished worker discovery
04:13:44 DISPATCHER: Starting worker discovery
04:13:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:13:44 DISPATCHER: Finished worker discovery
04:14:44 DISPATCHER: Starting worker discovery
04:14:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:14:44 DISPATCHER: Finished worker discovery
04:15:44 DISPATCHER: Starting worker discovery
04:15:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:15:44 DISPATCHER: Finished worker discovery
04:16:12 WORKER: done with job (7, 0, 0), trying to register it.
04:16:12 DISPATCHER: job (7, 0, 0) finished
04:16:12 WORKER: registered result for job (7, 0, 0) with dispatcher
04:16:12 DISPATCHER: register_result: lock acquired
04:16:12 DISPATCHER: job (7, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
04:16:12 job_id: (7, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 472, 'last_n_outputs': 48, 'leak_rate': 0.874419302422006, 'lr': 0.026204194261119147, 'optimizer': 'SGD', 'sparsity': 0.8350556580691927, 'steps_to_train': 85, 'weight_decay': 0.19176203780892673}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.3077950473998811, 'info': {'music-speech': 0.3077950473998811, 'config': "{'batch_size': 128, 'hidden_dim': 472, 'last_n_outputs': 48, 'leak_rate': 0.874419302422006, 'lr': 0.026204194261119147, 'optimizer': 'SGD', 'sparsity': 0.8350556580691927, 'steps_to_train': 85, 'weight_decay': 0.19176203780892673}"}}
exception: None

04:16:12 job_callback for (7, 0, 0) started
04:16:12 DISPATCHER: Trying to submit another job.
04:16:12 job_callback for (7, 0, 0) got condition
04:16:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:16:12 HBMASTER: Trying to run another job!
04:16:12 job_callback for (7, 0, 0) finished
04:16:12 start sampling a new configuration.
04:16:13 best_vector: [3, 0.4635405785969484, 0.20772610095197347, 0.7662384767235526, 0.473245935336867, 0, 0.16989946097426284, 0.21184771252583073, 0.5803934029002078], 3.618898295316568e-32, 0.2763271908730233, -0.003718130393970954
04:16:13 done sampling a new configuration.
04:16:13 HBMASTER: schedule new run for iteration 7
04:16:13 HBMASTER: trying submitting job (7, 0, 1) to dispatcher
04:16:13 HBMASTER: submitting job (7, 0, 1) to dispatcher
04:16:13 DISPATCHER: trying to submit job (7, 0, 1)
04:16:13 DISPATCHER: trying to notify the job_runner thread.
04:16:13 HBMASTER: job (7, 0, 1) submitted to dispatcher
04:16:13 DISPATCHER: Trying to submit another job.
04:16:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:16:13 DISPATCHER: starting job (7, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
04:16:13 DISPATCHER: job (7, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
04:16:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:16:13 WORKER: start processing job (7, 0, 1)
04:16:13 WORKER: args: ()
04:16:13 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 571, 'last_n_outputs': 18, 'leak_rate': 0.9415596191808882, 'lr': 0.008840806204130415, 'optimizer': 'Adam', 'sparsity': 0.790775870633823, 'steps_to_train': 29, 'weight_decay': 0.05689960171776621}, 'budget': 1200.0, 'working_directory': '.'}
04:16:44 DISPATCHER: Starting worker discovery
04:16:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:16:44 DISPATCHER: Finished worker discovery
04:17:44 DISPATCHER: Starting worker discovery
04:17:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:17:44 DISPATCHER: Finished worker discovery
04:18:44 DISPATCHER: Starting worker discovery
04:18:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:18:44 DISPATCHER: Finished worker discovery
04:19:44 DISPATCHER: Starting worker discovery
04:19:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:19:44 DISPATCHER: Finished worker discovery
04:20:44 DISPATCHER: Starting worker discovery
04:20:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:20:44 DISPATCHER: Finished worker discovery
04:21:44 DISPATCHER: Starting worker discovery
04:21:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:21:44 DISPATCHER: Finished worker discovery
04:22:44 DISPATCHER: Starting worker discovery
04:22:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:22:44 DISPATCHER: Finished worker discovery
04:23:44 DISPATCHER: Starting worker discovery
04:23:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:23:44 DISPATCHER: Finished worker discovery
04:24:44 DISPATCHER: Starting worker discovery
04:24:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:24:44 DISPATCHER: Finished worker discovery
04:25:44 DISPATCHER: Starting worker discovery
04:25:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:25:44 DISPATCHER: Finished worker discovery
04:26:44 DISPATCHER: Starting worker discovery
04:26:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:26:44 DISPATCHER: Finished worker discovery
04:27:44 DISPATCHER: Starting worker discovery
04:27:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:27:44 DISPATCHER: Finished worker discovery
04:28:44 DISPATCHER: Starting worker discovery
04:28:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:28:44 DISPATCHER: Finished worker discovery
04:29:44 DISPATCHER: Starting worker discovery
04:29:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:29:44 DISPATCHER: Finished worker discovery
04:30:44 DISPATCHER: Starting worker discovery
04:30:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:30:44 DISPATCHER: Finished worker discovery
04:31:44 DISPATCHER: Starting worker discovery
04:31:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:31:44 DISPATCHER: Finished worker discovery
04:32:44 DISPATCHER: Starting worker discovery
04:32:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:32:44 DISPATCHER: Finished worker discovery
04:33:44 DISPATCHER: Starting worker discovery
04:33:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:33:44 DISPATCHER: Finished worker discovery
04:34:44 DISPATCHER: Starting worker discovery
04:34:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:34:44 DISPATCHER: Finished worker discovery
04:35:44 DISPATCHER: Starting worker discovery
04:35:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:35:44 DISPATCHER: Finished worker discovery
04:36:31 WORKER: done with job (7, 0, 1), trying to register it.
04:36:31 WORKER: registered result for job (7, 0, 1) with dispatcher
04:36:31 DISPATCHER: job (7, 0, 1) finished
04:36:31 DISPATCHER: register_result: lock acquired
04:36:31 DISPATCHER: job (7, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
04:36:31 job_id: (7, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 571, 'last_n_outputs': 18, 'leak_rate': 0.9415596191808882, 'lr': 0.008840806204130415, 'optimizer': 'Adam', 'sparsity': 0.790775870633823, 'steps_to_train': 29, 'weight_decay': 0.05689960171776621}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5210721804439812, 'info': {'music-speech': 0.5210721804439812, 'config': "{'batch_size': 128, 'hidden_dim': 571, 'last_n_outputs': 18, 'leak_rate': 0.9415596191808882, 'lr': 0.008840806204130415, 'optimizer': 'Adam', 'sparsity': 0.790775870633823, 'steps_to_train': 29, 'weight_decay': 0.05689960171776621}"}}
exception: None

04:36:31 job_callback for (7, 0, 1) started
04:36:31 job_callback for (7, 0, 1) got condition
04:36:31 DISPATCHER: Trying to submit another job.
04:36:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:36:31 HBMASTER: Trying to run another job!
04:36:31 job_callback for (7, 0, 1) finished
04:36:31 start sampling a new configuration.
04:36:31 best_vector: [3, 0.20115700056530011, 0.8040026007215517, 0.753645761290195, 0.37942463813507427, 0, 0.5911398916929852, 0.3922698090171134, 0.6072755046026791], 2.986140019464646e-32, 0.3348804789734139, -0.0012115280982144122
04:36:31 done sampling a new configuration.
04:36:31 HBMASTER: schedule new run for iteration 7
04:36:31 HBMASTER: trying submitting job (7, 0, 2) to dispatcher
04:36:31 HBMASTER: submitting job (7, 0, 2) to dispatcher
04:36:31 DISPATCHER: trying to submit job (7, 0, 2)
04:36:31 DISPATCHER: trying to notify the job_runner thread.
04:36:31 HBMASTER: job (7, 0, 2) submitted to dispatcher
04:36:31 DISPATCHER: Trying to submit another job.
04:36:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:36:31 DISPATCHER: starting job (7, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
04:36:31 DISPATCHER: job (7, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
04:36:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:36:31 WORKER: start processing job (7, 0, 2)
04:36:31 WORKER: args: ()
04:36:31 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 361, 'last_n_outputs': 42, 'leak_rate': 0.9384114403225488, 'lr': 0.00573917247241266, 'optimizer': 'Adam', 'sparsity': 0.8918735740063164, 'steps_to_train': 45, 'weight_decay': 0.06167137723399173}, 'budget': 1200.0, 'working_directory': '.'}
04:36:44 DISPATCHER: Starting worker discovery
04:36:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:36:44 DISPATCHER: Finished worker discovery
04:37:44 DISPATCHER: Starting worker discovery
04:37:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:37:44 DISPATCHER: Finished worker discovery
04:38:44 DISPATCHER: Starting worker discovery
04:38:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:38:44 DISPATCHER: Finished worker discovery
04:39:44 DISPATCHER: Starting worker discovery
04:39:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:39:44 DISPATCHER: Finished worker discovery
04:40:44 DISPATCHER: Starting worker discovery
04:40:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:40:44 DISPATCHER: Finished worker discovery
04:41:44 DISPATCHER: Starting worker discovery
04:41:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:41:44 DISPATCHER: Finished worker discovery
04:42:44 DISPATCHER: Starting worker discovery
04:42:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:42:44 DISPATCHER: Finished worker discovery
04:43:44 DISPATCHER: Starting worker discovery
04:43:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:43:44 DISPATCHER: Finished worker discovery
04:44:44 DISPATCHER: Starting worker discovery
04:44:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:44:44 DISPATCHER: Finished worker discovery
04:45:44 DISPATCHER: Starting worker discovery
04:45:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:45:44 DISPATCHER: Finished worker discovery
04:46:44 DISPATCHER: Starting worker discovery
04:46:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:46:44 DISPATCHER: Finished worker discovery
04:47:44 DISPATCHER: Starting worker discovery
04:47:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:47:44 DISPATCHER: Finished worker discovery
04:48:44 DISPATCHER: Starting worker discovery
04:48:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:48:44 DISPATCHER: Finished worker discovery
04:49:44 DISPATCHER: Starting worker discovery
04:49:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:49:44 DISPATCHER: Finished worker discovery
04:50:44 DISPATCHER: Starting worker discovery
04:50:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:50:44 DISPATCHER: Finished worker discovery
04:51:44 DISPATCHER: Starting worker discovery
04:51:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:51:44 DISPATCHER: Finished worker discovery
04:52:44 DISPATCHER: Starting worker discovery
04:52:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:52:44 DISPATCHER: Finished worker discovery
04:53:44 DISPATCHER: Starting worker discovery
04:53:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:53:44 DISPATCHER: Finished worker discovery
04:54:44 DISPATCHER: Starting worker discovery
04:54:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:54:44 DISPATCHER: Finished worker discovery
04:55:44 DISPATCHER: Starting worker discovery
04:55:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:55:44 DISPATCHER: Finished worker discovery
04:56:44 DISPATCHER: Starting worker discovery
04:56:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:56:44 DISPATCHER: Finished worker discovery
04:56:50 WORKER: done with job (7, 0, 2), trying to register it.
04:56:50 DISPATCHER: job (7, 0, 2) finished
04:56:50 WORKER: registered result for job (7, 0, 2) with dispatcher
04:56:50 DISPATCHER: register_result: lock acquired
04:56:50 DISPATCHER: job (7, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
04:56:50 job_id: (7, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 361, 'last_n_outputs': 42, 'leak_rate': 0.9384114403225488, 'lr': 0.00573917247241266, 'optimizer': 'Adam', 'sparsity': 0.8918735740063164, 'steps_to_train': 45, 'weight_decay': 0.06167137723399173}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.6053595692055678, 'info': {'music-speech': 0.6053595692055678, 'config': "{'batch_size': 128, 'hidden_dim': 361, 'last_n_outputs': 42, 'leak_rate': 0.9384114403225488, 'lr': 0.00573917247241266, 'optimizer': 'Adam', 'sparsity': 0.8918735740063164, 'steps_to_train': 45, 'weight_decay': 0.06167137723399173}"}}
exception: None

04:56:50 job_callback for (7, 0, 2) started
04:56:50 DISPATCHER: Trying to submit another job.
04:56:50 job_callback for (7, 0, 2) got condition
04:56:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:56:50 HBMASTER: Trying to run another job!
04:56:50 job_callback for (7, 0, 2) finished
04:56:50 start sampling a new configuration.
04:56:50 best_vector: [3, 0.04668928912500725, 0.7096250998600812, 0.5197657020053005, 0.1786145415189077, 0, 0.5764523256862221, 0.13776968098566425, 0.8826623536813407], 6.246499222007378e-31, 0.016008967014305327, -0.00030898332820471734
04:56:50 done sampling a new configuration.
04:56:50 HBMASTER: schedule new run for iteration 7
04:56:50 HBMASTER: trying submitting job (7, 0, 3) to dispatcher
04:56:50 HBMASTER: submitting job (7, 0, 3) to dispatcher
04:56:50 DISPATCHER: trying to submit job (7, 0, 3)
04:56:50 DISPATCHER: trying to notify the job_runner thread.
04:56:50 HBMASTER: job (7, 0, 3) submitted to dispatcher
04:56:50 DISPATCHER: Trying to submit another job.
04:56:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:56:50 DISPATCHER: starting job (7, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
04:56:50 DISPATCHER: job (7, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
04:56:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:56:50 WORKER: start processing job (7, 0, 3)
04:56:50 WORKER: args: ()
04:56:50 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 237, 'last_n_outputs': 39, 'leak_rate': 0.8799414255013251, 'lr': 0.0022762978229832333, 'optimizer': 'Adam', 'sparsity': 0.8883485581646933, 'steps_to_train': 22, 'weight_decay': 0.14072465680286025}, 'budget': 1200.0, 'working_directory': '.'}
04:57:44 DISPATCHER: Starting worker discovery
04:57:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:57:44 DISPATCHER: Finished worker discovery
04:58:44 DISPATCHER: Starting worker discovery
04:58:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:58:44 DISPATCHER: Finished worker discovery
04:59:44 DISPATCHER: Starting worker discovery
04:59:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:59:44 DISPATCHER: Finished worker discovery
05:00:44 DISPATCHER: Starting worker discovery
05:00:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:00:44 DISPATCHER: Finished worker discovery
05:01:44 DISPATCHER: Starting worker discovery
05:01:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:01:44 DISPATCHER: Finished worker discovery
05:02:44 DISPATCHER: Starting worker discovery
05:02:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:02:44 DISPATCHER: Finished worker discovery
05:03:44 DISPATCHER: Starting worker discovery
05:03:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:03:44 DISPATCHER: Finished worker discovery
05:04:44 DISPATCHER: Starting worker discovery
05:04:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:04:44 DISPATCHER: Finished worker discovery
05:05:44 DISPATCHER: Starting worker discovery
05:05:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:05:44 DISPATCHER: Finished worker discovery
05:06:44 DISPATCHER: Starting worker discovery
05:06:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:06:44 DISPATCHER: Finished worker discovery
05:07:44 DISPATCHER: Starting worker discovery
05:07:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:07:44 DISPATCHER: Finished worker discovery
05:08:44 DISPATCHER: Starting worker discovery
05:08:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:08:44 DISPATCHER: Finished worker discovery
05:09:44 DISPATCHER: Starting worker discovery
05:09:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:09:44 DISPATCHER: Finished worker discovery
05:10:44 DISPATCHER: Starting worker discovery
05:10:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:10:44 DISPATCHER: Finished worker discovery
05:11:44 DISPATCHER: Starting worker discovery
05:11:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:11:45 DISPATCHER: Finished worker discovery
05:12:45 DISPATCHER: Starting worker discovery
05:12:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:12:45 DISPATCHER: Finished worker discovery
05:13:45 DISPATCHER: Starting worker discovery
05:13:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:13:45 DISPATCHER: Finished worker discovery
05:14:45 DISPATCHER: Starting worker discovery
05:14:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:14:45 DISPATCHER: Finished worker discovery
05:15:45 DISPATCHER: Starting worker discovery
05:15:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:15:45 DISPATCHER: Finished worker discovery
05:16:45 DISPATCHER: Starting worker discovery
05:16:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:16:45 DISPATCHER: Finished worker discovery
05:17:00 WORKER: done with job (7, 0, 3), trying to register it.
05:17:00 WORKER: registered result for job (7, 0, 3) with dispatcher
05:17:00 DISPATCHER: job (7, 0, 3) finished
05:17:00 DISPATCHER: register_result: lock acquired
05:17:00 DISPATCHER: job (7, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
05:17:00 job_id: (7, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 237, 'last_n_outputs': 39, 'leak_rate': 0.8799414255013251, 'lr': 0.0022762978229832333, 'optimizer': 'Adam', 'sparsity': 0.8883485581646933, 'steps_to_train': 22, 'weight_decay': 0.14072465680286025}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.3789589393723652, 'info': {'music-speech': 0.3789589393723652, 'config': "{'batch_size': 128, 'hidden_dim': 237, 'last_n_outputs': 39, 'leak_rate': 0.8799414255013251, 'lr': 0.0022762978229832333, 'optimizer': 'Adam', 'sparsity': 0.8883485581646933, 'steps_to_train': 22, 'weight_decay': 0.14072465680286025}"}}
exception: None

05:17:00 job_callback for (7, 0, 3) started
05:17:00 job_callback for (7, 0, 3) got condition
05:17:00 DISPATCHER: Trying to submit another job.
05:17:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:17:00 HBMASTER: Trying to run another job!
05:17:00 job_callback for (7, 0, 3) finished
05:17:00 start sampling a new configuration.
05:17:00 best_vector: [3, 0.7331003631700206, 0.22193110039102176, 0.7102889235464751, 0.01694878645674347, 1, 0.23609864336580952, 0.03309944826737937, 0.8118516570586708], 1.0615907307174166e-31, 0.09419826031489613, -0.005861546838614868
05:17:00 done sampling a new configuration.
05:17:00 HBMASTER: schedule new run for iteration 8
05:17:00 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
05:17:00 HBMASTER: submitting job (8, 0, 0) to dispatcher
05:17:00 DISPATCHER: trying to submit job (8, 0, 0)
05:17:00 DISPATCHER: trying to notify the job_runner thread.
05:17:00 HBMASTER: job (8, 0, 0) submitted to dispatcher
05:17:00 DISPATCHER: Trying to submit another job.
05:17:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:17:00 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
05:17:00 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
05:17:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:17:00 WORKER: start processing job (8, 0, 0)
05:17:00 WORKER: args: ()
05:17:00 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 787, 'last_n_outputs': 19, 'leak_rate': 0.9275722308866188, 'lr': 0.0010811789283299766, 'optimizer': 'SGD', 'sparsity': 0.8066636744077943, 'steps_to_train': 13, 'weight_decay': 0.11382649363990623}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:17:45 DISPATCHER: Starting worker discovery
05:17:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:17:45 DISPATCHER: Finished worker discovery
05:17:53 WORKER: done with job (8, 0, 0), trying to register it.
05:17:53 WORKER: registered result for job (8, 0, 0) with dispatcher
05:17:53 DISPATCHER: job (8, 0, 0) finished
05:17:53 DISPATCHER: register_result: lock acquired
05:17:53 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
05:17:53 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 787, 'last_n_outputs': 19, 'leak_rate': 0.9275722308866188, 'lr': 0.0010811789283299766, 'optimizer': 'SGD', 'sparsity': 0.8066636744077943, 'steps_to_train': 13, 'weight_decay': 0.11382649363990623}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.521779554387679, 'info': {'music-speech': 0.521779554387679, 'config': "{'batch_size': 128, 'hidden_dim': 787, 'last_n_outputs': 19, 'leak_rate': 0.9275722308866188, 'lr': 0.0010811789283299766, 'optimizer': 'SGD', 'sparsity': 0.8066636744077943, 'steps_to_train': 13, 'weight_decay': 0.11382649363990623}"}}
exception: None

05:17:53 job_callback for (8, 0, 0) started
05:17:53 DISPATCHER: Trying to submit another job.
05:17:53 job_callback for (8, 0, 0) got condition
05:17:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:17:53 HBMASTER: Trying to run another job!
05:17:53 job_callback for (8, 0, 0) finished
05:17:53 start sampling a new configuration.
05:17:53 done sampling a new configuration.
05:17:53 HBMASTER: schedule new run for iteration 8
05:17:53 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
05:17:53 HBMASTER: submitting job (8, 0, 1) to dispatcher
05:17:53 DISPATCHER: trying to submit job (8, 0, 1)
05:17:53 DISPATCHER: trying to notify the job_runner thread.
05:17:53 HBMASTER: job (8, 0, 1) submitted to dispatcher
05:17:53 DISPATCHER: Trying to submit another job.
05:17:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:17:53 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
05:17:53 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
05:17:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:17:53 WORKER: start processing job (8, 0, 1)
05:17:53 WORKER: args: ()
05:17:53 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 563, 'last_n_outputs': 11, 'leak_rate': 0.8704065932693104, 'lr': 0.0034382458441668314, 'optimizer': 'SGD', 'sparsity': 0.751929916772443, 'steps_to_train': 99, 'weight_decay': 0.03528523187597693}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:18:45 DISPATCHER: Starting worker discovery
05:18:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:18:45 DISPATCHER: Finished worker discovery
05:18:55 WORKER: done with job (8, 0, 1), trying to register it.
05:18:55 DISPATCHER: job (8, 0, 1) finished
05:18:55 WORKER: registered result for job (8, 0, 1) with dispatcher
05:18:55 DISPATCHER: register_result: lock acquired
05:18:55 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
05:18:55 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 563, 'last_n_outputs': 11, 'leak_rate': 0.8704065932693104, 'lr': 0.0034382458441668314, 'optimizer': 'SGD', 'sparsity': 0.751929916772443, 'steps_to_train': 99, 'weight_decay': 0.03528523187597693}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5153082278833891, 'info': {'music-speech': 0.5153082278833891, 'config': "{'batch_size': 16, 'hidden_dim': 563, 'last_n_outputs': 11, 'leak_rate': 0.8704065932693104, 'lr': 0.0034382458441668314, 'optimizer': 'SGD', 'sparsity': 0.751929916772443, 'steps_to_train': 99, 'weight_decay': 0.03528523187597693}"}}
exception: None

05:18:55 job_callback for (8, 0, 1) started
05:18:55 DISPATCHER: Trying to submit another job.
05:18:55 job_callback for (8, 0, 1) got condition
05:18:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:18:55 HBMASTER: Trying to run another job!
05:18:55 job_callback for (8, 0, 1) finished
05:18:55 start sampling a new configuration.
05:18:55 best_vector: [3, 0.4798333229569122, 0.8285034239060161, 0.5131532434886896, 0.2821514417608222, 1, 0.3230839372667746, 0.30997844432650934, 0.31147485351587106], 6.18503660725752e-32, 0.16168053052856637, -0.002670904871028923
05:18:55 done sampling a new configuration.
05:18:55 HBMASTER: schedule new run for iteration 8
05:18:55 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
05:18:55 HBMASTER: submitting job (8, 0, 2) to dispatcher
05:18:55 DISPATCHER: trying to submit job (8, 0, 2)
05:18:55 DISPATCHER: trying to notify the job_runner thread.
05:18:55 HBMASTER: job (8, 0, 2) submitted to dispatcher
05:18:55 DISPATCHER: Trying to submit another job.
05:18:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:18:55 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
05:18:55 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
05:18:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:18:55 WORKER: start processing job (8, 0, 2)
05:18:55 WORKER: args: ()
05:18:55 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 584, 'last_n_outputs': 43, 'leak_rate': 0.8782883108721724, 'lr': 0.0036669322287505276, 'optimizer': 'SGD', 'sparsity': 0.827540144944026, 'steps_to_train': 38, 'weight_decay': 0.025423663242986092}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:19:45 DISPATCHER: Starting worker discovery
05:19:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:19:45 DISPATCHER: Finished worker discovery
05:19:59 WORKER: done with job (8, 0, 2), trying to register it.
05:19:59 WORKER: registered result for job (8, 0, 2) with dispatcher
05:19:59 DISPATCHER: job (8, 0, 2) finished
05:19:59 DISPATCHER: register_result: lock acquired
05:19:59 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
05:19:59 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 584, 'last_n_outputs': 43, 'leak_rate': 0.8782883108721724, 'lr': 0.0036669322287505276, 'optimizer': 'SGD', 'sparsity': 0.827540144944026, 'steps_to_train': 38, 'weight_decay': 0.025423663242986092}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.42334569617808504, 'info': {'music-speech': 0.42334569617808504, 'config': "{'batch_size': 128, 'hidden_dim': 584, 'last_n_outputs': 43, 'leak_rate': 0.8782883108721724, 'lr': 0.0036669322287505276, 'optimizer': 'SGD', 'sparsity': 0.827540144944026, 'steps_to_train': 38, 'weight_decay': 0.025423663242986092}"}}
exception: None

05:19:59 job_callback for (8, 0, 2) started
05:19:59 DISPATCHER: Trying to submit another job.
05:19:59 job_callback for (8, 0, 2) got condition
05:19:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:19:59 HBMASTER: Trying to run another job!
05:19:59 job_callback for (8, 0, 2) finished
05:19:59 start sampling a new configuration.
05:19:59 best_vector: [3, 0.46766948558909216, 0.540197436675329, 0.9015954557204008, 0.49906056546800254, 0, 0.31092615361112597, 0.6422087596849795, 0.8171212682869977], 1.2897854442279069e-31, 0.07753227519160145, -0.001663069285552047
05:19:59 done sampling a new configuration.
05:19:59 HBMASTER: schedule new run for iteration 8
05:19:59 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
05:19:59 HBMASTER: submitting job (8, 0, 3) to dispatcher
05:19:59 DISPATCHER: trying to submit job (8, 0, 3)
05:19:59 DISPATCHER: trying to notify the job_runner thread.
05:19:59 HBMASTER: job (8, 0, 3) submitted to dispatcher
05:19:59 DISPATCHER: Trying to submit another job.
05:19:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:19:59 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
05:19:59 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
05:19:59 WORKER: start processing job (8, 0, 3)
05:19:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:19:59 WORKER: args: ()
05:19:59 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 574, 'last_n_outputs': 32, 'leak_rate': 0.9753988639301002, 'lr': 0.00995683088865804, 'optimizer': 'Adam', 'sparsity': 0.8246222768666702, 'steps_to_train': 68, 'weight_decay': 0.11563765607735006}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:20:45 DISPATCHER: Starting worker discovery
05:20:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:20:45 DISPATCHER: Finished worker discovery
05:21:09 WORKER: done with job (8, 0, 3), trying to register it.
05:21:09 WORKER: registered result for job (8, 0, 3) with dispatcher
05:21:09 DISPATCHER: job (8, 0, 3) finished
05:21:09 DISPATCHER: register_result: lock acquired
05:21:09 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
05:21:09 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 574, 'last_n_outputs': 32, 'leak_rate': 0.9753988639301002, 'lr': 0.00995683088865804, 'optimizer': 'Adam', 'sparsity': 0.8246222768666702, 'steps_to_train': 68, 'weight_decay': 0.11563765607735006}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4691967805280704, 'info': {'music-speech': 0.4691967805280704, 'config': "{'batch_size': 128, 'hidden_dim': 574, 'last_n_outputs': 32, 'leak_rate': 0.9753988639301002, 'lr': 0.00995683088865804, 'optimizer': 'Adam', 'sparsity': 0.8246222768666702, 'steps_to_train': 68, 'weight_decay': 0.11563765607735006}"}}
exception: None

05:21:09 job_callback for (8, 0, 3) started
05:21:09 DISPATCHER: Trying to submit another job.
05:21:09 job_callback for (8, 0, 3) got condition
05:21:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:21:09 HBMASTER: Trying to run another job!
05:21:09 job_callback for (8, 0, 3) finished
05:21:09 start sampling a new configuration.
05:21:09 done sampling a new configuration.
05:21:09 HBMASTER: schedule new run for iteration 8
05:21:09 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
05:21:09 HBMASTER: submitting job (8, 0, 4) to dispatcher
05:21:09 DISPATCHER: trying to submit job (8, 0, 4)
05:21:09 DISPATCHER: trying to notify the job_runner thread.
05:21:09 HBMASTER: job (8, 0, 4) submitted to dispatcher
05:21:09 DISPATCHER: Trying to submit another job.
05:21:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:21:09 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
05:21:09 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
05:21:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:21:09 WORKER: start processing job (8, 0, 4)
05:21:09 WORKER: args: ()
05:21:09 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 464, 'last_n_outputs': 45, 'leak_rate': 0.8035710732011853, 'lr': 0.00147267201495795, 'optimizer': 'SGD', 'sparsity': 0.9596897700409338, 'steps_to_train': 27, 'weight_decay': 0.011628016007379595}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:21:45 DISPATCHER: Starting worker discovery
05:21:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:21:45 DISPATCHER: Finished worker discovery
05:22:03 WORKER: done with job (8, 0, 4), trying to register it.
05:22:03 WORKER: registered result for job (8, 0, 4) with dispatcher
05:22:03 DISPATCHER: job (8, 0, 4) finished
05:22:03 DISPATCHER: register_result: lock acquired
05:22:03 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
05:22:03 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 464, 'last_n_outputs': 45, 'leak_rate': 0.8035710732011853, 'lr': 0.00147267201495795, 'optimizer': 'SGD', 'sparsity': 0.9596897700409338, 'steps_to_train': 27, 'weight_decay': 0.011628016007379595}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6034893989322729, 'info': {'music-speech': 0.6034893989322729, 'config': "{'batch_size': 32, 'hidden_dim': 464, 'last_n_outputs': 45, 'leak_rate': 0.8035710732011853, 'lr': 0.00147267201495795, 'optimizer': 'SGD', 'sparsity': 0.9596897700409338, 'steps_to_train': 27, 'weight_decay': 0.011628016007379595}"}}
exception: None

05:22:03 job_callback for (8, 0, 4) started
05:22:03 DISPATCHER: Trying to submit another job.
05:22:03 job_callback for (8, 0, 4) got condition
05:22:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:22:03 HBMASTER: Trying to run another job!
05:22:03 job_callback for (8, 0, 4) finished
05:22:03 start sampling a new configuration.
05:22:04 best_vector: [3, 0.5608571984716711, 0.34169970186413956, 0.5951588749274512, 0.2402653522990367, 0, 0.1854384388963385, 0.44997283333922905, 0.8574370098045465], 3.2686103793263395e-32, 0.3059404101280802, -0.0036408998932566106
05:22:04 done sampling a new configuration.
05:22:04 HBMASTER: schedule new run for iteration 8
05:22:04 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
05:22:04 HBMASTER: submitting job (8, 0, 5) to dispatcher
05:22:04 DISPATCHER: trying to submit job (8, 0, 5)
05:22:04 DISPATCHER: trying to notify the job_runner thread.
05:22:04 HBMASTER: job (8, 0, 5) submitted to dispatcher
05:22:04 DISPATCHER: Trying to submit another job.
05:22:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:22:04 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
05:22:04 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
05:22:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:22:04 WORKER: start processing job (8, 0, 5)
05:22:04 WORKER: args: ()
05:22:04 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 649, 'last_n_outputs': 24, 'leak_rate': 0.8987897187318628, 'lr': 0.003023644334457388, 'optimizer': 'Adam', 'sparsity': 0.7945052253351212, 'steps_to_train': 50, 'weight_decay': 0.13048219958414764}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:22:45 DISPATCHER: Starting worker discovery
05:22:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:22:45 DISPATCHER: Finished worker discovery
05:22:57 WORKER: done with job (8, 0, 5), trying to register it.
05:22:57 WORKER: registered result for job (8, 0, 5) with dispatcher
05:22:57 DISPATCHER: job (8, 0, 5) finished
05:22:57 DISPATCHER: register_result: lock acquired
05:22:57 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
05:22:57 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 649, 'last_n_outputs': 24, 'leak_rate': 0.8987897187318628, 'lr': 0.003023644334457388, 'optimizer': 'Adam', 'sparsity': 0.7945052253351212, 'steps_to_train': 50, 'weight_decay': 0.13048219958414764}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5847416521131502, 'info': {'music-speech': 0.5847416521131502, 'config': "{'batch_size': 128, 'hidden_dim': 649, 'last_n_outputs': 24, 'leak_rate': 0.8987897187318628, 'lr': 0.003023644334457388, 'optimizer': 'Adam', 'sparsity': 0.7945052253351212, 'steps_to_train': 50, 'weight_decay': 0.13048219958414764}"}}
exception: None

05:22:57 job_callback for (8, 0, 5) started
05:22:57 job_callback for (8, 0, 5) got condition
05:22:57 DISPATCHER: Trying to submit another job.
05:22:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:22:57 HBMASTER: Trying to run another job!
05:22:57 job_callback for (8, 0, 5) finished
05:22:57 start sampling a new configuration.
05:22:57 best_vector: [3, 0.3672356850214329, 0.8578495906857858, 0.8174396635340505, 0.6361182038378042, 0, 0.19221239085708222, 0.0890027153486776, 0.7627305197708096], 4.435261159726835e-31, 0.022546586638014107, -9.517643564385255e-05
05:22:57 done sampling a new configuration.
05:22:57 HBMASTER: schedule new run for iteration 8
05:22:57 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
05:22:57 HBMASTER: submitting job (8, 0, 6) to dispatcher
05:22:57 DISPATCHER: trying to submit job (8, 0, 6)
05:22:57 DISPATCHER: trying to notify the job_runner thread.
05:22:57 HBMASTER: job (8, 0, 6) submitted to dispatcher
05:22:57 DISPATCHER: Trying to submit another job.
05:22:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:22:57 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216
05:22:57 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
05:22:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:22:57 WORKER: start processing job (8, 0, 6)
05:22:57 WORKER: args: ()
05:22:57 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 494, 'last_n_outputs': 45, 'leak_rate': 0.9543599158835127, 'lr': 0.01871700721131321, 'optimizer': 'Adam', 'sparsity': 0.7961309738056997, 'steps_to_train': 18, 'weight_decay': 0.0982506166529984}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:23:45 DISPATCHER: Starting worker discovery
05:23:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:23:45 DISPATCHER: Finished worker discovery
05:23:56 WORKER: done with job (8, 0, 6), trying to register it.
05:23:56 WORKER: registered result for job (8, 0, 6) with dispatcher
05:23:56 DISPATCHER: job (8, 0, 6) finished
05:23:56 DISPATCHER: register_result: lock acquired
05:23:56 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
05:23:56 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 494, 'last_n_outputs': 45, 'leak_rate': 0.9543599158835127, 'lr': 0.01871700721131321, 'optimizer': 'Adam', 'sparsity': 0.7961309738056997, 'steps_to_train': 18, 'weight_decay': 0.0982506166529984}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.673080860110346, 'info': {'music-speech': 0.673080860110346, 'config': "{'batch_size': 128, 'hidden_dim': 494, 'last_n_outputs': 45, 'leak_rate': 0.9543599158835127, 'lr': 0.01871700721131321, 'optimizer': 'Adam', 'sparsity': 0.7961309738056997, 'steps_to_train': 18, 'weight_decay': 0.0982506166529984}"}}
exception: None

05:23:56 job_callback for (8, 0, 6) started
05:23:56 job_callback for (8, 0, 6) got condition
05:23:56 DISPATCHER: Trying to submit another job.
05:23:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:23:56 HBMASTER: Trying to run another job!
05:23:56 job_callback for (8, 0, 6) finished
05:23:56 start sampling a new configuration.
05:23:56 best_vector: [0, 0.0004522856258297736, 0.7033360278051304, 0.6863982756053306, 0.6371940875298616, 1, 0.25613306387505685, 0.64121149827773, 0.29317193723516843], 5.720400203963983e-32, 0.17481294391029575, -0.02089799646813163
05:23:56 done sampling a new configuration.
05:23:56 HBMASTER: schedule new run for iteration 8
05:23:56 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
05:23:56 HBMASTER: submitting job (8, 0, 7) to dispatcher
05:23:56 DISPATCHER: trying to submit job (8, 0, 7)
05:23:56 DISPATCHER: trying to notify the job_runner thread.
05:23:56 HBMASTER: job (8, 0, 7) submitted to dispatcher
05:23:56 DISPATCHER: Trying to submit another job.
05:23:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:23:56 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
05:23:56 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
05:23:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:23:56 WORKER: start processing job (8, 0, 7)
05:23:56 WORKER: args: ()
05:23:56 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 200, 'last_n_outputs': 38, 'leak_rate': 0.9215995689013327, 'lr': 0.01880997312556024, 'optimizer': 'SGD', 'sparsity': 0.8114719353300136, 'steps_to_train': 68, 'weight_decay': 0.02406719541326957}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:24:45 DISPATCHER: Starting worker discovery
05:24:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:24:45 DISPATCHER: Finished worker discovery
05:25:00 WORKER: done with job (8, 0, 7), trying to register it.
05:25:00 DISPATCHER: job (8, 0, 7) finished
05:25:00 WORKER: registered result for job (8, 0, 7) with dispatcher
05:25:00 DISPATCHER: register_result: lock acquired
05:25:00 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
05:25:00 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 200, 'last_n_outputs': 38, 'leak_rate': 0.9215995689013327, 'lr': 0.01880997312556024, 'optimizer': 'SGD', 'sparsity': 0.8114719353300136, 'steps_to_train': 68, 'weight_decay': 0.02406719541326957}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.49278891580039996, 'info': {'music-speech': 0.49278891580039996, 'config': "{'batch_size': 16, 'hidden_dim': 200, 'last_n_outputs': 38, 'leak_rate': 0.9215995689013327, 'lr': 0.01880997312556024, 'optimizer': 'SGD', 'sparsity': 0.8114719353300136, 'steps_to_train': 68, 'weight_decay': 0.02406719541326957}"}}
exception: None

05:25:00 job_callback for (8, 0, 7) started
05:25:00 DISPATCHER: Trying to submit another job.
05:25:00 job_callback for (8, 0, 7) got condition
05:25:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:25:00 HBMASTER: Trying to run another job!
05:25:00 job_callback for (8, 0, 7) finished
05:25:00 start sampling a new configuration.
05:25:00 done sampling a new configuration.
05:25:00 HBMASTER: schedule new run for iteration 8
05:25:00 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
05:25:00 HBMASTER: submitting job (8, 0, 8) to dispatcher
05:25:00 DISPATCHER: trying to submit job (8, 0, 8)
05:25:00 DISPATCHER: trying to notify the job_runner thread.
05:25:00 HBMASTER: job (8, 0, 8) submitted to dispatcher
05:25:00 DISPATCHER: Trying to submit another job.
05:25:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:25:00 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216
05:25:00 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
05:25:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:25:00 WORKER: start processing job (8, 0, 8)
05:25:00 WORKER: args: ()
05:25:00 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 843, 'last_n_outputs': 32, 'leak_rate': 0.9464204737347539, 'lr': 0.009734716373205547, 'optimizer': 'SGD', 'sparsity': 0.7508157699184114, 'steps_to_train': 99, 'weight_decay': 0.026664441718938565}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:25:45 DISPATCHER: Starting worker discovery
05:25:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:25:45 DISPATCHER: Finished worker discovery
05:26:04 WORKER: done with job (8, 0, 8), trying to register it.
05:26:04 WORKER: registered result for job (8, 0, 8) with dispatcher
05:26:04 DISPATCHER: job (8, 0, 8) finished
05:26:04 DISPATCHER: register_result: lock acquired
05:26:04 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
05:26:04 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 843, 'last_n_outputs': 32, 'leak_rate': 0.9464204737347539, 'lr': 0.009734716373205547, 'optimizer': 'SGD', 'sparsity': 0.7508157699184114, 'steps_to_train': 99, 'weight_decay': 0.026664441718938565}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5764227284947062, 'info': {'music-speech': 0.5764227284947062, 'config': "{'batch_size': 16, 'hidden_dim': 843, 'last_n_outputs': 32, 'leak_rate': 0.9464204737347539, 'lr': 0.009734716373205547, 'optimizer': 'SGD', 'sparsity': 0.7508157699184114, 'steps_to_train': 99, 'weight_decay': 0.026664441718938565}"}}
exception: None

05:26:04 job_callback for (8, 0, 8) started
05:26:04 job_callback for (8, 0, 8) got condition
05:26:04 DISPATCHER: Trying to submit another job.
05:26:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:26:04 HBMASTER: Trying to run another job!
05:26:04 job_callback for (8, 0, 8) finished
05:26:04 start sampling a new configuration.
05:26:04 best_vector: [0, 0.3187942111746945, 0.9456117443605135, 0.6832551886182299, 0.7542618771939087, 0, 0.0017106093710911596, 0.21173364586538426, 0.26965715311185534], 6.800895286900142e-31, 0.014703946433731985, -0.0029445512893515606
05:26:04 done sampling a new configuration.
05:26:04 HBMASTER: schedule new run for iteration 8
05:26:04 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
05:26:04 HBMASTER: submitting job (8, 0, 9) to dispatcher
05:26:04 DISPATCHER: trying to submit job (8, 0, 9)
05:26:04 DISPATCHER: trying to notify the job_runner thread.
05:26:04 HBMASTER: job (8, 0, 9) submitted to dispatcher
05:26:04 DISPATCHER: Trying to submit another job.
05:26:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:26:04 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpul.22021139727314577216
05:26:04 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
05:26:04 WORKER: start processing job (8, 0, 9)
05:26:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:26:04 WORKER: args: ()
05:26:04 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 455, 'last_n_outputs': 48, 'leak_rate': 0.9208137971545575, 'lr': 0.032249557082799855, 'optimizer': 'Adam', 'sparsity': 0.7504105462490619, 'steps_to_train': 29, 'weight_decay': 0.02243014312255884}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:26:45 DISPATCHER: Starting worker discovery
05:26:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:26:45 DISPATCHER: Finished worker discovery
05:27:02 WORKER: done with job (8, 0, 9), trying to register it.
05:27:02 DISPATCHER: job (8, 0, 9) finished
05:27:02 WORKER: registered result for job (8, 0, 9) with dispatcher
05:27:02 DISPATCHER: register_result: lock acquired
05:27:02 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
05:27:02 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 455, 'last_n_outputs': 48, 'leak_rate': 0.9208137971545575, 'lr': 0.032249557082799855, 'optimizer': 'Adam', 'sparsity': 0.7504105462490619, 'steps_to_train': 29, 'weight_decay': 0.02243014312255884}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.15837295266738902, 'info': {'music-speech': 0.15837295266738902, 'config': "{'batch_size': 16, 'hidden_dim': 455, 'last_n_outputs': 48, 'leak_rate': 0.9208137971545575, 'lr': 0.032249557082799855, 'optimizer': 'Adam', 'sparsity': 0.7504105462490619, 'steps_to_train': 29, 'weight_decay': 0.02243014312255884}"}}
exception: None

05:27:02 job_callback for (8, 0, 9) started
05:27:02 DISPATCHER: Trying to submit another job.
05:27:02 job_callback for (8, 0, 9) got condition
05:27:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:27:02 HBMASTER: Trying to run another job!
05:27:02 job_callback for (8, 0, 9) finished
05:27:02 start sampling a new configuration.
05:27:02 done sampling a new configuration.
05:27:02 HBMASTER: schedule new run for iteration 8
05:27:02 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
05:27:02 HBMASTER: submitting job (8, 0, 10) to dispatcher
05:27:02 DISPATCHER: trying to submit job (8, 0, 10)
05:27:02 DISPATCHER: trying to notify the job_runner thread.
05:27:02 HBMASTER: job (8, 0, 10) submitted to dispatcher
05:27:02 DISPATCHER: Trying to submit another job.
05:27:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:27:02 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpul.22021139727314577216
05:27:02 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
05:27:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:27:02 WORKER: start processing job (8, 0, 10)
05:27:02 WORKER: args: ()
05:27:02 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 885, 'last_n_outputs': 37, 'leak_rate': 0.8204795113158945, 'lr': 0.015604941107335662, 'optimizer': 'Adam', 'sparsity': 0.9448314492696279, 'steps_to_train': 10, 'weight_decay': 0.029073129183563893}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:27:45 DISPATCHER: Starting worker discovery
05:27:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:27:45 DISPATCHER: Finished worker discovery
05:27:58 WORKER: done with job (8, 0, 10), trying to register it.
05:27:58 WORKER: registered result for job (8, 0, 10) with dispatcher
05:27:58 DISPATCHER: job (8, 0, 10) finished
05:27:58 DISPATCHER: register_result: lock acquired
05:27:58 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
05:27:58 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 885, 'last_n_outputs': 37, 'leak_rate': 0.8204795113158945, 'lr': 0.015604941107335662, 'optimizer': 'Adam', 'sparsity': 0.9448314492696279, 'steps_to_train': 10, 'weight_decay': 0.029073129183563893}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5545223059426654, 'info': {'music-speech': 0.5545223059426654, 'config': "{'batch_size': 64, 'hidden_dim': 885, 'last_n_outputs': 37, 'leak_rate': 0.8204795113158945, 'lr': 0.015604941107335662, 'optimizer': 'Adam', 'sparsity': 0.9448314492696279, 'steps_to_train': 10, 'weight_decay': 0.029073129183563893}"}}
exception: None

05:27:58 job_callback for (8, 0, 10) started
05:27:58 DISPATCHER: Trying to submit another job.
05:27:58 job_callback for (8, 0, 10) got condition
05:27:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:27:58 HBMASTER: Trying to run another job!
05:27:58 job_callback for (8, 0, 10) finished
05:27:58 start sampling a new configuration.
05:27:58 best_vector: [3, 0.36028092102992426, 0.42697176952313876, 0.7461941180196302, 0.2190181383561338, 0, 0.40897166823474196, 0.13115589436363428, 0.6470419496435038], 7.853292164967804e-32, 0.12733513270534227, -0.010393248527200683
05:27:58 done sampling a new configuration.
05:27:58 HBMASTER: schedule new run for iteration 8
05:27:58 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
05:27:58 HBMASTER: submitting job (8, 0, 11) to dispatcher
05:27:58 DISPATCHER: trying to submit job (8, 0, 11)
05:27:58 DISPATCHER: trying to notify the job_runner thread.
05:27:58 HBMASTER: job (8, 0, 11) submitted to dispatcher
05:27:58 DISPATCHER: Trying to submit another job.
05:27:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:27:58 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpul.22021139727314577216
05:27:58 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
05:27:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:27:58 WORKER: start processing job (8, 0, 11)
05:27:58 WORKER: args: ()
05:27:58 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 488, 'last_n_outputs': 27, 'leak_rate': 0.9365485295049075, 'lr': 0.002741803185777741, 'optimizer': 'Adam', 'sparsity': 0.8481532003763381, 'steps_to_train': 21, 'weight_decay': 0.06947378894012848}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:28:45 DISPATCHER: Starting worker discovery
05:28:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:28:45 DISPATCHER: Finished worker discovery
05:28:56 WORKER: done with job (8, 0, 11), trying to register it.
05:28:56 WORKER: registered result for job (8, 0, 11) with dispatcher
05:28:56 DISPATCHER: job (8, 0, 11) finished
05:28:56 DISPATCHER: register_result: lock acquired
05:28:56 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
05:28:56 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 488, 'last_n_outputs': 27, 'leak_rate': 0.9365485295049075, 'lr': 0.002741803185777741, 'optimizer': 'Adam', 'sparsity': 0.8481532003763381, 'steps_to_train': 21, 'weight_decay': 0.06947378894012848}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3484559263769447, 'info': {'music-speech': 0.3484559263769447, 'config': "{'batch_size': 128, 'hidden_dim': 488, 'last_n_outputs': 27, 'leak_rate': 0.9365485295049075, 'lr': 0.002741803185777741, 'optimizer': 'Adam', 'sparsity': 0.8481532003763381, 'steps_to_train': 21, 'weight_decay': 0.06947378894012848}"}}
exception: None

05:28:56 job_callback for (8, 0, 11) started
05:28:56 DISPATCHER: Trying to submit another job.
05:28:56 job_callback for (8, 0, 11) got condition
05:28:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:28:56 HBMASTER: Trying to run another job!
05:28:56 job_callback for (8, 0, 11) finished
05:28:56 start sampling a new configuration.
05:28:56 done sampling a new configuration.
05:28:56 HBMASTER: schedule new run for iteration 8
05:28:56 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
05:28:56 HBMASTER: submitting job (8, 0, 12) to dispatcher
05:28:56 DISPATCHER: trying to submit job (8, 0, 12)
05:28:56 DISPATCHER: trying to notify the job_runner thread.
05:28:56 HBMASTER: job (8, 0, 12) submitted to dispatcher
05:28:56 DISPATCHER: Trying to submit another job.
05:28:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:28:56 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216
05:28:56 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
05:28:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:28:56 WORKER: start processing job (8, 0, 12)
05:28:56 WORKER: args: ()
05:28:56 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 759, 'last_n_outputs': 13, 'leak_rate': 0.9298097999999914, 'lr': 0.007453474501920732, 'optimizer': 'SGD', 'sparsity': 0.7639708648790227, 'steps_to_train': 70, 'weight_decay': 0.025369808264375272}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:29:45 DISPATCHER: Starting worker discovery
05:29:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:29:45 DISPATCHER: Finished worker discovery
05:30:08 WORKER: done with job (8, 0, 12), trying to register it.
05:30:08 WORKER: registered result for job (8, 0, 12) with dispatcher
05:30:08 DISPATCHER: job (8, 0, 12) finished
05:30:08 DISPATCHER: register_result: lock acquired
05:30:08 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
05:30:08 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 759, 'last_n_outputs': 13, 'leak_rate': 0.9298097999999914, 'lr': 0.007453474501920732, 'optimizer': 'SGD', 'sparsity': 0.7639708648790227, 'steps_to_train': 70, 'weight_decay': 0.025369808264375272}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4356942893290802, 'info': {'music-speech': 0.4356942893290802, 'config': "{'batch_size': 16, 'hidden_dim': 759, 'last_n_outputs': 13, 'leak_rate': 0.9298097999999914, 'lr': 0.007453474501920732, 'optimizer': 'SGD', 'sparsity': 0.7639708648790227, 'steps_to_train': 70, 'weight_decay': 0.025369808264375272}"}}
exception: None

05:30:08 job_callback for (8, 0, 12) started
05:30:08 DISPATCHER: Trying to submit another job.
05:30:08 job_callback for (8, 0, 12) got condition
05:30:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:30:08 HBMASTER: Trying to run another job!
05:30:08 job_callback for (8, 0, 12) finished
05:30:08 start sampling a new configuration.
05:30:08 done sampling a new configuration.
05:30:08 HBMASTER: schedule new run for iteration 8
05:30:08 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
05:30:08 HBMASTER: submitting job (8, 0, 13) to dispatcher
05:30:08 DISPATCHER: trying to submit job (8, 0, 13)
05:30:08 DISPATCHER: trying to notify the job_runner thread.
05:30:08 HBMASTER: job (8, 0, 13) submitted to dispatcher
05:30:08 DISPATCHER: Trying to submit another job.
05:30:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:30:08 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpul.22021139727314577216
05:30:08 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
05:30:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:30:08 WORKER: start processing job (8, 0, 13)
05:30:08 WORKER: args: ()
05:30:08 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 390, 'last_n_outputs': 23, 'leak_rate': 0.9179706709208394, 'lr': 0.07853971387565385, 'optimizer': 'Adam', 'sparsity': 0.7549604458620452, 'steps_to_train': 22, 'weight_decay': 0.0390641217177802}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:30:45 DISPATCHER: Starting worker discovery
05:30:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:30:45 DISPATCHER: Finished worker discovery
05:31:14 WORKER: done with job (8, 0, 13), trying to register it.
05:31:14 DISPATCHER: job (8, 0, 13) finished
05:31:14 WORKER: registered result for job (8, 0, 13) with dispatcher
05:31:14 DISPATCHER: register_result: lock acquired
05:31:14 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
05:31:14 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 390, 'last_n_outputs': 23, 'leak_rate': 0.9179706709208394, 'lr': 0.07853971387565385, 'optimizer': 'Adam', 'sparsity': 0.7549604458620452, 'steps_to_train': 22, 'weight_decay': 0.0390641217177802}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.30979339147550977, 'info': {'music-speech': 0.30979339147550977, 'config': "{'batch_size': 128, 'hidden_dim': 390, 'last_n_outputs': 23, 'leak_rate': 0.9179706709208394, 'lr': 0.07853971387565385, 'optimizer': 'Adam', 'sparsity': 0.7549604458620452, 'steps_to_train': 22, 'weight_decay': 0.0390641217177802}"}}
exception: None

05:31:14 job_callback for (8, 0, 13) started
05:31:14 DISPATCHER: Trying to submit another job.
05:31:14 job_callback for (8, 0, 13) got condition
05:31:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:31:15 HBMASTER: Trying to run another job!
05:31:15 job_callback for (8, 0, 13) finished
05:31:15 start sampling a new configuration.
05:31:15 best_vector: [0, 0.11835696830550851, 0.7252266495301551, 0.8477697421442525, 0.762741194266525, 0, 0.3020136623969631, 0.8863946203935369, 0.6997001353813852], 1.584247502734986e-31, 0.06312145029571688, -0.002380152666717176
05:31:15 done sampling a new configuration.
05:31:15 HBMASTER: schedule new run for iteration 8
05:31:15 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
05:31:15 HBMASTER: submitting job (8, 0, 14) to dispatcher
05:31:15 DISPATCHER: trying to submit job (8, 0, 14)
05:31:15 DISPATCHER: trying to notify the job_runner thread.
05:31:15 HBMASTER: job (8, 0, 14) submitted to dispatcher
05:31:15 DISPATCHER: Trying to submit another job.
05:31:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:31:15 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpul.22021139727314577216
05:31:15 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
05:31:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:31:15 WORKER: start processing job (8, 0, 14)
05:31:15 WORKER: args: ()
05:31:15 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 294, 'last_n_outputs': 39, 'leak_rate': 0.9619424355360631, 'lr': 0.03353377055933054, 'optimizer': 'Adam', 'sparsity': 0.8224832789752712, 'steps_to_train': 90, 'weight_decay': 0.08134500011429172}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:31:45 DISPATCHER: Starting worker discovery
05:31:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:31:45 DISPATCHER: Finished worker discovery
05:32:37 WORKER: done with job (8, 0, 14), trying to register it.
05:32:37 WORKER: registered result for job (8, 0, 14) with dispatcher
05:32:37 DISPATCHER: job (8, 0, 14) finished
05:32:37 DISPATCHER: register_result: lock acquired
05:32:37 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
05:32:37 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 294, 'last_n_outputs': 39, 'leak_rate': 0.9619424355360631, 'lr': 0.03353377055933054, 'optimizer': 'Adam', 'sparsity': 0.8224832789752712, 'steps_to_train': 90, 'weight_decay': 0.08134500011429172}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6504761547232265, 'info': {'music-speech': 0.6504761547232265, 'config': "{'batch_size': 16, 'hidden_dim': 294, 'last_n_outputs': 39, 'leak_rate': 0.9619424355360631, 'lr': 0.03353377055933054, 'optimizer': 'Adam', 'sparsity': 0.8224832789752712, 'steps_to_train': 90, 'weight_decay': 0.08134500011429172}"}}
exception: None

05:32:37 job_callback for (8, 0, 14) started
05:32:37 DISPATCHER: Trying to submit another job.
05:32:37 job_callback for (8, 0, 14) got condition
05:32:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:32:38 HBMASTER: Trying to run another job!
05:32:38 job_callback for (8, 0, 14) finished
05:32:38 start sampling a new configuration.
05:32:38 best_vector: [3, 0.9696282085896963, 0.5941127586119844, 0.5127594890100657, 0.1279822067303736, 1, 0.04690323847001632, 0.3418171665912811, 0.810652704589173], 6.627539646403013e-31, 0.01508855553271165, -0.021705026619896633
05:32:38 done sampling a new configuration.
05:32:38 HBMASTER: schedule new run for iteration 8
05:32:38 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
05:32:38 HBMASTER: submitting job (8, 0, 15) to dispatcher
05:32:38 DISPATCHER: trying to submit job (8, 0, 15)
05:32:38 DISPATCHER: trying to notify the job_runner thread.
05:32:38 HBMASTER: job (8, 0, 15) submitted to dispatcher
05:32:38 DISPATCHER: Trying to submit another job.
05:32:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:32:38 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216
05:32:38 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
05:32:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:32:38 WORKER: start processing job (8, 0, 15)
05:32:38 WORKER: args: ()
05:32:38 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 976, 'last_n_outputs': 34, 'leak_rate': 0.8781898722525164, 'lr': 0.0018028700057729956, 'optimizer': 'SGD', 'sparsity': 0.7612567772328039, 'steps_to_train': 41, 'weight_decay': 0.11341839173732719}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:32:45 DISPATCHER: Starting worker discovery
05:32:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:32:45 DISPATCHER: Finished worker discovery
05:33:45 WORKER: done with job (8, 0, 15), trying to register it.
05:33:45 DISPATCHER: job (8, 0, 15) finished
05:33:45 WORKER: registered result for job (8, 0, 15) with dispatcher
05:33:45 DISPATCHER: register_result: lock acquired
05:33:45 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
05:33:45 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 976, 'last_n_outputs': 34, 'leak_rate': 0.8781898722525164, 'lr': 0.0018028700057729956, 'optimizer': 'SGD', 'sparsity': 0.7612567772328039, 'steps_to_train': 41, 'weight_decay': 0.11341839173732719}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5129773831273071, 'info': {'music-speech': 0.5129773831273071, 'config': "{'batch_size': 128, 'hidden_dim': 976, 'last_n_outputs': 34, 'leak_rate': 0.8781898722525164, 'lr': 0.0018028700057729956, 'optimizer': 'SGD', 'sparsity': 0.7612567772328039, 'steps_to_train': 41, 'weight_decay': 0.11341839173732719}"}}
exception: None

05:33:45 job_callback for (8, 0, 15) started
05:33:45 job_callback for (8, 0, 15) got condition
05:33:45 DISPATCHER: Trying to submit another job.
05:33:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:33:45 HBMASTER: Trying to run another job!
05:33:45 job_callback for (8, 0, 15) finished
05:33:45 start sampling a new configuration.
05:33:45 best_vector: [3, 0.04250840046542326, 0.9817482641735127, 0.7754043508877765, 0.3473724275189495, 0, 0.6622690155680176, 0.668568162722066, 0.9702314038725475], 1.868281739598836e-31, 0.05352511769529598, -1.6308946256779886e-05
05:33:45 done sampling a new configuration.
05:33:45 HBMASTER: schedule new run for iteration 8
05:33:45 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
05:33:45 HBMASTER: submitting job (8, 0, 16) to dispatcher
05:33:45 DISPATCHER: trying to submit job (8, 0, 16)
05:33:45 DISPATCHER: trying to notify the job_runner thread.
05:33:45 HBMASTER: job (8, 0, 16) submitted to dispatcher
05:33:45 DISPATCHER: Trying to submit another job.
05:33:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:33:45 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216
05:33:45 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
05:33:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:33:45 WORKER: start processing job (8, 0, 16)
05:33:45 WORKER: args: ()
05:33:45 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 234, 'last_n_outputs': 50, 'leak_rate': 0.9438510877219441, 'lr': 0.004951592027777203, 'optimizer': 'Adam', 'sparsity': 0.9089445637363243, 'steps_to_train': 70, 'weight_decay': 0.1829364129773591}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:33:45 DISPATCHER: Starting worker discovery
05:33:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:33:45 DISPATCHER: Finished worker discovery
05:34:45 DISPATCHER: Starting worker discovery
05:34:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:34:45 DISPATCHER: Finished worker discovery
05:34:56 WORKER: done with job (8, 0, 16), trying to register it.
05:34:56 WORKER: registered result for job (8, 0, 16) with dispatcher
05:34:56 DISPATCHER: job (8, 0, 16) finished
05:34:56 DISPATCHER: register_result: lock acquired
05:34:56 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
05:34:56 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 234, 'last_n_outputs': 50, 'leak_rate': 0.9438510877219441, 'lr': 0.004951592027777203, 'optimizer': 'Adam', 'sparsity': 0.9089445637363243, 'steps_to_train': 70, 'weight_decay': 0.1829364129773591}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3296181440404939, 'info': {'music-speech': 0.3296181440404939, 'config': "{'batch_size': 128, 'hidden_dim': 234, 'last_n_outputs': 50, 'leak_rate': 0.9438510877219441, 'lr': 0.004951592027777203, 'optimizer': 'Adam', 'sparsity': 0.9089445637363243, 'steps_to_train': 70, 'weight_decay': 0.1829364129773591}"}}
exception: None

05:34:56 job_callback for (8, 0, 16) started
05:34:56 DISPATCHER: Trying to submit another job.
05:34:56 job_callback for (8, 0, 16) got condition
05:34:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:34:56 HBMASTER: Trying to run another job!
05:34:56 job_callback for (8, 0, 16) finished
05:34:56 start sampling a new configuration.
05:34:56 best_vector: [3, 0.41406792425769845, 0.8385758382361265, 0.3184155617510891, 0.5435428017575555, 1, 0.04167743172408345, 0.31691423375255623, 0.5833819190841827], 1.410986838242708e-31, 0.07087238327789327, -0.0011459428578087607
05:34:56 done sampling a new configuration.
05:34:56 HBMASTER: schedule new run for iteration 8
05:34:56 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
05:34:56 HBMASTER: submitting job (8, 0, 17) to dispatcher
05:34:56 DISPATCHER: trying to submit job (8, 0, 17)
05:34:56 DISPATCHER: trying to notify the job_runner thread.
05:34:56 HBMASTER: job (8, 0, 17) submitted to dispatcher
05:34:56 DISPATCHER: Trying to submit another job.
05:34:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:34:56 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpul.22021139727314577216
05:34:56 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
05:34:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:34:56 WORKER: start processing job (8, 0, 17)
05:34:56 WORKER: args: ()
05:34:56 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 531, 'last_n_outputs': 44, 'leak_rate': 0.8296038904377723, 'lr': 0.012220405120719917, 'optimizer': 'SGD', 'sparsity': 0.76000258361378, 'steps_to_train': 38, 'weight_decay': 0.05741129929617034}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:35:45 DISPATCHER: Starting worker discovery
05:35:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:35:45 DISPATCHER: Finished worker discovery
05:35:50 WORKER: done with job (8, 0, 17), trying to register it.
05:35:50 DISPATCHER: job (8, 0, 17) finished
05:35:50 WORKER: registered result for job (8, 0, 17) with dispatcher
05:35:50 DISPATCHER: register_result: lock acquired
05:35:50 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
05:35:50 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 531, 'last_n_outputs': 44, 'leak_rate': 0.8296038904377723, 'lr': 0.012220405120719917, 'optimizer': 'SGD', 'sparsity': 0.76000258361378, 'steps_to_train': 38, 'weight_decay': 0.05741129929617034}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.31467692160301064, 'info': {'music-speech': 0.31467692160301064, 'config': "{'batch_size': 128, 'hidden_dim': 531, 'last_n_outputs': 44, 'leak_rate': 0.8296038904377723, 'lr': 0.012220405120719917, 'optimizer': 'SGD', 'sparsity': 0.76000258361378, 'steps_to_train': 38, 'weight_decay': 0.05741129929617034}"}}
exception: None

05:35:50 DISPATCHER: Trying to submit another job.
05:35:50 job_callback for (8, 0, 17) started
05:35:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:35:50 job_callback for (8, 0, 17) got condition
05:35:50 HBMASTER: Trying to run another job!
05:35:50 job_callback for (8, 0, 17) finished
05:35:50 start sampling a new configuration.
05:35:50 done sampling a new configuration.
05:35:50 HBMASTER: schedule new run for iteration 8
05:35:50 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
05:35:50 HBMASTER: submitting job (8, 0, 18) to dispatcher
05:35:50 DISPATCHER: trying to submit job (8, 0, 18)
05:35:50 DISPATCHER: trying to notify the job_runner thread.
05:35:50 HBMASTER: job (8, 0, 18) submitted to dispatcher
05:35:50 DISPATCHER: Trying to submit another job.
05:35:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:35:50 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpul.22021139727314577216
05:35:50 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
05:35:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:35:50 WORKER: start processing job (8, 0, 18)
05:35:50 WORKER: args: ()
05:35:50 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 556, 'last_n_outputs': 32, 'leak_rate': 0.8240002504723166, 'lr': 0.0014823252717460307, 'optimizer': 'SGD', 'sparsity': 0.8035950431456826, 'steps_to_train': 39, 'weight_decay': 0.09462771137446502}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:36:44 WORKER: done with job (8, 0, 18), trying to register it.
05:36:44 WORKER: registered result for job (8, 0, 18) with dispatcher
05:36:44 DISPATCHER: job (8, 0, 18) finished
05:36:44 DISPATCHER: register_result: lock acquired
05:36:44 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
05:36:44 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 556, 'last_n_outputs': 32, 'leak_rate': 0.8240002504723166, 'lr': 0.0014823252717460307, 'optimizer': 'SGD', 'sparsity': 0.8035950431456826, 'steps_to_train': 39, 'weight_decay': 0.09462771137446502}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6720496070288764, 'info': {'music-speech': 0.6720496070288764, 'config': "{'batch_size': 64, 'hidden_dim': 556, 'last_n_outputs': 32, 'leak_rate': 0.8240002504723166, 'lr': 0.0014823252717460307, 'optimizer': 'SGD', 'sparsity': 0.8035950431456826, 'steps_to_train': 39, 'weight_decay': 0.09462771137446502}"}}
exception: None

05:36:44 job_callback for (8, 0, 18) started
05:36:44 DISPATCHER: Trying to submit another job.
05:36:44 job_callback for (8, 0, 18) got condition
05:36:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:36:44 HBMASTER: Trying to run another job!
05:36:44 job_callback for (8, 0, 18) finished
05:36:44 start sampling a new configuration.
05:36:44 best_vector: [3, 0.6169602583437721, 0.7367162104449073, 0.24964771732168012, 0.2341176636317595, 1, 0.5236794547966477, 0.4001757818407446, 0.6789508879091254], 3.876911198616261e-32, 0.25793729821743605, -0.01710207976832269
05:36:44 done sampling a new configuration.
05:36:44 HBMASTER: schedule new run for iteration 8
05:36:44 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
05:36:44 HBMASTER: submitting job (8, 0, 19) to dispatcher
05:36:44 DISPATCHER: trying to submit job (8, 0, 19)
05:36:44 DISPATCHER: trying to notify the job_runner thread.
05:36:44 HBMASTER: job (8, 0, 19) submitted to dispatcher
05:36:44 DISPATCHER: Trying to submit another job.
05:36:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:36:44 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpul.22021139727314577216
05:36:44 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
05:36:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:36:44 WORKER: start processing job (8, 0, 19)
05:36:44 WORKER: args: ()
05:36:44 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 694, 'last_n_outputs': 40, 'leak_rate': 0.8124119293304201, 'lr': 0.0029392418812279556, 'optimizer': 'SGD', 'sparsity': 0.8756830691511954, 'steps_to_train': 46, 'weight_decay': 0.07644260364344442}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:36:45 DISPATCHER: Starting worker discovery
05:36:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:36:45 DISPATCHER: Finished worker discovery
05:37:45 DISPATCHER: Starting worker discovery
05:37:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:37:45 DISPATCHER: Finished worker discovery
05:37:47 WORKER: done with job (8, 0, 19), trying to register it.
05:37:47 DISPATCHER: job (8, 0, 19) finished
05:37:47 WORKER: registered result for job (8, 0, 19) with dispatcher
05:37:47 DISPATCHER: register_result: lock acquired
05:37:47 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
05:37:47 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 694, 'last_n_outputs': 40, 'leak_rate': 0.8124119293304201, 'lr': 0.0029392418812279556, 'optimizer': 'SGD', 'sparsity': 0.8756830691511954, 'steps_to_train': 46, 'weight_decay': 0.07644260364344442}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.39568383267817936, 'info': {'music-speech': 0.39568383267817936, 'config': "{'batch_size': 128, 'hidden_dim': 694, 'last_n_outputs': 40, 'leak_rate': 0.8124119293304201, 'lr': 0.0029392418812279556, 'optimizer': 'SGD', 'sparsity': 0.8756830691511954, 'steps_to_train': 46, 'weight_decay': 0.07644260364344442}"}}
exception: None

05:37:47 job_callback for (8, 0, 19) started
05:37:47 DISPATCHER: Trying to submit another job.
05:37:47 job_callback for (8, 0, 19) got condition
05:37:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:37:47 HBMASTER: Trying to run another job!
05:37:47 job_callback for (8, 0, 19) finished
05:37:47 start sampling a new configuration.
05:37:47 done sampling a new configuration.
05:37:47 HBMASTER: schedule new run for iteration 8
05:37:47 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
05:37:47 HBMASTER: submitting job (8, 0, 20) to dispatcher
05:37:47 DISPATCHER: trying to submit job (8, 0, 20)
05:37:47 DISPATCHER: trying to notify the job_runner thread.
05:37:47 HBMASTER: job (8, 0, 20) submitted to dispatcher
05:37:47 DISPATCHER: Trying to submit another job.
05:37:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:37:47 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216
05:37:47 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
05:37:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:37:47 WORKER: start processing job (8, 0, 20)
05:37:47 WORKER: args: ()
05:37:47 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 349, 'last_n_outputs': 35, 'leak_rate': 0.9129818762080502, 'lr': 0.009391819444390553, 'optimizer': 'Adam', 'sparsity': 0.7839344578729072, 'steps_to_train': 44, 'weight_decay': 0.0393076319485415}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:38:45 DISPATCHER: Starting worker discovery
05:38:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:38:45 DISPATCHER: Finished worker discovery
05:38:45 WORKER: done with job (8, 0, 20), trying to register it.
05:38:45 WORKER: registered result for job (8, 0, 20) with dispatcher
05:38:45 DISPATCHER: job (8, 0, 20) finished
05:38:45 DISPATCHER: register_result: lock acquired
05:38:45 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
05:38:45 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 349, 'last_n_outputs': 35, 'leak_rate': 0.9129818762080502, 'lr': 0.009391819444390553, 'optimizer': 'Adam', 'sparsity': 0.7839344578729072, 'steps_to_train': 44, 'weight_decay': 0.0393076319485415}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.30878075765325486, 'info': {'music-speech': 0.30878075765325486, 'config': "{'batch_size': 32, 'hidden_dim': 349, 'last_n_outputs': 35, 'leak_rate': 0.9129818762080502, 'lr': 0.009391819444390553, 'optimizer': 'Adam', 'sparsity': 0.7839344578729072, 'steps_to_train': 44, 'weight_decay': 0.0393076319485415}"}}
exception: None

05:38:45 DISPATCHER: Trying to submit another job.
05:38:45 job_callback for (8, 0, 20) started
05:38:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:38:45 job_callback for (8, 0, 20) got condition
05:38:45 HBMASTER: Trying to run another job!
05:38:45 job_callback for (8, 0, 20) finished
05:38:45 start sampling a new configuration.
05:38:45 best_vector: [3, 0.5016502873827923, 0.44717021324702866, 0.6632458952898503, 0.13526566670536105, 1, 0.18604316167544835, 0.24963576834991508, 0.9864438382576087], 6.181022599764334e-32, 0.16178552721003275, -0.010979519091114368
05:38:45 done sampling a new configuration.
05:38:45 HBMASTER: schedule new run for iteration 8
05:38:45 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
05:38:45 HBMASTER: submitting job (8, 0, 21) to dispatcher
05:38:45 DISPATCHER: trying to submit job (8, 0, 21)
05:38:45 DISPATCHER: trying to notify the job_runner thread.
05:38:45 HBMASTER: job (8, 0, 21) submitted to dispatcher
05:38:45 DISPATCHER: Trying to submit another job.
05:38:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:38:45 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216
05:38:45 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
05:38:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:38:45 WORKER: start processing job (8, 0, 21)
05:38:45 WORKER: args: ()
05:38:45 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 601, 'last_n_outputs': 28, 'leak_rate': 0.9158114738224625, 'lr': 0.0018643666834377702, 'optimizer': 'SGD', 'sparsity': 0.7946503588021077, 'steps_to_train': 32, 'weight_decay': 0.19204058603939483}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:39:45 DISPATCHER: Starting worker discovery
05:39:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:39:45 DISPATCHER: Finished worker discovery
05:39:45 WORKER: done with job (8, 0, 21), trying to register it.
05:39:45 WORKER: registered result for job (8, 0, 21) with dispatcher
05:39:45 DISPATCHER: job (8, 0, 21) finished
05:39:45 DISPATCHER: register_result: lock acquired
05:39:45 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
05:39:45 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 601, 'last_n_outputs': 28, 'leak_rate': 0.9158114738224625, 'lr': 0.0018643666834377702, 'optimizer': 'SGD', 'sparsity': 0.7946503588021077, 'steps_to_train': 32, 'weight_decay': 0.19204058603939483}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6010472575728758, 'info': {'music-speech': 0.6010472575728758, 'config': "{'batch_size': 128, 'hidden_dim': 601, 'last_n_outputs': 28, 'leak_rate': 0.9158114738224625, 'lr': 0.0018643666834377702, 'optimizer': 'SGD', 'sparsity': 0.7946503588021077, 'steps_to_train': 32, 'weight_decay': 0.19204058603939483}"}}
exception: None

05:39:45 job_callback for (8, 0, 21) started
05:39:45 DISPATCHER: Trying to submit another job.
05:39:45 job_callback for (8, 0, 21) got condition
05:39:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:39:45 HBMASTER: Trying to run another job!
05:39:45 job_callback for (8, 0, 21) finished
05:39:45 start sampling a new configuration.
05:39:45 done sampling a new configuration.
05:39:45 HBMASTER: schedule new run for iteration 8
05:39:45 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
05:39:45 HBMASTER: submitting job (8, 0, 22) to dispatcher
05:39:45 DISPATCHER: trying to submit job (8, 0, 22)
05:39:45 DISPATCHER: trying to notify the job_runner thread.
05:39:45 HBMASTER: job (8, 0, 22) submitted to dispatcher
05:39:45 DISPATCHER: Trying to submit another job.
05:39:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:39:45 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpul.22021139727314577216
05:39:45 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
05:39:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:39:45 WORKER: start processing job (8, 0, 22)
05:39:45 WORKER: args: ()
05:39:45 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 687, 'last_n_outputs': 38, 'leak_rate': 0.8333071526047313, 'lr': 0.001158412712467143, 'optimizer': 'SGD', 'sparsity': 0.8333659969656755, 'steps_to_train': 25, 'weight_decay': 0.014822541743148872}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:40:45 WORKER: done with job (8, 0, 22), trying to register it.
05:40:45 WORKER: registered result for job (8, 0, 22) with dispatcher
05:40:45 DISPATCHER: job (8, 0, 22) finished
05:40:45 DISPATCHER: register_result: lock acquired
05:40:45 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
05:40:45 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 687, 'last_n_outputs': 38, 'leak_rate': 0.8333071526047313, 'lr': 0.001158412712467143, 'optimizer': 'SGD', 'sparsity': 0.8333659969656755, 'steps_to_train': 25, 'weight_decay': 0.014822541743148872}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5075416321631078, 'info': {'music-speech': 0.5075416321631078, 'config': "{'batch_size': 32, 'hidden_dim': 687, 'last_n_outputs': 38, 'leak_rate': 0.8333071526047313, 'lr': 0.001158412712467143, 'optimizer': 'SGD', 'sparsity': 0.8333659969656755, 'steps_to_train': 25, 'weight_decay': 0.014822541743148872}"}}
exception: None

05:40:45 job_callback for (8, 0, 22) started
05:40:45 DISPATCHER: Trying to submit another job.
05:40:45 job_callback for (8, 0, 22) got condition
05:40:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:40:45 HBMASTER: Trying to run another job!
05:40:45 job_callback for (8, 0, 22) finished
05:40:45 start sampling a new configuration.
05:40:45 best_vector: [3, 0.07997102682291818, 0.45377213222934315, 0.8175790074416847, 0.8318986654737748, 0, 0.2401442183713634, 0.2339468537986862, 0.46367036192235944], 4.8217606853205454e-32, 0.20739312157163212, -0.0002689811893642303
05:40:45 done sampling a new configuration.
05:40:45 HBMASTER: schedule new run for iteration 8
05:40:45 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
05:40:45 HBMASTER: submitting job (8, 0, 23) to dispatcher
05:40:45 DISPATCHER: trying to submit job (8, 0, 23)
05:40:45 DISPATCHER: trying to notify the job_runner thread.
05:40:45 HBMASTER: job (8, 0, 23) submitted to dispatcher
05:40:45 DISPATCHER: Trying to submit another job.
05:40:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:40:45 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216
05:40:45 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
05:40:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:40:45 WORKER: start processing job (8, 0, 23)
05:40:45 WORKER: args: ()
05:40:45 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 264, 'last_n_outputs': 28, 'leak_rate': 0.9543947518604212, 'lr': 0.046110234506119376, 'optimizer': 'Adam', 'sparsity': 0.8076346124091273, 'steps_to_train': 31, 'weight_decay': 0.040109666314800715}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:40:45 DISPATCHER: Starting worker discovery
05:40:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:40:45 DISPATCHER: Finished worker discovery
05:41:41 WORKER: done with job (8, 0, 23), trying to register it.
05:41:41 WORKER: registered result for job (8, 0, 23) with dispatcher
05:41:41 DISPATCHER: job (8, 0, 23) finished
05:41:41 DISPATCHER: register_result: lock acquired
05:41:41 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
05:41:41 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 264, 'last_n_outputs': 28, 'leak_rate': 0.9543947518604212, 'lr': 0.046110234506119376, 'optimizer': 'Adam', 'sparsity': 0.8076346124091273, 'steps_to_train': 31, 'weight_decay': 0.040109666314800715}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.591527437830755, 'info': {'music-speech': 0.591527437830755, 'config': "{'batch_size': 128, 'hidden_dim': 264, 'last_n_outputs': 28, 'leak_rate': 0.9543947518604212, 'lr': 0.046110234506119376, 'optimizer': 'Adam', 'sparsity': 0.8076346124091273, 'steps_to_train': 31, 'weight_decay': 0.040109666314800715}"}}
exception: None

05:41:41 job_callback for (8, 0, 23) started
05:41:41 DISPATCHER: Trying to submit another job.
05:41:41 job_callback for (8, 0, 23) got condition
05:41:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:41:41 HBMASTER: Trying to run another job!
05:41:41 job_callback for (8, 0, 23) finished
05:41:41 start sampling a new configuration.
05:41:41 best_vector: [3, 0.02741222716778434, 0.9196720845825535, 0.6986651020441419, 0.3722340483290107, 1, 0.5683033422823741, 0.6317093280269062, 0.9143927310808557], 5.193308502417133e-32, 0.19255547779119378, -9.541866428989219e-05
05:41:41 done sampling a new configuration.
05:41:41 HBMASTER: schedule new run for iteration 8
05:41:41 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
05:41:41 HBMASTER: submitting job (8, 0, 24) to dispatcher
05:41:41 DISPATCHER: trying to submit job (8, 0, 24)
05:41:41 DISPATCHER: trying to notify the job_runner thread.
05:41:41 HBMASTER: job (8, 0, 24) submitted to dispatcher
05:41:41 DISPATCHER: Trying to submit another job.
05:41:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:41:41 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpul.22021139727314577216
05:41:41 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
05:41:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:41:41 WORKER: start processing job (8, 0, 24)
05:41:41 WORKER: args: ()
05:41:41 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 221, 'last_n_outputs': 47, 'leak_rate': 0.9246662755110355, 'lr': 0.005552238287903151, 'optimizer': 'SGD', 'sparsity': 0.8863928021477698, 'steps_to_train': 67, 'weight_decay': 0.15475773717212923}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:41:45 DISPATCHER: Starting worker discovery
05:41:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:41:45 DISPATCHER: Finished worker discovery
05:42:40 WORKER: done with job (8, 0, 24), trying to register it.
05:42:40 DISPATCHER: job (8, 0, 24) finished
05:42:40 WORKER: registered result for job (8, 0, 24) with dispatcher
05:42:40 DISPATCHER: register_result: lock acquired
05:42:40 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
05:42:40 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 221, 'last_n_outputs': 47, 'leak_rate': 0.9246662755110355, 'lr': 0.005552238287903151, 'optimizer': 'SGD', 'sparsity': 0.8863928021477698, 'steps_to_train': 67, 'weight_decay': 0.15475773717212923}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.49350199310641185, 'info': {'music-speech': 0.49350199310641185, 'config': "{'batch_size': 128, 'hidden_dim': 221, 'last_n_outputs': 47, 'leak_rate': 0.9246662755110355, 'lr': 0.005552238287903151, 'optimizer': 'SGD', 'sparsity': 0.8863928021477698, 'steps_to_train': 67, 'weight_decay': 0.15475773717212923}"}}
exception: None

05:42:40 job_callback for (8, 0, 24) started
05:42:40 DISPATCHER: Trying to submit another job.
05:42:40 job_callback for (8, 0, 24) got condition
05:42:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:42:40 HBMASTER: Trying to run another job!
05:42:40 job_callback for (8, 0, 24) finished
05:42:40 start sampling a new configuration.
05:42:40 best_vector: [3, 0.4739451228583931, 0.59683507719141, 0.5454867022949911, 0.381228941211614, 0, 0.21673713875636277, 0.3304576934612588, 0.7435092546018509], 2.366521409821484e-32, 0.42256114643620907, -0.015552356550294586
05:42:40 done sampling a new configuration.
05:42:40 HBMASTER: schedule new run for iteration 8
05:42:40 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
05:42:40 HBMASTER: submitting job (8, 0, 25) to dispatcher
05:42:40 DISPATCHER: trying to submit job (8, 0, 25)
05:42:40 DISPATCHER: trying to notify the job_runner thread.
05:42:40 HBMASTER: job (8, 0, 25) submitted to dispatcher
05:42:40 DISPATCHER: Trying to submit another job.
05:42:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:42:40 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216
05:42:40 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
05:42:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:42:40 WORKER: start processing job (8, 0, 25)
05:42:40 WORKER: args: ()
05:42:40 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 579, 'last_n_outputs': 34, 'leak_rate': 0.8863716755737477, 'lr': 0.005787058631355974, 'optimizer': 'Adam', 'sparsity': 0.802016913301527, 'steps_to_train': 40, 'weight_decay': 0.09275297372427985}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:42:45 DISPATCHER: Starting worker discovery
05:42:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:42:45 DISPATCHER: Finished worker discovery
05:43:38 WORKER: done with job (8, 0, 25), trying to register it.
05:43:38 WORKER: registered result for job (8, 0, 25) with dispatcher
05:43:38 DISPATCHER: job (8, 0, 25) finished
05:43:38 DISPATCHER: register_result: lock acquired
05:43:38 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
05:43:38 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 579, 'last_n_outputs': 34, 'leak_rate': 0.8863716755737477, 'lr': 0.005787058631355974, 'optimizer': 'Adam', 'sparsity': 0.802016913301527, 'steps_to_train': 40, 'weight_decay': 0.09275297372427985}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5889809796507021, 'info': {'music-speech': 0.5889809796507021, 'config': "{'batch_size': 128, 'hidden_dim': 579, 'last_n_outputs': 34, 'leak_rate': 0.8863716755737477, 'lr': 0.005787058631355974, 'optimizer': 'Adam', 'sparsity': 0.802016913301527, 'steps_to_train': 40, 'weight_decay': 0.09275297372427985}"}}
exception: None

05:43:38 job_callback for (8, 0, 25) started
05:43:38 DISPATCHER: Trying to submit another job.
05:43:38 job_callback for (8, 0, 25) got condition
05:43:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:43:38 HBMASTER: Trying to run another job!
05:43:38 job_callback for (8, 0, 25) finished
05:43:38 start sampling a new configuration.
05:43:38 best_vector: [0, 0.2875775479526455, 0.9962774579841644, 0.349558841225435, 0.033125106371393875, 0, 0.43726265959658295, 0.9933317824394179, 0.24027058210766578], 3.21533229724399e-31, 0.031100984518991903, -4.1825450626531593e-05
05:43:38 done sampling a new configuration.
05:43:38 HBMASTER: schedule new run for iteration 8
05:43:38 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
05:43:38 HBMASTER: submitting job (8, 0, 26) to dispatcher
05:43:38 DISPATCHER: trying to submit job (8, 0, 26)
05:43:38 DISPATCHER: trying to notify the job_runner thread.
05:43:38 HBMASTER: job (8, 0, 26) submitted to dispatcher
05:43:38 DISPATCHER: Trying to submit another job.
05:43:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:43:38 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpul.22021139727314577216
05:43:38 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
05:43:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:43:38 WORKER: start processing job (8, 0, 26)
05:43:38 WORKER: args: ()
05:43:38 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 430, 'last_n_outputs': 50, 'leak_rate': 0.8373897103063588, 'lr': 0.0011647969177207352, 'optimizer': 'Adam', 'sparsity': 0.8549430383031799, 'steps_to_train': 100, 'weight_decay': 0.020539943015940042}, 'budget': 44.44444444444444, 'working_directory': '.'}
05:43:45 DISPATCHER: Starting worker discovery
05:43:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:43:45 DISPATCHER: Finished worker discovery
05:44:45 DISPATCHER: Starting worker discovery
05:44:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:44:45 DISPATCHER: Finished worker discovery
05:44:48 WORKER: done with job (8, 0, 26), trying to register it.
05:44:48 WORKER: registered result for job (8, 0, 26) with dispatcher
05:44:48 DISPATCHER: job (8, 0, 26) finished
05:44:48 DISPATCHER: register_result: lock acquired
05:44:48 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
05:44:48 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 430, 'last_n_outputs': 50, 'leak_rate': 0.8373897103063588, 'lr': 0.0011647969177207352, 'optimizer': 'Adam', 'sparsity': 0.8549430383031799, 'steps_to_train': 100, 'weight_decay': 0.020539943015940042}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4043418096663044, 'info': {'music-speech': 0.4043418096663044, 'config': "{'batch_size': 16, 'hidden_dim': 430, 'last_n_outputs': 50, 'leak_rate': 0.8373897103063588, 'lr': 0.0011647969177207352, 'optimizer': 'Adam', 'sparsity': 0.8549430383031799, 'steps_to_train': 100, 'weight_decay': 0.020539943015940042}"}}
exception: None

05:44:48 job_callback for (8, 0, 26) started
05:44:48 DISPATCHER: Trying to submit another job.
05:44:48 job_callback for (8, 0, 26) got condition
05:44:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:44:48 HBMASTER: Trying to run another job!
05:44:48 job_callback for (8, 0, 26) finished
05:44:48 ITERATION: Advancing config (8, 0, 4) to next budget 133.333333
05:44:48 ITERATION: Advancing config (8, 0, 5) to next budget 133.333333
05:44:48 ITERATION: Advancing config (8, 0, 6) to next budget 133.333333
05:44:48 ITERATION: Advancing config (8, 0, 8) to next budget 133.333333
05:44:48 ITERATION: Advancing config (8, 0, 14) to next budget 133.333333
05:44:48 ITERATION: Advancing config (8, 0, 18) to next budget 133.333333
05:44:48 ITERATION: Advancing config (8, 0, 21) to next budget 133.333333
05:44:48 ITERATION: Advancing config (8, 0, 23) to next budget 133.333333
05:44:48 ITERATION: Advancing config (8, 0, 25) to next budget 133.333333
05:44:48 HBMASTER: schedule new run for iteration 8
05:44:48 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
05:44:48 HBMASTER: submitting job (8, 0, 4) to dispatcher
05:44:48 DISPATCHER: trying to submit job (8, 0, 4)
05:44:48 DISPATCHER: trying to notify the job_runner thread.
05:44:48 HBMASTER: job (8, 0, 4) submitted to dispatcher
05:44:48 DISPATCHER: Trying to submit another job.
05:44:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:44:48 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
05:44:48 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
05:44:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:44:48 WORKER: start processing job (8, 0, 4)
05:44:48 WORKER: args: ()
05:44:48 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 464, 'last_n_outputs': 45, 'leak_rate': 0.8035710732011853, 'lr': 0.00147267201495795, 'optimizer': 'SGD', 'sparsity': 0.9596897700409338, 'steps_to_train': 27, 'weight_decay': 0.011628016007379595}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:45:45 DISPATCHER: Starting worker discovery
05:45:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:45:45 DISPATCHER: Finished worker discovery
05:46:45 DISPATCHER: Starting worker discovery
05:46:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:46:45 DISPATCHER: Finished worker discovery
05:47:14 WORKER: done with job (8, 0, 4), trying to register it.
05:47:14 WORKER: registered result for job (8, 0, 4) with dispatcher
05:47:14 DISPATCHER: job (8, 0, 4) finished
05:47:14 DISPATCHER: register_result: lock acquired
05:47:14 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
05:47:14 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 464, 'last_n_outputs': 45, 'leak_rate': 0.8035710732011853, 'lr': 0.00147267201495795, 'optimizer': 'SGD', 'sparsity': 0.9596897700409338, 'steps_to_train': 27, 'weight_decay': 0.011628016007379595}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5069569589597563, 'info': {'music-speech': 0.5069569589597563, 'config': "{'batch_size': 32, 'hidden_dim': 464, 'last_n_outputs': 45, 'leak_rate': 0.8035710732011853, 'lr': 0.00147267201495795, 'optimizer': 'SGD', 'sparsity': 0.9596897700409338, 'steps_to_train': 27, 'weight_decay': 0.011628016007379595}"}}
exception: None

05:47:14 job_callback for (8, 0, 4) started
05:47:14 DISPATCHER: Trying to submit another job.
05:47:14 job_callback for (8, 0, 4) got condition
05:47:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:47:14 HBMASTER: Trying to run another job!
05:47:14 job_callback for (8, 0, 4) finished
05:47:14 HBMASTER: schedule new run for iteration 8
05:47:14 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
05:47:14 HBMASTER: submitting job (8, 0, 5) to dispatcher
05:47:14 DISPATCHER: trying to submit job (8, 0, 5)
05:47:14 DISPATCHER: trying to notify the job_runner thread.
05:47:14 HBMASTER: job (8, 0, 5) submitted to dispatcher
05:47:14 DISPATCHER: Trying to submit another job.
05:47:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:47:14 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
05:47:14 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
05:47:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:47:14 WORKER: start processing job (8, 0, 5)
05:47:14 WORKER: args: ()
05:47:14 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 649, 'last_n_outputs': 24, 'leak_rate': 0.8987897187318628, 'lr': 0.003023644334457388, 'optimizer': 'Adam', 'sparsity': 0.7945052253351212, 'steps_to_train': 50, 'weight_decay': 0.13048219958414764}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:47:45 DISPATCHER: Starting worker discovery
05:47:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:47:45 DISPATCHER: Finished worker discovery
05:48:45 DISPATCHER: Starting worker discovery
05:48:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:48:45 DISPATCHER: Finished worker discovery
05:49:44 WORKER: done with job (8, 0, 5), trying to register it.
05:49:44 WORKER: registered result for job (8, 0, 5) with dispatcher
05:49:44 DISPATCHER: job (8, 0, 5) finished
05:49:44 DISPATCHER: register_result: lock acquired
05:49:44 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
05:49:44 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 649, 'last_n_outputs': 24, 'leak_rate': 0.8987897187318628, 'lr': 0.003023644334457388, 'optimizer': 'Adam', 'sparsity': 0.7945052253351212, 'steps_to_train': 50, 'weight_decay': 0.13048219958414764}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5752229630849393, 'info': {'music-speech': 0.5752229630849393, 'config': "{'batch_size': 128, 'hidden_dim': 649, 'last_n_outputs': 24, 'leak_rate': 0.8987897187318628, 'lr': 0.003023644334457388, 'optimizer': 'Adam', 'sparsity': 0.7945052253351212, 'steps_to_train': 50, 'weight_decay': 0.13048219958414764}"}}
exception: None

05:49:44 job_callback for (8, 0, 5) started
05:49:44 DISPATCHER: Trying to submit another job.
05:49:44 job_callback for (8, 0, 5) got condition
05:49:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:49:44 HBMASTER: Trying to run another job!
05:49:44 job_callback for (8, 0, 5) finished
05:49:44 HBMASTER: schedule new run for iteration 8
05:49:44 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
05:49:44 HBMASTER: submitting job (8, 0, 6) to dispatcher
05:49:44 DISPATCHER: trying to submit job (8, 0, 6)
05:49:44 DISPATCHER: trying to notify the job_runner thread.
05:49:44 HBMASTER: job (8, 0, 6) submitted to dispatcher
05:49:44 DISPATCHER: Trying to submit another job.
05:49:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:49:44 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216
05:49:44 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
05:49:44 WORKER: start processing job (8, 0, 6)
05:49:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:49:44 WORKER: args: ()
05:49:44 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 494, 'last_n_outputs': 45, 'leak_rate': 0.9543599158835127, 'lr': 0.01871700721131321, 'optimizer': 'Adam', 'sparsity': 0.7961309738056997, 'steps_to_train': 18, 'weight_decay': 0.0982506166529984}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:49:45 DISPATCHER: Starting worker discovery
05:49:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:49:45 DISPATCHER: Finished worker discovery
05:50:45 DISPATCHER: Starting worker discovery
05:50:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:50:45 DISPATCHER: Finished worker discovery
05:51:45 DISPATCHER: Starting worker discovery
05:51:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:51:45 DISPATCHER: Finished worker discovery
05:52:09 WORKER: done with job (8, 0, 6), trying to register it.
05:52:09 WORKER: registered result for job (8, 0, 6) with dispatcher
05:52:09 DISPATCHER: job (8, 0, 6) finished
05:52:09 DISPATCHER: register_result: lock acquired
05:52:09 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
05:52:09 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 494, 'last_n_outputs': 45, 'leak_rate': 0.9543599158835127, 'lr': 0.01871700721131321, 'optimizer': 'Adam', 'sparsity': 0.7961309738056997, 'steps_to_train': 18, 'weight_decay': 0.0982506166529984}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2119225520968031, 'info': {'music-speech': 0.2119225520968031, 'config': "{'batch_size': 128, 'hidden_dim': 494, 'last_n_outputs': 45, 'leak_rate': 0.9543599158835127, 'lr': 0.01871700721131321, 'optimizer': 'Adam', 'sparsity': 0.7961309738056997, 'steps_to_train': 18, 'weight_decay': 0.0982506166529984}"}}
exception: None

05:52:09 job_callback for (8, 0, 6) started
05:52:09 job_callback for (8, 0, 6) got condition
05:52:09 DISPATCHER: Trying to submit another job.
05:52:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:52:09 HBMASTER: Trying to run another job!
05:52:09 job_callback for (8, 0, 6) finished
05:52:09 HBMASTER: schedule new run for iteration 8
05:52:09 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
05:52:09 HBMASTER: submitting job (8, 0, 8) to dispatcher
05:52:09 DISPATCHER: trying to submit job (8, 0, 8)
05:52:09 DISPATCHER: trying to notify the job_runner thread.
05:52:09 HBMASTER: job (8, 0, 8) submitted to dispatcher
05:52:09 DISPATCHER: Trying to submit another job.
05:52:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:52:09 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216
05:52:09 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
05:52:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:52:09 WORKER: start processing job (8, 0, 8)
05:52:09 WORKER: args: ()
05:52:09 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 843, 'last_n_outputs': 32, 'leak_rate': 0.9464204737347539, 'lr': 0.009734716373205547, 'optimizer': 'SGD', 'sparsity': 0.7508157699184114, 'steps_to_train': 99, 'weight_decay': 0.026664441718938565}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:52:45 DISPATCHER: Starting worker discovery
05:52:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:52:46 DISPATCHER: Finished worker discovery
05:53:46 DISPATCHER: Starting worker discovery
05:53:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:53:46 DISPATCHER: Finished worker discovery
05:54:46 DISPATCHER: Starting worker discovery
05:54:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:54:46 DISPATCHER: Finished worker discovery
05:54:49 WORKER: done with job (8, 0, 8), trying to register it.
05:54:49 WORKER: registered result for job (8, 0, 8) with dispatcher
05:54:49 DISPATCHER: job (8, 0, 8) finished
05:54:49 DISPATCHER: register_result: lock acquired
05:54:49 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
05:54:49 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 843, 'last_n_outputs': 32, 'leak_rate': 0.9464204737347539, 'lr': 0.009734716373205547, 'optimizer': 'SGD', 'sparsity': 0.7508157699184114, 'steps_to_train': 99, 'weight_decay': 0.026664441718938565}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.24920915415159053, 'info': {'music-speech': 0.24920915415159053, 'config': "{'batch_size': 16, 'hidden_dim': 843, 'last_n_outputs': 32, 'leak_rate': 0.9464204737347539, 'lr': 0.009734716373205547, 'optimizer': 'SGD', 'sparsity': 0.7508157699184114, 'steps_to_train': 99, 'weight_decay': 0.026664441718938565}"}}
exception: None

05:54:49 job_callback for (8, 0, 8) started
05:54:49 DISPATCHER: Trying to submit another job.
05:54:49 job_callback for (8, 0, 8) got condition
05:54:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:54:49 HBMASTER: Trying to run another job!
05:54:49 job_callback for (8, 0, 8) finished
05:54:49 HBMASTER: schedule new run for iteration 8
05:54:49 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
05:54:49 HBMASTER: submitting job (8, 0, 14) to dispatcher
05:54:49 DISPATCHER: trying to submit job (8, 0, 14)
05:54:49 DISPATCHER: trying to notify the job_runner thread.
05:54:49 HBMASTER: job (8, 0, 14) submitted to dispatcher
05:54:49 DISPATCHER: Trying to submit another job.
05:54:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:54:49 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpul.22021139727314577216
05:54:49 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
05:54:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:54:49 WORKER: start processing job (8, 0, 14)
05:54:49 WORKER: args: ()
05:54:49 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 294, 'last_n_outputs': 39, 'leak_rate': 0.9619424355360631, 'lr': 0.03353377055933054, 'optimizer': 'Adam', 'sparsity': 0.8224832789752712, 'steps_to_train': 90, 'weight_decay': 0.08134500011429172}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:55:46 DISPATCHER: Starting worker discovery
05:55:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:55:46 DISPATCHER: Finished worker discovery
05:56:46 DISPATCHER: Starting worker discovery
05:56:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:56:46 DISPATCHER: Finished worker discovery
05:57:23 WORKER: done with job (8, 0, 14), trying to register it.
05:57:23 DISPATCHER: job (8, 0, 14) finished
05:57:23 WORKER: registered result for job (8, 0, 14) with dispatcher
05:57:23 DISPATCHER: register_result: lock acquired
05:57:23 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
05:57:23 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 294, 'last_n_outputs': 39, 'leak_rate': 0.9619424355360631, 'lr': 0.03353377055933054, 'optimizer': 'Adam', 'sparsity': 0.8224832789752712, 'steps_to_train': 90, 'weight_decay': 0.08134500011429172}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.35255517789472085, 'info': {'music-speech': 0.35255517789472085, 'config': "{'batch_size': 16, 'hidden_dim': 294, 'last_n_outputs': 39, 'leak_rate': 0.9619424355360631, 'lr': 0.03353377055933054, 'optimizer': 'Adam', 'sparsity': 0.8224832789752712, 'steps_to_train': 90, 'weight_decay': 0.08134500011429172}"}}
exception: None

05:57:23 job_callback for (8, 0, 14) started
05:57:23 job_callback for (8, 0, 14) got condition
05:57:23 DISPATCHER: Trying to submit another job.
05:57:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:57:23 HBMASTER: Trying to run another job!
05:57:23 job_callback for (8, 0, 14) finished
05:57:23 HBMASTER: schedule new run for iteration 8
05:57:23 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
05:57:23 HBMASTER: submitting job (8, 0, 18) to dispatcher
05:57:23 DISPATCHER: trying to submit job (8, 0, 18)
05:57:23 DISPATCHER: trying to notify the job_runner thread.
05:57:23 HBMASTER: job (8, 0, 18) submitted to dispatcher
05:57:23 DISPATCHER: Trying to submit another job.
05:57:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:57:23 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpul.22021139727314577216
05:57:23 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
05:57:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:57:23 WORKER: start processing job (8, 0, 18)
05:57:23 WORKER: args: ()
05:57:23 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 556, 'last_n_outputs': 32, 'leak_rate': 0.8240002504723166, 'lr': 0.0014823252717460307, 'optimizer': 'SGD', 'sparsity': 0.8035950431456826, 'steps_to_train': 39, 'weight_decay': 0.09462771137446502}, 'budget': 133.33333333333331, 'working_directory': '.'}
05:57:46 DISPATCHER: Starting worker discovery
05:57:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:57:46 DISPATCHER: Finished worker discovery
05:58:46 DISPATCHER: Starting worker discovery
05:58:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:58:46 DISPATCHER: Finished worker discovery
05:59:46 DISPATCHER: Starting worker discovery
05:59:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:59:46 DISPATCHER: Finished worker discovery
05:59:51 WORKER: done with job (8, 0, 18), trying to register it.
05:59:51 WORKER: registered result for job (8, 0, 18) with dispatcher
05:59:51 DISPATCHER: job (8, 0, 18) finished
05:59:51 DISPATCHER: register_result: lock acquired
05:59:51 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
05:59:51 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 556, 'last_n_outputs': 32, 'leak_rate': 0.8240002504723166, 'lr': 0.0014823252717460307, 'optimizer': 'SGD', 'sparsity': 0.8035950431456826, 'steps_to_train': 39, 'weight_decay': 0.09462771137446502}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4382814213537115, 'info': {'music-speech': 0.4382814213537115, 'config': "{'batch_size': 64, 'hidden_dim': 556, 'last_n_outputs': 32, 'leak_rate': 0.8240002504723166, 'lr': 0.0014823252717460307, 'optimizer': 'SGD', 'sparsity': 0.8035950431456826, 'steps_to_train': 39, 'weight_decay': 0.09462771137446502}"}}
exception: None

05:59:51 job_callback for (8, 0, 18) started
05:59:51 DISPATCHER: Trying to submit another job.
05:59:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:59:51 job_callback for (8, 0, 18) got condition
05:59:51 HBMASTER: Trying to run another job!
05:59:51 job_callback for (8, 0, 18) finished
05:59:51 HBMASTER: schedule new run for iteration 8
05:59:51 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
05:59:51 HBMASTER: submitting job (8, 0, 21) to dispatcher
05:59:51 DISPATCHER: trying to submit job (8, 0, 21)
05:59:51 DISPATCHER: trying to notify the job_runner thread.
05:59:51 HBMASTER: job (8, 0, 21) submitted to dispatcher
05:59:51 DISPATCHER: Trying to submit another job.
05:59:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:59:51 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216
05:59:51 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
05:59:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:59:51 WORKER: start processing job (8, 0, 21)
05:59:51 WORKER: args: ()
05:59:51 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 601, 'last_n_outputs': 28, 'leak_rate': 0.9158114738224625, 'lr': 0.0018643666834377702, 'optimizer': 'SGD', 'sparsity': 0.7946503588021077, 'steps_to_train': 32, 'weight_decay': 0.19204058603939483}, 'budget': 133.33333333333331, 'working_directory': '.'}
06:00:46 DISPATCHER: Starting worker discovery
06:00:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:00:46 DISPATCHER: Finished worker discovery
06:01:46 DISPATCHER: Starting worker discovery
06:01:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:01:46 DISPATCHER: Finished worker discovery
06:02:13 WORKER: done with job (8, 0, 21), trying to register it.
06:02:13 DISPATCHER: job (8, 0, 21) finished
06:02:13 WORKER: registered result for job (8, 0, 21) with dispatcher
06:02:13 DISPATCHER: register_result: lock acquired
06:02:13 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
06:02:13 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 601, 'last_n_outputs': 28, 'leak_rate': 0.9158114738224625, 'lr': 0.0018643666834377702, 'optimizer': 'SGD', 'sparsity': 0.7946503588021077, 'steps_to_train': 32, 'weight_decay': 0.19204058603939483}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5229124588919274, 'info': {'music-speech': 0.5229124588919274, 'config': "{'batch_size': 128, 'hidden_dim': 601, 'last_n_outputs': 28, 'leak_rate': 0.9158114738224625, 'lr': 0.0018643666834377702, 'optimizer': 'SGD', 'sparsity': 0.7946503588021077, 'steps_to_train': 32, 'weight_decay': 0.19204058603939483}"}}
exception: None

06:02:13 job_callback for (8, 0, 21) started
06:02:13 DISPATCHER: Trying to submit another job.
06:02:13 job_callback for (8, 0, 21) got condition
06:02:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:02:13 HBMASTER: Trying to run another job!
06:02:13 job_callback for (8, 0, 21) finished
06:02:13 HBMASTER: schedule new run for iteration 8
06:02:13 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
06:02:13 HBMASTER: submitting job (8, 0, 23) to dispatcher
06:02:13 DISPATCHER: trying to submit job (8, 0, 23)
06:02:13 DISPATCHER: trying to notify the job_runner thread.
06:02:13 HBMASTER: job (8, 0, 23) submitted to dispatcher
06:02:13 DISPATCHER: Trying to submit another job.
06:02:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:02:13 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216
06:02:13 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
06:02:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:02:13 WORKER: start processing job (8, 0, 23)
06:02:13 WORKER: args: ()
06:02:13 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 264, 'last_n_outputs': 28, 'leak_rate': 0.9543947518604212, 'lr': 0.046110234506119376, 'optimizer': 'Adam', 'sparsity': 0.8076346124091273, 'steps_to_train': 31, 'weight_decay': 0.040109666314800715}, 'budget': 133.33333333333331, 'working_directory': '.'}
06:02:46 DISPATCHER: Starting worker discovery
06:02:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:02:46 DISPATCHER: Finished worker discovery
06:03:46 DISPATCHER: Starting worker discovery
06:03:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:03:46 DISPATCHER: Finished worker discovery
06:04:39 WORKER: done with job (8, 0, 23), trying to register it.
06:04:39 WORKER: registered result for job (8, 0, 23) with dispatcher
06:04:39 DISPATCHER: job (8, 0, 23) finished
06:04:39 DISPATCHER: register_result: lock acquired
06:04:39 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
06:04:39 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 264, 'last_n_outputs': 28, 'leak_rate': 0.9543947518604212, 'lr': 0.046110234506119376, 'optimizer': 'Adam', 'sparsity': 0.8076346124091273, 'steps_to_train': 31, 'weight_decay': 0.040109666314800715}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.30500627806761227, 'info': {'music-speech': 0.30500627806761227, 'config': "{'batch_size': 128, 'hidden_dim': 264, 'last_n_outputs': 28, 'leak_rate': 0.9543947518604212, 'lr': 0.046110234506119376, 'optimizer': 'Adam', 'sparsity': 0.8076346124091273, 'steps_to_train': 31, 'weight_decay': 0.040109666314800715}"}}
exception: None

06:04:39 job_callback for (8, 0, 23) started
06:04:39 job_callback for (8, 0, 23) got condition
06:04:39 DISPATCHER: Trying to submit another job.
06:04:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:04:39 HBMASTER: Trying to run another job!
06:04:39 job_callback for (8, 0, 23) finished
06:04:39 HBMASTER: schedule new run for iteration 8
06:04:39 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
06:04:39 HBMASTER: submitting job (8, 0, 25) to dispatcher
06:04:39 DISPATCHER: trying to submit job (8, 0, 25)
06:04:39 DISPATCHER: trying to notify the job_runner thread.
06:04:39 HBMASTER: job (8, 0, 25) submitted to dispatcher
06:04:39 DISPATCHER: Trying to submit another job.
06:04:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:04:39 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216
06:04:39 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
06:04:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:04:39 WORKER: start processing job (8, 0, 25)
06:04:39 WORKER: args: ()
06:04:39 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 579, 'last_n_outputs': 34, 'leak_rate': 0.8863716755737477, 'lr': 0.005787058631355974, 'optimizer': 'Adam', 'sparsity': 0.802016913301527, 'steps_to_train': 40, 'weight_decay': 0.09275297372427985}, 'budget': 133.33333333333331, 'working_directory': '.'}
06:04:46 DISPATCHER: Starting worker discovery
06:04:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:04:46 DISPATCHER: Finished worker discovery
06:05:46 DISPATCHER: Starting worker discovery
06:05:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:05:46 DISPATCHER: Finished worker discovery
06:06:46 DISPATCHER: Starting worker discovery
06:06:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:06:46 DISPATCHER: Finished worker discovery
06:07:02 WORKER: done with job (8, 0, 25), trying to register it.
06:07:02 WORKER: registered result for job (8, 0, 25) with dispatcher
06:07:02 DISPATCHER: job (8, 0, 25) finished
06:07:02 DISPATCHER: register_result: lock acquired
06:07:02 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
06:07:02 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 579, 'last_n_outputs': 34, 'leak_rate': 0.8863716755737477, 'lr': 0.005787058631355974, 'optimizer': 'Adam', 'sparsity': 0.802016913301527, 'steps_to_train': 40, 'weight_decay': 0.09275297372427985}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5908233532398633, 'info': {'music-speech': 0.5908233532398633, 'config': "{'batch_size': 128, 'hidden_dim': 579, 'last_n_outputs': 34, 'leak_rate': 0.8863716755737477, 'lr': 0.005787058631355974, 'optimizer': 'Adam', 'sparsity': 0.802016913301527, 'steps_to_train': 40, 'weight_decay': 0.09275297372427985}"}}
exception: None

06:07:02 job_callback for (8, 0, 25) started
06:07:02 DISPATCHER: Trying to submit another job.
06:07:02 job_callback for (8, 0, 25) got condition
06:07:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:07:02 HBMASTER: Trying to run another job!
06:07:02 job_callback for (8, 0, 25) finished
06:07:02 ITERATION: Advancing config (8, 0, 5) to next budget 400.000000
06:07:02 ITERATION: Advancing config (8, 0, 21) to next budget 400.000000
06:07:02 ITERATION: Advancing config (8, 0, 25) to next budget 400.000000
06:07:02 HBMASTER: schedule new run for iteration 8
06:07:02 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
06:07:02 HBMASTER: submitting job (8, 0, 5) to dispatcher
06:07:02 DISPATCHER: trying to submit job (8, 0, 5)
06:07:02 DISPATCHER: trying to notify the job_runner thread.
06:07:02 HBMASTER: job (8, 0, 5) submitted to dispatcher
06:07:02 DISPATCHER: Trying to submit another job.
06:07:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:07:02 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
06:07:02 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
06:07:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:07:02 WORKER: start processing job (8, 0, 5)
06:07:02 WORKER: args: ()
06:07:02 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 649, 'last_n_outputs': 24, 'leak_rate': 0.8987897187318628, 'lr': 0.003023644334457388, 'optimizer': 'Adam', 'sparsity': 0.7945052253351212, 'steps_to_train': 50, 'weight_decay': 0.13048219958414764}, 'budget': 400.0, 'working_directory': '.'}
06:07:46 DISPATCHER: Starting worker discovery
06:07:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:07:46 DISPATCHER: Finished worker discovery
06:08:46 DISPATCHER: Starting worker discovery
06:08:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:08:46 DISPATCHER: Finished worker discovery
06:09:46 DISPATCHER: Starting worker discovery
06:09:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:09:46 DISPATCHER: Finished worker discovery
06:10:46 DISPATCHER: Starting worker discovery
06:10:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:10:46 DISPATCHER: Finished worker discovery
06:11:46 DISPATCHER: Starting worker discovery
06:11:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:11:46 DISPATCHER: Finished worker discovery
06:12:46 DISPATCHER: Starting worker discovery
06:12:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:12:46 DISPATCHER: Finished worker discovery
06:13:46 DISPATCHER: Starting worker discovery
06:13:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:13:46 DISPATCHER: Finished worker discovery
06:14:00 WORKER: done with job (8, 0, 5), trying to register it.
06:14:00 WORKER: registered result for job (8, 0, 5) with dispatcher
06:14:00 DISPATCHER: job (8, 0, 5) finished
06:14:00 DISPATCHER: register_result: lock acquired
06:14:00 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
06:14:00 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 649, 'last_n_outputs': 24, 'leak_rate': 0.8987897187318628, 'lr': 0.003023644334457388, 'optimizer': 'Adam', 'sparsity': 0.7945052253351212, 'steps_to_train': 50, 'weight_decay': 0.13048219958414764}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4132940266401244, 'info': {'music-speech': 0.4132940266401244, 'config': "{'batch_size': 128, 'hidden_dim': 649, 'last_n_outputs': 24, 'leak_rate': 0.8987897187318628, 'lr': 0.003023644334457388, 'optimizer': 'Adam', 'sparsity': 0.7945052253351212, 'steps_to_train': 50, 'weight_decay': 0.13048219958414764}"}}
exception: None

06:14:00 job_callback for (8, 0, 5) started
06:14:00 DISPATCHER: Trying to submit another job.
06:14:00 job_callback for (8, 0, 5) got condition
06:14:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:14:00 done building a new model for budget 400.000000 based on 10/21 split
Best loss for this budget:-0.599878





06:14:00 HBMASTER: Trying to run another job!
06:14:00 job_callback for (8, 0, 5) finished
06:14:00 HBMASTER: schedule new run for iteration 8
06:14:00 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
06:14:00 HBMASTER: submitting job (8, 0, 21) to dispatcher
06:14:00 DISPATCHER: trying to submit job (8, 0, 21)
06:14:00 DISPATCHER: trying to notify the job_runner thread.
06:14:00 HBMASTER: job (8, 0, 21) submitted to dispatcher
06:14:00 DISPATCHER: Trying to submit another job.
06:14:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:14:00 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216
06:14:00 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
06:14:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:14:00 WORKER: start processing job (8, 0, 21)
06:14:00 WORKER: args: ()
06:14:00 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 601, 'last_n_outputs': 28, 'leak_rate': 0.9158114738224625, 'lr': 0.0018643666834377702, 'optimizer': 'SGD', 'sparsity': 0.7946503588021077, 'steps_to_train': 32, 'weight_decay': 0.19204058603939483}, 'budget': 400.0, 'working_directory': '.'}
06:14:46 DISPATCHER: Starting worker discovery
06:14:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:14:46 DISPATCHER: Finished worker discovery
06:15:46 DISPATCHER: Starting worker discovery
06:15:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:15:46 DISPATCHER: Finished worker discovery
06:16:46 DISPATCHER: Starting worker discovery
06:16:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:16:46 DISPATCHER: Finished worker discovery
06:17:46 DISPATCHER: Starting worker discovery
06:17:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:17:46 DISPATCHER: Finished worker discovery
06:18:46 DISPATCHER: Starting worker discovery
06:18:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:18:46 DISPATCHER: Finished worker discovery
06:19:46 DISPATCHER: Starting worker discovery
06:19:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:19:46 DISPATCHER: Finished worker discovery
06:20:46 DISPATCHER: Starting worker discovery
06:20:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:20:46 DISPATCHER: Finished worker discovery
06:20:56 WORKER: done with job (8, 0, 21), trying to register it.
06:20:56 WORKER: registered result for job (8, 0, 21) with dispatcher
06:20:56 DISPATCHER: job (8, 0, 21) finished
06:20:56 DISPATCHER: register_result: lock acquired
06:20:56 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
06:20:56 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 601, 'last_n_outputs': 28, 'leak_rate': 0.9158114738224625, 'lr': 0.0018643666834377702, 'optimizer': 'SGD', 'sparsity': 0.7946503588021077, 'steps_to_train': 32, 'weight_decay': 0.19204058603939483}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4873583984534068, 'info': {'music-speech': 0.4873583984534068, 'config': "{'batch_size': 128, 'hidden_dim': 601, 'last_n_outputs': 28, 'leak_rate': 0.9158114738224625, 'lr': 0.0018643666834377702, 'optimizer': 'SGD', 'sparsity': 0.7946503588021077, 'steps_to_train': 32, 'weight_decay': 0.19204058603939483}"}}
exception: None

06:20:56 job_callback for (8, 0, 21) started
06:20:56 DISPATCHER: Trying to submit another job.
06:20:56 job_callback for (8, 0, 21) got condition
06:20:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:20:56 done building a new model for budget 400.000000 based on 10/22 split
Best loss for this budget:-0.599878





06:20:56 HBMASTER: Trying to run another job!
06:20:56 job_callback for (8, 0, 21) finished
06:20:56 HBMASTER: schedule new run for iteration 8
06:20:56 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
06:20:56 HBMASTER: submitting job (8, 0, 25) to dispatcher
06:20:56 DISPATCHER: trying to submit job (8, 0, 25)
06:20:56 DISPATCHER: trying to notify the job_runner thread.
06:20:56 HBMASTER: job (8, 0, 25) submitted to dispatcher
06:20:56 DISPATCHER: Trying to submit another job.
06:20:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:20:56 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216
06:20:56 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
06:20:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:20:56 WORKER: start processing job (8, 0, 25)
06:20:56 WORKER: args: ()
06:20:56 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 579, 'last_n_outputs': 34, 'leak_rate': 0.8863716755737477, 'lr': 0.005787058631355974, 'optimizer': 'Adam', 'sparsity': 0.802016913301527, 'steps_to_train': 40, 'weight_decay': 0.09275297372427985}, 'budget': 400.0, 'working_directory': '.'}
06:21:46 DISPATCHER: Starting worker discovery
06:21:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:21:46 DISPATCHER: Finished worker discovery
06:22:46 DISPATCHER: Starting worker discovery
06:22:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:22:46 DISPATCHER: Finished worker discovery
06:23:46 DISPATCHER: Starting worker discovery
06:23:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:23:46 DISPATCHER: Finished worker discovery
06:24:46 DISPATCHER: Starting worker discovery
06:24:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:24:46 DISPATCHER: Finished worker discovery
06:25:46 DISPATCHER: Starting worker discovery
06:25:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:25:46 DISPATCHER: Finished worker discovery
06:26:46 DISPATCHER: Starting worker discovery
06:26:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:26:46 DISPATCHER: Finished worker discovery
06:27:46 DISPATCHER: Starting worker discovery
06:27:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:27:46 DISPATCHER: Finished worker discovery
06:27:51 WORKER: done with job (8, 0, 25), trying to register it.
06:27:51 DISPATCHER: job (8, 0, 25) finished
06:27:51 WORKER: registered result for job (8, 0, 25) with dispatcher
06:27:51 DISPATCHER: register_result: lock acquired
06:27:51 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
06:27:51 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 579, 'last_n_outputs': 34, 'leak_rate': 0.8863716755737477, 'lr': 0.005787058631355974, 'optimizer': 'Adam', 'sparsity': 0.802016913301527, 'steps_to_train': 40, 'weight_decay': 0.09275297372427985}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.43764077140608093, 'info': {'music-speech': 0.43764077140608093, 'config': "{'batch_size': 128, 'hidden_dim': 579, 'last_n_outputs': 34, 'leak_rate': 0.8863716755737477, 'lr': 0.005787058631355974, 'optimizer': 'Adam', 'sparsity': 0.802016913301527, 'steps_to_train': 40, 'weight_decay': 0.09275297372427985}"}}
exception: None

06:27:51 job_callback for (8, 0, 25) started
06:27:51 DISPATCHER: Trying to submit another job.
06:27:51 job_callback for (8, 0, 25) got condition
06:27:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:27:51 done building a new model for budget 400.000000 based on 10/22 split
Best loss for this budget:-0.599878





06:27:51 HBMASTER: Trying to run another job!
06:27:51 job_callback for (8, 0, 25) finished
06:27:51 ITERATION: Advancing config (8, 0, 21) to next budget 1200.000000
06:27:51 HBMASTER: schedule new run for iteration 8
06:27:51 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
06:27:51 HBMASTER: submitting job (8, 0, 21) to dispatcher
06:27:51 DISPATCHER: trying to submit job (8, 0, 21)
06:27:51 DISPATCHER: trying to notify the job_runner thread.
06:27:51 HBMASTER: job (8, 0, 21) submitted to dispatcher
06:27:51 DISPATCHER: Trying to submit another job.
06:27:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:27:51 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216
06:27:51 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
06:27:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:27:51 WORKER: start processing job (8, 0, 21)
06:27:51 WORKER: args: ()
06:27:51 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 601, 'last_n_outputs': 28, 'leak_rate': 0.9158114738224625, 'lr': 0.0018643666834377702, 'optimizer': 'SGD', 'sparsity': 0.7946503588021077, 'steps_to_train': 32, 'weight_decay': 0.19204058603939483}, 'budget': 1200.0, 'working_directory': '.'}
06:28:46 DISPATCHER: Starting worker discovery
06:28:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:28:46 DISPATCHER: Finished worker discovery
06:29:46 DISPATCHER: Starting worker discovery
06:29:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:29:46 DISPATCHER: Finished worker discovery
06:30:46 DISPATCHER: Starting worker discovery
06:30:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:30:46 DISPATCHER: Finished worker discovery
06:31:46 DISPATCHER: Starting worker discovery
06:31:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:31:46 DISPATCHER: Finished worker discovery
06:32:46 DISPATCHER: Starting worker discovery
06:32:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:32:46 DISPATCHER: Finished worker discovery
06:33:46 DISPATCHER: Starting worker discovery
06:33:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:33:46 DISPATCHER: Finished worker discovery
06:34:46 DISPATCHER: Starting worker discovery
06:34:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:34:46 DISPATCHER: Finished worker discovery
06:35:46 DISPATCHER: Starting worker discovery
06:35:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:35:46 DISPATCHER: Finished worker discovery
06:36:46 DISPATCHER: Starting worker discovery
06:36:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:36:46 DISPATCHER: Finished worker discovery
06:37:46 DISPATCHER: Starting worker discovery
06:37:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:37:46 DISPATCHER: Finished worker discovery
06:38:46 DISPATCHER: Starting worker discovery
06:38:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:38:46 DISPATCHER: Finished worker discovery
06:39:46 DISPATCHER: Starting worker discovery
06:39:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:39:46 DISPATCHER: Finished worker discovery
06:40:46 DISPATCHER: Starting worker discovery
06:40:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:40:46 DISPATCHER: Finished worker discovery
06:41:46 DISPATCHER: Starting worker discovery
06:41:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:41:46 DISPATCHER: Finished worker discovery
06:42:46 DISPATCHER: Starting worker discovery
06:42:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:42:46 DISPATCHER: Finished worker discovery
06:43:46 DISPATCHER: Starting worker discovery
06:43:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:43:46 DISPATCHER: Finished worker discovery
06:44:46 DISPATCHER: Starting worker discovery
06:44:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:44:46 DISPATCHER: Finished worker discovery
06:45:46 DISPATCHER: Starting worker discovery
06:45:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:45:46 DISPATCHER: Finished worker discovery
06:46:46 DISPATCHER: Starting worker discovery
06:46:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:46:46 DISPATCHER: Finished worker discovery
06:47:46 DISPATCHER: Starting worker discovery
06:47:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:47:46 DISPATCHER: Finished worker discovery
06:48:06 WORKER: done with job (8, 0, 21), trying to register it.
06:48:06 WORKER: registered result for job (8, 0, 21) with dispatcher
06:48:06 DISPATCHER: job (8, 0, 21) finished
06:48:06 DISPATCHER: register_result: lock acquired
06:48:06 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
06:48:06 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 601, 'last_n_outputs': 28, 'leak_rate': 0.9158114738224625, 'lr': 0.0018643666834377702, 'optimizer': 'SGD', 'sparsity': 0.7946503588021077, 'steps_to_train': 32, 'weight_decay': 0.19204058603939483}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5180352587010095, 'info': {'music-speech': 0.5180352587010095, 'config': "{'batch_size': 128, 'hidden_dim': 601, 'last_n_outputs': 28, 'leak_rate': 0.9158114738224625, 'lr': 0.0018643666834377702, 'optimizer': 'SGD', 'sparsity': 0.7946503588021077, 'steps_to_train': 32, 'weight_decay': 0.19204058603939483}"}}
exception: None

06:48:06 job_callback for (8, 0, 21) started
06:48:06 DISPATCHER: Trying to submit another job.
06:48:06 job_callback for (8, 0, 21) got condition
06:48:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:48:06 HBMASTER: Trying to run another job!
06:48:06 job_callback for (8, 0, 21) finished
06:48:06 start sampling a new configuration.
06:48:06 done sampling a new configuration.
06:48:06 HBMASTER: schedule new run for iteration 9
06:48:06 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
06:48:06 HBMASTER: submitting job (9, 0, 0) to dispatcher
06:48:06 DISPATCHER: trying to submit job (9, 0, 0)
06:48:06 DISPATCHER: trying to notify the job_runner thread.
06:48:06 HBMASTER: job (9, 0, 0) submitted to dispatcher
06:48:06 DISPATCHER: Trying to submit another job.
06:48:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:48:06 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
06:48:06 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
06:48:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:48:06 WORKER: start processing job (9, 0, 0)
06:48:06 WORKER: args: ()
06:48:06 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 609, 'last_n_outputs': 34, 'leak_rate': 0.7920965141223497, 'lr': 0.023600765982046443, 'optimizer': 'SGD', 'sparsity': 0.9266429736206316, 'steps_to_train': 29, 'weight_decay': 0.03004330286943364}, 'budget': 133.33333333333331, 'working_directory': '.'}
06:48:46 DISPATCHER: Starting worker discovery
06:48:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:48:46 DISPATCHER: Finished worker discovery
06:49:46 DISPATCHER: Starting worker discovery
06:49:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:49:46 DISPATCHER: Finished worker discovery
06:50:31 WORKER: done with job (9, 0, 0), trying to register it.
06:50:31 WORKER: registered result for job (9, 0, 0) with dispatcher
06:50:31 DISPATCHER: job (9, 0, 0) finished
06:50:31 DISPATCHER: register_result: lock acquired
06:50:31 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
06:50:31 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 609, 'last_n_outputs': 34, 'leak_rate': 0.7920965141223497, 'lr': 0.023600765982046443, 'optimizer': 'SGD', 'sparsity': 0.9266429736206316, 'steps_to_train': 29, 'weight_decay': 0.03004330286943364}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.41713969111918003, 'info': {'music-speech': 0.41713969111918003, 'config': "{'batch_size': 16, 'hidden_dim': 609, 'last_n_outputs': 34, 'leak_rate': 0.7920965141223497, 'lr': 0.023600765982046443, 'optimizer': 'SGD', 'sparsity': 0.9266429736206316, 'steps_to_train': 29, 'weight_decay': 0.03004330286943364}"}}
exception: None

06:50:31 job_callback for (9, 0, 0) started
06:50:31 DISPATCHER: Trying to submit another job.
06:50:31 job_callback for (9, 0, 0) got condition
06:50:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:50:31 HBMASTER: Trying to run another job!
06:50:31 job_callback for (9, 0, 0) finished
06:50:31 start sampling a new configuration.
06:50:31 best_vector: [2, 0.5196163096121476, 0.4020233162729833, 0.27983992731496155, 0.6576230431443102, 0, 0.08510304312705817, 0.2763187361082369, 0.2669473968490135], 0.03565003087011736, 0.40610877147717417, 0.014477790239786695
06:50:31 done sampling a new configuration.
06:50:31 HBMASTER: schedule new run for iteration 9
06:50:31 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
06:50:31 HBMASTER: submitting job (9, 0, 1) to dispatcher
06:50:31 DISPATCHER: trying to submit job (9, 0, 1)
06:50:31 DISPATCHER: trying to notify the job_runner thread.
06:50:31 HBMASTER: job (9, 0, 1) submitted to dispatcher
06:50:31 DISPATCHER: Trying to submit another job.
06:50:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:50:31 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
06:50:31 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
06:50:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:50:31 WORKER: start processing job (9, 0, 1)
06:50:31 WORKER: args: ()
06:50:31 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 616, 'last_n_outputs': 26, 'leak_rate': 0.8199599818287404, 'lr': 0.020665508033431812, 'optimizer': 'Adam', 'sparsity': 0.770424730350494, 'steps_to_train': 35, 'weight_decay': 0.02224879889873549}, 'budget': 133.33333333333331, 'working_directory': '.'}
06:50:46 DISPATCHER: Starting worker discovery
06:50:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:50:46 DISPATCHER: Finished worker discovery
06:51:46 DISPATCHER: Starting worker discovery
06:51:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:51:46 DISPATCHER: Finished worker discovery
06:52:46 DISPATCHER: Starting worker discovery
06:52:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:52:46 DISPATCHER: Finished worker discovery
06:53:03 WORKER: done with job (9, 0, 1), trying to register it.
06:53:03 WORKER: registered result for job (9, 0, 1) with dispatcher
06:53:03 DISPATCHER: job (9, 0, 1) finished
06:53:03 DISPATCHER: register_result: lock acquired
06:53:03 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
06:53:03 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 616, 'last_n_outputs': 26, 'leak_rate': 0.8199599818287404, 'lr': 0.020665508033431812, 'optimizer': 'Adam', 'sparsity': 0.770424730350494, 'steps_to_train': 35, 'weight_decay': 0.02224879889873549}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.46333025874585987, 'info': {'music-speech': 0.46333025874585987, 'config': "{'batch_size': 64, 'hidden_dim': 616, 'last_n_outputs': 26, 'leak_rate': 0.8199599818287404, 'lr': 0.020665508033431812, 'optimizer': 'Adam', 'sparsity': 0.770424730350494, 'steps_to_train': 35, 'weight_decay': 0.02224879889873549}"}}
exception: None

06:53:03 job_callback for (9, 0, 1) started
06:53:03 job_callback for (9, 0, 1) got condition
06:53:03 DISPATCHER: Trying to submit another job.
06:53:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:53:03 HBMASTER: Trying to run another job!
06:53:03 job_callback for (9, 0, 1) finished
06:53:03 start sampling a new configuration.
06:53:03 done sampling a new configuration.
06:53:03 HBMASTER: schedule new run for iteration 9
06:53:03 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
06:53:03 HBMASTER: submitting job (9, 0, 2) to dispatcher
06:53:03 DISPATCHER: trying to submit job (9, 0, 2)
06:53:03 DISPATCHER: trying to notify the job_runner thread.
06:53:03 HBMASTER: job (9, 0, 2) submitted to dispatcher
06:53:03 DISPATCHER: Trying to submit another job.
06:53:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:53:03 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
06:53:03 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
06:53:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:53:03 WORKER: start processing job (9, 0, 2)
06:53:03 WORKER: args: ()
06:53:03 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 700, 'last_n_outputs': 21, 'leak_rate': 0.8811914299123802, 'lr': 0.002432999186933348, 'optimizer': 'SGD', 'sparsity': 0.8669060185512667, 'steps_to_train': 74, 'weight_decay': 0.09437251886221008}, 'budget': 133.33333333333331, 'working_directory': '.'}
06:53:46 DISPATCHER: Starting worker discovery
06:53:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:53:46 DISPATCHER: Finished worker discovery
06:54:46 DISPATCHER: Starting worker discovery
06:54:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:54:46 DISPATCHER: Finished worker discovery
06:55:38 WORKER: done with job (9, 0, 2), trying to register it.
06:55:38 WORKER: registered result for job (9, 0, 2) with dispatcher
06:55:38 DISPATCHER: job (9, 0, 2) finished
06:55:38 DISPATCHER: register_result: lock acquired
06:55:38 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
06:55:38 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 700, 'last_n_outputs': 21, 'leak_rate': 0.8811914299123802, 'lr': 0.002432999186933348, 'optimizer': 'SGD', 'sparsity': 0.8669060185512667, 'steps_to_train': 74, 'weight_decay': 0.09437251886221008}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6214922817112957, 'info': {'music-speech': 0.6214922817112957, 'config': "{'batch_size': 64, 'hidden_dim': 700, 'last_n_outputs': 21, 'leak_rate': 0.8811914299123802, 'lr': 0.002432999186933348, 'optimizer': 'SGD', 'sparsity': 0.8669060185512667, 'steps_to_train': 74, 'weight_decay': 0.09437251886221008}"}}
exception: None

06:55:38 job_callback for (9, 0, 2) started
06:55:38 DISPATCHER: Trying to submit another job.
06:55:38 job_callback for (9, 0, 2) got condition
06:55:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:55:38 HBMASTER: Trying to run another job!
06:55:38 job_callback for (9, 0, 2) finished
06:55:38 start sampling a new configuration.
06:55:38 best_vector: [0, 0.5472617106701669, 0.22918340348100696, 0.4119735704852405, 0.4738759022924837, 0, 0.04491238948161391, 0.17044036742896412, 0.40778004261580625], 0.013527052479965263, 2.6287269734448633, 0.035558927725288916
06:55:38 done sampling a new configuration.
06:55:38 HBMASTER: schedule new run for iteration 9
06:55:38 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
06:55:38 HBMASTER: submitting job (9, 0, 3) to dispatcher
06:55:38 DISPATCHER: trying to submit job (9, 0, 3)
06:55:38 DISPATCHER: trying to notify the job_runner thread.
06:55:38 HBMASTER: job (9, 0, 3) submitted to dispatcher
06:55:38 DISPATCHER: Trying to submit another job.
06:55:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:55:38 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
06:55:38 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
06:55:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:55:38 WORKER: start processing job (9, 0, 3)
06:55:38 WORKER: args: ()
06:55:38 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 638, 'last_n_outputs': 19, 'leak_rate': 0.8529933926213101, 'lr': 0.008866491551516545, 'optimizer': 'Adam', 'sparsity': 0.7607789734755873, 'steps_to_train': 25, 'weight_decay': 0.03392611009330238}, 'budget': 133.33333333333331, 'working_directory': '.'}
06:55:46 DISPATCHER: Starting worker discovery
06:55:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:55:47 DISPATCHER: Finished worker discovery
06:56:47 DISPATCHER: Starting worker discovery
06:56:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:56:47 DISPATCHER: Finished worker discovery
06:57:47 DISPATCHER: Starting worker discovery
06:57:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:57:47 DISPATCHER: Finished worker discovery
06:58:01 WORKER: done with job (9, 0, 3), trying to register it.
06:58:01 WORKER: registered result for job (9, 0, 3) with dispatcher
06:58:01 DISPATCHER: job (9, 0, 3) finished
06:58:01 DISPATCHER: register_result: lock acquired
06:58:01 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
06:58:01 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 638, 'last_n_outputs': 19, 'leak_rate': 0.8529933926213101, 'lr': 0.008866491551516545, 'optimizer': 'Adam', 'sparsity': 0.7607789734755873, 'steps_to_train': 25, 'weight_decay': 0.03392611009330238}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4611627650076361, 'info': {'music-speech': 0.4611627650076361, 'config': "{'batch_size': 16, 'hidden_dim': 638, 'last_n_outputs': 19, 'leak_rate': 0.8529933926213101, 'lr': 0.008866491551516545, 'optimizer': 'Adam', 'sparsity': 0.7607789734755873, 'steps_to_train': 25, 'weight_decay': 0.03392611009330238}"}}
exception: None

06:58:01 job_callback for (9, 0, 3) started
06:58:01 DISPATCHER: Trying to submit another job.
06:58:01 job_callback for (9, 0, 3) got condition
06:58:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:58:01 HBMASTER: Trying to run another job!
06:58:01 job_callback for (9, 0, 3) finished
06:58:01 start sampling a new configuration.
06:58:01 best_vector: [3, 0.3005642287622266, 0.9832968792834609, 0.8197999383813266, 0.5628393900554837, 0, 0.4041577067337945, 0.15604201189714273, 0.8881271890045397], 7.05676129391036e-30, 0.001417080666825093, -0.000149117863518826
06:58:01 done sampling a new configuration.
06:58:01 HBMASTER: schedule new run for iteration 9
06:58:01 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
06:58:01 HBMASTER: submitting job (9, 0, 4) to dispatcher
06:58:01 DISPATCHER: trying to submit job (9, 0, 4)
06:58:01 DISPATCHER: trying to notify the job_runner thread.
06:58:01 HBMASTER: job (9, 0, 4) submitted to dispatcher
06:58:01 DISPATCHER: Trying to submit another job.
06:58:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:58:01 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
06:58:01 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
06:58:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:58:01 WORKER: start processing job (9, 0, 4)
06:58:01 WORKER: args: ()
06:58:01 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 440, 'last_n_outputs': 50, 'leak_rate': 0.9549499845953316, 'lr': 0.013356072877237246, 'optimizer': 'Adam', 'sparsity': 0.8469978496161107, 'steps_to_train': 24, 'weight_decay': 0.14304744752720777}, 'budget': 133.33333333333331, 'working_directory': '.'}
06:58:47 DISPATCHER: Starting worker discovery
06:58:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:58:47 DISPATCHER: Finished worker discovery
06:59:47 DISPATCHER: Starting worker discovery
06:59:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:59:47 DISPATCHER: Finished worker discovery
07:00:28 WORKER: done with job (9, 0, 4), trying to register it.
07:00:28 WORKER: registered result for job (9, 0, 4) with dispatcher
07:00:28 DISPATCHER: job (9, 0, 4) finished
07:00:28 DISPATCHER: register_result: lock acquired
07:00:28 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:00:28 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 440, 'last_n_outputs': 50, 'leak_rate': 0.9549499845953316, 'lr': 0.013356072877237246, 'optimizer': 'Adam', 'sparsity': 0.8469978496161107, 'steps_to_train': 24, 'weight_decay': 0.14304744752720777}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.1341755377708081, 'info': {'music-speech': 0.1341755377708081, 'config': "{'batch_size': 128, 'hidden_dim': 440, 'last_n_outputs': 50, 'leak_rate': 0.9549499845953316, 'lr': 0.013356072877237246, 'optimizer': 'Adam', 'sparsity': 0.8469978496161107, 'steps_to_train': 24, 'weight_decay': 0.14304744752720777}"}}
exception: None

07:00:28 job_callback for (9, 0, 4) started
07:00:28 job_callback for (9, 0, 4) got condition
07:00:28 DISPATCHER: Trying to submit another job.
07:00:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:00:28 HBMASTER: Trying to run another job!
07:00:28 job_callback for (9, 0, 4) finished
07:00:28 start sampling a new configuration.
07:00:28 best_vector: [3, 0.5958513233945526, 0.17556162369035477, 0.7687830135569743, 0.32804921219776895, 1, 0.43555833918847053, 0.0648391210059722, 0.8434058453858622], 8.494578704329298e-31, 0.011772214194570307, -0.0001330092434626132
07:00:28 done sampling a new configuration.
07:00:28 HBMASTER: schedule new run for iteration 9
07:00:28 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
07:00:28 HBMASTER: submitting job (9, 0, 5) to dispatcher
07:00:28 DISPATCHER: trying to submit job (9, 0, 5)
07:00:28 DISPATCHER: trying to notify the job_runner thread.
07:00:28 HBMASTER: job (9, 0, 5) submitted to dispatcher
07:00:28 DISPATCHER: Trying to submit another job.
07:00:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:00:28 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:00:28 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:00:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:00:28 WORKER: start processing job (9, 0, 5)
07:00:28 WORKER: args: ()
07:00:28 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 677, 'last_n_outputs': 17, 'leak_rate': 0.9421957533892436, 'lr': 0.004530002319610216, 'optimizer': 'SGD', 'sparsity': 0.854534001405233, 'steps_to_train': 15, 'weight_decay': 0.12511123276385294}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:00:47 DISPATCHER: Starting worker discovery
07:00:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:00:47 DISPATCHER: Finished worker discovery
07:01:47 DISPATCHER: Starting worker discovery
07:01:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:01:47 DISPATCHER: Finished worker discovery
07:02:47 DISPATCHER: Starting worker discovery
07:02:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:02:47 DISPATCHER: Finished worker discovery
07:02:53 WORKER: done with job (9, 0, 5), trying to register it.
07:02:53 WORKER: registered result for job (9, 0, 5) with dispatcher
07:02:53 DISPATCHER: job (9, 0, 5) finished
07:02:53 DISPATCHER: register_result: lock acquired
07:02:53 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:02:53 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 677, 'last_n_outputs': 17, 'leak_rate': 0.9421957533892436, 'lr': 0.004530002319610216, 'optimizer': 'SGD', 'sparsity': 0.854534001405233, 'steps_to_train': 15, 'weight_decay': 0.12511123276385294}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5285658748329742, 'info': {'music-speech': 0.5285658748329742, 'config': "{'batch_size': 128, 'hidden_dim': 677, 'last_n_outputs': 17, 'leak_rate': 0.9421957533892436, 'lr': 0.004530002319610216, 'optimizer': 'SGD', 'sparsity': 0.854534001405233, 'steps_to_train': 15, 'weight_decay': 0.12511123276385294}"}}
exception: None

07:02:53 job_callback for (9, 0, 5) started
07:02:53 DISPATCHER: Trying to submit another job.
07:02:53 job_callback for (9, 0, 5) got condition
07:02:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:02:53 HBMASTER: Trying to run another job!
07:02:53 job_callback for (9, 0, 5) finished
07:02:53 start sampling a new configuration.
07:02:54 best_vector: [3, 0.0665161895899517, 0.4206741380718485, 0.7334342491561049, 0.8567802721275657, 0, 0.5648261599900184, 0.7123564417315296, 0.6367158884925279], 0.011521663179728346, 0.10086700736714875, 0.0011621556848314656
07:02:54 done sampling a new configuration.
07:02:54 HBMASTER: schedule new run for iteration 9
07:02:54 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
07:02:54 HBMASTER: submitting job (9, 0, 6) to dispatcher
07:02:54 DISPATCHER: trying to submit job (9, 0, 6)
07:02:54 DISPATCHER: trying to notify the job_runner thread.
07:02:54 HBMASTER: job (9, 0, 6) submitted to dispatcher
07:02:54 DISPATCHER: Trying to submit another job.
07:02:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:02:54 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:02:54 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:02:54 WORKER: start processing job (9, 0, 6)
07:02:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:02:54 WORKER: args: ()
07:02:54 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 253, 'last_n_outputs': 27, 'leak_rate': 0.9333585622890263, 'lr': 0.05170833386530703, 'optimizer': 'Adam', 'sparsity': 0.8855582783976044, 'steps_to_train': 74, 'weight_decay': 0.06735757907806386}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:03:47 DISPATCHER: Starting worker discovery
07:03:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:03:47 DISPATCHER: Finished worker discovery
07:04:47 DISPATCHER: Starting worker discovery
07:04:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:04:47 DISPATCHER: Finished worker discovery
07:05:22 WORKER: done with job (9, 0, 6), trying to register it.
07:05:22 WORKER: registered result for job (9, 0, 6) with dispatcher
07:05:22 DISPATCHER: job (9, 0, 6) finished
07:05:22 DISPATCHER: register_result: lock acquired
07:05:22 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:05:22 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 253, 'last_n_outputs': 27, 'leak_rate': 0.9333585622890263, 'lr': 0.05170833386530703, 'optimizer': 'Adam', 'sparsity': 0.8855582783976044, 'steps_to_train': 74, 'weight_decay': 0.06735757907806386}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.33721726407883257, 'info': {'music-speech': 0.33721726407883257, 'config': "{'batch_size': 128, 'hidden_dim': 253, 'last_n_outputs': 27, 'leak_rate': 0.9333585622890263, 'lr': 0.05170833386530703, 'optimizer': 'Adam', 'sparsity': 0.8855582783976044, 'steps_to_train': 74, 'weight_decay': 0.06735757907806386}"}}
exception: None

07:05:22 job_callback for (9, 0, 6) started
07:05:22 job_callback for (9, 0, 6) got condition
07:05:22 DISPATCHER: Trying to submit another job.
07:05:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:05:22 HBMASTER: Trying to run another job!
07:05:22 job_callback for (9, 0, 6) finished
07:05:22 start sampling a new configuration.
07:05:22 done sampling a new configuration.
07:05:22 HBMASTER: schedule new run for iteration 9
07:05:22 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
07:05:22 HBMASTER: submitting job (9, 0, 7) to dispatcher
07:05:22 DISPATCHER: trying to submit job (9, 0, 7)
07:05:22 DISPATCHER: trying to notify the job_runner thread.
07:05:22 HBMASTER: job (9, 0, 7) submitted to dispatcher
07:05:22 DISPATCHER: Trying to submit another job.
07:05:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:05:22 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:05:22 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:05:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:05:22 WORKER: start processing job (9, 0, 7)
07:05:22 WORKER: args: ()
07:05:22 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 684, 'last_n_outputs': 24, 'leak_rate': 0.8166761646995147, 'lr': 0.003994001064471765, 'optimizer': 'Adam', 'sparsity': 0.9152473936980519, 'steps_to_train': 85, 'weight_decay': 0.02621720780210252}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:05:47 DISPATCHER: Starting worker discovery
07:05:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:05:47 DISPATCHER: Finished worker discovery
07:06:47 DISPATCHER: Starting worker discovery
07:06:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:06:47 DISPATCHER: Finished worker discovery
07:07:47 DISPATCHER: Starting worker discovery
07:07:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:07:47 DISPATCHER: Finished worker discovery
07:07:59 WORKER: done with job (9, 0, 7), trying to register it.
07:07:59 DISPATCHER: job (9, 0, 7) finished
07:07:59 WORKER: registered result for job (9, 0, 7) with dispatcher
07:07:59 DISPATCHER: register_result: lock acquired
07:07:59 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:07:59 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 684, 'last_n_outputs': 24, 'leak_rate': 0.8166761646995147, 'lr': 0.003994001064471765, 'optimizer': 'Adam', 'sparsity': 0.9152473936980519, 'steps_to_train': 85, 'weight_decay': 0.02621720780210252}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5120684834078526, 'info': {'music-speech': 0.5120684834078526, 'config': "{'batch_size': 128, 'hidden_dim': 684, 'last_n_outputs': 24, 'leak_rate': 0.8166761646995147, 'lr': 0.003994001064471765, 'optimizer': 'Adam', 'sparsity': 0.9152473936980519, 'steps_to_train': 85, 'weight_decay': 0.02621720780210252}"}}
exception: None

07:07:59 job_callback for (9, 0, 7) started
07:07:59 DISPATCHER: Trying to submit another job.
07:07:59 job_callback for (9, 0, 7) got condition
07:07:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:07:59 HBMASTER: Trying to run another job!
07:07:59 job_callback for (9, 0, 7) finished
07:07:59 start sampling a new configuration.
07:07:59 best_vector: [3, 0.4992918572761836, 0.47257358043146686, 0.7618170929351925, 0.5739532319245847, 1, 0.5017200273980573, 0.3345635779809746, 0.7208076794334665], 2.8845864750643643e-31, 0.03466701409870844, -0.000991446581719553
07:07:59 done sampling a new configuration.
07:07:59 HBMASTER: schedule new run for iteration 9
07:07:59 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
07:07:59 HBMASTER: submitting job (9, 0, 8) to dispatcher
07:07:59 DISPATCHER: trying to submit job (9, 0, 8)
07:07:59 DISPATCHER: trying to notify the job_runner thread.
07:07:59 HBMASTER: job (9, 0, 8) submitted to dispatcher
07:07:59 DISPATCHER: Trying to submit another job.
07:07:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:07:59 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:07:59 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:07:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:07:59 WORKER: start processing job (9, 0, 8)
07:07:59 WORKER: args: ()
07:07:59 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 599, 'last_n_outputs': 29, 'leak_rate': 0.9404542732337982, 'lr': 0.014057447293279242, 'optimizer': 'SGD', 'sparsity': 0.8704128065755338, 'steps_to_train': 40, 'weight_decay': 0.08665475766071472}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:08:47 DISPATCHER: Starting worker discovery
07:08:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:08:47 DISPATCHER: Finished worker discovery
07:09:47 DISPATCHER: Starting worker discovery
07:09:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:09:47 DISPATCHER: Finished worker discovery
07:10:28 WORKER: done with job (9, 0, 8), trying to register it.
07:10:28 DISPATCHER: job (9, 0, 8) finished
07:10:28 WORKER: registered result for job (9, 0, 8) with dispatcher
07:10:28 DISPATCHER: register_result: lock acquired
07:10:28 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:10:28 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 599, 'last_n_outputs': 29, 'leak_rate': 0.9404542732337982, 'lr': 0.014057447293279242, 'optimizer': 'SGD', 'sparsity': 0.8704128065755338, 'steps_to_train': 40, 'weight_decay': 0.08665475766071472}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.36626916481240845, 'info': {'music-speech': 0.36626916481240845, 'config': "{'batch_size': 128, 'hidden_dim': 599, 'last_n_outputs': 29, 'leak_rate': 0.9404542732337982, 'lr': 0.014057447293279242, 'optimizer': 'SGD', 'sparsity': 0.8704128065755338, 'steps_to_train': 40, 'weight_decay': 0.08665475766071472}"}}
exception: None

07:10:28 job_callback for (9, 0, 8) started
07:10:28 DISPATCHER: Trying to submit another job.
07:10:28 job_callback for (9, 0, 8) got condition
07:10:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:10:28 HBMASTER: Trying to run another job!
07:10:28 job_callback for (9, 0, 8) finished
07:10:28 ITERATION: Advancing config (9, 0, 2) to next budget 400.000000
07:10:28 ITERATION: Advancing config (9, 0, 5) to next budget 400.000000
07:10:28 ITERATION: Advancing config (9, 0, 7) to next budget 400.000000
07:10:28 HBMASTER: schedule new run for iteration 9
07:10:28 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
07:10:28 HBMASTER: submitting job (9, 0, 2) to dispatcher
07:10:28 DISPATCHER: trying to submit job (9, 0, 2)
07:10:28 DISPATCHER: trying to notify the job_runner thread.
07:10:28 HBMASTER: job (9, 0, 2) submitted to dispatcher
07:10:28 DISPATCHER: Trying to submit another job.
07:10:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:10:28 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:10:28 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:10:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:10:28 WORKER: start processing job (9, 0, 2)
07:10:28 WORKER: args: ()
07:10:28 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 700, 'last_n_outputs': 21, 'leak_rate': 0.8811914299123802, 'lr': 0.002432999186933348, 'optimizer': 'SGD', 'sparsity': 0.8669060185512667, 'steps_to_train': 74, 'weight_decay': 0.09437251886221008}, 'budget': 400.0, 'working_directory': '.'}
07:10:47 DISPATCHER: Starting worker discovery
07:10:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:10:47 DISPATCHER: Finished worker discovery
07:11:47 DISPATCHER: Starting worker discovery
07:11:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:11:47 DISPATCHER: Finished worker discovery
07:12:47 DISPATCHER: Starting worker discovery
07:12:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:12:47 DISPATCHER: Finished worker discovery
07:13:47 DISPATCHER: Starting worker discovery
07:13:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:13:47 DISPATCHER: Finished worker discovery
07:14:47 DISPATCHER: Starting worker discovery
07:14:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:14:47 DISPATCHER: Finished worker discovery
07:15:47 DISPATCHER: Starting worker discovery
07:15:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:15:47 DISPATCHER: Finished worker discovery
07:16:47 DISPATCHER: Starting worker discovery
07:16:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:16:47 DISPATCHER: Finished worker discovery
07:17:22 WORKER: done with job (9, 0, 2), trying to register it.
07:17:22 DISPATCHER: job (9, 0, 2) finished
07:17:22 WORKER: registered result for job (9, 0, 2) with dispatcher
07:17:22 DISPATCHER: register_result: lock acquired
07:17:22 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:17:22 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 700, 'last_n_outputs': 21, 'leak_rate': 0.8811914299123802, 'lr': 0.002432999186933348, 'optimizer': 'SGD', 'sparsity': 0.8669060185512667, 'steps_to_train': 74, 'weight_decay': 0.09437251886221008}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.3569732122978075, 'info': {'music-speech': 0.3569732122978075, 'config': "{'batch_size': 64, 'hidden_dim': 700, 'last_n_outputs': 21, 'leak_rate': 0.8811914299123802, 'lr': 0.002432999186933348, 'optimizer': 'SGD', 'sparsity': 0.8669060185512667, 'steps_to_train': 74, 'weight_decay': 0.09437251886221008}"}}
exception: None

07:17:22 job_callback for (9, 0, 2) started
07:17:22 DISPATCHER: Trying to submit another job.
07:17:22 job_callback for (9, 0, 2) got condition
07:17:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:17:22 done building a new model for budget 400.000000 based on 10/23 split
Best loss for this budget:-0.599878





07:17:22 HBMASTER: Trying to run another job!
07:17:22 job_callback for (9, 0, 2) finished
07:17:22 HBMASTER: schedule new run for iteration 9
07:17:22 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
07:17:22 HBMASTER: submitting job (9, 0, 5) to dispatcher
07:17:22 DISPATCHER: trying to submit job (9, 0, 5)
07:17:22 DISPATCHER: trying to notify the job_runner thread.
07:17:22 HBMASTER: job (9, 0, 5) submitted to dispatcher
07:17:22 DISPATCHER: Trying to submit another job.
07:17:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:17:22 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:17:22 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:17:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:17:22 WORKER: start processing job (9, 0, 5)
07:17:22 WORKER: args: ()
07:17:22 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 677, 'last_n_outputs': 17, 'leak_rate': 0.9421957533892436, 'lr': 0.004530002319610216, 'optimizer': 'SGD', 'sparsity': 0.854534001405233, 'steps_to_train': 15, 'weight_decay': 0.12511123276385294}, 'budget': 400.0, 'working_directory': '.'}
07:17:47 DISPATCHER: Starting worker discovery
07:17:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:17:47 DISPATCHER: Finished worker discovery
07:18:47 DISPATCHER: Starting worker discovery
07:18:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:18:47 DISPATCHER: Finished worker discovery
07:19:47 DISPATCHER: Starting worker discovery
07:19:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:19:47 DISPATCHER: Finished worker discovery
07:20:47 DISPATCHER: Starting worker discovery
07:20:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:20:47 DISPATCHER: Finished worker discovery
07:21:47 DISPATCHER: Starting worker discovery
07:21:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:21:47 DISPATCHER: Finished worker discovery
07:22:47 DISPATCHER: Starting worker discovery
07:22:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:22:47 DISPATCHER: Finished worker discovery
07:23:47 DISPATCHER: Starting worker discovery
07:23:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:23:47 DISPATCHER: Finished worker discovery
07:24:15 WORKER: done with job (9, 0, 5), trying to register it.
07:24:15 WORKER: registered result for job (9, 0, 5) with dispatcher
07:24:15 DISPATCHER: job (9, 0, 5) finished
07:24:15 DISPATCHER: register_result: lock acquired
07:24:15 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:24:15 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 677, 'last_n_outputs': 17, 'leak_rate': 0.9421957533892436, 'lr': 0.004530002319610216, 'optimizer': 'SGD', 'sparsity': 0.854534001405233, 'steps_to_train': 15, 'weight_decay': 0.12511123276385294}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.43030176007663, 'info': {'music-speech': 0.43030176007663, 'config': "{'batch_size': 128, 'hidden_dim': 677, 'last_n_outputs': 17, 'leak_rate': 0.9421957533892436, 'lr': 0.004530002319610216, 'optimizer': 'SGD', 'sparsity': 0.854534001405233, 'steps_to_train': 15, 'weight_decay': 0.12511123276385294}"}}
exception: None

07:24:15 job_callback for (9, 0, 5) started
07:24:15 DISPATCHER: Trying to submit another job.
07:24:15 job_callback for (9, 0, 5) got condition
07:24:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:24:15 done building a new model for budget 400.000000 based on 10/24 split
Best loss for this budget:-0.599878





07:24:15 HBMASTER: Trying to run another job!
07:24:15 job_callback for (9, 0, 5) finished
07:24:15 HBMASTER: schedule new run for iteration 9
07:24:15 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
07:24:15 HBMASTER: submitting job (9, 0, 7) to dispatcher
07:24:15 DISPATCHER: trying to submit job (9, 0, 7)
07:24:15 DISPATCHER: trying to notify the job_runner thread.
07:24:15 HBMASTER: job (9, 0, 7) submitted to dispatcher
07:24:15 DISPATCHER: Trying to submit another job.
07:24:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:24:15 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:24:15 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:24:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:24:15 WORKER: start processing job (9, 0, 7)
07:24:15 WORKER: args: ()
07:24:15 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 684, 'last_n_outputs': 24, 'leak_rate': 0.8166761646995147, 'lr': 0.003994001064471765, 'optimizer': 'Adam', 'sparsity': 0.9152473936980519, 'steps_to_train': 85, 'weight_decay': 0.02621720780210252}, 'budget': 400.0, 'working_directory': '.'}
07:24:47 DISPATCHER: Starting worker discovery
07:24:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:24:47 DISPATCHER: Finished worker discovery
07:25:47 DISPATCHER: Starting worker discovery
07:25:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:25:47 DISPATCHER: Finished worker discovery
07:26:47 DISPATCHER: Starting worker discovery
07:26:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:26:47 DISPATCHER: Finished worker discovery
07:27:47 DISPATCHER: Starting worker discovery
07:27:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:27:47 DISPATCHER: Finished worker discovery
07:28:47 DISPATCHER: Starting worker discovery
07:28:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:28:47 DISPATCHER: Finished worker discovery
07:29:47 DISPATCHER: Starting worker discovery
07:29:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:29:47 DISPATCHER: Finished worker discovery
07:30:47 DISPATCHER: Starting worker discovery
07:30:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:30:47 DISPATCHER: Finished worker discovery
07:31:23 WORKER: done with job (9, 0, 7), trying to register it.
07:31:23 WORKER: registered result for job (9, 0, 7) with dispatcher
07:31:23 DISPATCHER: job (9, 0, 7) finished
07:31:23 DISPATCHER: register_result: lock acquired
07:31:23 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:31:23 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 684, 'last_n_outputs': 24, 'leak_rate': 0.8166761646995147, 'lr': 0.003994001064471765, 'optimizer': 'Adam', 'sparsity': 0.9152473936980519, 'steps_to_train': 85, 'weight_decay': 0.02621720780210252}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.4906279683753425, 'info': {'music-speech': 0.4906279683753425, 'config': "{'batch_size': 128, 'hidden_dim': 684, 'last_n_outputs': 24, 'leak_rate': 0.8166761646995147, 'lr': 0.003994001064471765, 'optimizer': 'Adam', 'sparsity': 0.9152473936980519, 'steps_to_train': 85, 'weight_decay': 0.02621720780210252}"}}
exception: None

07:31:23 job_callback for (9, 0, 7) started
07:31:23 DISPATCHER: Trying to submit another job.
07:31:23 job_callback for (9, 0, 7) got condition
07:31:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:31:23 done building a new model for budget 400.000000 based on 10/25 split
Best loss for this budget:-0.599878





07:31:23 HBMASTER: Trying to run another job!
07:31:23 job_callback for (9, 0, 7) finished
07:31:23 ITERATION: Advancing config (9, 0, 7) to next budget 1200.000000
07:31:23 HBMASTER: schedule new run for iteration 9
07:31:23 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
07:31:23 HBMASTER: submitting job (9, 0, 7) to dispatcher
07:31:23 DISPATCHER: trying to submit job (9, 0, 7)
07:31:23 DISPATCHER: trying to notify the job_runner thread.
07:31:23 HBMASTER: job (9, 0, 7) submitted to dispatcher
07:31:23 DISPATCHER: Trying to submit another job.
07:31:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:31:23 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:31:23 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:31:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:31:23 WORKER: start processing job (9, 0, 7)
07:31:23 WORKER: args: ()
07:31:23 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 684, 'last_n_outputs': 24, 'leak_rate': 0.8166761646995147, 'lr': 0.003994001064471765, 'optimizer': 'Adam', 'sparsity': 0.9152473936980519, 'steps_to_train': 85, 'weight_decay': 0.02621720780210252}, 'budget': 1200.0, 'working_directory': '.'}
07:31:47 DISPATCHER: Starting worker discovery
07:31:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:31:47 DISPATCHER: Finished worker discovery
07:32:47 DISPATCHER: Starting worker discovery
07:32:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:32:47 DISPATCHER: Finished worker discovery
07:33:47 DISPATCHER: Starting worker discovery
07:33:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:33:47 DISPATCHER: Finished worker discovery
07:34:47 DISPATCHER: Starting worker discovery
07:34:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:34:47 DISPATCHER: Finished worker discovery
07:35:47 DISPATCHER: Starting worker discovery
07:35:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:35:47 DISPATCHER: Finished worker discovery
07:36:47 DISPATCHER: Starting worker discovery
07:36:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:36:47 DISPATCHER: Finished worker discovery
07:37:47 DISPATCHER: Starting worker discovery
07:37:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:37:47 DISPATCHER: Finished worker discovery
07:38:47 DISPATCHER: Starting worker discovery
07:38:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:38:47 DISPATCHER: Finished worker discovery
07:39:47 DISPATCHER: Starting worker discovery
07:39:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:39:47 DISPATCHER: Finished worker discovery
07:40:47 DISPATCHER: Starting worker discovery
07:40:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:40:47 DISPATCHER: Finished worker discovery
07:41:47 DISPATCHER: Starting worker discovery
07:41:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:41:47 DISPATCHER: Finished worker discovery
07:42:47 DISPATCHER: Starting worker discovery
07:42:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:42:47 DISPATCHER: Finished worker discovery
07:43:47 DISPATCHER: Starting worker discovery
07:43:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:43:47 DISPATCHER: Finished worker discovery
07:44:47 DISPATCHER: Starting worker discovery
07:44:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:44:47 DISPATCHER: Finished worker discovery
07:45:47 DISPATCHER: Starting worker discovery
07:45:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:45:47 DISPATCHER: Finished worker discovery
07:46:47 DISPATCHER: Starting worker discovery
07:46:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:46:47 DISPATCHER: Finished worker discovery
07:47:47 DISPATCHER: Starting worker discovery
07:47:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:47:47 DISPATCHER: Finished worker discovery
07:48:47 DISPATCHER: Starting worker discovery
07:48:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:48:47 DISPATCHER: Finished worker discovery
07:49:47 DISPATCHER: Starting worker discovery
07:49:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:49:47 DISPATCHER: Finished worker discovery
07:50:47 DISPATCHER: Starting worker discovery
07:50:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:50:47 DISPATCHER: Finished worker discovery
07:51:47 DISPATCHER: Starting worker discovery
07:51:47 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:51:47 DISPATCHER: Finished worker discovery
07:51:48 WORKER: done with job (9, 0, 7), trying to register it.
07:51:48 DISPATCHER: job (9, 0, 7) finished
07:51:48 WORKER: registered result for job (9, 0, 7) with dispatcher
07:51:48 DISPATCHER: register_result: lock acquired
07:51:48 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:51:48 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 684, 'last_n_outputs': 24, 'leak_rate': 0.8166761646995147, 'lr': 0.003994001064471765, 'optimizer': 'Adam', 'sparsity': 0.9152473936980519, 'steps_to_train': 85, 'weight_decay': 0.02621720780210252}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.4729597564793278, 'info': {'music-speech': 0.4729597564793278, 'config': "{'batch_size': 128, 'hidden_dim': 684, 'last_n_outputs': 24, 'leak_rate': 0.8166761646995147, 'lr': 0.003994001064471765, 'optimizer': 'Adam', 'sparsity': 0.9152473936980519, 'steps_to_train': 85, 'weight_decay': 0.02621720780210252}"}}
exception: None

07:51:48 job_callback for (9, 0, 7) started
07:51:48 DISPATCHER: Trying to submit another job.
07:51:48 job_callback for (9, 0, 7) got condition
07:51:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:51:48 HBMASTER: Trying to run another job!
07:51:48 job_callback for (9, 0, 7) finished
07:51:48 HBMASTER: shutdown initiated, shutdown_workers = True
07:51:48 WORKER: shutting down now!
07:51:49 DISPATCHER: Dispatcher shutting down
07:51:49 DISPATCHER: discover_workers shutting down
07:51:49 DISPATCHER: 'discover_worker' thread exited
07:51:49 DISPATCHER: Trying to submit another job.
07:51:49 DISPATCHER: job_runner shutting down
07:51:49 DISPATCHER: 'job_runner' thread exited
07:51:49 DISPATCHER: shut down complete
07:51:49 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7f1400244390; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:35995>
07:51:49 WORKER: No dispatcher found. Waiting for one to initiate contact.
07:51:49 WORKER: start listening for jobs
07:51:49 wait_for_workers trying to get the condition
07:51:49 DISPATCHER: started the 'discover_worker' thread
07:51:49 DISPATCHER: started the 'job_runner' thread
07:51:49 DISPATCHER: Pyro daemon running on localhost:35871
07:51:49 DISPATCHER: Starting worker discovery
07:51:49 DISPATCHER: Found 1 potential workers, 0 currently in the pool.
07:51:49 DISPATCHER: discovered new worker, hpbandster.run_0.worker.metagpul.22021139727314577216
07:51:49 HBMASTER: number of workers changed to 1
07:51:49 Enough workers to start this run!
07:51:49 adjust_queue_size: lock accquired
07:51:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:51:49 HBMASTER: starting run at 1583823109.4655547
07:51:49 HBMASTER: adjusted queue size to (0, 1)
07:51:49 DISPATCHER: Finished worker discovery
07:51:49 start sampling a new configuration.
07:51:49 DISPATCHER: Trying to submit another job.
07:51:49 done sampling a new configuration.
07:51:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:51:49 HBMASTER: schedule new run for iteration 0
07:51:49 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
07:51:49 HBMASTER: submitting job (0, 0, 0) to dispatcher
07:51:49 DISPATCHER: trying to submit job (0, 0, 0)
07:51:49 DISPATCHER: trying to notify the job_runner thread.
07:51:49 HBMASTER: job (0, 0, 0) submitted to dispatcher
07:51:49 DISPATCHER: Trying to submit another job.
07:51:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:51:49 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:51:49 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:51:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:51:49 WORKER: start processing job (0, 0, 0)
07:51:49 WORKER: args: ()
07:51:49 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0018776106238474963, 'num_filters_1': 125, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.023767956226426502}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:52:44 WORKER: done with job (0, 0, 0), trying to register it.
07:52:44 WORKER: registered result for job (0, 0, 0) with dispatcher
07:52:44 DISPATCHER: job (0, 0, 0) finished
07:52:44 DISPATCHER: register_result: lock acquired
07:52:44 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:52:44 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0018776106238474963, 'num_filters_1': 125, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.023767956226426502}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6265092775807276, 'info': {'music-speech': 0.6265092775807276, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0018776106238474963, 'num_filters_1': 125, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.023767956226426502}"}}
exception: None

07:52:44 job_callback for (0, 0, 0) started
07:52:44 DISPATCHER: Trying to submit another job.
07:52:44 job_callback for (0, 0, 0) got condition
07:52:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:52:44 Only 1 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
07:52:44 HBMASTER: Trying to run another job!
07:52:44 job_callback for (0, 0, 0) finished
07:52:44 start sampling a new configuration.
07:52:44 done sampling a new configuration.
07:52:44 HBMASTER: schedule new run for iteration 0
07:52:44 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
07:52:44 HBMASTER: submitting job (0, 0, 1) to dispatcher
07:52:44 DISPATCHER: trying to submit job (0, 0, 1)
07:52:44 DISPATCHER: trying to notify the job_runner thread.
07:52:44 HBMASTER: job (0, 0, 1) submitted to dispatcher
07:52:44 DISPATCHER: Trying to submit another job.
07:52:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:52:44 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:52:44 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:52:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:52:44 WORKER: start processing job (0, 0, 1)
07:52:44 WORKER: args: ()
07:52:44 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.08275126394793379, 'num_filters_1': 120, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.0706090336267831}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:52:49 DISPATCHER: Starting worker discovery
07:52:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:52:49 DISPATCHER: Finished worker discovery
Exception in thread Thread-211:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

07:53:37 WORKER: done with job (0, 0, 1), trying to register it.
07:53:37 DISPATCHER: job (0, 0, 1) finished
07:53:37 WORKER: registered result for job (0, 0, 1) with dispatcher
07:53:37 DISPATCHER: register_result: lock acquired
07:53:37 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:53:37 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.08275126394793379, 'num_filters_1': 120, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.0706090336267831}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5446180429162334, 'info': {'music-speech': 0.5446180429162334, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.08275126394793379, 'num_filters_1': 120, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.0706090336267831}"}}
exception: None

07:53:37 job_callback for (0, 0, 1) started
07:53:37 DISPATCHER: Trying to submit another job.
07:53:37 job_callback for (0, 0, 1) got condition
07:53:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:53:37 Only 2 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
07:53:37 HBMASTER: Trying to run another job!
07:53:37 job_callback for (0, 0, 1) finished
07:53:37 start sampling a new configuration.
07:53:37 done sampling a new configuration.
07:53:37 HBMASTER: schedule new run for iteration 0
07:53:37 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
07:53:37 HBMASTER: submitting job (0, 0, 2) to dispatcher
07:53:37 DISPATCHER: trying to submit job (0, 0, 2)
07:53:37 DISPATCHER: trying to notify the job_runner thread.
07:53:37 HBMASTER: job (0, 0, 2) submitted to dispatcher
07:53:37 DISPATCHER: Trying to submit another job.
07:53:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:53:37 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:53:37 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:53:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:53:37 WORKER: start processing job (0, 0, 2)
07:53:37 WORKER: args: ()
07:53:37 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.041666099303622584, 'num_filters_1': 51, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.16934452750644505, 'kernel_size_2': 3, 'num_filters_2': 65}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:53:49 DISPATCHER: Starting worker discovery
07:53:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:53:49 DISPATCHER: Finished worker discovery
07:54:31 WORKER: done with job (0, 0, 2), trying to register it.
07:54:31 DISPATCHER: job (0, 0, 2) finished
07:54:31 WORKER: registered result for job (0, 0, 2) with dispatcher
07:54:31 DISPATCHER: register_result: lock acquired
07:54:31 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:54:31 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.041666099303622584, 'num_filters_1': 51, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.16934452750644505, 'kernel_size_2': 3, 'num_filters_2': 65}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.15880783265480314, 'info': {'music-speech': 0.15880783265480314, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.041666099303622584, 'num_filters_1': 51, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.16934452750644505, 'kernel_size_2': 3, 'num_filters_2': 65}"}}
exception: None

07:54:31 job_callback for (0, 0, 2) started
07:54:31 DISPATCHER: Trying to submit another job.
07:54:31 job_callback for (0, 0, 2) got condition
07:54:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:54:31 Only 3 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
07:54:31 HBMASTER: Trying to run another job!
07:54:31 job_callback for (0, 0, 2) finished
07:54:31 start sampling a new configuration.
07:54:31 done sampling a new configuration.
07:54:31 HBMASTER: schedule new run for iteration 0
07:54:31 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
07:54:31 HBMASTER: submitting job (0, 0, 3) to dispatcher
07:54:31 DISPATCHER: trying to submit job (0, 0, 3)
07:54:31 DISPATCHER: trying to notify the job_runner thread.
07:54:31 HBMASTER: job (0, 0, 3) submitted to dispatcher
07:54:31 DISPATCHER: Trying to submit another job.
07:54:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:54:31 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:54:31 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:54:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:54:31 WORKER: start processing job (0, 0, 3)
07:54:31 WORKER: args: ()
07:54:31 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.057660346631269184, 'num_filters_1': 47, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.07002195791831055, 'kernel_size_2': 7, 'num_filters_2': 51}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:54:49 DISPATCHER: Starting worker discovery
07:54:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:54:49 DISPATCHER: Finished worker discovery
07:55:25 WORKER: done with job (0, 0, 3), trying to register it.
07:55:25 WORKER: registered result for job (0, 0, 3) with dispatcher
07:55:25 DISPATCHER: job (0, 0, 3) finished
07:55:25 DISPATCHER: register_result: lock acquired
07:55:25 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:55:25 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.057660346631269184, 'num_filters_1': 47, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.07002195791831055, 'kernel_size_2': 7, 'num_filters_2': 51}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7096699049116773, 'info': {'music-speech': 0.7096699049116773, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.057660346631269184, 'num_filters_1': 47, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.07002195791831055, 'kernel_size_2': 7, 'num_filters_2': 51}"}}
exception: None

07:55:25 job_callback for (0, 0, 3) started
07:55:25 job_callback for (0, 0, 3) got condition
07:55:25 DISPATCHER: Trying to submit another job.
07:55:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:55:25 Only 4 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
07:55:25 HBMASTER: Trying to run another job!
07:55:25 job_callback for (0, 0, 3) finished
07:55:25 start sampling a new configuration.
07:55:25 done sampling a new configuration.
07:55:25 HBMASTER: schedule new run for iteration 0
07:55:25 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
07:55:25 HBMASTER: submitting job (0, 0, 4) to dispatcher
07:55:25 DISPATCHER: trying to submit job (0, 0, 4)
07:55:25 DISPATCHER: trying to notify the job_runner thread.
07:55:25 HBMASTER: job (0, 0, 4) submitted to dispatcher
07:55:25 DISPATCHER: Trying to submit another job.
07:55:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:55:25 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:55:25 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:55:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:55:25 WORKER: start processing job (0, 0, 4)
07:55:25 WORKER: args: ()
07:55:25 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.005868567462725588, 'num_filters_1': 68, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.014983602130622048, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 46, 'num_filters_3': 33}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:55:49 DISPATCHER: Starting worker discovery
07:55:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:55:49 DISPATCHER: Finished worker discovery
07:56:20 WORKER: done with job (0, 0, 4), trying to register it.
07:56:20 DISPATCHER: job (0, 0, 4) finished
07:56:20 WORKER: registered result for job (0, 0, 4) with dispatcher
07:56:20 DISPATCHER: register_result: lock acquired
07:56:20 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:56:20 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.005868567462725588, 'num_filters_1': 68, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.014983602130622048, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 46, 'num_filters_3': 33}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.819286822800306, 'info': {'music-speech': 0.819286822800306, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.005868567462725588, 'num_filters_1': 68, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.014983602130622048, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 46, 'num_filters_3': 33}"}}
exception: None

07:56:20 job_callback for (0, 0, 4) started
07:56:20 DISPATCHER: Trying to submit another job.
07:56:20 job_callback for (0, 0, 4) got condition
07:56:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:56:20 Only 5 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
07:56:20 HBMASTER: Trying to run another job!
07:56:20 job_callback for (0, 0, 4) finished
07:56:20 start sampling a new configuration.
07:56:20 done sampling a new configuration.
07:56:20 HBMASTER: schedule new run for iteration 0
07:56:20 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
07:56:20 HBMASTER: submitting job (0, 0, 5) to dispatcher
07:56:20 DISPATCHER: trying to submit job (0, 0, 5)
07:56:20 DISPATCHER: trying to notify the job_runner thread.
07:56:20 HBMASTER: job (0, 0, 5) submitted to dispatcher
07:56:20 DISPATCHER: Trying to submit another job.
07:56:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:56:20 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:56:20 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:56:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:56:20 WORKER: start processing job (0, 0, 5)
07:56:20 WORKER: args: ()
07:56:20 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.011320882113219312, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.04234605766778519, 'kernel_size_2': 5, 'num_filters_2': 100}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-215:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

07:56:49 DISPATCHER: Starting worker discovery
07:56:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:56:49 DISPATCHER: Finished worker discovery
07:57:13 WORKER: done with job (0, 0, 5), trying to register it.
07:57:13 WORKER: registered result for job (0, 0, 5) with dispatcher
07:57:13 DISPATCHER: job (0, 0, 5) finished
07:57:13 DISPATCHER: register_result: lock acquired
07:57:13 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:57:13 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.011320882113219312, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.04234605766778519, 'kernel_size_2': 5, 'num_filters_2': 100}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6600006312178809, 'info': {'music-speech': 0.6600006312178809, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.011320882113219312, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.04234605766778519, 'kernel_size_2': 5, 'num_filters_2': 100}"}}
exception: None

07:57:13 job_callback for (0, 0, 5) started
07:57:13 DISPATCHER: Trying to submit another job.
07:57:13 job_callback for (0, 0, 5) got condition
07:57:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:57:13 Only 6 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
07:57:13 HBMASTER: Trying to run another job!
07:57:13 job_callback for (0, 0, 5) finished
07:57:13 start sampling a new configuration.
07:57:13 done sampling a new configuration.
07:57:13 HBMASTER: schedule new run for iteration 0
07:57:13 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
07:57:13 HBMASTER: submitting job (0, 0, 6) to dispatcher
07:57:13 DISPATCHER: trying to submit job (0, 0, 6)
07:57:13 DISPATCHER: trying to notify the job_runner thread.
07:57:13 HBMASTER: job (0, 0, 6) submitted to dispatcher
07:57:13 DISPATCHER: Trying to submit another job.
07:57:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:57:13 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:57:13 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:57:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:57:13 WORKER: start processing job (0, 0, 6)
07:57:13 WORKER: args: ()
07:57:13 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.001093746920765784, 'num_filters_1': 21, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.020423125757466822, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 73, 'num_filters_3': 28, 'num_filters_4': 125}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:57:49 DISPATCHER: Starting worker discovery
07:57:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:57:49 DISPATCHER: Finished worker discovery
07:58:06 WORKER: done with job (0, 0, 6), trying to register it.
07:58:06 DISPATCHER: job (0, 0, 6) finished
07:58:06 WORKER: registered result for job (0, 0, 6) with dispatcher
07:58:06 DISPATCHER: register_result: lock acquired
07:58:06 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:58:06 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.001093746920765784, 'num_filters_1': 21, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.020423125757466822, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 73, 'num_filters_3': 28, 'num_filters_4': 125}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9088170743706686, 'info': {'music-speech': 0.9088170743706686, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.001093746920765784, 'num_filters_1': 21, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.020423125757466822, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 73, 'num_filters_3': 28, 'num_filters_4': 125}"}}
exception: None

07:58:06 job_callback for (0, 0, 6) started
07:58:06 job_callback for (0, 0, 6) got condition
07:58:06 DISPATCHER: Trying to submit another job.
07:58:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:58:06 Only 7 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
07:58:06 HBMASTER: Trying to run another job!
07:58:06 job_callback for (0, 0, 6) finished
07:58:06 start sampling a new configuration.
07:58:06 done sampling a new configuration.
07:58:06 HBMASTER: schedule new run for iteration 0
07:58:06 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
07:58:06 HBMASTER: submitting job (0, 0, 7) to dispatcher
07:58:06 DISPATCHER: trying to submit job (0, 0, 7)
07:58:06 DISPATCHER: trying to notify the job_runner thread.
07:58:06 HBMASTER: job (0, 0, 7) submitted to dispatcher
07:58:06 DISPATCHER: Trying to submit another job.
07:58:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:58:06 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:58:06 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:58:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:58:06 WORKER: start processing job (0, 0, 7)
07:58:06 WORKER: args: ()
07:58:06 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.004825411187422723, 'num_filters_1': 95, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.015069387236933091, 'kernel_size_2': 7, 'num_filters_2': 28}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:58:49 DISPATCHER: Starting worker discovery
07:58:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:58:49 DISPATCHER: Finished worker discovery
07:59:00 WORKER: done with job (0, 0, 7), trying to register it.
07:59:00 WORKER: registered result for job (0, 0, 7) with dispatcher
07:59:00 DISPATCHER: job (0, 0, 7) finished
07:59:00 DISPATCHER: register_result: lock acquired
07:59:00 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:59:00 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.004825411187422723, 'num_filters_1': 95, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.015069387236933091, 'kernel_size_2': 7, 'num_filters_2': 28}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9056366616531553, 'info': {'music-speech': 0.9056366616531553, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.004825411187422723, 'num_filters_1': 95, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.015069387236933091, 'kernel_size_2': 7, 'num_filters_2': 28}"}}
exception: None

07:59:00 job_callback for (0, 0, 7) started
07:59:00 job_callback for (0, 0, 7) got condition
07:59:00 DISPATCHER: Trying to submit another job.
07:59:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:59:00 Only 8 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
07:59:00 HBMASTER: Trying to run another job!
07:59:00 job_callback for (0, 0, 7) finished
07:59:00 start sampling a new configuration.
07:59:00 done sampling a new configuration.
07:59:00 HBMASTER: schedule new run for iteration 0
07:59:00 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
07:59:00 HBMASTER: submitting job (0, 0, 8) to dispatcher
07:59:00 DISPATCHER: trying to submit job (0, 0, 8)
07:59:00 DISPATCHER: trying to notify the job_runner thread.
07:59:00 HBMASTER: job (0, 0, 8) submitted to dispatcher
07:59:00 DISPATCHER: Trying to submit another job.
07:59:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:59:00 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:59:00 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:59:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:59:00 WORKER: start processing job (0, 0, 8)
07:59:00 WORKER: args: ()
07:59:00 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0025383634324292804, 'num_filters_1': 53, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.18454665144883664, 'kernel_size_2': 3, 'num_filters_2': 127}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:59:49 DISPATCHER: Starting worker discovery
07:59:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:59:49 DISPATCHER: Finished worker discovery
07:59:53 WORKER: done with job (0, 0, 8), trying to register it.
07:59:53 WORKER: registered result for job (0, 0, 8) with dispatcher
07:59:53 DISPATCHER: job (0, 0, 8) finished
07:59:53 DISPATCHER: register_result: lock acquired
07:59:53 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:59:53 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0025383634324292804, 'num_filters_1': 53, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.18454665144883664, 'kernel_size_2': 3, 'num_filters_2': 127}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5781215589687767, 'info': {'music-speech': 0.5781215589687767, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0025383634324292804, 'num_filters_1': 53, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 59, 'weight_decay': 0.18454665144883664, 'kernel_size_2': 3, 'num_filters_2': 127}"}}
exception: None

07:59:53 job_callback for (0, 0, 8) started
07:59:53 DISPATCHER: Trying to submit another job.
07:59:53 job_callback for (0, 0, 8) got condition
07:59:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:59:53 Only 9 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
07:59:53 HBMASTER: Trying to run another job!
07:59:53 job_callback for (0, 0, 8) finished
07:59:53 start sampling a new configuration.
07:59:53 done sampling a new configuration.
07:59:53 HBMASTER: schedule new run for iteration 0
07:59:53 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
07:59:53 HBMASTER: submitting job (0, 0, 9) to dispatcher
07:59:53 DISPATCHER: trying to submit job (0, 0, 9)
07:59:53 DISPATCHER: trying to notify the job_runner thread.
07:59:53 HBMASTER: job (0, 0, 9) submitted to dispatcher
07:59:53 DISPATCHER: Trying to submit another job.
07:59:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:59:53 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:59:53 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:59:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:59:53 WORKER: start processing job (0, 0, 9)
07:59:53 WORKER: args: ()
07:59:53 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0036587149305823494, 'num_filters_1': 45, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.07153409630413571, 'kernel_size_2': 3, 'num_filters_2': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:00:47 WORKER: done with job (0, 0, 9), trying to register it.
08:00:47 WORKER: registered result for job (0, 0, 9) with dispatcher
08:00:47 DISPATCHER: job (0, 0, 9) finished
08:00:47 DISPATCHER: register_result: lock acquired
08:00:47 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:00:47 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0036587149305823494, 'num_filters_1': 45, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.07153409630413571, 'kernel_size_2': 3, 'num_filters_2': 20}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6579732754599278, 'info': {'music-speech': 0.6579732754599278, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0036587149305823494, 'num_filters_1': 45, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.07153409630413571, 'kernel_size_2': 3, 'num_filters_2': 20}"}}
exception: None

08:00:47 job_callback for (0, 0, 9) started
08:00:47 DISPATCHER: Trying to submit another job.
08:00:47 job_callback for (0, 0, 9) got condition
08:00:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:00:47 Only 10 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
08:00:47 HBMASTER: Trying to run another job!
08:00:47 job_callback for (0, 0, 9) finished
08:00:47 start sampling a new configuration.
08:00:47 done sampling a new configuration.
08:00:47 HBMASTER: schedule new run for iteration 0
08:00:47 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
08:00:47 HBMASTER: submitting job (0, 0, 10) to dispatcher
08:00:47 DISPATCHER: trying to submit job (0, 0, 10)
08:00:47 DISPATCHER: trying to notify the job_runner thread.
08:00:47 HBMASTER: job (0, 0, 10) submitted to dispatcher
08:00:47 DISPATCHER: Trying to submit another job.
08:00:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:00:47 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:00:47 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:00:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:00:47 WORKER: start processing job (0, 0, 10)
08:00:47 WORKER: args: ()
08:00:47 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0012200805938718479, 'num_filters_1': 58, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.012751214710038667, 'kernel_size_2': 5, 'num_filters_2': 49}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:00:49 DISPATCHER: Starting worker discovery
08:00:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:00:49 DISPATCHER: Finished worker discovery
08:01:40 WORKER: done with job (0, 0, 10), trying to register it.
08:01:40 WORKER: registered result for job (0, 0, 10) with dispatcher
08:01:40 DISPATCHER: job (0, 0, 10) finished
08:01:40 DISPATCHER: register_result: lock acquired
08:01:40 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:01:40 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0012200805938718479, 'num_filters_1': 58, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.012751214710038667, 'kernel_size_2': 5, 'num_filters_2': 49}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6739609072154347, 'info': {'music-speech': 0.6739609072154347, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0012200805938718479, 'num_filters_1': 58, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.012751214710038667, 'kernel_size_2': 5, 'num_filters_2': 49}"}}
exception: None

08:01:40 job_callback for (0, 0, 10) started
08:01:40 job_callback for (0, 0, 10) got condition
08:01:40 DISPATCHER: Trying to submit another job.
08:01:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:01:40 Only 11 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
08:01:40 HBMASTER: Trying to run another job!
08:01:40 job_callback for (0, 0, 10) finished
08:01:40 start sampling a new configuration.
08:01:40 done sampling a new configuration.
08:01:40 HBMASTER: schedule new run for iteration 0
08:01:40 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
08:01:40 HBMASTER: submitting job (0, 0, 11) to dispatcher
08:01:40 DISPATCHER: trying to submit job (0, 0, 11)
08:01:40 DISPATCHER: trying to notify the job_runner thread.
08:01:40 HBMASTER: job (0, 0, 11) submitted to dispatcher
08:01:40 DISPATCHER: Trying to submit another job.
08:01:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:01:40 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:01:40 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:01:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:01:40 WORKER: start processing job (0, 0, 11)
08:01:40 WORKER: args: ()
08:01:40 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.012987642664123526, 'num_filters_1': 49, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.019494849003300944}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:01:49 DISPATCHER: Starting worker discovery
08:01:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:01:49 DISPATCHER: Finished worker discovery
08:02:33 WORKER: done with job (0, 0, 11), trying to register it.
08:02:33 WORKER: registered result for job (0, 0, 11) with dispatcher
08:02:33 DISPATCHER: job (0, 0, 11) finished
08:02:33 DISPATCHER: register_result: lock acquired
08:02:33 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:02:33 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.012987642664123526, 'num_filters_1': 49, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.019494849003300944}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3933630463719993, 'info': {'music-speech': 0.3933630463719993, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.012987642664123526, 'num_filters_1': 49, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.019494849003300944}"}}
exception: None

08:02:33 job_callback for (0, 0, 11) started
08:02:33 DISPATCHER: Trying to submit another job.
08:02:33 job_callback for (0, 0, 11) got condition
08:02:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:02:33 Only 12 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
08:02:33 HBMASTER: Trying to run another job!
08:02:33 job_callback for (0, 0, 11) finished
08:02:33 start sampling a new configuration.
08:02:33 done sampling a new configuration.
08:02:33 HBMASTER: schedule new run for iteration 0
08:02:33 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
08:02:33 HBMASTER: submitting job (0, 0, 12) to dispatcher
08:02:33 DISPATCHER: trying to submit job (0, 0, 12)
08:02:33 DISPATCHER: trying to notify the job_runner thread.
08:02:33 HBMASTER: job (0, 0, 12) submitted to dispatcher
08:02:33 DISPATCHER: Trying to submit another job.
08:02:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:02:33 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:02:33 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:02:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:02:33 WORKER: start processing job (0, 0, 12)
08:02:33 WORKER: args: ()
08:02:33 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.03686480677342548, 'num_filters_1': 38, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.12034569963153292, 'kernel_size_2': 7, 'num_filters_2': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:02:49 DISPATCHER: Starting worker discovery
08:02:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:02:49 DISPATCHER: Finished worker discovery
08:03:26 WORKER: done with job (0, 0, 12), trying to register it.
08:03:26 WORKER: registered result for job (0, 0, 12) with dispatcher
08:03:26 DISPATCHER: job (0, 0, 12) finished
08:03:27 DISPATCHER: register_result: lock acquired
08:03:27 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:03:27 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.03686480677342548, 'num_filters_1': 38, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.12034569963153292, 'kernel_size_2': 7, 'num_filters_2': 44}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.03686480677342548, 'num_filters_1': 38, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.12034569963153292, 'kernel_size_2': 7, 'num_filters_2': 44}"}}
exception: None

08:03:27 job_callback for (0, 0, 12) started
08:03:27 DISPATCHER: Trying to submit another job.
08:03:27 job_callback for (0, 0, 12) got condition
08:03:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:03:27 Only 13 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
08:03:27 HBMASTER: Trying to run another job!
08:03:27 job_callback for (0, 0, 12) finished
08:03:27 start sampling a new configuration.
08:03:27 done sampling a new configuration.
08:03:27 HBMASTER: schedule new run for iteration 0
08:03:27 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
08:03:27 HBMASTER: submitting job (0, 0, 13) to dispatcher
08:03:27 DISPATCHER: trying to submit job (0, 0, 13)
08:03:27 DISPATCHER: trying to notify the job_runner thread.
08:03:27 HBMASTER: job (0, 0, 13) submitted to dispatcher
08:03:27 DISPATCHER: Trying to submit another job.
08:03:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:03:27 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:03:27 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:03:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:03:27 WORKER: start processing job (0, 0, 13)
08:03:27 WORKER: args: ()
08:03:27 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.052813864696766195, 'num_filters_1': 86, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.07823713177743213, 'kernel_size_2': 7, 'num_filters_2': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:03:49 DISPATCHER: Starting worker discovery
08:03:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:03:49 DISPATCHER: Finished worker discovery
08:04:20 WORKER: done with job (0, 0, 13), trying to register it.
08:04:20 WORKER: registered result for job (0, 0, 13) with dispatcher
08:04:20 DISPATCHER: job (0, 0, 13) finished
08:04:20 DISPATCHER: register_result: lock acquired
08:04:20 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:04:20 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.052813864696766195, 'num_filters_1': 86, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.07823713177743213, 'kernel_size_2': 7, 'num_filters_2': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0038826058897545365, 'info': {'music-speech': 0.0038826058897545365, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.052813864696766195, 'num_filters_1': 86, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.07823713177743213, 'kernel_size_2': 7, 'num_filters_2': 21}"}}
exception: None

08:04:20 job_callback for (0, 0, 13) started
08:04:20 DISPATCHER: Trying to submit another job.
08:04:20 job_callback for (0, 0, 13) got condition
08:04:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:04:20 Only 14 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
08:04:20 HBMASTER: Trying to run another job!
08:04:20 job_callback for (0, 0, 13) finished
08:04:20 start sampling a new configuration.
08:04:20 done sampling a new configuration.
08:04:20 HBMASTER: schedule new run for iteration 0
08:04:20 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
08:04:20 HBMASTER: submitting job (0, 0, 14) to dispatcher
08:04:20 DISPATCHER: trying to submit job (0, 0, 14)
08:04:20 DISPATCHER: trying to notify the job_runner thread.
08:04:20 HBMASTER: job (0, 0, 14) submitted to dispatcher
08:04:20 DISPATCHER: Trying to submit another job.
08:04:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:04:20 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:04:20 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:04:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:04:20 WORKER: start processing job (0, 0, 14)
08:04:20 WORKER: args: ()
08:04:20 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.015044226715823712, 'num_filters_1': 90, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.02122348062705941, 'kernel_size_2': 3, 'num_filters_2': 68}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:04:49 DISPATCHER: Starting worker discovery
08:04:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:04:49 DISPATCHER: Finished worker discovery
08:05:14 WORKER: done with job (0, 0, 14), trying to register it.
08:05:14 DISPATCHER: job (0, 0, 14) finished
08:05:14 WORKER: registered result for job (0, 0, 14) with dispatcher
08:05:14 DISPATCHER: register_result: lock acquired
08:05:14 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:05:14 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.015044226715823712, 'num_filters_1': 90, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.02122348062705941, 'kernel_size_2': 3, 'num_filters_2': 68}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5858459161542463, 'info': {'music-speech': 0.5858459161542463, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.015044226715823712, 'num_filters_1': 90, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.02122348062705941, 'kernel_size_2': 3, 'num_filters_2': 68}"}}
exception: None

08:05:14 job_callback for (0, 0, 14) started
08:05:14 job_callback for (0, 0, 14) got condition
08:05:14 DISPATCHER: Trying to submit another job.
08:05:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:05:14 Only 15 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
08:05:14 HBMASTER: Trying to run another job!
08:05:14 job_callback for (0, 0, 14) finished
08:05:14 start sampling a new configuration.
08:05:14 done sampling a new configuration.
08:05:14 HBMASTER: schedule new run for iteration 0
08:05:14 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
08:05:14 HBMASTER: submitting job (0, 0, 15) to dispatcher
08:05:14 DISPATCHER: trying to submit job (0, 0, 15)
08:05:14 DISPATCHER: trying to notify the job_runner thread.
08:05:14 HBMASTER: job (0, 0, 15) submitted to dispatcher
08:05:14 DISPATCHER: Trying to submit another job.
08:05:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:05:14 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:05:14 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:05:14 WORKER: start processing job (0, 0, 15)
08:05:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:05:14 WORKER: args: ()
08:05:14 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.009194672216406175, 'num_filters_1': 26, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.09749428387476416, 'kernel_size_2': 3, 'num_filters_2': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:05:49 DISPATCHER: Starting worker discovery
08:05:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:05:49 DISPATCHER: Finished worker discovery
08:06:07 WORKER: done with job (0, 0, 15), trying to register it.
08:06:07 DISPATCHER: job (0, 0, 15) finished
08:06:07 WORKER: registered result for job (0, 0, 15) with dispatcher
08:06:07 DISPATCHER: register_result: lock acquired
08:06:07 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:06:07 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.009194672216406175, 'num_filters_1': 26, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.09749428387476416, 'kernel_size_2': 3, 'num_filters_2': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9295884529132675, 'info': {'music-speech': 0.9295884529132675, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.009194672216406175, 'num_filters_1': 26, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.09749428387476416, 'kernel_size_2': 3, 'num_filters_2': 17}"}}
exception: None

08:06:07 job_callback for (0, 0, 15) started
08:06:07 job_callback for (0, 0, 15) got condition
08:06:07 DISPATCHER: Trying to submit another job.
08:06:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:06:07 Only 16 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
08:06:07 HBMASTER: Trying to run another job!
08:06:07 job_callback for (0, 0, 15) finished
08:06:07 start sampling a new configuration.
08:06:07 done sampling a new configuration.
08:06:07 HBMASTER: schedule new run for iteration 0
08:06:07 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
08:06:07 HBMASTER: submitting job (0, 0, 16) to dispatcher
08:06:07 DISPATCHER: trying to submit job (0, 0, 16)
08:06:07 DISPATCHER: trying to notify the job_runner thread.
08:06:07 HBMASTER: job (0, 0, 16) submitted to dispatcher
08:06:07 DISPATCHER: Trying to submit another job.
08:06:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:06:07 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:06:07 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:06:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:06:07 WORKER: start processing job (0, 0, 16)
08:06:07 WORKER: args: ()
08:06:07 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0034848903823596084, 'num_filters_1': 102, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.011079058696131747, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 98, 'num_filters_3': 23, 'num_filters_4': 24, 'num_filters_5': 59}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:06:49 DISPATCHER: Starting worker discovery
08:06:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:06:49 DISPATCHER: Finished worker discovery
08:07:00 WORKER: done with job (0, 0, 16), trying to register it.
08:07:00 WORKER: registered result for job (0, 0, 16) with dispatcher
08:07:00 DISPATCHER: job (0, 0, 16) finished
08:07:00 DISPATCHER: register_result: lock acquired
08:07:00 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:07:00 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0034848903823596084, 'num_filters_1': 102, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.011079058696131747, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 98, 'num_filters_3': 23, 'num_filters_4': 24, 'num_filters_5': 59}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8327635090596485, 'info': {'music-speech': 0.8327635090596485, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0034848903823596084, 'num_filters_1': 102, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.011079058696131747, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 98, 'num_filters_3': 23, 'num_filters_4': 24, 'num_filters_5': 59}"}}
exception: None

08:07:00 job_callback for (0, 0, 16) started
08:07:00 job_callback for (0, 0, 16) got condition
08:07:00 DISPATCHER: Trying to submit another job.
08:07:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:07:00 HBMASTER: Trying to run another job!
08:07:00 job_callback for (0, 0, 16) finished
08:07:00 start sampling a new configuration.
08:07:00 done sampling a new configuration.
08:07:00 HBMASTER: schedule new run for iteration 0
08:07:00 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
08:07:00 HBMASTER: submitting job (0, 0, 17) to dispatcher
08:07:00 DISPATCHER: trying to submit job (0, 0, 17)
08:07:00 DISPATCHER: trying to notify the job_runner thread.
08:07:00 HBMASTER: job (0, 0, 17) submitted to dispatcher
08:07:00 DISPATCHER: Trying to submit another job.
08:07:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:07:00 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:07:00 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:07:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:07:00 WORKER: start processing job (0, 0, 17)
08:07:00 WORKER: args: ()
08:07:00 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.09978058618675348, 'num_filters_1': 119, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.1044585435261435, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 24, 'num_filters_3': 111}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:07:49 DISPATCHER: Starting worker discovery
08:07:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:07:49 DISPATCHER: Finished worker discovery
08:07:54 WORKER: done with job (0, 0, 17), trying to register it.
08:07:54 WORKER: registered result for job (0, 0, 17) with dispatcher
08:07:54 DISPATCHER: job (0, 0, 17) finished
08:07:54 DISPATCHER: register_result: lock acquired
08:07:54 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:07:54 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.09978058618675348, 'num_filters_1': 119, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.1044585435261435, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 24, 'num_filters_3': 111}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.09978058618675348, 'num_filters_1': 119, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.1044585435261435, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 24, 'num_filters_3': 111}"}}
exception: None

08:07:54 job_callback for (0, 0, 17) started
08:07:54 job_callback for (0, 0, 17) got condition
08:07:54 DISPATCHER: Trying to submit another job.
08:07:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:07:54 HBMASTER: Trying to run another job!
08:07:54 job_callback for (0, 0, 17) finished
08:07:54 start sampling a new configuration.
08:07:54 done sampling a new configuration.
08:07:54 HBMASTER: schedule new run for iteration 0
08:07:54 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
08:07:54 HBMASTER: submitting job (0, 0, 18) to dispatcher
08:07:54 DISPATCHER: trying to submit job (0, 0, 18)
08:07:54 DISPATCHER: trying to notify the job_runner thread.
08:07:54 HBMASTER: job (0, 0, 18) submitted to dispatcher
08:07:54 DISPATCHER: Trying to submit another job.
08:07:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:07:54 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:07:54 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:07:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:07:54 WORKER: start processing job (0, 0, 18)
08:07:54 WORKER: args: ()
08:07:54 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006773572424858516, 'num_filters_1': 54, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.07696902081537649, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 16, 'num_filters_3': 47, 'num_filters_4': 30}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:08:48 WORKER: done with job (0, 0, 18), trying to register it.
08:08:48 WORKER: registered result for job (0, 0, 18) with dispatcher
08:08:48 DISPATCHER: job (0, 0, 18) finished
08:08:48 DISPATCHER: register_result: lock acquired
08:08:48 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:08:48 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006773572424858516, 'num_filters_1': 54, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.07696902081537649, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 16, 'num_filters_3': 47, 'num_filters_4': 30}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9214641907635137, 'info': {'music-speech': 0.9214641907635137, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006773572424858516, 'num_filters_1': 54, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.07696902081537649, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 16, 'num_filters_3': 47, 'num_filters_4': 30}"}}
exception: None

08:08:48 job_callback for (0, 0, 18) started
08:08:48 DISPATCHER: Trying to submit another job.
08:08:48 job_callback for (0, 0, 18) got condition
08:08:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:08:48 HBMASTER: Trying to run another job!
08:08:48 job_callback for (0, 0, 18) finished
08:08:48 start sampling a new configuration.
08:08:48 done sampling a new configuration.
08:08:48 HBMASTER: schedule new run for iteration 0
08:08:48 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
08:08:48 HBMASTER: submitting job (0, 0, 19) to dispatcher
08:08:48 DISPATCHER: trying to submit job (0, 0, 19)
08:08:48 DISPATCHER: trying to notify the job_runner thread.
08:08:48 HBMASTER: job (0, 0, 19) submitted to dispatcher
08:08:48 DISPATCHER: Trying to submit another job.
08:08:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:08:48 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:08:48 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:08:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:08:48 WORKER: start processing job (0, 0, 19)
08:08:48 WORKER: args: ()
08:08:48 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.02388734214366955, 'num_filters_1': 38, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 11, 'weight_decay': 0.01111804077577953}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:08:49 DISPATCHER: Starting worker discovery
08:08:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:08:49 DISPATCHER: Finished worker discovery
08:09:41 WORKER: done with job (0, 0, 19), trying to register it.
08:09:41 DISPATCHER: job (0, 0, 19) finished
08:09:41 WORKER: registered result for job (0, 0, 19) with dispatcher
08:09:41 DISPATCHER: register_result: lock acquired
08:09:41 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:09:41 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.02388734214366955, 'num_filters_1': 38, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 11, 'weight_decay': 0.01111804077577953}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8977923964436828, 'info': {'music-speech': 0.8977923964436828, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.02388734214366955, 'num_filters_1': 38, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 11, 'weight_decay': 0.01111804077577953}"}}
exception: None

08:09:41 job_callback for (0, 0, 19) started
08:09:41 DISPATCHER: Trying to submit another job.
08:09:41 job_callback for (0, 0, 19) got condition
08:09:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:09:41 HBMASTER: Trying to run another job!
08:09:41 job_callback for (0, 0, 19) finished
08:09:41 start sampling a new configuration.
08:09:41 done sampling a new configuration.
08:09:41 HBMASTER: schedule new run for iteration 0
08:09:41 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
08:09:41 HBMASTER: submitting job (0, 0, 20) to dispatcher
08:09:41 DISPATCHER: trying to submit job (0, 0, 20)
08:09:41 DISPATCHER: trying to notify the job_runner thread.
08:09:41 HBMASTER: job (0, 0, 20) submitted to dispatcher
08:09:41 DISPATCHER: Trying to submit another job.
08:09:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:09:41 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:09:41 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:09:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:09:41 WORKER: start processing job (0, 0, 20)
08:09:41 WORKER: args: ()
08:09:41 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005045250580694626, 'num_filters_1': 19, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.18334432508666906, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 55, 'num_filters_3': 83, 'num_filters_4': 64}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:09:49 DISPATCHER: Starting worker discovery
08:09:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:09:49 DISPATCHER: Finished worker discovery
08:10:35 WORKER: done with job (0, 0, 20), trying to register it.
08:10:35 WORKER: registered result for job (0, 0, 20) with dispatcher
08:10:35 DISPATCHER: job (0, 0, 20) finished
08:10:35 DISPATCHER: register_result: lock acquired
08:10:35 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:10:35 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005045250580694626, 'num_filters_1': 19, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.18334432508666906, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 55, 'num_filters_3': 83, 'num_filters_4': 64}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8674314483698904, 'info': {'music-speech': 0.8674314483698904, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005045250580694626, 'num_filters_1': 19, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.18334432508666906, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 55, 'num_filters_3': 83, 'num_filters_4': 64}"}}
exception: None

08:10:35 job_callback for (0, 0, 20) started
08:10:35 DISPATCHER: Trying to submit another job.
08:10:35 job_callback for (0, 0, 20) got condition
08:10:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:10:35 HBMASTER: Trying to run another job!
08:10:35 job_callback for (0, 0, 20) finished
08:10:35 start sampling a new configuration.
08:10:35 done sampling a new configuration.
08:10:35 HBMASTER: schedule new run for iteration 0
08:10:35 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
08:10:35 HBMASTER: submitting job (0, 0, 21) to dispatcher
08:10:35 DISPATCHER: trying to submit job (0, 0, 21)
08:10:35 DISPATCHER: trying to notify the job_runner thread.
08:10:35 HBMASTER: job (0, 0, 21) submitted to dispatcher
08:10:35 DISPATCHER: Trying to submit another job.
08:10:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:10:35 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:10:35 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:10:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:10:35 WORKER: start processing job (0, 0, 21)
08:10:35 WORKER: args: ()
08:10:35 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.021309136581368068, 'num_filters_1': 27, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.15438410923374488, 'kernel_size_2': 7, 'num_filters_2': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:10:49 DISPATCHER: Starting worker discovery
08:10:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:10:49 DISPATCHER: Finished worker discovery
08:11:28 WORKER: done with job (0, 0, 21), trying to register it.
08:11:28 WORKER: registered result for job (0, 0, 21) with dispatcher
08:11:28 DISPATCHER: job (0, 0, 21) finished
08:11:28 DISPATCHER: register_result: lock acquired
08:11:28 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:11:28 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.021309136581368068, 'num_filters_1': 27, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.15438410923374488, 'kernel_size_2': 7, 'num_filters_2': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.571187639085692, 'info': {'music-speech': 0.571187639085692, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.021309136581368068, 'num_filters_1': 27, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 69, 'weight_decay': 0.15438410923374488, 'kernel_size_2': 7, 'num_filters_2': 23}"}}
exception: None

08:11:28 job_callback for (0, 0, 21) started
08:11:28 job_callback for (0, 0, 21) got condition
08:11:28 DISPATCHER: Trying to submit another job.
08:11:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:11:28 HBMASTER: Trying to run another job!
08:11:28 job_callback for (0, 0, 21) finished
08:11:28 start sampling a new configuration.
08:11:28 done sampling a new configuration.
08:11:28 HBMASTER: schedule new run for iteration 0
08:11:28 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
08:11:28 HBMASTER: submitting job (0, 0, 22) to dispatcher
08:11:28 DISPATCHER: trying to submit job (0, 0, 22)
08:11:28 DISPATCHER: trying to notify the job_runner thread.
08:11:28 HBMASTER: job (0, 0, 22) submitted to dispatcher
08:11:28 DISPATCHER: Trying to submit another job.
08:11:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:11:28 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:11:28 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:11:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:11:28 WORKER: start processing job (0, 0, 22)
08:11:28 WORKER: args: ()
08:11:28 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0025720599021979563, 'num_filters_1': 91, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.030050170096807348, 'kernel_size_2': 3, 'num_filters_2': 122}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:11:49 DISPATCHER: Starting worker discovery
08:11:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:11:49 DISPATCHER: Finished worker discovery
08:12:21 WORKER: done with job (0, 0, 22), trying to register it.
08:12:21 WORKER: registered result for job (0, 0, 22) with dispatcher
08:12:21 DISPATCHER: job (0, 0, 22) finished
08:12:21 DISPATCHER: register_result: lock acquired
08:12:21 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:12:21 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0025720599021979563, 'num_filters_1': 91, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.030050170096807348, 'kernel_size_2': 3, 'num_filters_2': 122}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9052701115422109, 'info': {'music-speech': 0.9052701115422109, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0025720599021979563, 'num_filters_1': 91, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.030050170096807348, 'kernel_size_2': 3, 'num_filters_2': 122}"}}
exception: None

08:12:21 job_callback for (0, 0, 22) started
08:12:21 job_callback for (0, 0, 22) got condition
08:12:21 DISPATCHER: Trying to submit another job.
08:12:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:12:21 HBMASTER: Trying to run another job!
08:12:21 job_callback for (0, 0, 22) finished
08:12:21 start sampling a new configuration.
08:12:21 done sampling a new configuration.
08:12:21 HBMASTER: schedule new run for iteration 0
08:12:21 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
08:12:21 HBMASTER: submitting job (0, 0, 23) to dispatcher
08:12:21 DISPATCHER: trying to submit job (0, 0, 23)
08:12:21 DISPATCHER: trying to notify the job_runner thread.
08:12:21 HBMASTER: job (0, 0, 23) submitted to dispatcher
08:12:21 DISPATCHER: Trying to submit another job.
08:12:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:12:21 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:12:21 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:12:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:12:21 WORKER: start processing job (0, 0, 23)
08:12:21 WORKER: args: ()
08:12:21 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.009167944565715479, 'num_filters_1': 85, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 10, 'weight_decay': 0.09669603637726626, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 70, 'num_filters_3': 105, 'num_filters_4': 62, 'num_filters_5': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:12:49 DISPATCHER: Starting worker discovery
08:12:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:12:49 DISPATCHER: Finished worker discovery
08:13:15 WORKER: done with job (0, 0, 23), trying to register it.
08:13:15 WORKER: registered result for job (0, 0, 23) with dispatcher
08:13:15 DISPATCHER: job (0, 0, 23) finished
08:13:15 DISPATCHER: register_result: lock acquired
08:13:15 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:13:15 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.009167944565715479, 'num_filters_1': 85, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 10, 'weight_decay': 0.09669603637726626, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 70, 'num_filters_3': 105, 'num_filters_4': 62, 'num_filters_5': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.009167944565715479, 'num_filters_1': 85, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 10, 'weight_decay': 0.09669603637726626, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 70, 'num_filters_3': 105, 'num_filters_4': 62, 'num_filters_5': 18}"}}
exception: None

08:13:15 job_callback for (0, 0, 23) started
08:13:15 DISPATCHER: Trying to submit another job.
08:13:15 job_callback for (0, 0, 23) got condition
08:13:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:13:15 HBMASTER: Trying to run another job!
08:13:15 job_callback for (0, 0, 23) finished
08:13:15 start sampling a new configuration.
08:13:15 done sampling a new configuration.
08:13:15 HBMASTER: schedule new run for iteration 0
08:13:15 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
08:13:15 HBMASTER: submitting job (0, 0, 24) to dispatcher
08:13:15 DISPATCHER: trying to submit job (0, 0, 24)
08:13:15 DISPATCHER: trying to notify the job_runner thread.
08:13:15 HBMASTER: job (0, 0, 24) submitted to dispatcher
08:13:15 DISPATCHER: Trying to submit another job.
08:13:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:13:15 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:13:15 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:13:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:13:15 WORKER: start processing job (0, 0, 24)
08:13:15 WORKER: args: ()
08:13:15 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003742564284934438, 'num_filters_1': 99, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.012182404801198579, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 49, 'num_filters_3': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:13:49 DISPATCHER: Starting worker discovery
08:13:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:13:49 DISPATCHER: Finished worker discovery
08:14:08 WORKER: done with job (0, 0, 24), trying to register it.
08:14:08 WORKER: registered result for job (0, 0, 24) with dispatcher
08:14:08 DISPATCHER: job (0, 0, 24) finished
08:14:08 DISPATCHER: register_result: lock acquired
08:14:08 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:14:08 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003742564284934438, 'num_filters_1': 99, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.012182404801198579, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 49, 'num_filters_3': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7396503223764066, 'info': {'music-speech': 0.7396503223764066, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003742564284934438, 'num_filters_1': 99, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.012182404801198579, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 49, 'num_filters_3': 19}"}}
exception: None

08:14:08 job_callback for (0, 0, 24) started
08:14:08 job_callback for (0, 0, 24) got condition
08:14:08 DISPATCHER: Trying to submit another job.
08:14:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:14:08 HBMASTER: Trying to run another job!
08:14:08 job_callback for (0, 0, 24) finished
08:14:08 start sampling a new configuration.
08:14:08 done sampling a new configuration.
08:14:08 HBMASTER: schedule new run for iteration 0
08:14:08 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
08:14:08 HBMASTER: submitting job (0, 0, 25) to dispatcher
08:14:08 DISPATCHER: trying to submit job (0, 0, 25)
08:14:08 DISPATCHER: trying to notify the job_runner thread.
08:14:08 HBMASTER: job (0, 0, 25) submitted to dispatcher
08:14:08 DISPATCHER: Trying to submit another job.
08:14:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:14:08 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:14:08 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:14:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:14:08 WORKER: start processing job (0, 0, 25)
08:14:08 WORKER: args: ()
08:14:08 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.001688339010583241, 'num_filters_1': 25, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.013071331206462805}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:14:49 DISPATCHER: Starting worker discovery
08:14:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:14:49 DISPATCHER: Finished worker discovery
08:15:02 WORKER: done with job (0, 0, 25), trying to register it.
08:15:02 DISPATCHER: job (0, 0, 25) finished
08:15:02 WORKER: registered result for job (0, 0, 25) with dispatcher
08:15:02 DISPATCHER: register_result: lock acquired
08:15:02 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:15:02 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.001688339010583241, 'num_filters_1': 25, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.013071331206462805}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.653398520244449, 'info': {'music-speech': 0.653398520244449, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.001688339010583241, 'num_filters_1': 25, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 97, 'weight_decay': 0.013071331206462805}"}}
exception: None

08:15:02 job_callback for (0, 0, 25) started
08:15:02 DISPATCHER: Trying to submit another job.
08:15:02 job_callback for (0, 0, 25) got condition
08:15:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:15:02 HBMASTER: Trying to run another job!
08:15:02 job_callback for (0, 0, 25) finished
08:15:02 start sampling a new configuration.
08:15:02 done sampling a new configuration.
08:15:02 HBMASTER: schedule new run for iteration 0
08:15:02 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
08:15:02 HBMASTER: submitting job (0, 0, 26) to dispatcher
08:15:02 DISPATCHER: trying to submit job (0, 0, 26)
08:15:02 DISPATCHER: trying to notify the job_runner thread.
08:15:02 HBMASTER: job (0, 0, 26) submitted to dispatcher
08:15:02 DISPATCHER: Trying to submit another job.
08:15:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:15:02 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:15:02 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:15:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:15:02 WORKER: start processing job (0, 0, 26)
08:15:02 WORKER: args: ()
08:15:02 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.021064778824512003, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.0806975061374513, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 17, 'num_filters_3': 35}, 'budget': 44.44444444444444, 'working_directory': '.'}
08:15:49 DISPATCHER: Starting worker discovery
08:15:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:15:49 DISPATCHER: Finished worker discovery
08:15:55 WORKER: done with job (0, 0, 26), trying to register it.
08:15:55 WORKER: registered result for job (0, 0, 26) with dispatcher
08:15:55 DISPATCHER: job (0, 0, 26) finished
08:15:55 DISPATCHER: register_result: lock acquired
08:15:55 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:15:55 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.021064778824512003, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.0806975061374513, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 17, 'num_filters_3': 35}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.22179059330144896, 'info': {'music-speech': 0.22179059330144896, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.021064778824512003, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.0806975061374513, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 17, 'num_filters_3': 35}"}}
exception: None

08:15:55 job_callback for (0, 0, 26) started
08:15:55 job_callback for (0, 0, 26) got condition
08:15:55 DISPATCHER: Trying to submit another job.
08:15:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:15:55 HBMASTER: Trying to run another job!
08:15:55 job_callback for (0, 0, 26) finished
08:15:55 ITERATION: Advancing config (0, 0, 4) to next budget 133.333333
08:15:55 ITERATION: Advancing config (0, 0, 6) to next budget 133.333333
08:15:55 ITERATION: Advancing config (0, 0, 7) to next budget 133.333333
08:15:55 ITERATION: Advancing config (0, 0, 15) to next budget 133.333333
08:15:55 ITERATION: Advancing config (0, 0, 16) to next budget 133.333333
08:15:55 ITERATION: Advancing config (0, 0, 18) to next budget 133.333333
08:15:55 ITERATION: Advancing config (0, 0, 19) to next budget 133.333333
08:15:55 ITERATION: Advancing config (0, 0, 20) to next budget 133.333333
08:15:55 ITERATION: Advancing config (0, 0, 22) to next budget 133.333333
08:15:55 HBMASTER: schedule new run for iteration 0
08:15:55 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
08:15:55 HBMASTER: submitting job (0, 0, 4) to dispatcher
08:15:55 DISPATCHER: trying to submit job (0, 0, 4)
08:15:55 DISPATCHER: trying to notify the job_runner thread.
08:15:55 HBMASTER: job (0, 0, 4) submitted to dispatcher
08:15:55 DISPATCHER: Trying to submit another job.
08:15:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:15:55 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:15:55 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:15:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:15:55 WORKER: start processing job (0, 0, 4)
08:15:55 WORKER: args: ()
08:15:55 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.005868567462725588, 'num_filters_1': 68, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.014983602130622048, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 46, 'num_filters_3': 33}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:16:49 DISPATCHER: Starting worker discovery
08:16:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:16:49 DISPATCHER: Finished worker discovery
08:17:49 DISPATCHER: Starting worker discovery
08:17:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:17:49 DISPATCHER: Finished worker discovery
08:18:18 WORKER: done with job (0, 0, 4), trying to register it.
08:18:18 WORKER: registered result for job (0, 0, 4) with dispatcher
08:18:18 DISPATCHER: job (0, 0, 4) finished
08:18:18 DISPATCHER: register_result: lock acquired
08:18:18 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:18:18 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.005868567462725588, 'num_filters_1': 68, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.014983602130622048, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 46, 'num_filters_3': 33}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8495047471364238, 'info': {'music-speech': 0.8495047471364238, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.005868567462725588, 'num_filters_1': 68, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 95, 'weight_decay': 0.014983602130622048, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 46, 'num_filters_3': 33}"}}
exception: None

08:18:18 job_callback for (0, 0, 4) started
08:18:18 job_callback for (0, 0, 4) got condition
08:18:18 DISPATCHER: Trying to submit another job.
08:18:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:18:18 Only 1 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
08:18:18 HBMASTER: Trying to run another job!
08:18:18 job_callback for (0, 0, 4) finished
08:18:18 HBMASTER: schedule new run for iteration 0
08:18:18 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
08:18:18 HBMASTER: submitting job (0, 0, 6) to dispatcher
08:18:18 DISPATCHER: trying to submit job (0, 0, 6)
08:18:18 DISPATCHER: trying to notify the job_runner thread.
08:18:18 HBMASTER: job (0, 0, 6) submitted to dispatcher
08:18:18 DISPATCHER: Trying to submit another job.
08:18:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:18:18 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:18:18 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:18:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:18:18 WORKER: start processing job (0, 0, 6)
08:18:18 WORKER: args: ()
08:18:18 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.001093746920765784, 'num_filters_1': 21, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.020423125757466822, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 73, 'num_filters_3': 28, 'num_filters_4': 125}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:18:49 DISPATCHER: Starting worker discovery
08:18:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:18:49 DISPATCHER: Finished worker discovery
08:19:49 DISPATCHER: Starting worker discovery
08:19:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:19:49 DISPATCHER: Finished worker discovery
08:20:40 WORKER: done with job (0, 0, 6), trying to register it.
08:20:40 WORKER: registered result for job (0, 0, 6) with dispatcher
08:20:40 DISPATCHER: job (0, 0, 6) finished
08:20:40 DISPATCHER: register_result: lock acquired
08:20:40 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:20:40 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.001093746920765784, 'num_filters_1': 21, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.020423125757466822, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 73, 'num_filters_3': 28, 'num_filters_4': 125}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9314642381735522, 'info': {'music-speech': 0.9314642381735522, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.001093746920765784, 'num_filters_1': 21, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.020423125757466822, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 73, 'num_filters_3': 28, 'num_filters_4': 125}"}}
exception: None

08:20:40 job_callback for (0, 0, 6) started
08:20:40 job_callback for (0, 0, 6) got condition
08:20:40 DISPATCHER: Trying to submit another job.
08:20:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:20:40 Only 2 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
08:20:40 HBMASTER: Trying to run another job!
08:20:40 job_callback for (0, 0, 6) finished
08:20:40 HBMASTER: schedule new run for iteration 0
08:20:40 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
08:20:40 HBMASTER: submitting job (0, 0, 7) to dispatcher
08:20:40 DISPATCHER: trying to submit job (0, 0, 7)
08:20:40 DISPATCHER: trying to notify the job_runner thread.
08:20:40 HBMASTER: job (0, 0, 7) submitted to dispatcher
08:20:40 DISPATCHER: Trying to submit another job.
08:20:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:20:40 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:20:40 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:20:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:20:40 WORKER: start processing job (0, 0, 7)
08:20:40 WORKER: args: ()
08:20:40 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.004825411187422723, 'num_filters_1': 95, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.015069387236933091, 'kernel_size_2': 7, 'num_filters_2': 28}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:20:49 DISPATCHER: Starting worker discovery
08:20:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:20:49 DISPATCHER: Finished worker discovery
08:21:49 DISPATCHER: Starting worker discovery
08:21:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:21:49 DISPATCHER: Finished worker discovery
08:22:49 DISPATCHER: Starting worker discovery
08:22:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:22:49 DISPATCHER: Finished worker discovery
08:23:04 WORKER: done with job (0, 0, 7), trying to register it.
08:23:04 DISPATCHER: job (0, 0, 7) finished
08:23:04 WORKER: registered result for job (0, 0, 7) with dispatcher
08:23:04 DISPATCHER: register_result: lock acquired
08:23:04 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:23:04 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.004825411187422723, 'num_filters_1': 95, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.015069387236933091, 'kernel_size_2': 7, 'num_filters_2': 28}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6962986191750278, 'info': {'music-speech': 0.6962986191750278, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.004825411187422723, 'num_filters_1': 95, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.015069387236933091, 'kernel_size_2': 7, 'num_filters_2': 28}"}}
exception: None

08:23:04 job_callback for (0, 0, 7) started
08:23:04 DISPATCHER: Trying to submit another job.
08:23:04 job_callback for (0, 0, 7) got condition
08:23:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:23:05 Only 3 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
08:23:05 HBMASTER: Trying to run another job!
08:23:05 job_callback for (0, 0, 7) finished
08:23:05 HBMASTER: schedule new run for iteration 0
08:23:05 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
08:23:05 HBMASTER: submitting job (0, 0, 15) to dispatcher
08:23:05 DISPATCHER: trying to submit job (0, 0, 15)
08:23:05 DISPATCHER: trying to notify the job_runner thread.
08:23:05 HBMASTER: job (0, 0, 15) submitted to dispatcher
08:23:05 DISPATCHER: Trying to submit another job.
08:23:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:23:05 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:23:05 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:23:05 WORKER: start processing job (0, 0, 15)
08:23:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:23:05 WORKER: args: ()
08:23:05 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.009194672216406175, 'num_filters_1': 26, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.09749428387476416, 'kernel_size_2': 3, 'num_filters_2': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:23:49 DISPATCHER: Starting worker discovery
08:23:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:23:49 DISPATCHER: Finished worker discovery
08:24:49 DISPATCHER: Starting worker discovery
08:24:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:24:49 DISPATCHER: Finished worker discovery
08:25:28 WORKER: done with job (0, 0, 15), trying to register it.
08:25:28 WORKER: registered result for job (0, 0, 15) with dispatcher
08:25:28 DISPATCHER: job (0, 0, 15) finished
08:25:28 DISPATCHER: register_result: lock acquired
08:25:28 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:25:28 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.009194672216406175, 'num_filters_1': 26, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.09749428387476416, 'kernel_size_2': 3, 'num_filters_2': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8672519679233737, 'info': {'music-speech': 0.8672519679233737, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.009194672216406175, 'num_filters_1': 26, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.09749428387476416, 'kernel_size_2': 3, 'num_filters_2': 17}"}}
exception: None

08:25:28 job_callback for (0, 0, 15) started
08:25:28 job_callback for (0, 0, 15) got condition
08:25:28 DISPATCHER: Trying to submit another job.
08:25:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:25:28 Only 4 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
08:25:28 HBMASTER: Trying to run another job!
08:25:28 job_callback for (0, 0, 15) finished
08:25:28 HBMASTER: schedule new run for iteration 0
08:25:28 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
08:25:28 HBMASTER: submitting job (0, 0, 16) to dispatcher
08:25:28 DISPATCHER: trying to submit job (0, 0, 16)
08:25:28 DISPATCHER: trying to notify the job_runner thread.
08:25:28 HBMASTER: job (0, 0, 16) submitted to dispatcher
08:25:28 DISPATCHER: Trying to submit another job.
08:25:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:25:28 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:25:28 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:25:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:25:28 WORKER: start processing job (0, 0, 16)
08:25:28 WORKER: args: ()
08:25:28 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0034848903823596084, 'num_filters_1': 102, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.011079058696131747, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 98, 'num_filters_3': 23, 'num_filters_4': 24, 'num_filters_5': 59}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:25:49 DISPATCHER: Starting worker discovery
08:25:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:25:49 DISPATCHER: Finished worker discovery
08:26:49 DISPATCHER: Starting worker discovery
08:26:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:26:49 DISPATCHER: Finished worker discovery
08:27:49 DISPATCHER: Starting worker discovery
08:27:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:27:49 DISPATCHER: Finished worker discovery
08:27:50 WORKER: done with job (0, 0, 16), trying to register it.
08:27:50 WORKER: registered result for job (0, 0, 16) with dispatcher
08:27:50 DISPATCHER: job (0, 0, 16) finished
08:27:50 DISPATCHER: register_result: lock acquired
08:27:50 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:27:50 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0034848903823596084, 'num_filters_1': 102, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.011079058696131747, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 98, 'num_filters_3': 23, 'num_filters_4': 24, 'num_filters_5': 59}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8616895919784968, 'info': {'music-speech': 0.8616895919784968, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0034848903823596084, 'num_filters_1': 102, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.011079058696131747, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 98, 'num_filters_3': 23, 'num_filters_4': 24, 'num_filters_5': 59}"}}
exception: None

08:27:50 job_callback for (0, 0, 16) started
08:27:50 DISPATCHER: Trying to submit another job.
08:27:50 job_callback for (0, 0, 16) got condition
08:27:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:27:50 Only 5 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
08:27:50 HBMASTER: Trying to run another job!
08:27:50 job_callback for (0, 0, 16) finished
08:27:50 HBMASTER: schedule new run for iteration 0
08:27:50 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
08:27:50 HBMASTER: submitting job (0, 0, 18) to dispatcher
08:27:50 DISPATCHER: trying to submit job (0, 0, 18)
08:27:50 DISPATCHER: trying to notify the job_runner thread.
08:27:50 HBMASTER: job (0, 0, 18) submitted to dispatcher
08:27:50 DISPATCHER: Trying to submit another job.
08:27:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:27:50 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:27:50 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:27:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:27:50 WORKER: start processing job (0, 0, 18)
08:27:50 WORKER: args: ()
08:27:50 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006773572424858516, 'num_filters_1': 54, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.07696902081537649, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 16, 'num_filters_3': 47, 'num_filters_4': 30}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:28:49 DISPATCHER: Starting worker discovery
08:28:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:28:49 DISPATCHER: Finished worker discovery
08:29:49 DISPATCHER: Starting worker discovery
08:29:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:29:49 DISPATCHER: Finished worker discovery
08:30:13 WORKER: done with job (0, 0, 18), trying to register it.
08:30:13 WORKER: registered result for job (0, 0, 18) with dispatcher
08:30:13 DISPATCHER: job (0, 0, 18) finished
08:30:13 DISPATCHER: register_result: lock acquired
08:30:13 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:30:13 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006773572424858516, 'num_filters_1': 54, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.07696902081537649, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 16, 'num_filters_3': 47, 'num_filters_4': 30}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8491289804505102, 'info': {'music-speech': 0.8491289804505102, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006773572424858516, 'num_filters_1': 54, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 26, 'weight_decay': 0.07696902081537649, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 16, 'num_filters_3': 47, 'num_filters_4': 30}"}}
exception: None

08:30:13 job_callback for (0, 0, 18) started
08:30:13 job_callback for (0, 0, 18) got condition
08:30:13 DISPATCHER: Trying to submit another job.
08:30:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:30:13 Only 6 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
08:30:13 HBMASTER: Trying to run another job!
08:30:13 job_callback for (0, 0, 18) finished
08:30:13 HBMASTER: schedule new run for iteration 0
08:30:13 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
08:30:13 HBMASTER: submitting job (0, 0, 19) to dispatcher
08:30:13 DISPATCHER: trying to submit job (0, 0, 19)
08:30:13 DISPATCHER: trying to notify the job_runner thread.
08:30:13 HBMASTER: job (0, 0, 19) submitted to dispatcher
08:30:13 DISPATCHER: Trying to submit another job.
08:30:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:30:13 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:30:13 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:30:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:30:13 WORKER: start processing job (0, 0, 19)
08:30:13 WORKER: args: ()
08:30:13 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.02388734214366955, 'num_filters_1': 38, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 11, 'weight_decay': 0.01111804077577953}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:30:49 DISPATCHER: Starting worker discovery
08:30:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:30:49 DISPATCHER: Finished worker discovery
08:31:49 DISPATCHER: Starting worker discovery
08:31:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:31:49 DISPATCHER: Finished worker discovery
08:32:35 WORKER: done with job (0, 0, 19), trying to register it.
08:32:35 WORKER: registered result for job (0, 0, 19) with dispatcher
08:32:35 DISPATCHER: job (0, 0, 19) finished
08:32:35 DISPATCHER: register_result: lock acquired
08:32:35 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:32:35 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.02388734214366955, 'num_filters_1': 38, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 11, 'weight_decay': 0.01111804077577953}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.704784081719558, 'info': {'music-speech': 0.704784081719558, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.02388734214366955, 'num_filters_1': 38, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 11, 'weight_decay': 0.01111804077577953}"}}
exception: None

08:32:35 job_callback for (0, 0, 19) started
08:32:35 job_callback for (0, 0, 19) got condition
08:32:35 DISPATCHER: Trying to submit another job.
08:32:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:32:35 Only 7 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
08:32:35 HBMASTER: Trying to run another job!
08:32:35 job_callback for (0, 0, 19) finished
08:32:35 HBMASTER: schedule new run for iteration 0
08:32:35 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
08:32:35 HBMASTER: submitting job (0, 0, 20) to dispatcher
08:32:35 DISPATCHER: trying to submit job (0, 0, 20)
08:32:35 DISPATCHER: trying to notify the job_runner thread.
08:32:35 HBMASTER: job (0, 0, 20) submitted to dispatcher
08:32:35 DISPATCHER: Trying to submit another job.
08:32:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:32:35 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:32:35 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:32:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:32:35 WORKER: start processing job (0, 0, 20)
08:32:35 WORKER: args: ()
08:32:35 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005045250580694626, 'num_filters_1': 19, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.18334432508666906, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 55, 'num_filters_3': 83, 'num_filters_4': 64}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:32:49 DISPATCHER: Starting worker discovery
08:32:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:32:49 DISPATCHER: Finished worker discovery
08:33:49 DISPATCHER: Starting worker discovery
08:33:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:33:49 DISPATCHER: Finished worker discovery
08:34:49 DISPATCHER: Starting worker discovery
08:34:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:34:49 DISPATCHER: Finished worker discovery
08:34:58 WORKER: done with job (0, 0, 20), trying to register it.
08:34:58 WORKER: registered result for job (0, 0, 20) with dispatcher
08:34:58 DISPATCHER: job (0, 0, 20) finished
08:34:58 DISPATCHER: register_result: lock acquired
08:34:58 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:34:58 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005045250580694626, 'num_filters_1': 19, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.18334432508666906, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 55, 'num_filters_3': 83, 'num_filters_4': 64}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.005045250580694626, 'num_filters_1': 19, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.18334432508666906, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 55, 'num_filters_3': 83, 'num_filters_4': 64}"}}
exception: None

08:34:58 job_callback for (0, 0, 20) started
08:34:58 DISPATCHER: Trying to submit another job.
08:34:58 job_callback for (0, 0, 20) got condition
08:34:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:34:58 Only 8 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
08:34:58 HBMASTER: Trying to run another job!
08:34:58 job_callback for (0, 0, 20) finished
08:34:58 HBMASTER: schedule new run for iteration 0
08:34:58 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
08:34:58 HBMASTER: submitting job (0, 0, 22) to dispatcher
08:34:58 DISPATCHER: trying to submit job (0, 0, 22)
08:34:58 DISPATCHER: trying to notify the job_runner thread.
08:34:58 HBMASTER: job (0, 0, 22) submitted to dispatcher
08:34:58 DISPATCHER: Trying to submit another job.
08:34:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:34:58 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:34:58 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:34:58 WORKER: start processing job (0, 0, 22)
08:34:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:34:58 WORKER: args: ()
08:34:58 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0025720599021979563, 'num_filters_1': 91, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.030050170096807348, 'kernel_size_2': 3, 'num_filters_2': 122}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:35:49 DISPATCHER: Starting worker discovery
08:35:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:35:49 DISPATCHER: Finished worker discovery
08:36:49 DISPATCHER: Starting worker discovery
08:36:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:36:49 DISPATCHER: Finished worker discovery
08:37:20 WORKER: done with job (0, 0, 22), trying to register it.
08:37:20 WORKER: registered result for job (0, 0, 22) with dispatcher
08:37:20 DISPATCHER: job (0, 0, 22) finished
08:37:20 DISPATCHER: register_result: lock acquired
08:37:20 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:37:20 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0025720599021979563, 'num_filters_1': 91, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.030050170096807348, 'kernel_size_2': 3, 'num_filters_2': 122}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9045553046639492, 'info': {'music-speech': 0.9045553046639492, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0025720599021979563, 'num_filters_1': 91, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.030050170096807348, 'kernel_size_2': 3, 'num_filters_2': 122}"}}
exception: None

08:37:20 job_callback for (0, 0, 22) started
08:37:20 DISPATCHER: Trying to submit another job.
08:37:20 job_callback for (0, 0, 22) got condition
08:37:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:37:20 Only 9 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
08:37:20 HBMASTER: Trying to run another job!
08:37:20 job_callback for (0, 0, 22) finished
08:37:20 ITERATION: Advancing config (0, 0, 6) to next budget 400.000000
08:37:20 ITERATION: Advancing config (0, 0, 15) to next budget 400.000000
08:37:20 ITERATION: Advancing config (0, 0, 22) to next budget 400.000000
08:37:20 HBMASTER: schedule new run for iteration 0
08:37:20 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
08:37:20 HBMASTER: submitting job (0, 0, 6) to dispatcher
08:37:20 DISPATCHER: trying to submit job (0, 0, 6)
08:37:20 DISPATCHER: trying to notify the job_runner thread.
08:37:20 HBMASTER: job (0, 0, 6) submitted to dispatcher
08:37:20 DISPATCHER: Trying to submit another job.
08:37:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:37:20 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:37:20 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:37:20 WORKER: start processing job (0, 0, 6)
08:37:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:37:20 WORKER: args: ()
08:37:20 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.001093746920765784, 'num_filters_1': 21, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.020423125757466822, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 73, 'num_filters_3': 28, 'num_filters_4': 125}, 'budget': 400.0, 'working_directory': '.'}
08:37:49 DISPATCHER: Starting worker discovery
08:37:49 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:37:49 DISPATCHER: Finished worker discovery
08:38:49 DISPATCHER: Starting worker discovery
08:38:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:38:50 DISPATCHER: Finished worker discovery
08:39:50 DISPATCHER: Starting worker discovery
08:39:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:39:50 DISPATCHER: Finished worker discovery
08:40:50 DISPATCHER: Starting worker discovery
08:40:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:40:50 DISPATCHER: Finished worker discovery
08:41:50 DISPATCHER: Starting worker discovery
08:41:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:41:50 DISPATCHER: Finished worker discovery
08:42:50 DISPATCHER: Starting worker discovery
08:42:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:42:50 DISPATCHER: Finished worker discovery
08:43:50 DISPATCHER: Starting worker discovery
08:43:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:43:50 DISPATCHER: Finished worker discovery
08:44:10 WORKER: done with job (0, 0, 6), trying to register it.
08:44:10 WORKER: registered result for job (0, 0, 6) with dispatcher
08:44:10 DISPATCHER: job (0, 0, 6) finished
08:44:10 DISPATCHER: register_result: lock acquired
08:44:10 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:44:10 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.001093746920765784, 'num_filters_1': 21, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.020423125757466822, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 73, 'num_filters_3': 28, 'num_filters_4': 125}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9026440307518828, 'info': {'music-speech': 0.9026440307518828, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.001093746920765784, 'num_filters_1': 21, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.020423125757466822, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 73, 'num_filters_3': 28, 'num_filters_4': 125}"}}
exception: None

08:44:10 job_callback for (0, 0, 6) started
08:44:10 DISPATCHER: Trying to submit another job.
08:44:10 job_callback for (0, 0, 6) got condition
08:44:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:44:10 Only 1 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
08:44:10 HBMASTER: Trying to run another job!
08:44:10 job_callback for (0, 0, 6) finished
08:44:10 HBMASTER: schedule new run for iteration 0
08:44:10 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
08:44:10 HBMASTER: submitting job (0, 0, 15) to dispatcher
08:44:10 DISPATCHER: trying to submit job (0, 0, 15)
08:44:10 DISPATCHER: trying to notify the job_runner thread.
08:44:10 HBMASTER: job (0, 0, 15) submitted to dispatcher
08:44:10 DISPATCHER: Trying to submit another job.
08:44:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:44:10 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:44:10 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:44:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:44:10 WORKER: start processing job (0, 0, 15)
08:44:10 WORKER: args: ()
08:44:10 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.009194672216406175, 'num_filters_1': 26, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.09749428387476416, 'kernel_size_2': 3, 'num_filters_2': 17}, 'budget': 400.0, 'working_directory': '.'}
08:44:50 DISPATCHER: Starting worker discovery
08:44:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:44:50 DISPATCHER: Finished worker discovery
08:45:50 DISPATCHER: Starting worker discovery
08:45:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:45:50 DISPATCHER: Finished worker discovery
08:46:50 DISPATCHER: Starting worker discovery
08:46:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:46:50 DISPATCHER: Finished worker discovery
08:47:50 DISPATCHER: Starting worker discovery
08:47:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:47:50 DISPATCHER: Finished worker discovery
08:48:50 DISPATCHER: Starting worker discovery
08:48:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:48:50 DISPATCHER: Finished worker discovery
08:49:50 DISPATCHER: Starting worker discovery
08:49:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:49:50 DISPATCHER: Finished worker discovery
08:50:50 DISPATCHER: Starting worker discovery
08:50:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:50:50 DISPATCHER: Finished worker discovery
08:50:59 WORKER: done with job (0, 0, 15), trying to register it.
08:50:59 WORKER: registered result for job (0, 0, 15) with dispatcher
08:50:59 DISPATCHER: job (0, 0, 15) finished
08:50:59 DISPATCHER: register_result: lock acquired
08:50:59 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:50:59 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.009194672216406175, 'num_filters_1': 26, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.09749428387476416, 'kernel_size_2': 3, 'num_filters_2': 17}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7858750201611742, 'info': {'music-speech': 0.7858750201611742, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.009194672216406175, 'num_filters_1': 26, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.09749428387476416, 'kernel_size_2': 3, 'num_filters_2': 17}"}}
exception: None

08:50:59 job_callback for (0, 0, 15) started
08:50:59 DISPATCHER: Trying to submit another job.
08:50:59 job_callback for (0, 0, 15) got condition
08:50:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:50:59 Only 2 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
08:50:59 HBMASTER: Trying to run another job!
08:50:59 job_callback for (0, 0, 15) finished
08:50:59 HBMASTER: schedule new run for iteration 0
08:50:59 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
08:50:59 HBMASTER: submitting job (0, 0, 22) to dispatcher
08:50:59 DISPATCHER: trying to submit job (0, 0, 22)
08:50:59 DISPATCHER: trying to notify the job_runner thread.
08:50:59 HBMASTER: job (0, 0, 22) submitted to dispatcher
08:50:59 DISPATCHER: Trying to submit another job.
08:50:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:50:59 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:50:59 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:50:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:50:59 WORKER: start processing job (0, 0, 22)
08:50:59 WORKER: args: ()
08:50:59 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0025720599021979563, 'num_filters_1': 91, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.030050170096807348, 'kernel_size_2': 3, 'num_filters_2': 122}, 'budget': 400.0, 'working_directory': '.'}
08:51:50 DISPATCHER: Starting worker discovery
08:51:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:51:50 DISPATCHER: Finished worker discovery
08:52:50 DISPATCHER: Starting worker discovery
08:52:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:52:50 DISPATCHER: Finished worker discovery
08:53:50 DISPATCHER: Starting worker discovery
08:53:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:53:50 DISPATCHER: Finished worker discovery
08:54:50 DISPATCHER: Starting worker discovery
08:54:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:54:50 DISPATCHER: Finished worker discovery
08:55:50 DISPATCHER: Starting worker discovery
08:55:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:55:50 DISPATCHER: Finished worker discovery
08:56:50 DISPATCHER: Starting worker discovery
08:56:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:56:50 DISPATCHER: Finished worker discovery
08:57:48 WORKER: done with job (0, 0, 22), trying to register it.
08:57:48 WORKER: registered result for job (0, 0, 22) with dispatcher
08:57:48 DISPATCHER: job (0, 0, 22) finished
08:57:48 DISPATCHER: register_result: lock acquired
08:57:48 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:57:48 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0025720599021979563, 'num_filters_1': 91, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.030050170096807348, 'kernel_size_2': 3, 'num_filters_2': 122}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6673540739516075, 'info': {'music-speech': 0.6673540739516075, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0025720599021979563, 'num_filters_1': 91, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.030050170096807348, 'kernel_size_2': 3, 'num_filters_2': 122}"}}
exception: None

08:57:48 job_callback for (0, 0, 22) started
08:57:48 job_callback for (0, 0, 22) got condition
08:57:48 DISPATCHER: Trying to submit another job.
08:57:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:57:48 Only 3 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
08:57:48 HBMASTER: Trying to run another job!
08:57:48 job_callback for (0, 0, 22) finished
08:57:48 ITERATION: Advancing config (0, 0, 6) to next budget 1200.000000
08:57:48 HBMASTER: schedule new run for iteration 0
08:57:48 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
08:57:48 HBMASTER: submitting job (0, 0, 6) to dispatcher
08:57:48 DISPATCHER: trying to submit job (0, 0, 6)
08:57:48 DISPATCHER: trying to notify the job_runner thread.
08:57:48 HBMASTER: job (0, 0, 6) submitted to dispatcher
08:57:48 DISPATCHER: Trying to submit another job.
08:57:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:57:48 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:57:48 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:57:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:57:48 WORKER: start processing job (0, 0, 6)
08:57:48 WORKER: args: ()
08:57:48 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.001093746920765784, 'num_filters_1': 21, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.020423125757466822, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 73, 'num_filters_3': 28, 'num_filters_4': 125}, 'budget': 1200.0, 'working_directory': '.'}
08:57:50 DISPATCHER: Starting worker discovery
08:57:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:57:50 DISPATCHER: Finished worker discovery
08:58:50 DISPATCHER: Starting worker discovery
08:58:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:58:50 DISPATCHER: Finished worker discovery
08:59:50 DISPATCHER: Starting worker discovery
08:59:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:59:50 DISPATCHER: Finished worker discovery
09:00:50 DISPATCHER: Starting worker discovery
09:00:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:00:50 DISPATCHER: Finished worker discovery
09:01:50 DISPATCHER: Starting worker discovery
09:01:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:01:50 DISPATCHER: Finished worker discovery
09:02:50 DISPATCHER: Starting worker discovery
09:02:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:02:50 DISPATCHER: Finished worker discovery
09:03:50 DISPATCHER: Starting worker discovery
09:03:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:03:50 DISPATCHER: Finished worker discovery
09:04:50 DISPATCHER: Starting worker discovery
09:04:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:04:50 DISPATCHER: Finished worker discovery
09:05:50 DISPATCHER: Starting worker discovery
09:05:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:05:50 DISPATCHER: Finished worker discovery
09:06:50 DISPATCHER: Starting worker discovery
09:06:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:06:50 DISPATCHER: Finished worker discovery
09:07:50 DISPATCHER: Starting worker discovery
09:07:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:07:50 DISPATCHER: Finished worker discovery
09:08:50 DISPATCHER: Starting worker discovery
09:08:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:08:50 DISPATCHER: Finished worker discovery
09:09:50 DISPATCHER: Starting worker discovery
09:09:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:09:50 DISPATCHER: Finished worker discovery
09:10:50 DISPATCHER: Starting worker discovery
09:10:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:10:50 DISPATCHER: Finished worker discovery
09:11:50 DISPATCHER: Starting worker discovery
09:11:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:11:50 DISPATCHER: Finished worker discovery
09:12:50 DISPATCHER: Starting worker discovery
09:12:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:12:50 DISPATCHER: Finished worker discovery
09:13:50 DISPATCHER: Starting worker discovery
09:13:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:13:50 DISPATCHER: Finished worker discovery
09:14:50 DISPATCHER: Starting worker discovery
09:14:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:14:50 DISPATCHER: Finished worker discovery
09:15:50 DISPATCHER: Starting worker discovery
09:15:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:15:50 DISPATCHER: Finished worker discovery
09:16:50 DISPATCHER: Starting worker discovery
09:16:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:16:50 DISPATCHER: Finished worker discovery
09:17:50 DISPATCHER: Starting worker discovery
09:17:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:17:50 DISPATCHER: Finished worker discovery
09:17:58 WORKER: done with job (0, 0, 6), trying to register it.
09:17:58 DISPATCHER: job (0, 0, 6) finished
09:17:58 WORKER: registered result for job (0, 0, 6) with dispatcher
09:17:58 DISPATCHER: register_result: lock acquired
09:17:58 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:17:58 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.001093746920765784, 'num_filters_1': 21, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.020423125757466822, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 73, 'num_filters_3': 28, 'num_filters_4': 125}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9167270078517658, 'info': {'music-speech': 0.9167270078517658, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.001093746920765784, 'num_filters_1': 21, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.020423125757466822, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 73, 'num_filters_3': 28, 'num_filters_4': 125}"}}
exception: None

09:17:58 job_callback for (0, 0, 6) started
09:17:58 DISPATCHER: Trying to submit another job.
09:17:58 job_callback for (0, 0, 6) got condition
09:17:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:17:58 Only 1 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
09:17:58 HBMASTER: Trying to run another job!
09:17:58 job_callback for (0, 0, 6) finished
09:17:58 start sampling a new configuration.
09:17:58 done sampling a new configuration.
09:17:58 HBMASTER: schedule new run for iteration 1
09:17:58 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
09:17:58 HBMASTER: submitting job (1, 0, 0) to dispatcher
09:17:58 DISPATCHER: trying to submit job (1, 0, 0)
09:17:58 DISPATCHER: trying to notify the job_runner thread.
09:17:58 HBMASTER: job (1, 0, 0) submitted to dispatcher
09:17:58 DISPATCHER: Trying to submit another job.
09:17:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:17:58 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:17:58 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:17:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:17:58 WORKER: start processing job (1, 0, 0)
09:17:58 WORKER: args: ()
09:17:58 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0022875490590563204, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.024137492253749625, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 105, 'num_filters_3': 20, 'num_filters_4': 54}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:18:50 DISPATCHER: Starting worker discovery
09:18:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:18:50 DISPATCHER: Finished worker discovery
09:19:50 DISPATCHER: Starting worker discovery
09:19:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:19:50 DISPATCHER: Finished worker discovery
09:20:21 WORKER: done with job (1, 0, 0), trying to register it.
09:20:21 WORKER: registered result for job (1, 0, 0) with dispatcher
09:20:21 DISPATCHER: job (1, 0, 0) finished
09:20:21 DISPATCHER: register_result: lock acquired
09:20:21 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:20:21 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0022875490590563204, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.024137492253749625, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 105, 'num_filters_3': 20, 'num_filters_4': 54}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.935357498554326, 'info': {'music-speech': 0.935357498554326, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0022875490590563204, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.024137492253749625, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 105, 'num_filters_3': 20, 'num_filters_4': 54}"}}
exception: None

09:20:21 job_callback for (1, 0, 0) started
09:20:21 DISPATCHER: Trying to submit another job.
09:20:21 job_callback for (1, 0, 0) got condition
09:20:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:20:21 Only 10 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
09:20:21 HBMASTER: Trying to run another job!
09:20:21 job_callback for (1, 0, 0) finished
09:20:21 start sampling a new configuration.
09:20:21 done sampling a new configuration.
09:20:21 HBMASTER: schedule new run for iteration 1
09:20:21 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
09:20:21 HBMASTER: submitting job (1, 0, 1) to dispatcher
09:20:21 DISPATCHER: trying to submit job (1, 0, 1)
09:20:21 DISPATCHER: trying to notify the job_runner thread.
09:20:21 HBMASTER: job (1, 0, 1) submitted to dispatcher
09:20:21 DISPATCHER: Trying to submit another job.
09:20:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:20:21 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:20:21 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:20:21 WORKER: start processing job (1, 0, 1)
09:20:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:20:21 WORKER: args: ()
09:20:21 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.053687415435518734, 'num_filters_1': 97, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.036514701336195284, 'kernel_size_2': 5, 'num_filters_2': 18}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:20:50 DISPATCHER: Starting worker discovery
09:20:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:20:50 DISPATCHER: Finished worker discovery
Exception in thread Thread-251:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

09:21:50 DISPATCHER: Starting worker discovery
09:21:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:21:50 DISPATCHER: Finished worker discovery
09:22:43 WORKER: done with job (1, 0, 1), trying to register it.
09:22:43 WORKER: registered result for job (1, 0, 1) with dispatcher
09:22:43 DISPATCHER: job (1, 0, 1) finished
09:22:43 DISPATCHER: register_result: lock acquired
09:22:43 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:22:43 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.053687415435518734, 'num_filters_1': 97, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.036514701336195284, 'kernel_size_2': 5, 'num_filters_2': 18}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.07583594319515931, 'info': {'music-speech': 0.07583594319515931, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.053687415435518734, 'num_filters_1': 97, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.036514701336195284, 'kernel_size_2': 5, 'num_filters_2': 18}"}}
exception: None

09:22:43 job_callback for (1, 0, 1) started
09:22:43 DISPATCHER: Trying to submit another job.
09:22:43 job_callback for (1, 0, 1) got condition
09:22:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:22:43 Only 11 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
09:22:43 HBMASTER: Trying to run another job!
09:22:43 job_callback for (1, 0, 1) finished
09:22:43 start sampling a new configuration.
09:22:43 done sampling a new configuration.
09:22:43 HBMASTER: schedule new run for iteration 1
09:22:43 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
09:22:43 HBMASTER: submitting job (1, 0, 2) to dispatcher
09:22:43 DISPATCHER: trying to submit job (1, 0, 2)
09:22:43 DISPATCHER: trying to notify the job_runner thread.
09:22:43 HBMASTER: job (1, 0, 2) submitted to dispatcher
09:22:43 DISPATCHER: Trying to submit another job.
09:22:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:22:43 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:22:43 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:22:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:22:43 WORKER: start processing job (1, 0, 2)
09:22:43 WORKER: args: ()
09:22:43 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.05180712575049063, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.04333730079687017}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:22:50 DISPATCHER: Starting worker discovery
09:22:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:22:50 DISPATCHER: Finished worker discovery
Exception in thread Thread-252:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

09:23:50 DISPATCHER: Starting worker discovery
09:23:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:23:50 DISPATCHER: Finished worker discovery
09:24:50 DISPATCHER: Starting worker discovery
09:24:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:24:50 DISPATCHER: Finished worker discovery
09:25:05 WORKER: done with job (1, 0, 2), trying to register it.
09:25:05 DISPATCHER: job (1, 0, 2) finished
09:25:05 WORKER: registered result for job (1, 0, 2) with dispatcher
09:25:05 DISPATCHER: register_result: lock acquired
09:25:05 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:25:05 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.05180712575049063, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.04333730079687017}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': 0.04190237436009671, 'info': {'music-speech': -0.04190237436009671, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.05180712575049063, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.04333730079687017}"}}
exception: None

09:25:05 job_callback for (1, 0, 2) started
09:25:05 DISPATCHER: Trying to submit another job.
09:25:05 job_callback for (1, 0, 2) got condition
09:25:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:25:05 Only 12 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
09:25:05 HBMASTER: Trying to run another job!
09:25:05 job_callback for (1, 0, 2) finished
09:25:05 start sampling a new configuration.
09:25:05 done sampling a new configuration.
09:25:05 HBMASTER: schedule new run for iteration 1
09:25:05 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
09:25:05 HBMASTER: submitting job (1, 0, 3) to dispatcher
09:25:05 DISPATCHER: trying to submit job (1, 0, 3)
09:25:05 DISPATCHER: trying to notify the job_runner thread.
09:25:05 HBMASTER: job (1, 0, 3) submitted to dispatcher
09:25:05 DISPATCHER: Trying to submit another job.
09:25:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:25:05 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:25:05 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:25:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:25:05 WORKER: start processing job (1, 0, 3)
09:25:05 WORKER: args: ()
09:25:05 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.03348599497639729, 'num_filters_1': 50, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.11137656708593144, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 24, 'num_filters_3': 43, 'num_filters_4': 113}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:25:50 DISPATCHER: Starting worker discovery
09:25:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:25:50 DISPATCHER: Finished worker discovery
09:26:50 DISPATCHER: Starting worker discovery
09:26:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:26:50 DISPATCHER: Finished worker discovery
09:27:28 WORKER: done with job (1, 0, 3), trying to register it.
09:27:28 WORKER: registered result for job (1, 0, 3) with dispatcher
09:27:28 DISPATCHER: job (1, 0, 3) finished
09:27:28 DISPATCHER: register_result: lock acquired
09:27:28 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:27:28 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.03348599497639729, 'num_filters_1': 50, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.11137656708593144, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 24, 'num_filters_3': 43, 'num_filters_4': 113}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.03348599497639729, 'num_filters_1': 50, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.11137656708593144, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 24, 'num_filters_3': 43, 'num_filters_4': 113}"}}
exception: None

09:27:28 job_callback for (1, 0, 3) started
09:27:28 DISPATCHER: Trying to submit another job.
09:27:28 job_callback for (1, 0, 3) got condition
09:27:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:27:28 Only 13 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
09:27:28 HBMASTER: Trying to run another job!
09:27:28 job_callback for (1, 0, 3) finished
09:27:28 start sampling a new configuration.
09:27:28 done sampling a new configuration.
09:27:28 HBMASTER: schedule new run for iteration 1
09:27:28 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
09:27:28 HBMASTER: submitting job (1, 0, 4) to dispatcher
09:27:28 DISPATCHER: trying to submit job (1, 0, 4)
09:27:28 DISPATCHER: trying to notify the job_runner thread.
09:27:28 HBMASTER: job (1, 0, 4) submitted to dispatcher
09:27:28 DISPATCHER: Trying to submit another job.
09:27:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:27:28 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:27:28 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:27:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:27:28 WORKER: start processing job (1, 0, 4)
09:27:28 WORKER: args: ()
09:27:28 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.04341709625385188, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.040673085292061865, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 50, 'num_filters_3': 20, 'num_filters_4': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:27:50 DISPATCHER: Starting worker discovery
09:27:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:27:50 DISPATCHER: Finished worker discovery
09:28:50 DISPATCHER: Starting worker discovery
09:28:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:28:50 DISPATCHER: Finished worker discovery
09:29:50 DISPATCHER: Starting worker discovery
09:29:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:29:50 DISPATCHER: Finished worker discovery
09:29:52 WORKER: done with job (1, 0, 4), trying to register it.
09:29:52 WORKER: registered result for job (1, 0, 4) with dispatcher
09:29:52 DISPATCHER: job (1, 0, 4) finished
09:29:52 DISPATCHER: register_result: lock acquired
09:29:52 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:29:52 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.04341709625385188, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.040673085292061865, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 50, 'num_filters_3': 20, 'num_filters_4': 43}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.04341709625385188, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.040673085292061865, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 50, 'num_filters_3': 20, 'num_filters_4': 43}"}}
exception: None

09:29:52 job_callback for (1, 0, 4) started
09:29:52 job_callback for (1, 0, 4) got condition
09:29:52 DISPATCHER: Trying to submit another job.
09:29:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:29:52 Only 14 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
09:29:52 HBMASTER: Trying to run another job!
09:29:52 job_callback for (1, 0, 4) finished
09:29:52 start sampling a new configuration.
09:29:52 done sampling a new configuration.
09:29:52 HBMASTER: schedule new run for iteration 1
09:29:52 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
09:29:52 HBMASTER: submitting job (1, 0, 5) to dispatcher
09:29:52 DISPATCHER: trying to submit job (1, 0, 5)
09:29:52 DISPATCHER: trying to notify the job_runner thread.
09:29:52 HBMASTER: job (1, 0, 5) submitted to dispatcher
09:29:52 DISPATCHER: Trying to submit another job.
09:29:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:29:52 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:29:52 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:29:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:29:52 WORKER: start processing job (1, 0, 5)
09:29:52 WORKER: args: ()
09:29:52 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.008515414840108964, 'num_filters_1': 82, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.02884470662856626, 'kernel_size_2': 5, 'num_filters_2': 38}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:30:50 DISPATCHER: Starting worker discovery
09:30:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:30:50 DISPATCHER: Finished worker discovery
09:31:50 DISPATCHER: Starting worker discovery
09:31:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:31:50 DISPATCHER: Finished worker discovery
09:32:14 WORKER: done with job (1, 0, 5), trying to register it.
09:32:14 WORKER: registered result for job (1, 0, 5) with dispatcher
09:32:14 DISPATCHER: job (1, 0, 5) finished
09:32:14 DISPATCHER: register_result: lock acquired
09:32:14 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:32:14 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.008515414840108964, 'num_filters_1': 82, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.02884470662856626, 'kernel_size_2': 5, 'num_filters_2': 38}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.581316038983135, 'info': {'music-speech': 0.581316038983135, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.008515414840108964, 'num_filters_1': 82, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.02884470662856626, 'kernel_size_2': 5, 'num_filters_2': 38}"}}
exception: None

09:32:14 job_callback for (1, 0, 5) started
09:32:14 job_callback for (1, 0, 5) got condition
09:32:14 DISPATCHER: Trying to submit another job.
09:32:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:32:14 Only 15 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
09:32:14 HBMASTER: Trying to run another job!
09:32:14 job_callback for (1, 0, 5) finished
09:32:14 start sampling a new configuration.
09:32:14 done sampling a new configuration.
09:32:14 HBMASTER: schedule new run for iteration 1
09:32:14 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
09:32:14 HBMASTER: submitting job (1, 0, 6) to dispatcher
09:32:14 DISPATCHER: trying to submit job (1, 0, 6)
09:32:14 DISPATCHER: trying to notify the job_runner thread.
09:32:14 HBMASTER: job (1, 0, 6) submitted to dispatcher
09:32:14 DISPATCHER: Trying to submit another job.
09:32:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:32:14 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:32:14 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:32:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:32:14 WORKER: start processing job (1, 0, 6)
09:32:14 WORKER: args: ()
09:32:14 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.08784404660849962, 'num_filters_1': 49, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.039761149541976445}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:32:50 DISPATCHER: Starting worker discovery
09:32:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:32:50 DISPATCHER: Finished worker discovery
09:33:50 DISPATCHER: Starting worker discovery
09:33:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:33:50 DISPATCHER: Finished worker discovery
09:34:36 WORKER: done with job (1, 0, 6), trying to register it.
09:34:36 WORKER: registered result for job (1, 0, 6) with dispatcher
09:34:36 DISPATCHER: job (1, 0, 6) finished
09:34:36 DISPATCHER: register_result: lock acquired
09:34:36 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:34:36 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.08784404660849962, 'num_filters_1': 49, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.039761149541976445}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.06435859965342579, 'info': {'music-speech': 0.06435859965342579, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.08784404660849962, 'num_filters_1': 49, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.039761149541976445}"}}
exception: None

09:34:36 job_callback for (1, 0, 6) started
09:34:36 DISPATCHER: Trying to submit another job.
09:34:36 job_callback for (1, 0, 6) got condition
09:34:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:34:36 Only 16 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
09:34:36 HBMASTER: Trying to run another job!
09:34:36 job_callback for (1, 0, 6) finished
09:34:36 start sampling a new configuration.
09:34:36 done sampling a new configuration.
09:34:36 HBMASTER: schedule new run for iteration 1
09:34:36 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
09:34:36 HBMASTER: submitting job (1, 0, 7) to dispatcher
09:34:36 DISPATCHER: trying to submit job (1, 0, 7)
09:34:36 DISPATCHER: trying to notify the job_runner thread.
09:34:36 HBMASTER: job (1, 0, 7) submitted to dispatcher
09:34:36 DISPATCHER: Trying to submit another job.
09:34:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:34:36 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:34:36 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:34:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:34:36 WORKER: start processing job (1, 0, 7)
09:34:36 WORKER: args: ()
09:34:36 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.021382076431743814, 'num_filters_1': 65, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.06993467110908445, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 25, 'num_filters_3': 29}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-257:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 2147483647 is out of bounds for axis 0 with size 2

09:34:50 DISPATCHER: Starting worker discovery
09:34:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:34:50 DISPATCHER: Finished worker discovery
09:35:50 DISPATCHER: Starting worker discovery
09:35:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:35:50 DISPATCHER: Finished worker discovery
09:36:50 DISPATCHER: Starting worker discovery
09:36:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:36:50 DISPATCHER: Finished worker discovery
09:36:58 WORKER: done with job (1, 0, 7), trying to register it.
09:36:58 WORKER: registered result for job (1, 0, 7) with dispatcher
09:36:58 DISPATCHER: job (1, 0, 7) finished
09:36:58 DISPATCHER: register_result: lock acquired
09:36:58 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:36:58 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.021382076431743814, 'num_filters_1': 65, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.06993467110908445, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 25, 'num_filters_3': 29}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5330364982442993, 'info': {'music-speech': 0.5330364982442993, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.021382076431743814, 'num_filters_1': 65, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.06993467110908445, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 25, 'num_filters_3': 29}"}}
exception: None

09:36:58 job_callback for (1, 0, 7) started
09:36:58 DISPATCHER: Trying to submit another job.
09:36:58 job_callback for (1, 0, 7) got condition
09:36:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:36:58 HBMASTER: Trying to run another job!
09:36:58 job_callback for (1, 0, 7) finished
09:36:58 start sampling a new configuration.
09:36:58 done sampling a new configuration.
09:36:58 HBMASTER: schedule new run for iteration 1
09:36:58 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
09:36:58 HBMASTER: submitting job (1, 0, 8) to dispatcher
09:36:58 DISPATCHER: trying to submit job (1, 0, 8)
09:36:58 DISPATCHER: trying to notify the job_runner thread.
09:36:58 HBMASTER: job (1, 0, 8) submitted to dispatcher
09:36:58 DISPATCHER: Trying to submit another job.
09:36:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:36:58 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:36:58 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:36:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:36:58 WORKER: start processing job (1, 0, 8)
09:36:58 WORKER: args: ()
09:36:58 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0017604156513336751, 'num_filters_1': 50, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.09055836781147734}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:37:50 DISPATCHER: Starting worker discovery
09:37:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:37:50 DISPATCHER: Finished worker discovery
09:38:50 DISPATCHER: Starting worker discovery
09:38:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:38:50 DISPATCHER: Finished worker discovery
09:39:24 WORKER: done with job (1, 0, 8), trying to register it.
09:39:24 WORKER: registered result for job (1, 0, 8) with dispatcher
09:39:24 DISPATCHER: job (1, 0, 8) finished
09:39:24 DISPATCHER: register_result: lock acquired
09:39:24 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:39:24 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0017604156513336751, 'num_filters_1': 50, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.09055836781147734}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.961751469674494, 'info': {'music-speech': 0.961751469674494, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0017604156513336751, 'num_filters_1': 50, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.09055836781147734}"}}
exception: None

09:39:24 job_callback for (1, 0, 8) started
09:39:24 job_callback for (1, 0, 8) got condition
09:39:24 DISPATCHER: Trying to submit another job.
09:39:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:39:24 HBMASTER: Trying to run another job!
09:39:24 job_callback for (1, 0, 8) finished
09:39:24 ITERATION: Advancing config (1, 0, 0) to next budget 400.000000
09:39:24 ITERATION: Advancing config (1, 0, 5) to next budget 400.000000
09:39:24 ITERATION: Advancing config (1, 0, 8) to next budget 400.000000
09:39:24 HBMASTER: schedule new run for iteration 1
09:39:24 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
09:39:24 HBMASTER: submitting job (1, 0, 0) to dispatcher
09:39:24 DISPATCHER: trying to submit job (1, 0, 0)
09:39:24 DISPATCHER: trying to notify the job_runner thread.
09:39:24 HBMASTER: job (1, 0, 0) submitted to dispatcher
09:39:24 DISPATCHER: Trying to submit another job.
09:39:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:39:24 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:39:24 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:39:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:39:24 WORKER: start processing job (1, 0, 0)
09:39:24 WORKER: args: ()
09:39:24 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0022875490590563204, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.024137492253749625, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 105, 'num_filters_3': 20, 'num_filters_4': 54}, 'budget': 400.0, 'working_directory': '.'}
09:39:50 DISPATCHER: Starting worker discovery
09:39:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:39:50 DISPATCHER: Finished worker discovery
09:40:50 DISPATCHER: Starting worker discovery
09:40:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:40:50 DISPATCHER: Finished worker discovery
09:41:50 DISPATCHER: Starting worker discovery
09:41:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:41:50 DISPATCHER: Finished worker discovery
09:42:50 DISPATCHER: Starting worker discovery
09:42:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:42:50 DISPATCHER: Finished worker discovery
09:43:50 DISPATCHER: Starting worker discovery
09:43:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:43:50 DISPATCHER: Finished worker discovery
09:44:50 DISPATCHER: Starting worker discovery
09:44:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:44:50 DISPATCHER: Finished worker discovery
09:45:50 DISPATCHER: Starting worker discovery
09:45:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:45:50 DISPATCHER: Finished worker discovery
09:46:13 WORKER: done with job (1, 0, 0), trying to register it.
09:46:13 WORKER: registered result for job (1, 0, 0) with dispatcher
09:46:13 DISPATCHER: job (1, 0, 0) finished
09:46:13 DISPATCHER: register_result: lock acquired
09:46:13 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:46:13 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0022875490590563204, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.024137492253749625, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 105, 'num_filters_3': 20, 'num_filters_4': 54}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9790565310415954, 'info': {'music-speech': 0.9790565310415954, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0022875490590563204, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.024137492253749625, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 105, 'num_filters_3': 20, 'num_filters_4': 54}"}}
exception: None

09:46:13 job_callback for (1, 0, 0) started
09:46:13 DISPATCHER: Trying to submit another job.
09:46:13 job_callback for (1, 0, 0) got condition
09:46:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:46:13 Only 4 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
09:46:13 HBMASTER: Trying to run another job!
09:46:13 job_callback for (1, 0, 0) finished
09:46:13 HBMASTER: schedule new run for iteration 1
09:46:13 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
09:46:13 HBMASTER: submitting job (1, 0, 5) to dispatcher
09:46:13 DISPATCHER: trying to submit job (1, 0, 5)
09:46:13 DISPATCHER: trying to notify the job_runner thread.
09:46:13 HBMASTER: job (1, 0, 5) submitted to dispatcher
09:46:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:46:13 DISPATCHER: Trying to submit another job.
09:46:13 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:46:13 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:46:13 WORKER: start processing job (1, 0, 5)
09:46:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:46:13 WORKER: args: ()
09:46:13 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.008515414840108964, 'num_filters_1': 82, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.02884470662856626, 'kernel_size_2': 5, 'num_filters_2': 38}, 'budget': 400.0, 'working_directory': '.'}
09:46:50 DISPATCHER: Starting worker discovery
09:46:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:46:50 DISPATCHER: Finished worker discovery
09:47:50 DISPATCHER: Starting worker discovery
09:47:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:47:50 DISPATCHER: Finished worker discovery
09:48:50 DISPATCHER: Starting worker discovery
09:48:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:48:50 DISPATCHER: Finished worker discovery
09:49:50 DISPATCHER: Starting worker discovery
09:49:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:49:50 DISPATCHER: Finished worker discovery
09:50:50 DISPATCHER: Starting worker discovery
09:50:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:50:50 DISPATCHER: Finished worker discovery
09:51:50 DISPATCHER: Starting worker discovery
09:51:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:51:50 DISPATCHER: Finished worker discovery
09:52:50 DISPATCHER: Starting worker discovery
09:52:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:52:50 DISPATCHER: Finished worker discovery
09:53:02 WORKER: done with job (1, 0, 5), trying to register it.
09:53:02 WORKER: registered result for job (1, 0, 5) with dispatcher
09:53:02 DISPATCHER: job (1, 0, 5) finished
09:53:02 DISPATCHER: register_result: lock acquired
09:53:02 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:53:02 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.008515414840108964, 'num_filters_1': 82, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.02884470662856626, 'kernel_size_2': 5, 'num_filters_2': 38}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7296333696663426, 'info': {'music-speech': 0.7296333696663426, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.008515414840108964, 'num_filters_1': 82, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.02884470662856626, 'kernel_size_2': 5, 'num_filters_2': 38}"}}
exception: None

09:53:02 job_callback for (1, 0, 5) started
09:53:02 DISPATCHER: Trying to submit another job.
09:53:02 job_callback for (1, 0, 5) got condition
09:53:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:53:02 Only 5 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
09:53:02 HBMASTER: Trying to run another job!
09:53:02 job_callback for (1, 0, 5) finished
09:53:02 HBMASTER: schedule new run for iteration 1
09:53:02 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
09:53:02 HBMASTER: submitting job (1, 0, 8) to dispatcher
09:53:02 DISPATCHER: trying to submit job (1, 0, 8)
09:53:02 DISPATCHER: trying to notify the job_runner thread.
09:53:02 HBMASTER: job (1, 0, 8) submitted to dispatcher
09:53:02 DISPATCHER: Trying to submit another job.
09:53:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:53:02 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:53:02 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:53:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:53:02 WORKER: start processing job (1, 0, 8)
09:53:02 WORKER: args: ()
09:53:02 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0017604156513336751, 'num_filters_1': 50, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.09055836781147734}, 'budget': 400.0, 'working_directory': '.'}
09:53:50 DISPATCHER: Starting worker discovery
09:53:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:53:50 DISPATCHER: Finished worker discovery
09:54:50 DISPATCHER: Starting worker discovery
09:54:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:54:50 DISPATCHER: Finished worker discovery
09:55:50 DISPATCHER: Starting worker discovery
09:55:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:55:50 DISPATCHER: Finished worker discovery
09:56:50 DISPATCHER: Starting worker discovery
09:56:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:56:50 DISPATCHER: Finished worker discovery
09:57:50 DISPATCHER: Starting worker discovery
09:57:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:57:50 DISPATCHER: Finished worker discovery
09:58:50 DISPATCHER: Starting worker discovery
09:58:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:58:50 DISPATCHER: Finished worker discovery
09:59:50 DISPATCHER: Starting worker discovery
09:59:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:59:50 DISPATCHER: Finished worker discovery
09:59:52 WORKER: done with job (1, 0, 8), trying to register it.
09:59:52 DISPATCHER: job (1, 0, 8) finished
09:59:52 WORKER: registered result for job (1, 0, 8) with dispatcher
09:59:52 DISPATCHER: register_result: lock acquired
09:59:52 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:59:52 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0017604156513336751, 'num_filters_1': 50, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.09055836781147734}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9732507499353715, 'info': {'music-speech': 0.9732507499353715, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0017604156513336751, 'num_filters_1': 50, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.09055836781147734}"}}
exception: None

09:59:52 job_callback for (1, 0, 8) started
09:59:52 DISPATCHER: Trying to submit another job.
09:59:52 job_callback for (1, 0, 8) got condition
09:59:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:59:52 Only 6 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
09:59:52 HBMASTER: Trying to run another job!
09:59:52 job_callback for (1, 0, 8) finished
09:59:52 ITERATION: Advancing config (1, 0, 0) to next budget 1200.000000
09:59:52 HBMASTER: schedule new run for iteration 1
09:59:52 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
09:59:52 HBMASTER: submitting job (1, 0, 0) to dispatcher
09:59:52 DISPATCHER: trying to submit job (1, 0, 0)
09:59:52 DISPATCHER: trying to notify the job_runner thread.
09:59:52 HBMASTER: job (1, 0, 0) submitted to dispatcher
09:59:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:59:52 DISPATCHER: Trying to submit another job.
09:59:52 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:59:52 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:59:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:59:52 WORKER: start processing job (1, 0, 0)
09:59:52 WORKER: args: ()
09:59:52 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0022875490590563204, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.024137492253749625, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 105, 'num_filters_3': 20, 'num_filters_4': 54}, 'budget': 1200.0, 'working_directory': '.'}
10:00:50 DISPATCHER: Starting worker discovery
10:00:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:00:51 DISPATCHER: Finished worker discovery
10:01:51 DISPATCHER: Starting worker discovery
10:01:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:01:51 DISPATCHER: Finished worker discovery
10:02:51 DISPATCHER: Starting worker discovery
10:02:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:02:51 DISPATCHER: Finished worker discovery
10:03:51 DISPATCHER: Starting worker discovery
10:03:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:03:51 DISPATCHER: Finished worker discovery
10:04:51 DISPATCHER: Starting worker discovery
10:04:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:04:51 DISPATCHER: Finished worker discovery
10:05:51 DISPATCHER: Starting worker discovery
10:05:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:05:51 DISPATCHER: Finished worker discovery
10:06:51 DISPATCHER: Starting worker discovery
10:06:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:06:51 DISPATCHER: Finished worker discovery
10:07:51 DISPATCHER: Starting worker discovery
10:07:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:07:51 DISPATCHER: Finished worker discovery
10:08:51 DISPATCHER: Starting worker discovery
10:08:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:08:51 DISPATCHER: Finished worker discovery
10:09:51 DISPATCHER: Starting worker discovery
10:09:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:09:51 DISPATCHER: Finished worker discovery
10:10:51 DISPATCHER: Starting worker discovery
10:10:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:10:51 DISPATCHER: Finished worker discovery
10:11:51 DISPATCHER: Starting worker discovery
10:11:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:11:51 DISPATCHER: Finished worker discovery
10:12:51 DISPATCHER: Starting worker discovery
10:12:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:12:51 DISPATCHER: Finished worker discovery
10:13:51 DISPATCHER: Starting worker discovery
10:13:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:13:51 DISPATCHER: Finished worker discovery
10:14:51 DISPATCHER: Starting worker discovery
10:14:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:14:51 DISPATCHER: Finished worker discovery
10:15:51 DISPATCHER: Starting worker discovery
10:15:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:15:51 DISPATCHER: Finished worker discovery
10:16:51 DISPATCHER: Starting worker discovery
10:16:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:16:51 DISPATCHER: Finished worker discovery
10:17:51 DISPATCHER: Starting worker discovery
10:17:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:17:51 DISPATCHER: Finished worker discovery
10:18:51 DISPATCHER: Starting worker discovery
10:18:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:18:51 DISPATCHER: Finished worker discovery
10:19:51 DISPATCHER: Starting worker discovery
10:19:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:19:51 DISPATCHER: Finished worker discovery
10:20:04 WORKER: done with job (1, 0, 0), trying to register it.
10:20:04 WORKER: registered result for job (1, 0, 0) with dispatcher
10:20:04 DISPATCHER: job (1, 0, 0) finished
10:20:04 DISPATCHER: register_result: lock acquired
10:20:04 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
10:20:04 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0022875490590563204, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.024137492253749625, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 105, 'num_filters_3': 20, 'num_filters_4': 54}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9236814982124272, 'info': {'music-speech': 0.9236814982124272, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0022875490590563204, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.024137492253749625, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 105, 'num_filters_3': 20, 'num_filters_4': 54}"}}
exception: None

10:20:04 job_callback for (1, 0, 0) started
10:20:04 DISPATCHER: Trying to submit another job.
10:20:04 job_callback for (1, 0, 0) got condition
10:20:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:20:04 Only 2 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
10:20:04 HBMASTER: Trying to run another job!
10:20:04 job_callback for (1, 0, 0) finished
10:20:04 start sampling a new configuration.
10:20:04 done sampling a new configuration.
10:20:04 HBMASTER: schedule new run for iteration 2
10:20:04 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
10:20:04 HBMASTER: submitting job (2, 0, 0) to dispatcher
10:20:04 DISPATCHER: trying to submit job (2, 0, 0)
10:20:04 DISPATCHER: trying to notify the job_runner thread.
10:20:04 HBMASTER: job (2, 0, 0) submitted to dispatcher
10:20:04 DISPATCHER: Trying to submit another job.
10:20:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:20:04 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
10:20:04 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
10:20:04 WORKER: start processing job (2, 0, 0)
10:20:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:20:04 WORKER: args: ()
10:20:04 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.04048067224714991, 'num_filters_1': 41, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.0330053020985372, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 110, 'num_filters_3': 27}, 'budget': 400.0, 'working_directory': '.'}
10:20:51 DISPATCHER: Starting worker discovery
10:20:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:20:51 DISPATCHER: Finished worker discovery
10:21:51 DISPATCHER: Starting worker discovery
10:21:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:21:51 DISPATCHER: Finished worker discovery
10:22:51 DISPATCHER: Starting worker discovery
10:22:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:22:51 DISPATCHER: Finished worker discovery
10:23:51 DISPATCHER: Starting worker discovery
10:23:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:23:51 DISPATCHER: Finished worker discovery
10:24:51 DISPATCHER: Starting worker discovery
10:24:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:24:51 DISPATCHER: Finished worker discovery
10:25:51 DISPATCHER: Starting worker discovery
10:25:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:25:51 DISPATCHER: Finished worker discovery
10:26:51 DISPATCHER: Starting worker discovery
10:26:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:26:51 DISPATCHER: Finished worker discovery
10:26:54 WORKER: done with job (2, 0, 0), trying to register it.
10:26:54 WORKER: registered result for job (2, 0, 0) with dispatcher
10:26:54 DISPATCHER: job (2, 0, 0) finished
10:26:54 DISPATCHER: register_result: lock acquired
10:26:54 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
10:26:54 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.04048067224714991, 'num_filters_1': 41, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.0330053020985372, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 110, 'num_filters_3': 27}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.07685964499424437, 'info': {'music-speech': 0.07685964499424437, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.04048067224714991, 'num_filters_1': 41, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.0330053020985372, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 110, 'num_filters_3': 27}"}}
exception: None

10:26:54 job_callback for (2, 0, 0) started
10:26:54 DISPATCHER: Trying to submit another job.
10:26:54 job_callback for (2, 0, 0) got condition
10:26:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:26:54 Only 7 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
10:26:54 HBMASTER: Trying to run another job!
10:26:54 job_callback for (2, 0, 0) finished
10:26:54 start sampling a new configuration.
10:26:54 done sampling a new configuration.
10:26:54 HBMASTER: schedule new run for iteration 2
10:26:54 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
10:26:54 HBMASTER: submitting job (2, 0, 1) to dispatcher
10:26:54 DISPATCHER: trying to submit job (2, 0, 1)
10:26:54 DISPATCHER: trying to notify the job_runner thread.
10:26:54 HBMASTER: job (2, 0, 1) submitted to dispatcher
10:26:54 DISPATCHER: Trying to submit another job.
10:26:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:26:54 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
10:26:54 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
10:26:54 WORKER: start processing job (2, 0, 1)
10:26:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:26:54 WORKER: args: ()
10:26:54 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0011263138983411754, 'num_filters_1': 34, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.06381947036014417, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 29, 'num_filters_3': 35}, 'budget': 400.0, 'working_directory': '.'}
10:27:51 DISPATCHER: Starting worker discovery
10:27:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:27:51 DISPATCHER: Finished worker discovery
10:28:51 DISPATCHER: Starting worker discovery
10:28:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:28:51 DISPATCHER: Finished worker discovery
10:29:51 DISPATCHER: Starting worker discovery
10:29:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:29:51 DISPATCHER: Finished worker discovery
10:30:51 DISPATCHER: Starting worker discovery
10:30:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:30:51 DISPATCHER: Finished worker discovery
10:31:51 DISPATCHER: Starting worker discovery
10:31:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:31:51 DISPATCHER: Finished worker discovery
10:32:51 DISPATCHER: Starting worker discovery
10:32:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:32:51 DISPATCHER: Finished worker discovery
10:33:44 WORKER: done with job (2, 0, 1), trying to register it.
10:33:44 WORKER: registered result for job (2, 0, 1) with dispatcher
10:33:44 DISPATCHER: job (2, 0, 1) finished
10:33:44 DISPATCHER: register_result: lock acquired
10:33:44 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
10:33:44 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0011263138983411754, 'num_filters_1': 34, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.06381947036014417, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 29, 'num_filters_3': 35}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9007346640588304, 'info': {'music-speech': 0.9007346640588304, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0011263138983411754, 'num_filters_1': 34, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.06381947036014417, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 29, 'num_filters_3': 35}"}}
exception: None

10:33:44 job_callback for (2, 0, 1) started
10:33:44 job_callback for (2, 0, 1) got condition
10:33:44 DISPATCHER: Trying to submit another job.
10:33:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:33:44 Only 8 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
10:33:44 HBMASTER: Trying to run another job!
10:33:44 job_callback for (2, 0, 1) finished
10:33:44 start sampling a new configuration.
10:33:44 done sampling a new configuration.
10:33:44 HBMASTER: schedule new run for iteration 2
10:33:44 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
10:33:44 HBMASTER: submitting job (2, 0, 2) to dispatcher
10:33:44 DISPATCHER: trying to submit job (2, 0, 2)
10:33:44 DISPATCHER: trying to notify the job_runner thread.
10:33:44 HBMASTER: job (2, 0, 2) submitted to dispatcher
10:33:44 DISPATCHER: Trying to submit another job.
10:33:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:33:44 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
10:33:44 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
10:33:44 WORKER: start processing job (2, 0, 2)
10:33:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:33:44 WORKER: args: ()
10:33:44 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006285685250941895, 'num_filters_1': 50, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.012098771783898775, 'kernel_size_2': 5, 'num_filters_2': 29}, 'budget': 400.0, 'working_directory': '.'}
10:33:51 DISPATCHER: Starting worker discovery
10:33:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:33:51 DISPATCHER: Finished worker discovery
10:34:51 DISPATCHER: Starting worker discovery
10:34:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:34:51 DISPATCHER: Finished worker discovery
10:35:51 DISPATCHER: Starting worker discovery
10:35:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:35:51 DISPATCHER: Finished worker discovery
10:36:51 DISPATCHER: Starting worker discovery
10:36:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:36:51 DISPATCHER: Finished worker discovery
10:37:51 DISPATCHER: Starting worker discovery
10:37:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:37:51 DISPATCHER: Finished worker discovery
10:38:51 DISPATCHER: Starting worker discovery
10:38:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:38:51 DISPATCHER: Finished worker discovery
10:39:51 DISPATCHER: Starting worker discovery
10:39:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:39:51 DISPATCHER: Finished worker discovery
10:40:35 WORKER: done with job (2, 0, 2), trying to register it.
10:40:35 DISPATCHER: job (2, 0, 2) finished
10:40:35 WORKER: registered result for job (2, 0, 2) with dispatcher
10:40:35 DISPATCHER: register_result: lock acquired
10:40:35 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
10:40:35 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006285685250941895, 'num_filters_1': 50, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.012098771783898775, 'kernel_size_2': 5, 'num_filters_2': 29}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8736013095719267, 'info': {'music-speech': 0.8736013095719267, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006285685250941895, 'num_filters_1': 50, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.012098771783898775, 'kernel_size_2': 5, 'num_filters_2': 29}"}}
exception: None

10:40:35 job_callback for (2, 0, 2) started
10:40:35 DISPATCHER: Trying to submit another job.
10:40:35 job_callback for (2, 0, 2) got condition
10:40:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:40:35 Only 9 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
10:40:35 HBMASTER: Trying to run another job!
10:40:35 job_callback for (2, 0, 2) finished
10:40:35 start sampling a new configuration.
10:40:35 done sampling a new configuration.
10:40:36 HBMASTER: schedule new run for iteration 2
10:40:36 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
10:40:36 HBMASTER: submitting job (2, 0, 3) to dispatcher
10:40:36 DISPATCHER: trying to submit job (2, 0, 3)
10:40:36 DISPATCHER: trying to notify the job_runner thread.
10:40:36 HBMASTER: job (2, 0, 3) submitted to dispatcher
10:40:36 DISPATCHER: Trying to submit another job.
10:40:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:40:36 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
10:40:36 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
10:40:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:40:36 WORKER: start processing job (2, 0, 3)
10:40:36 WORKER: args: ()
10:40:36 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.06635765348212017, 'num_filters_1': 124, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.014497102167390974, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 90, 'num_filters_3': 44, 'num_filters_4': 24, 'num_filters_5': 71}, 'budget': 400.0, 'working_directory': '.'}
10:40:51 DISPATCHER: Starting worker discovery
10:40:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:40:51 DISPATCHER: Finished worker discovery
10:41:51 DISPATCHER: Starting worker discovery
10:41:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:41:51 DISPATCHER: Finished worker discovery
10:42:51 DISPATCHER: Starting worker discovery
10:42:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:42:51 DISPATCHER: Finished worker discovery
10:43:51 DISPATCHER: Starting worker discovery
10:43:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:43:51 DISPATCHER: Finished worker discovery
10:44:51 DISPATCHER: Starting worker discovery
10:44:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:44:51 DISPATCHER: Finished worker discovery
10:45:51 DISPATCHER: Starting worker discovery
10:45:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:45:51 DISPATCHER: Finished worker discovery
10:46:51 DISPATCHER: Starting worker discovery
10:46:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:46:51 DISPATCHER: Finished worker discovery
10:47:25 WORKER: done with job (2, 0, 3), trying to register it.
10:47:25 DISPATCHER: job (2, 0, 3) finished
10:47:25 WORKER: registered result for job (2, 0, 3) with dispatcher
10:47:25 DISPATCHER: register_result: lock acquired
10:47:25 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
10:47:25 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.06635765348212017, 'num_filters_1': 124, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.014497102167390974, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 90, 'num_filters_3': 44, 'num_filters_4': 24, 'num_filters_5': 71}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.06635765348212017, 'num_filters_1': 124, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.014497102167390974, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 90, 'num_filters_3': 44, 'num_filters_4': 24, 'num_filters_5': 71}"}}
exception: None

10:47:25 job_callback for (2, 0, 3) started
10:47:25 DISPATCHER: Trying to submit another job.
10:47:25 job_callback for (2, 0, 3) got condition
10:47:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:47:25 Only 10 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
10:47:25 HBMASTER: Trying to run another job!
10:47:25 job_callback for (2, 0, 3) finished
10:47:25 start sampling a new configuration.
10:47:25 done sampling a new configuration.
10:47:25 HBMASTER: schedule new run for iteration 2
10:47:25 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
10:47:25 HBMASTER: submitting job (2, 0, 4) to dispatcher
10:47:25 DISPATCHER: trying to submit job (2, 0, 4)
10:47:25 DISPATCHER: trying to notify the job_runner thread.
10:47:25 HBMASTER: job (2, 0, 4) submitted to dispatcher
10:47:25 DISPATCHER: Trying to submit another job.
10:47:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:47:25 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
10:47:25 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
10:47:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:47:25 WORKER: start processing job (2, 0, 4)
10:47:25 WORKER: args: ()
10:47:25 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.006763309470052224, 'num_filters_1': 114, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.01427634033852558, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 63, 'num_filters_3': 23, 'num_filters_4': 22}, 'budget': 400.0, 'working_directory': '.'}
10:47:51 DISPATCHER: Starting worker discovery
10:47:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:47:51 DISPATCHER: Finished worker discovery
10:48:51 DISPATCHER: Starting worker discovery
10:48:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:48:51 DISPATCHER: Finished worker discovery
10:49:51 DISPATCHER: Starting worker discovery
10:49:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:49:51 DISPATCHER: Finished worker discovery
10:50:51 DISPATCHER: Starting worker discovery
10:50:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:50:52 DISPATCHER: Finished worker discovery
10:51:52 DISPATCHER: Starting worker discovery
10:51:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:51:52 DISPATCHER: Finished worker discovery
10:52:52 DISPATCHER: Starting worker discovery
10:52:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:52:52 DISPATCHER: Finished worker discovery
10:53:52 DISPATCHER: Starting worker discovery
10:53:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:53:52 DISPATCHER: Finished worker discovery
10:54:14 WORKER: done with job (2, 0, 4), trying to register it.
10:54:14 WORKER: registered result for job (2, 0, 4) with dispatcher
10:54:14 DISPATCHER: job (2, 0, 4) finished
10:54:14 DISPATCHER: register_result: lock acquired
10:54:14 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
10:54:14 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.006763309470052224, 'num_filters_1': 114, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.01427634033852558, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 63, 'num_filters_3': 23, 'num_filters_4': 22}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9107142454520814, 'info': {'music-speech': 0.9107142454520814, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.006763309470052224, 'num_filters_1': 114, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.01427634033852558, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 63, 'num_filters_3': 23, 'num_filters_4': 22}"}}
exception: None

10:54:14 job_callback for (2, 0, 4) started
10:54:14 DISPATCHER: Trying to submit another job.
10:54:14 job_callback for (2, 0, 4) got condition
10:54:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:54:14 Only 11 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
10:54:14 HBMASTER: Trying to run another job!
10:54:14 job_callback for (2, 0, 4) finished
10:54:14 start sampling a new configuration.
10:54:14 done sampling a new configuration.
10:54:14 HBMASTER: schedule new run for iteration 2
10:54:14 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
10:54:14 HBMASTER: submitting job (2, 0, 5) to dispatcher
10:54:14 DISPATCHER: trying to submit job (2, 0, 5)
10:54:14 DISPATCHER: trying to notify the job_runner thread.
10:54:14 HBMASTER: job (2, 0, 5) submitted to dispatcher
10:54:14 DISPATCHER: Trying to submit another job.
10:54:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:54:14 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
10:54:14 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
10:54:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:54:14 WORKER: start processing job (2, 0, 5)
10:54:14 WORKER: args: ()
10:54:14 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.002823348350434287, 'num_filters_1': 32, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.01610164601418499, 'kernel_size_2': 5, 'num_filters_2': 106}, 'budget': 400.0, 'working_directory': '.'}
10:54:52 DISPATCHER: Starting worker discovery
10:54:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:54:52 DISPATCHER: Finished worker discovery
10:55:52 DISPATCHER: Starting worker discovery
10:55:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:55:52 DISPATCHER: Finished worker discovery
10:56:52 DISPATCHER: Starting worker discovery
10:56:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:56:52 DISPATCHER: Finished worker discovery
10:57:52 DISPATCHER: Starting worker discovery
10:57:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:57:52 DISPATCHER: Finished worker discovery
10:58:52 DISPATCHER: Starting worker discovery
10:58:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:58:52 DISPATCHER: Finished worker discovery
10:59:52 DISPATCHER: Starting worker discovery
10:59:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:59:52 DISPATCHER: Finished worker discovery
11:00:52 DISPATCHER: Starting worker discovery
11:00:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:00:52 DISPATCHER: Finished worker discovery
11:01:03 WORKER: done with job (2, 0, 5), trying to register it.
11:01:04 DISPATCHER: job (2, 0, 5) finished
11:01:04 WORKER: registered result for job (2, 0, 5) with dispatcher
11:01:04 DISPATCHER: register_result: lock acquired
11:01:04 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
11:01:04 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.002823348350434287, 'num_filters_1': 32, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.01610164601418499, 'kernel_size_2': 5, 'num_filters_2': 106}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6637653251490667, 'info': {'music-speech': 0.6637653251490667, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.002823348350434287, 'num_filters_1': 32, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.01610164601418499, 'kernel_size_2': 5, 'num_filters_2': 106}"}}
exception: None

11:01:04 job_callback for (2, 0, 5) started
11:01:04 DISPATCHER: Trying to submit another job.
11:01:04 job_callback for (2, 0, 5) got condition
11:01:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:01:04 Only 12 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
11:01:04 HBMASTER: Trying to run another job!
11:01:04 job_callback for (2, 0, 5) finished
11:01:04 ITERATION: Advancing config (2, 0, 1) to next budget 1200.000000
11:01:04 ITERATION: Advancing config (2, 0, 4) to next budget 1200.000000
11:01:04 HBMASTER: schedule new run for iteration 2
11:01:04 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
11:01:04 HBMASTER: submitting job (2, 0, 1) to dispatcher
11:01:04 DISPATCHER: trying to submit job (2, 0, 1)
11:01:04 DISPATCHER: trying to notify the job_runner thread.
11:01:04 HBMASTER: job (2, 0, 1) submitted to dispatcher
11:01:04 DISPATCHER: Trying to submit another job.
11:01:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:01:04 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
11:01:04 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
11:01:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:01:04 WORKER: start processing job (2, 0, 1)
11:01:04 WORKER: args: ()
11:01:04 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0011263138983411754, 'num_filters_1': 34, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.06381947036014417, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 29, 'num_filters_3': 35}, 'budget': 1200.0, 'working_directory': '.'}
11:01:52 DISPATCHER: Starting worker discovery
11:01:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:01:52 DISPATCHER: Finished worker discovery
11:02:52 DISPATCHER: Starting worker discovery
11:02:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:02:52 DISPATCHER: Finished worker discovery
11:03:52 DISPATCHER: Starting worker discovery
11:03:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:03:52 DISPATCHER: Finished worker discovery
11:04:52 DISPATCHER: Starting worker discovery
11:04:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:04:52 DISPATCHER: Finished worker discovery
11:05:52 DISPATCHER: Starting worker discovery
11:05:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:05:52 DISPATCHER: Finished worker discovery
11:06:52 DISPATCHER: Starting worker discovery
11:06:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:06:52 DISPATCHER: Finished worker discovery
11:07:52 DISPATCHER: Starting worker discovery
11:07:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:07:52 DISPATCHER: Finished worker discovery
11:08:52 DISPATCHER: Starting worker discovery
11:08:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:08:52 DISPATCHER: Finished worker discovery
11:09:52 DISPATCHER: Starting worker discovery
11:09:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:09:52 DISPATCHER: Finished worker discovery
11:10:52 DISPATCHER: Starting worker discovery
11:10:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:10:52 DISPATCHER: Finished worker discovery
11:11:52 DISPATCHER: Starting worker discovery
11:11:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:11:52 DISPATCHER: Finished worker discovery
11:12:52 DISPATCHER: Starting worker discovery
11:12:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:12:52 DISPATCHER: Finished worker discovery
11:13:52 DISPATCHER: Starting worker discovery
11:13:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:13:52 DISPATCHER: Finished worker discovery
11:14:52 DISPATCHER: Starting worker discovery
11:14:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:14:52 DISPATCHER: Finished worker discovery
11:15:52 DISPATCHER: Starting worker discovery
11:15:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:15:52 DISPATCHER: Finished worker discovery
11:16:52 DISPATCHER: Starting worker discovery
11:16:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:16:52 DISPATCHER: Finished worker discovery
11:17:52 DISPATCHER: Starting worker discovery
11:17:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:17:52 DISPATCHER: Finished worker discovery
11:18:52 DISPATCHER: Starting worker discovery
11:18:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:18:52 DISPATCHER: Finished worker discovery
11:19:52 DISPATCHER: Starting worker discovery
11:19:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:19:52 DISPATCHER: Finished worker discovery
11:20:52 DISPATCHER: Starting worker discovery
11:20:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:20:52 DISPATCHER: Finished worker discovery
11:21:14 WORKER: done with job (2, 0, 1), trying to register it.
11:21:14 DISPATCHER: job (2, 0, 1) finished
11:21:14 WORKER: registered result for job (2, 0, 1) with dispatcher
11:21:14 DISPATCHER: register_result: lock acquired
11:21:14 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
11:21:14 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0011263138983411754, 'num_filters_1': 34, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.06381947036014417, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 29, 'num_filters_3': 35}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.8968393302212212, 'info': {'music-speech': 0.8968393302212212, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0011263138983411754, 'num_filters_1': 34, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.06381947036014417, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 29, 'num_filters_3': 35}"}}
exception: None

11:21:14 job_callback for (2, 0, 1) started
11:21:14 DISPATCHER: Trying to submit another job.
11:21:14 job_callback for (2, 0, 1) got condition
11:21:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:21:14 Only 3 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
11:21:14 HBMASTER: Trying to run another job!
11:21:14 job_callback for (2, 0, 1) finished
11:21:14 HBMASTER: schedule new run for iteration 2
11:21:14 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
11:21:14 HBMASTER: submitting job (2, 0, 4) to dispatcher
11:21:14 DISPATCHER: trying to submit job (2, 0, 4)
11:21:14 DISPATCHER: trying to notify the job_runner thread.
11:21:14 HBMASTER: job (2, 0, 4) submitted to dispatcher
11:21:14 DISPATCHER: Trying to submit another job.
11:21:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:21:14 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
11:21:14 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
11:21:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:21:14 WORKER: start processing job (2, 0, 4)
11:21:14 WORKER: args: ()
11:21:14 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.006763309470052224, 'num_filters_1': 114, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.01427634033852558, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 63, 'num_filters_3': 23, 'num_filters_4': 22}, 'budget': 1200.0, 'working_directory': '.'}
11:21:52 DISPATCHER: Starting worker discovery
11:21:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:21:52 DISPATCHER: Finished worker discovery
11:22:52 DISPATCHER: Starting worker discovery
11:22:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:22:52 DISPATCHER: Finished worker discovery
11:23:52 DISPATCHER: Starting worker discovery
11:23:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:23:52 DISPATCHER: Finished worker discovery
11:24:52 DISPATCHER: Starting worker discovery
11:24:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:24:52 DISPATCHER: Finished worker discovery
11:25:52 DISPATCHER: Starting worker discovery
11:25:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:25:52 DISPATCHER: Finished worker discovery
11:26:52 DISPATCHER: Starting worker discovery
11:26:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:26:52 DISPATCHER: Finished worker discovery
11:27:52 DISPATCHER: Starting worker discovery
11:27:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:27:52 DISPATCHER: Finished worker discovery
11:28:52 DISPATCHER: Starting worker discovery
11:28:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:28:52 DISPATCHER: Finished worker discovery
11:29:52 DISPATCHER: Starting worker discovery
11:29:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:29:52 DISPATCHER: Finished worker discovery
11:30:52 DISPATCHER: Starting worker discovery
11:30:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:30:52 DISPATCHER: Finished worker discovery
11:31:52 DISPATCHER: Starting worker discovery
11:31:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:31:52 DISPATCHER: Finished worker discovery
11:32:52 DISPATCHER: Starting worker discovery
11:32:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:32:52 DISPATCHER: Finished worker discovery
11:33:52 DISPATCHER: Starting worker discovery
11:33:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:33:52 DISPATCHER: Finished worker discovery
11:34:52 DISPATCHER: Starting worker discovery
11:34:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:34:52 DISPATCHER: Finished worker discovery
11:35:52 DISPATCHER: Starting worker discovery
11:35:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:35:52 DISPATCHER: Finished worker discovery
11:36:52 DISPATCHER: Starting worker discovery
11:36:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:36:52 DISPATCHER: Finished worker discovery
11:37:52 DISPATCHER: Starting worker discovery
11:37:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:37:52 DISPATCHER: Finished worker discovery
11:38:52 DISPATCHER: Starting worker discovery
11:38:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:38:52 DISPATCHER: Finished worker discovery
11:39:52 DISPATCHER: Starting worker discovery
11:39:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:39:52 DISPATCHER: Finished worker discovery
11:40:52 DISPATCHER: Starting worker discovery
11:40:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:40:52 DISPATCHER: Finished worker discovery
11:41:24 WORKER: done with job (2, 0, 4), trying to register it.
11:41:24 WORKER: registered result for job (2, 0, 4) with dispatcher
11:41:24 DISPATCHER: job (2, 0, 4) finished
11:41:24 DISPATCHER: register_result: lock acquired
11:41:24 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
11:41:24 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.006763309470052224, 'num_filters_1': 114, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.01427634033852558, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 63, 'num_filters_3': 23, 'num_filters_4': 22}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.910456039756213, 'info': {'music-speech': 0.910456039756213, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.006763309470052224, 'num_filters_1': 114, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.01427634033852558, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 63, 'num_filters_3': 23, 'num_filters_4': 22}"}}
exception: None

11:41:24 job_callback for (2, 0, 4) started
11:41:24 job_callback for (2, 0, 4) got condition
11:41:24 DISPATCHER: Trying to submit another job.
11:41:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:41:24 Only 4 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
11:41:24 HBMASTER: Trying to run another job!
11:41:24 job_callback for (2, 0, 4) finished
11:41:24 start sampling a new configuration.
11:41:24 done sampling a new configuration.
11:41:24 HBMASTER: schedule new run for iteration 3
11:41:24 HBMASTER: trying submitting job (3, 0, 0) to dispatcher
11:41:24 HBMASTER: submitting job (3, 0, 0) to dispatcher
11:41:24 DISPATCHER: trying to submit job (3, 0, 0)
11:41:24 DISPATCHER: trying to notify the job_runner thread.
11:41:24 HBMASTER: job (3, 0, 0) submitted to dispatcher
11:41:24 DISPATCHER: Trying to submit another job.
11:41:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:41:24 DISPATCHER: starting job (3, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
11:41:24 DISPATCHER: job (3, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
11:41:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:41:24 WORKER: start processing job (3, 0, 0)
11:41:24 WORKER: args: ()
11:41:24 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.06580708772037741, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.04224190387577264, 'kernel_size_2': 7, 'num_filters_2': 48}, 'budget': 1200.0, 'working_directory': '.'}
11:41:52 DISPATCHER: Starting worker discovery
11:41:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:41:52 DISPATCHER: Finished worker discovery
11:42:52 DISPATCHER: Starting worker discovery
11:42:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:42:52 DISPATCHER: Finished worker discovery
11:43:52 DISPATCHER: Starting worker discovery
11:43:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:43:52 DISPATCHER: Finished worker discovery
11:44:52 DISPATCHER: Starting worker discovery
11:44:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:44:52 DISPATCHER: Finished worker discovery
11:45:52 DISPATCHER: Starting worker discovery
11:45:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:45:52 DISPATCHER: Finished worker discovery
11:46:52 DISPATCHER: Starting worker discovery
11:46:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:46:52 DISPATCHER: Finished worker discovery
11:47:52 DISPATCHER: Starting worker discovery
11:47:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:47:52 DISPATCHER: Finished worker discovery
11:48:52 DISPATCHER: Starting worker discovery
11:48:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:48:52 DISPATCHER: Finished worker discovery
11:49:52 DISPATCHER: Starting worker discovery
11:49:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:49:52 DISPATCHER: Finished worker discovery
11:50:52 DISPATCHER: Starting worker discovery
11:50:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:50:52 DISPATCHER: Finished worker discovery
11:51:52 DISPATCHER: Starting worker discovery
11:51:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:51:52 DISPATCHER: Finished worker discovery
11:52:52 DISPATCHER: Starting worker discovery
11:52:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:52:52 DISPATCHER: Finished worker discovery
11:53:52 DISPATCHER: Starting worker discovery
11:53:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:53:52 DISPATCHER: Finished worker discovery
11:54:52 DISPATCHER: Starting worker discovery
11:54:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:54:52 DISPATCHER: Finished worker discovery
11:55:52 DISPATCHER: Starting worker discovery
11:55:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:55:52 DISPATCHER: Finished worker discovery
11:56:52 DISPATCHER: Starting worker discovery
11:56:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:56:52 DISPATCHER: Finished worker discovery
11:57:52 DISPATCHER: Starting worker discovery
11:57:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:57:52 DISPATCHER: Finished worker discovery
11:58:52 DISPATCHER: Starting worker discovery
11:58:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:58:52 DISPATCHER: Finished worker discovery
11:59:52 DISPATCHER: Starting worker discovery
11:59:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:59:52 DISPATCHER: Finished worker discovery
12:00:52 DISPATCHER: Starting worker discovery
12:00:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:00:52 DISPATCHER: Finished worker discovery
12:01:34 WORKER: done with job (3, 0, 0), trying to register it.
12:01:34 WORKER: registered result for job (3, 0, 0) with dispatcher
12:01:34 DISPATCHER: job (3, 0, 0) finished
12:01:34 DISPATCHER: register_result: lock acquired
12:01:34 DISPATCHER: job (3, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
12:01:34 job_id: (3, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.06580708772037741, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.04224190387577264, 'kernel_size_2': 7, 'num_filters_2': 48}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.005667498940461139, 'info': {'music-speech': 0.005667498940461139, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.06580708772037741, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.04224190387577264, 'kernel_size_2': 7, 'num_filters_2': 48}"}}
exception: None

12:01:34 job_callback for (3, 0, 0) started
12:01:34 job_callback for (3, 0, 0) got condition
12:01:34 DISPATCHER: Trying to submit another job.
12:01:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:01:34 Only 5 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
12:01:34 HBMASTER: Trying to run another job!
12:01:34 job_callback for (3, 0, 0) finished
12:01:34 start sampling a new configuration.
12:01:34 done sampling a new configuration.
12:01:34 HBMASTER: schedule new run for iteration 3
12:01:34 HBMASTER: trying submitting job (3, 0, 1) to dispatcher
12:01:34 HBMASTER: submitting job (3, 0, 1) to dispatcher
12:01:34 DISPATCHER: trying to submit job (3, 0, 1)
12:01:34 DISPATCHER: trying to notify the job_runner thread.
12:01:34 HBMASTER: job (3, 0, 1) submitted to dispatcher
12:01:34 DISPATCHER: Trying to submit another job.
12:01:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:01:34 DISPATCHER: starting job (3, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
12:01:34 DISPATCHER: job (3, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
12:01:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:01:34 WORKER: start processing job (3, 0, 1)
12:01:34 WORKER: args: ()
12:01:34 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.059902091658202934, 'num_filters_1': 79, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.050507532687714074, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 27, 'num_filters_3': 123, 'num_filters_4': 56}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-272:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

12:01:52 DISPATCHER: Starting worker discovery
12:01:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:01:52 DISPATCHER: Finished worker discovery
12:02:52 DISPATCHER: Starting worker discovery
12:02:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:02:52 DISPATCHER: Finished worker discovery
12:03:52 DISPATCHER: Starting worker discovery
12:03:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:03:52 DISPATCHER: Finished worker discovery
12:04:52 DISPATCHER: Starting worker discovery
12:04:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:04:52 DISPATCHER: Finished worker discovery
12:05:52 DISPATCHER: Starting worker discovery
12:05:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:05:52 DISPATCHER: Finished worker discovery
12:06:52 DISPATCHER: Starting worker discovery
12:06:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:06:52 DISPATCHER: Finished worker discovery
12:07:52 DISPATCHER: Starting worker discovery
12:07:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:07:52 DISPATCHER: Finished worker discovery
12:08:52 DISPATCHER: Starting worker discovery
12:08:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:08:52 DISPATCHER: Finished worker discovery
12:09:52 DISPATCHER: Starting worker discovery
12:09:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:09:52 DISPATCHER: Finished worker discovery
12:10:52 DISPATCHER: Starting worker discovery
12:10:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:10:52 DISPATCHER: Finished worker discovery
12:11:52 DISPATCHER: Starting worker discovery
12:11:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:11:53 DISPATCHER: Finished worker discovery
12:12:53 DISPATCHER: Starting worker discovery
12:12:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:12:53 DISPATCHER: Finished worker discovery
12:13:53 DISPATCHER: Starting worker discovery
12:13:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:13:53 DISPATCHER: Finished worker discovery
12:14:53 DISPATCHER: Starting worker discovery
12:14:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:14:53 DISPATCHER: Finished worker discovery
12:15:53 DISPATCHER: Starting worker discovery
12:15:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:15:53 DISPATCHER: Finished worker discovery
12:16:53 DISPATCHER: Starting worker discovery
12:16:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:16:53 DISPATCHER: Finished worker discovery
12:17:53 DISPATCHER: Starting worker discovery
12:17:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:17:53 DISPATCHER: Finished worker discovery
12:18:53 DISPATCHER: Starting worker discovery
12:18:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:18:53 DISPATCHER: Finished worker discovery
12:19:53 DISPATCHER: Starting worker discovery
12:19:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:19:53 DISPATCHER: Finished worker discovery
12:20:53 DISPATCHER: Starting worker discovery
12:20:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:20:53 DISPATCHER: Finished worker discovery
12:21:43 WORKER: done with job (3, 0, 1), trying to register it.
12:21:43 WORKER: registered result for job (3, 0, 1) with dispatcher
12:21:43 DISPATCHER: job (3, 0, 1) finished
12:21:43 DISPATCHER: register_result: lock acquired
12:21:43 DISPATCHER: job (3, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
12:21:43 job_id: (3, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.059902091658202934, 'num_filters_1': 79, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.050507532687714074, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 27, 'num_filters_3': 123, 'num_filters_4': 56}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9030365109723645, 'info': {'music-speech': 0.9030365109723645, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.059902091658202934, 'num_filters_1': 79, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.050507532687714074, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 27, 'num_filters_3': 123, 'num_filters_4': 56}"}}
exception: None

12:21:43 job_callback for (3, 0, 1) started
12:21:43 DISPATCHER: Trying to submit another job.
12:21:43 job_callback for (3, 0, 1) got condition
12:21:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:21:43 Only 6 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
12:21:43 HBMASTER: Trying to run another job!
12:21:43 job_callback for (3, 0, 1) finished
12:21:43 start sampling a new configuration.
12:21:43 done sampling a new configuration.
12:21:43 HBMASTER: schedule new run for iteration 3
12:21:43 HBMASTER: trying submitting job (3, 0, 2) to dispatcher
12:21:43 HBMASTER: submitting job (3, 0, 2) to dispatcher
12:21:43 DISPATCHER: trying to submit job (3, 0, 2)
12:21:43 DISPATCHER: trying to notify the job_runner thread.
12:21:43 HBMASTER: job (3, 0, 2) submitted to dispatcher
12:21:43 DISPATCHER: Trying to submit another job.
12:21:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:21:43 DISPATCHER: starting job (3, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
12:21:43 DISPATCHER: job (3, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
12:21:43 WORKER: start processing job (3, 0, 2)
12:21:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:21:43 WORKER: args: ()
12:21:43 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012550526138042563, 'num_filters_1': 122, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.01570717349651353, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 59, 'num_filters_3': 48}, 'budget': 1200.0, 'working_directory': '.'}
12:21:53 DISPATCHER: Starting worker discovery
12:21:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:21:53 DISPATCHER: Finished worker discovery
12:22:53 DISPATCHER: Starting worker discovery
12:22:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:22:53 DISPATCHER: Finished worker discovery
12:23:53 DISPATCHER: Starting worker discovery
12:23:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:23:53 DISPATCHER: Finished worker discovery
12:24:53 DISPATCHER: Starting worker discovery
12:24:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:24:53 DISPATCHER: Finished worker discovery
12:25:53 DISPATCHER: Starting worker discovery
12:25:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:25:53 DISPATCHER: Finished worker discovery
12:26:53 DISPATCHER: Starting worker discovery
12:26:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:26:53 DISPATCHER: Finished worker discovery
12:27:53 DISPATCHER: Starting worker discovery
12:27:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:27:53 DISPATCHER: Finished worker discovery
12:28:53 DISPATCHER: Starting worker discovery
12:28:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:28:53 DISPATCHER: Finished worker discovery
12:29:53 DISPATCHER: Starting worker discovery
12:29:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:29:53 DISPATCHER: Finished worker discovery
12:30:53 DISPATCHER: Starting worker discovery
12:30:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:30:53 DISPATCHER: Finished worker discovery
12:31:53 DISPATCHER: Starting worker discovery
12:31:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:31:53 DISPATCHER: Finished worker discovery
12:32:53 DISPATCHER: Starting worker discovery
12:32:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:32:53 DISPATCHER: Finished worker discovery
12:33:53 DISPATCHER: Starting worker discovery
12:33:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:33:53 DISPATCHER: Finished worker discovery
12:34:53 DISPATCHER: Starting worker discovery
12:34:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:34:53 DISPATCHER: Finished worker discovery
12:35:53 DISPATCHER: Starting worker discovery
12:35:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:35:53 DISPATCHER: Finished worker discovery
12:36:53 DISPATCHER: Starting worker discovery
12:36:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:36:53 DISPATCHER: Finished worker discovery
12:37:53 DISPATCHER: Starting worker discovery
12:37:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:37:53 DISPATCHER: Finished worker discovery
12:38:53 DISPATCHER: Starting worker discovery
12:38:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:38:53 DISPATCHER: Finished worker discovery
12:39:53 DISPATCHER: Starting worker discovery
12:39:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:39:53 DISPATCHER: Finished worker discovery
12:40:53 DISPATCHER: Starting worker discovery
12:40:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:40:53 DISPATCHER: Finished worker discovery
12:41:53 DISPATCHER: Starting worker discovery
12:41:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:41:53 DISPATCHER: Finished worker discovery
12:41:55 WORKER: done with job (3, 0, 2), trying to register it.
12:41:55 WORKER: registered result for job (3, 0, 2) with dispatcher
12:41:55 DISPATCHER: job (3, 0, 2) finished
12:41:55 DISPATCHER: register_result: lock acquired
12:41:55 DISPATCHER: job (3, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
12:41:55 job_id: (3, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012550526138042563, 'num_filters_1': 122, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.01570717349651353, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 59, 'num_filters_3': 48}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.8161682102764777, 'info': {'music-speech': 0.8161682102764777, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.012550526138042563, 'num_filters_1': 122, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.01570717349651353, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 59, 'num_filters_3': 48}"}}
exception: None

12:41:55 job_callback for (3, 0, 2) started
12:41:55 DISPATCHER: Trying to submit another job.
12:41:55 job_callback for (3, 0, 2) got condition
12:41:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:41:55 Only 7 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
12:41:55 HBMASTER: Trying to run another job!
12:41:55 job_callback for (3, 0, 2) finished
12:41:55 start sampling a new configuration.
12:41:55 done sampling a new configuration.
12:41:55 HBMASTER: schedule new run for iteration 3
12:41:55 HBMASTER: trying submitting job (3, 0, 3) to dispatcher
12:41:55 HBMASTER: submitting job (3, 0, 3) to dispatcher
12:41:55 DISPATCHER: trying to submit job (3, 0, 3)
12:41:55 DISPATCHER: trying to notify the job_runner thread.
12:41:55 HBMASTER: job (3, 0, 3) submitted to dispatcher
12:41:55 DISPATCHER: Trying to submit another job.
12:41:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:41:55 DISPATCHER: starting job (3, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
12:41:55 DISPATCHER: job (3, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
12:41:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:41:55 WORKER: start processing job (3, 0, 3)
12:41:55 WORKER: args: ()
12:41:55 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0015083313383510164, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.0589877803669121, 'kernel_size_2': 7, 'num_filters_2': 31}, 'budget': 1200.0, 'working_directory': '.'}
12:42:53 DISPATCHER: Starting worker discovery
12:42:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:42:53 DISPATCHER: Finished worker discovery
12:43:53 DISPATCHER: Starting worker discovery
12:43:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:43:53 DISPATCHER: Finished worker discovery
12:44:53 DISPATCHER: Starting worker discovery
12:44:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:44:53 DISPATCHER: Finished worker discovery
12:45:53 DISPATCHER: Starting worker discovery
12:45:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:45:53 DISPATCHER: Finished worker discovery
12:46:53 DISPATCHER: Starting worker discovery
12:46:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:46:53 DISPATCHER: Finished worker discovery
12:47:53 DISPATCHER: Starting worker discovery
12:47:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:47:53 DISPATCHER: Finished worker discovery
12:48:53 DISPATCHER: Starting worker discovery
12:48:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:48:53 DISPATCHER: Finished worker discovery
12:49:53 DISPATCHER: Starting worker discovery
12:49:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:49:53 DISPATCHER: Finished worker discovery
12:50:53 DISPATCHER: Starting worker discovery
12:50:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:50:53 DISPATCHER: Finished worker discovery
12:51:53 DISPATCHER: Starting worker discovery
12:51:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:51:53 DISPATCHER: Finished worker discovery
12:52:53 DISPATCHER: Starting worker discovery
12:52:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:52:53 DISPATCHER: Finished worker discovery
12:53:53 DISPATCHER: Starting worker discovery
12:53:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:53:53 DISPATCHER: Finished worker discovery
12:54:53 DISPATCHER: Starting worker discovery
12:54:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:54:53 DISPATCHER: Finished worker discovery
12:55:53 DISPATCHER: Starting worker discovery
12:55:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:55:53 DISPATCHER: Finished worker discovery
12:56:53 DISPATCHER: Starting worker discovery
12:56:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:56:53 DISPATCHER: Finished worker discovery
12:57:53 DISPATCHER: Starting worker discovery
12:57:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:57:53 DISPATCHER: Finished worker discovery
12:58:53 DISPATCHER: Starting worker discovery
12:58:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:58:53 DISPATCHER: Finished worker discovery
12:59:53 DISPATCHER: Starting worker discovery
12:59:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:59:53 DISPATCHER: Finished worker discovery
13:00:53 DISPATCHER: Starting worker discovery
13:00:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:00:53 DISPATCHER: Finished worker discovery
13:01:53 DISPATCHER: Starting worker discovery
13:01:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:01:53 DISPATCHER: Finished worker discovery
13:02:05 WORKER: done with job (3, 0, 3), trying to register it.
13:02:05 WORKER: registered result for job (3, 0, 3) with dispatcher
13:02:05 DISPATCHER: job (3, 0, 3) finished
13:02:05 DISPATCHER: register_result: lock acquired
13:02:05 DISPATCHER: job (3, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:02:05 job_id: (3, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0015083313383510164, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.0589877803669121, 'kernel_size_2': 7, 'num_filters_2': 31}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9144107173485186, 'info': {'music-speech': 0.9144107173485186, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0015083313383510164, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.0589877803669121, 'kernel_size_2': 7, 'num_filters_2': 31}"}}
exception: None

13:02:05 job_callback for (3, 0, 3) started
13:02:05 DISPATCHER: Trying to submit another job.
13:02:05 job_callback for (3, 0, 3) got condition
13:02:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:02:05 Only 8 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
13:02:05 HBMASTER: Trying to run another job!
13:02:05 job_callback for (3, 0, 3) finished
13:02:05 start sampling a new configuration.
13:02:05 done sampling a new configuration.
13:02:05 HBMASTER: schedule new run for iteration 4
13:02:05 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
13:02:05 HBMASTER: submitting job (4, 0, 0) to dispatcher
13:02:05 DISPATCHER: trying to submit job (4, 0, 0)
13:02:05 DISPATCHER: trying to notify the job_runner thread.
13:02:05 HBMASTER: job (4, 0, 0) submitted to dispatcher
13:02:05 DISPATCHER: Trying to submit another job.
13:02:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:02:05 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:02:05 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:02:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:02:06 WORKER: start processing job (4, 0, 0)
13:02:06 WORKER: args: ()
13:02:06 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.06832568594544923, 'num_filters_1': 101, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.06926060590816774}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-275:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

13:02:53 DISPATCHER: Starting worker discovery
13:02:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:02:53 DISPATCHER: Finished worker discovery
13:02:59 WORKER: done with job (4, 0, 0), trying to register it.
13:02:59 DISPATCHER: job (4, 0, 0) finished
13:02:59 WORKER: registered result for job (4, 0, 0) with dispatcher
13:02:59 DISPATCHER: register_result: lock acquired
13:02:59 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:02:59 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.06832568594544923, 'num_filters_1': 101, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.06926060590816774}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.18170639285819545, 'info': {'music-speech': 0.18170639285819545, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.06832568594544923, 'num_filters_1': 101, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.06926060590816774}"}}
exception: None

13:02:59 job_callback for (4, 0, 0) started
13:02:59 DISPATCHER: Trying to submit another job.
13:02:59 job_callback for (4, 0, 0) got condition
13:02:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:02:59 HBMASTER: Trying to run another job!
13:02:59 job_callback for (4, 0, 0) finished
13:02:59 start sampling a new configuration.
13:02:59 done sampling a new configuration.
13:02:59 HBMASTER: schedule new run for iteration 4
13:02:59 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
13:02:59 HBMASTER: submitting job (4, 0, 1) to dispatcher
13:02:59 DISPATCHER: trying to submit job (4, 0, 1)
13:02:59 DISPATCHER: trying to notify the job_runner thread.
13:02:59 HBMASTER: job (4, 0, 1) submitted to dispatcher
13:02:59 DISPATCHER: Trying to submit another job.
13:02:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:02:59 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:02:59 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:02:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:02:59 WORKER: start processing job (4, 0, 1)
13:02:59 WORKER: args: ()
13:02:59 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.006782397457041025, 'num_filters_1': 34, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.02814201483224562, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 16, 'num_filters_3': 41, 'num_filters_4': 72}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:03:53 DISPATCHER: Starting worker discovery
13:03:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:03:53 DISPATCHER: Finished worker discovery
13:03:53 WORKER: done with job (4, 0, 1), trying to register it.
13:03:53 WORKER: registered result for job (4, 0, 1) with dispatcher
13:03:53 DISPATCHER: job (4, 0, 1) finished
13:03:53 DISPATCHER: register_result: lock acquired
13:03:53 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:03:53 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.006782397457041025, 'num_filters_1': 34, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.02814201483224562, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 16, 'num_filters_3': 41, 'num_filters_4': 72}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9896691642085785, 'info': {'music-speech': 0.9896691642085785, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.006782397457041025, 'num_filters_1': 34, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.02814201483224562, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 16, 'num_filters_3': 41, 'num_filters_4': 72}"}}
exception: None

13:03:53 job_callback for (4, 0, 1) started
13:03:53 DISPATCHER: Trying to submit another job.
13:03:53 job_callback for (4, 0, 1) got condition
13:03:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:03:53 HBMASTER: Trying to run another job!
13:03:53 job_callback for (4, 0, 1) finished
13:03:53 start sampling a new configuration.
13:03:53 done sampling a new configuration.
13:03:53 HBMASTER: schedule new run for iteration 4
13:03:53 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
13:03:53 HBMASTER: submitting job (4, 0, 2) to dispatcher
13:03:53 DISPATCHER: trying to submit job (4, 0, 2)
13:03:53 DISPATCHER: trying to notify the job_runner thread.
13:03:53 HBMASTER: job (4, 0, 2) submitted to dispatcher
13:03:53 DISPATCHER: Trying to submit another job.
13:03:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:03:53 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:03:53 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:03:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:03:53 WORKER: start processing job (4, 0, 2)
13:03:53 WORKER: args: ()
13:03:53 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.032665702966847024, 'num_filters_1': 23, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.018637131797548525, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 40, 'num_filters_3': 18, 'num_filters_4': 124, 'num_filters_5': 41}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:04:47 WORKER: done with job (4, 0, 2), trying to register it.
13:04:47 DISPATCHER: job (4, 0, 2) finished
13:04:47 WORKER: registered result for job (4, 0, 2) with dispatcher
13:04:47 DISPATCHER: register_result: lock acquired
13:04:47 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:04:47 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.032665702966847024, 'num_filters_1': 23, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.018637131797548525, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 40, 'num_filters_3': 18, 'num_filters_4': 124, 'num_filters_5': 41}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.032665702966847024, 'num_filters_1': 23, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.018637131797548525, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 40, 'num_filters_3': 18, 'num_filters_4': 124, 'num_filters_5': 41}"}}
exception: None

13:04:47 job_callback for (4, 0, 2) started
13:04:47 DISPATCHER: Trying to submit another job.
13:04:47 job_callback for (4, 0, 2) got condition
13:04:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:04:47 HBMASTER: Trying to run another job!
13:04:47 job_callback for (4, 0, 2) finished
13:04:47 start sampling a new configuration.
13:04:47 done sampling a new configuration.
13:04:47 HBMASTER: schedule new run for iteration 4
13:04:47 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
13:04:47 HBMASTER: submitting job (4, 0, 3) to dispatcher
13:04:47 DISPATCHER: trying to submit job (4, 0, 3)
13:04:47 DISPATCHER: trying to notify the job_runner thread.
13:04:47 HBMASTER: job (4, 0, 3) submitted to dispatcher
13:04:47 DISPATCHER: Trying to submit another job.
13:04:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:04:47 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:04:47 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:04:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:04:47 WORKER: start processing job (4, 0, 3)
13:04:47 WORKER: args: ()
13:04:47 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.03728389150096759, 'num_filters_1': 55, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.06664322456440329, 'kernel_size_2': 3, 'num_filters_2': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:04:53 DISPATCHER: Starting worker discovery
13:04:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:04:53 DISPATCHER: Finished worker discovery
13:05:40 WORKER: done with job (4, 0, 3), trying to register it.
13:05:40 WORKER: registered result for job (4, 0, 3) with dispatcher
13:05:40 DISPATCHER: job (4, 0, 3) finished
13:05:40 DISPATCHER: register_result: lock acquired
13:05:40 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:05:40 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.03728389150096759, 'num_filters_1': 55, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.06664322456440329, 'kernel_size_2': 3, 'num_filters_2': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2361570673509336, 'info': {'music-speech': 0.2361570673509336, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.03728389150096759, 'num_filters_1': 55, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.06664322456440329, 'kernel_size_2': 3, 'num_filters_2': 26}"}}
exception: None

13:05:40 job_callback for (4, 0, 3) started
13:05:40 DISPATCHER: Trying to submit another job.
13:05:40 job_callback for (4, 0, 3) got condition
13:05:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:05:40 HBMASTER: Trying to run another job!
13:05:40 job_callback for (4, 0, 3) finished
13:05:40 start sampling a new configuration.
13:05:40 done sampling a new configuration.
13:05:40 HBMASTER: schedule new run for iteration 4
13:05:40 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
13:05:40 HBMASTER: submitting job (4, 0, 4) to dispatcher
13:05:40 DISPATCHER: trying to submit job (4, 0, 4)
13:05:40 DISPATCHER: trying to notify the job_runner thread.
13:05:40 HBMASTER: job (4, 0, 4) submitted to dispatcher
13:05:40 DISPATCHER: Trying to submit another job.
13:05:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:05:40 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:05:40 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:05:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:05:40 WORKER: start processing job (4, 0, 4)
13:05:40 WORKER: args: ()
13:05:40 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003063038326330839, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.012654794643760835, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 20, 'num_filters_3': 38, 'num_filters_4': 92, 'num_filters_5': 47}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:05:53 DISPATCHER: Starting worker discovery
13:05:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:05:53 DISPATCHER: Finished worker discovery
13:06:34 WORKER: done with job (4, 0, 4), trying to register it.
13:06:34 DISPATCHER: job (4, 0, 4) finished
13:06:34 WORKER: registered result for job (4, 0, 4) with dispatcher
13:06:34 DISPATCHER: register_result: lock acquired
13:06:34 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:06:34 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003063038326330839, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.012654794643760835, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 20, 'num_filters_3': 38, 'num_filters_4': 92, 'num_filters_5': 47}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9039249233370449, 'info': {'music-speech': 0.9039249233370449, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.003063038326330839, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.012654794643760835, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 20, 'num_filters_3': 38, 'num_filters_4': 92, 'num_filters_5': 47}"}}
exception: None

13:06:34 job_callback for (4, 0, 4) started
13:06:34 DISPATCHER: Trying to submit another job.
13:06:34 job_callback for (4, 0, 4) got condition
13:06:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:06:34 HBMASTER: Trying to run another job!
13:06:34 job_callback for (4, 0, 4) finished
13:06:34 start sampling a new configuration.
13:06:34 done sampling a new configuration.
13:06:34 HBMASTER: schedule new run for iteration 4
13:06:34 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
13:06:34 HBMASTER: submitting job (4, 0, 5) to dispatcher
13:06:34 DISPATCHER: trying to submit job (4, 0, 5)
13:06:34 DISPATCHER: trying to notify the job_runner thread.
13:06:34 HBMASTER: job (4, 0, 5) submitted to dispatcher
13:06:34 DISPATCHER: Trying to submit another job.
13:06:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:06:34 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:06:34 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:06:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:06:34 WORKER: start processing job (4, 0, 5)
13:06:34 WORKER: args: ()
13:06:34 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005034460011845734, 'num_filters_1': 60, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.023607840638113217, 'kernel_size_2': 7, 'num_filters_2': 53}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:06:53 DISPATCHER: Starting worker discovery
13:06:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:06:53 DISPATCHER: Finished worker discovery
13:07:27 WORKER: done with job (4, 0, 5), trying to register it.
13:07:27 WORKER: registered result for job (4, 0, 5) with dispatcher
13:07:27 DISPATCHER: job (4, 0, 5) finished
13:07:27 DISPATCHER: register_result: lock acquired
13:07:27 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:07:27 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005034460011845734, 'num_filters_1': 60, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.023607840638113217, 'kernel_size_2': 7, 'num_filters_2': 53}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5718480986049795, 'info': {'music-speech': 0.5718480986049795, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.005034460011845734, 'num_filters_1': 60, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.023607840638113217, 'kernel_size_2': 7, 'num_filters_2': 53}"}}
exception: None

13:07:27 job_callback for (4, 0, 5) started
13:07:27 DISPATCHER: Trying to submit another job.
13:07:27 job_callback for (4, 0, 5) got condition
13:07:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:07:27 HBMASTER: Trying to run another job!
13:07:27 job_callback for (4, 0, 5) finished
13:07:27 start sampling a new configuration.
13:07:27 done sampling a new configuration.
13:07:27 HBMASTER: schedule new run for iteration 4
13:07:27 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
13:07:27 HBMASTER: submitting job (4, 0, 6) to dispatcher
13:07:27 DISPATCHER: trying to submit job (4, 0, 6)
13:07:27 DISPATCHER: trying to notify the job_runner thread.
13:07:27 HBMASTER: job (4, 0, 6) submitted to dispatcher
13:07:27 DISPATCHER: Trying to submit another job.
13:07:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:07:27 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:07:27 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:07:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:07:27 WORKER: start processing job (4, 0, 6)
13:07:27 WORKER: args: ()
13:07:27 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0016817306674514712, 'num_filters_1': 82, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.013865302249569472, 'kernel_size_2': 3, 'num_filters_2': 58}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:07:53 DISPATCHER: Starting worker discovery
13:07:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:07:53 DISPATCHER: Finished worker discovery
13:08:20 WORKER: done with job (4, 0, 6), trying to register it.
13:08:20 DISPATCHER: job (4, 0, 6) finished
13:08:20 WORKER: registered result for job (4, 0, 6) with dispatcher
13:08:20 DISPATCHER: register_result: lock acquired
13:08:20 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:08:20 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0016817306674514712, 'num_filters_1': 82, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.013865302249569472, 'kernel_size_2': 3, 'num_filters_2': 58}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8168046565057868, 'info': {'music-speech': 0.8168046565057868, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0016817306674514712, 'num_filters_1': 82, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.013865302249569472, 'kernel_size_2': 3, 'num_filters_2': 58}"}}
exception: None

13:08:20 job_callback for (4, 0, 6) started
13:08:20 job_callback for (4, 0, 6) got condition
13:08:20 DISPATCHER: Trying to submit another job.
13:08:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:08:20 done building a new model for budget 44.444444 based on 17/28 split
Best loss for this budget:-0.989669





13:08:20 HBMASTER: Trying to run another job!
13:08:20 job_callback for (4, 0, 6) finished
13:08:20 start sampling a new configuration.
/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/statsmodels/nonparametric/kernels.py:62: RuntimeWarning: divide by zero encountered in true_divide
  kernel_value = np.ones(Xi.size) * h / (num_levels - 1)
13:08:21 best_vector: [2, 2, 0.15433581619737274, 0.3458536369516241, 0.874390875810212, 0, 0.2844876199208547, 0.2943864743275338, 2, 1, 2, 2, 0.6008998355509836, 0.2892456710592658, 0.2596959682117353, 0.7059490990581945], 1.4218981645328557e-29, 0.0007032852456972795, -1.5607877841231851e-10
13:08:21 done sampling a new configuration.
13:08:21 HBMASTER: schedule new run for iteration 4
13:08:21 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
13:08:21 HBMASTER: submitting job (4, 0, 7) to dispatcher
13:08:21 DISPATCHER: trying to submit job (4, 0, 7)
13:08:21 DISPATCHER: trying to notify the job_runner thread.
13:08:21 HBMASTER: job (4, 0, 7) submitted to dispatcher
13:08:21 DISPATCHER: Trying to submit another job.
13:08:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:08:21 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:08:21 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:08:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:08:21 WORKER: start processing job (4, 0, 7)
13:08:21 WORKER: args: ()
13:08:21 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0020355024638142156, 'num_filters_1': 32, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.02415492166614904, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 55, 'num_filters_3': 29, 'num_filters_4': 27, 'num_filters_5': 69}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:08:53 DISPATCHER: Starting worker discovery
13:08:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:08:53 DISPATCHER: Finished worker discovery
13:09:14 WORKER: done with job (4, 0, 7), trying to register it.
13:09:14 WORKER: registered result for job (4, 0, 7) with dispatcher
13:09:14 DISPATCHER: job (4, 0, 7) finished
13:09:14 DISPATCHER: register_result: lock acquired
13:09:14 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:09:14 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0020355024638142156, 'num_filters_1': 32, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.02415492166614904, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 55, 'num_filters_3': 29, 'num_filters_4': 27, 'num_filters_5': 69}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.932150794014966, 'info': {'music-speech': 0.932150794014966, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0020355024638142156, 'num_filters_1': 32, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.02415492166614904, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 55, 'num_filters_3': 29, 'num_filters_4': 27, 'num_filters_5': 69}"}}
exception: None

13:09:14 job_callback for (4, 0, 7) started
13:09:14 DISPATCHER: Trying to submit another job.
13:09:14 job_callback for (4, 0, 7) got condition
13:09:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:09:14 done building a new model for budget 44.444444 based on 17/29 split
Best loss for this budget:-0.989669





13:09:14 HBMASTER: Trying to run another job!
13:09:14 job_callback for (4, 0, 7) finished
13:09:14 start sampling a new configuration.
13:09:14 done sampling a new configuration.
13:09:14 HBMASTER: schedule new run for iteration 4
13:09:14 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
13:09:14 HBMASTER: submitting job (4, 0, 8) to dispatcher
13:09:14 DISPATCHER: trying to submit job (4, 0, 8)
13:09:14 DISPATCHER: trying to notify the job_runner thread.
13:09:14 HBMASTER: job (4, 0, 8) submitted to dispatcher
13:09:14 DISPATCHER: Trying to submit another job.
13:09:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:09:14 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:09:14 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:09:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:09:14 WORKER: start processing job (4, 0, 8)
13:09:14 WORKER: args: ()
13:09:14 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0014785767667887903, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.08491182095993074, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 28, 'num_filters_3': 72, 'num_filters_4': 53, 'num_filters_5': 76}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:09:53 DISPATCHER: Starting worker discovery
13:09:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:09:53 DISPATCHER: Finished worker discovery
13:10:12 WORKER: done with job (4, 0, 8), trying to register it.
13:10:12 WORKER: registered result for job (4, 0, 8) with dispatcher
13:10:12 DISPATCHER: job (4, 0, 8) finished
13:10:12 DISPATCHER: register_result: lock acquired
13:10:12 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:10:12 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0014785767667887903, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.08491182095993074, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 28, 'num_filters_3': 72, 'num_filters_4': 53, 'num_filters_5': 76}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9005929943852168, 'info': {'music-speech': 0.9005929943852168, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0014785767667887903, 'num_filters_1': 25, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.08491182095993074, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 28, 'num_filters_3': 72, 'num_filters_4': 53, 'num_filters_5': 76}"}}
exception: None

13:10:12 job_callback for (4, 0, 8) started
13:10:12 job_callback for (4, 0, 8) got condition
13:10:12 DISPATCHER: Trying to submit another job.
13:10:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:10:12 done building a new model for budget 44.444444 based on 17/30 split
Best loss for this budget:-0.989669





13:10:12 HBMASTER: Trying to run another job!
13:10:12 job_callback for (4, 0, 8) finished
13:10:12 start sampling a new configuration.
13:10:12 sampled vector: [2, 0, 0.7851219695318807, 0.21266312216249098, 0.9549522986042681, 0, 0.05438481675521395, 0.6840599641889049, 0, 0, 2, 1, 0.8002727540084974, 0.24016194965279059, 0.8652282967108859, 0.5446415008162564] has EI value inf
13:10:12 data in the KDEs:
[[0.         0.         0.41569162 0.37138871 0.7000008  0.
  0.8296704  0.34538419 0.         1.         2.         2.
  0.01501027 0.45990111 0.72612834 0.63198159]
 [2.         2.         0.15433582 0.34272578 0.9000016  0.
  0.28021973 0.29438647 2.         1.         2.         2.
  0.59878947 0.29618395 0.26239861 0.70600643]
 [1.         2.         0.48176813 0.24455523 0.2999992  0.
  0.1703296  0.76015092 0.         2.         2.         1.
  0.0436732  0.09625996 0.5812766  0.75169097]
 [3.         1.         0.41540889 0.59011412 0.7000008  0.
  0.18131861 0.68124176 1.         1.         1.         2.
  0.01501027 0.52447314 0.31221238 0.70600643]
 [0.         2.         0.01945842 0.14357878 0.7000008  1.
  0.48901099 0.23836669 1.         2.         1.         1.
  0.73264973 0.279593   0.98694376 0.75169097]
 [1.         2.         0.34176716 0.8571918  0.2999992  1.
  0.07142848 0.13688815 2.         0.         2.         1.
  0.279593   0.72612834 0.5812766  0.75169097]
 [1.         0.         0.20514054 0.83685346 0.2999992  1.
  0.76373632 0.36728356 0.         0.         1.         2.
  0.97545834 0.35727442 0.84202065 0.52447314]
 [0.         0.         0.24307622 0.1205111  0.9000016  0.
  0.85164843 0.0785955  1.         0.         1.         2.
  0.1205111  0.42397547 0.84202065 0.52447314]
 [3.         1.         0.08492194 0.22601193 0.9000016  0.
  0.78571435 0.71402516 1.         0.         2.         1.
  0.279593   0.72612834 0.5812766  0.75169097]
 [3.         2.         0.68908392 0.42397547 0.0999984  0.
  0.01648341 0.03537833 1.         2.         1.         2.
  0.54417572 0.09625996 0.31221238 0.70600643]
 [0.         1.         0.35144137 0.09625996 0.7000008  0.
  0.37912085 0.9709749  0.         2.         1.         1.
  0.59878947 0.79334752 0.67044128 0.75169097]
 [1.         1.         0.27109456 0.89080549 0.9000016  0.
  0.21428565 0.03420587 2.         2.         0.         2.
  0.87189123 0.18658964 0.20671155 0.63198159]
 [3.         1.         0.38426605 0.69910421 0.5        1.
  0.93956054 0.13498246 1.         0.         2.         2.
  0.51430515 0.35727442 0.72612834 0.52447314]
 [1.         1.         0.11287822 0.78761662 0.2999992  1.
  0.34615381 0.10908998 0.         1.         2.         2.
  0.62389945 0.45990111 0.72612834 0.63198159]
 [0.         0.         0.28658463 0.8766912  0.5        0.
  0.40109888 0.06589627 1.         2.         1.         2.
  0.54417572 0.09625996 0.84202065 0.52447314]
 [3.         1.         0.88043862 0.52447314 0.2999992  0.
  0.57692309 0.64966546 2.         2.         1.         2.
  0.56308999 0.279593   0.98694376 0.63198159]
 [2.         0.         0.04319426 0.62389945 0.2999992  0.
  0.55494507 0.08112923 1.         2.         0.         2.
  0.54417572 0.18658964 0.20671155 0.63198159]]
[[1.         2.         0.52694013 0.01501027 0.2999992  1.
  0.41208789 0.48178212 1.         0.         0.         2.
  0.88144294 0.90451061 0.6554307  0.07069733]
 [1.         0.         0.28166429 0.50391366 0.2999992  0.
  0.76373632 0.65679738 0.         1.         2.         2.
  0.1205111  0.07069733 0.98314621 0.45990111]
 [1.         1.         0.11372983 0.22601193 0.0999984  0.
  0.96153856 0.08940595 2.         1.         0.         2.
  0.5812766  0.38509383 0.6554307  0.07069733]
 [3.         2.         0.13680277 0.98694376 0.0999984  1.
  0.57692309 0.28899552 2.         0.         0.         2.
  0.49328864 0.90451061 0.6554307  0.07069733]
 [2.         0.         0.58868493 0.83162917 0.2999992  1.
  0.71978027 0.25119837 0.         1.         2.         2.
  0.69910421 0.38509383 0.98314621 0.45990111]
 [2.         0.         0.2022769  0.5812766  0.2999992  0.
  0.54395605 0.97315679 0.         2.         0.         2.
  0.99444858 0.93078368 0.6554307  0.07069733]
 [0.         2.         0.35097645 0.63992789 0.2999992  0.
  0.91758251 0.28673917 2.         1.         0.         2.
  0.5812766  0.38509383 0.6554307  0.07069733]
 [0.         2.         0.66428293 0.26239861 0.2999992  1.
  0.65384619 0.91358585 2.         1.         2.         2.
  0.18658964 0.07069733 0.98314621 0.45990111]
 [1.         2.         0.95888732 0.96764339 0.0999984  1.
  0.75274731 0.6524525  2.         1.         2.         2.
  0.49328864 0.07069733 0.98314621 0.45990111]
 [1.         0.         0.55676517 0.54417572 0.0999984  1.
  0.23626368 0.22283873 0.         1.         2.         2.
  0.69910421 0.38509383 0.98314621 0.45990111]
 [3.         2.         0.78576062 0.59878947 0.2999992  0.
  0.57692309 0.63315681 0.         2.         2.         2.
  0.24455523 0.93078368 0.98314621 0.45990111]
 [2.         0.         0.66177845 0.09625996 0.5        1.
  0.02747242 0.69703244 2.         1.         2.         2.
  0.0436732  0.38509383 0.98314621 0.45990111]
 [0.         1.         0.917292   0.88614739 0.0999984  1.
  0.36813184 0.64601607 0.         1.         0.         2.
  0.99444858 0.38509383 0.6554307  0.07069733]
 [3.         1.         0.80989142 0.56308999 0.2999992  1.
  0.12637354 0.94446029 0.         1.         2.         2.
  0.67777156 0.07069733 0.98314621 0.45990111]
 [3.         0.         0.86137397 0.81013485 0.2999992  0.
  0.22527466 0.68669664 2.         0.         0.         2.
  0.14357878 0.90451061 0.6554307  0.07069733]
 [2.         1.         0.48113599 0.80460504 0.9000016  0.
  0.0054944  0.75740657 1.         0.         0.         2.
  0.71280933 0.90451061 0.6554307  0.07069733]
 [0.         1.         0.78330598 0.42397547 0.2999992  0.
  0.14835157 0.83044248 2.         1.         0.         2.
  0.49328864 0.38509383 0.6554307  0.07069733]
 [0.         0.         0.757046   0.18658964 0.9000016  0.
  0.77472534 0.20781925 1.         1.         2.         2.
  0.44822661 0.07069733 0.98314621 0.45990111]
 [1.         1.         0.99952303 0.96368694 0.5        1.
  0.95054955 0.78318253 1.         2.         2.         2.
  0.20671155 0.93078368 0.98314621 0.45990111]]
13:10:12 bandwidth of the KDEs:
[1.09578771 0.70560063 0.20147318 0.25461547 0.24056348 0.41918924
 0.26085972 0.27081313 0.66720039 0.78795684 0.61226507 0.41918924
 0.26016469 0.1983019  0.23568473 0.07899858]
[0.99384666 0.75523505 0.24800024 0.27305816 0.20789272 0.45681025
 0.28027816 0.24591758 0.8114724  0.55322468 0.9136205  0.001
 0.25991016 0.31308645 0.1497038  0.17779228]
13:10:12 l(x) = 9.977743855325761e-06
13:10:12 g(x) = inf
13:10:12 best_vector: [2, 0, 0.7851219695318807, 0.21266312216249098, 0.9549522986042681, 0, 0.05438481675521395, 0.6840599641889049, 0, 0, 2, 1, 0.8002727540084974, 0.24016194965279059, 0.8652282967108859, 0.5446415008162564], 0.559104651126941, 9.977743855325761e-06, inf
13:10:12 done sampling a new configuration.
13:10:12 HBMASTER: schedule new run for iteration 4
13:10:12 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
13:10:12 HBMASTER: submitting job (4, 0, 9) to dispatcher
13:10:12 DISPATCHER: trying to submit job (4, 0, 9)
13:10:12 DISPATCHER: trying to notify the job_runner thread.
13:10:12 HBMASTER: job (4, 0, 9) submitted to dispatcher
13:10:12 DISPATCHER: Trying to submit another job.
13:10:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:10:12 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:10:12 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:10:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:10:12 WORKER: start processing job (4, 0, 9)
13:10:12 WORKER: args: ()
13:10:12 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.03717439755078146, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.07762158958229831, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 84, 'num_filters_3': 26, 'num_filters_4': 97, 'num_filters_5': 49}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:10:53 DISPATCHER: Starting worker discovery
13:10:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:10:53 DISPATCHER: Finished worker discovery
13:11:06 WORKER: done with job (4, 0, 9), trying to register it.
13:11:06 DISPATCHER: job (4, 0, 9) finished
13:11:06 WORKER: registered result for job (4, 0, 9) with dispatcher
13:11:06 DISPATCHER: register_result: lock acquired
13:11:06 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:11:06 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.03717439755078146, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.07762158958229831, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 84, 'num_filters_3': 26, 'num_filters_4': 97, 'num_filters_5': 49}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.03717439755078146, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.07762158958229831, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 84, 'num_filters_3': 26, 'num_filters_4': 97, 'num_filters_5': 49}"}}
exception: None

13:11:06 job_callback for (4, 0, 9) started
13:11:06 DISPATCHER: Trying to submit another job.
13:11:06 job_callback for (4, 0, 9) got condition
13:11:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:11:06 done building a new model for budget 44.444444 based on 17/31 split
Best loss for this budget:-0.989669





13:11:06 HBMASTER: Trying to run another job!
13:11:06 job_callback for (4, 0, 9) finished
13:11:06 start sampling a new configuration.
13:11:06 done sampling a new configuration.
13:11:06 HBMASTER: schedule new run for iteration 4
13:11:06 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
13:11:06 HBMASTER: submitting job (4, 0, 10) to dispatcher
13:11:06 DISPATCHER: trying to submit job (4, 0, 10)
13:11:06 DISPATCHER: trying to notify the job_runner thread.
13:11:06 HBMASTER: job (4, 0, 10) submitted to dispatcher
13:11:06 DISPATCHER: Trying to submit another job.
13:11:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:11:06 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:11:06 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:11:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:11:06 WORKER: start processing job (4, 0, 10)
13:11:06 WORKER: args: ()
13:11:06 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.01230301189636673, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.07514128125291543}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:11:53 DISPATCHER: Starting worker discovery
13:11:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:11:53 DISPATCHER: Finished worker discovery
13:11:59 WORKER: done with job (4, 0, 10), trying to register it.
13:11:59 WORKER: registered result for job (4, 0, 10) with dispatcher
13:11:59 DISPATCHER: job (4, 0, 10) finished
13:11:59 DISPATCHER: register_result: lock acquired
13:11:59 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:11:59 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.01230301189636673, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.07514128125291543}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8405752856559208, 'info': {'music-speech': 0.8405752856559208, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.01230301189636673, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.07514128125291543}"}}
exception: None

13:11:59 job_callback for (4, 0, 10) started
13:11:59 DISPATCHER: Trying to submit another job.
13:11:59 job_callback for (4, 0, 10) got condition
13:11:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:11:59 done building a new model for budget 44.444444 based on 17/32 split
Best loss for this budget:-0.989669





13:11:59 HBMASTER: Trying to run another job!
13:11:59 job_callback for (4, 0, 10) finished
13:11:59 start sampling a new configuration.
13:12:00 best_vector: [0, 1, 0.49042872340450466, 0.5362396218325226, 0.4701696680995966, 0, 0.12658823074401132, 0.1918251679352801, 1, 0, 1, 2, 0.68208182833278, 0.050042344293444646, 0.048741469166763696, 0.7770129125410883], 5.547727038842567e-09, 0.0005202645844040505, 2.8862859022505422e-12
13:12:00 done sampling a new configuration.
13:12:00 HBMASTER: schedule new run for iteration 4
13:12:00 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
13:12:00 HBMASTER: submitting job (4, 0, 11) to dispatcher
13:12:00 DISPATCHER: trying to submit job (4, 0, 11)
13:12:00 DISPATCHER: trying to notify the job_runner thread.
13:12:00 HBMASTER: job (4, 0, 11) submitted to dispatcher
13:12:00 DISPATCHER: Trying to submit another job.
13:12:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:12:00 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:12:00 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:12:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:12:00 WORKER: start processing job (4, 0, 11)
13:12:00 WORKER: args: ()
13:12:00 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.009568799326562303, 'num_filters_1': 48, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.017765208029095994, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 66, 'num_filters_3': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:12:53 DISPATCHER: Starting worker discovery
13:12:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:12:53 DISPATCHER: Finished worker discovery
13:12:54 WORKER: done with job (4, 0, 11), trying to register it.
13:12:54 WORKER: registered result for job (4, 0, 11) with dispatcher
13:12:54 DISPATCHER: job (4, 0, 11) finished
13:12:54 DISPATCHER: register_result: lock acquired
13:12:54 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:12:54 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.009568799326562303, 'num_filters_1': 48, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.017765208029095994, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 66, 'num_filters_3': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8927615830192446, 'info': {'music-speech': 0.8927615830192446, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.009568799326562303, 'num_filters_1': 48, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.017765208029095994, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 66, 'num_filters_3': 17}"}}
exception: None

13:12:54 job_callback for (4, 0, 11) started
13:12:54 DISPATCHER: Trying to submit another job.
13:12:54 job_callback for (4, 0, 11) got condition
13:12:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:12:54 done building a new model for budget 44.444444 based on 17/33 split
Best loss for this budget:-0.989669





13:12:54 HBMASTER: Trying to run another job!
13:12:54 job_callback for (4, 0, 11) finished
13:12:54 start sampling a new configuration.
13:12:54 best_vector: [0, 0, 0.20685184402597312, 0.2652900501732696, 0.4471997029660921, 0, 0.5185215044011424, 0.2569936553413473, 1, 0, 2, 2, 0.1294873997961134, 0.546647313727619, 0.027017156337805215, 0.9778063715821387], 1.675228366924841e-10, 1.7021249214571084e-06, 2.8514479524746646e-16
13:12:54 done sampling a new configuration.
13:12:55 HBMASTER: schedule new run for iteration 4
13:12:55 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
13:12:55 HBMASTER: submitting job (4, 0, 12) to dispatcher
13:12:55 DISPATCHER: trying to submit job (4, 0, 12)
13:12:55 DISPATCHER: trying to notify the job_runner thread.
13:12:55 HBMASTER: job (4, 0, 12) submitted to dispatcher
13:12:55 DISPATCHER: Trying to submit another job.
13:12:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:12:55 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:12:55 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:12:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:12:55 WORKER: start processing job (4, 0, 12)
13:12:55 WORKER: args: ()
13:12:55 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0025924100000821204, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.021595161401332264, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 20, 'num_filters_3': 49}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:13:48 WORKER: done with job (4, 0, 12), trying to register it.
13:13:48 WORKER: registered result for job (4, 0, 12) with dispatcher
13:13:48 DISPATCHER: job (4, 0, 12) finished
13:13:48 DISPATCHER: register_result: lock acquired
13:13:48 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:13:48 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0025924100000821204, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.021595161401332264, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 20, 'num_filters_3': 49}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9958687593034072, 'info': {'music-speech': 0.9958687593034072, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0025924100000821204, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.021595161401332264, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 20, 'num_filters_3': 49}"}}
exception: None

13:13:48 job_callback for (4, 0, 12) started
13:13:48 job_callback for (4, 0, 12) got condition
13:13:48 DISPATCHER: Trying to submit another job.
13:13:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:13:48 done building a new model for budget 44.444444 based on 17/34 split
Best loss for this budget:-0.995869





13:13:48 HBMASTER: Trying to run another job!
13:13:48 job_callback for (4, 0, 12) finished
13:13:48 start sampling a new configuration.
13:13:48 done sampling a new configuration.
13:13:48 HBMASTER: schedule new run for iteration 4
13:13:48 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
13:13:48 HBMASTER: submitting job (4, 0, 13) to dispatcher
13:13:48 DISPATCHER: trying to submit job (4, 0, 13)
13:13:48 DISPATCHER: trying to notify the job_runner thread.
13:13:48 HBMASTER: job (4, 0, 13) submitted to dispatcher
13:13:48 DISPATCHER: Trying to submit another job.
13:13:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:13:48 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:13:48 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:13:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:13:48 WORKER: start processing job (4, 0, 13)
13:13:48 WORKER: args: ()
13:13:48 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0020877020551333136, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.01178092328621746, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 32, 'num_filters_3': 25}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:13:53 DISPATCHER: Starting worker discovery
13:13:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:13:53 DISPATCHER: Finished worker discovery
13:14:42 WORKER: done with job (4, 0, 13), trying to register it.
13:14:42 WORKER: registered result for job (4, 0, 13) with dispatcher
13:14:42 DISPATCHER: job (4, 0, 13) finished
13:14:42 DISPATCHER: register_result: lock acquired
13:14:42 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:14:42 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0020877020551333136, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.01178092328621746, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 32, 'num_filters_3': 25}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9309049103215158, 'info': {'music-speech': 0.9309049103215158, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0020877020551333136, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.01178092328621746, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 32, 'num_filters_3': 25}"}}
exception: None

13:14:42 job_callback for (4, 0, 13) started
13:14:42 DISPATCHER: Trying to submit another job.
13:14:42 job_callback for (4, 0, 13) got condition
13:14:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:14:42 done building a new model for budget 44.444444 based on 17/34 split
Best loss for this budget:-0.995869





13:14:42 HBMASTER: Trying to run another job!
13:14:42 job_callback for (4, 0, 13) finished
13:14:42 start sampling a new configuration.
13:14:42 best_vector: [3, 2, 0.23247807758956124, 0.9772450924621184, 0.1056362919472027, 1, 0.7179259299889748, 0.7500282730942189, 0, 0, 2, 0, 0.4691792280149306, 0.8827005955213023, 0.030427180407992083, 0.8200507485979068], 1.3425801859751962e-12, 4.2984441484825186e-05, 5.771005944273653e-17
13:14:42 done sampling a new configuration.
13:14:42 HBMASTER: schedule new run for iteration 4
13:14:42 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
13:14:42 HBMASTER: submitting job (4, 0, 14) to dispatcher
13:14:42 DISPATCHER: trying to submit job (4, 0, 14)
13:14:42 DISPATCHER: trying to notify the job_runner thread.
13:14:42 HBMASTER: job (4, 0, 14) submitted to dispatcher
13:14:42 DISPATCHER: Trying to submit another job.
13:14:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:14:42 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:14:42 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:14:42 WORKER: start processing job (4, 0, 14)
13:14:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:14:42 WORKER: args: ()
13:14:42 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0029171324958492564, 'num_filters_1': 122, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.09458217154055182}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:14:53 DISPATCHER: Starting worker discovery
13:14:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:14:53 DISPATCHER: Finished worker discovery
13:15:36 WORKER: done with job (4, 0, 14), trying to register it.
13:15:36 DISPATCHER: job (4, 0, 14) finished
13:15:36 WORKER: registered result for job (4, 0, 14) with dispatcher
13:15:36 DISPATCHER: register_result: lock acquired
13:15:36 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:15:36 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0029171324958492564, 'num_filters_1': 122, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.09458217154055182}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6309156028324566, 'info': {'music-speech': 0.6309156028324566, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0029171324958492564, 'num_filters_1': 122, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.09458217154055182}"}}
exception: None

13:15:36 job_callback for (4, 0, 14) started
13:15:36 DISPATCHER: Trying to submit another job.
13:15:36 job_callback for (4, 0, 14) got condition
13:15:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:15:36 done building a new model for budget 44.444444 based on 17/35 split
Best loss for this budget:-0.995869





13:15:36 HBMASTER: Trying to run another job!
13:15:36 job_callback for (4, 0, 14) finished
13:15:36 start sampling a new configuration.
13:15:36 best_vector: [0, 1, 0.4350270837764016, 0.669816632183093, 0.9215532994323135, 1, 0.7346245412758474, 0.4613139890458635, 2, 2, 2, 1, 0.021757272147796682, 0.19605428381045054, 0.10704368814592258, 0.8847029020141798], 2.3659040484684932e-09, 3.49654957665245e-05, 8.272500799072828e-14
13:15:36 done sampling a new configuration.
13:15:36 HBMASTER: schedule new run for iteration 4
13:15:36 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
13:15:36 HBMASTER: submitting job (4, 0, 15) to dispatcher
13:15:36 DISPATCHER: trying to submit job (4, 0, 15)
13:15:36 DISPATCHER: trying to notify the job_runner thread.
13:15:36 HBMASTER: job (4, 0, 15) submitted to dispatcher
13:15:36 DISPATCHER: Trying to submit another job.
13:15:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:15:36 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:15:36 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:15:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:15:36 WORKER: start processing job (4, 0, 15)
13:15:36 WORKER: args: ()
13:15:36 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.007414027072833066, 'num_filters_1': 64, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.03982752667470641, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 16, 'num_filters_3': 23, 'num_filters_4': 19, 'num_filters_5': 101}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-290:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 1497625682 is out of bounds for axis 0 with size 2

13:15:53 DISPATCHER: Starting worker discovery
13:15:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:15:53 DISPATCHER: Finished worker discovery
13:16:29 WORKER: done with job (4, 0, 15), trying to register it.
13:16:29 WORKER: registered result for job (4, 0, 15) with dispatcher
13:16:29 DISPATCHER: job (4, 0, 15) finished
13:16:29 DISPATCHER: register_result: lock acquired
13:16:29 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:16:29 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.007414027072833066, 'num_filters_1': 64, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.03982752667470641, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 16, 'num_filters_3': 23, 'num_filters_4': 19, 'num_filters_5': 101}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9076387186519197, 'info': {'music-speech': 0.9076387186519197, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.007414027072833066, 'num_filters_1': 64, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.03982752667470641, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 16, 'num_filters_3': 23, 'num_filters_4': 19, 'num_filters_5': 101}"}}
exception: None

13:16:29 job_callback for (4, 0, 15) started
13:16:29 DISPATCHER: Trying to submit another job.
13:16:29 job_callback for (4, 0, 15) got condition
13:16:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:16:29 done building a new model for budget 44.444444 based on 17/36 split
Best loss for this budget:-0.995869





13:16:29 HBMASTER: Trying to run another job!
13:16:29 job_callback for (4, 0, 15) finished
13:16:29 start sampling a new configuration.
13:16:29 done sampling a new configuration.
13:16:29 HBMASTER: schedule new run for iteration 4
13:16:29 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
13:16:29 HBMASTER: submitting job (4, 0, 16) to dispatcher
13:16:29 DISPATCHER: trying to submit job (4, 0, 16)
13:16:29 DISPATCHER: trying to notify the job_runner thread.
13:16:29 HBMASTER: job (4, 0, 16) submitted to dispatcher
13:16:29 DISPATCHER: Trying to submit another job.
13:16:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:16:29 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:16:29 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:16:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:16:29 WORKER: start processing job (4, 0, 16)
13:16:29 WORKER: args: ()
13:16:29 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.02091185702094436, 'num_filters_1': 90, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.0155486885409178}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:16:53 DISPATCHER: Starting worker discovery
13:16:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:16:53 DISPATCHER: Finished worker discovery
13:17:22 WORKER: done with job (4, 0, 16), trying to register it.
13:17:22 WORKER: registered result for job (4, 0, 16) with dispatcher
13:17:22 DISPATCHER: job (4, 0, 16) finished
13:17:22 DISPATCHER: register_result: lock acquired
13:17:22 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:17:22 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.02091185702094436, 'num_filters_1': 90, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.0155486885409178}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5566644934939361, 'info': {'music-speech': 0.5566644934939361, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.02091185702094436, 'num_filters_1': 90, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.0155486885409178}"}}
exception: None

13:17:22 job_callback for (4, 0, 16) started
13:17:22 job_callback for (4, 0, 16) got condition
13:17:22 DISPATCHER: Trying to submit another job.
13:17:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:17:22 done building a new model for budget 44.444444 based on 17/37 split
Best loss for this budget:-0.995869





13:17:22 HBMASTER: Trying to run another job!
13:17:22 job_callback for (4, 0, 16) finished
13:17:22 start sampling a new configuration.
13:17:22 done sampling a new configuration.
13:17:22 HBMASTER: schedule new run for iteration 4
13:17:22 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
13:17:22 HBMASTER: submitting job (4, 0, 17) to dispatcher
13:17:22 DISPATCHER: trying to submit job (4, 0, 17)
13:17:22 DISPATCHER: trying to notify the job_runner thread.
13:17:22 HBMASTER: job (4, 0, 17) submitted to dispatcher
13:17:22 DISPATCHER: Trying to submit another job.
13:17:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:17:22 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:17:22 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:17:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:17:22 WORKER: start processing job (4, 0, 17)
13:17:22 WORKER: args: ()
13:17:22 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.01193967617407876, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.0584068849302866, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 34, 'num_filters_3': 91}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:17:53 DISPATCHER: Starting worker discovery
13:17:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:17:53 DISPATCHER: Finished worker discovery
13:18:15 WORKER: done with job (4, 0, 17), trying to register it.
13:18:15 WORKER: registered result for job (4, 0, 17) with dispatcher
13:18:15 DISPATCHER: job (4, 0, 17) finished
13:18:15 DISPATCHER: register_result: lock acquired
13:18:15 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:18:15 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.01193967617407876, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.0584068849302866, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 34, 'num_filters_3': 91}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.06720162434576933, 'info': {'music-speech': 0.06720162434576933, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.01193967617407876, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.0584068849302866, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 34, 'num_filters_3': 91}"}}
exception: None

13:18:15 job_callback for (4, 0, 17) started
13:18:15 DISPATCHER: Trying to submit another job.
13:18:15 job_callback for (4, 0, 17) got condition
13:18:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:18:15 done building a new model for budget 44.444444 based on 17/38 split
Best loss for this budget:-0.995869





13:18:15 HBMASTER: Trying to run another job!
13:18:15 job_callback for (4, 0, 17) finished
13:18:15 start sampling a new configuration.
13:18:15 done sampling a new configuration.
13:18:15 HBMASTER: schedule new run for iteration 4
13:18:15 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
13:18:15 HBMASTER: submitting job (4, 0, 18) to dispatcher
13:18:15 DISPATCHER: trying to submit job (4, 0, 18)
13:18:15 DISPATCHER: trying to notify the job_runner thread.
13:18:15 HBMASTER: job (4, 0, 18) submitted to dispatcher
13:18:15 DISPATCHER: Trying to submit another job.
13:18:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:18:15 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:18:15 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:18:15 WORKER: start processing job (4, 0, 18)
13:18:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:18:15 WORKER: args: ()
13:18:15 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002399439895680347, 'num_filters_1': 35, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.016024196434305707, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 75, 'num_filters_3': 62}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:18:53 DISPATCHER: Starting worker discovery
13:18:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:18:53 DISPATCHER: Finished worker discovery
13:19:09 WORKER: done with job (4, 0, 18), trying to register it.
13:19:09 DISPATCHER: job (4, 0, 18) finished
13:19:09 WORKER: registered result for job (4, 0, 18) with dispatcher
13:19:09 DISPATCHER: register_result: lock acquired
13:19:09 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:19:09 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002399439895680347, 'num_filters_1': 35, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.016024196434305707, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 75, 'num_filters_3': 62}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9257535470291545, 'info': {'music-speech': 0.9257535470291545, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002399439895680347, 'num_filters_1': 35, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.016024196434305707, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 75, 'num_filters_3': 62}"}}
exception: None

13:19:09 job_callback for (4, 0, 18) started
13:19:09 DISPATCHER: Trying to submit another job.
13:19:09 job_callback for (4, 0, 18) got condition
13:19:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:19:09 done building a new model for budget 44.444444 based on 17/39 split
Best loss for this budget:-0.995869





13:19:09 HBMASTER: Trying to run another job!
13:19:09 job_callback for (4, 0, 18) finished
13:19:09 start sampling a new configuration.
13:19:09 best_vector: [1, 0, 0.07616002796153937, 0.5950832826122875, 0.7442335738081819, 0, 0.8055516368173572, 0.8696058675652131, 0, 0, 2, 1, 0.032430385726425065, 0.5804827477829831, 0.20434230576983964, 0.980481020015434], 2.6132938737324558e-05, 0.00039971958572555355, 1.0445847445874643e-08
13:19:09 done sampling a new configuration.
13:19:09 HBMASTER: schedule new run for iteration 4
13:19:09 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
13:19:09 HBMASTER: submitting job (4, 0, 19) to dispatcher
13:19:09 DISPATCHER: trying to submit job (4, 0, 19)
13:19:09 DISPATCHER: trying to notify the job_runner thread.
13:19:09 HBMASTER: job (4, 0, 19) submitted to dispatcher
13:19:09 DISPATCHER: Trying to submit another job.
13:19:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:19:09 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:19:09 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:19:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:19:09 WORKER: start processing job (4, 0, 19)
13:19:09 WORKER: args: ()
13:19:09 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0014201036900830526, 'num_filters_1': 55, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.13532664597448474, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 17, 'num_filters_3': 53, 'num_filters_4': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:19:53 DISPATCHER: Starting worker discovery
13:19:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:19:53 DISPATCHER: Finished worker discovery
13:20:02 WORKER: done with job (4, 0, 19), trying to register it.
13:20:02 WORKER: registered result for job (4, 0, 19) with dispatcher
13:20:02 DISPATCHER: job (4, 0, 19) finished
13:20:02 DISPATCHER: register_result: lock acquired
13:20:02 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:20:02 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0014201036900830526, 'num_filters_1': 55, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.13532664597448474, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 17, 'num_filters_3': 53, 'num_filters_4': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9028191721478076, 'info': {'music-speech': 0.9028191721478076, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0014201036900830526, 'num_filters_1': 55, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.13532664597448474, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 17, 'num_filters_3': 53, 'num_filters_4': 24}"}}
exception: None

13:20:03 job_callback for (4, 0, 19) started
13:20:03 DISPATCHER: Trying to submit another job.
13:20:03 job_callback for (4, 0, 19) got condition
13:20:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:20:03 done building a new model for budget 44.444444 based on 17/39 split
Best loss for this budget:-0.995869





13:20:03 HBMASTER: Trying to run another job!
13:20:03 job_callback for (4, 0, 19) finished
13:20:03 start sampling a new configuration.
13:20:03 best_vector: [1, 0, 0.055293131916388655, 0.3128325377776017, 0.9074710454108972, 0, 0.1688498662032074, 0.602092239168231, 1, 0, 2, 2, 0.36028770729206305, 0.46020139199698235, 0.3304709913240893, 0.7779031380901543], 0.0001367223422446197, 0.006976138324568275, 9.537939715574315e-07
13:20:03 done sampling a new configuration.
13:20:03 HBMASTER: schedule new run for iteration 4
13:20:03 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
13:20:03 HBMASTER: submitting job (4, 0, 20) to dispatcher
13:20:03 DISPATCHER: trying to submit job (4, 0, 20)
13:20:03 DISPATCHER: trying to notify the job_runner thread.
13:20:03 HBMASTER: job (4, 0, 20) submitted to dispatcher
13:20:03 DISPATCHER: Trying to submit another job.
13:20:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:20:03 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:20:03 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:20:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:20:03 WORKER: start processing job (4, 0, 20)
13:20:03 WORKER: args: ()
13:20:03 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0012899897628814263, 'num_filters_1': 30, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.06072116051840622, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 33, 'num_filters_3': 41, 'num_filters_4': 31, 'num_filters_5': 80}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:20:53 DISPATCHER: Starting worker discovery
13:20:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:20:53 DISPATCHER: Finished worker discovery
13:20:56 WORKER: done with job (4, 0, 20), trying to register it.
13:20:56 DISPATCHER: job (4, 0, 20) finished
13:20:56 WORKER: registered result for job (4, 0, 20) with dispatcher
13:20:56 DISPATCHER: register_result: lock acquired
13:20:56 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:20:56 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0012899897628814263, 'num_filters_1': 30, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.06072116051840622, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 33, 'num_filters_3': 41, 'num_filters_4': 31, 'num_filters_5': 80}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9889506663964089, 'info': {'music-speech': 0.9889506663964089, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0012899897628814263, 'num_filters_1': 30, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.06072116051840622, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 33, 'num_filters_3': 41, 'num_filters_4': 31, 'num_filters_5': 80}"}}
exception: None

13:20:56 job_callback for (4, 0, 20) started
13:20:56 DISPATCHER: Trying to submit another job.
13:20:56 job_callback for (4, 0, 20) got condition
13:20:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:20:56 done building a new model for budget 44.444444 based on 17/40 split
Best loss for this budget:-0.995869





13:20:56 HBMASTER: Trying to run another job!
13:20:56 job_callback for (4, 0, 20) finished
13:20:56 start sampling a new configuration.
13:20:56 done sampling a new configuration.
13:20:56 HBMASTER: schedule new run for iteration 4
13:20:56 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
13:20:56 HBMASTER: submitting job (4, 0, 21) to dispatcher
13:20:56 DISPATCHER: trying to submit job (4, 0, 21)
13:20:56 DISPATCHER: trying to notify the job_runner thread.
13:20:56 HBMASTER: job (4, 0, 21) submitted to dispatcher
13:20:56 DISPATCHER: Trying to submit another job.
13:20:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:20:56 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:20:56 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:20:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:20:56 WORKER: start processing job (4, 0, 21)
13:20:56 WORKER: args: ()
13:20:56 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0011731307084509868, 'num_filters_1': 107, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.011724184410128746, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 19, 'num_filters_3': 19, 'num_filters_4': 37, 'num_filters_5': 45}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:21:50 WORKER: done with job (4, 0, 21), trying to register it.
13:21:50 WORKER: registered result for job (4, 0, 21) with dispatcher
13:21:50 DISPATCHER: job (4, 0, 21) finished
13:21:50 DISPATCHER: register_result: lock acquired
13:21:50 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:21:50 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0011731307084509868, 'num_filters_1': 107, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.011724184410128746, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 19, 'num_filters_3': 19, 'num_filters_4': 37, 'num_filters_5': 45}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9912238202155004, 'info': {'music-speech': 0.9912238202155004, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0011731307084509868, 'num_filters_1': 107, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.011724184410128746, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 19, 'num_filters_3': 19, 'num_filters_4': 37, 'num_filters_5': 45}"}}
exception: None

13:21:50 job_callback for (4, 0, 21) started
13:21:50 DISPATCHER: Trying to submit another job.
13:21:50 job_callback for (4, 0, 21) got condition
13:21:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:21:50 done building a new model for budget 44.444444 based on 17/41 split
Best loss for this budget:-0.995869





13:21:50 HBMASTER: Trying to run another job!
13:21:50 job_callback for (4, 0, 21) finished
13:21:50 start sampling a new configuration.
13:21:50 done sampling a new configuration.
13:21:50 HBMASTER: schedule new run for iteration 4
13:21:50 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
13:21:50 HBMASTER: submitting job (4, 0, 22) to dispatcher
13:21:50 DISPATCHER: trying to submit job (4, 0, 22)
13:21:50 DISPATCHER: trying to notify the job_runner thread.
13:21:50 HBMASTER: job (4, 0, 22) submitted to dispatcher
13:21:50 DISPATCHER: Trying to submit another job.
13:21:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:21:50 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:21:50 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:21:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:21:50 WORKER: start processing job (4, 0, 22)
13:21:50 WORKER: args: ()
13:21:50 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.006319935204192114, 'num_filters_1': 25, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.014424984866435736, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 51, 'num_filters_3': 36}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:21:53 DISPATCHER: Starting worker discovery
13:21:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:21:53 DISPATCHER: Finished worker discovery
13:22:44 WORKER: done with job (4, 0, 22), trying to register it.
13:22:44 WORKER: registered result for job (4, 0, 22) with dispatcher
13:22:44 DISPATCHER: job (4, 0, 22) finished
13:22:44 DISPATCHER: register_result: lock acquired
13:22:44 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:22:44 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.006319935204192114, 'num_filters_1': 25, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.014424984866435736, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 51, 'num_filters_3': 36}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.837224428297938, 'info': {'music-speech': 0.837224428297938, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.006319935204192114, 'num_filters_1': 25, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.014424984866435736, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 51, 'num_filters_3': 36}"}}
exception: None

13:22:44 job_callback for (4, 0, 22) started
13:22:44 DISPATCHER: Trying to submit another job.
13:22:44 job_callback for (4, 0, 22) got condition
13:22:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:22:44 done building a new model for budget 44.444444 based on 17/42 split
Best loss for this budget:-0.995869





13:22:44 HBMASTER: Trying to run another job!
13:22:44 job_callback for (4, 0, 22) finished
13:22:44 start sampling a new configuration.
13:22:44 done sampling a new configuration.
13:22:44 HBMASTER: schedule new run for iteration 4
13:22:44 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
13:22:44 HBMASTER: submitting job (4, 0, 23) to dispatcher
13:22:44 DISPATCHER: trying to submit job (4, 0, 23)
13:22:44 DISPATCHER: trying to notify the job_runner thread.
13:22:44 HBMASTER: job (4, 0, 23) submitted to dispatcher
13:22:44 DISPATCHER: Trying to submit another job.
13:22:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:22:44 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:22:44 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:22:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:22:44 WORKER: start processing job (4, 0, 23)
13:22:44 WORKER: args: ()
13:22:44 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0027173454067001934, 'num_filters_1': 62, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.021659495426148312}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:22:53 DISPATCHER: Starting worker discovery
13:22:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:22:53 DISPATCHER: Finished worker discovery
13:23:38 WORKER: done with job (4, 0, 23), trying to register it.
13:23:38 WORKER: registered result for job (4, 0, 23) with dispatcher
13:23:38 DISPATCHER: job (4, 0, 23) finished
13:23:38 DISPATCHER: register_result: lock acquired
13:23:38 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:23:38 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0027173454067001934, 'num_filters_1': 62, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.021659495426148312}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9682742053503491, 'info': {'music-speech': 0.9682742053503491, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0027173454067001934, 'num_filters_1': 62, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.021659495426148312}"}}
exception: None

13:23:38 job_callback for (4, 0, 23) started
13:23:38 DISPATCHER: Trying to submit another job.
13:23:38 job_callback for (4, 0, 23) got condition
13:23:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:23:38 done building a new model for budget 44.444444 based on 17/43 split
Best loss for this budget:-0.995869





13:23:38 HBMASTER: Trying to run another job!
13:23:38 job_callback for (4, 0, 23) finished
13:23:38 start sampling a new configuration.
13:23:38 best_vector: [2, 1, 0.2596150569678618, 0.6414487432786292, 0.6764802089605416, 0, 0.11908806724069115, 0.40648408416494747, 1, 2, 2, 1, 0.015333085659702924, 0.5326262537559695, 0.23533858803090862, 0.8933138366079134], 0.0007136694416422849, 0.0028001000279710337, 1.998345823504634e-06
13:23:38 done sampling a new configuration.
13:23:38 HBMASTER: schedule new run for iteration 4
13:23:38 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
13:23:38 HBMASTER: submitting job (4, 0, 24) to dispatcher
13:23:38 DISPATCHER: trying to submit job (4, 0, 24)
13:23:38 DISPATCHER: trying to notify the job_runner thread.
13:23:38 HBMASTER: job (4, 0, 24) submitted to dispatcher
13:23:38 DISPATCHER: Trying to submit another job.
13:23:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:23:38 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:23:38 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:23:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:23:38 WORKER: start processing job (4, 0, 24)
13:23:38 WORKER: args: ()
13:23:38 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0033054463600720283, 'num_filters_1': 60, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.03379465259123698, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 16, 'num_filters_3': 48, 'num_filters_4': 25}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:23:53 DISPATCHER: Starting worker discovery
13:23:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:23:53 DISPATCHER: Finished worker discovery
13:24:32 WORKER: done with job (4, 0, 24), trying to register it.
13:24:32 WORKER: registered result for job (4, 0, 24) with dispatcher
13:24:32 DISPATCHER: job (4, 0, 24) finished
13:24:32 DISPATCHER: register_result: lock acquired
13:24:32 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:24:32 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0033054463600720283, 'num_filters_1': 60, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.03379465259123698, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 16, 'num_filters_3': 48, 'num_filters_4': 25}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9181905039340134, 'info': {'music-speech': 0.9181905039340134, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0033054463600720283, 'num_filters_1': 60, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.03379465259123698, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 16, 'num_filters_3': 48, 'num_filters_4': 25}"}}
exception: None

13:24:32 job_callback for (4, 0, 24) started
13:24:32 job_callback for (4, 0, 24) got condition
13:24:32 DISPATCHER: Trying to submit another job.
13:24:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:24:32 done building a new model for budget 44.444444 based on 17/44 split
Best loss for this budget:-0.995869





13:24:32 HBMASTER: Trying to run another job!
13:24:32 job_callback for (4, 0, 24) finished
13:24:32 start sampling a new configuration.
13:24:32 best_vector: [3, 1, 0.22333258841133802, 0.4395002391131557, 0.8694674637172362, 1, 0.3826434384047732, 0.5651478538761943, 2, 1, 0, 1, 0.29768824479868566, 0.36842866982161593, 0.44033252448965876, 0.894502927319471], 0.006966447439491249, 0.005123832138883391, 3.5694907284307166e-05
13:24:32 done sampling a new configuration.
13:24:32 HBMASTER: schedule new run for iteration 4
13:24:32 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
13:24:32 HBMASTER: submitting job (4, 0, 25) to dispatcher
13:24:32 DISPATCHER: trying to submit job (4, 0, 25)
13:24:32 DISPATCHER: trying to notify the job_runner thread.
13:24:32 HBMASTER: job (4, 0, 25) submitted to dispatcher
13:24:32 DISPATCHER: Trying to submit another job.
13:24:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:24:32 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:24:32 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:24:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:24:32 WORKER: start processing job (4, 0, 25)
13:24:32 WORKER: args: ()
13:24:32 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002796824251807824, 'num_filters_1': 39, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.054359356865088526, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 29, 'num_filters_3': 34, 'num_filters_4': 39, 'num_filters_5': 103}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:24:53 DISPATCHER: Starting worker discovery
13:24:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:24:53 DISPATCHER: Finished worker discovery
13:25:26 WORKER: done with job (4, 0, 25), trying to register it.
13:25:26 WORKER: registered result for job (4, 0, 25) with dispatcher
13:25:26 DISPATCHER: job (4, 0, 25) finished
13:25:26 DISPATCHER: register_result: lock acquired
13:25:26 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:25:26 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002796824251807824, 'num_filters_1': 39, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.054359356865088526, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 29, 'num_filters_3': 34, 'num_filters_4': 39, 'num_filters_5': 103}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8401810799793547, 'info': {'music-speech': 0.8401810799793547, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.002796824251807824, 'num_filters_1': 39, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.054359356865088526, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 29, 'num_filters_3': 34, 'num_filters_4': 39, 'num_filters_5': 103}"}}
exception: None

13:25:26 job_callback for (4, 0, 25) started
13:25:26 job_callback for (4, 0, 25) got condition
13:25:26 DISPATCHER: Trying to submit another job.
13:25:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:25:26 done building a new model for budget 44.444444 based on 17/45 split
Best loss for this budget:-0.995869





13:25:26 HBMASTER: Trying to run another job!
13:25:26 job_callback for (4, 0, 25) finished
13:25:26 start sampling a new configuration.
13:25:26 done sampling a new configuration.
13:25:26 HBMASTER: schedule new run for iteration 4
13:25:26 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
13:25:26 HBMASTER: submitting job (4, 0, 26) to dispatcher
13:25:26 DISPATCHER: trying to submit job (4, 0, 26)
13:25:26 DISPATCHER: trying to notify the job_runner thread.
13:25:26 HBMASTER: job (4, 0, 26) submitted to dispatcher
13:25:26 DISPATCHER: Trying to submit another job.
13:25:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:25:26 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:25:26 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:25:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:25:26 WORKER: start processing job (4, 0, 26)
13:25:26 WORKER: args: ()
13:25:26 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0013464016400121497, 'num_filters_1': 17, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.1023507726494255, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 61, 'num_filters_3': 19, 'num_filters_4': 31, 'num_filters_5': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
13:25:53 DISPATCHER: Starting worker discovery
13:25:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:25:53 DISPATCHER: Finished worker discovery
13:26:19 WORKER: done with job (4, 0, 26), trying to register it.
13:26:19 WORKER: registered result for job (4, 0, 26) with dispatcher
13:26:19 DISPATCHER: job (4, 0, 26) finished
13:26:19 DISPATCHER: register_result: lock acquired
13:26:19 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:26:19 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0013464016400121497, 'num_filters_1': 17, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.1023507726494255, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 61, 'num_filters_3': 19, 'num_filters_4': 31, 'num_filters_5': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9888946315011987, 'info': {'music-speech': 0.9888946315011987, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0013464016400121497, 'num_filters_1': 17, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.1023507726494255, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 61, 'num_filters_3': 19, 'num_filters_4': 31, 'num_filters_5': 18}"}}
exception: None

13:26:19 job_callback for (4, 0, 26) started
13:26:19 DISPATCHER: Trying to submit another job.
13:26:19 job_callback for (4, 0, 26) got condition
13:26:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:26:19 done building a new model for budget 44.444444 based on 17/45 split
Best loss for this budget:-0.995869





13:26:19 HBMASTER: Trying to run another job!
13:26:19 job_callback for (4, 0, 26) finished
13:26:19 ITERATION: Advancing config (4, 0, 1) to next budget 133.333333
13:26:19 ITERATION: Advancing config (4, 0, 7) to next budget 133.333333
13:26:19 ITERATION: Advancing config (4, 0, 12) to next budget 133.333333
13:26:19 ITERATION: Advancing config (4, 0, 13) to next budget 133.333333
13:26:19 ITERATION: Advancing config (4, 0, 18) to next budget 133.333333
13:26:19 ITERATION: Advancing config (4, 0, 20) to next budget 133.333333
13:26:19 ITERATION: Advancing config (4, 0, 21) to next budget 133.333333
13:26:19 ITERATION: Advancing config (4, 0, 23) to next budget 133.333333
13:26:19 ITERATION: Advancing config (4, 0, 26) to next budget 133.333333
13:26:19 HBMASTER: schedule new run for iteration 4
13:26:19 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
13:26:19 HBMASTER: submitting job (4, 0, 1) to dispatcher
13:26:19 DISPATCHER: trying to submit job (4, 0, 1)
13:26:19 DISPATCHER: trying to notify the job_runner thread.
13:26:19 HBMASTER: job (4, 0, 1) submitted to dispatcher
13:26:19 DISPATCHER: Trying to submit another job.
13:26:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:26:19 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:26:19 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:26:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:26:19 WORKER: start processing job (4, 0, 1)
13:26:19 WORKER: args: ()
13:26:19 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.006782397457041025, 'num_filters_1': 34, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.02814201483224562, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 16, 'num_filters_3': 41, 'num_filters_4': 72}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:26:53 DISPATCHER: Starting worker discovery
13:26:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:26:53 DISPATCHER: Finished worker discovery
13:27:53 DISPATCHER: Starting worker discovery
13:27:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:27:53 DISPATCHER: Finished worker discovery
13:28:42 WORKER: done with job (4, 0, 1), trying to register it.
13:28:42 WORKER: registered result for job (4, 0, 1) with dispatcher
13:28:42 DISPATCHER: job (4, 0, 1) finished
13:28:42 DISPATCHER: register_result: lock acquired
13:28:42 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:28:42 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.006782397457041025, 'num_filters_1': 34, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.02814201483224562, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 16, 'num_filters_3': 41, 'num_filters_4': 72}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9246300210435037, 'info': {'music-speech': 0.9246300210435037, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.006782397457041025, 'num_filters_1': 34, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.02814201483224562, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'num_filters_2': 16, 'num_filters_3': 41, 'num_filters_4': 72}"}}
exception: None

13:28:42 job_callback for (4, 0, 1) started
13:28:42 DISPATCHER: Trying to submit another job.
13:28:42 job_callback for (4, 0, 1) got condition
13:28:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:28:42 HBMASTER: Trying to run another job!
13:28:42 job_callback for (4, 0, 1) finished
13:28:42 HBMASTER: schedule new run for iteration 4
13:28:42 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
13:28:42 HBMASTER: submitting job (4, 0, 7) to dispatcher
13:28:42 DISPATCHER: trying to submit job (4, 0, 7)
13:28:42 DISPATCHER: trying to notify the job_runner thread.
13:28:42 HBMASTER: job (4, 0, 7) submitted to dispatcher
13:28:42 DISPATCHER: Trying to submit another job.
13:28:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:28:42 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:28:42 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:28:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:28:42 WORKER: start processing job (4, 0, 7)
13:28:42 WORKER: args: ()
13:28:42 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0020355024638142156, 'num_filters_1': 32, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.02415492166614904, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 55, 'num_filters_3': 29, 'num_filters_4': 27, 'num_filters_5': 69}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:28:53 DISPATCHER: Starting worker discovery
13:28:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:28:53 DISPATCHER: Finished worker discovery
13:29:53 DISPATCHER: Starting worker discovery
13:29:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:29:53 DISPATCHER: Finished worker discovery
13:30:53 DISPATCHER: Starting worker discovery
13:30:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:30:53 DISPATCHER: Finished worker discovery
13:31:05 WORKER: done with job (4, 0, 7), trying to register it.
13:31:05 WORKER: registered result for job (4, 0, 7) with dispatcher
13:31:05 DISPATCHER: job (4, 0, 7) finished
13:31:05 DISPATCHER: register_result: lock acquired
13:31:05 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:31:05 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0020355024638142156, 'num_filters_1': 32, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.02415492166614904, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 55, 'num_filters_3': 29, 'num_filters_4': 27, 'num_filters_5': 69}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8647636492653462, 'info': {'music-speech': 0.8647636492653462, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0020355024638142156, 'num_filters_1': 32, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.02415492166614904, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 55, 'num_filters_3': 29, 'num_filters_4': 27, 'num_filters_5': 69}"}}
exception: None

13:31:05 job_callback for (4, 0, 7) started
13:31:05 DISPATCHER: Trying to submit another job.
13:31:05 job_callback for (4, 0, 7) got condition
13:31:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:31:05 HBMASTER: Trying to run another job!
13:31:05 job_callback for (4, 0, 7) finished
13:31:05 HBMASTER: schedule new run for iteration 4
13:31:05 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
13:31:05 HBMASTER: submitting job (4, 0, 12) to dispatcher
13:31:05 DISPATCHER: trying to submit job (4, 0, 12)
13:31:05 DISPATCHER: trying to notify the job_runner thread.
13:31:05 HBMASTER: job (4, 0, 12) submitted to dispatcher
13:31:05 DISPATCHER: Trying to submit another job.
13:31:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:31:05 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:31:05 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:31:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:31:05 WORKER: start processing job (4, 0, 12)
13:31:05 WORKER: args: ()
13:31:05 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0025924100000821204, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.021595161401332264, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 20, 'num_filters_3': 49}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:31:53 DISPATCHER: Starting worker discovery
13:31:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:31:53 DISPATCHER: Finished worker discovery
13:32:53 DISPATCHER: Starting worker discovery
13:32:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:32:53 DISPATCHER: Finished worker discovery
13:33:27 WORKER: done with job (4, 0, 12), trying to register it.
13:33:27 WORKER: registered result for job (4, 0, 12) with dispatcher
13:33:27 DISPATCHER: job (4, 0, 12) finished
13:33:27 DISPATCHER: register_result: lock acquired
13:33:27 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:33:27 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0025924100000821204, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.021595161401332264, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 20, 'num_filters_3': 49}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9927761917425861, 'info': {'music-speech': 0.9927761917425861, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0025924100000821204, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.021595161401332264, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 20, 'num_filters_3': 49}"}}
exception: None

13:33:27 job_callback for (4, 0, 12) started
13:33:27 DISPATCHER: Trying to submit another job.
13:33:27 job_callback for (4, 0, 12) got condition
13:33:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:33:27 HBMASTER: Trying to run another job!
13:33:27 job_callback for (4, 0, 12) finished
13:33:27 HBMASTER: schedule new run for iteration 4
13:33:27 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
13:33:27 HBMASTER: submitting job (4, 0, 13) to dispatcher
13:33:27 DISPATCHER: trying to submit job (4, 0, 13)
13:33:27 DISPATCHER: trying to notify the job_runner thread.
13:33:27 HBMASTER: job (4, 0, 13) submitted to dispatcher
13:33:27 DISPATCHER: Trying to submit another job.
13:33:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:33:27 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:33:27 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:33:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:33:27 WORKER: start processing job (4, 0, 13)
13:33:27 WORKER: args: ()
13:33:27 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0020877020551333136, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.01178092328621746, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 32, 'num_filters_3': 25}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:33:53 DISPATCHER: Starting worker discovery
13:33:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:33:53 DISPATCHER: Finished worker discovery
13:34:53 DISPATCHER: Starting worker discovery
13:34:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:34:53 DISPATCHER: Finished worker discovery
13:35:51 WORKER: done with job (4, 0, 13), trying to register it.
13:35:51 DISPATCHER: job (4, 0, 13) finished
13:35:51 WORKER: registered result for job (4, 0, 13) with dispatcher
13:35:51 DISPATCHER: register_result: lock acquired
13:35:51 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:35:51 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0020877020551333136, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.01178092328621746, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 32, 'num_filters_3': 25}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.893560720505949, 'info': {'music-speech': 0.893560720505949, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0020877020551333136, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 81, 'weight_decay': 0.01178092328621746, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 32, 'num_filters_3': 25}"}}
exception: None

13:35:51 job_callback for (4, 0, 13) started
13:35:51 DISPATCHER: Trying to submit another job.
13:35:51 job_callback for (4, 0, 13) got condition
13:35:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:35:51 HBMASTER: Trying to run another job!
13:35:51 job_callback for (4, 0, 13) finished
13:35:51 HBMASTER: schedule new run for iteration 4
13:35:51 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
13:35:51 HBMASTER: submitting job (4, 0, 18) to dispatcher
13:35:51 DISPATCHER: trying to submit job (4, 0, 18)
13:35:51 DISPATCHER: trying to notify the job_runner thread.
13:35:51 HBMASTER: job (4, 0, 18) submitted to dispatcher
13:35:51 DISPATCHER: Trying to submit another job.
13:35:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:35:51 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:35:51 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:35:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:35:51 WORKER: start processing job (4, 0, 18)
13:35:51 WORKER: args: ()
13:35:51 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002399439895680347, 'num_filters_1': 35, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.016024196434305707, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 75, 'num_filters_3': 62}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:35:53 DISPATCHER: Starting worker discovery
13:35:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:35:53 DISPATCHER: Finished worker discovery
13:36:53 DISPATCHER: Starting worker discovery
13:36:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:36:53 DISPATCHER: Finished worker discovery
13:37:53 DISPATCHER: Starting worker discovery
13:37:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:37:53 DISPATCHER: Finished worker discovery
13:38:14 WORKER: done with job (4, 0, 18), trying to register it.
13:38:14 WORKER: registered result for job (4, 0, 18) with dispatcher
13:38:14 DISPATCHER: job (4, 0, 18) finished
13:38:14 DISPATCHER: register_result: lock acquired
13:38:14 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:38:14 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002399439895680347, 'num_filters_1': 35, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.016024196434305707, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 75, 'num_filters_3': 62}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9787910855636626, 'info': {'music-speech': 0.9787910855636626, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.002399439895680347, 'num_filters_1': 35, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.016024196434305707, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 75, 'num_filters_3': 62}"}}
exception: None

13:38:14 job_callback for (4, 0, 18) started
13:38:14 DISPATCHER: Trying to submit another job.
13:38:14 job_callback for (4, 0, 18) got condition
13:38:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:38:14 HBMASTER: Trying to run another job!
13:38:14 job_callback for (4, 0, 18) finished
13:38:14 HBMASTER: schedule new run for iteration 4
13:38:14 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
13:38:14 HBMASTER: submitting job (4, 0, 20) to dispatcher
13:38:14 DISPATCHER: trying to submit job (4, 0, 20)
13:38:14 DISPATCHER: trying to notify the job_runner thread.
13:38:14 HBMASTER: job (4, 0, 20) submitted to dispatcher
13:38:14 DISPATCHER: Trying to submit another job.
13:38:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:38:14 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:38:14 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:38:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:38:14 WORKER: start processing job (4, 0, 20)
13:38:14 WORKER: args: ()
13:38:14 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0012899897628814263, 'num_filters_1': 30, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.06072116051840622, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 33, 'num_filters_3': 41, 'num_filters_4': 31, 'num_filters_5': 80}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:38:53 DISPATCHER: Starting worker discovery
13:38:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:38:53 DISPATCHER: Finished worker discovery
13:39:53 DISPATCHER: Starting worker discovery
13:39:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:39:53 DISPATCHER: Finished worker discovery
13:40:36 WORKER: done with job (4, 0, 20), trying to register it.
13:40:36 WORKER: registered result for job (4, 0, 20) with dispatcher
13:40:36 DISPATCHER: job (4, 0, 20) finished
13:40:36 DISPATCHER: register_result: lock acquired
13:40:36 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:40:36 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0012899897628814263, 'num_filters_1': 30, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.06072116051840622, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 33, 'num_filters_3': 41, 'num_filters_4': 31, 'num_filters_5': 80}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9913853553823248, 'info': {'music-speech': 0.9913853553823248, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0012899897628814263, 'num_filters_1': 30, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.06072116051840622, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 33, 'num_filters_3': 41, 'num_filters_4': 31, 'num_filters_5': 80}"}}
exception: None

13:40:36 job_callback for (4, 0, 20) started
13:40:36 DISPATCHER: Trying to submit another job.
13:40:36 job_callback for (4, 0, 20) got condition
13:40:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:40:36 HBMASTER: Trying to run another job!
13:40:36 job_callback for (4, 0, 20) finished
13:40:36 HBMASTER: schedule new run for iteration 4
13:40:36 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
13:40:36 HBMASTER: submitting job (4, 0, 21) to dispatcher
13:40:36 DISPATCHER: trying to submit job (4, 0, 21)
13:40:36 DISPATCHER: trying to notify the job_runner thread.
13:40:36 HBMASTER: job (4, 0, 21) submitted to dispatcher
13:40:36 DISPATCHER: Trying to submit another job.
13:40:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:40:36 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:40:36 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:40:36 WORKER: start processing job (4, 0, 21)
13:40:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:40:36 WORKER: args: ()
13:40:36 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0011731307084509868, 'num_filters_1': 107, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.011724184410128746, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 19, 'num_filters_3': 19, 'num_filters_4': 37, 'num_filters_5': 45}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:40:53 DISPATCHER: Starting worker discovery
13:40:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:40:53 DISPATCHER: Finished worker discovery
13:41:53 DISPATCHER: Starting worker discovery
13:41:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:41:53 DISPATCHER: Finished worker discovery
13:42:53 DISPATCHER: Starting worker discovery
13:42:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:42:53 DISPATCHER: Finished worker discovery
13:42:59 WORKER: done with job (4, 0, 21), trying to register it.
13:42:59 WORKER: registered result for job (4, 0, 21) with dispatcher
13:42:59 DISPATCHER: job (4, 0, 21) finished
13:42:59 DISPATCHER: register_result: lock acquired
13:42:59 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:42:59 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0011731307084509868, 'num_filters_1': 107, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.011724184410128746, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 19, 'num_filters_3': 19, 'num_filters_4': 37, 'num_filters_5': 45}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9905098345923965, 'info': {'music-speech': 0.9905098345923965, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0011731307084509868, 'num_filters_1': 107, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.011724184410128746, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 19, 'num_filters_3': 19, 'num_filters_4': 37, 'num_filters_5': 45}"}}
exception: None

13:42:59 job_callback for (4, 0, 21) started
13:42:59 DISPATCHER: Trying to submit another job.
13:42:59 job_callback for (4, 0, 21) got condition
13:42:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:42:59 HBMASTER: Trying to run another job!
13:42:59 job_callback for (4, 0, 21) finished
13:42:59 HBMASTER: schedule new run for iteration 4
13:42:59 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
13:42:59 HBMASTER: submitting job (4, 0, 23) to dispatcher
13:42:59 DISPATCHER: trying to submit job (4, 0, 23)
13:42:59 DISPATCHER: trying to notify the job_runner thread.
13:42:59 HBMASTER: job (4, 0, 23) submitted to dispatcher
13:42:59 DISPATCHER: Trying to submit another job.
13:42:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:42:59 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:42:59 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:42:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:42:59 WORKER: start processing job (4, 0, 23)
13:42:59 WORKER: args: ()
13:42:59 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0027173454067001934, 'num_filters_1': 62, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.021659495426148312}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:43:53 DISPATCHER: Starting worker discovery
13:43:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:43:53 DISPATCHER: Finished worker discovery
13:44:53 DISPATCHER: Starting worker discovery
13:44:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:44:53 DISPATCHER: Finished worker discovery
13:45:22 WORKER: done with job (4, 0, 23), trying to register it.
13:45:22 WORKER: registered result for job (4, 0, 23) with dispatcher
13:45:22 DISPATCHER: job (4, 0, 23) finished
13:45:22 DISPATCHER: register_result: lock acquired
13:45:22 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:45:22 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0027173454067001934, 'num_filters_1': 62, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.021659495426148312}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.969121464907391, 'info': {'music-speech': 0.969121464907391, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0027173454067001934, 'num_filters_1': 62, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.021659495426148312}"}}
exception: None

13:45:22 job_callback for (4, 0, 23) started
13:45:22 DISPATCHER: Trying to submit another job.
13:45:22 job_callback for (4, 0, 23) got condition
13:45:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:45:22 HBMASTER: Trying to run another job!
13:45:22 job_callback for (4, 0, 23) finished
13:45:22 HBMASTER: schedule new run for iteration 4
13:45:22 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
13:45:22 HBMASTER: submitting job (4, 0, 26) to dispatcher
13:45:22 DISPATCHER: trying to submit job (4, 0, 26)
13:45:22 DISPATCHER: trying to notify the job_runner thread.
13:45:22 HBMASTER: job (4, 0, 26) submitted to dispatcher
13:45:22 DISPATCHER: Trying to submit another job.
13:45:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:45:22 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:45:22 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:45:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:45:22 WORKER: start processing job (4, 0, 26)
13:45:22 WORKER: args: ()
13:45:22 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0013464016400121497, 'num_filters_1': 17, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.1023507726494255, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 61, 'num_filters_3': 19, 'num_filters_4': 31, 'num_filters_5': 18}, 'budget': 133.33333333333331, 'working_directory': '.'}
13:45:53 DISPATCHER: Starting worker discovery
13:45:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:45:53 DISPATCHER: Finished worker discovery
13:46:53 DISPATCHER: Starting worker discovery
13:46:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:46:53 DISPATCHER: Finished worker discovery
13:47:44 WORKER: done with job (4, 0, 26), trying to register it.
13:47:44 WORKER: registered result for job (4, 0, 26) with dispatcher
13:47:44 DISPATCHER: job (4, 0, 26) finished
13:47:44 DISPATCHER: register_result: lock acquired
13:47:44 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:47:44 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0013464016400121497, 'num_filters_1': 17, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.1023507726494255, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 61, 'num_filters_3': 19, 'num_filters_4': 31, 'num_filters_5': 18}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9779985956237257, 'info': {'music-speech': 0.9779985956237257, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0013464016400121497, 'num_filters_1': 17, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.1023507726494255, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 61, 'num_filters_3': 19, 'num_filters_4': 31, 'num_filters_5': 18}"}}
exception: None

13:47:44 job_callback for (4, 0, 26) started
13:47:44 DISPATCHER: Trying to submit another job.
13:47:44 job_callback for (4, 0, 26) got condition
13:47:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:47:44 HBMASTER: Trying to run another job!
13:47:44 job_callback for (4, 0, 26) finished
13:47:44 ITERATION: Advancing config (4, 0, 12) to next budget 400.000000
13:47:44 ITERATION: Advancing config (4, 0, 20) to next budget 400.000000
13:47:44 ITERATION: Advancing config (4, 0, 21) to next budget 400.000000
13:47:44 HBMASTER: schedule new run for iteration 4
13:47:44 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
13:47:44 HBMASTER: submitting job (4, 0, 12) to dispatcher
13:47:44 DISPATCHER: trying to submit job (4, 0, 12)
13:47:44 DISPATCHER: trying to notify the job_runner thread.
13:47:44 HBMASTER: job (4, 0, 12) submitted to dispatcher
13:47:44 DISPATCHER: Trying to submit another job.
13:47:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:47:44 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:47:44 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:47:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:47:44 WORKER: start processing job (4, 0, 12)
13:47:44 WORKER: args: ()
13:47:44 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0025924100000821204, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.021595161401332264, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 20, 'num_filters_3': 49}, 'budget': 400.0, 'working_directory': '.'}
13:47:53 DISPATCHER: Starting worker discovery
13:47:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:47:53 DISPATCHER: Finished worker discovery
13:48:53 DISPATCHER: Starting worker discovery
13:48:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:48:53 DISPATCHER: Finished worker discovery
13:49:53 DISPATCHER: Starting worker discovery
13:49:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:49:53 DISPATCHER: Finished worker discovery
13:50:53 DISPATCHER: Starting worker discovery
13:50:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:50:53 DISPATCHER: Finished worker discovery
13:51:53 DISPATCHER: Starting worker discovery
13:51:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:51:53 DISPATCHER: Finished worker discovery
13:52:53 DISPATCHER: Starting worker discovery
13:52:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:52:53 DISPATCHER: Finished worker discovery
13:53:53 DISPATCHER: Starting worker discovery
13:53:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:53:53 DISPATCHER: Finished worker discovery
13:54:34 WORKER: done with job (4, 0, 12), trying to register it.
13:54:34 WORKER: registered result for job (4, 0, 12) with dispatcher
13:54:34 DISPATCHER: job (4, 0, 12) finished
13:54:34 DISPATCHER: register_result: lock acquired
13:54:34 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:54:34 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0025924100000821204, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.021595161401332264, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 20, 'num_filters_3': 49}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9943281857930893, 'info': {'music-speech': 0.9943281857930893, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0025924100000821204, 'num_filters_1': 27, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.021595161401332264, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 20, 'num_filters_3': 49}"}}
exception: None

13:54:34 job_callback for (4, 0, 12) started
13:54:34 DISPATCHER: Trying to submit another job.
13:54:34 job_callback for (4, 0, 12) got condition
13:54:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:54:34 Only 13 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
13:54:34 HBMASTER: Trying to run another job!
13:54:34 job_callback for (4, 0, 12) finished
13:54:34 HBMASTER: schedule new run for iteration 4
13:54:34 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
13:54:34 HBMASTER: submitting job (4, 0, 20) to dispatcher
13:54:34 DISPATCHER: trying to submit job (4, 0, 20)
13:54:34 DISPATCHER: trying to notify the job_runner thread.
13:54:34 HBMASTER: job (4, 0, 20) submitted to dispatcher
13:54:34 DISPATCHER: Trying to submit another job.
13:54:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:54:34 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:54:34 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:54:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:54:34 WORKER: start processing job (4, 0, 20)
13:54:34 WORKER: args: ()
13:54:34 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0012899897628814263, 'num_filters_1': 30, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.06072116051840622, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 33, 'num_filters_3': 41, 'num_filters_4': 31, 'num_filters_5': 80}, 'budget': 400.0, 'working_directory': '.'}
13:54:53 DISPATCHER: Starting worker discovery
13:54:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:54:53 DISPATCHER: Finished worker discovery
13:55:53 DISPATCHER: Starting worker discovery
13:55:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:55:53 DISPATCHER: Finished worker discovery
13:56:53 DISPATCHER: Starting worker discovery
13:56:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:56:53 DISPATCHER: Finished worker discovery
13:57:53 DISPATCHER: Starting worker discovery
13:57:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:57:53 DISPATCHER: Finished worker discovery
13:58:53 DISPATCHER: Starting worker discovery
13:58:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:58:53 DISPATCHER: Finished worker discovery
13:59:53 DISPATCHER: Starting worker discovery
13:59:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:59:53 DISPATCHER: Finished worker discovery
14:00:53 DISPATCHER: Starting worker discovery
14:00:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:00:53 DISPATCHER: Finished worker discovery
14:01:24 WORKER: done with job (4, 0, 20), trying to register it.
14:01:24 WORKER: registered result for job (4, 0, 20) with dispatcher
14:01:24 DISPATCHER: job (4, 0, 20) finished
14:01:24 DISPATCHER: register_result: lock acquired
14:01:24 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:01:24 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0012899897628814263, 'num_filters_1': 30, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.06072116051840622, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 33, 'num_filters_3': 41, 'num_filters_4': 31, 'num_filters_5': 80}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9966488357792634, 'info': {'music-speech': 0.9966488357792634, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0012899897628814263, 'num_filters_1': 30, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.06072116051840622, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 33, 'num_filters_3': 41, 'num_filters_4': 31, 'num_filters_5': 80}"}}
exception: None

14:01:24 job_callback for (4, 0, 20) started
14:01:24 DISPATCHER: Trying to submit another job.
14:01:24 job_callback for (4, 0, 20) got condition
14:01:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:01:24 Only 14 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
14:01:24 HBMASTER: Trying to run another job!
14:01:24 job_callback for (4, 0, 20) finished
14:01:24 HBMASTER: schedule new run for iteration 4
14:01:24 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
14:01:24 HBMASTER: submitting job (4, 0, 21) to dispatcher
14:01:24 DISPATCHER: trying to submit job (4, 0, 21)
14:01:24 DISPATCHER: trying to notify the job_runner thread.
14:01:24 HBMASTER: job (4, 0, 21) submitted to dispatcher
14:01:24 DISPATCHER: Trying to submit another job.
14:01:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:01:24 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:01:24 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:01:24 WORKER: start processing job (4, 0, 21)
14:01:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:01:24 WORKER: args: ()
14:01:24 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0011731307084509868, 'num_filters_1': 107, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.011724184410128746, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 19, 'num_filters_3': 19, 'num_filters_4': 37, 'num_filters_5': 45}, 'budget': 400.0, 'working_directory': '.'}
14:01:53 DISPATCHER: Starting worker discovery
14:01:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:01:53 DISPATCHER: Finished worker discovery
14:02:53 DISPATCHER: Starting worker discovery
14:02:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:02:53 DISPATCHER: Finished worker discovery
14:03:53 DISPATCHER: Starting worker discovery
14:03:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:03:53 DISPATCHER: Finished worker discovery
14:04:53 DISPATCHER: Starting worker discovery
14:04:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:04:53 DISPATCHER: Finished worker discovery
14:05:53 DISPATCHER: Starting worker discovery
14:05:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:05:53 DISPATCHER: Finished worker discovery
14:06:53 DISPATCHER: Starting worker discovery
14:06:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:06:53 DISPATCHER: Finished worker discovery
14:07:53 DISPATCHER: Starting worker discovery
14:07:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:07:53 DISPATCHER: Finished worker discovery
14:08:14 WORKER: done with job (4, 0, 21), trying to register it.
14:08:14 WORKER: registered result for job (4, 0, 21) with dispatcher
14:08:14 DISPATCHER: job (4, 0, 21) finished
14:08:14 DISPATCHER: register_result: lock acquired
14:08:14 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:08:14 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0011731307084509868, 'num_filters_1': 107, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.011724184410128746, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 19, 'num_filters_3': 19, 'num_filters_4': 37, 'num_filters_5': 45}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.964936515927052, 'info': {'music-speech': 0.964936515927052, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0011731307084509868, 'num_filters_1': 107, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.011724184410128746, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 19, 'num_filters_3': 19, 'num_filters_4': 37, 'num_filters_5': 45}"}}
exception: None

14:08:14 job_callback for (4, 0, 21) started
14:08:14 job_callback for (4, 0, 21) got condition
14:08:14 DISPATCHER: Trying to submit another job.
14:08:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:08:14 Only 15 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
14:08:14 HBMASTER: Trying to run another job!
14:08:14 job_callback for (4, 0, 21) finished
14:08:14 ITERATION: Advancing config (4, 0, 20) to next budget 1200.000000
14:08:14 HBMASTER: schedule new run for iteration 4
14:08:14 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
14:08:14 HBMASTER: submitting job (4, 0, 20) to dispatcher
14:08:14 DISPATCHER: trying to submit job (4, 0, 20)
14:08:14 DISPATCHER: trying to notify the job_runner thread.
14:08:14 HBMASTER: job (4, 0, 20) submitted to dispatcher
14:08:14 DISPATCHER: Trying to submit another job.
14:08:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:08:14 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:08:14 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:08:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:08:14 WORKER: start processing job (4, 0, 20)
14:08:14 WORKER: args: ()
14:08:14 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0012899897628814263, 'num_filters_1': 30, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.06072116051840622, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 33, 'num_filters_3': 41, 'num_filters_4': 31, 'num_filters_5': 80}, 'budget': 1200.0, 'working_directory': '.'}
14:08:53 DISPATCHER: Starting worker discovery
14:08:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:08:53 DISPATCHER: Finished worker discovery
14:09:53 DISPATCHER: Starting worker discovery
14:09:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:09:53 DISPATCHER: Finished worker discovery
14:10:53 DISPATCHER: Starting worker discovery
14:10:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:10:53 DISPATCHER: Finished worker discovery
14:11:53 DISPATCHER: Starting worker discovery
14:11:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:11:53 DISPATCHER: Finished worker discovery
14:12:53 DISPATCHER: Starting worker discovery
14:12:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:12:53 DISPATCHER: Finished worker discovery
14:13:53 DISPATCHER: Starting worker discovery
14:13:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:13:53 DISPATCHER: Finished worker discovery
14:14:53 DISPATCHER: Starting worker discovery
14:14:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:14:53 DISPATCHER: Finished worker discovery
14:15:53 DISPATCHER: Starting worker discovery
14:15:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:15:53 DISPATCHER: Finished worker discovery
14:16:53 DISPATCHER: Starting worker discovery
14:16:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:16:53 DISPATCHER: Finished worker discovery
14:17:53 DISPATCHER: Starting worker discovery
14:17:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:17:53 DISPATCHER: Finished worker discovery
14:18:53 DISPATCHER: Starting worker discovery
14:18:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:18:53 DISPATCHER: Finished worker discovery
14:19:53 DISPATCHER: Starting worker discovery
14:19:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:19:53 DISPATCHER: Finished worker discovery
14:20:53 DISPATCHER: Starting worker discovery
14:20:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:20:53 DISPATCHER: Finished worker discovery
14:21:53 DISPATCHER: Starting worker discovery
14:21:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:21:53 DISPATCHER: Finished worker discovery
14:22:53 DISPATCHER: Starting worker discovery
14:22:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:22:53 DISPATCHER: Finished worker discovery
14:23:53 DISPATCHER: Starting worker discovery
14:23:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:23:53 DISPATCHER: Finished worker discovery
14:24:53 DISPATCHER: Starting worker discovery
14:24:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:24:53 DISPATCHER: Finished worker discovery
14:25:53 DISPATCHER: Starting worker discovery
14:25:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:25:53 DISPATCHER: Finished worker discovery
14:26:53 DISPATCHER: Starting worker discovery
14:26:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:26:53 DISPATCHER: Finished worker discovery
14:27:53 DISPATCHER: Starting worker discovery
14:27:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:27:53 DISPATCHER: Finished worker discovery
14:28:24 WORKER: done with job (4, 0, 20), trying to register it.
14:28:24 WORKER: registered result for job (4, 0, 20) with dispatcher
14:28:24 DISPATCHER: job (4, 0, 20) finished
14:28:24 DISPATCHER: register_result: lock acquired
14:28:24 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:28:24 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0012899897628814263, 'num_filters_1': 30, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.06072116051840622, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 33, 'num_filters_3': 41, 'num_filters_4': 31, 'num_filters_5': 80}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.8851464578407933, 'info': {'music-speech': 0.8851464578407933, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0012899897628814263, 'num_filters_1': 30, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.06072116051840622, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 33, 'num_filters_3': 41, 'num_filters_4': 31, 'num_filters_5': 80}"}}
exception: None

14:28:24 job_callback for (4, 0, 20) started
14:28:24 DISPATCHER: Trying to submit another job.
14:28:24 job_callback for (4, 0, 20) got condition
14:28:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:28:24 Only 9 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
14:28:24 HBMASTER: Trying to run another job!
14:28:24 job_callback for (4, 0, 20) finished
14:28:24 start sampling a new configuration.
14:28:25 best_vector: [1, 0, 0.21191222999643455, 0.11494725980726586, 0.4676315110697165, 0, 0.6219288145006513, 0.30231513602380383, 1, 0, 2, 1, 0.10977799176685768, 0.6116536148968588, 0.5895025934940037, 0.05206676873768905], 0.001463889215810904, 0.0030317785450602393, 4.438187916840557e-06
14:28:25 done sampling a new configuration.
14:28:25 HBMASTER: schedule new run for iteration 5
14:28:25 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
14:28:25 HBMASTER: submitting job (5, 0, 0) to dispatcher
14:28:25 DISPATCHER: trying to submit job (5, 0, 0)
14:28:25 DISPATCHER: trying to notify the job_runner thread.
14:28:25 HBMASTER: job (5, 0, 0) submitted to dispatcher
14:28:25 DISPATCHER: Trying to submit another job.
14:28:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:28:25 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:28:25 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:28:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:28:25 WORKER: start processing job (5, 0, 0)
14:28:25 WORKER: args: ()
14:28:25 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0026535327983649407, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.02473552087721056, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 20, 'num_filters_3': 57}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:28:53 DISPATCHER: Starting worker discovery
14:28:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:28:53 DISPATCHER: Finished worker discovery
14:29:53 DISPATCHER: Starting worker discovery
14:29:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:29:53 DISPATCHER: Finished worker discovery
14:30:47 WORKER: done with job (5, 0, 0), trying to register it.
14:30:47 WORKER: registered result for job (5, 0, 0) with dispatcher
14:30:47 DISPATCHER: job (5, 0, 0) finished
14:30:47 DISPATCHER: register_result: lock acquired
14:30:47 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:30:47 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0026535327983649407, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.02473552087721056, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 20, 'num_filters_3': 57}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9921730666456305, 'info': {'music-speech': 0.9921730666456305, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0026535327983649407, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.02473552087721056, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 20, 'num_filters_3': 57}"}}
exception: None

14:30:47 job_callback for (5, 0, 0) started
14:30:47 job_callback for (5, 0, 0) got condition
14:30:47 DISPATCHER: Trying to submit another job.
14:30:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:30:47 HBMASTER: Trying to run another job!
14:30:47 job_callback for (5, 0, 0) finished
14:30:47 start sampling a new configuration.
14:30:48 best_vector: [3, 2, 0.04319342410920045, 0.12348540143404674, 0.9830156296967284, 0, 0.07672931318440537, 0.7435232605606537, 1, 2, 1, 1, 0.7726147981542276, 0.09122523688568326, 0.18242762395839218, 0.4215245226120081], 0.0005694009813097551, 0.0015072283245210131, 8.582172870401229e-07
14:30:48 done sampling a new configuration.
14:30:48 HBMASTER: schedule new run for iteration 5
14:30:48 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
14:30:48 HBMASTER: submitting job (5, 0, 1) to dispatcher
14:30:48 DISPATCHER: trying to submit job (5, 0, 1)
14:30:48 DISPATCHER: trying to notify the job_runner thread.
14:30:48 HBMASTER: job (5, 0, 1) submitted to dispatcher
14:30:48 DISPATCHER: Trying to submit another job.
14:30:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:30:48 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:30:48 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:30:48 WORKER: start processing job (5, 0, 1)
14:30:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:30:48 WORKER: args: ()
14:30:48 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0012200758987965974, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.09275686554473321, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 79, 'num_filters_3': 19, 'num_filters_4': 23, 'num_filters_5': 38}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:30:53 DISPATCHER: Starting worker discovery
14:30:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:30:53 DISPATCHER: Finished worker discovery
14:31:53 DISPATCHER: Starting worker discovery
14:31:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:31:53 DISPATCHER: Finished worker discovery
14:32:53 DISPATCHER: Starting worker discovery
14:32:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:32:54 DISPATCHER: Finished worker discovery
14:33:10 WORKER: done with job (5, 0, 1), trying to register it.
14:33:10 DISPATCHER: job (5, 0, 1) finished
14:33:10 WORKER: registered result for job (5, 0, 1) with dispatcher
14:33:10 DISPATCHER: register_result: lock acquired
14:33:10 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:33:10 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0012200758987965974, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.09275686554473321, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 79, 'num_filters_3': 19, 'num_filters_4': 23, 'num_filters_5': 38}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9143354381829096, 'info': {'music-speech': 0.9143354381829096, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0012200758987965974, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.09275686554473321, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 79, 'num_filters_3': 19, 'num_filters_4': 23, 'num_filters_5': 38}"}}
exception: None

14:33:10 job_callback for (5, 0, 1) started
14:33:10 DISPATCHER: Trying to submit another job.
14:33:10 job_callback for (5, 0, 1) got condition
14:33:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:33:10 HBMASTER: Trying to run another job!
14:33:10 job_callback for (5, 0, 1) finished
14:33:10 start sampling a new configuration.
14:33:10 best_vector: [1, 1, 0.0361405327825985, 0.24137336497110018, 0.9658699990348898, 1, 0.30938875496220497, 0.4259996771682369, 2, 0, 1, 0, 0.3328551282552841, 0.41404514317672636, 0.05053237700394153, 0.24250756414975633], 0.007012165768440978, 0.0005011904160242871, 3.5144302787161987e-06
14:33:10 done sampling a new configuration.
14:33:10 HBMASTER: schedule new run for iteration 5
14:33:10 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
14:33:10 HBMASTER: submitting job (5, 0, 2) to dispatcher
14:33:10 DISPATCHER: trying to submit job (5, 0, 2)
14:33:10 DISPATCHER: trying to notify the job_runner thread.
14:33:10 HBMASTER: job (5, 0, 2) submitted to dispatcher
14:33:10 DISPATCHER: Trying to submit another job.
14:33:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:33:10 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:33:10 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:33:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:33:10 WORKER: start processing job (5, 0, 2)
14:33:10 WORKER: args: ()
14:33:10 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0011810847597041824, 'num_filters_1': 26, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.035829302865827604, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 31, 'num_filters_3': 37, 'num_filters_4': 17, 'num_filters_5': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:33:54 DISPATCHER: Starting worker discovery
14:33:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:33:54 DISPATCHER: Finished worker discovery
14:34:54 DISPATCHER: Starting worker discovery
14:34:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:34:54 DISPATCHER: Finished worker discovery
14:35:33 WORKER: done with job (5, 0, 2), trying to register it.
14:35:33 WORKER: registered result for job (5, 0, 2) with dispatcher
14:35:33 DISPATCHER: job (5, 0, 2) finished
14:35:33 DISPATCHER: register_result: lock acquired
14:35:33 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:35:33 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0011810847597041824, 'num_filters_1': 26, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.035829302865827604, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 31, 'num_filters_3': 37, 'num_filters_4': 17, 'num_filters_5': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8556443179460693, 'info': {'music-speech': 0.8556443179460693, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0011810847597041824, 'num_filters_1': 26, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.035829302865827604, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 31, 'num_filters_3': 37, 'num_filters_4': 17, 'num_filters_5': 26}"}}
exception: None

14:35:33 job_callback for (5, 0, 2) started
14:35:33 job_callback for (5, 0, 2) got condition
14:35:33 DISPATCHER: Trying to submit another job.
14:35:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:35:33 HBMASTER: Trying to run another job!
14:35:33 job_callback for (5, 0, 2) finished
14:35:33 start sampling a new configuration.
14:35:33 best_vector: [1, 1, 0.20845692735665938, 0.22782147630882874, 0.36325700707372033, 1, 0.2674269012033116, 0.9058336964438798, 2, 2, 1, 2, 0.521475989872335, 0.0009323894107435421, 0.010900492706566622, 0.14127909417342852], 0.0012254118259164585, 5.959688194462235e-05, 7.30307239226873e-08
14:35:33 done sampling a new configuration.
14:35:33 HBMASTER: schedule new run for iteration 5
14:35:33 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
14:35:33 HBMASTER: submitting job (5, 0, 3) to dispatcher
14:35:33 DISPATCHER: trying to submit job (5, 0, 3)
14:35:33 DISPATCHER: trying to notify the job_runner thread.
14:35:33 HBMASTER: job (5, 0, 3) submitted to dispatcher
14:35:33 DISPATCHER: Trying to submit another job.
14:35:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:35:33 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:35:33 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:35:33 WORKER: start processing job (5, 0, 3)
14:35:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:35:33 WORKER: args: ()
14:35:33 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.00261164326567849, 'num_filters_1': 25, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.1508400994810535, 'kernel_size_2': 7, 'num_filters_2': 47}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:35:54 DISPATCHER: Starting worker discovery
14:35:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:35:54 DISPATCHER: Finished worker discovery
14:36:54 DISPATCHER: Starting worker discovery
14:36:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:36:54 DISPATCHER: Finished worker discovery
14:37:54 DISPATCHER: Starting worker discovery
14:37:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:37:54 DISPATCHER: Finished worker discovery
14:37:55 WORKER: done with job (5, 0, 3), trying to register it.
14:37:55 WORKER: registered result for job (5, 0, 3) with dispatcher
14:37:55 DISPATCHER: job (5, 0, 3) finished
14:37:55 DISPATCHER: register_result: lock acquired
14:37:55 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:37:55 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.00261164326567849, 'num_filters_1': 25, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.1508400994810535, 'kernel_size_2': 7, 'num_filters_2': 47}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7643700128953114, 'info': {'music-speech': 0.7643700128953114, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.00261164326567849, 'num_filters_1': 25, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.1508400994810535, 'kernel_size_2': 7, 'num_filters_2': 47}"}}
exception: None

14:37:55 job_callback for (5, 0, 3) started
14:37:55 DISPATCHER: Trying to submit another job.
14:37:55 job_callback for (5, 0, 3) got condition
14:37:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:37:55 HBMASTER: Trying to run another job!
14:37:55 job_callback for (5, 0, 3) finished
14:37:55 start sampling a new configuration.
14:37:55 best_vector: [3, 0, 0.21897471617548236, 0.7140379510274574, 0.2029532134683542, 1, 0.3543976392289715, 0.20156308301567777, 0, 0, 1, 1, 0.6023810053721841, 0.4014329626768008, 0.04005479381684485, 0.005032129844959446], 0.01009675953362413, 0.00039753433629156275, 4.013808599894777e-06
14:37:55 done sampling a new configuration.
14:37:55 HBMASTER: schedule new run for iteration 5
14:37:55 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
14:37:55 HBMASTER: submitting job (5, 0, 4) to dispatcher
14:37:55 DISPATCHER: trying to submit job (5, 0, 4)
14:37:55 DISPATCHER: trying to notify the job_runner thread.
14:37:55 HBMASTER: job (5, 0, 4) submitted to dispatcher
14:37:55 DISPATCHER: Trying to submit another job.
14:37:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:37:55 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:37:55 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:37:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:37:55 WORKER: start processing job (5, 0, 4)
14:37:55 WORKER: args: ()
14:37:55 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0027412549717180062, 'num_filters_1': 70, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.01829109127867142, 'kernel_size_2': 3, 'num_filters_2': 55}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:38:54 DISPATCHER: Starting worker discovery
14:38:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:38:54 DISPATCHER: Finished worker discovery
14:39:54 DISPATCHER: Starting worker discovery
14:39:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:39:54 DISPATCHER: Finished worker discovery
14:40:18 WORKER: done with job (5, 0, 4), trying to register it.
14:40:18 WORKER: registered result for job (5, 0, 4) with dispatcher
14:40:18 DISPATCHER: job (5, 0, 4) finished
14:40:18 DISPATCHER: register_result: lock acquired
14:40:18 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:40:18 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0027412549717180062, 'num_filters_1': 70, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.01829109127867142, 'kernel_size_2': 3, 'num_filters_2': 55}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9027184244342684, 'info': {'music-speech': 0.9027184244342684, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0027412549717180062, 'num_filters_1': 70, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.01829109127867142, 'kernel_size_2': 3, 'num_filters_2': 55}"}}
exception: None

14:40:18 job_callback for (5, 0, 4) started
14:40:18 DISPATCHER: Trying to submit another job.
14:40:18 job_callback for (5, 0, 4) got condition
14:40:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:40:18 HBMASTER: Trying to run another job!
14:40:18 job_callback for (5, 0, 4) finished
14:40:18 start sampling a new configuration.
14:40:19 best_vector: [3, 0, 0.4239421906443125, 0.29559006676809635, 0.9516989052754079, 0, 0.9884709218921879, 0.5072041878424253, 1, 1, 0, 1, 0.05269996375842945, 0.3154423876717714, 0.42380660284126775, 0.6599837413356155], 0.03341620516441035, 0.0009247830083715489, 3.090273874030429e-05
14:40:19 done sampling a new configuration.
14:40:19 HBMASTER: schedule new run for iteration 5
14:40:19 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
14:40:19 HBMASTER: submitting job (5, 0, 5) to dispatcher
14:40:19 DISPATCHER: trying to submit job (5, 0, 5)
14:40:19 DISPATCHER: trying to notify the job_runner thread.
14:40:19 HBMASTER: job (5, 0, 5) submitted to dispatcher
14:40:19 DISPATCHER: Trying to submit another job.
14:40:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:40:19 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:40:19 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:40:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:40:19 WORKER: start processing job (5, 0, 5)
14:40:19 WORKER: args: ()
14:40:19 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.00704505489194443, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.045697018167493254, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 17, 'num_filters_3': 30, 'num_filters_4': 38, 'num_filters_5': 63}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:40:54 DISPATCHER: Starting worker discovery
14:40:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:40:54 DISPATCHER: Finished worker discovery
14:41:54 DISPATCHER: Starting worker discovery
14:41:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:41:54 DISPATCHER: Finished worker discovery
14:42:42 WORKER: done with job (5, 0, 5), trying to register it.
14:42:42 WORKER: registered result for job (5, 0, 5) with dispatcher
14:42:42 DISPATCHER: job (5, 0, 5) finished
14:42:42 DISPATCHER: register_result: lock acquired
14:42:42 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:42:42 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.00704505489194443, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.045697018167493254, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 17, 'num_filters_3': 30, 'num_filters_4': 38, 'num_filters_5': 63}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8606095372472322, 'info': {'music-speech': 0.8606095372472322, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.00704505489194443, 'num_filters_1': 29, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.045697018167493254, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 17, 'num_filters_3': 30, 'num_filters_4': 38, 'num_filters_5': 63}"}}
exception: None

14:42:42 job_callback for (5, 0, 5) started
14:42:42 job_callback for (5, 0, 5) got condition
14:42:42 DISPATCHER: Trying to submit another job.
14:42:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:42:42 HBMASTER: Trying to run another job!
14:42:42 job_callback for (5, 0, 5) finished
14:42:42 start sampling a new configuration.
14:42:42 best_vector: [3, 2, 0.39866326263396606, 0.17005785868424647, 0.7389216050599623, 0, 0.7651287995634655, 0.28584936677232275, 0, 2, 0, 1, 0.23385388459884893, 0.4117122487663465, 0.6658197591395179, 0.921265552500129], 0.010296946658922414, 0.007350978379497247, 7.569263226457508e-05
14:42:42 done sampling a new configuration.
14:42:42 HBMASTER: schedule new run for iteration 5
14:42:42 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
14:42:42 HBMASTER: submitting job (5, 0, 6) to dispatcher
14:42:42 DISPATCHER: trying to submit job (5, 0, 6)
14:42:42 DISPATCHER: trying to notify the job_runner thread.
14:42:42 HBMASTER: job (5, 0, 6) submitted to dispatcher
14:42:42 DISPATCHER: Trying to submit another job.
14:42:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:42:42 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:42:42 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:42:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:42:42 WORKER: start processing job (5, 0, 6)
14:42:42 WORKER: args: ()
14:42:42 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.006270851628451658, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.023544994883986314, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 25, 'num_filters_3': 37, 'num_filters_4': 63}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:42:54 DISPATCHER: Starting worker discovery
14:42:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:42:54 DISPATCHER: Finished worker discovery
14:43:54 DISPATCHER: Starting worker discovery
14:43:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:43:54 DISPATCHER: Finished worker discovery
14:44:54 DISPATCHER: Starting worker discovery
14:44:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:44:54 DISPATCHER: Finished worker discovery
14:45:05 WORKER: done with job (5, 0, 6), trying to register it.
14:45:05 WORKER: registered result for job (5, 0, 6) with dispatcher
14:45:05 DISPATCHER: job (5, 0, 6) finished
14:45:05 DISPATCHER: register_result: lock acquired
14:45:05 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:45:05 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.006270851628451658, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.023544994883986314, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 25, 'num_filters_3': 37, 'num_filters_4': 63}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9121891264039949, 'info': {'music-speech': 0.9121891264039949, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.006270851628451658, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.023544994883986314, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 25, 'num_filters_3': 37, 'num_filters_4': 63}"}}
exception: None

14:45:05 job_callback for (5, 0, 6) started
14:45:05 DISPATCHER: Trying to submit another job.
14:45:05 job_callback for (5, 0, 6) got condition
14:45:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:45:05 done building a new model for budget 133.333333 based on 17/28 split
Best loss for this budget:-0.992776





14:45:05 HBMASTER: Trying to run another job!
14:45:05 job_callback for (5, 0, 6) finished
14:45:05 start sampling a new configuration.
14:45:05 best_vector: [3, 0, 0.1413585478572533, 0.33355347442118355, 0.5268119037049511, 0, 0.9075751515253272, 0.2939567246540032, 2, 0, 1, 1, 0.2163172508798591, 0.3681471441931767, 0.7126046771225599, 0.45074189077316695], 1.0674324413338e-29, 0.0009368274386999701, -1.9083765422079668e-05
14:45:05 done sampling a new configuration.
14:45:05 HBMASTER: schedule new run for iteration 5
14:45:05 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
14:45:05 HBMASTER: submitting job (5, 0, 7) to dispatcher
14:45:05 DISPATCHER: trying to submit job (5, 0, 7)
14:45:05 DISPATCHER: trying to notify the job_runner thread.
14:45:05 HBMASTER: job (5, 0, 7) submitted to dispatcher
14:45:05 DISPATCHER: Trying to submit another job.
14:45:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:45:05 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:45:05 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:45:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:45:05 WORKER: start processing job (5, 0, 7)
14:45:05 WORKER: args: ()
14:45:05 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0019174193053739634, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.024123844267526784, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 24, 'num_filters_3': 34}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:45:54 DISPATCHER: Starting worker discovery
14:45:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:45:54 DISPATCHER: Finished worker discovery
14:46:54 DISPATCHER: Starting worker discovery
14:46:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:46:54 DISPATCHER: Finished worker discovery
14:47:41 WORKER: done with job (5, 0, 7), trying to register it.
14:47:41 DISPATCHER: job (5, 0, 7) finished
14:47:41 WORKER: registered result for job (5, 0, 7) with dispatcher
14:47:41 DISPATCHER: register_result: lock acquired
14:47:41 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:47:41 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0019174193053739634, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.024123844267526784, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 24, 'num_filters_3': 34}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9231767333965304, 'info': {'music-speech': 0.9231767333965304, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0019174193053739634, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.024123844267526784, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 24, 'num_filters_3': 34}"}}
exception: None

14:47:41 job_callback for (5, 0, 7) started
14:47:41 job_callback for (5, 0, 7) got condition
14:47:41 DISPATCHER: Trying to submit another job.
14:47:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:47:41 done building a new model for budget 133.333333 based on 17/29 split
Best loss for this budget:-0.992776





14:47:41 HBMASTER: Trying to run another job!
14:47:41 job_callback for (5, 0, 7) finished
14:47:41 start sampling a new configuration.
14:47:41 done sampling a new configuration.
14:47:41 HBMASTER: schedule new run for iteration 5
14:47:41 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
14:47:41 HBMASTER: submitting job (5, 0, 8) to dispatcher
14:47:41 DISPATCHER: trying to submit job (5, 0, 8)
14:47:41 DISPATCHER: trying to notify the job_runner thread.
14:47:41 HBMASTER: job (5, 0, 8) submitted to dispatcher
14:47:41 DISPATCHER: Trying to submit another job.
14:47:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:47:41 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:47:41 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:47:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:47:41 WORKER: start processing job (5, 0, 8)
14:47:41 WORKER: args: ()
14:47:41 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.039326393205371964, 'num_filters_1': 17, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.016746356976143444, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 119, 'num_filters_3': 28, 'num_filters_4': 47, 'num_filters_5': 89}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-323:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

14:47:54 DISPATCHER: Starting worker discovery
14:47:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:47:54 DISPATCHER: Finished worker discovery
14:48:54 DISPATCHER: Starting worker discovery
14:48:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:48:54 DISPATCHER: Finished worker discovery
14:49:54 DISPATCHER: Starting worker discovery
14:49:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:49:54 DISPATCHER: Finished worker discovery
14:50:03 WORKER: done with job (5, 0, 8), trying to register it.
14:50:03 WORKER: registered result for job (5, 0, 8) with dispatcher
14:50:03 DISPATCHER: job (5, 0, 8) finished
14:50:03 DISPATCHER: register_result: lock acquired
14:50:03 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:50:03 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.039326393205371964, 'num_filters_1': 17, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.016746356976143444, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 119, 'num_filters_3': 28, 'num_filters_4': 47, 'num_filters_5': 89}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9065523533849252, 'info': {'music-speech': 0.9065523533849252, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.039326393205371964, 'num_filters_1': 17, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.016746356976143444, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 119, 'num_filters_3': 28, 'num_filters_4': 47, 'num_filters_5': 89}"}}
exception: None

14:50:03 job_callback for (5, 0, 8) started
14:50:03 DISPATCHER: Trying to submit another job.
14:50:03 job_callback for (5, 0, 8) got condition
14:50:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:50:03 done building a new model for budget 133.333333 based on 17/30 split
Best loss for this budget:-0.992776





14:50:03 HBMASTER: Trying to run another job!
14:50:03 job_callback for (5, 0, 8) finished
14:50:03 ITERATION: Advancing config (5, 0, 0) to next budget 400.000000
14:50:03 ITERATION: Advancing config (5, 0, 1) to next budget 400.000000
14:50:03 ITERATION: Advancing config (5, 0, 7) to next budget 400.000000
14:50:03 HBMASTER: schedule new run for iteration 5
14:50:03 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
14:50:03 HBMASTER: submitting job (5, 0, 0) to dispatcher
14:50:03 DISPATCHER: trying to submit job (5, 0, 0)
14:50:03 DISPATCHER: trying to notify the job_runner thread.
14:50:03 HBMASTER: job (5, 0, 0) submitted to dispatcher
14:50:03 DISPATCHER: Trying to submit another job.
14:50:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:50:03 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:50:03 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:50:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:50:03 WORKER: start processing job (5, 0, 0)
14:50:03 WORKER: args: ()
14:50:03 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0026535327983649407, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.02473552087721056, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 20, 'num_filters_3': 57}, 'budget': 400.0, 'working_directory': '.'}
14:50:54 DISPATCHER: Starting worker discovery
14:50:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:50:54 DISPATCHER: Finished worker discovery
14:51:54 DISPATCHER: Starting worker discovery
14:51:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:51:54 DISPATCHER: Finished worker discovery
14:52:54 DISPATCHER: Starting worker discovery
14:52:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:52:54 DISPATCHER: Finished worker discovery
14:53:54 DISPATCHER: Starting worker discovery
14:53:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:53:54 DISPATCHER: Finished worker discovery
14:54:54 DISPATCHER: Starting worker discovery
14:54:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:54:54 DISPATCHER: Finished worker discovery
14:55:54 DISPATCHER: Starting worker discovery
14:55:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:55:54 DISPATCHER: Finished worker discovery
14:56:53 WORKER: done with job (5, 0, 0), trying to register it.
14:56:53 DISPATCHER: job (5, 0, 0) finished
14:56:53 WORKER: registered result for job (5, 0, 0) with dispatcher
14:56:53 DISPATCHER: register_result: lock acquired
14:56:53 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:56:53 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0026535327983649407, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.02473552087721056, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 20, 'num_filters_3': 57}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9922791633934588, 'info': {'music-speech': 0.9922791633934588, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0026535327983649407, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.02473552087721056, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 20, 'num_filters_3': 57}"}}
exception: None

14:56:53 job_callback for (5, 0, 0) started
14:56:53 DISPATCHER: Trying to submit another job.
14:56:53 job_callback for (5, 0, 0) got condition
14:56:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:56:53 Only 16 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
14:56:53 HBMASTER: Trying to run another job!
14:56:53 job_callback for (5, 0, 0) finished
14:56:53 HBMASTER: schedule new run for iteration 5
14:56:53 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
14:56:53 HBMASTER: submitting job (5, 0, 1) to dispatcher
14:56:53 DISPATCHER: trying to submit job (5, 0, 1)
14:56:53 DISPATCHER: trying to notify the job_runner thread.
14:56:53 HBMASTER: job (5, 0, 1) submitted to dispatcher
14:56:53 DISPATCHER: Trying to submit another job.
14:56:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:56:53 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:56:53 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:56:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:56:53 WORKER: start processing job (5, 0, 1)
14:56:53 WORKER: args: ()
14:56:53 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0012200758987965974, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.09275686554473321, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 79, 'num_filters_3': 19, 'num_filters_4': 23, 'num_filters_5': 38}, 'budget': 400.0, 'working_directory': '.'}
14:56:54 DISPATCHER: Starting worker discovery
14:56:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:56:54 DISPATCHER: Finished worker discovery
14:57:54 DISPATCHER: Starting worker discovery
14:57:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:57:54 DISPATCHER: Finished worker discovery
14:58:54 DISPATCHER: Starting worker discovery
14:58:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:58:54 DISPATCHER: Finished worker discovery
14:59:54 DISPATCHER: Starting worker discovery
14:59:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:59:54 DISPATCHER: Finished worker discovery
15:00:54 DISPATCHER: Starting worker discovery
15:00:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:00:54 DISPATCHER: Finished worker discovery
15:01:54 DISPATCHER: Starting worker discovery
15:01:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:01:54 DISPATCHER: Finished worker discovery
15:02:54 DISPATCHER: Starting worker discovery
15:02:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:02:54 DISPATCHER: Finished worker discovery
15:03:42 WORKER: done with job (5, 0, 1), trying to register it.
15:03:42 WORKER: registered result for job (5, 0, 1) with dispatcher
15:03:42 DISPATCHER: job (5, 0, 1) finished
15:03:42 DISPATCHER: register_result: lock acquired
15:03:42 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
15:03:42 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0012200758987965974, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.09275686554473321, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 79, 'num_filters_3': 19, 'num_filters_4': 23, 'num_filters_5': 38}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9087410446701119, 'info': {'music-speech': 0.9087410446701119, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0012200758987965974, 'num_filters_1': 20, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 16, 'weight_decay': 0.09275686554473321, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 79, 'num_filters_3': 19, 'num_filters_4': 23, 'num_filters_5': 38}"}}
exception: None

15:03:42 job_callback for (5, 0, 1) started
15:03:42 DISPATCHER: Trying to submit another job.
15:03:42 job_callback for (5, 0, 1) got condition
15:03:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:03:42 HBMASTER: Trying to run another job!
15:03:42 job_callback for (5, 0, 1) finished
15:03:42 HBMASTER: schedule new run for iteration 5
15:03:42 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
15:03:42 HBMASTER: submitting job (5, 0, 7) to dispatcher
15:03:42 DISPATCHER: trying to submit job (5, 0, 7)
15:03:42 DISPATCHER: trying to notify the job_runner thread.
15:03:42 HBMASTER: job (5, 0, 7) submitted to dispatcher
15:03:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:03:42 DISPATCHER: Trying to submit another job.
15:03:42 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
15:03:42 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
15:03:42 WORKER: start processing job (5, 0, 7)
15:03:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:03:42 WORKER: args: ()
15:03:42 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0019174193053739634, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.024123844267526784, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 24, 'num_filters_3': 34}, 'budget': 400.0, 'working_directory': '.'}
15:03:54 DISPATCHER: Starting worker discovery
15:03:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:03:54 DISPATCHER: Finished worker discovery
15:04:54 DISPATCHER: Starting worker discovery
15:04:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:04:54 DISPATCHER: Finished worker discovery
15:05:54 DISPATCHER: Starting worker discovery
15:05:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:05:54 DISPATCHER: Finished worker discovery
15:06:54 DISPATCHER: Starting worker discovery
15:06:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:06:54 DISPATCHER: Finished worker discovery
15:07:54 DISPATCHER: Starting worker discovery
15:07:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:07:54 DISPATCHER: Finished worker discovery
15:08:54 DISPATCHER: Starting worker discovery
15:08:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:08:54 DISPATCHER: Finished worker discovery
15:09:54 DISPATCHER: Starting worker discovery
15:09:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:09:54 DISPATCHER: Finished worker discovery
15:10:31 WORKER: done with job (5, 0, 7), trying to register it.
15:10:31 WORKER: registered result for job (5, 0, 7) with dispatcher
15:10:31 DISPATCHER: job (5, 0, 7) finished
15:10:31 DISPATCHER: register_result: lock acquired
15:10:31 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
15:10:31 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0019174193053739634, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.024123844267526784, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 24, 'num_filters_3': 34}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7194981185231467, 'info': {'music-speech': 0.7194981185231467, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0019174193053739634, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.024123844267526784, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 24, 'num_filters_3': 34}"}}
exception: None

15:10:31 job_callback for (5, 0, 7) started
15:10:31 DISPATCHER: Trying to submit another job.
15:10:31 job_callback for (5, 0, 7) got condition
15:10:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:10:31 HBMASTER: Trying to run another job!
15:10:31 job_callback for (5, 0, 7) finished
15:10:31 ITERATION: Advancing config (5, 0, 0) to next budget 1200.000000
15:10:31 HBMASTER: schedule new run for iteration 5
15:10:31 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
15:10:31 HBMASTER: submitting job (5, 0, 0) to dispatcher
15:10:31 DISPATCHER: trying to submit job (5, 0, 0)
15:10:31 DISPATCHER: trying to notify the job_runner thread.
15:10:31 HBMASTER: job (5, 0, 0) submitted to dispatcher
15:10:31 DISPATCHER: Trying to submit another job.
15:10:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:10:31 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
15:10:31 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
15:10:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:10:31 WORKER: start processing job (5, 0, 0)
15:10:31 WORKER: args: ()
15:10:31 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0026535327983649407, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.02473552087721056, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 20, 'num_filters_3': 57}, 'budget': 1200.0, 'working_directory': '.'}
15:10:54 DISPATCHER: Starting worker discovery
15:10:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:10:54 DISPATCHER: Finished worker discovery
15:11:54 DISPATCHER: Starting worker discovery
15:11:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:11:54 DISPATCHER: Finished worker discovery
15:12:54 DISPATCHER: Starting worker discovery
15:12:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:12:54 DISPATCHER: Finished worker discovery
15:13:54 DISPATCHER: Starting worker discovery
15:13:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:13:54 DISPATCHER: Finished worker discovery
15:14:54 DISPATCHER: Starting worker discovery
15:14:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:14:54 DISPATCHER: Finished worker discovery
15:15:54 DISPATCHER: Starting worker discovery
15:15:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:15:54 DISPATCHER: Finished worker discovery
15:16:54 DISPATCHER: Starting worker discovery
15:16:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:16:54 DISPATCHER: Finished worker discovery
15:17:54 DISPATCHER: Starting worker discovery
15:17:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:17:54 DISPATCHER: Finished worker discovery
15:18:54 DISPATCHER: Starting worker discovery
15:18:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:18:54 DISPATCHER: Finished worker discovery
15:19:54 DISPATCHER: Starting worker discovery
15:19:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:19:54 DISPATCHER: Finished worker discovery
15:20:54 DISPATCHER: Starting worker discovery
15:20:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:20:54 DISPATCHER: Finished worker discovery
15:21:54 DISPATCHER: Starting worker discovery
15:21:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:21:54 DISPATCHER: Finished worker discovery
15:22:54 DISPATCHER: Starting worker discovery
15:22:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:22:54 DISPATCHER: Finished worker discovery
15:23:54 DISPATCHER: Starting worker discovery
15:23:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:23:54 DISPATCHER: Finished worker discovery
15:24:54 DISPATCHER: Starting worker discovery
15:24:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:24:54 DISPATCHER: Finished worker discovery
15:25:54 DISPATCHER: Starting worker discovery
15:25:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:25:54 DISPATCHER: Finished worker discovery
15:26:54 DISPATCHER: Starting worker discovery
15:26:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:26:54 DISPATCHER: Finished worker discovery
15:27:54 DISPATCHER: Starting worker discovery
15:27:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:27:54 DISPATCHER: Finished worker discovery
15:28:54 DISPATCHER: Starting worker discovery
15:28:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:28:54 DISPATCHER: Finished worker discovery
15:29:54 DISPATCHER: Starting worker discovery
15:29:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:29:54 DISPATCHER: Finished worker discovery
15:30:40 WORKER: done with job (5, 0, 0), trying to register it.
15:30:40 WORKER: registered result for job (5, 0, 0) with dispatcher
15:30:40 DISPATCHER: job (5, 0, 0) finished
15:30:40 DISPATCHER: register_result: lock acquired
15:30:40 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
15:30:40 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0026535327983649407, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.02473552087721056, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 20, 'num_filters_3': 57}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.6022863334687898, 'info': {'music-speech': 0.6022863334687898, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0026535327983649407, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.02473552087721056, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 20, 'num_filters_3': 57}"}}
exception: None

15:30:40 job_callback for (5, 0, 0) started
15:30:40 job_callback for (5, 0, 0) got condition
15:30:40 DISPATCHER: Trying to submit another job.
15:30:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:30:40 Only 10 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
15:30:40 HBMASTER: Trying to run another job!
15:30:40 job_callback for (5, 0, 0) finished
15:30:40 start sampling a new configuration.
15:30:41 best_vector: [1, 2, 0.2549185843592833, 0.5002549479535892, 0.9488906652469502, 0, 0.45876791691071567, 0.06796524071777801, 1, 1, 2, 1, 0.18766724432363152, 0.4314521158601238, 0.05320218024417844, 0.01720973233589572], 6.759155005180899e-28, 1.479474874053782e-05, -5.139603895479554e-06
15:30:41 done sampling a new configuration.
15:30:41 HBMASTER: schedule new run for iteration 6
15:30:41 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
15:30:41 HBMASTER: submitting job (6, 0, 0) to dispatcher
15:30:41 DISPATCHER: trying to submit job (6, 0, 0)
15:30:41 DISPATCHER: trying to notify the job_runner thread.
15:30:41 HBMASTER: job (6, 0, 0) submitted to dispatcher
15:30:41 DISPATCHER: Trying to submit another job.
15:30:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:30:41 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
15:30:41 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
15:30:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:30:41 WORKER: start processing job (6, 0, 0)
15:30:41 WORKER: args: ()
15:30:41 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.003234723537691576, 'num_filters_1': 45, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.01225814676626343, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 23, 'num_filters_3': 39, 'num_filters_4': 17, 'num_filters_5': 16}, 'budget': 400.0, 'working_directory': '.'}
15:30:54 DISPATCHER: Starting worker discovery
15:30:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:30:54 DISPATCHER: Finished worker discovery
15:31:54 DISPATCHER: Starting worker discovery
15:31:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:31:54 DISPATCHER: Finished worker discovery
15:32:54 DISPATCHER: Starting worker discovery
15:32:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:32:54 DISPATCHER: Finished worker discovery
15:33:54 DISPATCHER: Starting worker discovery
15:33:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:33:54 DISPATCHER: Finished worker discovery
15:34:54 DISPATCHER: Starting worker discovery
15:34:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:34:54 DISPATCHER: Finished worker discovery
15:35:54 DISPATCHER: Starting worker discovery
15:35:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:35:54 DISPATCHER: Finished worker discovery
15:36:54 DISPATCHER: Starting worker discovery
15:36:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:36:54 DISPATCHER: Finished worker discovery
15:37:31 WORKER: done with job (6, 0, 0), trying to register it.
15:37:31 WORKER: registered result for job (6, 0, 0) with dispatcher
15:37:31 DISPATCHER: job (6, 0, 0) finished
15:37:31 DISPATCHER: register_result: lock acquired
15:37:31 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
15:37:31 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.003234723537691576, 'num_filters_1': 45, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.01225814676626343, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 23, 'num_filters_3': 39, 'num_filters_4': 17, 'num_filters_5': 16}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9347610453385373, 'info': {'music-speech': 0.9347610453385373, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.003234723537691576, 'num_filters_1': 45, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.01225814676626343, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 23, 'num_filters_3': 39, 'num_filters_4': 17, 'num_filters_5': 16}"}}
exception: None

15:37:31 job_callback for (6, 0, 0) started
15:37:31 job_callback for (6, 0, 0) got condition
15:37:31 DISPATCHER: Trying to submit another job.
15:37:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:37:31 HBMASTER: Trying to run another job!
15:37:31 job_callback for (6, 0, 0) finished
15:37:31 start sampling a new configuration.
15:37:31 done sampling a new configuration.
15:37:31 HBMASTER: schedule new run for iteration 6
15:37:31 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
15:37:31 HBMASTER: submitting job (6, 0, 1) to dispatcher
15:37:31 DISPATCHER: trying to submit job (6, 0, 1)
15:37:31 DISPATCHER: trying to notify the job_runner thread.
15:37:31 HBMASTER: job (6, 0, 1) submitted to dispatcher
15:37:31 DISPATCHER: Trying to submit another job.
15:37:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:37:31 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
15:37:31 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
15:37:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:37:31 WORKER: start processing job (6, 0, 1)
15:37:31 WORKER: args: ()
15:37:31 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.004002445183509515, 'num_filters_1': 37, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.056887945400899136, 'kernel_size_2': 3, 'num_filters_2': 51}, 'budget': 400.0, 'working_directory': '.'}
15:37:54 DISPATCHER: Starting worker discovery
15:37:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:37:54 DISPATCHER: Finished worker discovery
15:38:54 DISPATCHER: Starting worker discovery
15:38:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:38:54 DISPATCHER: Finished worker discovery
15:39:54 DISPATCHER: Starting worker discovery
15:39:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:39:54 DISPATCHER: Finished worker discovery
15:40:54 DISPATCHER: Starting worker discovery
15:40:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:40:54 DISPATCHER: Finished worker discovery
15:41:54 DISPATCHER: Starting worker discovery
15:41:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:41:54 DISPATCHER: Finished worker discovery
15:42:54 DISPATCHER: Starting worker discovery
15:42:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:42:54 DISPATCHER: Finished worker discovery
15:43:54 DISPATCHER: Starting worker discovery
15:43:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:43:54 DISPATCHER: Finished worker discovery
15:44:20 WORKER: done with job (6, 0, 1), trying to register it.
15:44:20 WORKER: registered result for job (6, 0, 1) with dispatcher
15:44:20 DISPATCHER: job (6, 0, 1) finished
15:44:20 DISPATCHER: register_result: lock acquired
15:44:20 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
15:44:20 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.004002445183509515, 'num_filters_1': 37, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.056887945400899136, 'kernel_size_2': 3, 'num_filters_2': 51}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6385731724078682, 'info': {'music-speech': 0.6385731724078682, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.004002445183509515, 'num_filters_1': 37, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 78, 'weight_decay': 0.056887945400899136, 'kernel_size_2': 3, 'num_filters_2': 51}"}}
exception: None

15:44:20 job_callback for (6, 0, 1) started
15:44:20 job_callback for (6, 0, 1) got condition
15:44:20 DISPATCHER: Trying to submit another job.
15:44:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:44:20 HBMASTER: Trying to run another job!
15:44:20 job_callback for (6, 0, 1) finished
15:44:20 start sampling a new configuration.
15:44:20 done sampling a new configuration.
15:44:20 HBMASTER: schedule new run for iteration 6
15:44:20 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
15:44:20 HBMASTER: submitting job (6, 0, 2) to dispatcher
15:44:20 DISPATCHER: trying to submit job (6, 0, 2)
15:44:20 DISPATCHER: trying to notify the job_runner thread.
15:44:20 HBMASTER: job (6, 0, 2) submitted to dispatcher
15:44:20 DISPATCHER: Trying to submit another job.
15:44:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:44:20 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
15:44:20 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
15:44:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:44:20 WORKER: start processing job (6, 0, 2)
15:44:20 WORKER: args: ()
15:44:20 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003996553346495177, 'num_filters_1': 100, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.03484384264446215, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 55, 'num_filters_3': 34, 'num_filters_4': 49, 'num_filters_5': 25}, 'budget': 400.0, 'working_directory': '.'}
15:44:54 DISPATCHER: Starting worker discovery
15:44:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:44:54 DISPATCHER: Finished worker discovery
15:45:54 DISPATCHER: Starting worker discovery
15:45:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:45:54 DISPATCHER: Finished worker discovery
15:46:54 DISPATCHER: Starting worker discovery
15:46:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:46:54 DISPATCHER: Finished worker discovery
15:47:54 DISPATCHER: Starting worker discovery
15:47:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:47:54 DISPATCHER: Finished worker discovery
15:48:54 DISPATCHER: Starting worker discovery
15:48:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:48:54 DISPATCHER: Finished worker discovery
15:49:54 DISPATCHER: Starting worker discovery
15:49:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:49:54 DISPATCHER: Finished worker discovery
15:50:54 DISPATCHER: Starting worker discovery
15:50:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:50:54 DISPATCHER: Finished worker discovery
15:51:09 WORKER: done with job (6, 0, 2), trying to register it.
15:51:09 WORKER: registered result for job (6, 0, 2) with dispatcher
15:51:09 DISPATCHER: job (6, 0, 2) finished
15:51:09 DISPATCHER: register_result: lock acquired
15:51:09 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
15:51:09 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003996553346495177, 'num_filters_1': 100, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.03484384264446215, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 55, 'num_filters_3': 34, 'num_filters_4': 49, 'num_filters_5': 25}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8799918881741606, 'info': {'music-speech': 0.8799918881741606, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003996553346495177, 'num_filters_1': 100, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.03484384264446215, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 55, 'num_filters_3': 34, 'num_filters_4': 49, 'num_filters_5': 25}"}}
exception: None

15:51:09 job_callback for (6, 0, 2) started
15:51:09 job_callback for (6, 0, 2) got condition
15:51:09 DISPATCHER: Trying to submit another job.
15:51:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:51:09 HBMASTER: Trying to run another job!
15:51:09 job_callback for (6, 0, 2) finished
15:51:09 start sampling a new configuration.
15:51:09 best_vector: [0, 0, 0.592500470112008, 0.0345190754062224, 0.4413823175929509, 0, 0.6181502900259152, 0.5476850623146717, 1, 1, 2, 1, 0.5918651996231339, 0.8183245935788014, 0.6300918442567833, 0.13625796645806548], 2.095789478543544e-28, 4.771471611237136e-05, -3.065477808284806e-05
15:51:09 done sampling a new configuration.
15:51:09 HBMASTER: schedule new run for iteration 6
15:51:09 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
15:51:09 HBMASTER: submitting job (6, 0, 3) to dispatcher
15:51:09 DISPATCHER: trying to submit job (6, 0, 3)
15:51:09 DISPATCHER: trying to notify the job_runner thread.
15:51:09 HBMASTER: job (6, 0, 3) submitted to dispatcher
15:51:09 DISPATCHER: Trying to submit another job.
15:51:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:51:09 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
15:51:09 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
15:51:09 WORKER: start processing job (6, 0, 3)
15:51:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:51:09 WORKER: args: ()
15:51:09 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.015310907764069947, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.05158871308580484, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 54, 'num_filters_3': 88}, 'budget': 400.0, 'working_directory': '.'}
15:51:54 DISPATCHER: Starting worker discovery
15:51:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:51:54 DISPATCHER: Finished worker discovery
15:52:54 DISPATCHER: Starting worker discovery
15:52:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:52:54 DISPATCHER: Finished worker discovery
15:53:54 DISPATCHER: Starting worker discovery
15:53:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:53:54 DISPATCHER: Finished worker discovery
15:54:54 DISPATCHER: Starting worker discovery
15:54:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:54:54 DISPATCHER: Finished worker discovery
15:55:54 DISPATCHER: Starting worker discovery
15:55:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:55:54 DISPATCHER: Finished worker discovery
15:56:54 DISPATCHER: Starting worker discovery
15:56:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:56:54 DISPATCHER: Finished worker discovery
15:57:54 DISPATCHER: Starting worker discovery
15:57:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:57:54 DISPATCHER: Finished worker discovery
15:57:59 WORKER: done with job (6, 0, 3), trying to register it.
15:57:59 WORKER: registered result for job (6, 0, 3) with dispatcher
15:57:59 DISPATCHER: job (6, 0, 3) finished
15:57:59 DISPATCHER: register_result: lock acquired
15:57:59 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
15:57:59 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.015310907764069947, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.05158871308580484, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 54, 'num_filters_3': 88}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9004068514473993, 'info': {'music-speech': 0.9004068514473993, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.015310907764069947, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.05158871308580484, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 54, 'num_filters_3': 88}"}}
exception: None

15:57:59 job_callback for (6, 0, 3) started
15:57:59 DISPATCHER: Trying to submit another job.
15:57:59 job_callback for (6, 0, 3) got condition
15:57:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:57:59 HBMASTER: Trying to run another job!
15:57:59 job_callback for (6, 0, 3) finished
15:57:59 start sampling a new configuration.
15:57:59 best_vector: [1, 0, 0.28427789047336993, 0.2669764393397334, 0.7958416825510984, 0, 0.33775718713485686, 0.26776677550558425, 0, 1, 1, 0, 0.2449191735482934, 0.45123690207685685, 0.22863635435836413, 0.03369821474379975], 4.3590167193215196e-29, 0.00022940953531273676, -7.873282672032508e-05
15:57:59 done sampling a new configuration.
15:57:59 HBMASTER: schedule new run for iteration 6
15:57:59 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
15:57:59 HBMASTER: submitting job (6, 0, 4) to dispatcher
15:57:59 DISPATCHER: trying to submit job (6, 0, 4)
15:57:59 DISPATCHER: trying to notify the job_runner thread.
15:57:59 HBMASTER: job (6, 0, 4) submitted to dispatcher
15:57:59 DISPATCHER: Trying to submit another job.
15:57:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:57:59 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
15:57:59 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
15:57:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:57:59 WORKER: start processing job (6, 0, 4)
15:57:59 WORKER: args: ()
15:57:59 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0037030176404381355, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.022303478752321245, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 26, 'num_filters_3': 40, 'num_filters_4': 25}, 'budget': 400.0, 'working_directory': '.'}
15:58:54 DISPATCHER: Starting worker discovery
15:58:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:58:54 DISPATCHER: Finished worker discovery
15:59:54 DISPATCHER: Starting worker discovery
15:59:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:59:54 DISPATCHER: Finished worker discovery
16:00:54 DISPATCHER: Starting worker discovery
16:00:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:00:54 DISPATCHER: Finished worker discovery
16:01:54 DISPATCHER: Starting worker discovery
16:01:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:01:54 DISPATCHER: Finished worker discovery
16:02:54 DISPATCHER: Starting worker discovery
16:02:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:02:54 DISPATCHER: Finished worker discovery
16:03:54 DISPATCHER: Starting worker discovery
16:03:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:03:54 DISPATCHER: Finished worker discovery
16:04:48 WORKER: done with job (6, 0, 4), trying to register it.
16:04:48 WORKER: registered result for job (6, 0, 4) with dispatcher
16:04:48 DISPATCHER: job (6, 0, 4) finished
16:04:48 DISPATCHER: register_result: lock acquired
16:04:48 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
16:04:48 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0037030176404381355, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.022303478752321245, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 26, 'num_filters_3': 40, 'num_filters_4': 25}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8755202601586836, 'info': {'music-speech': 0.8755202601586836, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0037030176404381355, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.022303478752321245, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 26, 'num_filters_3': 40, 'num_filters_4': 25}"}}
exception: None

16:04:48 job_callback for (6, 0, 4) started
16:04:48 job_callback for (6, 0, 4) got condition
16:04:48 DISPATCHER: Trying to submit another job.
16:04:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:04:48 HBMASTER: Trying to run another job!
16:04:48 job_callback for (6, 0, 4) finished
16:04:48 start sampling a new configuration.
16:04:48 done sampling a new configuration.
16:04:48 HBMASTER: schedule new run for iteration 6
16:04:48 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
16:04:48 HBMASTER: submitting job (6, 0, 5) to dispatcher
16:04:48 DISPATCHER: trying to submit job (6, 0, 5)
16:04:48 DISPATCHER: trying to notify the job_runner thread.
16:04:48 HBMASTER: job (6, 0, 5) submitted to dispatcher
16:04:48 DISPATCHER: Trying to submit another job.
16:04:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:04:48 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
16:04:48 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
16:04:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:04:48 WORKER: start processing job (6, 0, 5)
16:04:48 WORKER: args: ()
16:04:48 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.009601446625763961, 'num_filters_1': 83, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.013326895743533903, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 89, 'num_filters_3': 21, 'num_filters_4': 114, 'num_filters_5': 25}, 'budget': 400.0, 'working_directory': '.'}
16:04:54 DISPATCHER: Starting worker discovery
16:04:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:04:54 DISPATCHER: Finished worker discovery
16:05:54 DISPATCHER: Starting worker discovery
16:05:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:05:55 DISPATCHER: Finished worker discovery
16:06:55 DISPATCHER: Starting worker discovery
16:06:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:06:55 DISPATCHER: Finished worker discovery
16:07:55 DISPATCHER: Starting worker discovery
16:07:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:07:55 DISPATCHER: Finished worker discovery
16:08:55 DISPATCHER: Starting worker discovery
16:08:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:08:55 DISPATCHER: Finished worker discovery
16:09:55 DISPATCHER: Starting worker discovery
16:09:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:09:55 DISPATCHER: Finished worker discovery
16:10:55 DISPATCHER: Starting worker discovery
16:10:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:10:55 DISPATCHER: Finished worker discovery
16:11:37 WORKER: done with job (6, 0, 5), trying to register it.
16:11:37 DISPATCHER: job (6, 0, 5) finished
16:11:37 WORKER: registered result for job (6, 0, 5) with dispatcher
16:11:37 DISPATCHER: register_result: lock acquired
16:11:37 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
16:11:37 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.009601446625763961, 'num_filters_1': 83, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.013326895743533903, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 89, 'num_filters_3': 21, 'num_filters_4': 114, 'num_filters_5': 25}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8972724607348862, 'info': {'music-speech': 0.8972724607348862, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.009601446625763961, 'num_filters_1': 83, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.013326895743533903, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 89, 'num_filters_3': 21, 'num_filters_4': 114, 'num_filters_5': 25}"}}
exception: None

16:11:37 job_callback for (6, 0, 5) started
16:11:37 job_callback for (6, 0, 5) got condition
16:11:37 DISPATCHER: Trying to submit another job.
16:11:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:11:37 HBMASTER: Trying to run another job!
16:11:37 job_callback for (6, 0, 5) finished
16:11:37 ITERATION: Advancing config (6, 0, 0) to next budget 1200.000000
16:11:37 ITERATION: Advancing config (6, 0, 3) to next budget 1200.000000
16:11:37 HBMASTER: schedule new run for iteration 6
16:11:37 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
16:11:37 HBMASTER: submitting job (6, 0, 0) to dispatcher
16:11:37 DISPATCHER: trying to submit job (6, 0, 0)
16:11:37 DISPATCHER: trying to notify the job_runner thread.
16:11:37 HBMASTER: job (6, 0, 0) submitted to dispatcher
16:11:37 DISPATCHER: Trying to submit another job.
16:11:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:11:37 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
16:11:37 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
16:11:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:11:37 WORKER: start processing job (6, 0, 0)
16:11:37 WORKER: args: ()
16:11:37 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.003234723537691576, 'num_filters_1': 45, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.01225814676626343, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 23, 'num_filters_3': 39, 'num_filters_4': 17, 'num_filters_5': 16}, 'budget': 1200.0, 'working_directory': '.'}
16:11:55 DISPATCHER: Starting worker discovery
16:11:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:11:55 DISPATCHER: Finished worker discovery
16:12:55 DISPATCHER: Starting worker discovery
16:12:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:12:55 DISPATCHER: Finished worker discovery
16:13:55 DISPATCHER: Starting worker discovery
16:13:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:13:55 DISPATCHER: Finished worker discovery
16:14:55 DISPATCHER: Starting worker discovery
16:14:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:14:55 DISPATCHER: Finished worker discovery
16:15:55 DISPATCHER: Starting worker discovery
16:15:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:15:55 DISPATCHER: Finished worker discovery
16:16:55 DISPATCHER: Starting worker discovery
16:16:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:16:55 DISPATCHER: Finished worker discovery
16:17:55 DISPATCHER: Starting worker discovery
16:17:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:17:55 DISPATCHER: Finished worker discovery
16:18:55 DISPATCHER: Starting worker discovery
16:18:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:18:55 DISPATCHER: Finished worker discovery
16:19:55 DISPATCHER: Starting worker discovery
16:19:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:19:55 DISPATCHER: Finished worker discovery
16:20:55 DISPATCHER: Starting worker discovery
16:20:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:20:55 DISPATCHER: Finished worker discovery
16:21:55 DISPATCHER: Starting worker discovery
16:21:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:21:55 DISPATCHER: Finished worker discovery
16:22:55 DISPATCHER: Starting worker discovery
16:22:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:22:55 DISPATCHER: Finished worker discovery
16:23:55 DISPATCHER: Starting worker discovery
16:23:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:23:55 DISPATCHER: Finished worker discovery
16:24:55 DISPATCHER: Starting worker discovery
16:24:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:24:55 DISPATCHER: Finished worker discovery
16:25:55 DISPATCHER: Starting worker discovery
16:25:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:25:55 DISPATCHER: Finished worker discovery
16:26:55 DISPATCHER: Starting worker discovery
16:26:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:26:55 DISPATCHER: Finished worker discovery
16:27:55 DISPATCHER: Starting worker discovery
16:27:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:27:55 DISPATCHER: Finished worker discovery
16:28:55 DISPATCHER: Starting worker discovery
16:28:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:28:55 DISPATCHER: Finished worker discovery
16:29:55 DISPATCHER: Starting worker discovery
16:29:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:29:55 DISPATCHER: Finished worker discovery
16:30:55 DISPATCHER: Starting worker discovery
16:30:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:30:55 DISPATCHER: Finished worker discovery
16:31:47 WORKER: done with job (6, 0, 0), trying to register it.
16:31:47 WORKER: registered result for job (6, 0, 0) with dispatcher
16:31:47 DISPATCHER: job (6, 0, 0) finished
16:31:47 DISPATCHER: register_result: lock acquired
16:31:47 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
16:31:47 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.003234723537691576, 'num_filters_1': 45, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.01225814676626343, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 23, 'num_filters_3': 39, 'num_filters_4': 17, 'num_filters_5': 16}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9537714146892162, 'info': {'music-speech': 0.9537714146892162, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.003234723537691576, 'num_filters_1': 45, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.01225814676626343, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 23, 'num_filters_3': 39, 'num_filters_4': 17, 'num_filters_5': 16}"}}
exception: None

16:31:47 job_callback for (6, 0, 0) started
16:31:47 DISPATCHER: Trying to submit another job.
16:31:47 job_callback for (6, 0, 0) got condition
16:31:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:31:47 Only 11 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
16:31:47 HBMASTER: Trying to run another job!
16:31:47 job_callback for (6, 0, 0) finished
16:31:47 HBMASTER: schedule new run for iteration 6
16:31:47 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
16:31:47 HBMASTER: submitting job (6, 0, 3) to dispatcher
16:31:47 DISPATCHER: trying to submit job (6, 0, 3)
16:31:47 DISPATCHER: trying to notify the job_runner thread.
16:31:47 HBMASTER: job (6, 0, 3) submitted to dispatcher
16:31:47 DISPATCHER: Trying to submit another job.
16:31:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:31:47 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
16:31:47 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
16:31:47 WORKER: start processing job (6, 0, 3)
16:31:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:31:47 WORKER: args: ()
16:31:47 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.015310907764069947, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.05158871308580484, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 54, 'num_filters_3': 88}, 'budget': 1200.0, 'working_directory': '.'}
16:31:55 DISPATCHER: Starting worker discovery
16:31:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:31:55 DISPATCHER: Finished worker discovery
16:32:55 DISPATCHER: Starting worker discovery
16:32:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:32:55 DISPATCHER: Finished worker discovery
16:33:55 DISPATCHER: Starting worker discovery
16:33:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:33:55 DISPATCHER: Finished worker discovery
16:34:55 DISPATCHER: Starting worker discovery
16:34:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:34:55 DISPATCHER: Finished worker discovery
16:35:55 DISPATCHER: Starting worker discovery
16:35:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:35:55 DISPATCHER: Finished worker discovery
16:36:55 DISPATCHER: Starting worker discovery
16:36:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:36:55 DISPATCHER: Finished worker discovery
16:37:55 DISPATCHER: Starting worker discovery
16:37:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:37:55 DISPATCHER: Finished worker discovery
16:38:55 DISPATCHER: Starting worker discovery
16:38:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:38:55 DISPATCHER: Finished worker discovery
16:39:55 DISPATCHER: Starting worker discovery
16:39:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:39:55 DISPATCHER: Finished worker discovery
16:40:55 DISPATCHER: Starting worker discovery
16:40:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:40:55 DISPATCHER: Finished worker discovery
16:41:55 DISPATCHER: Starting worker discovery
16:41:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:41:55 DISPATCHER: Finished worker discovery
16:42:55 DISPATCHER: Starting worker discovery
16:42:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:42:55 DISPATCHER: Finished worker discovery
16:43:55 DISPATCHER: Starting worker discovery
16:43:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:43:55 DISPATCHER: Finished worker discovery
16:44:55 DISPATCHER: Starting worker discovery
16:44:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:44:55 DISPATCHER: Finished worker discovery
16:45:55 DISPATCHER: Starting worker discovery
16:45:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:45:55 DISPATCHER: Finished worker discovery
16:46:55 DISPATCHER: Starting worker discovery
16:46:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:46:55 DISPATCHER: Finished worker discovery
16:47:55 DISPATCHER: Starting worker discovery
16:47:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:47:55 DISPATCHER: Finished worker discovery
16:48:55 DISPATCHER: Starting worker discovery
16:48:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:48:55 DISPATCHER: Finished worker discovery
16:49:55 DISPATCHER: Starting worker discovery
16:49:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:49:55 DISPATCHER: Finished worker discovery
16:50:55 DISPATCHER: Starting worker discovery
16:50:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:50:55 DISPATCHER: Finished worker discovery
16:51:55 DISPATCHER: Starting worker discovery
16:51:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:51:55 DISPATCHER: Finished worker discovery
16:51:57 WORKER: done with job (6, 0, 3), trying to register it.
16:51:57 WORKER: registered result for job (6, 0, 3) with dispatcher
16:51:57 DISPATCHER: job (6, 0, 3) finished
16:51:57 DISPATCHER: register_result: lock acquired
16:51:57 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
16:51:57 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.015310907764069947, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.05158871308580484, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 54, 'num_filters_3': 88}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.7823336657105044, 'info': {'music-speech': 0.7823336657105044, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.015310907764069947, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 66, 'weight_decay': 0.05158871308580484, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 54, 'num_filters_3': 88}"}}
exception: None

16:51:57 job_callback for (6, 0, 3) started
16:51:57 DISPATCHER: Trying to submit another job.
16:51:57 job_callback for (6, 0, 3) got condition
16:51:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:51:57 Only 12 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
16:51:57 HBMASTER: Trying to run another job!
16:51:57 job_callback for (6, 0, 3) finished
16:51:57 start sampling a new configuration.
16:51:57 best_vector: [3, 0, 0.1782673226462436, 0.3579544452593016, 0.07146999544966581, 0, 0.4910396830921153, 0.02401356482225092, 1, 0, 0, 0, 0.8558658696716264, 0.43540906057540907, 0.25723760476061575, 0.18365744728432065], 2.1988428966177206e-29, 0.00045478465129919417, -7.900480054394537e-07
16:51:57 done sampling a new configuration.
16:51:57 HBMASTER: schedule new run for iteration 7
16:51:57 HBMASTER: trying submitting job (7, 0, 0) to dispatcher
16:51:57 HBMASTER: submitting job (7, 0, 0) to dispatcher
16:51:57 DISPATCHER: trying to submit job (7, 0, 0)
16:51:57 DISPATCHER: trying to notify the job_runner thread.
16:51:57 HBMASTER: job (7, 0, 0) submitted to dispatcher
16:51:57 DISPATCHER: Trying to submit another job.
16:51:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:51:57 DISPATCHER: starting job (7, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
16:51:57 DISPATCHER: job (7, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
16:51:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:51:57 WORKER: start processing job (7, 0, 0)
16:51:57 WORKER: args: ()
16:51:57 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.002272660926687893, 'num_filters_1': 33, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.010745889443877924}, 'budget': 1200.0, 'working_directory': '.'}
16:52:55 DISPATCHER: Starting worker discovery
16:52:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:52:55 DISPATCHER: Finished worker discovery
16:53:55 DISPATCHER: Starting worker discovery
16:53:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:53:55 DISPATCHER: Finished worker discovery
16:54:55 DISPATCHER: Starting worker discovery
16:54:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:54:55 DISPATCHER: Finished worker discovery
16:55:55 DISPATCHER: Starting worker discovery
16:55:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:55:55 DISPATCHER: Finished worker discovery
16:56:55 DISPATCHER: Starting worker discovery
16:56:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:56:55 DISPATCHER: Finished worker discovery
16:57:55 DISPATCHER: Starting worker discovery
16:57:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:57:55 DISPATCHER: Finished worker discovery
16:58:55 DISPATCHER: Starting worker discovery
16:58:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:58:55 DISPATCHER: Finished worker discovery
16:59:55 DISPATCHER: Starting worker discovery
16:59:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:59:55 DISPATCHER: Finished worker discovery
17:00:55 DISPATCHER: Starting worker discovery
17:00:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:00:55 DISPATCHER: Finished worker discovery
17:01:55 DISPATCHER: Starting worker discovery
17:01:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:01:55 DISPATCHER: Finished worker discovery
17:02:55 DISPATCHER: Starting worker discovery
17:02:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:02:55 DISPATCHER: Finished worker discovery
17:03:55 DISPATCHER: Starting worker discovery
17:03:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:03:55 DISPATCHER: Finished worker discovery
17:04:55 DISPATCHER: Starting worker discovery
17:04:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:04:55 DISPATCHER: Finished worker discovery
17:05:55 DISPATCHER: Starting worker discovery
17:05:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:05:55 DISPATCHER: Finished worker discovery
17:06:55 DISPATCHER: Starting worker discovery
17:06:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:06:55 DISPATCHER: Finished worker discovery
17:07:55 DISPATCHER: Starting worker discovery
17:07:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:07:55 DISPATCHER: Finished worker discovery
17:08:55 DISPATCHER: Starting worker discovery
17:08:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:08:55 DISPATCHER: Finished worker discovery
17:09:55 DISPATCHER: Starting worker discovery
17:09:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:09:55 DISPATCHER: Finished worker discovery
17:10:55 DISPATCHER: Starting worker discovery
17:10:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:10:55 DISPATCHER: Finished worker discovery
17:11:55 DISPATCHER: Starting worker discovery
17:11:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:11:55 DISPATCHER: Finished worker discovery
17:12:06 WORKER: done with job (7, 0, 0), trying to register it.
17:12:06 WORKER: registered result for job (7, 0, 0) with dispatcher
17:12:06 DISPATCHER: job (7, 0, 0) finished
17:12:06 DISPATCHER: register_result: lock acquired
17:12:06 DISPATCHER: job (7, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
17:12:06 job_id: (7, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.002272660926687893, 'num_filters_1': 33, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.010745889443877924}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5778899097282748, 'info': {'music-speech': 0.5778899097282748, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.002272660926687893, 'num_filters_1': 33, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 54, 'weight_decay': 0.010745889443877924}"}}
exception: None

17:12:06 job_callback for (7, 0, 0) started
17:12:06 DISPATCHER: Trying to submit another job.
17:12:06 job_callback for (7, 0, 0) got condition
17:12:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:12:07 Only 13 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
17:12:07 HBMASTER: Trying to run another job!
17:12:07 job_callback for (7, 0, 0) finished
17:12:07 start sampling a new configuration.
17:12:07 best_vector: [1, 2, 0.16398460354590155, 0.07306451836559025, 0.9712285781714911, 0, 0.26436309802478997, 0.19653751140923148, 1, 1, 1, 0, 0.30376992040151296, 0.09213976161717582, 0.4578130023496364, 0.17301577214987152], 2.0442429160212944e-28, 4.8917865492536376e-05, -9.204143241442506e-06
17:12:07 done sampling a new configuration.
17:12:07 HBMASTER: schedule new run for iteration 7
17:12:07 HBMASTER: trying submitting job (7, 0, 1) to dispatcher
17:12:07 HBMASTER: submitting job (7, 0, 1) to dispatcher
17:12:07 DISPATCHER: trying to submit job (7, 0, 1)
17:12:07 DISPATCHER: trying to notify the job_runner thread.
17:12:07 HBMASTER: job (7, 0, 1) submitted to dispatcher
17:12:07 DISPATCHER: Trying to submit another job.
17:12:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:12:07 DISPATCHER: starting job (7, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
17:12:07 DISPATCHER: job (7, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
17:12:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:12:07 WORKER: start processing job (7, 0, 1)
17:12:07 WORKER: args: ()
17:12:07 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002127988159269075, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.01801777659003043, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 29, 'num_filters_3': 19, 'num_filters_4': 41, 'num_filters_5': 22}, 'budget': 1200.0, 'working_directory': '.'}
17:12:55 DISPATCHER: Starting worker discovery
17:12:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:12:55 DISPATCHER: Finished worker discovery
17:13:55 DISPATCHER: Starting worker discovery
17:13:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:13:55 DISPATCHER: Finished worker discovery
17:14:55 DISPATCHER: Starting worker discovery
17:14:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:14:55 DISPATCHER: Finished worker discovery
17:15:55 DISPATCHER: Starting worker discovery
17:15:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:15:55 DISPATCHER: Finished worker discovery
17:16:55 DISPATCHER: Starting worker discovery
17:16:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:16:55 DISPATCHER: Finished worker discovery
17:17:55 DISPATCHER: Starting worker discovery
17:17:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:17:55 DISPATCHER: Finished worker discovery
17:18:55 DISPATCHER: Starting worker discovery
17:18:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:18:55 DISPATCHER: Finished worker discovery
17:19:55 DISPATCHER: Starting worker discovery
17:19:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:19:55 DISPATCHER: Finished worker discovery
17:20:55 DISPATCHER: Starting worker discovery
17:20:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:20:56 DISPATCHER: Finished worker discovery
17:21:56 DISPATCHER: Starting worker discovery
17:21:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:21:56 DISPATCHER: Finished worker discovery
17:22:56 DISPATCHER: Starting worker discovery
17:22:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:22:56 DISPATCHER: Finished worker discovery
17:23:56 DISPATCHER: Starting worker discovery
17:23:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:23:56 DISPATCHER: Finished worker discovery
17:24:56 DISPATCHER: Starting worker discovery
17:24:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:24:56 DISPATCHER: Finished worker discovery
17:25:56 DISPATCHER: Starting worker discovery
17:25:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:25:56 DISPATCHER: Finished worker discovery
17:26:56 DISPATCHER: Starting worker discovery
17:26:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:26:56 DISPATCHER: Finished worker discovery
17:27:56 DISPATCHER: Starting worker discovery
17:27:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:27:56 DISPATCHER: Finished worker discovery
17:28:56 DISPATCHER: Starting worker discovery
17:28:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:28:56 DISPATCHER: Finished worker discovery
17:29:56 DISPATCHER: Starting worker discovery
17:29:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:29:56 DISPATCHER: Finished worker discovery
17:30:56 DISPATCHER: Starting worker discovery
17:30:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:30:56 DISPATCHER: Finished worker discovery
17:31:56 DISPATCHER: Starting worker discovery
17:31:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:31:56 DISPATCHER: Finished worker discovery
17:32:17 WORKER: done with job (7, 0, 1), trying to register it.
17:32:17 DISPATCHER: job (7, 0, 1) finished
17:32:17 WORKER: registered result for job (7, 0, 1) with dispatcher
17:32:17 DISPATCHER: register_result: lock acquired
17:32:17 DISPATCHER: job (7, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
17:32:17 job_id: (7, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002127988159269075, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.01801777659003043, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 29, 'num_filters_3': 19, 'num_filters_4': 41, 'num_filters_5': 22}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9695144660706386, 'info': {'music-speech': 0.9695144660706386, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.002127988159269075, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.01801777659003043, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 29, 'num_filters_3': 19, 'num_filters_4': 41, 'num_filters_5': 22}"}}
exception: None

17:32:17 job_callback for (7, 0, 1) started
17:32:17 DISPATCHER: Trying to submit another job.
17:32:17 job_callback for (7, 0, 1) got condition
17:32:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:32:17 Only 14 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
17:32:17 HBMASTER: Trying to run another job!
17:32:17 job_callback for (7, 0, 1) finished
17:32:17 start sampling a new configuration.
17:32:17 done sampling a new configuration.
17:32:17 HBMASTER: schedule new run for iteration 7
17:32:17 HBMASTER: trying submitting job (7, 0, 2) to dispatcher
17:32:17 HBMASTER: submitting job (7, 0, 2) to dispatcher
17:32:17 DISPATCHER: trying to submit job (7, 0, 2)
17:32:17 DISPATCHER: trying to notify the job_runner thread.
17:32:17 HBMASTER: job (7, 0, 2) submitted to dispatcher
17:32:17 DISPATCHER: Trying to submit another job.
17:32:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:32:17 DISPATCHER: starting job (7, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
17:32:17 DISPATCHER: job (7, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
17:32:17 WORKER: start processing job (7, 0, 2)
17:32:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:32:17 WORKER: args: ()
17:32:17 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.015029061825941352, 'num_filters_1': 119, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.0707940807156156}, 'budget': 1200.0, 'working_directory': '.'}
17:32:56 DISPATCHER: Starting worker discovery
17:32:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:32:56 DISPATCHER: Finished worker discovery
17:33:56 DISPATCHER: Starting worker discovery
17:33:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:33:56 DISPATCHER: Finished worker discovery
17:34:56 DISPATCHER: Starting worker discovery
17:34:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:34:56 DISPATCHER: Finished worker discovery
17:35:56 DISPATCHER: Starting worker discovery
17:35:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:35:56 DISPATCHER: Finished worker discovery
17:36:56 DISPATCHER: Starting worker discovery
17:36:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:36:56 DISPATCHER: Finished worker discovery
17:37:56 DISPATCHER: Starting worker discovery
17:37:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:37:56 DISPATCHER: Finished worker discovery
17:38:56 DISPATCHER: Starting worker discovery
17:38:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:38:56 DISPATCHER: Finished worker discovery
17:39:56 DISPATCHER: Starting worker discovery
17:39:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:39:56 DISPATCHER: Finished worker discovery
17:40:56 DISPATCHER: Starting worker discovery
17:40:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:40:56 DISPATCHER: Finished worker discovery
17:41:56 DISPATCHER: Starting worker discovery
17:41:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:41:56 DISPATCHER: Finished worker discovery
17:42:56 DISPATCHER: Starting worker discovery
17:42:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:42:56 DISPATCHER: Finished worker discovery
17:43:56 DISPATCHER: Starting worker discovery
17:43:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:43:56 DISPATCHER: Finished worker discovery
17:44:56 DISPATCHER: Starting worker discovery
17:44:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:44:56 DISPATCHER: Finished worker discovery
17:45:56 DISPATCHER: Starting worker discovery
17:45:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:45:56 DISPATCHER: Finished worker discovery
17:46:56 DISPATCHER: Starting worker discovery
17:46:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:46:56 DISPATCHER: Finished worker discovery
17:47:56 DISPATCHER: Starting worker discovery
17:47:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:47:56 DISPATCHER: Finished worker discovery
17:48:56 DISPATCHER: Starting worker discovery
17:48:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:48:56 DISPATCHER: Finished worker discovery
17:49:56 DISPATCHER: Starting worker discovery
17:49:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:49:56 DISPATCHER: Finished worker discovery
17:50:56 DISPATCHER: Starting worker discovery
17:50:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:50:56 DISPATCHER: Finished worker discovery
17:51:56 DISPATCHER: Starting worker discovery
17:51:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:51:56 DISPATCHER: Finished worker discovery
17:52:28 WORKER: done with job (7, 0, 2), trying to register it.
17:52:28 DISPATCHER: job (7, 0, 2) finished
17:52:28 WORKER: registered result for job (7, 0, 2) with dispatcher
17:52:28 DISPATCHER: register_result: lock acquired
17:52:28 DISPATCHER: job (7, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
17:52:28 job_id: (7, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.015029061825941352, 'num_filters_1': 119, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.0707940807156156}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.485613309491691, 'info': {'music-speech': 0.485613309491691, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.015029061825941352, 'num_filters_1': 119, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.0707940807156156}"}}
exception: None

17:52:28 job_callback for (7, 0, 2) started
17:52:28 DISPATCHER: Trying to submit another job.
17:52:28 job_callback for (7, 0, 2) got condition
17:52:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:52:28 Only 15 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
17:52:28 HBMASTER: Trying to run another job!
17:52:28 job_callback for (7, 0, 2) finished
17:52:28 start sampling a new configuration.
17:52:28 done sampling a new configuration.
17:52:28 HBMASTER: schedule new run for iteration 7
17:52:28 HBMASTER: trying submitting job (7, 0, 3) to dispatcher
17:52:28 HBMASTER: submitting job (7, 0, 3) to dispatcher
17:52:28 DISPATCHER: trying to submit job (7, 0, 3)
17:52:28 DISPATCHER: trying to notify the job_runner thread.
17:52:28 HBMASTER: job (7, 0, 3) submitted to dispatcher
17:52:28 DISPATCHER: Trying to submit another job.
17:52:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:52:28 DISPATCHER: starting job (7, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
17:52:28 DISPATCHER: job (7, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
17:52:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:52:28 WORKER: start processing job (7, 0, 3)
17:52:28 WORKER: args: ()
17:52:28 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001991153961360117, 'num_filters_1': 112, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.17715021842680953, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 74, 'num_filters_3': 26}, 'budget': 1200.0, 'working_directory': '.'}
17:52:56 DISPATCHER: Starting worker discovery
17:52:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:52:56 DISPATCHER: Finished worker discovery
17:53:56 DISPATCHER: Starting worker discovery
17:53:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:53:56 DISPATCHER: Finished worker discovery
17:54:56 DISPATCHER: Starting worker discovery
17:54:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:54:56 DISPATCHER: Finished worker discovery
17:55:56 DISPATCHER: Starting worker discovery
17:55:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:55:56 DISPATCHER: Finished worker discovery
17:56:56 DISPATCHER: Starting worker discovery
17:56:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:56:56 DISPATCHER: Finished worker discovery
17:57:56 DISPATCHER: Starting worker discovery
17:57:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:57:56 DISPATCHER: Finished worker discovery
17:58:56 DISPATCHER: Starting worker discovery
17:58:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:58:56 DISPATCHER: Finished worker discovery
17:59:56 DISPATCHER: Starting worker discovery
17:59:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:59:56 DISPATCHER: Finished worker discovery
18:00:56 DISPATCHER: Starting worker discovery
18:00:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:00:56 DISPATCHER: Finished worker discovery
18:01:56 DISPATCHER: Starting worker discovery
18:01:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:01:56 DISPATCHER: Finished worker discovery
18:02:56 DISPATCHER: Starting worker discovery
18:02:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:02:56 DISPATCHER: Finished worker discovery
18:03:56 DISPATCHER: Starting worker discovery
18:03:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:03:56 DISPATCHER: Finished worker discovery
18:04:56 DISPATCHER: Starting worker discovery
18:04:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:04:56 DISPATCHER: Finished worker discovery
18:05:56 DISPATCHER: Starting worker discovery
18:05:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:05:56 DISPATCHER: Finished worker discovery
18:06:56 DISPATCHER: Starting worker discovery
18:06:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:06:56 DISPATCHER: Finished worker discovery
18:07:56 DISPATCHER: Starting worker discovery
18:07:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:07:56 DISPATCHER: Finished worker discovery
18:08:56 DISPATCHER: Starting worker discovery
18:08:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:08:56 DISPATCHER: Finished worker discovery
18:09:56 DISPATCHER: Starting worker discovery
18:09:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:09:56 DISPATCHER: Finished worker discovery
18:10:56 DISPATCHER: Starting worker discovery
18:10:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:10:56 DISPATCHER: Finished worker discovery
18:11:56 DISPATCHER: Starting worker discovery
18:11:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:11:56 DISPATCHER: Finished worker discovery
18:12:38 WORKER: done with job (7, 0, 3), trying to register it.
18:12:38 WORKER: registered result for job (7, 0, 3) with dispatcher
18:12:38 DISPATCHER: job (7, 0, 3) finished
18:12:38 DISPATCHER: register_result: lock acquired
18:12:38 DISPATCHER: job (7, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:12:38 job_id: (7, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001991153961360117, 'num_filters_1': 112, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.17715021842680953, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 74, 'num_filters_3': 26}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.8506233579984015, 'info': {'music-speech': 0.8506233579984015, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001991153961360117, 'num_filters_1': 112, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.17715021842680953, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 74, 'num_filters_3': 26}"}}
exception: None

18:12:38 job_callback for (7, 0, 3) started
18:12:38 DISPATCHER: Trying to submit another job.
18:12:38 job_callback for (7, 0, 3) got condition
18:12:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:12:38 Only 16 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
18:12:38 HBMASTER: Trying to run another job!
18:12:38 job_callback for (7, 0, 3) finished
18:12:38 start sampling a new configuration.
18:12:38 done sampling a new configuration.
18:12:38 HBMASTER: schedule new run for iteration 8
18:12:38 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
18:12:38 HBMASTER: submitting job (8, 0, 0) to dispatcher
18:12:38 DISPATCHER: trying to submit job (8, 0, 0)
18:12:38 DISPATCHER: trying to notify the job_runner thread.
18:12:38 HBMASTER: job (8, 0, 0) submitted to dispatcher
18:12:38 DISPATCHER: Trying to submit another job.
18:12:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:12:38 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:12:38 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:12:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:12:38 WORKER: start processing job (8, 0, 0)
18:12:38 WORKER: args: ()
18:12:38 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.006304489561433158, 'num_filters_1': 42, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.17690457043262725, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 37, 'num_filters_3': 36, 'num_filters_4': 51, 'num_filters_5': 81}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:12:56 DISPATCHER: Starting worker discovery
18:12:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:12:56 DISPATCHER: Finished worker discovery
18:13:31 WORKER: done with job (8, 0, 0), trying to register it.
18:13:31 DISPATCHER: job (8, 0, 0) finished
18:13:31 WORKER: registered result for job (8, 0, 0) with dispatcher
18:13:31 DISPATCHER: register_result: lock acquired
18:13:31 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:13:31 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.006304489561433158, 'num_filters_1': 42, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.17690457043262725, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 37, 'num_filters_3': 36, 'num_filters_4': 51, 'num_filters_5': 81}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8112187296928051, 'info': {'music-speech': 0.8112187296928051, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.006304489561433158, 'num_filters_1': 42, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.17690457043262725, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 37, 'num_filters_3': 36, 'num_filters_4': 51, 'num_filters_5': 81}"}}
exception: None

18:13:31 job_callback for (8, 0, 0) started
18:13:31 DISPATCHER: Trying to submit another job.
18:13:31 job_callback for (8, 0, 0) got condition
18:13:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:13:31 HBMASTER: Trying to run another job!
18:13:31 job_callback for (8, 0, 0) finished
18:13:31 start sampling a new configuration.
18:13:32 best_vector: [1, 1, 0.7023086795740958, 0.7102494270459758, 0.3219706920182756, 0, 0.8272693406914751, 0.3313344601918029, 2, 0, 1, 1, 0.8626981950373478, 0.9820150225852631, 0.2857462610664505, 0.9471576840932019], 6.718668080081598e-26, 1.488390240566632e-07, -2.10013146932156e-09
18:13:32 done sampling a new configuration.
18:13:32 HBMASTER: schedule new run for iteration 8
18:13:32 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
18:13:32 HBMASTER: submitting job (8, 0, 1) to dispatcher
18:13:32 DISPATCHER: trying to submit job (8, 0, 1)
18:13:32 DISPATCHER: trying to notify the job_runner thread.
18:13:32 HBMASTER: job (8, 0, 1) submitted to dispatcher
18:13:32 DISPATCHER: Trying to submit another job.
18:13:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:13:32 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:13:32 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:13:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:13:32 WORKER: start processing job (8, 0, 1)
18:13:32 WORKER: args: ()
18:13:32 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.02538734934159786, 'num_filters_1': 70, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.02698212011643055, 'kernel_size_2': 7, 'num_filters_2': 96}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:13:56 DISPATCHER: Starting worker discovery
18:13:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:13:56 DISPATCHER: Finished worker discovery
18:14:25 WORKER: done with job (8, 0, 1), trying to register it.
18:14:25 WORKER: registered result for job (8, 0, 1) with dispatcher
18:14:25 DISPATCHER: job (8, 0, 1) finished
18:14:25 DISPATCHER: register_result: lock acquired
18:14:25 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:14:25 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.02538734934159786, 'num_filters_1': 70, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.02698212011643055, 'kernel_size_2': 7, 'num_filters_2': 96}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7386087844017885, 'info': {'music-speech': 0.7386087844017885, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.02538734934159786, 'num_filters_1': 70, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.02698212011643055, 'kernel_size_2': 7, 'num_filters_2': 96}"}}
exception: None

18:14:25 job_callback for (8, 0, 1) started
18:14:25 job_callback for (8, 0, 1) got condition
18:14:25 DISPATCHER: Trying to submit another job.
18:14:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:14:25 HBMASTER: Trying to run another job!
18:14:25 job_callback for (8, 0, 1) finished
18:14:25 start sampling a new configuration.
18:14:26 best_vector: [0, 1, 0.4902535773539612, 0.04037641873932467, 0.3703700326974436, 0, 0.3821793420843005, 0.5110613562750074, 2, 1, 1, 1, 0.882889519178524, 0.42380681285669247, 0.8165038946701401, 0.13637588378273025], 1.9036846824344332e-28, 5.252970774136815e-05, -5.348708375407074e-07
18:14:26 done sampling a new configuration.
18:14:26 HBMASTER: schedule new run for iteration 8
18:14:26 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
18:14:26 HBMASTER: submitting job (8, 0, 2) to dispatcher
18:14:26 DISPATCHER: trying to submit job (8, 0, 2)
18:14:26 DISPATCHER: trying to notify the job_runner thread.
18:14:26 HBMASTER: job (8, 0, 2) submitted to dispatcher
18:14:26 DISPATCHER: Trying to submit another job.
18:14:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:14:26 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:14:26 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:14:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:14:26 WORKER: start processing job (8, 0, 2)
18:14:26 WORKER: args: ()
18:14:26 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.009561084461302053, 'num_filters_1': 17, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.04622811171657652, 'kernel_size_2': 7, 'num_filters_2': 100}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:14:56 DISPATCHER: Starting worker discovery
18:14:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:14:56 DISPATCHER: Finished worker discovery
18:15:19 WORKER: done with job (8, 0, 2), trying to register it.
18:15:19 WORKER: registered result for job (8, 0, 2) with dispatcher
18:15:19 DISPATCHER: job (8, 0, 2) finished
18:15:19 DISPATCHER: register_result: lock acquired
18:15:19 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:15:19 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.009561084461302053, 'num_filters_1': 17, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.04622811171657652, 'kernel_size_2': 7, 'num_filters_2': 100}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9099721995820214, 'info': {'music-speech': 0.9099721995820214, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.009561084461302053, 'num_filters_1': 17, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.04622811171657652, 'kernel_size_2': 7, 'num_filters_2': 100}"}}
exception: None

18:15:19 job_callback for (8, 0, 2) started
18:15:19 DISPATCHER: Trying to submit another job.
18:15:19 job_callback for (8, 0, 2) got condition
18:15:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:15:19 HBMASTER: Trying to run another job!
18:15:19 job_callback for (8, 0, 2) finished
18:15:19 start sampling a new configuration.
18:15:19 done sampling a new configuration.
18:15:19 HBMASTER: schedule new run for iteration 8
18:15:19 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
18:15:19 HBMASTER: submitting job (8, 0, 3) to dispatcher
18:15:19 DISPATCHER: trying to submit job (8, 0, 3)
18:15:19 DISPATCHER: trying to notify the job_runner thread.
18:15:19 HBMASTER: job (8, 0, 3) submitted to dispatcher
18:15:19 DISPATCHER: Trying to submit another job.
18:15:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:15:19 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:15:19 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:15:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:15:19 WORKER: start processing job (8, 0, 3)
18:15:19 WORKER: args: ()
18:15:19 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.013918759372994215, 'num_filters_1': 62, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.15937426159270432, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 23, 'num_filters_3': 30, 'num_filters_4': 72}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:15:56 DISPATCHER: Starting worker discovery
18:15:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:15:56 DISPATCHER: Finished worker discovery
18:16:12 WORKER: done with job (8, 0, 3), trying to register it.
18:16:12 WORKER: registered result for job (8, 0, 3) with dispatcher
18:16:12 DISPATCHER: job (8, 0, 3) finished
18:16:12 DISPATCHER: register_result: lock acquired
18:16:12 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:16:12 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.013918759372994215, 'num_filters_1': 62, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.15937426159270432, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 23, 'num_filters_3': 30, 'num_filters_4': 72}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.013918759372994215, 'num_filters_1': 62, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.15937426159270432, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 23, 'num_filters_3': 30, 'num_filters_4': 72}"}}
exception: None

18:16:12 job_callback for (8, 0, 3) started
18:16:12 DISPATCHER: Trying to submit another job.
18:16:12 job_callback for (8, 0, 3) got condition
18:16:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:16:12 HBMASTER: Trying to run another job!
18:16:12 job_callback for (8, 0, 3) finished
18:16:12 start sampling a new configuration.
18:16:12 best_vector: [1, 2, 0.3672002761640478, 0.7551353241390862, 0.0801793990951801, 0, 0.5812932041755466, 0.49588672525508376, 0, 2, 2, 0, 0.33519880111202777, 0.498817524060842, 0.3498236176688606, 0.9879524307788213], 3.170951418336587e-28, 3.1536276280277374e-05, -1.9336517798098675e-05
18:16:12 done sampling a new configuration.
18:16:12 HBMASTER: schedule new run for iteration 8
18:16:12 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
18:16:12 HBMASTER: submitting job (8, 0, 4) to dispatcher
18:16:12 DISPATCHER: trying to submit job (8, 0, 4)
18:16:12 DISPATCHER: trying to notify the job_runner thread.
18:16:12 HBMASTER: job (8, 0, 4) submitted to dispatcher
18:16:12 DISPATCHER: Trying to submit another job.
18:16:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:16:12 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:16:12 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:16:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:16:12 WORKER: start processing job (8, 0, 4)
18:16:12 WORKER: args: ()
18:16:12 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005425010115739717, 'num_filters_1': 77, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.0441736721928722}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:16:56 DISPATCHER: Starting worker discovery
18:16:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:16:56 DISPATCHER: Finished worker discovery
18:17:05 WORKER: done with job (8, 0, 4), trying to register it.
18:17:05 WORKER: registered result for job (8, 0, 4) with dispatcher
18:17:05 DISPATCHER: job (8, 0, 4) finished
18:17:05 DISPATCHER: register_result: lock acquired
18:17:05 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:17:05 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005425010115739717, 'num_filters_1': 77, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.0441736721928722}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9865267312154576, 'info': {'music-speech': 0.9865267312154576, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005425010115739717, 'num_filters_1': 77, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.0441736721928722}"}}
exception: None

18:17:05 job_callback for (8, 0, 4) started
18:17:05 job_callback for (8, 0, 4) got condition
18:17:05 DISPATCHER: Trying to submit another job.
18:17:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:17:05 HBMASTER: Trying to run another job!
18:17:05 job_callback for (8, 0, 4) finished
18:17:05 start sampling a new configuration.
18:17:05 best_vector: [2, 0, 0.26179786260305116, 0.05790857101745117, 0.9436178436817387, 0, 0.20401283638538636, 0.43199898617152843, 1, 1, 2, 1, 0.3104625091622802, 0.317063618038457, 0.024671483035402342, 0.8121460768944273], 3.7541014745228145e-29, 0.0002663753249043729, -2.3379859124432332e-05
18:17:05 done sampling a new configuration.
18:17:05 HBMASTER: schedule new run for iteration 8
18:17:05 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
18:17:05 HBMASTER: submitting job (8, 0, 5) to dispatcher
18:17:05 DISPATCHER: trying to submit job (8, 0, 5)
18:17:05 DISPATCHER: trying to notify the job_runner thread.
18:17:05 HBMASTER: job (8, 0, 5) submitted to dispatcher
18:17:05 DISPATCHER: Trying to submit another job.
18:17:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:17:05 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:17:05 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:17:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:17:05 WORKER: start processing job (8, 0, 5)
18:17:05 WORKER: args: ()
18:17:05 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003338840902622378, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.036479060024820924, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 30, 'num_filters_3': 30, 'num_filters_4': 16, 'num_filters_5': 86}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:17:56 DISPATCHER: Starting worker discovery
18:17:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:17:56 DISPATCHER: Finished worker discovery
18:17:59 WORKER: done with job (8, 0, 5), trying to register it.
18:17:59 DISPATCHER: job (8, 0, 5) finished
18:17:59 WORKER: registered result for job (8, 0, 5) with dispatcher
18:17:59 DISPATCHER: register_result: lock acquired
18:17:59 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:17:59 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003338840902622378, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.036479060024820924, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 30, 'num_filters_3': 30, 'num_filters_4': 16, 'num_filters_5': 86}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.842666969524983, 'info': {'music-speech': 0.842666969524983, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003338840902622378, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.036479060024820924, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 30, 'num_filters_3': 30, 'num_filters_4': 16, 'num_filters_5': 86}"}}
exception: None

18:17:59 job_callback for (8, 0, 5) started
18:17:59 DISPATCHER: Trying to submit another job.
18:17:59 job_callback for (8, 0, 5) got condition
18:17:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:17:59 HBMASTER: Trying to run another job!
18:17:59 job_callback for (8, 0, 5) finished
18:17:59 start sampling a new configuration.
18:17:59 best_vector: [3, 2, 0.24299721353114015, 0.7729685524446777, 0.45551984920456007, 0, 0.904213877956554, 0.4773554290704958, 1, 1, 2, 0, 0.9294251743011247, 0.6611041394570415, 0.10578661894149433, 0.305745971886563], 2.4208226193394238e-29, 0.00041308272320789564, -5.221820794485238e-06
18:17:59 done sampling a new configuration.
18:17:59 HBMASTER: schedule new run for iteration 8
18:17:59 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
18:17:59 HBMASTER: submitting job (8, 0, 6) to dispatcher
18:17:59 DISPATCHER: trying to submit job (8, 0, 6)
18:17:59 DISPATCHER: trying to notify the job_runner thread.
18:17:59 HBMASTER: job (8, 0, 6) submitted to dispatcher
18:17:59 DISPATCHER: Trying to submit another job.
18:17:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:17:59 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:17:59 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:17:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:17:59 WORKER: start processing job (8, 0, 6)
18:17:59 WORKER: args: ()
18:17:59 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0030619241423279226, 'num_filters_1': 79, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.04178820646839389, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 111, 'num_filters_3': 63}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:18:56 WORKER: done with job (8, 0, 6), trying to register it.
18:18:56 DISPATCHER: job (8, 0, 6) finished
18:18:56 WORKER: registered result for job (8, 0, 6) with dispatcher
18:18:56 DISPATCHER: register_result: lock acquired
18:18:56 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:18:56 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0030619241423279226, 'num_filters_1': 79, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.04178820646839389, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 111, 'num_filters_3': 63}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7386291632250065, 'info': {'music-speech': 0.7386291632250065, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0030619241423279226, 'num_filters_1': 79, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.04178820646839389, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 111, 'num_filters_3': 63}"}}
exception: None

18:18:56 job_callback for (8, 0, 6) started
18:18:56 DISPATCHER: Trying to submit another job.
18:18:56 job_callback for (8, 0, 6) got condition
18:18:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:18:56 HBMASTER: Trying to run another job!
18:18:56 job_callback for (8, 0, 6) finished
18:18:56 start sampling a new configuration.
18:18:56 DISPATCHER: Starting worker discovery
18:18:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:18:56 DISPATCHER: Finished worker discovery
18:18:56 best_vector: [3, 2, 0.20249778283343142, 0.25154470770296194, 0.802092545407687, 0, 0.8470227268072984, 0.6116805629411943, 0, 1, 2, 2, 0.047061535989252085, 0.3877315467731216, 0.44589588760336835, 0.9874364319441988], 2.880348288019644e-29, 0.00034718023655658, -1.798649176883088e-05
18:18:56 done sampling a new configuration.
18:18:56 HBMASTER: schedule new run for iteration 8
18:18:56 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
18:18:56 HBMASTER: submitting job (8, 0, 7) to dispatcher
18:18:56 DISPATCHER: trying to submit job (8, 0, 7)
18:18:56 DISPATCHER: trying to notify the job_runner thread.
18:18:56 HBMASTER: job (8, 0, 7) submitted to dispatcher
18:18:56 DISPATCHER: Trying to submit another job.
18:18:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:18:56 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:18:56 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:18:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:18:56 WORKER: start processing job (8, 0, 7)
18:18:56 WORKER: args: ()
18:18:56 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0025409467612593937, 'num_filters_1': 26, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.06249060944055022, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 17, 'num_filters_3': 35, 'num_filters_4': 40, 'num_filters_5': 125}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:19:51 WORKER: done with job (8, 0, 7), trying to register it.
18:19:51 WORKER: registered result for job (8, 0, 7) with dispatcher
18:19:51 DISPATCHER: job (8, 0, 7) finished
18:19:51 DISPATCHER: register_result: lock acquired
18:19:51 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:19:51 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0025409467612593937, 'num_filters_1': 26, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.06249060944055022, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 17, 'num_filters_3': 35, 'num_filters_4': 40, 'num_filters_5': 125}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8926163184889645, 'info': {'music-speech': 0.8926163184889645, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0025409467612593937, 'num_filters_1': 26, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.06249060944055022, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 17, 'num_filters_3': 35, 'num_filters_4': 40, 'num_filters_5': 125}"}}
exception: None

18:19:51 job_callback for (8, 0, 7) started
18:19:51 DISPATCHER: Trying to submit another job.
18:19:51 job_callback for (8, 0, 7) got condition
18:19:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:19:51 HBMASTER: Trying to run another job!
18:19:51 job_callback for (8, 0, 7) finished
18:19:51 start sampling a new configuration.
18:19:52 best_vector: [1, 2, 0.5343225016010167, 0.6960948013487451, 0.14715628930293567, 1, 0.24202941079531493, 0.08399644042624643, 0, 1, 0, 2, 0.8885076148823823, 0.6515724235206108, 0.1653912127938741, 0.8154646514248578], 3.460038598507792e-29, 0.0002890141169035713, -7.604881989286322e-07
18:19:52 done sampling a new configuration.
18:19:52 HBMASTER: schedule new run for iteration 8
18:19:52 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
18:19:52 HBMASTER: submitting job (8, 0, 8) to dispatcher
18:19:52 DISPATCHER: trying to submit job (8, 0, 8)
18:19:52 DISPATCHER: trying to notify the job_runner thread.
18:19:52 HBMASTER: job (8, 0, 8) submitted to dispatcher
18:19:52 DISPATCHER: Trying to submit another job.
18:19:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:19:52 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:19:52 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:19:52 WORKER: start processing job (8, 0, 8)
18:19:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:19:52 WORKER: args: ()
18:19:52 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.01171237592441771, 'num_filters_1': 68, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.012861211747287616}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:19:56 DISPATCHER: Starting worker discovery
18:19:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:19:56 DISPATCHER: Finished worker discovery
18:20:45 WORKER: done with job (8, 0, 8), trying to register it.
18:20:45 WORKER: registered result for job (8, 0, 8) with dispatcher
18:20:45 DISPATCHER: job (8, 0, 8) finished
18:20:45 DISPATCHER: register_result: lock acquired
18:20:45 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:20:45 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.01171237592441771, 'num_filters_1': 68, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.012861211747287616}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5405539250220782, 'info': {'music-speech': 0.5405539250220782, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.01171237592441771, 'num_filters_1': 68, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 32, 'weight_decay': 0.012861211747287616}"}}
exception: None

18:20:45 job_callback for (8, 0, 8) started
18:20:45 job_callback for (8, 0, 8) got condition
18:20:45 DISPATCHER: Trying to submit another job.
18:20:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:20:45 HBMASTER: Trying to run another job!
18:20:45 job_callback for (8, 0, 8) finished
18:20:45 start sampling a new configuration.
18:20:45 best_vector: [0, 1, 0.2489265773417227, 0.23274231571548373, 0.2954749038398191, 0, 0.7994720330634395, 0.8685178712870333, 2, 2, 0, 0, 0.9611468418623719, 0.6234260928384225, 0.7420892273185294, 0.09712199140082367], 3.616492251348255e-27, 2.7651103071690324e-06, -2.361237759191379e-06
18:20:45 done sampling a new configuration.
18:20:45 HBMASTER: schedule new run for iteration 8
18:20:45 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
18:20:45 HBMASTER: submitting job (8, 0, 9) to dispatcher
18:20:45 DISPATCHER: trying to submit job (8, 0, 9)
18:20:45 DISPATCHER: trying to notify the job_runner thread.
18:20:45 HBMASTER: job (8, 0, 9) submitted to dispatcher
18:20:45 DISPATCHER: Trying to submit another job.
18:20:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:20:45 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:20:45 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:20:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:20:45 WORKER: start processing job (8, 0, 9)
18:20:45 WORKER: args: ()
18:20:45 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.003146684165281015, 'num_filters_1': 25, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.1348862877009621, 'kernel_size_2': 7, 'num_filters_2': 118}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:20:56 DISPATCHER: Starting worker discovery
18:20:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:20:56 DISPATCHER: Finished worker discovery
18:21:39 WORKER: done with job (8, 0, 9), trying to register it.
18:21:39 DISPATCHER: job (8, 0, 9) finished
18:21:39 WORKER: registered result for job (8, 0, 9) with dispatcher
18:21:39 DISPATCHER: register_result: lock acquired
18:21:39 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:21:39 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.003146684165281015, 'num_filters_1': 25, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.1348862877009621, 'kernel_size_2': 7, 'num_filters_2': 118}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8424352427804099, 'info': {'music-speech': 0.8424352427804099, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.003146684165281015, 'num_filters_1': 25, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.1348862877009621, 'kernel_size_2': 7, 'num_filters_2': 118}"}}
exception: None

18:21:39 job_callback for (8, 0, 9) started
18:21:39 DISPATCHER: Trying to submit another job.
18:21:39 job_callback for (8, 0, 9) got condition
18:21:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:21:42 HBMASTER: Trying to run another job!
18:21:42 job_callback for (8, 0, 9) finished
18:21:42 start sampling a new configuration.
18:21:42 best_vector: [2, 0, 0.033373411267464584, 0.0234921281033188, 0.6142112264093599, 0, 0.2680301054592601, 0.5034412332329445, 2, 1, 0, 0, 0.9814143735507832, 0.22535665214428358, 0.7309131444780983, 0.6658081052797032], 9.452150808995292e-30, 0.0010579602676761505, -1.6170363080176163e-06
18:21:42 done sampling a new configuration.
18:21:42 HBMASTER: schedule new run for iteration 8
18:21:42 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
18:21:42 HBMASTER: submitting job (8, 0, 10) to dispatcher
18:21:42 DISPATCHER: trying to submit job (8, 0, 10)
18:21:42 DISPATCHER: trying to notify the job_runner thread.
18:21:42 HBMASTER: job (8, 0, 10) submitted to dispatcher
18:21:42 DISPATCHER: Trying to submit another job.
18:21:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:21:42 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:21:42 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:21:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:21:42 WORKER: start processing job (8, 0, 10)
18:21:42 WORKER: args: ()
18:21:42 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0011661296088553948, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.04518477723280045, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 124, 'num_filters_3': 25, 'num_filters_4': 73}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:21:56 DISPATCHER: Starting worker discovery
18:21:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:21:56 DISPATCHER: Finished worker discovery
18:22:35 WORKER: done with job (8, 0, 10), trying to register it.
18:22:35 WORKER: registered result for job (8, 0, 10) with dispatcher
18:22:35 DISPATCHER: job (8, 0, 10) finished
18:22:35 DISPATCHER: register_result: lock acquired
18:22:35 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:22:35 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0011661296088553948, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.04518477723280045, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 124, 'num_filters_3': 25, 'num_filters_4': 73}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9313997832649449, 'info': {'music-speech': 0.9313997832649449, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0011661296088553948, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.04518477723280045, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 124, 'num_filters_3': 25, 'num_filters_4': 73}"}}
exception: None

18:22:35 job_callback for (8, 0, 10) started
18:22:35 job_callback for (8, 0, 10) got condition
18:22:35 DISPATCHER: Trying to submit another job.
18:22:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:22:35 HBMASTER: Trying to run another job!
18:22:35 job_callback for (8, 0, 10) finished
18:22:35 start sampling a new configuration.
18:22:35 best_vector: [3, 1, 0.3242630180906444, 0.5905201425294578, 0.048285733947891485, 0, 0.282803034650016, 0.24984675750370333, 2, 2, 0, 2, 0.35566529528197643, 0.5927543595827687, 0.7423844183801949, 0.24821634666585624], 2.561455458267891e-29, 0.00039040304088528663, -3.9178346303226265e-05
18:22:35 done sampling a new configuration.
18:22:35 HBMASTER: schedule new run for iteration 8
18:22:35 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
18:22:35 HBMASTER: submitting job (8, 0, 11) to dispatcher
18:22:35 DISPATCHER: trying to submit job (8, 0, 11)
18:22:35 DISPATCHER: trying to notify the job_runner thread.
18:22:35 HBMASTER: job (8, 0, 11) submitted to dispatcher
18:22:35 DISPATCHER: Trying to submit another job.
18:22:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:22:35 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:22:35 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:22:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:22:35 WORKER: start processing job (8, 0, 11)
18:22:35 WORKER: args: ()
18:22:35 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0044517015030343995, 'num_filters_1': 54, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.021137719274502607}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:22:56 DISPATCHER: Starting worker discovery
18:22:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:22:56 DISPATCHER: Finished worker discovery
18:23:29 WORKER: done with job (8, 0, 11), trying to register it.
18:23:29 WORKER: registered result for job (8, 0, 11) with dispatcher
18:23:29 DISPATCHER: job (8, 0, 11) finished
18:23:29 DISPATCHER: register_result: lock acquired
18:23:29 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:23:29 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0044517015030343995, 'num_filters_1': 54, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.021137719274502607}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9224729864755177, 'info': {'music-speech': 0.9224729864755177, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0044517015030343995, 'num_filters_1': 54, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.021137719274502607}"}}
exception: None

18:23:29 job_callback for (8, 0, 11) started
18:23:29 DISPATCHER: Trying to submit another job.
18:23:29 job_callback for (8, 0, 11) got condition
18:23:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:23:29 HBMASTER: Trying to run another job!
18:23:29 job_callback for (8, 0, 11) finished
18:23:29 start sampling a new configuration.
18:23:29 done sampling a new configuration.
18:23:29 HBMASTER: schedule new run for iteration 8
18:23:29 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
18:23:29 HBMASTER: submitting job (8, 0, 12) to dispatcher
18:23:29 DISPATCHER: trying to submit job (8, 0, 12)
18:23:29 DISPATCHER: trying to notify the job_runner thread.
18:23:29 HBMASTER: job (8, 0, 12) submitted to dispatcher
18:23:29 DISPATCHER: Trying to submit another job.
18:23:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:23:29 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:23:29 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:23:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:23:29 WORKER: start processing job (8, 0, 12)
18:23:29 WORKER: args: ()
18:23:29 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004928668966317219, 'num_filters_1': 61, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.08510312548985119, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 26, 'num_filters_3': 111}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:23:56 DISPATCHER: Starting worker discovery
18:23:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:23:56 DISPATCHER: Finished worker discovery
18:24:22 WORKER: done with job (8, 0, 12), trying to register it.
18:24:22 WORKER: registered result for job (8, 0, 12) with dispatcher
18:24:22 DISPATCHER: job (8, 0, 12) finished
18:24:22 DISPATCHER: register_result: lock acquired
18:24:22 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:24:22 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004928668966317219, 'num_filters_1': 61, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.08510312548985119, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 26, 'num_filters_3': 111}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.927113616797804, 'info': {'music-speech': 0.927113616797804, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004928668966317219, 'num_filters_1': 61, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.08510312548985119, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 26, 'num_filters_3': 111}"}}
exception: None

18:24:22 job_callback for (8, 0, 12) started
18:24:22 DISPATCHER: Trying to submit another job.
18:24:22 job_callback for (8, 0, 12) got condition
18:24:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:24:22 HBMASTER: Trying to run another job!
18:24:22 job_callback for (8, 0, 12) finished
18:24:22 start sampling a new configuration.
18:24:22 best_vector: [3, 0, 0.3944546199645332, 0.5373954892613749, 0.08752233266970144, 1, 0.8102698102679038, 0.6305466437104552, 2, 0, 2, 2, 0.8434824607959794, 0.24573813638267167, 0.02169001749770416, 0.04035632257635746], 2.418587694260095e-29, 0.0004134644372719032, -1.7044453035584696e-06
18:24:22 done sampling a new configuration.
18:24:22 HBMASTER: schedule new run for iteration 8
18:24:22 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
18:24:22 HBMASTER: submitting job (8, 0, 13) to dispatcher
18:24:22 DISPATCHER: trying to submit job (8, 0, 13)
18:24:22 DISPATCHER: trying to notify the job_runner thread.
18:24:22 HBMASTER: job (8, 0, 13) submitted to dispatcher
18:24:22 DISPATCHER: Trying to submit another job.
18:24:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:24:22 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:24:22 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:24:22 WORKER: start processing job (8, 0, 13)
18:24:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:24:22 WORKER: args: ()
18:24:22 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.006150483247655203, 'num_filters_1': 48, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.06612414919891291}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:24:56 DISPATCHER: Starting worker discovery
18:24:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:24:56 DISPATCHER: Finished worker discovery
18:25:17 WORKER: done with job (8, 0, 13), trying to register it.
18:25:17 DISPATCHER: job (8, 0, 13) finished
18:25:17 WORKER: registered result for job (8, 0, 13) with dispatcher
18:25:17 DISPATCHER: register_result: lock acquired
18:25:17 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:25:17 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.006150483247655203, 'num_filters_1': 48, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.06612414919891291}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5411970183977624, 'info': {'music-speech': 0.5411970183977624, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.006150483247655203, 'num_filters_1': 48, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.06612414919891291}"}}
exception: None

18:25:17 job_callback for (8, 0, 13) started
18:25:17 DISPATCHER: Trying to submit another job.
18:25:17 job_callback for (8, 0, 13) got condition
18:25:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:25:17 HBMASTER: Trying to run another job!
18:25:17 job_callback for (8, 0, 13) finished
18:25:17 start sampling a new configuration.
18:25:17 done sampling a new configuration.
18:25:17 HBMASTER: schedule new run for iteration 8
18:25:17 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
18:25:17 HBMASTER: submitting job (8, 0, 14) to dispatcher
18:25:17 DISPATCHER: trying to submit job (8, 0, 14)
18:25:17 DISPATCHER: trying to notify the job_runner thread.
18:25:17 HBMASTER: job (8, 0, 14) submitted to dispatcher
18:25:17 DISPATCHER: Trying to submit another job.
18:25:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:25:17 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:25:17 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:25:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:25:17 WORKER: start processing job (8, 0, 14)
18:25:17 WORKER: args: ()
18:25:17 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.027579919601364168, 'num_filters_1': 63, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.06396670472688029}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:25:56 DISPATCHER: Starting worker discovery
18:25:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:25:56 DISPATCHER: Finished worker discovery
18:26:11 WORKER: done with job (8, 0, 14), trying to register it.
18:26:11 WORKER: registered result for job (8, 0, 14) with dispatcher
18:26:11 DISPATCHER: job (8, 0, 14) finished
18:26:11 DISPATCHER: register_result: lock acquired
18:26:11 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:26:11 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.027579919601364168, 'num_filters_1': 63, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.06396670472688029}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.651411563017393, 'info': {'music-speech': 0.651411563017393, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.027579919601364168, 'num_filters_1': 63, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.06396670472688029}"}}
exception: None

18:26:11 job_callback for (8, 0, 14) started
18:26:11 DISPATCHER: Trying to submit another job.
18:26:11 job_callback for (8, 0, 14) got condition
18:26:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:26:11 HBMASTER: Trying to run another job!
18:26:11 job_callback for (8, 0, 14) finished
18:26:11 start sampling a new configuration.
18:26:12 best_vector: [3, 2, 0.5180225545515214, 0.3696434062126025, 0.8147345649690176, 1, 0.6045030258452085, 0.34333007018666917, 1, 2, 0, 0, 0.9876421320842339, 0.18562775979033277, 0.8239515285423182, 0.10467709368592565], 1.764990483143132e-28, 5.665752929268939e-05, -3.0903662709711577e-09
18:26:12 done sampling a new configuration.
18:26:12 HBMASTER: schedule new run for iteration 8
18:26:12 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
18:26:12 HBMASTER: submitting job (8, 0, 15) to dispatcher
18:26:12 DISPATCHER: trying to submit job (8, 0, 15)
18:26:12 DISPATCHER: trying to notify the job_runner thread.
18:26:12 HBMASTER: job (8, 0, 15) submitted to dispatcher
18:26:12 DISPATCHER: Trying to submit another job.
18:26:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:26:12 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:26:12 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:26:12 WORKER: start processing job (8, 0, 15)
18:26:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:26:12 WORKER: args: ()
18:26:12 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.010865384738435556, 'num_filters_1': 34, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.027969372290876406, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 125, 'num_filters_3': 23, 'num_filters_4': 89, 'num_filters_5': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:26:56 DISPATCHER: Starting worker discovery
18:26:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:26:56 DISPATCHER: Finished worker discovery
18:27:06 WORKER: done with job (8, 0, 15), trying to register it.
18:27:06 WORKER: registered result for job (8, 0, 15) with dispatcher
18:27:06 DISPATCHER: job (8, 0, 15) finished
18:27:06 DISPATCHER: register_result: lock acquired
18:27:06 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:27:06 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.010865384738435556, 'num_filters_1': 34, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.027969372290876406, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 125, 'num_filters_3': 23, 'num_filters_4': 89, 'num_filters_5': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9184532111014925, 'info': {'music-speech': 0.9184532111014925, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.010865384738435556, 'num_filters_1': 34, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.027969372290876406, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 125, 'num_filters_3': 23, 'num_filters_4': 89, 'num_filters_5': 19}"}}
exception: None

18:27:06 job_callback for (8, 0, 15) started
18:27:06 DISPATCHER: Trying to submit another job.
18:27:06 job_callback for (8, 0, 15) got condition
18:27:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:27:06 HBMASTER: Trying to run another job!
18:27:06 job_callback for (8, 0, 15) finished
18:27:06 start sampling a new configuration.
18:27:06 best_vector: [3, 1, 0.395212459000878, 0.5444658477667476, 0.436266867949456, 0, 0.4637528192407924, 0.41134161666884966, 0, 2, 0, 1, 0.9610847595323732, 0.42220364230408186, 0.3069052515264064, 0.17488697359250632], 5.71285244244363e-29, 0.00017504390496251947, -2.2700063067246085e-07
18:27:06 done sampling a new configuration.
18:27:06 HBMASTER: schedule new run for iteration 8
18:27:06 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
18:27:06 HBMASTER: submitting job (8, 0, 16) to dispatcher
18:27:06 DISPATCHER: trying to submit job (8, 0, 16)
18:27:06 DISPATCHER: trying to notify the job_runner thread.
18:27:06 HBMASTER: job (8, 0, 16) submitted to dispatcher
18:27:06 DISPATCHER: Trying to submit another job.
18:27:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:27:06 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:27:06 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:27:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:27:06 WORKER: start processing job (8, 0, 16)
18:27:06 WORKER: args: ()
18:27:06 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006171985797139369, 'num_filters_1': 49, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.03429002342110546, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 118, 'num_filters_3': 38}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:27:56 DISPATCHER: Starting worker discovery
18:27:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:27:56 DISPATCHER: Finished worker discovery
18:28:01 WORKER: done with job (8, 0, 16), trying to register it.
18:28:01 DISPATCHER: job (8, 0, 16) finished
18:28:01 WORKER: registered result for job (8, 0, 16) with dispatcher
18:28:01 DISPATCHER: register_result: lock acquired
18:28:01 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:28:01 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006171985797139369, 'num_filters_1': 49, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.03429002342110546, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 118, 'num_filters_3': 38}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.733832884993085, 'info': {'music-speech': 0.733832884993085, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.006171985797139369, 'num_filters_1': 49, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.03429002342110546, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 118, 'num_filters_3': 38}"}}
exception: None

18:28:01 job_callback for (8, 0, 16) started
18:28:01 DISPATCHER: Trying to submit another job.
18:28:01 job_callback for (8, 0, 16) got condition
18:28:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:28:01 HBMASTER: Trying to run another job!
18:28:01 job_callback for (8, 0, 16) finished
18:28:01 start sampling a new configuration.
18:28:01 best_vector: [3, 0, 0.15490729810074239, 0.6236993902290762, 0.16973678213699273, 0, 0.8078380768188448, 0.1289114747583689, 0, 1, 2, 1, 0.27570919412318495, 0.6432295835034247, 0.34491670752729187, 0.06968123009540972], 1.3519307398607952e-29, 0.0007396828628239991, -4.110792129359311e-06
18:28:01 done sampling a new configuration.
18:28:01 HBMASTER: schedule new run for iteration 8
18:28:01 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
18:28:01 HBMASTER: submitting job (8, 0, 17) to dispatcher
18:28:01 DISPATCHER: trying to submit job (8, 0, 17)
18:28:01 DISPATCHER: trying to notify the job_runner thread.
18:28:01 HBMASTER: job (8, 0, 17) submitted to dispatcher
18:28:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:28:01 DISPATCHER: Trying to submit another job.
18:28:01 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:28:01 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:28:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:28:01 WORKER: start processing job (8, 0, 17)
18:28:01 WORKER: args: ()
18:28:01 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0020408664963881763, 'num_filters_1': 58, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.014713557657446205}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:28:54 WORKER: done with job (8, 0, 17), trying to register it.
18:28:54 WORKER: registered result for job (8, 0, 17) with dispatcher
18:28:54 DISPATCHER: job (8, 0, 17) finished
18:28:54 DISPATCHER: register_result: lock acquired
18:28:54 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:28:54 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0020408664963881763, 'num_filters_1': 58, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.014713557657446205}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7199322948152341, 'info': {'music-speech': 0.7199322948152341, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0020408664963881763, 'num_filters_1': 58, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.014713557657446205}"}}
exception: None

18:28:54 job_callback for (8, 0, 17) started
18:28:54 DISPATCHER: Trying to submit another job.
18:28:54 job_callback for (8, 0, 17) got condition
18:28:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:28:54 HBMASTER: Trying to run another job!
18:28:54 job_callback for (8, 0, 17) finished
18:28:54 start sampling a new configuration.
18:28:54 best_vector: [1, 2, 0.11699000030845713, 0.015368032647236539, 0.994036884715415, 1, 0.3855111722516458, 0.5218732418178031, 2, 2, 2, 0, 0.8573753338921976, 0.4784855128650324, 0.24098823485253074, 0.24269895516672513], 2.6659531833298006e-28, 3.751003604463116e-05, -1.5346840263061723e-06
18:28:54 done sampling a new configuration.
18:28:54 HBMASTER: schedule new run for iteration 8
18:28:54 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
18:28:54 HBMASTER: submitting job (8, 0, 18) to dispatcher
18:28:54 DISPATCHER: trying to submit job (8, 0, 18)
18:28:54 DISPATCHER: trying to notify the job_runner thread.
18:28:54 HBMASTER: job (8, 0, 18) submitted to dispatcher
18:28:54 DISPATCHER: Trying to submit another job.
18:28:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:28:54 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:28:54 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:28:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:28:54 WORKER: start processing job (8, 0, 18)
18:28:54 WORKER: args: ()
18:28:54 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0017138783811094782, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.047749930250916645, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 95, 'num_filters_3': 43, 'num_filters_4': 26, 'num_filters_5': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:28:56 DISPATCHER: Starting worker discovery
18:28:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:28:56 DISPATCHER: Finished worker discovery
18:29:47 WORKER: done with job (8, 0, 18), trying to register it.
18:29:47 WORKER: registered result for job (8, 0, 18) with dispatcher
18:29:47 DISPATCHER: job (8, 0, 18) finished
18:29:47 DISPATCHER: register_result: lock acquired
18:29:47 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:29:47 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0017138783811094782, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.047749930250916645, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 95, 'num_filters_3': 43, 'num_filters_4': 26, 'num_filters_5': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8518538682274698, 'info': {'music-speech': 0.8518538682274698, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0017138783811094782, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.047749930250916645, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 95, 'num_filters_3': 43, 'num_filters_4': 26, 'num_filters_5': 26}"}}
exception: None

18:29:47 job_callback for (8, 0, 18) started
18:29:47 DISPATCHER: Trying to submit another job.
18:29:47 job_callback for (8, 0, 18) got condition
18:29:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:29:47 HBMASTER: Trying to run another job!
18:29:47 job_callback for (8, 0, 18) finished
18:29:47 start sampling a new configuration.
18:29:47 done sampling a new configuration.
18:29:47 HBMASTER: schedule new run for iteration 8
18:29:47 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
18:29:47 HBMASTER: submitting job (8, 0, 19) to dispatcher
18:29:47 DISPATCHER: trying to submit job (8, 0, 19)
18:29:47 DISPATCHER: trying to notify the job_runner thread.
18:29:47 HBMASTER: job (8, 0, 19) submitted to dispatcher
18:29:47 DISPATCHER: Trying to submit another job.
18:29:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:29:47 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:29:47 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:29:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:29:47 WORKER: start processing job (8, 0, 19)
18:29:47 WORKER: args: ()
18:29:47 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.007272383097457406, 'num_filters_1': 60, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.039377442277777966}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:29:56 DISPATCHER: Starting worker discovery
18:29:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:29:56 DISPATCHER: Finished worker discovery
18:30:40 WORKER: done with job (8, 0, 19), trying to register it.
18:30:40 WORKER: registered result for job (8, 0, 19) with dispatcher
18:30:40 DISPATCHER: job (8, 0, 19) finished
18:30:40 DISPATCHER: register_result: lock acquired
18:30:40 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:30:40 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.007272383097457406, 'num_filters_1': 60, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.039377442277777966}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4771285426796126, 'info': {'music-speech': 0.4771285426796126, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.007272383097457406, 'num_filters_1': 60, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 31, 'weight_decay': 0.039377442277777966}"}}
exception: None

18:30:40 job_callback for (8, 0, 19) started
18:30:40 job_callback for (8, 0, 19) got condition
18:30:40 DISPATCHER: Trying to submit another job.
18:30:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:30:40 HBMASTER: Trying to run another job!
18:30:40 job_callback for (8, 0, 19) finished
18:30:40 start sampling a new configuration.
18:30:40 done sampling a new configuration.
18:30:40 HBMASTER: schedule new run for iteration 8
18:30:40 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
18:30:40 HBMASTER: submitting job (8, 0, 20) to dispatcher
18:30:40 DISPATCHER: trying to submit job (8, 0, 20)
18:30:40 DISPATCHER: trying to notify the job_runner thread.
18:30:40 HBMASTER: job (8, 0, 20) submitted to dispatcher
18:30:40 DISPATCHER: Trying to submit another job.
18:30:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:30:40 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:30:40 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:30:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:30:40 WORKER: start processing job (8, 0, 20)
18:30:40 WORKER: args: ()
18:30:40 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.05804942328687281, 'num_filters_1': 109, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.07887041984874828, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 30, 'num_filters_3': 107, 'num_filters_4': 50, 'num_filters_5': 84}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:30:56 DISPATCHER: Starting worker discovery
18:30:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:30:56 DISPATCHER: Finished worker discovery
18:31:35 WORKER: done with job (8, 0, 20), trying to register it.
18:31:35 DISPATCHER: job (8, 0, 20) finished
18:31:35 WORKER: registered result for job (8, 0, 20) with dispatcher
18:31:35 DISPATCHER: register_result: lock acquired
18:31:35 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:31:35 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.05804942328687281, 'num_filters_1': 109, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.07887041984874828, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 30, 'num_filters_3': 107, 'num_filters_4': 50, 'num_filters_5': 84}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0007231663242945001, 'info': {'music-speech': 0.0007231663242945001, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.05804942328687281, 'num_filters_1': 109, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.07887041984874828, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 30, 'num_filters_3': 107, 'num_filters_4': 50, 'num_filters_5': 84}"}}
exception: None

18:31:35 job_callback for (8, 0, 20) started
18:31:35 DISPATCHER: Trying to submit another job.
18:31:35 job_callback for (8, 0, 20) got condition
18:31:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:31:35 HBMASTER: Trying to run another job!
18:31:35 job_callback for (8, 0, 20) finished
18:31:35 start sampling a new configuration.
18:31:35 done sampling a new configuration.
18:31:35 HBMASTER: schedule new run for iteration 8
18:31:35 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
18:31:35 HBMASTER: submitting job (8, 0, 21) to dispatcher
18:31:35 DISPATCHER: trying to submit job (8, 0, 21)
18:31:35 DISPATCHER: trying to notify the job_runner thread.
18:31:35 HBMASTER: job (8, 0, 21) submitted to dispatcher
18:31:35 DISPATCHER: Trying to submit another job.
18:31:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:31:35 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:31:35 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:31:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:31:35 WORKER: start processing job (8, 0, 21)
18:31:35 WORKER: args: ()
18:31:35 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0025987430213891874, 'num_filters_1': 77, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.16632201313339565, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 115, 'num_filters_3': 87}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:31:56 DISPATCHER: Starting worker discovery
18:31:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:31:56 DISPATCHER: Finished worker discovery
18:32:29 WORKER: done with job (8, 0, 21), trying to register it.
18:32:29 WORKER: registered result for job (8, 0, 21) with dispatcher
18:32:29 DISPATCHER: job (8, 0, 21) finished
18:32:29 DISPATCHER: register_result: lock acquired
18:32:29 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:32:29 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0025987430213891874, 'num_filters_1': 77, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.16632201313339565, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 115, 'num_filters_3': 87}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8208355530433671, 'info': {'music-speech': 0.8208355530433671, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0025987430213891874, 'num_filters_1': 77, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.16632201313339565, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 115, 'num_filters_3': 87}"}}
exception: None

18:32:29 job_callback for (8, 0, 21) started
18:32:29 DISPATCHER: Trying to submit another job.
18:32:29 job_callback for (8, 0, 21) got condition
18:32:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:32:29 HBMASTER: Trying to run another job!
18:32:29 job_callback for (8, 0, 21) finished
18:32:29 start sampling a new configuration.
18:32:29 best_vector: [1, 0, 0.1875124255989952, 0.9666691324268394, 0.28532492818142685, 0, 0.023819513046531515, 0.2451511989017272, 2, 0, 2, 0, 0.7473359557833013, 0.21841176250528993, 0.7815342488618534, 0.3591055968988762], 7.568596393404491e-28, 1.321248945011034e-05, -1.1577536322594778e-06
18:32:29 done sampling a new configuration.
18:32:29 HBMASTER: schedule new run for iteration 8
18:32:29 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
18:32:29 HBMASTER: submitting job (8, 0, 22) to dispatcher
18:32:29 DISPATCHER: trying to submit job (8, 0, 22)
18:32:29 DISPATCHER: trying to notify the job_runner thread.
18:32:29 HBMASTER: job (8, 0, 22) submitted to dispatcher
18:32:29 DISPATCHER: Trying to submit another job.
18:32:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:32:29 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:32:29 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:32:29 WORKER: start processing job (8, 0, 22)
18:32:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:32:29 WORKER: args: ()
18:32:29 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0023715094042856197, 'num_filters_1': 120, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.02084246415388572, 'kernel_size_2': 7, 'num_filters_2': 75}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:32:56 DISPATCHER: Starting worker discovery
18:32:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:32:56 DISPATCHER: Finished worker discovery
18:33:22 WORKER: done with job (8, 0, 22), trying to register it.
18:33:22 WORKER: registered result for job (8, 0, 22) with dispatcher
18:33:22 DISPATCHER: job (8, 0, 22) finished
18:33:22 DISPATCHER: register_result: lock acquired
18:33:22 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:33:22 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0023715094042856197, 'num_filters_1': 120, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.02084246415388572, 'kernel_size_2': 7, 'num_filters_2': 75}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7478630999043246, 'info': {'music-speech': 0.7478630999043246, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0023715094042856197, 'num_filters_1': 120, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.02084246415388572, 'kernel_size_2': 7, 'num_filters_2': 75}"}}
exception: None

18:33:22 job_callback for (8, 0, 22) started
18:33:22 job_callback for (8, 0, 22) got condition
18:33:22 DISPATCHER: Trying to submit another job.
18:33:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:33:22 HBMASTER: Trying to run another job!
18:33:22 job_callback for (8, 0, 22) finished
18:33:22 start sampling a new configuration.
18:33:22 done sampling a new configuration.
18:33:22 HBMASTER: schedule new run for iteration 8
18:33:22 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
18:33:22 HBMASTER: submitting job (8, 0, 23) to dispatcher
18:33:22 DISPATCHER: trying to submit job (8, 0, 23)
18:33:22 DISPATCHER: trying to notify the job_runner thread.
18:33:22 HBMASTER: job (8, 0, 23) submitted to dispatcher
18:33:22 DISPATCHER: Trying to submit another job.
18:33:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:33:22 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:33:22 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:33:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:33:22 WORKER: start processing job (8, 0, 23)
18:33:22 WORKER: args: ()
18:33:22 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.011613518502155133, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.034621282993975044}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:33:56 DISPATCHER: Starting worker discovery
18:33:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:33:56 DISPATCHER: Finished worker discovery
18:34:16 WORKER: done with job (8, 0, 23), trying to register it.
18:34:16 WORKER: registered result for job (8, 0, 23) with dispatcher
18:34:16 DISPATCHER: job (8, 0, 23) finished
18:34:16 DISPATCHER: register_result: lock acquired
18:34:16 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:34:16 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.011613518502155133, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.034621282993975044}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8270853288215508, 'info': {'music-speech': 0.8270853288215508, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.011613518502155133, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 64, 'weight_decay': 0.034621282993975044}"}}
exception: None

18:34:16 job_callback for (8, 0, 23) started
18:34:16 job_callback for (8, 0, 23) got condition
18:34:16 DISPATCHER: Trying to submit another job.
18:34:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:34:16 HBMASTER: Trying to run another job!
18:34:16 job_callback for (8, 0, 23) finished
18:34:16 start sampling a new configuration.
18:34:16 best_vector: [1, 0, 0.24613001860490896, 0.6463847550811421, 0.26749375702734546, 0, 0.1627753581295388, 0.03870425953165807, 0, 0, 0, 0, 0.8234429428138252, 0.8198798249012753, 0.47009293319307444, 0.47161376259820564], 0.00010579486993663863, 0.0009809018869337289, 1.0377438754875726e-07
18:34:16 done sampling a new configuration.
18:34:16 HBMASTER: schedule new run for iteration 8
18:34:16 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
18:34:16 HBMASTER: submitting job (8, 0, 24) to dispatcher
18:34:16 DISPATCHER: trying to submit job (8, 0, 24)
18:34:16 DISPATCHER: trying to notify the job_runner thread.
18:34:16 HBMASTER: job (8, 0, 24) submitted to dispatcher
18:34:16 DISPATCHER: Trying to submit another job.
18:34:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:34:16 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:34:16 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:34:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:34:16 WORKER: start processing job (8, 0, 24)
18:34:16 WORKER: args: ()
18:34:16 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0031064190240267975, 'num_filters_1': 61, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.011229370280208711, 'kernel_size_2': 3, 'num_filters_2': 88}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:34:56 DISPATCHER: Starting worker discovery
18:34:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:34:56 DISPATCHER: Finished worker discovery
18:35:09 WORKER: done with job (8, 0, 24), trying to register it.
18:35:09 WORKER: registered result for job (8, 0, 24) with dispatcher
18:35:09 DISPATCHER: job (8, 0, 24) finished
18:35:09 DISPATCHER: register_result: lock acquired
18:35:09 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:35:09 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0031064190240267975, 'num_filters_1': 61, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.011229370280208711, 'kernel_size_2': 3, 'num_filters_2': 88}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6138534030994237, 'info': {'music-speech': 0.6138534030994237, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0031064190240267975, 'num_filters_1': 61, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.011229370280208711, 'kernel_size_2': 3, 'num_filters_2': 88}"}}
exception: None

18:35:09 job_callback for (8, 0, 24) started
18:35:09 DISPATCHER: Trying to submit another job.
18:35:09 job_callback for (8, 0, 24) got condition
18:35:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:35:09 HBMASTER: Trying to run another job!
18:35:09 job_callback for (8, 0, 24) finished
18:35:09 start sampling a new configuration.
18:35:09 best_vector: [3, 2, 0.7727647855896439, 0.11304870795761546, 0.7950986084237813, 0, 0.8753112547122432, 0.5964217417437772, 1, 0, 0, 0, 0.3998987761493277, 0.19356379356050954, 0.5925758492943985, 0.572356107707672], 3.2826858974560757e-28, 3.0462859720296483e-05, -0.00022363383746290666
18:35:09 done sampling a new configuration.
18:35:10 HBMASTER: schedule new run for iteration 8
18:35:10 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
18:35:10 HBMASTER: submitting job (8, 0, 25) to dispatcher
18:35:10 DISPATCHER: trying to submit job (8, 0, 25)
18:35:10 DISPATCHER: trying to notify the job_runner thread.
18:35:10 HBMASTER: job (8, 0, 25) submitted to dispatcher
18:35:10 DISPATCHER: Trying to submit another job.
18:35:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:35:10 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:35:10 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:35:10 WORKER: start processing job (8, 0, 25)
18:35:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:35:10 WORKER: args: ()
18:35:10 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.03511798355922311, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.059698384121168985, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 36, 'num_filters_3': 23, 'num_filters_4': 54}, 'budget': 44.44444444444444, 'working_directory': '.'}
18:35:56 DISPATCHER: Starting worker discovery
18:35:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:35:56 DISPATCHER: Finished worker discovery
18:36:06 WORKER: done with job (8, 0, 25), trying to register it.
18:36:06 DISPATCHER: job (8, 0, 25) finished
18:36:06 WORKER: registered result for job (8, 0, 25) with dispatcher
18:36:06 DISPATCHER: register_result: lock acquired
18:36:06 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:36:06 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.03511798355922311, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.059698384121168985, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 36, 'num_filters_3': 23, 'num_filters_4': 54}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.03511798355922311, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.059698384121168985, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 36, 'num_filters_3': 23, 'num_filters_4': 54}"}}
exception: None

18:36:06 job_callback for (8, 0, 25) started
18:36:06 DISPATCHER: Trying to submit another job.
18:36:06 job_callback for (8, 0, 25) got condition
18:36:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:36:06 HBMASTER: Trying to run another job!
18:36:06 job_callback for (8, 0, 25) finished
18:36:06 start sampling a new configuration.
18:36:06 done sampling a new configuration.
18:36:06 HBMASTER: schedule new run for iteration 8
18:36:06 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
18:36:06 HBMASTER: submitting job (8, 0, 26) to dispatcher
18:36:06 DISPATCHER: trying to submit job (8, 0, 26)
18:36:06 DISPATCHER: trying to notify the job_runner thread.
18:36:06 HBMASTER: job (8, 0, 26) submitted to dispatcher
18:36:06 DISPATCHER: Trying to submit another job.
18:36:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:36:06 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:36:06 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:36:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:36:06 WORKER: start processing job (8, 0, 26)
18:36:06 WORKER: args: ()
18:36:06 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.06422030125791117, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.1547487653534709, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 46, 'num_filters_3': 48}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-366:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

18:36:56 DISPATCHER: Starting worker discovery
18:36:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:36:56 DISPATCHER: Finished worker discovery
18:37:00 WORKER: done with job (8, 0, 26), trying to register it.
18:37:00 WORKER: registered result for job (8, 0, 26) with dispatcher
18:37:00 DISPATCHER: job (8, 0, 26) finished
18:37:00 DISPATCHER: register_result: lock acquired
18:37:00 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:37:00 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.06422030125791117, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.1547487653534709, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 46, 'num_filters_3': 48}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2717652153114558, 'info': {'music-speech': 0.2717652153114558, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.06422030125791117, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.1547487653534709, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 46, 'num_filters_3': 48}"}}
exception: None

18:37:00 job_callback for (8, 0, 26) started
18:37:00 DISPATCHER: Trying to submit another job.
18:37:00 job_callback for (8, 0, 26) got condition
18:37:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:37:00 HBMASTER: Trying to run another job!
18:37:00 job_callback for (8, 0, 26) finished
18:37:00 ITERATION: Advancing config (8, 0, 2) to next budget 133.333333
18:37:00 ITERATION: Advancing config (8, 0, 4) to next budget 133.333333
18:37:00 ITERATION: Advancing config (8, 0, 5) to next budget 133.333333
18:37:00 ITERATION: Advancing config (8, 0, 7) to next budget 133.333333
18:37:00 ITERATION: Advancing config (8, 0, 10) to next budget 133.333333
18:37:00 ITERATION: Advancing config (8, 0, 11) to next budget 133.333333
18:37:00 ITERATION: Advancing config (8, 0, 12) to next budget 133.333333
18:37:00 ITERATION: Advancing config (8, 0, 15) to next budget 133.333333
18:37:00 ITERATION: Advancing config (8, 0, 18) to next budget 133.333333
18:37:00 HBMASTER: schedule new run for iteration 8
18:37:00 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
18:37:00 HBMASTER: submitting job (8, 0, 2) to dispatcher
18:37:00 DISPATCHER: trying to submit job (8, 0, 2)
18:37:00 DISPATCHER: trying to notify the job_runner thread.
18:37:00 HBMASTER: job (8, 0, 2) submitted to dispatcher
18:37:00 DISPATCHER: Trying to submit another job.
18:37:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:37:00 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:37:00 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:37:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:37:00 WORKER: start processing job (8, 0, 2)
18:37:00 WORKER: args: ()
18:37:00 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.009561084461302053, 'num_filters_1': 17, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.04622811171657652, 'kernel_size_2': 7, 'num_filters_2': 100}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:37:56 DISPATCHER: Starting worker discovery
18:37:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:37:56 DISPATCHER: Finished worker discovery
18:38:56 DISPATCHER: Starting worker discovery
18:38:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:38:56 DISPATCHER: Finished worker discovery
18:39:22 WORKER: done with job (8, 0, 2), trying to register it.
18:39:22 WORKER: registered result for job (8, 0, 2) with dispatcher
18:39:22 DISPATCHER: job (8, 0, 2) finished
18:39:22 DISPATCHER: register_result: lock acquired
18:39:22 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:39:22 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.009561084461302053, 'num_filters_1': 17, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.04622811171657652, 'kernel_size_2': 7, 'num_filters_2': 100}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8860766647651781, 'info': {'music-speech': 0.8860766647651781, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.009561084461302053, 'num_filters_1': 17, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.04622811171657652, 'kernel_size_2': 7, 'num_filters_2': 100}"}}
exception: None

18:39:22 job_callback for (8, 0, 2) started
18:39:22 job_callback for (8, 0, 2) got condition
18:39:22 DISPATCHER: Trying to submit another job.
18:39:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:39:22 done building a new model for budget 133.333333 based on 17/31 split
Best loss for this budget:-0.992776





18:39:22 HBMASTER: Trying to run another job!
18:39:22 job_callback for (8, 0, 2) finished
18:39:22 HBMASTER: schedule new run for iteration 8
18:39:22 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
18:39:22 HBMASTER: submitting job (8, 0, 4) to dispatcher
18:39:22 DISPATCHER: trying to submit job (8, 0, 4)
18:39:22 DISPATCHER: trying to notify the job_runner thread.
18:39:22 HBMASTER: job (8, 0, 4) submitted to dispatcher
18:39:22 DISPATCHER: Trying to submit another job.
18:39:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:39:22 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:39:22 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:39:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:39:22 WORKER: start processing job (8, 0, 4)
18:39:22 WORKER: args: ()
18:39:22 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005425010115739717, 'num_filters_1': 77, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.0441736721928722}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:39:56 DISPATCHER: Starting worker discovery
18:39:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:39:56 DISPATCHER: Finished worker discovery
18:40:56 DISPATCHER: Starting worker discovery
18:40:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:40:56 DISPATCHER: Finished worker discovery
18:41:45 WORKER: done with job (8, 0, 4), trying to register it.
18:41:45 WORKER: registered result for job (8, 0, 4) with dispatcher
18:41:45 DISPATCHER: job (8, 0, 4) finished
18:41:45 DISPATCHER: register_result: lock acquired
18:41:45 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:41:45 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005425010115739717, 'num_filters_1': 77, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.0441736721928722}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8930833919681687, 'info': {'music-speech': 0.8930833919681687, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005425010115739717, 'num_filters_1': 77, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.0441736721928722}"}}
exception: None

18:41:45 job_callback for (8, 0, 4) started
18:41:45 DISPATCHER: Trying to submit another job.
18:41:45 job_callback for (8, 0, 4) got condition
18:41:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:41:45 done building a new model for budget 133.333333 based on 17/32 split
Best loss for this budget:-0.992776





18:41:45 HBMASTER: Trying to run another job!
18:41:45 job_callback for (8, 0, 4) finished
18:41:45 HBMASTER: schedule new run for iteration 8
18:41:45 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
18:41:45 HBMASTER: submitting job (8, 0, 5) to dispatcher
18:41:45 DISPATCHER: trying to submit job (8, 0, 5)
18:41:45 DISPATCHER: trying to notify the job_runner thread.
18:41:45 HBMASTER: job (8, 0, 5) submitted to dispatcher
18:41:45 DISPATCHER: Trying to submit another job.
18:41:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:41:45 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:41:45 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:41:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:41:45 WORKER: start processing job (8, 0, 5)
18:41:45 WORKER: args: ()
18:41:45 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003338840902622378, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.036479060024820924, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 30, 'num_filters_3': 30, 'num_filters_4': 16, 'num_filters_5': 86}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:41:56 DISPATCHER: Starting worker discovery
18:41:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:41:56 DISPATCHER: Finished worker discovery
18:42:56 DISPATCHER: Starting worker discovery
18:42:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:42:56 DISPATCHER: Finished worker discovery
18:43:56 DISPATCHER: Starting worker discovery
18:43:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:43:56 DISPATCHER: Finished worker discovery
18:44:07 WORKER: done with job (8, 0, 5), trying to register it.
18:44:07 WORKER: registered result for job (8, 0, 5) with dispatcher
18:44:07 DISPATCHER: job (8, 0, 5) finished
18:44:07 DISPATCHER: register_result: lock acquired
18:44:07 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:44:07 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003338840902622378, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.036479060024820924, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 30, 'num_filters_3': 30, 'num_filters_4': 16, 'num_filters_5': 86}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9302213150120567, 'info': {'music-speech': 0.9302213150120567, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003338840902622378, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.036479060024820924, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 30, 'num_filters_3': 30, 'num_filters_4': 16, 'num_filters_5': 86}"}}
exception: None

18:44:07 job_callback for (8, 0, 5) started
18:44:07 DISPATCHER: Trying to submit another job.
18:44:07 job_callback for (8, 0, 5) got condition
18:44:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:44:07 done building a new model for budget 133.333333 based on 17/33 split
Best loss for this budget:-0.992776





18:44:07 HBMASTER: Trying to run another job!
18:44:07 job_callback for (8, 0, 5) finished
18:44:07 HBMASTER: schedule new run for iteration 8
18:44:07 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
18:44:07 HBMASTER: submitting job (8, 0, 7) to dispatcher
18:44:07 DISPATCHER: trying to submit job (8, 0, 7)
18:44:07 DISPATCHER: trying to notify the job_runner thread.
18:44:07 HBMASTER: job (8, 0, 7) submitted to dispatcher
18:44:07 DISPATCHER: Trying to submit another job.
18:44:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:44:07 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:44:07 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:44:07 WORKER: start processing job (8, 0, 7)
18:44:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:44:07 WORKER: args: ()
18:44:07 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0025409467612593937, 'num_filters_1': 26, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.06249060944055022, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 17, 'num_filters_3': 35, 'num_filters_4': 40, 'num_filters_5': 125}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:44:56 DISPATCHER: Starting worker discovery
18:44:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:44:56 DISPATCHER: Finished worker discovery
18:45:56 DISPATCHER: Starting worker discovery
18:45:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:45:56 DISPATCHER: Finished worker discovery
18:46:31 WORKER: done with job (8, 0, 7), trying to register it.
18:46:31 WORKER: registered result for job (8, 0, 7) with dispatcher
18:46:31 DISPATCHER: job (8, 0, 7) finished
18:46:31 DISPATCHER: register_result: lock acquired
18:46:31 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:46:31 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0025409467612593937, 'num_filters_1': 26, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.06249060944055022, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 17, 'num_filters_3': 35, 'num_filters_4': 40, 'num_filters_5': 125}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8984660983666243, 'info': {'music-speech': 0.8984660983666243, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0025409467612593937, 'num_filters_1': 26, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.06249060944055022, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 17, 'num_filters_3': 35, 'num_filters_4': 40, 'num_filters_5': 125}"}}
exception: None

18:46:31 job_callback for (8, 0, 7) started
18:46:31 DISPATCHER: Trying to submit another job.
18:46:31 job_callback for (8, 0, 7) got condition
18:46:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:46:31 done building a new model for budget 133.333333 based on 17/34 split
Best loss for this budget:-0.992776





18:46:31 HBMASTER: Trying to run another job!
18:46:31 job_callback for (8, 0, 7) finished
18:46:31 HBMASTER: schedule new run for iteration 8
18:46:31 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
18:46:31 HBMASTER: submitting job (8, 0, 10) to dispatcher
18:46:31 DISPATCHER: trying to submit job (8, 0, 10)
18:46:31 DISPATCHER: trying to notify the job_runner thread.
18:46:31 HBMASTER: job (8, 0, 10) submitted to dispatcher
18:46:31 DISPATCHER: Trying to submit another job.
18:46:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:46:31 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:46:31 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:46:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:46:31 WORKER: start processing job (8, 0, 10)
18:46:31 WORKER: args: ()
18:46:31 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0011661296088553948, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.04518477723280045, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 124, 'num_filters_3': 25, 'num_filters_4': 73}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:46:56 DISPATCHER: Starting worker discovery
18:46:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:46:56 DISPATCHER: Finished worker discovery
18:47:56 DISPATCHER: Starting worker discovery
18:47:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:47:56 DISPATCHER: Finished worker discovery
18:48:54 WORKER: done with job (8, 0, 10), trying to register it.
18:48:54 WORKER: registered result for job (8, 0, 10) with dispatcher
18:48:54 DISPATCHER: job (8, 0, 10) finished
18:48:54 DISPATCHER: register_result: lock acquired
18:48:54 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:48:54 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0011661296088553948, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.04518477723280045, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 124, 'num_filters_3': 25, 'num_filters_4': 73}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9298837104964126, 'info': {'music-speech': 0.9298837104964126, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0011661296088553948, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.04518477723280045, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 124, 'num_filters_3': 25, 'num_filters_4': 73}"}}
exception: None

18:48:54 job_callback for (8, 0, 10) started
18:48:54 DISPATCHER: Trying to submit another job.
18:48:54 job_callback for (8, 0, 10) got condition
18:48:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:48:54 done building a new model for budget 133.333333 based on 17/34 split
Best loss for this budget:-0.992776





18:48:54 HBMASTER: Trying to run another job!
18:48:54 job_callback for (8, 0, 10) finished
18:48:54 HBMASTER: schedule new run for iteration 8
18:48:54 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
18:48:54 HBMASTER: submitting job (8, 0, 11) to dispatcher
18:48:54 DISPATCHER: trying to submit job (8, 0, 11)
18:48:54 DISPATCHER: trying to notify the job_runner thread.
18:48:54 HBMASTER: job (8, 0, 11) submitted to dispatcher
18:48:54 DISPATCHER: Trying to submit another job.
18:48:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:48:54 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:48:54 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:48:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:48:54 WORKER: start processing job (8, 0, 11)
18:48:54 WORKER: args: ()
18:48:54 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0044517015030343995, 'num_filters_1': 54, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.021137719274502607}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:48:56 DISPATCHER: Starting worker discovery
18:48:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:48:56 DISPATCHER: Finished worker discovery
18:49:56 DISPATCHER: Starting worker discovery
18:49:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:49:56 DISPATCHER: Finished worker discovery
18:50:56 DISPATCHER: Starting worker discovery
18:50:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:50:56 DISPATCHER: Finished worker discovery
18:51:16 WORKER: done with job (8, 0, 11), trying to register it.
18:51:16 WORKER: registered result for job (8, 0, 11) with dispatcher
18:51:16 DISPATCHER: job (8, 0, 11) finished
18:51:16 DISPATCHER: register_result: lock acquired
18:51:16 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:51:16 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0044517015030343995, 'num_filters_1': 54, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.021137719274502607}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9767659058213298, 'info': {'music-speech': 0.9767659058213298, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0044517015030343995, 'num_filters_1': 54, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.021137719274502607}"}}
exception: None

18:51:16 job_callback for (8, 0, 11) started
18:51:16 DISPATCHER: Trying to submit another job.
18:51:16 job_callback for (8, 0, 11) got condition
18:51:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:51:16 done building a new model for budget 133.333333 based on 17/35 split
Best loss for this budget:-0.992776





18:51:16 HBMASTER: Trying to run another job!
18:51:16 job_callback for (8, 0, 11) finished
18:51:16 HBMASTER: schedule new run for iteration 8
18:51:16 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
18:51:16 HBMASTER: submitting job (8, 0, 12) to dispatcher
18:51:16 DISPATCHER: trying to submit job (8, 0, 12)
18:51:16 DISPATCHER: trying to notify the job_runner thread.
18:51:16 HBMASTER: job (8, 0, 12) submitted to dispatcher
18:51:16 DISPATCHER: Trying to submit another job.
18:51:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:51:16 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:51:16 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:51:16 WORKER: start processing job (8, 0, 12)
18:51:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:51:16 WORKER: args: ()
18:51:16 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004928668966317219, 'num_filters_1': 61, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.08510312548985119, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 26, 'num_filters_3': 111}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:51:56 DISPATCHER: Starting worker discovery
18:51:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:51:56 DISPATCHER: Finished worker discovery
18:52:56 DISPATCHER: Starting worker discovery
18:52:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:52:56 DISPATCHER: Finished worker discovery
18:53:39 WORKER: done with job (8, 0, 12), trying to register it.
18:53:39 WORKER: registered result for job (8, 0, 12) with dispatcher
18:53:39 DISPATCHER: job (8, 0, 12) finished
18:53:39 DISPATCHER: register_result: lock acquired
18:53:39 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:53:39 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004928668966317219, 'num_filters_1': 61, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.08510312548985119, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 26, 'num_filters_3': 111}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9043320290210838, 'info': {'music-speech': 0.9043320290210838, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004928668966317219, 'num_filters_1': 61, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 18, 'weight_decay': 0.08510312548985119, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 26, 'num_filters_3': 111}"}}
exception: None

18:53:39 job_callback for (8, 0, 12) started
18:53:39 DISPATCHER: Trying to submit another job.
18:53:39 job_callback for (8, 0, 12) got condition
18:53:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:53:39 done building a new model for budget 133.333333 based on 17/36 split
Best loss for this budget:-0.992776





18:53:39 HBMASTER: Trying to run another job!
18:53:39 job_callback for (8, 0, 12) finished
18:53:39 HBMASTER: schedule new run for iteration 8
18:53:39 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
18:53:39 HBMASTER: submitting job (8, 0, 15) to dispatcher
18:53:39 DISPATCHER: trying to submit job (8, 0, 15)
18:53:39 DISPATCHER: trying to notify the job_runner thread.
18:53:39 HBMASTER: job (8, 0, 15) submitted to dispatcher
18:53:39 DISPATCHER: Trying to submit another job.
18:53:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:53:39 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:53:39 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:53:39 WORKER: start processing job (8, 0, 15)
18:53:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:53:39 WORKER: args: ()
18:53:39 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.010865384738435556, 'num_filters_1': 34, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.027969372290876406, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 125, 'num_filters_3': 23, 'num_filters_4': 89, 'num_filters_5': 19}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:53:56 DISPATCHER: Starting worker discovery
18:53:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:53:56 DISPATCHER: Finished worker discovery
18:54:56 DISPATCHER: Starting worker discovery
18:54:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:54:56 DISPATCHER: Finished worker discovery
18:55:56 DISPATCHER: Starting worker discovery
18:55:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:55:56 DISPATCHER: Finished worker discovery
18:56:01 WORKER: done with job (8, 0, 15), trying to register it.
18:56:01 WORKER: registered result for job (8, 0, 15) with dispatcher
18:56:01 DISPATCHER: job (8, 0, 15) finished
18:56:01 DISPATCHER: register_result: lock acquired
18:56:01 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:56:01 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.010865384738435556, 'num_filters_1': 34, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.027969372290876406, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 125, 'num_filters_3': 23, 'num_filters_4': 89, 'num_filters_5': 19}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9406576055529146, 'info': {'music-speech': 0.9406576055529146, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.010865384738435556, 'num_filters_1': 34, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.027969372290876406, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 125, 'num_filters_3': 23, 'num_filters_4': 89, 'num_filters_5': 19}"}}
exception: None

18:56:01 job_callback for (8, 0, 15) started
18:56:01 DISPATCHER: Trying to submit another job.
18:56:01 job_callback for (8, 0, 15) got condition
18:56:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:56:01 done building a new model for budget 133.333333 based on 17/37 split
Best loss for this budget:-0.992776





18:56:01 HBMASTER: Trying to run another job!
18:56:01 job_callback for (8, 0, 15) finished
18:56:01 HBMASTER: schedule new run for iteration 8
18:56:01 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
18:56:01 HBMASTER: submitting job (8, 0, 18) to dispatcher
18:56:01 DISPATCHER: trying to submit job (8, 0, 18)
18:56:01 DISPATCHER: trying to notify the job_runner thread.
18:56:01 HBMASTER: job (8, 0, 18) submitted to dispatcher
18:56:01 DISPATCHER: Trying to submit another job.
18:56:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:56:01 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:56:01 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:56:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:56:01 WORKER: start processing job (8, 0, 18)
18:56:01 WORKER: args: ()
18:56:01 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0017138783811094782, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.047749930250916645, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 95, 'num_filters_3': 43, 'num_filters_4': 26, 'num_filters_5': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
18:56:56 DISPATCHER: Starting worker discovery
18:56:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:56:56 DISPATCHER: Finished worker discovery
18:57:56 DISPATCHER: Starting worker discovery
18:57:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:57:56 DISPATCHER: Finished worker discovery
18:58:23 WORKER: done with job (8, 0, 18), trying to register it.
18:58:23 WORKER: registered result for job (8, 0, 18) with dispatcher
18:58:23 DISPATCHER: job (8, 0, 18) finished
18:58:23 DISPATCHER: register_result: lock acquired
18:58:23 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:58:23 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0017138783811094782, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.047749930250916645, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 95, 'num_filters_3': 43, 'num_filters_4': 26, 'num_filters_5': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8926251368540798, 'info': {'music-speech': 0.8926251368540798, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0017138783811094782, 'num_filters_1': 16, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.047749930250916645, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 95, 'num_filters_3': 43, 'num_filters_4': 26, 'num_filters_5': 26}"}}
exception: None

18:58:23 job_callback for (8, 0, 18) started
18:58:23 DISPATCHER: Trying to submit another job.
18:58:23 job_callback for (8, 0, 18) got condition
18:58:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:58:23 done building a new model for budget 133.333333 based on 17/38 split
Best loss for this budget:-0.992776





18:58:23 HBMASTER: Trying to run another job!
18:58:23 job_callback for (8, 0, 18) finished
18:58:23 ITERATION: Advancing config (8, 0, 5) to next budget 400.000000
18:58:23 ITERATION: Advancing config (8, 0, 11) to next budget 400.000000
18:58:23 ITERATION: Advancing config (8, 0, 15) to next budget 400.000000
18:58:23 HBMASTER: schedule new run for iteration 8
18:58:23 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
18:58:23 HBMASTER: submitting job (8, 0, 5) to dispatcher
18:58:23 DISPATCHER: trying to submit job (8, 0, 5)
18:58:23 DISPATCHER: trying to notify the job_runner thread.
18:58:23 HBMASTER: job (8, 0, 5) submitted to dispatcher
18:58:23 DISPATCHER: Trying to submit another job.
18:58:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:58:23 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:58:23 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:58:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:58:23 WORKER: start processing job (8, 0, 5)
18:58:23 WORKER: args: ()
18:58:23 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003338840902622378, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.036479060024820924, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 30, 'num_filters_3': 30, 'num_filters_4': 16, 'num_filters_5': 86}, 'budget': 400.0, 'working_directory': '.'}
18:58:56 DISPATCHER: Starting worker discovery
18:58:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:58:56 DISPATCHER: Finished worker discovery
18:59:56 DISPATCHER: Starting worker discovery
18:59:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:59:56 DISPATCHER: Finished worker discovery
19:00:56 DISPATCHER: Starting worker discovery
19:00:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:00:56 DISPATCHER: Finished worker discovery
19:01:56 DISPATCHER: Starting worker discovery
19:01:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:01:56 DISPATCHER: Finished worker discovery
19:02:56 DISPATCHER: Starting worker discovery
19:02:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:02:56 DISPATCHER: Finished worker discovery
19:03:56 DISPATCHER: Starting worker discovery
19:03:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:03:56 DISPATCHER: Finished worker discovery
19:04:56 DISPATCHER: Starting worker discovery
19:04:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:04:56 DISPATCHER: Finished worker discovery
19:05:12 WORKER: done with job (8, 0, 5), trying to register it.
19:05:12 WORKER: registered result for job (8, 0, 5) with dispatcher
19:05:12 DISPATCHER: job (8, 0, 5) finished
19:05:12 DISPATCHER: register_result: lock acquired
19:05:12 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
19:05:12 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003338840902622378, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.036479060024820924, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 30, 'num_filters_3': 30, 'num_filters_4': 16, 'num_filters_5': 86}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9938674183898306, 'info': {'music-speech': 0.9938674183898306, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003338840902622378, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.036479060024820924, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 30, 'num_filters_3': 30, 'num_filters_4': 16, 'num_filters_5': 86}"}}
exception: None

19:05:12 job_callback for (8, 0, 5) started
19:05:12 DISPATCHER: Trying to submit another job.
19:05:12 job_callback for (8, 0, 5) got condition
19:05:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:05:12 HBMASTER: Trying to run another job!
19:05:12 job_callback for (8, 0, 5) finished
19:05:12 HBMASTER: schedule new run for iteration 8
19:05:12 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
19:05:12 HBMASTER: submitting job (8, 0, 11) to dispatcher
19:05:12 DISPATCHER: trying to submit job (8, 0, 11)
19:05:12 DISPATCHER: trying to notify the job_runner thread.
19:05:12 HBMASTER: job (8, 0, 11) submitted to dispatcher
19:05:12 DISPATCHER: Trying to submit another job.
19:05:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:05:12 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpul.22021139727314577216
19:05:12 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
19:05:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:05:12 WORKER: start processing job (8, 0, 11)
19:05:12 WORKER: args: ()
19:05:12 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0044517015030343995, 'num_filters_1': 54, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.021137719274502607}, 'budget': 400.0, 'working_directory': '.'}
19:05:56 DISPATCHER: Starting worker discovery
19:05:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:05:56 DISPATCHER: Finished worker discovery
19:06:56 DISPATCHER: Starting worker discovery
19:06:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:06:56 DISPATCHER: Finished worker discovery
19:07:56 DISPATCHER: Starting worker discovery
19:07:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:07:56 DISPATCHER: Finished worker discovery
19:08:56 DISPATCHER: Starting worker discovery
19:08:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:08:56 DISPATCHER: Finished worker discovery
19:09:56 DISPATCHER: Starting worker discovery
19:09:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:09:56 DISPATCHER: Finished worker discovery
19:10:56 DISPATCHER: Starting worker discovery
19:10:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:10:56 DISPATCHER: Finished worker discovery
19:11:56 DISPATCHER: Starting worker discovery
19:11:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:11:56 DISPATCHER: Finished worker discovery
19:12:02 WORKER: done with job (8, 0, 11), trying to register it.
19:12:02 WORKER: registered result for job (8, 0, 11) with dispatcher
19:12:02 DISPATCHER: job (8, 0, 11) finished
19:12:02 DISPATCHER: register_result: lock acquired
19:12:02 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
19:12:02 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0044517015030343995, 'num_filters_1': 54, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.021137719274502607}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9677219195727655, 'info': {'music-speech': 0.9677219195727655, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0044517015030343995, 'num_filters_1': 54, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.021137719274502607}"}}
exception: None

19:12:02 job_callback for (8, 0, 11) started
19:12:02 DISPATCHER: Trying to submit another job.
19:12:02 job_callback for (8, 0, 11) got condition
19:12:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:12:02 HBMASTER: Trying to run another job!
19:12:02 job_callback for (8, 0, 11) finished
19:12:02 HBMASTER: schedule new run for iteration 8
19:12:02 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
19:12:02 HBMASTER: submitting job (8, 0, 15) to dispatcher
19:12:02 DISPATCHER: trying to submit job (8, 0, 15)
19:12:02 DISPATCHER: trying to notify the job_runner thread.
19:12:02 HBMASTER: job (8, 0, 15) submitted to dispatcher
19:12:02 DISPATCHER: Trying to submit another job.
19:12:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:12:02 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216
19:12:02 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
19:12:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:12:02 WORKER: start processing job (8, 0, 15)
19:12:02 WORKER: args: ()
19:12:02 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.010865384738435556, 'num_filters_1': 34, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.027969372290876406, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 125, 'num_filters_3': 23, 'num_filters_4': 89, 'num_filters_5': 19}, 'budget': 400.0, 'working_directory': '.'}
19:12:56 DISPATCHER: Starting worker discovery
19:12:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:12:56 DISPATCHER: Finished worker discovery
19:13:56 DISPATCHER: Starting worker discovery
19:13:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:13:57 DISPATCHER: Finished worker discovery
19:14:57 DISPATCHER: Starting worker discovery
19:14:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:14:57 DISPATCHER: Finished worker discovery
19:15:57 DISPATCHER: Starting worker discovery
19:15:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:15:57 DISPATCHER: Finished worker discovery
19:16:57 DISPATCHER: Starting worker discovery
19:16:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:16:57 DISPATCHER: Finished worker discovery
19:17:57 DISPATCHER: Starting worker discovery
19:17:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:17:57 DISPATCHER: Finished worker discovery
19:18:52 WORKER: done with job (8, 0, 15), trying to register it.
19:18:52 WORKER: registered result for job (8, 0, 15) with dispatcher
19:18:52 DISPATCHER: job (8, 0, 15) finished
19:18:52 DISPATCHER: register_result: lock acquired
19:18:52 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
19:18:52 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.010865384738435556, 'num_filters_1': 34, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.027969372290876406, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 125, 'num_filters_3': 23, 'num_filters_4': 89, 'num_filters_5': 19}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.353374219243598, 'info': {'music-speech': 0.353374219243598, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.010865384738435556, 'num_filters_1': 34, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.027969372290876406, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 125, 'num_filters_3': 23, 'num_filters_4': 89, 'num_filters_5': 19}"}}
exception: None

19:18:52 job_callback for (8, 0, 15) started
19:18:52 DISPATCHER: Trying to submit another job.
19:18:52 job_callback for (8, 0, 15) got condition
19:18:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:18:52 HBMASTER: Trying to run another job!
19:18:52 job_callback for (8, 0, 15) finished
19:18:52 ITERATION: Advancing config (8, 0, 5) to next budget 1200.000000
19:18:52 HBMASTER: schedule new run for iteration 8
19:18:52 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
19:18:52 HBMASTER: submitting job (8, 0, 5) to dispatcher
19:18:52 DISPATCHER: trying to submit job (8, 0, 5)
19:18:52 DISPATCHER: trying to notify the job_runner thread.
19:18:52 HBMASTER: job (8, 0, 5) submitted to dispatcher
19:18:52 DISPATCHER: Trying to submit another job.
19:18:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:18:52 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
19:18:52 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
19:18:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:18:52 WORKER: start processing job (8, 0, 5)
19:18:52 WORKER: args: ()
19:18:52 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003338840902622378, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.036479060024820924, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 30, 'num_filters_3': 30, 'num_filters_4': 16, 'num_filters_5': 86}, 'budget': 1200.0, 'working_directory': '.'}
19:18:57 DISPATCHER: Starting worker discovery
19:18:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:18:57 DISPATCHER: Finished worker discovery
19:19:57 DISPATCHER: Starting worker discovery
19:19:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:19:57 DISPATCHER: Finished worker discovery
19:20:57 DISPATCHER: Starting worker discovery
19:20:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:20:57 DISPATCHER: Finished worker discovery
19:21:57 DISPATCHER: Starting worker discovery
19:21:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:21:57 DISPATCHER: Finished worker discovery
19:22:57 DISPATCHER: Starting worker discovery
19:22:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:22:57 DISPATCHER: Finished worker discovery
19:23:57 DISPATCHER: Starting worker discovery
19:23:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:23:57 DISPATCHER: Finished worker discovery
19:24:57 DISPATCHER: Starting worker discovery
19:24:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:24:57 DISPATCHER: Finished worker discovery
19:25:57 DISPATCHER: Starting worker discovery
19:25:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:25:57 DISPATCHER: Finished worker discovery
19:26:57 DISPATCHER: Starting worker discovery
19:26:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:26:57 DISPATCHER: Finished worker discovery
19:27:57 DISPATCHER: Starting worker discovery
19:27:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:27:57 DISPATCHER: Finished worker discovery
19:28:57 DISPATCHER: Starting worker discovery
19:28:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:28:57 DISPATCHER: Finished worker discovery
19:29:57 DISPATCHER: Starting worker discovery
19:29:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:29:57 DISPATCHER: Finished worker discovery
19:30:57 DISPATCHER: Starting worker discovery
19:30:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:30:57 DISPATCHER: Finished worker discovery
19:31:57 DISPATCHER: Starting worker discovery
19:31:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:31:57 DISPATCHER: Finished worker discovery
19:32:57 DISPATCHER: Starting worker discovery
19:32:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:32:57 DISPATCHER: Finished worker discovery
19:33:57 DISPATCHER: Starting worker discovery
19:33:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:33:57 DISPATCHER: Finished worker discovery
19:34:57 DISPATCHER: Starting worker discovery
19:34:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:34:57 DISPATCHER: Finished worker discovery
19:35:57 DISPATCHER: Starting worker discovery
19:35:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:35:57 DISPATCHER: Finished worker discovery
19:36:57 DISPATCHER: Starting worker discovery
19:36:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:36:57 DISPATCHER: Finished worker discovery
19:37:57 DISPATCHER: Starting worker discovery
19:37:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:37:57 DISPATCHER: Finished worker discovery
19:38:57 DISPATCHER: Starting worker discovery
19:38:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:38:57 DISPATCHER: Finished worker discovery
19:39:02 WORKER: done with job (8, 0, 5), trying to register it.
19:39:02 DISPATCHER: job (8, 0, 5) finished
19:39:02 WORKER: registered result for job (8, 0, 5) with dispatcher
19:39:02 DISPATCHER: register_result: lock acquired
19:39:02 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
19:39:02 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003338840902622378, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.036479060024820924, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 30, 'num_filters_3': 30, 'num_filters_4': 16, 'num_filters_5': 86}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.9340057883564306, 'info': {'music-speech': 0.9340057883564306, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003338840902622378, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 28, 'weight_decay': 0.036479060024820924, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 5, 'num_filters_2': 30, 'num_filters_3': 30, 'num_filters_4': 16, 'num_filters_5': 86}"}}
exception: None

19:39:02 job_callback for (8, 0, 5) started
19:39:02 DISPATCHER: Trying to submit another job.
19:39:02 job_callback for (8, 0, 5) got condition
19:39:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:39:02 HBMASTER: Trying to run another job!
19:39:02 job_callback for (8, 0, 5) finished
19:39:02 start sampling a new configuration.
19:39:02 done sampling a new configuration.
19:39:02 HBMASTER: schedule new run for iteration 9
19:39:02 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
19:39:02 HBMASTER: submitting job (9, 0, 0) to dispatcher
19:39:02 DISPATCHER: trying to submit job (9, 0, 0)
19:39:02 DISPATCHER: trying to notify the job_runner thread.
19:39:02 HBMASTER: job (9, 0, 0) submitted to dispatcher
19:39:02 DISPATCHER: Trying to submit another job.
19:39:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:39:02 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
19:39:02 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
19:39:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:39:02 WORKER: start processing job (9, 0, 0)
19:39:02 WORKER: args: ()
19:39:02 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0014379591371020746, 'num_filters_1': 43, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.013654886578901022, 'kernel_size_2': 3, 'num_filters_2': 70}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:39:57 DISPATCHER: Starting worker discovery
19:39:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:39:57 DISPATCHER: Finished worker discovery
19:40:57 DISPATCHER: Starting worker discovery
19:40:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:40:57 DISPATCHER: Finished worker discovery
19:41:25 WORKER: done with job (9, 0, 0), trying to register it.
19:41:25 WORKER: registered result for job (9, 0, 0) with dispatcher
19:41:25 DISPATCHER: job (9, 0, 0) finished
19:41:25 DISPATCHER: register_result: lock acquired
19:41:25 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
19:41:25 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0014379591371020746, 'num_filters_1': 43, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.013654886578901022, 'kernel_size_2': 3, 'num_filters_2': 70}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7296437877766674, 'info': {'music-speech': 0.7296437877766674, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.0014379591371020746, 'num_filters_1': 43, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.013654886578901022, 'kernel_size_2': 3, 'num_filters_2': 70}"}}
exception: None

19:41:25 job_callback for (9, 0, 0) started
19:41:25 DISPATCHER: Trying to submit another job.
19:41:25 job_callback for (9, 0, 0) got condition
19:41:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:41:25 done building a new model for budget 133.333333 based on 17/39 split
Best loss for this budget:-0.992776





19:41:25 HBMASTER: Trying to run another job!
19:41:25 job_callback for (9, 0, 0) finished
19:41:25 start sampling a new configuration.
19:41:25 best_vector: [3, 0, 0.3275174510900512, 0.11788563139007366, 0.3091664587472613, 0, 0.9757993213768807, 0.45263277605994673, 1, 2, 1, 2, 0.05532156080892327, 0.6342750327085491, 0.785326375577429, 0.22457428872378712], 1.1227018336164451e-29, 0.0008907084410638235, -3.365097149640513e-05
19:41:25 done sampling a new configuration.
19:41:25 HBMASTER: schedule new run for iteration 9
19:41:25 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
19:41:25 HBMASTER: submitting job (9, 0, 1) to dispatcher
19:41:25 DISPATCHER: trying to submit job (9, 0, 1)
19:41:25 DISPATCHER: trying to notify the job_runner thread.
19:41:25 HBMASTER: job (9, 0, 1) submitted to dispatcher
19:41:25 DISPATCHER: Trying to submit another job.
19:41:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:41:25 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
19:41:25 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
19:41:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:41:25 WORKER: start processing job (9, 0, 1)
19:41:25 WORKER: args: ()
19:41:25 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.004518922593453756, 'num_filters_1': 20, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.03880510104831519, 'kernel_size_2': 5, 'num_filters_2': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:41:57 DISPATCHER: Starting worker discovery
19:41:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:41:57 DISPATCHER: Finished worker discovery
19:42:57 DISPATCHER: Starting worker discovery
19:42:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:42:57 DISPATCHER: Finished worker discovery
19:43:47 WORKER: done with job (9, 0, 1), trying to register it.
19:43:47 WORKER: registered result for job (9, 0, 1) with dispatcher
19:43:47 DISPATCHER: job (9, 0, 1) finished
19:43:47 DISPATCHER: register_result: lock acquired
19:43:47 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
19:43:47 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.004518922593453756, 'num_filters_1': 20, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.03880510104831519, 'kernel_size_2': 5, 'num_filters_2': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5752862264332107, 'info': {'music-speech': 0.5752862264332107, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.004518922593453756, 'num_filters_1': 20, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.03880510104831519, 'kernel_size_2': 5, 'num_filters_2': 17}"}}
exception: None

19:43:47 job_callback for (9, 0, 1) started
19:43:47 DISPATCHER: Trying to submit another job.
19:43:47 job_callback for (9, 0, 1) got condition
19:43:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:43:47 done building a new model for budget 133.333333 based on 17/39 split
Best loss for this budget:-0.992776





19:43:47 HBMASTER: Trying to run another job!
19:43:47 job_callback for (9, 0, 1) finished
19:43:47 start sampling a new configuration.
19:43:47 done sampling a new configuration.
19:43:47 HBMASTER: schedule new run for iteration 9
19:43:47 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
19:43:47 HBMASTER: submitting job (9, 0, 2) to dispatcher
19:43:47 DISPATCHER: trying to submit job (9, 0, 2)
19:43:47 DISPATCHER: trying to notify the job_runner thread.
19:43:47 HBMASTER: job (9, 0, 2) submitted to dispatcher
19:43:47 DISPATCHER: Trying to submit another job.
19:43:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:43:47 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
19:43:47 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
19:43:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:43:47 WORKER: start processing job (9, 0, 2)
19:43:47 WORKER: args: ()
19:43:47 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0023432580174797663, 'num_filters_1': 121, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.028842478642980278, 'kernel_size_2': 5, 'num_filters_2': 101}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:43:57 DISPATCHER: Starting worker discovery
19:43:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:43:57 DISPATCHER: Finished worker discovery
19:44:57 DISPATCHER: Starting worker discovery
19:44:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:44:57 DISPATCHER: Finished worker discovery
19:45:57 DISPATCHER: Starting worker discovery
19:45:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:45:57 DISPATCHER: Finished worker discovery
19:46:10 WORKER: done with job (9, 0, 2), trying to register it.
19:46:10 WORKER: registered result for job (9, 0, 2) with dispatcher
19:46:10 DISPATCHER: job (9, 0, 2) finished
19:46:10 DISPATCHER: register_result: lock acquired
19:46:10 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
19:46:10 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0023432580174797663, 'num_filters_1': 121, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.028842478642980278, 'kernel_size_2': 5, 'num_filters_2': 101}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9074809072289567, 'info': {'music-speech': 0.9074809072289567, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0023432580174797663, 'num_filters_1': 121, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.028842478642980278, 'kernel_size_2': 5, 'num_filters_2': 101}"}}
exception: None

19:46:10 job_callback for (9, 0, 2) started
19:46:10 DISPATCHER: Trying to submit another job.
19:46:10 job_callback for (9, 0, 2) got condition
19:46:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:46:10 done building a new model for budget 133.333333 based on 17/40 split
Best loss for this budget:-0.992776





19:46:10 HBMASTER: Trying to run another job!
19:46:10 job_callback for (9, 0, 2) finished
19:46:10 start sampling a new configuration.
19:46:10 best_vector: [1, 2, 0.0412610689882914, 0.5678374995978893, 0.006342318874643649, 1, 0.45993519495958, 0.9273671478376281, 1, 1, 2, 1, 0.5507401775615176, 0.0061482963898911724, 0.005794784591757418, 0.05436498929146427], 1.655694265697004e-26, 6.039762417000498e-07, -6.348155755979914e-10
19:46:10 done sampling a new configuration.
19:46:10 HBMASTER: schedule new run for iteration 9
19:46:10 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
19:46:10 HBMASTER: submitting job (9, 0, 3) to dispatcher
19:46:10 DISPATCHER: trying to submit job (9, 0, 3)
19:46:10 DISPATCHER: trying to notify the job_runner thread.
19:46:10 HBMASTER: job (9, 0, 3) submitted to dispatcher
19:46:10 DISPATCHER: Trying to submit another job.
19:46:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:46:10 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
19:46:10 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
19:46:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:46:10 WORKER: start processing job (9, 0, 3)
19:46:10 WORKER: args: ()
19:46:10 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0012092668232343688, 'num_filters_1': 52, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.1608912687098546}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:46:57 DISPATCHER: Starting worker discovery
19:46:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:46:57 DISPATCHER: Finished worker discovery
19:47:57 DISPATCHER: Starting worker discovery
19:47:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:47:57 DISPATCHER: Finished worker discovery
19:48:32 WORKER: done with job (9, 0, 3), trying to register it.
19:48:32 WORKER: registered result for job (9, 0, 3) with dispatcher
19:48:32 DISPATCHER: job (9, 0, 3) finished
19:48:32 DISPATCHER: register_result: lock acquired
19:48:32 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
19:48:32 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0012092668232343688, 'num_filters_1': 52, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.1608912687098546}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5381436511117257, 'info': {'music-speech': 0.5381436511117257, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0012092668232343688, 'num_filters_1': 52, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.1608912687098546}"}}
exception: None

19:48:32 job_callback for (9, 0, 3) started
19:48:32 job_callback for (9, 0, 3) got condition
19:48:32 DISPATCHER: Trying to submit another job.
19:48:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:48:32 done building a new model for budget 133.333333 based on 17/41 split
Best loss for this budget:-0.992776





19:48:32 HBMASTER: Trying to run another job!
19:48:32 job_callback for (9, 0, 3) finished
19:48:32 start sampling a new configuration.
19:48:32 best_vector: [3, 0, 0.5861795965010919, 0.47353240144575326, 0.4037731521651485, 1, 0.8650545793587427, 0.010067316114205305, 0, 0, 2, 2, 0.19612829991766673, 0.24064227324693116, 0.3261400193762149, 0.23541664449132638], 6.87427604142777e-28, 1.4546986387708437e-05, -3.128812280366853e-05
19:48:32 done sampling a new configuration.
19:48:32 HBMASTER: schedule new run for iteration 9
19:48:32 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
19:48:32 HBMASTER: submitting job (9, 0, 4) to dispatcher
19:48:32 DISPATCHER: trying to submit job (9, 0, 4)
19:48:32 DISPATCHER: trying to notify the job_runner thread.
19:48:32 HBMASTER: job (9, 0, 4) submitted to dispatcher
19:48:32 DISPATCHER: Trying to submit another job.
19:48:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:48:32 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
19:48:32 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
19:48:32 WORKER: start processing job (9, 0, 4)
19:48:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:48:32 WORKER: args: ()
19:48:32 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.014871651270891064, 'num_filters_1': 42, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.010306183725456807, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 23, 'num_filters_3': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:48:57 DISPATCHER: Starting worker discovery
19:48:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:48:57 DISPATCHER: Finished worker discovery
19:49:57 DISPATCHER: Starting worker discovery
19:49:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:49:57 DISPATCHER: Finished worker discovery
19:50:56 WORKER: done with job (9, 0, 4), trying to register it.
19:50:56 WORKER: registered result for job (9, 0, 4) with dispatcher
19:50:56 DISPATCHER: job (9, 0, 4) finished
19:50:56 DISPATCHER: register_result: lock acquired
19:50:56 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
19:50:56 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.014871651270891064, 'num_filters_1': 42, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.010306183725456807, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 23, 'num_filters_3': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9201266753930587, 'info': {'music-speech': 0.9201266753930587, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.014871651270891064, 'num_filters_1': 42, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.010306183725456807, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 23, 'num_filters_3': 26}"}}
exception: None

19:50:56 job_callback for (9, 0, 4) started
19:50:56 DISPATCHER: Trying to submit another job.
19:50:56 job_callback for (9, 0, 4) got condition
19:50:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:50:56 done building a new model for budget 133.333333 based on 17/42 split
Best loss for this budget:-0.992776





19:50:56 HBMASTER: Trying to run another job!
19:50:56 job_callback for (9, 0, 4) finished
19:50:56 start sampling a new configuration.
19:50:56 best_vector: [3, 2, 0.30428312735022844, 0.3306306167873354, 0.6842662726969589, 0, 0.8515968687120613, 0.11845383566334769, 2, 2, 1, 0, 0.8189415766950383, 0.6485829086060051, 0.9270038360741627, 0.20747869920701234], 4.0869836417917576e-29, 0.00024467922743179717, -2.0247732792607082e-07
19:50:56 done sampling a new configuration.
19:50:56 HBMASTER: schedule new run for iteration 9
19:50:56 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
19:50:56 HBMASTER: submitting job (9, 0, 5) to dispatcher
19:50:56 DISPATCHER: trying to submit job (9, 0, 5)
19:50:56 DISPATCHER: trying to notify the job_runner thread.
19:50:56 HBMASTER: job (9, 0, 5) submitted to dispatcher
19:50:56 DISPATCHER: Trying to submit another job.
19:50:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:50:56 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
19:50:56 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
19:50:56 WORKER: start processing job (9, 0, 5)
19:50:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:50:56 WORKER: args: ()
19:50:56 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004060376024400949, 'num_filters_1': 31, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.014259752682848573, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 88, 'num_filters_3': 61, 'num_filters_4': 110}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:50:57 DISPATCHER: Starting worker discovery
19:50:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:50:57 DISPATCHER: Finished worker discovery
19:51:57 DISPATCHER: Starting worker discovery
19:51:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:51:57 DISPATCHER: Finished worker discovery
19:52:57 DISPATCHER: Starting worker discovery
19:52:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:52:57 DISPATCHER: Finished worker discovery
19:53:24 WORKER: done with job (9, 0, 5), trying to register it.
19:53:24 WORKER: registered result for job (9, 0, 5) with dispatcher
19:53:24 DISPATCHER: job (9, 0, 5) finished
19:53:24 DISPATCHER: register_result: lock acquired
19:53:24 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
19:53:24 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004060376024400949, 'num_filters_1': 31, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.014259752682848573, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 88, 'num_filters_3': 61, 'num_filters_4': 110}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.945420048416704, 'info': {'music-speech': 0.945420048416704, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004060376024400949, 'num_filters_1': 31, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.014259752682848573, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 88, 'num_filters_3': 61, 'num_filters_4': 110}"}}
exception: None

19:53:24 job_callback for (9, 0, 5) started
19:53:24 DISPATCHER: Trying to submit another job.
19:53:24 job_callback for (9, 0, 5) got condition
19:53:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:53:24 done building a new model for budget 133.333333 based on 17/43 split
Best loss for this budget:-0.992776





19:53:24 HBMASTER: Trying to run another job!
19:53:24 job_callback for (9, 0, 5) finished
19:53:24 start sampling a new configuration.
19:53:24 done sampling a new configuration.
19:53:24 HBMASTER: schedule new run for iteration 9
19:53:24 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
19:53:24 HBMASTER: submitting job (9, 0, 6) to dispatcher
19:53:24 DISPATCHER: trying to submit job (9, 0, 6)
19:53:24 DISPATCHER: trying to notify the job_runner thread.
19:53:24 HBMASTER: job (9, 0, 6) submitted to dispatcher
19:53:24 DISPATCHER: Trying to submit another job.
19:53:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:53:24 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216
19:53:24 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
19:53:24 WORKER: start processing job (9, 0, 6)
19:53:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:53:24 WORKER: args: ()
19:53:24 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.06683221557045069, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.04163257472749443, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 49, 'num_filters_3': 47, 'num_filters_4': 21, 'num_filters_5': 128}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-386:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

19:53:57 DISPATCHER: Starting worker discovery
19:53:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:53:57 DISPATCHER: Finished worker discovery
19:54:57 DISPATCHER: Starting worker discovery
19:54:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:54:57 DISPATCHER: Finished worker discovery
19:55:45 WORKER: done with job (9, 0, 6), trying to register it.
19:55:45 WORKER: registered result for job (9, 0, 6) with dispatcher
19:55:45 DISPATCHER: job (9, 0, 6) finished
19:55:45 DISPATCHER: register_result: lock acquired
19:55:45 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
19:55:45 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.06683221557045069, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.04163257472749443, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 49, 'num_filters_3': 47, 'num_filters_4': 21, 'num_filters_5': 128}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7500767626641383, 'info': {'music-speech': 0.7500767626641383, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.06683221557045069, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.04163257472749443, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 49, 'num_filters_3': 47, 'num_filters_4': 21, 'num_filters_5': 128}"}}
exception: None

19:55:45 job_callback for (9, 0, 6) started
19:55:45 DISPATCHER: Trying to submit another job.
19:55:45 job_callback for (9, 0, 6) got condition
19:55:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:55:45 done building a new model for budget 133.333333 based on 17/44 split
Best loss for this budget:-0.992776





19:55:45 HBMASTER: Trying to run another job!
19:55:45 job_callback for (9, 0, 6) finished
19:55:45 start sampling a new configuration.
19:55:45 best_vector: [3, 0, 0.5122219413335961, 0.42031412260258644, 0.6551575428058916, 0, 0.7056528861681711, 0.052661993453506, 2, 1, 1, 0, 0.326153990225036, 0.3119605792462131, 0.5203330326858226, 0.41100721015640085], 2.9582721661081304e-29, 0.0003380351583118834, -1.9760840668363824e-05
19:55:45 done sampling a new configuration.
19:55:45 HBMASTER: schedule new run for iteration 9
19:55:45 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
19:55:45 HBMASTER: submitting job (9, 0, 7) to dispatcher
19:55:45 DISPATCHER: trying to submit job (9, 0, 7)
19:55:45 DISPATCHER: trying to notify the job_runner thread.
19:55:45 HBMASTER: job (9, 0, 7) submitted to dispatcher
19:55:45 DISPATCHER: Trying to submit another job.
19:55:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:55:45 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
19:55:45 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
19:55:45 WORKER: start processing job (9, 0, 7)
19:55:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:55:45 WORKER: args: ()
19:55:45 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.010578982109167698, 'num_filters_1': 38, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.01170886592693119, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 31, 'num_filters_3': 30, 'num_filters_4': 47}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:55:57 DISPATCHER: Starting worker discovery
19:55:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:55:57 DISPATCHER: Finished worker discovery
19:56:57 DISPATCHER: Starting worker discovery
19:56:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:56:57 DISPATCHER: Finished worker discovery
19:57:57 DISPATCHER: Starting worker discovery
19:57:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:57:57 DISPATCHER: Finished worker discovery
19:58:11 WORKER: done with job (9, 0, 7), trying to register it.
19:58:11 WORKER: registered result for job (9, 0, 7) with dispatcher
19:58:11 DISPATCHER: job (9, 0, 7) finished
19:58:11 DISPATCHER: register_result: lock acquired
19:58:11 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
19:58:11 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.010578982109167698, 'num_filters_1': 38, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.01170886592693119, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 31, 'num_filters_3': 30, 'num_filters_4': 47}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9122503827516161, 'info': {'music-speech': 0.9122503827516161, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.010578982109167698, 'num_filters_1': 38, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.01170886592693119, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 31, 'num_filters_3': 30, 'num_filters_4': 47}"}}
exception: None

19:58:11 job_callback for (9, 0, 7) started
19:58:11 DISPATCHER: Trying to submit another job.
19:58:11 job_callback for (9, 0, 7) got condition
19:58:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
19:58:11 done building a new model for budget 133.333333 based on 17/45 split
Best loss for this budget:-0.992776





19:58:11 HBMASTER: Trying to run another job!
19:58:11 job_callback for (9, 0, 7) finished
19:58:11 start sampling a new configuration.
19:58:11 done sampling a new configuration.
19:58:11 HBMASTER: schedule new run for iteration 9
19:58:11 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
19:58:11 HBMASTER: submitting job (9, 0, 8) to dispatcher
19:58:11 DISPATCHER: trying to submit job (9, 0, 8)
19:58:11 DISPATCHER: trying to notify the job_runner thread.
19:58:11 HBMASTER: job (9, 0, 8) submitted to dispatcher
19:58:11 DISPATCHER: Trying to submit another job.
19:58:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
19:58:11 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216
19:58:11 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
19:58:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
19:58:11 WORKER: start processing job (9, 0, 8)
19:58:11 WORKER: args: ()
19:58:11 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.028059993682340134, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.06064519747247334, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 19, 'num_filters_3': 112, 'num_filters_4': 81}, 'budget': 133.33333333333331, 'working_directory': '.'}
19:58:57 DISPATCHER: Starting worker discovery
19:58:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:58:57 DISPATCHER: Finished worker discovery
19:59:57 DISPATCHER: Starting worker discovery
19:59:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:59:57 DISPATCHER: Finished worker discovery
20:00:33 WORKER: done with job (9, 0, 8), trying to register it.
20:00:33 WORKER: registered result for job (9, 0, 8) with dispatcher
20:00:33 DISPATCHER: job (9, 0, 8) finished
20:00:33 DISPATCHER: register_result: lock acquired
20:00:33 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:00:33 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.028059993682340134, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.06064519747247334, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 19, 'num_filters_3': 112, 'num_filters_4': 81}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.028059993682340134, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.06064519747247334, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 19, 'num_filters_3': 112, 'num_filters_4': 81}"}}
exception: None

20:00:33 job_callback for (9, 0, 8) started
20:00:33 DISPATCHER: Trying to submit another job.
20:00:33 job_callback for (9, 0, 8) got condition
20:00:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:00:33 done building a new model for budget 133.333333 based on 17/45 split
Best loss for this budget:-0.992776





20:00:33 HBMASTER: Trying to run another job!
20:00:33 job_callback for (9, 0, 8) finished
20:00:33 ITERATION: Advancing config (9, 0, 4) to next budget 400.000000
20:00:33 ITERATION: Advancing config (9, 0, 5) to next budget 400.000000
20:00:33 ITERATION: Advancing config (9, 0, 7) to next budget 400.000000
20:00:33 HBMASTER: schedule new run for iteration 9
20:00:33 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
20:00:33 HBMASTER: submitting job (9, 0, 4) to dispatcher
20:00:33 DISPATCHER: trying to submit job (9, 0, 4)
20:00:33 DISPATCHER: trying to notify the job_runner thread.
20:00:33 HBMASTER: job (9, 0, 4) submitted to dispatcher
20:00:33 DISPATCHER: Trying to submit another job.
20:00:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:00:33 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:00:33 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:00:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:00:33 WORKER: start processing job (9, 0, 4)
20:00:33 WORKER: args: ()
20:00:33 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.014871651270891064, 'num_filters_1': 42, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.010306183725456807, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 23, 'num_filters_3': 26}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-389:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

20:00:57 DISPATCHER: Starting worker discovery
20:00:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:00:57 DISPATCHER: Finished worker discovery
20:01:57 DISPATCHER: Starting worker discovery
20:01:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:01:57 DISPATCHER: Finished worker discovery
20:02:57 DISPATCHER: Starting worker discovery
20:02:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:02:57 DISPATCHER: Finished worker discovery
20:03:57 DISPATCHER: Starting worker discovery
20:03:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:03:57 DISPATCHER: Finished worker discovery
20:04:57 DISPATCHER: Starting worker discovery
20:04:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:04:57 DISPATCHER: Finished worker discovery
20:05:57 DISPATCHER: Starting worker discovery
20:05:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:05:57 DISPATCHER: Finished worker discovery
20:06:57 DISPATCHER: Starting worker discovery
20:06:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:06:57 DISPATCHER: Finished worker discovery
20:07:21 WORKER: done with job (9, 0, 4), trying to register it.
20:07:21 WORKER: registered result for job (9, 0, 4) with dispatcher
20:07:21 DISPATCHER: job (9, 0, 4) finished
20:07:21 DISPATCHER: register_result: lock acquired
20:07:21 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:07:21 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.014871651270891064, 'num_filters_1': 42, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.010306183725456807, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 23, 'num_filters_3': 26}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8386661022256465, 'info': {'music-speech': 0.8386661022256465, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.014871651270891064, 'num_filters_1': 42, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.010306183725456807, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 23, 'num_filters_3': 26}"}}
exception: None

20:07:21 job_callback for (9, 0, 4) started
20:07:21 DISPATCHER: Trying to submit another job.
20:07:21 job_callback for (9, 0, 4) got condition
20:07:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:07:21 HBMASTER: Trying to run another job!
20:07:21 job_callback for (9, 0, 4) finished
20:07:21 HBMASTER: schedule new run for iteration 9
20:07:21 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
20:07:21 HBMASTER: submitting job (9, 0, 5) to dispatcher
20:07:21 DISPATCHER: trying to submit job (9, 0, 5)
20:07:21 DISPATCHER: trying to notify the job_runner thread.
20:07:21 HBMASTER: job (9, 0, 5) submitted to dispatcher
20:07:21 DISPATCHER: Trying to submit another job.
20:07:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:07:21 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:07:21 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:07:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:07:21 WORKER: start processing job (9, 0, 5)
20:07:21 WORKER: args: ()
20:07:21 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004060376024400949, 'num_filters_1': 31, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.014259752682848573, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 88, 'num_filters_3': 61, 'num_filters_4': 110}, 'budget': 400.0, 'working_directory': '.'}
20:07:57 DISPATCHER: Starting worker discovery
20:07:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:07:57 DISPATCHER: Finished worker discovery
20:08:57 DISPATCHER: Starting worker discovery
20:08:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:08:57 DISPATCHER: Finished worker discovery
20:09:57 DISPATCHER: Starting worker discovery
20:09:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:09:57 DISPATCHER: Finished worker discovery
20:10:57 DISPATCHER: Starting worker discovery
20:10:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:10:57 DISPATCHER: Finished worker discovery
20:11:57 DISPATCHER: Starting worker discovery
20:11:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:11:57 DISPATCHER: Finished worker discovery
20:12:57 DISPATCHER: Starting worker discovery
20:12:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:12:57 DISPATCHER: Finished worker discovery
20:13:57 DISPATCHER: Starting worker discovery
20:13:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:13:57 DISPATCHER: Finished worker discovery
20:14:13 WORKER: done with job (9, 0, 5), trying to register it.
20:14:13 DISPATCHER: job (9, 0, 5) finished
20:14:13 WORKER: registered result for job (9, 0, 5) with dispatcher
20:14:13 DISPATCHER: register_result: lock acquired
20:14:13 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:14:13 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004060376024400949, 'num_filters_1': 31, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.014259752682848573, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 88, 'num_filters_3': 61, 'num_filters_4': 110}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9141579218648688, 'info': {'music-speech': 0.9141579218648688, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004060376024400949, 'num_filters_1': 31, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.014259752682848573, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 88, 'num_filters_3': 61, 'num_filters_4': 110}"}}
exception: None

20:14:13 job_callback for (9, 0, 5) started
20:14:13 DISPATCHER: Trying to submit another job.
20:14:13 job_callback for (9, 0, 5) got condition
20:14:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:14:13 HBMASTER: Trying to run another job!
20:14:13 job_callback for (9, 0, 5) finished
20:14:13 HBMASTER: schedule new run for iteration 9
20:14:13 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
20:14:13 HBMASTER: submitting job (9, 0, 7) to dispatcher
20:14:13 DISPATCHER: trying to submit job (9, 0, 7)
20:14:13 DISPATCHER: trying to notify the job_runner thread.
20:14:13 HBMASTER: job (9, 0, 7) submitted to dispatcher
20:14:13 DISPATCHER: Trying to submit another job.
20:14:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:14:13 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:14:13 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:14:13 WORKER: start processing job (9, 0, 7)
20:14:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:14:13 WORKER: args: ()
20:14:13 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.010578982109167698, 'num_filters_1': 38, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.01170886592693119, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 31, 'num_filters_3': 30, 'num_filters_4': 47}, 'budget': 400.0, 'working_directory': '.'}
20:14:57 DISPATCHER: Starting worker discovery
20:14:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:14:57 DISPATCHER: Finished worker discovery
20:15:57 DISPATCHER: Starting worker discovery
20:15:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:15:57 DISPATCHER: Finished worker discovery
20:16:57 DISPATCHER: Starting worker discovery
20:16:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:16:57 DISPATCHER: Finished worker discovery
20:17:57 DISPATCHER: Starting worker discovery
20:17:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:17:57 DISPATCHER: Finished worker discovery
20:18:57 DISPATCHER: Starting worker discovery
20:18:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:18:57 DISPATCHER: Finished worker discovery
20:19:57 DISPATCHER: Starting worker discovery
20:19:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:19:57 DISPATCHER: Finished worker discovery
20:20:57 DISPATCHER: Starting worker discovery
20:20:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:20:57 DISPATCHER: Finished worker discovery
20:21:02 WORKER: done with job (9, 0, 7), trying to register it.
20:21:02 DISPATCHER: job (9, 0, 7) finished
20:21:02 WORKER: registered result for job (9, 0, 7) with dispatcher
20:21:02 DISPATCHER: register_result: lock acquired
20:21:02 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:21:02 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.010578982109167698, 'num_filters_1': 38, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.01170886592693119, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 31, 'num_filters_3': 30, 'num_filters_4': 47}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9172025357651944, 'info': {'music-speech': 0.9172025357651944, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.010578982109167698, 'num_filters_1': 38, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.01170886592693119, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 31, 'num_filters_3': 30, 'num_filters_4': 47}"}}
exception: None

20:21:02 job_callback for (9, 0, 7) started
20:21:02 DISPATCHER: Trying to submit another job.
20:21:02 job_callback for (9, 0, 7) got condition
20:21:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:21:02 HBMASTER: Trying to run another job!
20:21:02 job_callback for (9, 0, 7) finished
20:21:02 ITERATION: Advancing config (9, 0, 7) to next budget 1200.000000
20:21:02 HBMASTER: schedule new run for iteration 9
20:21:02 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
20:21:02 HBMASTER: submitting job (9, 0, 7) to dispatcher
20:21:02 DISPATCHER: trying to submit job (9, 0, 7)
20:21:02 DISPATCHER: trying to notify the job_runner thread.
20:21:02 HBMASTER: job (9, 0, 7) submitted to dispatcher
20:21:02 DISPATCHER: Trying to submit another job.
20:21:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:21:02 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:21:02 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:21:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:21:02 WORKER: start processing job (9, 0, 7)
20:21:02 WORKER: args: ()
20:21:02 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.010578982109167698, 'num_filters_1': 38, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.01170886592693119, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 31, 'num_filters_3': 30, 'num_filters_4': 47}, 'budget': 1200.0, 'working_directory': '.'}
20:21:57 DISPATCHER: Starting worker discovery
20:21:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:21:57 DISPATCHER: Finished worker discovery
20:22:57 DISPATCHER: Starting worker discovery
20:22:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:22:57 DISPATCHER: Finished worker discovery
20:23:57 DISPATCHER: Starting worker discovery
20:23:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:23:57 DISPATCHER: Finished worker discovery
20:24:57 DISPATCHER: Starting worker discovery
20:24:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:24:57 DISPATCHER: Finished worker discovery
20:25:57 DISPATCHER: Starting worker discovery
20:25:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:25:57 DISPATCHER: Finished worker discovery
20:26:57 DISPATCHER: Starting worker discovery
20:26:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:26:57 DISPATCHER: Finished worker discovery
20:27:57 DISPATCHER: Starting worker discovery
20:27:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:27:57 DISPATCHER: Finished worker discovery
20:28:57 DISPATCHER: Starting worker discovery
20:28:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:28:57 DISPATCHER: Finished worker discovery
20:29:57 DISPATCHER: Starting worker discovery
20:29:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:29:57 DISPATCHER: Finished worker discovery
20:30:57 DISPATCHER: Starting worker discovery
20:30:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:30:57 DISPATCHER: Finished worker discovery
20:31:57 DISPATCHER: Starting worker discovery
20:31:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:31:57 DISPATCHER: Finished worker discovery
20:32:57 DISPATCHER: Starting worker discovery
20:32:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:32:57 DISPATCHER: Finished worker discovery
20:33:57 DISPATCHER: Starting worker discovery
20:33:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:33:57 DISPATCHER: Finished worker discovery
20:34:57 DISPATCHER: Starting worker discovery
20:34:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:34:57 DISPATCHER: Finished worker discovery
20:35:57 DISPATCHER: Starting worker discovery
20:35:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:35:57 DISPATCHER: Finished worker discovery
20:36:57 DISPATCHER: Starting worker discovery
20:36:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:36:57 DISPATCHER: Finished worker discovery
20:37:57 DISPATCHER: Starting worker discovery
20:37:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:37:57 DISPATCHER: Finished worker discovery
20:38:57 DISPATCHER: Starting worker discovery
20:38:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:38:57 DISPATCHER: Finished worker discovery
20:39:57 DISPATCHER: Starting worker discovery
20:39:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:39:57 DISPATCHER: Finished worker discovery
20:40:57 DISPATCHER: Starting worker discovery
20:40:57 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:40:57 DISPATCHER: Finished worker discovery
20:41:12 WORKER: done with job (9, 0, 7), trying to register it.
20:41:12 WORKER: registered result for job (9, 0, 7) with dispatcher
20:41:12 DISPATCHER: job (9, 0, 7) finished
20:41:12 DISPATCHER: register_result: lock acquired
20:41:12 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:41:12 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.010578982109167698, 'num_filters_1': 38, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.01170886592693119, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 31, 'num_filters_3': 30, 'num_filters_4': 47}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.792596282047954, 'info': {'music-speech': 0.792596282047954, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.010578982109167698, 'num_filters_1': 38, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 74, 'weight_decay': 0.01170886592693119, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 31, 'num_filters_3': 30, 'num_filters_4': 47}"}}
exception: None

20:41:12 job_callback for (9, 0, 7) started
20:41:12 DISPATCHER: Trying to submit another job.
20:41:12 job_callback for (9, 0, 7) got condition
20:41:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:41:12 HBMASTER: Trying to run another job!
20:41:12 job_callback for (9, 0, 7) finished
20:41:12 HBMASTER: shutdown initiated, shutdown_workers = True
20:41:12 WORKER: shutting down now!
20:41:12 DISPATCHER: Dispatcher shutting down
20:41:12 DISPATCHER: discover_workers shutting down
20:41:12 DISPATCHER: 'discover_worker' thread exited
20:41:12 DISPATCHER: Trying to submit another job.
20:41:12 DISPATCHER: job_runner shutting down
20:41:12 DISPATCHER: 'job_runner' thread exited
20:41:12 DISPATCHER: shut down complete
20:41:13 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7f14ccdb0be0; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:33991>
20:41:13 WORKER: No dispatcher found. Waiting for one to initiate contact.
20:41:13 WORKER: start listening for jobs
20:41:13 wait_for_workers trying to get the condition
20:41:13 DISPATCHER: started the 'discover_worker' thread
20:41:13 DISPATCHER: started the 'job_runner' thread
20:41:13 DISPATCHER: Pyro daemon running on localhost:42633
20:41:13 DISPATCHER: Starting worker discovery
20:41:13 DISPATCHER: Found 1 potential workers, 0 currently in the pool.
20:41:13 DISPATCHER: discovered new worker, hpbandster.run_0.worker.metagpul.22021139727314577216
20:41:13 HBMASTER: number of workers changed to 1
20:41:13 Enough workers to start this run!
20:41:13 adjust_queue_size: lock accquired
20:41:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:41:13 HBMASTER: starting run at 1583869273.1615012
20:41:13 HBMASTER: adjusted queue size to (0, 1)
20:41:13 DISPATCHER: Finished worker discovery
20:41:13 start sampling a new configuration.
20:41:13 DISPATCHER: Trying to submit another job.
20:41:13 done sampling a new configuration.
20:41:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:41:13 HBMASTER: schedule new run for iteration 0
20:41:13 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
20:41:13 HBMASTER: submitting job (0, 0, 0) to dispatcher
20:41:13 DISPATCHER: trying to submit job (0, 0, 0)
20:41:13 DISPATCHER: trying to notify the job_runner thread.
20:41:13 HBMASTER: job (0, 0, 0) submitted to dispatcher
20:41:13 DISPATCHER: Trying to submit another job.
20:41:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:41:13 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:41:13 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:41:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:41:13 WORKER: start processing job (0, 0, 0)
20:41:13 WORKER: args: ()
20:41:13 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 58, 'last_n_outputs': 49, 'lr': 0.004174314383387121, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.011255239188562801}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-406:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

20:42:06 WORKER: done with job (0, 0, 0), trying to register it.
20:42:06 WORKER: registered result for job (0, 0, 0) with dispatcher
20:42:06 DISPATCHER: job (0, 0, 0) finished
20:42:06 DISPATCHER: register_result: lock acquired
20:42:06 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:42:06 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 58, 'last_n_outputs': 49, 'lr': 0.004174314383387121, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.011255239188562801}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6791347152336524, 'info': {'music-speech': 0.6791347152336524, 'config': "{'batch_size': 32, 'hidden_dim': 58, 'last_n_outputs': 49, 'lr': 0.004174314383387121, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.011255239188562801}"}}
exception: None

20:42:06 job_callback for (0, 0, 0) started
20:42:06 job_callback for (0, 0, 0) got condition
20:42:06 DISPATCHER: Trying to submit another job.
20:42:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:42:06 Only 1 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
20:42:06 HBMASTER: Trying to run another job!
20:42:06 job_callback for (0, 0, 0) finished
20:42:06 start sampling a new configuration.
20:42:06 done sampling a new configuration.
20:42:06 HBMASTER: schedule new run for iteration 0
20:42:06 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
20:42:06 HBMASTER: submitting job (0, 0, 1) to dispatcher
20:42:06 DISPATCHER: trying to submit job (0, 0, 1)
20:42:06 DISPATCHER: trying to notify the job_runner thread.
20:42:06 HBMASTER: job (0, 0, 1) submitted to dispatcher
20:42:06 DISPATCHER: Trying to submit another job.
20:42:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:42:06 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:42:06 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:42:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:42:06 WORKER: start processing job (0, 0, 1)
20:42:06 WORKER: args: ()
20:42:06 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 35, 'lr': 0.0037516581403008484, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.10974043412873306}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:42:13 DISPATCHER: Starting worker discovery
20:42:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:42:13 DISPATCHER: Finished worker discovery
Exception in thread Thread-407:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

20:42:59 WORKER: done with job (0, 0, 1), trying to register it.
20:42:59 WORKER: registered result for job (0, 0, 1) with dispatcher
20:42:59 DISPATCHER: job (0, 0, 1) finished
20:42:59 DISPATCHER: register_result: lock acquired
20:42:59 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:42:59 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 35, 'lr': 0.0037516581403008484, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.10974043412873306}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 97, 'last_n_outputs': 35, 'lr': 0.0037516581403008484, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 45, 'weight_decay': 0.10974043412873306}"}}
exception: None

20:42:59 job_callback for (0, 0, 1) started
20:42:59 DISPATCHER: Trying to submit another job.
20:42:59 job_callback for (0, 0, 1) got condition
20:42:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:42:59 Only 2 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
20:42:59 HBMASTER: Trying to run another job!
20:42:59 job_callback for (0, 0, 1) finished
20:42:59 start sampling a new configuration.
20:42:59 done sampling a new configuration.
20:42:59 HBMASTER: schedule new run for iteration 0
20:42:59 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
20:42:59 HBMASTER: submitting job (0, 0, 2) to dispatcher
20:42:59 DISPATCHER: trying to submit job (0, 0, 2)
20:42:59 DISPATCHER: trying to notify the job_runner thread.
20:42:59 HBMASTER: job (0, 0, 2) submitted to dispatcher
20:42:59 DISPATCHER: Trying to submit another job.
20:42:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:42:59 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:42:59 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:42:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:42:59 WORKER: start processing job (0, 0, 2)
20:42:59 WORKER: args: ()
20:42:59 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 99, 'last_n_outputs': 31, 'lr': 0.004201159178989937, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.07726506203237059}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:43:13 DISPATCHER: Starting worker discovery
20:43:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:43:13 DISPATCHER: Finished worker discovery
Exception in thread Thread-408:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

20:43:52 WORKER: done with job (0, 0, 2), trying to register it.
20:43:52 WORKER: registered result for job (0, 0, 2) with dispatcher
20:43:52 DISPATCHER: job (0, 0, 2) finished
20:43:52 DISPATCHER: register_result: lock acquired
20:43:52 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:43:52 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 99, 'last_n_outputs': 31, 'lr': 0.004201159178989937, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.07726506203237059}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6366739988068448, 'info': {'music-speech': 0.6366739988068448, 'config': "{'batch_size': 16, 'hidden_dim': 99, 'last_n_outputs': 31, 'lr': 0.004201159178989937, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.07726506203237059}"}}
exception: None

20:43:52 job_callback for (0, 0, 2) started
20:43:52 DISPATCHER: Trying to submit another job.
20:43:52 job_callback for (0, 0, 2) got condition
20:43:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:43:52 Only 3 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
20:43:52 HBMASTER: Trying to run another job!
20:43:52 job_callback for (0, 0, 2) finished
20:43:52 start sampling a new configuration.
20:43:52 done sampling a new configuration.
20:43:52 HBMASTER: schedule new run for iteration 0
20:43:52 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
20:43:52 HBMASTER: submitting job (0, 0, 3) to dispatcher
20:43:52 DISPATCHER: trying to submit job (0, 0, 3)
20:43:52 DISPATCHER: trying to notify the job_runner thread.
20:43:52 HBMASTER: job (0, 0, 3) submitted to dispatcher
20:43:52 DISPATCHER: Trying to submit another job.
20:43:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:43:52 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:43:52 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:43:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:43:52 WORKER: start processing job (0, 0, 3)
20:43:52 WORKER: args: ()
20:43:52 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 54, 'last_n_outputs': 17, 'lr': 0.03088371491859569, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.06563132292099166}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-409:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

20:44:13 DISPATCHER: Starting worker discovery
20:44:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:44:13 DISPATCHER: Finished worker discovery
20:44:45 WORKER: done with job (0, 0, 3), trying to register it.
20:44:45 DISPATCHER: job (0, 0, 3) finished
20:44:45 WORKER: registered result for job (0, 0, 3) with dispatcher
20:44:45 DISPATCHER: register_result: lock acquired
20:44:45 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:44:45 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 54, 'last_n_outputs': 17, 'lr': 0.03088371491859569, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.06563132292099166}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.65850797351512, 'info': {'music-speech': 0.65850797351512, 'config': "{'batch_size': 16, 'hidden_dim': 54, 'last_n_outputs': 17, 'lr': 0.03088371491859569, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.06563132292099166}"}}
exception: None

20:44:45 job_callback for (0, 0, 3) started
20:44:45 DISPATCHER: Trying to submit another job.
20:44:45 job_callback for (0, 0, 3) got condition
20:44:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:44:45 Only 4 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
20:44:45 HBMASTER: Trying to run another job!
20:44:45 job_callback for (0, 0, 3) finished
20:44:45 start sampling a new configuration.
20:44:45 done sampling a new configuration.
20:44:45 HBMASTER: schedule new run for iteration 0
20:44:45 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
20:44:45 HBMASTER: submitting job (0, 0, 4) to dispatcher
20:44:45 DISPATCHER: trying to submit job (0, 0, 4)
20:44:45 DISPATCHER: trying to notify the job_runner thread.
20:44:45 HBMASTER: job (0, 0, 4) submitted to dispatcher
20:44:45 DISPATCHER: Trying to submit another job.
20:44:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:44:45 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:44:45 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:44:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:44:45 WORKER: start processing job (0, 0, 4)
20:44:45 WORKER: args: ()
20:44:45 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 35, 'last_n_outputs': 44, 'lr': 0.017728676987301045, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.15173621930163794}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-410:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

20:45:13 DISPATCHER: Starting worker discovery
20:45:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:45:13 DISPATCHER: Finished worker discovery
20:45:38 WORKER: done with job (0, 0, 4), trying to register it.
20:45:38 WORKER: registered result for job (0, 0, 4) with dispatcher
20:45:38 DISPATCHER: job (0, 0, 4) finished
20:45:38 DISPATCHER: register_result: lock acquired
20:45:38 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:45:38 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 35, 'last_n_outputs': 44, 'lr': 0.017728676987301045, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.15173621930163794}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.26611441736551283, 'info': {'music-speech': 0.26611441736551283, 'config': "{'batch_size': 16, 'hidden_dim': 35, 'last_n_outputs': 44, 'lr': 0.017728676987301045, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 11, 'weight_decay': 0.15173621930163794}"}}
exception: None

20:45:38 job_callback for (0, 0, 4) started
20:45:38 DISPATCHER: Trying to submit another job.
20:45:38 job_callback for (0, 0, 4) got condition
20:45:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:45:38 Only 5 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
20:45:38 HBMASTER: Trying to run another job!
20:45:38 job_callback for (0, 0, 4) finished
20:45:38 start sampling a new configuration.
20:45:38 done sampling a new configuration.
20:45:38 HBMASTER: schedule new run for iteration 0
20:45:38 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
20:45:38 HBMASTER: submitting job (0, 0, 5) to dispatcher
20:45:38 DISPATCHER: trying to submit job (0, 0, 5)
20:45:38 DISPATCHER: trying to notify the job_runner thread.
20:45:38 HBMASTER: job (0, 0, 5) submitted to dispatcher
20:45:38 DISPATCHER: Trying to submit another job.
20:45:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:45:38 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:45:38 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:45:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:45:38 WORKER: start processing job (0, 0, 5)
20:45:38 WORKER: args: ()
20:45:38 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 21, 'last_n_outputs': 8, 'lr': 0.06133881409433595, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.022815325705305745}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-411:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

20:46:13 DISPATCHER: Starting worker discovery
20:46:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:46:13 DISPATCHER: Finished worker discovery
20:46:31 WORKER: done with job (0, 0, 5), trying to register it.
20:46:31 WORKER: registered result for job (0, 0, 5) with dispatcher
20:46:31 DISPATCHER: job (0, 0, 5) finished
20:46:31 DISPATCHER: register_result: lock acquired
20:46:31 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:46:31 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 21, 'last_n_outputs': 8, 'lr': 0.06133881409433595, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.022815325705305745}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 21, 'last_n_outputs': 8, 'lr': 0.06133881409433595, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 80, 'weight_decay': 0.022815325705305745}"}}
exception: None

20:46:31 DISPATCHER: Trying to submit another job.
20:46:31 job_callback for (0, 0, 5) started
20:46:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:46:31 job_callback for (0, 0, 5) got condition
20:46:31 Only 6 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
20:46:31 HBMASTER: Trying to run another job!
20:46:31 job_callback for (0, 0, 5) finished
20:46:31 start sampling a new configuration.
20:46:31 done sampling a new configuration.
20:46:31 HBMASTER: schedule new run for iteration 0
20:46:31 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
20:46:31 HBMASTER: submitting job (0, 0, 6) to dispatcher
20:46:31 DISPATCHER: trying to submit job (0, 0, 6)
20:46:31 DISPATCHER: trying to notify the job_runner thread.
20:46:31 HBMASTER: job (0, 0, 6) submitted to dispatcher
20:46:31 DISPATCHER: Trying to submit another job.
20:46:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:46:31 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:46:31 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:46:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:46:31 WORKER: start processing job (0, 0, 6)
20:46:31 WORKER: args: ()
20:46:31 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 31, 'last_n_outputs': 19, 'lr': 0.006640402440131341, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.023828061935201657}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-412:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

20:47:13 DISPATCHER: Starting worker discovery
20:47:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:47:13 DISPATCHER: Finished worker discovery
20:47:24 WORKER: done with job (0, 0, 6), trying to register it.
20:47:24 DISPATCHER: job (0, 0, 6) finished
20:47:24 WORKER: registered result for job (0, 0, 6) with dispatcher
20:47:24 DISPATCHER: register_result: lock acquired
20:47:24 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:47:24 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 31, 'last_n_outputs': 19, 'lr': 0.006640402440131341, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.023828061935201657}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 31, 'last_n_outputs': 19, 'lr': 0.006640402440131341, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.023828061935201657}"}}
exception: None

20:47:24 job_callback for (0, 0, 6) started
20:47:24 DISPATCHER: Trying to submit another job.
20:47:24 job_callback for (0, 0, 6) got condition
20:47:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:47:24 Only 7 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
20:47:24 HBMASTER: Trying to run another job!
20:47:24 job_callback for (0, 0, 6) finished
20:47:24 start sampling a new configuration.
20:47:24 done sampling a new configuration.
20:47:24 HBMASTER: schedule new run for iteration 0
20:47:24 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
20:47:24 HBMASTER: submitting job (0, 0, 7) to dispatcher
20:47:24 DISPATCHER: trying to submit job (0, 0, 7)
20:47:24 DISPATCHER: trying to notify the job_runner thread.
20:47:24 HBMASTER: job (0, 0, 7) submitted to dispatcher
20:47:24 DISPATCHER: Trying to submit another job.
20:47:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:47:24 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:47:24 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:47:24 WORKER: start processing job (0, 0, 7)
20:47:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:47:24 WORKER: args: ()
20:47:24 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 25, 'last_n_outputs': 46, 'lr': 0.0013095431373116623, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.03846888659208803}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-413:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

20:48:13 DISPATCHER: Starting worker discovery
20:48:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:48:13 DISPATCHER: Finished worker discovery
20:48:17 WORKER: done with job (0, 0, 7), trying to register it.
20:48:17 DISPATCHER: job (0, 0, 7) finished
20:48:17 WORKER: registered result for job (0, 0, 7) with dispatcher
20:48:17 DISPATCHER: register_result: lock acquired
20:48:17 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:48:17 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 25, 'last_n_outputs': 46, 'lr': 0.0013095431373116623, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.03846888659208803}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7397980349684072, 'info': {'music-speech': 0.7397980349684072, 'config': "{'batch_size': 16, 'hidden_dim': 25, 'last_n_outputs': 46, 'lr': 0.0013095431373116623, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.03846888659208803}"}}
exception: None

20:48:17 job_callback for (0, 0, 7) started
20:48:17 DISPATCHER: Trying to submit another job.
20:48:17 job_callback for (0, 0, 7) got condition
20:48:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:48:17 Only 8 run(s) for budget 44.444444 available, need more than 10 -> can't build model!
20:48:17 HBMASTER: Trying to run another job!
20:48:17 job_callback for (0, 0, 7) finished
20:48:17 start sampling a new configuration.
20:48:17 done sampling a new configuration.
20:48:17 HBMASTER: schedule new run for iteration 0
20:48:17 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
20:48:17 HBMASTER: submitting job (0, 0, 8) to dispatcher
20:48:17 DISPATCHER: trying to submit job (0, 0, 8)
20:48:17 DISPATCHER: trying to notify the job_runner thread.
20:48:17 HBMASTER: job (0, 0, 8) submitted to dispatcher
20:48:17 DISPATCHER: Trying to submit another job.
20:48:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:48:17 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:48:17 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:48:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:48:17 WORKER: start processing job (0, 0, 8)
20:48:17 WORKER: args: ()
20:48:17 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 57, 'last_n_outputs': 5, 'lr': 0.004662146395572507, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.11303333518999796}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-414:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

20:49:10 WORKER: done with job (0, 0, 8), trying to register it.
20:49:10 DISPATCHER: job (0, 0, 8) finished
20:49:10 WORKER: registered result for job (0, 0, 8) with dispatcher
20:49:10 DISPATCHER: register_result: lock acquired
20:49:10 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:49:10 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 57, 'last_n_outputs': 5, 'lr': 0.004662146395572507, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.11303333518999796}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 57, 'last_n_outputs': 5, 'lr': 0.004662146395572507, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.11303333518999796}"}}
exception: None

20:49:10 job_callback for (0, 0, 8) started
20:49:10 DISPATCHER: Trying to submit another job.
20:49:10 job_callback for (0, 0, 8) got condition
20:49:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:49:10 HBMASTER: Trying to run another job!
20:49:10 job_callback for (0, 0, 8) finished
20:49:10 start sampling a new configuration.
20:49:10 done sampling a new configuration.
20:49:10 HBMASTER: schedule new run for iteration 0
20:49:10 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
20:49:10 HBMASTER: submitting job (0, 0, 9) to dispatcher
20:49:10 DISPATCHER: trying to submit job (0, 0, 9)
20:49:10 DISPATCHER: trying to notify the job_runner thread.
20:49:10 HBMASTER: job (0, 0, 9) submitted to dispatcher
20:49:10 DISPATCHER: Trying to submit another job.
20:49:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:49:10 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:49:10 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:49:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:49:10 WORKER: start processing job (0, 0, 9)
20:49:10 WORKER: args: ()
20:49:10 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 23, 'last_n_outputs': 36, 'lr': 0.07169889752113105, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.027949787704449027}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:49:13 DISPATCHER: Starting worker discovery
20:49:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:49:13 DISPATCHER: Finished worker discovery
Exception in thread Thread-415:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

20:50:03 WORKER: done with job (0, 0, 9), trying to register it.
20:50:03 WORKER: registered result for job (0, 0, 9) with dispatcher
20:50:03 DISPATCHER: job (0, 0, 9) finished
20:50:03 DISPATCHER: register_result: lock acquired
20:50:03 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:50:03 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 23, 'last_n_outputs': 36, 'lr': 0.07169889752113105, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.027949787704449027}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 23, 'last_n_outputs': 36, 'lr': 0.07169889752113105, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.027949787704449027}"}}
exception: None

20:50:03 job_callback for (0, 0, 9) started
20:50:03 DISPATCHER: Trying to submit another job.
20:50:03 job_callback for (0, 0, 9) got condition
20:50:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:50:03 HBMASTER: Trying to run another job!
20:50:03 job_callback for (0, 0, 9) finished
20:50:03 start sampling a new configuration.
20:50:03 done sampling a new configuration.
20:50:03 HBMASTER: schedule new run for iteration 0
20:50:03 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
20:50:03 HBMASTER: submitting job (0, 0, 10) to dispatcher
20:50:03 DISPATCHER: trying to submit job (0, 0, 10)
20:50:03 DISPATCHER: trying to notify the job_runner thread.
20:50:03 HBMASTER: job (0, 0, 10) submitted to dispatcher
20:50:03 DISPATCHER: Trying to submit another job.
20:50:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:50:03 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:50:03 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:50:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:50:03 WORKER: start processing job (0, 0, 10)
20:50:03 WORKER: args: ()
20:50:03 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 46, 'last_n_outputs': 21, 'lr': 0.031162237263176844, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.14485642418857084}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:50:13 DISPATCHER: Starting worker discovery
20:50:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:50:13 DISPATCHER: Finished worker discovery
Exception in thread Thread-416:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

20:50:56 WORKER: done with job (0, 0, 10), trying to register it.
20:50:56 WORKER: registered result for job (0, 0, 10) with dispatcher
20:50:56 DISPATCHER: job (0, 0, 10) finished
20:50:56 DISPATCHER: register_result: lock acquired
20:50:56 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:50:56 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 46, 'last_n_outputs': 21, 'lr': 0.031162237263176844, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.14485642418857084}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6246870307564852, 'info': {'music-speech': 0.6246870307564852, 'config': "{'batch_size': 64, 'hidden_dim': 46, 'last_n_outputs': 21, 'lr': 0.031162237263176844, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.14485642418857084}"}}
exception: None

20:50:56 job_callback for (0, 0, 10) started
20:50:56 job_callback for (0, 0, 10) got condition
20:50:56 DISPATCHER: Trying to submit another job.
20:50:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:50:56 HBMASTER: Trying to run another job!
20:50:56 job_callback for (0, 0, 10) finished
20:50:56 start sampling a new configuration.
20:50:56 done sampling a new configuration.
20:50:56 HBMASTER: schedule new run for iteration 0
20:50:56 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
20:50:56 HBMASTER: submitting job (0, 0, 11) to dispatcher
20:50:56 DISPATCHER: trying to submit job (0, 0, 11)
20:50:56 DISPATCHER: trying to notify the job_runner thread.
20:50:56 HBMASTER: job (0, 0, 11) submitted to dispatcher
20:50:56 DISPATCHER: Trying to submit another job.
20:50:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:50:56 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:50:56 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:50:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:50:56 WORKER: start processing job (0, 0, 11)
20:50:56 WORKER: args: ()
20:50:56 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 35, 'last_n_outputs': 50, 'lr': 0.006576646352082888, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.07204560098683786}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:51:13 DISPATCHER: Starting worker discovery
20:51:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:51:13 DISPATCHER: Finished worker discovery
Exception in thread Thread-417:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

20:51:49 WORKER: done with job (0, 0, 11), trying to register it.
20:51:49 WORKER: registered result for job (0, 0, 11) with dispatcher
20:51:49 DISPATCHER: job (0, 0, 11) finished
20:51:49 DISPATCHER: register_result: lock acquired
20:51:49 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:51:49 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 35, 'last_n_outputs': 50, 'lr': 0.006576646352082888, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.07204560098683786}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7376007397545394, 'info': {'music-speech': 0.7376007397545394, 'config': "{'batch_size': 32, 'hidden_dim': 35, 'last_n_outputs': 50, 'lr': 0.006576646352082888, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.07204560098683786}"}}
exception: None

20:51:49 job_callback for (0, 0, 11) started
20:51:49 DISPATCHER: Trying to submit another job.
20:51:49 job_callback for (0, 0, 11) got condition
20:51:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:51:50 HBMASTER: Trying to run another job!
20:51:50 job_callback for (0, 0, 11) finished
20:51:50 start sampling a new configuration.
20:51:50 done sampling a new configuration.
20:51:50 HBMASTER: schedule new run for iteration 0
20:51:50 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
20:51:50 HBMASTER: submitting job (0, 0, 12) to dispatcher
20:51:50 DISPATCHER: trying to submit job (0, 0, 12)
20:51:50 DISPATCHER: trying to notify the job_runner thread.
20:51:50 HBMASTER: job (0, 0, 12) submitted to dispatcher
20:51:50 DISPATCHER: Trying to submit another job.
20:51:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:51:50 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:51:50 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:51:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:51:50 WORKER: start processing job (0, 0, 12)
20:51:50 WORKER: args: ()
20:51:50 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 87, 'last_n_outputs': 30, 'lr': 0.00951794158823696, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.035127588807569214}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-418:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

20:52:13 DISPATCHER: Starting worker discovery
20:52:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:52:13 DISPATCHER: Finished worker discovery
20:52:43 WORKER: done with job (0, 0, 12), trying to register it.
20:52:43 WORKER: registered result for job (0, 0, 12) with dispatcher
20:52:43 DISPATCHER: job (0, 0, 12) finished
20:52:43 DISPATCHER: register_result: lock acquired
20:52:43 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:52:43 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 87, 'last_n_outputs': 30, 'lr': 0.00951794158823696, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.035127588807569214}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.70213423497054, 'info': {'music-speech': 0.70213423497054, 'config': "{'batch_size': 64, 'hidden_dim': 87, 'last_n_outputs': 30, 'lr': 0.00951794158823696, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.035127588807569214}"}}
exception: None

20:52:43 job_callback for (0, 0, 12) started
20:52:43 DISPATCHER: Trying to submit another job.
20:52:43 job_callback for (0, 0, 12) got condition
20:52:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:52:43 HBMASTER: Trying to run another job!
20:52:43 job_callback for (0, 0, 12) finished
20:52:43 start sampling a new configuration.
20:52:43 done sampling a new configuration.
20:52:43 HBMASTER: schedule new run for iteration 0
20:52:43 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
20:52:43 HBMASTER: submitting job (0, 0, 13) to dispatcher
20:52:43 DISPATCHER: trying to submit job (0, 0, 13)
20:52:43 DISPATCHER: trying to notify the job_runner thread.
20:52:43 HBMASTER: job (0, 0, 13) submitted to dispatcher
20:52:43 DISPATCHER: Trying to submit another job.
20:52:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:52:43 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:52:43 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:52:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:52:43 WORKER: start processing job (0, 0, 13)
20:52:43 WORKER: args: ()
20:52:43 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 24, 'lr': 0.0018586976158686418, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.16543972626431372}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-419:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

20:53:13 DISPATCHER: Starting worker discovery
20:53:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:53:13 DISPATCHER: Finished worker discovery
20:53:36 WORKER: done with job (0, 0, 13), trying to register it.
20:53:36 WORKER: registered result for job (0, 0, 13) with dispatcher
20:53:36 DISPATCHER: job (0, 0, 13) finished
20:53:36 DISPATCHER: register_result: lock acquired
20:53:36 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:53:36 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 24, 'lr': 0.0018586976158686418, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.16543972626431372}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 74, 'last_n_outputs': 24, 'lr': 0.0018586976158686418, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.16543972626431372}"}}
exception: None

20:53:36 job_callback for (0, 0, 13) started
20:53:36 DISPATCHER: Trying to submit another job.
20:53:36 job_callback for (0, 0, 13) got condition
20:53:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:53:36 HBMASTER: Trying to run another job!
20:53:36 job_callback for (0, 0, 13) finished
20:53:36 start sampling a new configuration.
20:53:36 done sampling a new configuration.
20:53:36 HBMASTER: schedule new run for iteration 0
20:53:36 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
20:53:36 HBMASTER: submitting job (0, 0, 14) to dispatcher
20:53:36 DISPATCHER: trying to submit job (0, 0, 14)
20:53:36 DISPATCHER: trying to notify the job_runner thread.
20:53:36 HBMASTER: job (0, 0, 14) submitted to dispatcher
20:53:36 DISPATCHER: Trying to submit another job.
20:53:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:53:36 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:53:36 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:53:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:53:36 WORKER: start processing job (0, 0, 14)
20:53:36 WORKER: args: ()
20:53:36 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 32, 'last_n_outputs': 20, 'lr': 0.014989621948055996, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.022892845755044324}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-420:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

20:54:13 DISPATCHER: Starting worker discovery
20:54:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:54:13 DISPATCHER: Finished worker discovery
20:54:30 WORKER: done with job (0, 0, 14), trying to register it.
20:54:30 WORKER: registered result for job (0, 0, 14) with dispatcher
20:54:30 DISPATCHER: job (0, 0, 14) finished
20:54:30 DISPATCHER: register_result: lock acquired
20:54:30 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:54:30 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 32, 'last_n_outputs': 20, 'lr': 0.014989621948055996, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.022892845755044324}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6132362154685341, 'info': {'music-speech': 0.6132362154685341, 'config': "{'batch_size': 64, 'hidden_dim': 32, 'last_n_outputs': 20, 'lr': 0.014989621948055996, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.022892845755044324}"}}
exception: None

20:54:30 job_callback for (0, 0, 14) started
20:54:30 DISPATCHER: Trying to submit another job.
20:54:30 job_callback for (0, 0, 14) got condition
20:54:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:54:30 HBMASTER: Trying to run another job!
20:54:30 job_callback for (0, 0, 14) finished
20:54:30 start sampling a new configuration.
20:54:30 done sampling a new configuration.
20:54:30 HBMASTER: schedule new run for iteration 0
20:54:30 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
20:54:30 HBMASTER: submitting job (0, 0, 15) to dispatcher
20:54:30 DISPATCHER: trying to submit job (0, 0, 15)
20:54:30 DISPATCHER: trying to notify the job_runner thread.
20:54:30 HBMASTER: job (0, 0, 15) submitted to dispatcher
20:54:30 DISPATCHER: Trying to submit another job.
20:54:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:54:30 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:54:30 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:54:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:54:30 WORKER: start processing job (0, 0, 15)
20:54:30 WORKER: args: ()
20:54:30 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 58, 'last_n_outputs': 46, 'lr': 0.04204952501226439, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.011886915873379601}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-421:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

20:55:13 DISPATCHER: Starting worker discovery
20:55:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:55:13 DISPATCHER: Finished worker discovery
20:55:23 WORKER: done with job (0, 0, 15), trying to register it.
20:55:23 WORKER: registered result for job (0, 0, 15) with dispatcher
20:55:23 DISPATCHER: job (0, 0, 15) finished
20:55:23 DISPATCHER: register_result: lock acquired
20:55:23 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:55:23 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 58, 'last_n_outputs': 46, 'lr': 0.04204952501226439, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.011886915873379601}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4098983740551537, 'info': {'music-speech': 0.4098983740551537, 'config': "{'batch_size': 128, 'hidden_dim': 58, 'last_n_outputs': 46, 'lr': 0.04204952501226439, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.011886915873379601}"}}
exception: None

20:55:23 job_callback for (0, 0, 15) started
20:55:23 DISPATCHER: Trying to submit another job.
20:55:23 job_callback for (0, 0, 15) got condition
20:55:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:55:23 HBMASTER: Trying to run another job!
20:55:23 job_callback for (0, 0, 15) finished
20:55:23 start sampling a new configuration.
20:55:23 done sampling a new configuration.
20:55:23 HBMASTER: schedule new run for iteration 0
20:55:23 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
20:55:23 HBMASTER: submitting job (0, 0, 16) to dispatcher
20:55:23 DISPATCHER: trying to submit job (0, 0, 16)
20:55:23 DISPATCHER: trying to notify the job_runner thread.
20:55:23 HBMASTER: job (0, 0, 16) submitted to dispatcher
20:55:23 DISPATCHER: Trying to submit another job.
20:55:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:55:23 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:55:23 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:55:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:55:23 WORKER: start processing job (0, 0, 16)
20:55:23 WORKER: args: ()
20:55:23 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 72, 'last_n_outputs': 17, 'lr': 0.004768652857833486, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.08288191084184723}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-422:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

20:56:13 DISPATCHER: Starting worker discovery
20:56:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:56:13 DISPATCHER: Finished worker discovery
20:56:15 WORKER: done with job (0, 0, 16), trying to register it.
20:56:15 DISPATCHER: job (0, 0, 16) finished
20:56:15 WORKER: registered result for job (0, 0, 16) with dispatcher
20:56:15 DISPATCHER: register_result: lock acquired
20:56:15 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:56:15 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 72, 'last_n_outputs': 17, 'lr': 0.004768652857833486, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.08288191084184723}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7716191774512471, 'info': {'music-speech': 0.7716191774512471, 'config': "{'batch_size': 64, 'hidden_dim': 72, 'last_n_outputs': 17, 'lr': 0.004768652857833486, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.08288191084184723}"}}
exception: None

20:56:15 job_callback for (0, 0, 16) started
20:56:15 DISPATCHER: Trying to submit another job.
20:56:15 job_callback for (0, 0, 16) got condition
20:56:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:56:15 HBMASTER: Trying to run another job!
20:56:15 job_callback for (0, 0, 16) finished
20:56:15 start sampling a new configuration.
20:56:15 done sampling a new configuration.
20:56:15 HBMASTER: schedule new run for iteration 0
20:56:15 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
20:56:15 HBMASTER: submitting job (0, 0, 17) to dispatcher
20:56:15 DISPATCHER: trying to submit job (0, 0, 17)
20:56:15 DISPATCHER: trying to notify the job_runner thread.
20:56:15 HBMASTER: job (0, 0, 17) submitted to dispatcher
20:56:15 DISPATCHER: Trying to submit another job.
20:56:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:56:15 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:56:15 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:56:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:56:15 WORKER: start processing job (0, 0, 17)
20:56:15 WORKER: args: ()
20:56:15 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 98, 'last_n_outputs': 25, 'lr': 0.032909025824607634, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.023152458906399203}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-423:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

20:57:08 WORKER: done with job (0, 0, 17), trying to register it.
20:57:08 WORKER: registered result for job (0, 0, 17) with dispatcher
20:57:08 DISPATCHER: job (0, 0, 17) finished
20:57:08 DISPATCHER: register_result: lock acquired
20:57:08 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:57:08 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 98, 'last_n_outputs': 25, 'lr': 0.032909025824607634, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.023152458906399203}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6143395503197708, 'info': {'music-speech': 0.6143395503197708, 'config': "{'batch_size': 64, 'hidden_dim': 98, 'last_n_outputs': 25, 'lr': 0.032909025824607634, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.023152458906399203}"}}
exception: None

20:57:08 job_callback for (0, 0, 17) started
20:57:08 job_callback for (0, 0, 17) got condition
20:57:08 DISPATCHER: Trying to submit another job.
20:57:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:57:09 done building a new model for budget 44.444444 based on 9/15 split
Best loss for this budget:-0.771619





20:57:09 HBMASTER: Trying to run another job!
20:57:09 job_callback for (0, 0, 17) finished
20:57:09 start sampling a new configuration.
20:57:09 done sampling a new configuration.
20:57:09 HBMASTER: schedule new run for iteration 0
20:57:09 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
20:57:09 HBMASTER: submitting job (0, 0, 18) to dispatcher
20:57:09 DISPATCHER: trying to submit job (0, 0, 18)
20:57:09 DISPATCHER: trying to notify the job_runner thread.
20:57:09 HBMASTER: job (0, 0, 18) submitted to dispatcher
20:57:09 DISPATCHER: Trying to submit another job.
20:57:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:57:09 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:57:09 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:57:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:57:09 WORKER: start processing job (0, 0, 18)
20:57:09 WORKER: args: ()
20:57:09 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 46, 'last_n_outputs': 11, 'lr': 0.023792427493353068, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.01916806622985107}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:57:13 DISPATCHER: Starting worker discovery
20:57:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:57:13 DISPATCHER: Finished worker discovery
Exception in thread Thread-424:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

20:58:02 WORKER: done with job (0, 0, 18), trying to register it.
20:58:02 WORKER: registered result for job (0, 0, 18) with dispatcher
20:58:02 DISPATCHER: job (0, 0, 18) finished
20:58:02 DISPATCHER: register_result: lock acquired
20:58:02 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:58:02 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 46, 'last_n_outputs': 11, 'lr': 0.023792427493353068, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.01916806622985107}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.13279415071043557, 'info': {'music-speech': 0.13279415071043557, 'config': "{'batch_size': 16, 'hidden_dim': 46, 'last_n_outputs': 11, 'lr': 0.023792427493353068, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.01916806622985107}"}}
exception: None

20:58:02 job_callback for (0, 0, 18) started
20:58:02 job_callback for (0, 0, 18) got condition
20:58:02 DISPATCHER: Trying to submit another job.
20:58:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:58:02 done building a new model for budget 44.444444 based on 9/16 split
Best loss for this budget:-0.771619





20:58:02 HBMASTER: Trying to run another job!
20:58:02 job_callback for (0, 0, 18) finished
20:58:02 start sampling a new configuration.
20:58:02 best_vector: [2, 0.010447250061586505, 0.2543790681273429, 0.8655410325500625, 0.04740791750489479, 0, 0.8406015810834495, 0.6407663434854718], 9.293683234763757e-32, 0.10759996599189231, -0.003639153285385145
20:58:02 done sampling a new configuration.
20:58:02 HBMASTER: schedule new run for iteration 0
20:58:02 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
20:58:02 HBMASTER: submitting job (0, 0, 19) to dispatcher
20:58:02 DISPATCHER: trying to submit job (0, 0, 19)
20:58:02 DISPATCHER: trying to notify the job_runner thread.
20:58:02 HBMASTER: job (0, 0, 19) submitted to dispatcher
20:58:02 DISPATCHER: Trying to submit another job.
20:58:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:58:02 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:58:02 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:58:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:58:02 WORKER: start processing job (0, 0, 19)
20:58:02 WORKER: args: ()
20:58:02 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 20, 'last_n_outputs': 13, 'lr': 0.0538371504594791, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.06817988008995533}, 'budget': 44.44444444444444, 'working_directory': '.'}
20:58:13 DISPATCHER: Starting worker discovery
20:58:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:58:13 DISPATCHER: Finished worker discovery
Exception in thread Thread-425:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

20:58:55 WORKER: done with job (0, 0, 19), trying to register it.
20:58:55 WORKER: registered result for job (0, 0, 19) with dispatcher
20:58:55 DISPATCHER: job (0, 0, 19) finished
20:58:55 DISPATCHER: register_result: lock acquired
20:58:55 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:58:55 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 20, 'last_n_outputs': 13, 'lr': 0.0538371504594791, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.06817988008995533}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.36604115942069265, 'info': {'music-speech': 0.36604115942069265, 'config': "{'batch_size': 64, 'hidden_dim': 20, 'last_n_outputs': 13, 'lr': 0.0538371504594791, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 86, 'weight_decay': 0.06817988008995533}"}}
exception: None

20:58:55 job_callback for (0, 0, 19) started
20:58:55 DISPATCHER: Trying to submit another job.
20:58:55 job_callback for (0, 0, 19) got condition
20:58:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:58:55 done building a new model for budget 44.444444 based on 9/17 split
Best loss for this budget:-0.771619





20:58:55 HBMASTER: Trying to run another job!
20:58:55 job_callback for (0, 0, 19) finished
20:58:55 start sampling a new configuration.
20:58:55 done sampling a new configuration.
20:58:55 HBMASTER: schedule new run for iteration 0
20:58:55 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
20:58:55 HBMASTER: submitting job (0, 0, 20) to dispatcher
20:58:55 DISPATCHER: trying to submit job (0, 0, 20)
20:58:55 DISPATCHER: trying to notify the job_runner thread.
20:58:55 HBMASTER: job (0, 0, 20) submitted to dispatcher
20:58:55 DISPATCHER: Trying to submit another job.
20:58:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:58:55 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:58:55 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:58:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:58:55 WORKER: start processing job (0, 0, 20)
20:58:55 WORKER: args: ()
20:58:55 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 37, 'last_n_outputs': 44, 'lr': 0.0012771989060066124, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.18041980192015164}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-426:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

20:59:13 DISPATCHER: Starting worker discovery
20:59:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:59:13 DISPATCHER: Finished worker discovery
20:59:48 WORKER: done with job (0, 0, 20), trying to register it.
20:59:48 WORKER: registered result for job (0, 0, 20) with dispatcher
20:59:48 DISPATCHER: job (0, 0, 20) finished
20:59:48 DISPATCHER: register_result: lock acquired
20:59:48 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
20:59:48 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 37, 'last_n_outputs': 44, 'lr': 0.0012771989060066124, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.18041980192015164}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.859463038994192, 'info': {'music-speech': 0.859463038994192, 'config': "{'batch_size': 64, 'hidden_dim': 37, 'last_n_outputs': 44, 'lr': 0.0012771989060066124, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.18041980192015164}"}}
exception: None

20:59:48 job_callback for (0, 0, 20) started
20:59:48 DISPATCHER: Trying to submit another job.
20:59:48 job_callback for (0, 0, 20) got condition
20:59:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
20:59:48 done building a new model for budget 44.444444 based on 9/17 split
Best loss for this budget:-0.859463





20:59:48 HBMASTER: Trying to run another job!
20:59:48 job_callback for (0, 0, 20) finished
20:59:48 start sampling a new configuration.
20:59:48 best_vector: [2, 0.7177737430340013, 0.4438168762383576, 0.9224032493619858, 0.12181032859448324, 0, 0.7271961825558282, 0.8813769365749508], 0.004507082692285768, 0.28139517634034455, 0.0012682713289762686
20:59:48 done sampling a new configuration.
20:59:48 HBMASTER: schedule new run for iteration 0
20:59:48 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
20:59:48 HBMASTER: submitting job (0, 0, 21) to dispatcher
20:59:48 DISPATCHER: trying to submit job (0, 0, 21)
20:59:48 DISPATCHER: trying to notify the job_runner thread.
20:59:48 HBMASTER: job (0, 0, 21) submitted to dispatcher
20:59:48 DISPATCHER: Trying to submit another job.
20:59:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
20:59:48 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216
20:59:48 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
20:59:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
20:59:48 WORKER: start processing job (0, 0, 21)
20:59:48 WORKER: args: ()
20:59:48 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 78, 'last_n_outputs': 23, 'lr': 0.0699530248649058, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.14018380117039683}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-427:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

21:00:13 DISPATCHER: Starting worker discovery
21:00:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:00:13 DISPATCHER: Finished worker discovery
21:00:41 WORKER: done with job (0, 0, 21), trying to register it.
21:00:41 WORKER: registered result for job (0, 0, 21) with dispatcher
21:00:41 DISPATCHER: job (0, 0, 21) finished
21:00:41 DISPATCHER: register_result: lock acquired
21:00:41 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
21:00:41 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 78, 'last_n_outputs': 23, 'lr': 0.0699530248649058, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.14018380117039683}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6538029181667625, 'info': {'music-speech': 0.6538029181667625, 'config': "{'batch_size': 64, 'hidden_dim': 78, 'last_n_outputs': 23, 'lr': 0.0699530248649058, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.14018380117039683}"}}
exception: None

21:00:41 job_callback for (0, 0, 21) started
21:00:41 DISPATCHER: Trying to submit another job.
21:00:41 job_callback for (0, 0, 21) got condition
21:00:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:00:41 done building a new model for budget 44.444444 based on 9/18 split
Best loss for this budget:-0.859463





21:00:41 HBMASTER: Trying to run another job!
21:00:41 job_callback for (0, 0, 21) finished
21:00:41 start sampling a new configuration.
21:00:41 done sampling a new configuration.
21:00:41 HBMASTER: schedule new run for iteration 0
21:00:41 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
21:00:41 HBMASTER: submitting job (0, 0, 22) to dispatcher
21:00:41 DISPATCHER: trying to submit job (0, 0, 22)
21:00:41 DISPATCHER: trying to notify the job_runner thread.
21:00:41 HBMASTER: job (0, 0, 22) submitted to dispatcher
21:00:41 DISPATCHER: Trying to submit another job.
21:00:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:00:41 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpul.22021139727314577216
21:00:41 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
21:00:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:00:41 WORKER: start processing job (0, 0, 22)
21:00:41 WORKER: args: ()
21:00:41 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 40, 'last_n_outputs': 23, 'lr': 0.04572631462712304, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.010732284861934338}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-428:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

21:01:13 DISPATCHER: Starting worker discovery
21:01:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:01:13 DISPATCHER: Finished worker discovery
21:01:34 WORKER: done with job (0, 0, 22), trying to register it.
21:01:34 DISPATCHER: job (0, 0, 22) finished
21:01:34 WORKER: registered result for job (0, 0, 22) with dispatcher
21:01:34 DISPATCHER: register_result: lock acquired
21:01:34 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
21:01:34 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 40, 'last_n_outputs': 23, 'lr': 0.04572631462712304, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.010732284861934338}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3700126713261435, 'info': {'music-speech': 0.3700126713261435, 'config': "{'batch_size': 64, 'hidden_dim': 40, 'last_n_outputs': 23, 'lr': 0.04572631462712304, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.010732284861934338}"}}
exception: None

21:01:34 job_callback for (0, 0, 22) started
21:01:34 DISPATCHER: Trying to submit another job.
21:01:34 job_callback for (0, 0, 22) got condition
21:01:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:01:34 done building a new model for budget 44.444444 based on 9/19 split
Best loss for this budget:-0.859463





21:01:34 HBMASTER: Trying to run another job!
21:01:34 job_callback for (0, 0, 22) finished
21:01:34 start sampling a new configuration.
21:01:34 best_vector: [0, 0.04375843563995235, 0.8295948742139525, 0.201502079820604, 0.06299881735524701, 0, 0.8268960358852013, 0.7344896943381798], 0.001170671496360132, 1.135098175853849, 0.0013288270800424814
21:01:34 done sampling a new configuration.
21:01:34 HBMASTER: schedule new run for iteration 0
21:01:34 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
21:01:34 HBMASTER: submitting job (0, 0, 23) to dispatcher
21:01:34 DISPATCHER: trying to submit job (0, 0, 23)
21:01:34 DISPATCHER: trying to notify the job_runner thread.
21:01:34 HBMASTER: job (0, 0, 23) submitted to dispatcher
21:01:34 DISPATCHER: Trying to submit another job.
21:01:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:01:34 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216
21:01:34 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
21:01:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:01:34 WORKER: start processing job (0, 0, 23)
21:01:34 WORKER: args: ()
21:01:34 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 23, 'last_n_outputs': 42, 'lr': 0.00252932222199585, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.09028032708199928}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-429:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

21:02:13 DISPATCHER: Starting worker discovery
21:02:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:02:13 DISPATCHER: Finished worker discovery
21:02:27 WORKER: done with job (0, 0, 23), trying to register it.
21:02:27 WORKER: registered result for job (0, 0, 23) with dispatcher
21:02:27 DISPATCHER: job (0, 0, 23) finished
21:02:27 DISPATCHER: register_result: lock acquired
21:02:27 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
21:02:27 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 23, 'last_n_outputs': 42, 'lr': 0.00252932222199585, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.09028032708199928}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6791189103937271, 'info': {'music-speech': 0.6791189103937271, 'config': "{'batch_size': 16, 'hidden_dim': 23, 'last_n_outputs': 42, 'lr': 0.00252932222199585, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.09028032708199928}"}}
exception: None

21:02:27 job_callback for (0, 0, 23) started
21:02:27 DISPATCHER: Trying to submit another job.
21:02:27 job_callback for (0, 0, 23) got condition
21:02:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:02:27 done building a new model for budget 44.444444 based on 9/20 split
Best loss for this budget:-0.859463





21:02:27 HBMASTER: Trying to run another job!
21:02:27 job_callback for (0, 0, 23) finished
21:02:27 start sampling a new configuration.
21:02:27 done sampling a new configuration.
21:02:27 HBMASTER: schedule new run for iteration 0
21:02:27 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
21:02:27 HBMASTER: submitting job (0, 0, 24) to dispatcher
21:02:27 DISPATCHER: trying to submit job (0, 0, 24)
21:02:27 DISPATCHER: trying to notify the job_runner thread.
21:02:27 HBMASTER: job (0, 0, 24) submitted to dispatcher
21:02:27 DISPATCHER: Trying to submit another job.
21:02:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:02:27 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpul.22021139727314577216
21:02:27 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
21:02:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:02:27 WORKER: start processing job (0, 0, 24)
21:02:27 WORKER: args: ()
21:02:27 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 56, 'last_n_outputs': 2, 'lr': 0.0055078866473045746, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.09050443354227}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-430:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

21:03:13 DISPATCHER: Starting worker discovery
21:03:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:03:13 DISPATCHER: Finished worker discovery
21:03:20 WORKER: done with job (0, 0, 24), trying to register it.
21:03:20 WORKER: registered result for job (0, 0, 24) with dispatcher
21:03:20 DISPATCHER: job (0, 0, 24) finished
21:03:20 DISPATCHER: register_result: lock acquired
21:03:20 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
21:03:20 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 56, 'last_n_outputs': 2, 'lr': 0.0055078866473045746, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.09050443354227}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0784412719528728, 'info': {'music-speech': 0.0784412719528728, 'config': "{'batch_size': 64, 'hidden_dim': 56, 'last_n_outputs': 2, 'lr': 0.0055078866473045746, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 21, 'weight_decay': 0.09050443354227}"}}
exception: None

21:03:20 job_callback for (0, 0, 24) started
21:03:20 DISPATCHER: Trying to submit another job.
21:03:20 job_callback for (0, 0, 24) got condition
21:03:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:03:20 done building a new model for budget 44.444444 based on 9/21 split
Best loss for this budget:-0.859463





21:03:20 HBMASTER: Trying to run another job!
21:03:20 job_callback for (0, 0, 24) finished
21:03:20 start sampling a new configuration.
21:03:20 done sampling a new configuration.
21:03:20 HBMASTER: schedule new run for iteration 0
21:03:20 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
21:03:20 HBMASTER: submitting job (0, 0, 25) to dispatcher
21:03:20 DISPATCHER: trying to submit job (0, 0, 25)
21:03:20 DISPATCHER: trying to notify the job_runner thread.
21:03:20 HBMASTER: job (0, 0, 25) submitted to dispatcher
21:03:20 DISPATCHER: Trying to submit another job.
21:03:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:03:20 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216
21:03:20 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
21:03:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:03:20 WORKER: start processing job (0, 0, 25)
21:03:20 WORKER: args: ()
21:03:20 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 22, 'last_n_outputs': 7, 'lr': 0.08242345183055545, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.01910051846422005}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-431:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

21:04:13 DISPATCHER: Starting worker discovery
21:04:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:04:13 DISPATCHER: Finished worker discovery
21:04:13 WORKER: done with job (0, 0, 25), trying to register it.
21:04:13 WORKER: registered result for job (0, 0, 25) with dispatcher
21:04:13 DISPATCHER: job (0, 0, 25) finished
21:04:13 DISPATCHER: register_result: lock acquired
21:04:13 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
21:04:13 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 22, 'last_n_outputs': 7, 'lr': 0.08242345183055545, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.01910051846422005}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.475368821854251, 'info': {'music-speech': 0.475368821854251, 'config': "{'batch_size': 16, 'hidden_dim': 22, 'last_n_outputs': 7, 'lr': 0.08242345183055545, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.01910051846422005}"}}
exception: None

21:04:13 job_callback for (0, 0, 25) started
21:04:13 DISPATCHER: Trying to submit another job.
21:04:13 job_callback for (0, 0, 25) got condition
21:04:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:04:13 done building a new model for budget 44.444444 based on 9/22 split
Best loss for this budget:-0.859463





21:04:13 HBMASTER: Trying to run another job!
21:04:13 job_callback for (0, 0, 25) finished
21:04:13 start sampling a new configuration.
21:04:13 best_vector: [0, 0.5783372072670082, 0.9885295438167707, 0.16124388014767693, 0.11642465281938666, 0, 0.28471949325401746, 0.8050375436861334], 0.012263583924920229, 0.23047012647188606, 0.002826389738174954
21:04:13 done sampling a new configuration.
21:04:13 HBMASTER: schedule new run for iteration 0
21:04:13 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
21:04:13 HBMASTER: submitting job (0, 0, 26) to dispatcher
21:04:13 DISPATCHER: trying to submit job (0, 0, 26)
21:04:13 DISPATCHER: trying to notify the job_runner thread.
21:04:13 HBMASTER: job (0, 0, 26) submitted to dispatcher
21:04:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:04:13 DISPATCHER: Trying to submit another job.
21:04:13 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpul.22021139727314577216
21:04:13 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
21:04:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:04:13 WORKER: start processing job (0, 0, 26)
21:04:13 WORKER: args: ()
21:04:13 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 66, 'last_n_outputs': 50, 'lr': 0.002101298547396252, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.11152647916843783}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-432:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

21:05:06 WORKER: done with job (0, 0, 26), trying to register it.
21:05:06 WORKER: registered result for job (0, 0, 26) with dispatcher
21:05:06 DISPATCHER: job (0, 0, 26) finished
21:05:06 DISPATCHER: register_result: lock acquired
21:05:06 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
21:05:06 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 66, 'last_n_outputs': 50, 'lr': 0.002101298547396252, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.11152647916843783}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7063111066062975, 'info': {'music-speech': 0.7063111066062975, 'config': "{'batch_size': 16, 'hidden_dim': 66, 'last_n_outputs': 50, 'lr': 0.002101298547396252, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.11152647916843783}"}}
exception: None

21:05:06 job_callback for (0, 0, 26) started
21:05:06 DISPATCHER: Trying to submit another job.
21:05:06 job_callback for (0, 0, 26) got condition
21:05:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:05:06 done building a new model for budget 44.444444 based on 9/22 split
Best loss for this budget:-0.859463





21:05:06 HBMASTER: Trying to run another job!
21:05:06 job_callback for (0, 0, 26) finished
21:05:06 ITERATION: Advancing config (0, 0, 0) to next budget 133.333333
21:05:06 ITERATION: Advancing config (0, 0, 3) to next budget 133.333333
21:05:06 ITERATION: Advancing config (0, 0, 7) to next budget 133.333333
21:05:06 ITERATION: Advancing config (0, 0, 11) to next budget 133.333333
21:05:06 ITERATION: Advancing config (0, 0, 12) to next budget 133.333333
21:05:06 ITERATION: Advancing config (0, 0, 16) to next budget 133.333333
21:05:06 ITERATION: Advancing config (0, 0, 20) to next budget 133.333333
21:05:06 ITERATION: Advancing config (0, 0, 23) to next budget 133.333333
21:05:06 ITERATION: Advancing config (0, 0, 26) to next budget 133.333333
21:05:06 HBMASTER: schedule new run for iteration 0
21:05:06 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
21:05:06 HBMASTER: submitting job (0, 0, 0) to dispatcher
21:05:06 DISPATCHER: trying to submit job (0, 0, 0)
21:05:06 DISPATCHER: trying to notify the job_runner thread.
21:05:06 HBMASTER: job (0, 0, 0) submitted to dispatcher
21:05:06 DISPATCHER: Trying to submit another job.
21:05:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:05:06 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
21:05:06 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
21:05:06 WORKER: start processing job (0, 0, 0)
21:05:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:05:06 WORKER: args: ()
21:05:06 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 58, 'last_n_outputs': 49, 'lr': 0.004174314383387121, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.011255239188562801}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:05:13 DISPATCHER: Starting worker discovery
21:05:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:05:13 DISPATCHER: Finished worker discovery
Exception in thread Thread-433:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

21:06:13 DISPATCHER: Starting worker discovery
21:06:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:06:13 DISPATCHER: Finished worker discovery
21:07:13 DISPATCHER: Starting worker discovery
21:07:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:07:13 DISPATCHER: Finished worker discovery
21:07:29 WORKER: done with job (0, 0, 0), trying to register it.
21:07:29 WORKER: registered result for job (0, 0, 0) with dispatcher
21:07:29 DISPATCHER: job (0, 0, 0) finished
21:07:29 DISPATCHER: register_result: lock acquired
21:07:29 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
21:07:29 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 58, 'last_n_outputs': 49, 'lr': 0.004174314383387121, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.011255239188562801}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5841388876882845, 'info': {'music-speech': 0.5841388876882845, 'config': "{'batch_size': 32, 'hidden_dim': 58, 'last_n_outputs': 49, 'lr': 0.004174314383387121, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.011255239188562801}"}}
exception: None

21:07:29 job_callback for (0, 0, 0) started
21:07:29 DISPATCHER: Trying to submit another job.
21:07:29 job_callback for (0, 0, 0) got condition
21:07:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:07:29 Only 1 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
21:07:29 HBMASTER: Trying to run another job!
21:07:29 job_callback for (0, 0, 0) finished
21:07:29 HBMASTER: schedule new run for iteration 0
21:07:29 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
21:07:29 HBMASTER: submitting job (0, 0, 3) to dispatcher
21:07:29 DISPATCHER: trying to submit job (0, 0, 3)
21:07:29 DISPATCHER: trying to notify the job_runner thread.
21:07:29 HBMASTER: job (0, 0, 3) submitted to dispatcher
21:07:29 DISPATCHER: Trying to submit another job.
21:07:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:07:29 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
21:07:29 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
21:07:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:07:29 WORKER: start processing job (0, 0, 3)
21:07:29 WORKER: args: ()
21:07:29 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 54, 'last_n_outputs': 17, 'lr': 0.03088371491859569, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.06563132292099166}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-434:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

21:08:13 DISPATCHER: Starting worker discovery
21:08:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:08:13 DISPATCHER: Finished worker discovery
21:09:13 DISPATCHER: Starting worker discovery
21:09:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:09:13 DISPATCHER: Finished worker discovery
21:09:51 WORKER: done with job (0, 0, 3), trying to register it.
21:09:51 DISPATCHER: job (0, 0, 3) finished
21:09:51 WORKER: registered result for job (0, 0, 3) with dispatcher
21:09:51 DISPATCHER: register_result: lock acquired
21:09:51 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
21:09:51 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 54, 'last_n_outputs': 17, 'lr': 0.03088371491859569, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.06563132292099166}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7957386092249061, 'info': {'music-speech': 0.7957386092249061, 'config': "{'batch_size': 16, 'hidden_dim': 54, 'last_n_outputs': 17, 'lr': 0.03088371491859569, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.06563132292099166}"}}
exception: None

21:09:51 job_callback for (0, 0, 3) started
21:09:51 DISPATCHER: Trying to submit another job.
21:09:51 job_callback for (0, 0, 3) got condition
21:09:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:09:51 Only 2 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
21:09:51 HBMASTER: Trying to run another job!
21:09:51 job_callback for (0, 0, 3) finished
21:09:51 HBMASTER: schedule new run for iteration 0
21:09:51 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
21:09:51 HBMASTER: submitting job (0, 0, 7) to dispatcher
21:09:51 DISPATCHER: trying to submit job (0, 0, 7)
21:09:51 DISPATCHER: trying to notify the job_runner thread.
21:09:51 HBMASTER: job (0, 0, 7) submitted to dispatcher
21:09:51 DISPATCHER: Trying to submit another job.
21:09:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:09:51 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
21:09:51 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
21:09:51 WORKER: start processing job (0, 0, 7)
21:09:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:09:51 WORKER: args: ()
21:09:51 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 25, 'last_n_outputs': 46, 'lr': 0.0013095431373116623, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.03846888659208803}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-435:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

21:10:13 DISPATCHER: Starting worker discovery
21:10:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:10:13 DISPATCHER: Finished worker discovery
21:11:13 DISPATCHER: Starting worker discovery
21:11:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:11:13 DISPATCHER: Finished worker discovery
21:12:13 DISPATCHER: Starting worker discovery
21:12:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:12:13 DISPATCHER: Finished worker discovery
21:12:13 WORKER: done with job (0, 0, 7), trying to register it.
21:12:13 DISPATCHER: job (0, 0, 7) finished
21:12:13 WORKER: registered result for job (0, 0, 7) with dispatcher
21:12:13 DISPATCHER: register_result: lock acquired
21:12:13 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
21:12:13 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 25, 'last_n_outputs': 46, 'lr': 0.0013095431373116623, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.03846888659208803}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5190747339706276, 'info': {'music-speech': 0.5190747339706276, 'config': "{'batch_size': 16, 'hidden_dim': 25, 'last_n_outputs': 46, 'lr': 0.0013095431373116623, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.03846888659208803}"}}
exception: None

21:12:13 job_callback for (0, 0, 7) started
21:12:13 DISPATCHER: Trying to submit another job.
21:12:13 job_callback for (0, 0, 7) got condition
21:12:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:12:13 Only 3 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
21:12:13 HBMASTER: Trying to run another job!
21:12:13 job_callback for (0, 0, 7) finished
21:12:13 HBMASTER: schedule new run for iteration 0
21:12:13 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
21:12:13 HBMASTER: submitting job (0, 0, 11) to dispatcher
21:12:13 DISPATCHER: trying to submit job (0, 0, 11)
21:12:13 DISPATCHER: trying to notify the job_runner thread.
21:12:13 HBMASTER: job (0, 0, 11) submitted to dispatcher
21:12:13 DISPATCHER: Trying to submit another job.
21:12:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:12:13 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpul.22021139727314577216
21:12:13 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
21:12:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:12:13 WORKER: start processing job (0, 0, 11)
21:12:13 WORKER: args: ()
21:12:13 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 35, 'last_n_outputs': 50, 'lr': 0.006576646352082888, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.07204560098683786}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-436:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

21:13:13 DISPATCHER: Starting worker discovery
21:13:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:13:13 DISPATCHER: Finished worker discovery
21:14:13 DISPATCHER: Starting worker discovery
21:14:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:14:13 DISPATCHER: Finished worker discovery
21:14:35 WORKER: done with job (0, 0, 11), trying to register it.
21:14:35 WORKER: registered result for job (0, 0, 11) with dispatcher
21:14:35 DISPATCHER: job (0, 0, 11) finished
21:14:35 DISPATCHER: register_result: lock acquired
21:14:35 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
21:14:35 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 35, 'last_n_outputs': 50, 'lr': 0.006576646352082888, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.07204560098683786}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.769917828760358, 'info': {'music-speech': 0.769917828760358, 'config': "{'batch_size': 32, 'hidden_dim': 35, 'last_n_outputs': 50, 'lr': 0.006576646352082888, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.07204560098683786}"}}
exception: None

21:14:35 job_callback for (0, 0, 11) started
21:14:35 DISPATCHER: Trying to submit another job.
21:14:35 job_callback for (0, 0, 11) got condition
21:14:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:14:35 Only 4 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
21:14:35 HBMASTER: Trying to run another job!
21:14:35 job_callback for (0, 0, 11) finished
21:14:35 HBMASTER: schedule new run for iteration 0
21:14:35 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
21:14:35 HBMASTER: submitting job (0, 0, 12) to dispatcher
21:14:35 DISPATCHER: trying to submit job (0, 0, 12)
21:14:35 DISPATCHER: trying to notify the job_runner thread.
21:14:35 HBMASTER: job (0, 0, 12) submitted to dispatcher
21:14:35 DISPATCHER: Trying to submit another job.
21:14:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:14:35 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216
21:14:35 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
21:14:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:14:35 WORKER: start processing job (0, 0, 12)
21:14:35 WORKER: args: ()
21:14:35 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 87, 'last_n_outputs': 30, 'lr': 0.00951794158823696, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.035127588807569214}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-437:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

21:15:13 DISPATCHER: Starting worker discovery
21:15:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:15:13 DISPATCHER: Finished worker discovery
21:16:13 DISPATCHER: Starting worker discovery
21:16:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:16:13 DISPATCHER: Finished worker discovery
21:16:57 WORKER: done with job (0, 0, 12), trying to register it.
21:16:57 WORKER: registered result for job (0, 0, 12) with dispatcher
21:16:57 DISPATCHER: job (0, 0, 12) finished
21:16:57 DISPATCHER: register_result: lock acquired
21:16:57 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
21:16:57 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 87, 'last_n_outputs': 30, 'lr': 0.00951794158823696, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.035127588807569214}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.2717559391290731, 'info': {'music-speech': 0.2717559391290731, 'config': "{'batch_size': 64, 'hidden_dim': 87, 'last_n_outputs': 30, 'lr': 0.00951794158823696, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 24, 'weight_decay': 0.035127588807569214}"}}
exception: None

21:16:57 job_callback for (0, 0, 12) started
21:16:57 DISPATCHER: Trying to submit another job.
21:16:57 job_callback for (0, 0, 12) got condition
21:16:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:16:57 Only 5 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
21:16:57 HBMASTER: Trying to run another job!
21:16:57 job_callback for (0, 0, 12) finished
21:16:57 HBMASTER: schedule new run for iteration 0
21:16:57 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
21:16:57 HBMASTER: submitting job (0, 0, 16) to dispatcher
21:16:57 DISPATCHER: trying to submit job (0, 0, 16)
21:16:57 DISPATCHER: trying to notify the job_runner thread.
21:16:57 HBMASTER: job (0, 0, 16) submitted to dispatcher
21:16:57 DISPATCHER: Trying to submit another job.
21:16:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:16:57 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216
21:16:57 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
21:16:57 WORKER: start processing job (0, 0, 16)
21:16:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:16:57 WORKER: args: ()
21:16:57 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 72, 'last_n_outputs': 17, 'lr': 0.004768652857833486, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.08288191084184723}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-438:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

21:17:13 DISPATCHER: Starting worker discovery
21:17:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:17:13 DISPATCHER: Finished worker discovery
21:18:13 DISPATCHER: Starting worker discovery
21:18:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:18:13 DISPATCHER: Finished worker discovery
21:19:13 DISPATCHER: Starting worker discovery
21:19:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:19:13 DISPATCHER: Finished worker discovery
21:19:19 WORKER: done with job (0, 0, 16), trying to register it.
21:19:19 WORKER: registered result for job (0, 0, 16) with dispatcher
21:19:19 DISPATCHER: job (0, 0, 16) finished
21:19:19 DISPATCHER: register_result: lock acquired
21:19:19 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
21:19:19 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 72, 'last_n_outputs': 17, 'lr': 0.004768652857833486, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.08288191084184723}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8618914931603838, 'info': {'music-speech': 0.8618914931603838, 'config': "{'batch_size': 64, 'hidden_dim': 72, 'last_n_outputs': 17, 'lr': 0.004768652857833486, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.08288191084184723}"}}
exception: None

21:19:19 job_callback for (0, 0, 16) started
21:19:19 DISPATCHER: Trying to submit another job.
21:19:19 job_callback for (0, 0, 16) got condition
21:19:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:19:19 Only 6 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
21:19:19 HBMASTER: Trying to run another job!
21:19:19 job_callback for (0, 0, 16) finished
21:19:19 HBMASTER: schedule new run for iteration 0
21:19:19 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
21:19:19 HBMASTER: submitting job (0, 0, 20) to dispatcher
21:19:19 DISPATCHER: trying to submit job (0, 0, 20)
21:19:19 DISPATCHER: trying to notify the job_runner thread.
21:19:19 HBMASTER: job (0, 0, 20) submitted to dispatcher
21:19:19 DISPATCHER: Trying to submit another job.
21:19:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:19:19 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216
21:19:19 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
21:19:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:19:19 WORKER: start processing job (0, 0, 20)
21:19:19 WORKER: args: ()
21:19:19 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 37, 'last_n_outputs': 44, 'lr': 0.0012771989060066124, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.18041980192015164}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-439:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

21:20:13 DISPATCHER: Starting worker discovery
21:20:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:20:13 DISPATCHER: Finished worker discovery
21:21:13 DISPATCHER: Starting worker discovery
21:21:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:21:13 DISPATCHER: Finished worker discovery
21:21:41 WORKER: done with job (0, 0, 20), trying to register it.
21:21:41 WORKER: registered result for job (0, 0, 20) with dispatcher
21:21:41 DISPATCHER: job (0, 0, 20) finished
21:21:41 DISPATCHER: register_result: lock acquired
21:21:41 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
21:21:41 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 37, 'last_n_outputs': 44, 'lr': 0.0012771989060066124, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.18041980192015164}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7693253012342784, 'info': {'music-speech': 0.7693253012342784, 'config': "{'batch_size': 64, 'hidden_dim': 37, 'last_n_outputs': 44, 'lr': 0.0012771989060066124, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 68, 'weight_decay': 0.18041980192015164}"}}
exception: None

21:21:41 job_callback for (0, 0, 20) started
21:21:41 DISPATCHER: Trying to submit another job.
21:21:41 job_callback for (0, 0, 20) got condition
21:21:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:21:41 Only 7 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
21:21:41 HBMASTER: Trying to run another job!
21:21:41 job_callback for (0, 0, 20) finished
21:21:41 HBMASTER: schedule new run for iteration 0
21:21:41 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
21:21:41 HBMASTER: submitting job (0, 0, 23) to dispatcher
21:21:41 DISPATCHER: trying to submit job (0, 0, 23)
21:21:41 DISPATCHER: trying to notify the job_runner thread.
21:21:41 HBMASTER: job (0, 0, 23) submitted to dispatcher
21:21:41 DISPATCHER: Trying to submit another job.
21:21:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:21:41 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216
21:21:41 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
21:21:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:21:41 WORKER: start processing job (0, 0, 23)
21:21:41 WORKER: args: ()
21:21:41 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 23, 'last_n_outputs': 42, 'lr': 0.00252932222199585, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.09028032708199928}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-440:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

21:22:13 DISPATCHER: Starting worker discovery
21:22:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:22:13 DISPATCHER: Finished worker discovery
21:23:13 DISPATCHER: Starting worker discovery
21:23:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:23:13 DISPATCHER: Finished worker discovery
21:24:03 WORKER: done with job (0, 0, 23), trying to register it.
21:24:03 WORKER: registered result for job (0, 0, 23) with dispatcher
21:24:03 DISPATCHER: job (0, 0, 23) finished
21:24:03 DISPATCHER: register_result: lock acquired
21:24:03 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
21:24:03 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 23, 'last_n_outputs': 42, 'lr': 0.00252932222199585, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.09028032708199928}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6787098687532429, 'info': {'music-speech': 0.6787098687532429, 'config': "{'batch_size': 16, 'hidden_dim': 23, 'last_n_outputs': 42, 'lr': 0.00252932222199585, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.09028032708199928}"}}
exception: None

21:24:03 job_callback for (0, 0, 23) started
21:24:03 DISPATCHER: Trying to submit another job.
21:24:03 job_callback for (0, 0, 23) got condition
21:24:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:24:03 Only 8 run(s) for budget 133.333333 available, need more than 10 -> can't build model!
21:24:03 HBMASTER: Trying to run another job!
21:24:03 job_callback for (0, 0, 23) finished
21:24:03 HBMASTER: schedule new run for iteration 0
21:24:03 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
21:24:03 HBMASTER: submitting job (0, 0, 26) to dispatcher
21:24:03 DISPATCHER: trying to submit job (0, 0, 26)
21:24:03 DISPATCHER: trying to notify the job_runner thread.
21:24:03 HBMASTER: job (0, 0, 26) submitted to dispatcher
21:24:03 DISPATCHER: Trying to submit another job.
21:24:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:24:03 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpul.22021139727314577216
21:24:03 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
21:24:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:24:03 WORKER: start processing job (0, 0, 26)
21:24:03 WORKER: args: ()
21:24:03 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 66, 'last_n_outputs': 50, 'lr': 0.002101298547396252, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.11152647916843783}, 'budget': 133.33333333333331, 'working_directory': '.'}
21:24:13 DISPATCHER: Starting worker discovery
21:24:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:24:13 DISPATCHER: Finished worker discovery
Exception in thread Thread-441:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

21:25:13 DISPATCHER: Starting worker discovery
21:25:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:25:13 DISPATCHER: Finished worker discovery
21:26:13 DISPATCHER: Starting worker discovery
21:26:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:26:13 DISPATCHER: Finished worker discovery
21:26:25 WORKER: done with job (0, 0, 26), trying to register it.
21:26:25 WORKER: registered result for job (0, 0, 26) with dispatcher
21:26:25 DISPATCHER: job (0, 0, 26) finished
21:26:25 DISPATCHER: register_result: lock acquired
21:26:25 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
21:26:25 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 66, 'last_n_outputs': 50, 'lr': 0.002101298547396252, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.11152647916843783}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7019225295173958, 'info': {'music-speech': 0.7019225295173958, 'config': "{'batch_size': 16, 'hidden_dim': 66, 'last_n_outputs': 50, 'lr': 0.002101298547396252, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.11152647916843783}"}}
exception: None

21:26:25 job_callback for (0, 0, 26) started
21:26:25 DISPATCHER: Trying to submit another job.
21:26:25 job_callback for (0, 0, 26) got condition
21:26:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:26:25 HBMASTER: Trying to run another job!
21:26:25 job_callback for (0, 0, 26) finished
21:26:25 ITERATION: Advancing config (0, 0, 3) to next budget 400.000000
21:26:25 ITERATION: Advancing config (0, 0, 11) to next budget 400.000000
21:26:25 ITERATION: Advancing config (0, 0, 16) to next budget 400.000000
21:26:25 HBMASTER: schedule new run for iteration 0
21:26:25 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
21:26:25 HBMASTER: submitting job (0, 0, 3) to dispatcher
21:26:25 DISPATCHER: trying to submit job (0, 0, 3)
21:26:25 DISPATCHER: trying to notify the job_runner thread.
21:26:25 HBMASTER: job (0, 0, 3) submitted to dispatcher
21:26:25 DISPATCHER: Trying to submit another job.
21:26:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:26:25 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
21:26:25 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
21:26:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:26:25 WORKER: start processing job (0, 0, 3)
21:26:25 WORKER: args: ()
21:26:25 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 54, 'last_n_outputs': 17, 'lr': 0.03088371491859569, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.06563132292099166}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-442:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

21:27:13 DISPATCHER: Starting worker discovery
21:27:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:27:13 DISPATCHER: Finished worker discovery
21:28:13 DISPATCHER: Starting worker discovery
21:28:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:28:13 DISPATCHER: Finished worker discovery
21:29:13 DISPATCHER: Starting worker discovery
21:29:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:29:13 DISPATCHER: Finished worker discovery
21:30:13 DISPATCHER: Starting worker discovery
21:30:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:30:13 DISPATCHER: Finished worker discovery
21:31:13 DISPATCHER: Starting worker discovery
21:31:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:31:13 DISPATCHER: Finished worker discovery
21:32:13 DISPATCHER: Starting worker discovery
21:32:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:32:13 DISPATCHER: Finished worker discovery
21:33:13 DISPATCHER: Starting worker discovery
21:33:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:33:13 DISPATCHER: Finished worker discovery
21:33:14 WORKER: done with job (0, 0, 3), trying to register it.
21:33:14 WORKER: registered result for job (0, 0, 3) with dispatcher
21:33:14 DISPATCHER: job (0, 0, 3) finished
21:33:14 DISPATCHER: register_result: lock acquired
21:33:14 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
21:33:14 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 54, 'last_n_outputs': 17, 'lr': 0.03088371491859569, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.06563132292099166}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6791921868878791, 'info': {'music-speech': 0.6791921868878791, 'config': "{'batch_size': 16, 'hidden_dim': 54, 'last_n_outputs': 17, 'lr': 0.03088371491859569, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.06563132292099166}"}}
exception: None

21:33:14 job_callback for (0, 0, 3) started
21:33:14 DISPATCHER: Trying to submit another job.
21:33:14 job_callback for (0, 0, 3) got condition
21:33:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:33:14 Only 1 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
21:33:14 HBMASTER: Trying to run another job!
21:33:14 job_callback for (0, 0, 3) finished
21:33:14 HBMASTER: schedule new run for iteration 0
21:33:14 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
21:33:14 HBMASTER: submitting job (0, 0, 11) to dispatcher
21:33:14 DISPATCHER: trying to submit job (0, 0, 11)
21:33:14 DISPATCHER: trying to notify the job_runner thread.
21:33:14 HBMASTER: job (0, 0, 11) submitted to dispatcher
21:33:14 DISPATCHER: Trying to submit another job.
21:33:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:33:14 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpul.22021139727314577216
21:33:14 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
21:33:14 WORKER: start processing job (0, 0, 11)
21:33:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:33:14 WORKER: args: ()
21:33:14 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 35, 'last_n_outputs': 50, 'lr': 0.006576646352082888, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.07204560098683786}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-443:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

21:34:13 DISPATCHER: Starting worker discovery
21:34:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:34:13 DISPATCHER: Finished worker discovery
21:35:13 DISPATCHER: Starting worker discovery
21:35:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:35:14 DISPATCHER: Finished worker discovery
21:36:14 DISPATCHER: Starting worker discovery
21:36:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:36:14 DISPATCHER: Finished worker discovery
21:37:14 DISPATCHER: Starting worker discovery
21:37:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:37:14 DISPATCHER: Finished worker discovery
21:38:14 DISPATCHER: Starting worker discovery
21:38:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:38:14 DISPATCHER: Finished worker discovery
21:39:14 DISPATCHER: Starting worker discovery
21:39:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:39:14 DISPATCHER: Finished worker discovery
21:40:03 WORKER: done with job (0, 0, 11), trying to register it.
21:40:03 WORKER: registered result for job (0, 0, 11) with dispatcher
21:40:03 DISPATCHER: job (0, 0, 11) finished
21:40:03 DISPATCHER: register_result: lock acquired
21:40:03 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
21:40:03 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 35, 'last_n_outputs': 50, 'lr': 0.006576646352082888, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.07204560098683786}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7278149085215236, 'info': {'music-speech': 0.7278149085215236, 'config': "{'batch_size': 32, 'hidden_dim': 35, 'last_n_outputs': 50, 'lr': 0.006576646352082888, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 70, 'weight_decay': 0.07204560098683786}"}}
exception: None

21:40:03 job_callback for (0, 0, 11) started
21:40:03 DISPATCHER: Trying to submit another job.
21:40:03 job_callback for (0, 0, 11) got condition
21:40:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:40:03 Only 2 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
21:40:03 HBMASTER: Trying to run another job!
21:40:03 job_callback for (0, 0, 11) finished
21:40:03 HBMASTER: schedule new run for iteration 0
21:40:03 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
21:40:03 HBMASTER: submitting job (0, 0, 16) to dispatcher
21:40:03 DISPATCHER: trying to submit job (0, 0, 16)
21:40:03 DISPATCHER: trying to notify the job_runner thread.
21:40:03 HBMASTER: job (0, 0, 16) submitted to dispatcher
21:40:03 DISPATCHER: Trying to submit another job.
21:40:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:40:03 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216
21:40:03 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
21:40:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:40:03 WORKER: start processing job (0, 0, 16)
21:40:03 WORKER: args: ()
21:40:03 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 72, 'last_n_outputs': 17, 'lr': 0.004768652857833486, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.08288191084184723}, 'budget': 400.0, 'working_directory': '.'}
21:40:14 DISPATCHER: Starting worker discovery
21:40:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:40:14 DISPATCHER: Finished worker discovery
Exception in thread Thread-444:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

21:41:14 DISPATCHER: Starting worker discovery
21:41:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:41:14 DISPATCHER: Finished worker discovery
21:42:14 DISPATCHER: Starting worker discovery
21:42:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:42:14 DISPATCHER: Finished worker discovery
21:43:14 DISPATCHER: Starting worker discovery
21:43:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:43:14 DISPATCHER: Finished worker discovery
21:44:14 DISPATCHER: Starting worker discovery
21:44:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:44:14 DISPATCHER: Finished worker discovery
21:45:14 DISPATCHER: Starting worker discovery
21:45:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:45:14 DISPATCHER: Finished worker discovery
21:46:14 DISPATCHER: Starting worker discovery
21:46:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:46:14 DISPATCHER: Finished worker discovery
21:46:52 WORKER: done with job (0, 0, 16), trying to register it.
21:46:52 WORKER: registered result for job (0, 0, 16) with dispatcher
21:46:52 DISPATCHER: job (0, 0, 16) finished
21:46:52 DISPATCHER: register_result: lock acquired
21:46:52 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
21:46:52 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 72, 'last_n_outputs': 17, 'lr': 0.004768652857833486, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.08288191084184723}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9949288330152393, 'info': {'music-speech': 0.9949288330152393, 'config': "{'batch_size': 64, 'hidden_dim': 72, 'last_n_outputs': 17, 'lr': 0.004768652857833486, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.08288191084184723}"}}
exception: None

21:46:52 job_callback for (0, 0, 16) started
21:46:52 DISPATCHER: Trying to submit another job.
21:46:52 job_callback for (0, 0, 16) got condition
21:46:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
21:46:52 Only 3 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
21:46:52 HBMASTER: Trying to run another job!
21:46:52 job_callback for (0, 0, 16) finished
21:46:52 ITERATION: Advancing config (0, 0, 16) to next budget 1200.000000
21:46:52 HBMASTER: schedule new run for iteration 0
21:46:52 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
21:46:52 HBMASTER: submitting job (0, 0, 16) to dispatcher
21:46:52 DISPATCHER: trying to submit job (0, 0, 16)
21:46:52 DISPATCHER: trying to notify the job_runner thread.
21:46:52 HBMASTER: job (0, 0, 16) submitted to dispatcher
21:46:52 DISPATCHER: Trying to submit another job.
21:46:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
21:46:52 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216
21:46:52 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
21:46:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
21:46:52 WORKER: start processing job (0, 0, 16)
21:46:52 WORKER: args: ()
21:46:52 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 72, 'last_n_outputs': 17, 'lr': 0.004768652857833486, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.08288191084184723}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-445:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

21:47:14 DISPATCHER: Starting worker discovery
21:47:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:47:14 DISPATCHER: Finished worker discovery
21:48:14 DISPATCHER: Starting worker discovery
21:48:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:48:14 DISPATCHER: Finished worker discovery
21:49:14 DISPATCHER: Starting worker discovery
21:49:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:49:14 DISPATCHER: Finished worker discovery
21:50:14 DISPATCHER: Starting worker discovery
21:50:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:50:14 DISPATCHER: Finished worker discovery
21:51:14 DISPATCHER: Starting worker discovery
21:51:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:51:14 DISPATCHER: Finished worker discovery
21:52:14 DISPATCHER: Starting worker discovery
21:52:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:52:14 DISPATCHER: Finished worker discovery
21:53:14 DISPATCHER: Starting worker discovery
21:53:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:53:14 DISPATCHER: Finished worker discovery
21:54:14 DISPATCHER: Starting worker discovery
21:54:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:54:14 DISPATCHER: Finished worker discovery
21:55:14 DISPATCHER: Starting worker discovery
21:55:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:55:14 DISPATCHER: Finished worker discovery
21:56:14 DISPATCHER: Starting worker discovery
21:56:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:56:14 DISPATCHER: Finished worker discovery
21:57:14 DISPATCHER: Starting worker discovery
21:57:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:57:14 DISPATCHER: Finished worker discovery
21:58:14 DISPATCHER: Starting worker discovery
21:58:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:58:14 DISPATCHER: Finished worker discovery
21:59:14 DISPATCHER: Starting worker discovery
21:59:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:59:14 DISPATCHER: Finished worker discovery
22:00:14 DISPATCHER: Starting worker discovery
22:00:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:00:14 DISPATCHER: Finished worker discovery
22:01:14 DISPATCHER: Starting worker discovery
22:01:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:01:14 DISPATCHER: Finished worker discovery
22:02:14 DISPATCHER: Starting worker discovery
22:02:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:02:14 DISPATCHER: Finished worker discovery
22:03:14 DISPATCHER: Starting worker discovery
22:03:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:03:14 DISPATCHER: Finished worker discovery
22:04:14 DISPATCHER: Starting worker discovery
22:04:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:04:14 DISPATCHER: Finished worker discovery
22:05:14 DISPATCHER: Starting worker discovery
22:05:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:05:14 DISPATCHER: Finished worker discovery
22:06:14 DISPATCHER: Starting worker discovery
22:06:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:06:14 DISPATCHER: Finished worker discovery
22:07:01 WORKER: done with job (0, 0, 16), trying to register it.
22:07:01 WORKER: registered result for job (0, 0, 16) with dispatcher
22:07:01 DISPATCHER: job (0, 0, 16) finished
22:07:01 DISPATCHER: register_result: lock acquired
22:07:01 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
22:07:01 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 72, 'last_n_outputs': 17, 'lr': 0.004768652857833486, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.08288191084184723}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.7898832712852994, 'info': {'music-speech': 0.7898832712852994, 'config': "{'batch_size': 64, 'hidden_dim': 72, 'last_n_outputs': 17, 'lr': 0.004768652857833486, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.08288191084184723}"}}
exception: None

22:07:01 job_callback for (0, 0, 16) started
22:07:01 DISPATCHER: Trying to submit another job.
22:07:01 job_callback for (0, 0, 16) got condition
22:07:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:07:01 Only 1 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
22:07:01 HBMASTER: Trying to run another job!
22:07:01 job_callback for (0, 0, 16) finished
22:07:01 start sampling a new configuration.
22:07:01 best_vector: [0, 0.4632589863508929, 0.8551406122944021, 0.03840886328264082, 0.2129857542529977, 0, 0.24876257926773515, 0.2102387649008186], 0.0028861239881092684, 0.36206824862124676, 0.0010449738576784908
22:07:01 done sampling a new configuration.
22:07:01 HBMASTER: schedule new run for iteration 1
22:07:01 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
22:07:01 HBMASTER: submitting job (1, 0, 0) to dispatcher
22:07:01 DISPATCHER: trying to submit job (1, 0, 0)
22:07:01 DISPATCHER: trying to notify the job_runner thread.
22:07:01 HBMASTER: job (1, 0, 0) submitted to dispatcher
22:07:01 DISPATCHER: Trying to submit another job.
22:07:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:07:01 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
22:07:01 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
22:07:01 WORKER: start processing job (1, 0, 0)
22:07:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:07:01 WORKER: args: ()
22:07:01 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 57, 'last_n_outputs': 43, 'lr': 0.001193487092689734, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.01877270862309906}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-446:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

22:07:14 DISPATCHER: Starting worker discovery
22:07:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:07:14 DISPATCHER: Finished worker discovery
22:08:14 DISPATCHER: Starting worker discovery
22:08:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:08:14 DISPATCHER: Finished worker discovery
22:09:14 DISPATCHER: Starting worker discovery
22:09:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:09:14 DISPATCHER: Finished worker discovery
22:09:23 WORKER: done with job (1, 0, 0), trying to register it.
22:09:23 WORKER: registered result for job (1, 0, 0) with dispatcher
22:09:23 DISPATCHER: job (1, 0, 0) finished
22:09:23 DISPATCHER: register_result: lock acquired
22:09:23 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
22:09:23 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 57, 'last_n_outputs': 43, 'lr': 0.001193487092689734, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.01877270862309906}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6145327279383486, 'info': {'music-speech': 0.6145327279383486, 'config': "{'batch_size': 16, 'hidden_dim': 57, 'last_n_outputs': 43, 'lr': 0.001193487092689734, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.01877270862309906}"}}
exception: None

22:09:23 job_callback for (1, 0, 0) started
22:09:23 DISPATCHER: Trying to submit another job.
22:09:23 job_callback for (1, 0, 0) got condition
22:09:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:09:23 HBMASTER: Trying to run another job!
22:09:23 job_callback for (1, 0, 0) finished
22:09:23 start sampling a new configuration.
22:09:23 done sampling a new configuration.
22:09:23 HBMASTER: schedule new run for iteration 1
22:09:23 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
22:09:23 HBMASTER: submitting job (1, 0, 1) to dispatcher
22:09:23 DISPATCHER: trying to submit job (1, 0, 1)
22:09:23 DISPATCHER: trying to notify the job_runner thread.
22:09:23 HBMASTER: job (1, 0, 1) submitted to dispatcher
22:09:23 DISPATCHER: Trying to submit another job.
22:09:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:09:23 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
22:09:23 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
22:09:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:09:23 WORKER: start processing job (1, 0, 1)
22:09:23 WORKER: args: ()
22:09:23 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 32, 'last_n_outputs': 9, 'lr': 0.04964186433875411, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.06239940485926942}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-447:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

22:10:14 DISPATCHER: Starting worker discovery
22:10:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:10:14 DISPATCHER: Finished worker discovery
22:11:14 DISPATCHER: Starting worker discovery
22:11:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:11:14 DISPATCHER: Finished worker discovery
22:11:45 WORKER: done with job (1, 0, 1), trying to register it.
22:11:45 WORKER: registered result for job (1, 0, 1) with dispatcher
22:11:45 DISPATCHER: job (1, 0, 1) finished
22:11:45 DISPATCHER: register_result: lock acquired
22:11:45 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
22:11:45 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 32, 'last_n_outputs': 9, 'lr': 0.04964186433875411, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.06239940485926942}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 32, 'last_n_outputs': 9, 'lr': 0.04964186433875411, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 22, 'weight_decay': 0.06239940485926942}"}}
exception: None

22:11:45 job_callback for (1, 0, 1) started
22:11:45 DISPATCHER: Trying to submit another job.
22:11:45 job_callback for (1, 0, 1) got condition
22:11:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:11:45 HBMASTER: Trying to run another job!
22:11:45 job_callback for (1, 0, 1) finished
22:11:45 start sampling a new configuration.
22:11:45 done sampling a new configuration.
22:11:45 HBMASTER: schedule new run for iteration 1
22:11:45 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
22:11:45 HBMASTER: submitting job (1, 0, 2) to dispatcher
22:11:45 DISPATCHER: trying to submit job (1, 0, 2)
22:11:45 DISPATCHER: trying to notify the job_runner thread.
22:11:45 HBMASTER: job (1, 0, 2) submitted to dispatcher
22:11:45 DISPATCHER: Trying to submit another job.
22:11:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:11:45 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
22:11:45 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
22:11:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:11:45 WORKER: start processing job (1, 0, 2)
22:11:45 WORKER: args: ()
22:11:45 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 62, 'last_n_outputs': 42, 'lr': 0.0031162821164915826, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.012740345113101185}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-448:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

22:12:14 DISPATCHER: Starting worker discovery
22:12:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:12:14 DISPATCHER: Finished worker discovery
22:13:14 DISPATCHER: Starting worker discovery
22:13:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:13:14 DISPATCHER: Finished worker discovery
22:14:07 WORKER: done with job (1, 0, 2), trying to register it.
22:14:07 WORKER: registered result for job (1, 0, 2) with dispatcher
22:14:07 DISPATCHER: job (1, 0, 2) finished
22:14:07 DISPATCHER: register_result: lock acquired
22:14:07 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
22:14:07 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 62, 'last_n_outputs': 42, 'lr': 0.0031162821164915826, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.012740345113101185}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8354167332570896, 'info': {'music-speech': 0.8354167332570896, 'config': "{'batch_size': 16, 'hidden_dim': 62, 'last_n_outputs': 42, 'lr': 0.0031162821164915826, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.012740345113101185}"}}
exception: None

22:14:07 job_callback for (1, 0, 2) started
22:14:07 DISPATCHER: Trying to submit another job.
22:14:07 job_callback for (1, 0, 2) got condition
22:14:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:14:07 HBMASTER: Trying to run another job!
22:14:07 job_callback for (1, 0, 2) finished
22:14:07 start sampling a new configuration.
22:14:07 done sampling a new configuration.
22:14:07 HBMASTER: schedule new run for iteration 1
22:14:07 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
22:14:07 HBMASTER: submitting job (1, 0, 3) to dispatcher
22:14:07 DISPATCHER: trying to submit job (1, 0, 3)
22:14:07 DISPATCHER: trying to notify the job_runner thread.
22:14:07 HBMASTER: job (1, 0, 3) submitted to dispatcher
22:14:07 DISPATCHER: Trying to submit another job.
22:14:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:14:07 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
22:14:07 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
22:14:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:14:07 WORKER: start processing job (1, 0, 3)
22:14:07 WORKER: args: ()
22:14:07 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 32, 'last_n_outputs': 3, 'lr': 0.03504054400120512, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.023282889732569256}, 'budget': 133.33333333333331, 'working_directory': '.'}
22:14:14 DISPATCHER: Starting worker discovery
22:14:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:14:14 DISPATCHER: Finished worker discovery
Exception in thread Thread-449:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

22:15:14 DISPATCHER: Starting worker discovery
22:15:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:15:14 DISPATCHER: Finished worker discovery
22:16:14 DISPATCHER: Starting worker discovery
22:16:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:16:14 DISPATCHER: Finished worker discovery
22:16:29 WORKER: done with job (1, 0, 3), trying to register it.
22:16:29 WORKER: registered result for job (1, 0, 3) with dispatcher
22:16:29 DISPATCHER: job (1, 0, 3) finished
22:16:29 DISPATCHER: register_result: lock acquired
22:16:29 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
22:16:29 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 32, 'last_n_outputs': 3, 'lr': 0.03504054400120512, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.023282889732569256}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 32, 'last_n_outputs': 3, 'lr': 0.03504054400120512, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.023282889732569256}"}}
exception: None

22:16:29 job_callback for (1, 0, 3) started
22:16:29 DISPATCHER: Trying to submit another job.
22:16:29 job_callback for (1, 0, 3) got condition
22:16:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:16:29 HBMASTER: Trying to run another job!
22:16:29 job_callback for (1, 0, 3) finished
22:16:29 start sampling a new configuration.
22:16:29 best_vector: [2, 0.07053978243386744, 0.9696437875524831, 0.2730320313669342, 0.3302798627398839, 0, 0.8992792853384153, 0.7492930570997021], 0.0004076992518219669, 0.6244729615149114, 0.0002545971591926773
22:16:29 done sampling a new configuration.
22:16:29 HBMASTER: schedule new run for iteration 1
22:16:29 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
22:16:29 HBMASTER: submitting job (1, 0, 4) to dispatcher
22:16:29 DISPATCHER: trying to submit job (1, 0, 4)
22:16:29 DISPATCHER: trying to notify the job_runner thread.
22:16:29 HBMASTER: job (1, 0, 4) submitted to dispatcher
22:16:29 DISPATCHER: Trying to submit another job.
22:16:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:16:29 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
22:16:29 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
22:16:29 WORKER: start processing job (1, 0, 4)
22:16:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:16:29 WORKER: args: ()
22:16:29 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 25, 'last_n_outputs': 49, 'lr': 0.0035161230299734546, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.0943740825783239}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-450:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

22:17:14 DISPATCHER: Starting worker discovery
22:17:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:17:14 DISPATCHER: Finished worker discovery
22:18:14 DISPATCHER: Starting worker discovery
22:18:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:18:14 DISPATCHER: Finished worker discovery
22:18:51 WORKER: done with job (1, 0, 4), trying to register it.
22:18:51 WORKER: registered result for job (1, 0, 4) with dispatcher
22:18:51 DISPATCHER: job (1, 0, 4) finished
22:18:51 DISPATCHER: register_result: lock acquired
22:18:51 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
22:18:51 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 25, 'last_n_outputs': 49, 'lr': 0.0035161230299734546, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.0943740825783239}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8929952603361778, 'info': {'music-speech': 0.8929952603361778, 'config': "{'batch_size': 64, 'hidden_dim': 25, 'last_n_outputs': 49, 'lr': 0.0035161230299734546, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.0943740825783239}"}}
exception: None

22:18:51 job_callback for (1, 0, 4) started
22:18:51 DISPATCHER: Trying to submit another job.
22:18:51 job_callback for (1, 0, 4) got condition
22:18:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:18:51 HBMASTER: Trying to run another job!
22:18:51 job_callback for (1, 0, 4) finished
22:18:51 start sampling a new configuration.
22:18:51 best_vector: [1, 0.3935135796037995, 0.9994572313998663, 0.08493828879246772, 0.1408820720980644, 0, 0.4399274318711224, 0.10824598918209949], 0.0027754550162260205, 0.14092110457436136, 0.0003911201865830228
22:18:51 done sampling a new configuration.
22:18:51 HBMASTER: schedule new run for iteration 1
22:18:51 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
22:18:51 HBMASTER: submitting job (1, 0, 5) to dispatcher
22:18:51 DISPATCHER: trying to submit job (1, 0, 5)
22:18:51 DISPATCHER: trying to notify the job_runner thread.
22:18:51 HBMASTER: job (1, 0, 5) submitted to dispatcher
22:18:51 DISPATCHER: Trying to submit another job.
22:18:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:18:51 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
22:18:51 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
22:18:51 WORKER: start processing job (1, 0, 5)
22:18:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:18:51 WORKER: args: ()
22:18:51 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 51, 'last_n_outputs': 50, 'lr': 0.0014786880991725013, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.013830289749735991}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-451:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

22:19:14 DISPATCHER: Starting worker discovery
22:19:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:19:14 DISPATCHER: Finished worker discovery
22:20:14 DISPATCHER: Starting worker discovery
22:20:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:20:14 DISPATCHER: Finished worker discovery
22:21:14 WORKER: done with job (1, 0, 5), trying to register it.
22:21:14 WORKER: registered result for job (1, 0, 5) with dispatcher
22:21:14 DISPATCHER: job (1, 0, 5) finished
22:21:14 DISPATCHER: register_result: lock acquired
22:21:14 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
22:21:14 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 51, 'last_n_outputs': 50, 'lr': 0.0014786880991725013, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.013830289749735991}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9280430731173772, 'info': {'music-speech': 0.9280430731173772, 'config': "{'batch_size': 32, 'hidden_dim': 51, 'last_n_outputs': 50, 'lr': 0.0014786880991725013, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.013830289749735991}"}}
exception: None

22:21:14 job_callback for (1, 0, 5) started
22:21:14 DISPATCHER: Trying to submit another job.
22:21:14 job_callback for (1, 0, 5) got condition
22:21:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:21:14 DISPATCHER: Starting worker discovery
22:21:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:21:14 DISPATCHER: Finished worker discovery
22:21:14 HBMASTER: Trying to run another job!
22:21:14 job_callback for (1, 0, 5) finished
22:21:14 start sampling a new configuration.
22:21:14 best_vector: [1, 0.028858933656882347, 0.8422026518180001, 0.013092679682198682, 0.2317507745755927, 0, 0.6077973929214294, 0.3429715225815833], 0.0005783890196743959, 0.9884576797579546, 0.0005717130683848314
22:21:14 done sampling a new configuration.
22:21:14 HBMASTER: schedule new run for iteration 1
22:21:14 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
22:21:14 HBMASTER: submitting job (1, 0, 6) to dispatcher
22:21:14 DISPATCHER: trying to submit job (1, 0, 6)
22:21:14 DISPATCHER: trying to notify the job_runner thread.
22:21:14 HBMASTER: job (1, 0, 6) submitted to dispatcher
22:21:14 DISPATCHER: Trying to submit another job.
22:21:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:21:14 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216
22:21:14 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
22:21:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:21:14 WORKER: start processing job (1, 0, 6)
22:21:14 WORKER: args: ()
22:21:14 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 22, 'last_n_outputs': 43, 'lr': 0.001062148791638728, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.02793934616339337}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-452:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

22:22:14 DISPATCHER: Starting worker discovery
22:22:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:22:14 DISPATCHER: Finished worker discovery
22:23:14 DISPATCHER: Starting worker discovery
22:23:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:23:14 DISPATCHER: Finished worker discovery
22:23:37 WORKER: done with job (1, 0, 6), trying to register it.
22:23:37 WORKER: registered result for job (1, 0, 6) with dispatcher
22:23:37 DISPATCHER: job (1, 0, 6) finished
22:23:37 DISPATCHER: register_result: lock acquired
22:23:37 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
22:23:37 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 22, 'last_n_outputs': 43, 'lr': 0.001062148791638728, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.02793934616339337}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8008839711990418, 'info': {'music-speech': 0.8008839711990418, 'config': "{'batch_size': 32, 'hidden_dim': 22, 'last_n_outputs': 43, 'lr': 0.001062148791638728, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 65, 'weight_decay': 0.02793934616339337}"}}
exception: None

22:23:37 job_callback for (1, 0, 6) started
22:23:37 DISPATCHER: Trying to submit another job.
22:23:37 job_callback for (1, 0, 6) got condition
22:23:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:23:37 HBMASTER: Trying to run another job!
22:23:37 job_callback for (1, 0, 6) finished
22:23:37 start sampling a new configuration.
22:23:37 best_vector: [0, 0.019882143106456966, 0.909303284072577, 0.269677849136974, 0.033944142084795126, 0, 0.9765284475616104, 0.4228739364696153], 0.0016969557679121269, 0.649524511708627, 0.0011022143665442624
22:23:37 done sampling a new configuration.
22:23:37 HBMASTER: schedule new run for iteration 1
22:23:37 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
22:23:37 HBMASTER: submitting job (1, 0, 7) to dispatcher
22:23:37 DISPATCHER: trying to submit job (1, 0, 7)
22:23:37 DISPATCHER: trying to notify the job_runner thread.
22:23:37 HBMASTER: job (1, 0, 7) submitted to dispatcher
22:23:37 DISPATCHER: Trying to submit another job.
22:23:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:23:37 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
22:23:37 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
22:23:37 WORKER: start processing job (1, 0, 7)
22:23:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:23:37 WORKER: args: ()
22:23:37 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 21, 'last_n_outputs': 46, 'lr': 0.003462228270732009, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.035495367397497035}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-453:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

22:24:14 DISPATCHER: Starting worker discovery
22:24:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:24:14 DISPATCHER: Finished worker discovery
22:25:14 DISPATCHER: Starting worker discovery
22:25:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:25:14 DISPATCHER: Finished worker discovery
22:26:00 WORKER: done with job (1, 0, 7), trying to register it.
22:26:00 WORKER: registered result for job (1, 0, 7) with dispatcher
22:26:00 DISPATCHER: job (1, 0, 7) finished
22:26:00 DISPATCHER: register_result: lock acquired
22:26:00 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
22:26:00 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 21, 'last_n_outputs': 46, 'lr': 0.003462228270732009, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.035495367397497035}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4321781838320997, 'info': {'music-speech': 0.4321781838320997, 'config': "{'batch_size': 16, 'hidden_dim': 21, 'last_n_outputs': 46, 'lr': 0.003462228270732009, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.035495367397497035}"}}
exception: None

22:26:00 job_callback for (1, 0, 7) started
22:26:00 DISPATCHER: Trying to submit another job.
22:26:00 job_callback for (1, 0, 7) got condition
22:26:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:26:00 HBMASTER: Trying to run another job!
22:26:00 job_callback for (1, 0, 7) finished
22:26:00 start sampling a new configuration.
22:26:00 best_vector: [0, 0.07733291705829315, 0.9982428897407774, 0.324901526043581, 0.19817168406532648, 0, 0.967607709096485, 0.25715732184981954], 0.0021474827613905123, 0.3330217278374898, 0.0007151584196994922
22:26:00 done sampling a new configuration.
22:26:00 HBMASTER: schedule new run for iteration 1
22:26:00 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
22:26:00 HBMASTER: submitting job (1, 0, 8) to dispatcher
22:26:00 DISPATCHER: trying to submit job (1, 0, 8)
22:26:00 DISPATCHER: trying to notify the job_runner thread.
22:26:00 HBMASTER: job (1, 0, 8) submitted to dispatcher
22:26:00 DISPATCHER: Trying to submit another job.
22:26:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:26:00 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216
22:26:00 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
22:26:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:26:00 WORKER: start processing job (1, 0, 8)
22:26:00 WORKER: args: ()
22:26:00 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 26, 'last_n_outputs': 50, 'lr': 0.004464810718327144, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.021605752127569242}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-454:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

22:26:14 DISPATCHER: Starting worker discovery
22:26:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:26:14 DISPATCHER: Finished worker discovery
22:27:14 DISPATCHER: Starting worker discovery
22:27:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:27:14 DISPATCHER: Finished worker discovery
22:28:14 DISPATCHER: Starting worker discovery
22:28:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:28:14 DISPATCHER: Finished worker discovery
22:28:21 WORKER: done with job (1, 0, 8), trying to register it.
22:28:21 WORKER: registered result for job (1, 0, 8) with dispatcher
22:28:21 DISPATCHER: job (1, 0, 8) finished
22:28:21 DISPATCHER: register_result: lock acquired
22:28:21 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
22:28:21 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 26, 'last_n_outputs': 50, 'lr': 0.004464810718327144, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.021605752127569242}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.85832391727626, 'info': {'music-speech': 0.85832391727626, 'config': "{'batch_size': 16, 'hidden_dim': 26, 'last_n_outputs': 50, 'lr': 0.004464810718327144, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.021605752127569242}"}}
exception: None

22:28:21 job_callback for (1, 0, 8) started
22:28:21 DISPATCHER: Trying to submit another job.
22:28:21 job_callback for (1, 0, 8) got condition
22:28:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:28:21 done building a new model for budget 133.333333 based on 9/15 split
Best loss for this budget:-0.928043





22:28:21 HBMASTER: Trying to run another job!
22:28:21 job_callback for (1, 0, 8) finished
22:28:21 ITERATION: Advancing config (1, 0, 4) to next budget 400.000000
22:28:21 ITERATION: Advancing config (1, 0, 5) to next budget 400.000000
22:28:21 ITERATION: Advancing config (1, 0, 8) to next budget 400.000000
22:28:21 HBMASTER: schedule new run for iteration 1
22:28:21 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
22:28:21 HBMASTER: submitting job (1, 0, 4) to dispatcher
22:28:21 DISPATCHER: trying to submit job (1, 0, 4)
22:28:21 DISPATCHER: trying to notify the job_runner thread.
22:28:21 HBMASTER: job (1, 0, 4) submitted to dispatcher
22:28:21 DISPATCHER: Trying to submit another job.
22:28:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:28:21 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
22:28:21 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
22:28:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:28:21 WORKER: start processing job (1, 0, 4)
22:28:21 WORKER: args: ()
22:28:21 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 25, 'last_n_outputs': 49, 'lr': 0.0035161230299734546, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.0943740825783239}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-455:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

22:29:14 DISPATCHER: Starting worker discovery
22:29:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:29:14 DISPATCHER: Finished worker discovery
22:30:14 DISPATCHER: Starting worker discovery
22:30:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:30:14 DISPATCHER: Finished worker discovery
22:31:14 DISPATCHER: Starting worker discovery
22:31:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:31:14 DISPATCHER: Finished worker discovery
22:32:14 DISPATCHER: Starting worker discovery
22:32:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:32:14 DISPATCHER: Finished worker discovery
22:33:14 DISPATCHER: Starting worker discovery
22:33:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:33:14 DISPATCHER: Finished worker discovery
22:34:14 DISPATCHER: Starting worker discovery
22:34:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:34:14 DISPATCHER: Finished worker discovery
22:35:10 WORKER: done with job (1, 0, 4), trying to register it.
22:35:10 WORKER: registered result for job (1, 0, 4) with dispatcher
22:35:10 DISPATCHER: job (1, 0, 4) finished
22:35:10 DISPATCHER: register_result: lock acquired
22:35:10 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
22:35:10 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 25, 'last_n_outputs': 49, 'lr': 0.0035161230299734546, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.0943740825783239}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6728622527235903, 'info': {'music-speech': 0.6728622527235903, 'config': "{'batch_size': 64, 'hidden_dim': 25, 'last_n_outputs': 49, 'lr': 0.0035161230299734546, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 91, 'weight_decay': 0.0943740825783239}"}}
exception: None

22:35:10 job_callback for (1, 0, 4) started
22:35:10 DISPATCHER: Trying to submit another job.
22:35:10 job_callback for (1, 0, 4) got condition
22:35:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:35:10 Only 4 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
22:35:10 HBMASTER: Trying to run another job!
22:35:10 job_callback for (1, 0, 4) finished
22:35:10 HBMASTER: schedule new run for iteration 1
22:35:10 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
22:35:10 HBMASTER: submitting job (1, 0, 5) to dispatcher
22:35:10 DISPATCHER: trying to submit job (1, 0, 5)
22:35:10 DISPATCHER: trying to notify the job_runner thread.
22:35:10 HBMASTER: job (1, 0, 5) submitted to dispatcher
22:35:10 DISPATCHER: Trying to submit another job.
22:35:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:35:10 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
22:35:10 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
22:35:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:35:10 WORKER: start processing job (1, 0, 5)
22:35:10 WORKER: args: ()
22:35:10 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 51, 'last_n_outputs': 50, 'lr': 0.0014786880991725013, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.013830289749735991}, 'budget': 400.0, 'working_directory': '.'}
22:35:14 DISPATCHER: Starting worker discovery
22:35:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:35:14 DISPATCHER: Finished worker discovery
Exception in thread Thread-456:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

22:36:14 DISPATCHER: Starting worker discovery
22:36:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:36:14 DISPATCHER: Finished worker discovery
22:37:14 DISPATCHER: Starting worker discovery
22:37:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:37:14 DISPATCHER: Finished worker discovery
22:38:14 DISPATCHER: Starting worker discovery
22:38:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:38:14 DISPATCHER: Finished worker discovery
22:39:14 DISPATCHER: Starting worker discovery
22:39:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:39:14 DISPATCHER: Finished worker discovery
22:40:14 DISPATCHER: Starting worker discovery
22:40:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:40:14 DISPATCHER: Finished worker discovery
22:41:14 DISPATCHER: Starting worker discovery
22:41:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:41:14 DISPATCHER: Finished worker discovery
22:41:59 WORKER: done with job (1, 0, 5), trying to register it.
22:41:59 WORKER: registered result for job (1, 0, 5) with dispatcher
22:41:59 DISPATCHER: job (1, 0, 5) finished
22:41:59 DISPATCHER: register_result: lock acquired
22:41:59 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
22:41:59 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 51, 'last_n_outputs': 50, 'lr': 0.0014786880991725013, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.013830289749735991}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6568678351846116, 'info': {'music-speech': 0.6568678351846116, 'config': "{'batch_size': 32, 'hidden_dim': 51, 'last_n_outputs': 50, 'lr': 0.0014786880991725013, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 50, 'weight_decay': 0.013830289749735991}"}}
exception: None

22:41:59 job_callback for (1, 0, 5) started
22:41:59 DISPATCHER: Trying to submit another job.
22:41:59 job_callback for (1, 0, 5) got condition
22:41:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:41:59 Only 5 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
22:41:59 HBMASTER: Trying to run another job!
22:41:59 job_callback for (1, 0, 5) finished
22:41:59 HBMASTER: schedule new run for iteration 1
22:41:59 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
22:41:59 HBMASTER: submitting job (1, 0, 8) to dispatcher
22:41:59 DISPATCHER: trying to submit job (1, 0, 8)
22:41:59 DISPATCHER: trying to notify the job_runner thread.
22:41:59 HBMASTER: job (1, 0, 8) submitted to dispatcher
22:41:59 DISPATCHER: Trying to submit another job.
22:41:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:41:59 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216
22:41:59 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
22:41:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:41:59 WORKER: start processing job (1, 0, 8)
22:41:59 WORKER: args: ()
22:41:59 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 26, 'last_n_outputs': 50, 'lr': 0.004464810718327144, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.021605752127569242}, 'budget': 400.0, 'working_directory': '.'}
22:42:14 DISPATCHER: Starting worker discovery
22:42:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:42:14 DISPATCHER: Finished worker discovery
Exception in thread Thread-457:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

22:43:14 DISPATCHER: Starting worker discovery
22:43:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:43:14 DISPATCHER: Finished worker discovery
22:44:14 DISPATCHER: Starting worker discovery
22:44:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:44:14 DISPATCHER: Finished worker discovery
22:45:14 DISPATCHER: Starting worker discovery
22:45:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:45:15 DISPATCHER: Finished worker discovery
22:46:15 DISPATCHER: Starting worker discovery
22:46:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:46:15 DISPATCHER: Finished worker discovery
22:47:15 DISPATCHER: Starting worker discovery
22:47:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:47:15 DISPATCHER: Finished worker discovery
22:48:15 DISPATCHER: Starting worker discovery
22:48:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:48:15 DISPATCHER: Finished worker discovery
22:48:48 WORKER: done with job (1, 0, 8), trying to register it.
22:48:48 WORKER: registered result for job (1, 0, 8) with dispatcher
22:48:48 DISPATCHER: job (1, 0, 8) finished
22:48:48 DISPATCHER: register_result: lock acquired
22:48:48 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
22:48:48 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 26, 'last_n_outputs': 50, 'lr': 0.004464810718327144, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.021605752127569242}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8296216854950385, 'info': {'music-speech': 0.8296216854950385, 'config': "{'batch_size': 16, 'hidden_dim': 26, 'last_n_outputs': 50, 'lr': 0.004464810718327144, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.021605752127569242}"}}
exception: None

22:48:48 job_callback for (1, 0, 8) started
22:48:48 DISPATCHER: Trying to submit another job.
22:48:48 job_callback for (1, 0, 8) got condition
22:48:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
22:48:48 Only 6 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
22:48:48 HBMASTER: Trying to run another job!
22:48:48 job_callback for (1, 0, 8) finished
22:48:48 ITERATION: Advancing config (1, 0, 8) to next budget 1200.000000
22:48:48 HBMASTER: schedule new run for iteration 1
22:48:48 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
22:48:48 HBMASTER: submitting job (1, 0, 8) to dispatcher
22:48:48 DISPATCHER: trying to submit job (1, 0, 8)
22:48:48 DISPATCHER: trying to notify the job_runner thread.
22:48:48 HBMASTER: job (1, 0, 8) submitted to dispatcher
22:48:48 DISPATCHER: Trying to submit another job.
22:48:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
22:48:48 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216
22:48:48 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
22:48:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
22:48:48 WORKER: start processing job (1, 0, 8)
22:48:48 WORKER: args: ()
22:48:48 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 26, 'last_n_outputs': 50, 'lr': 0.004464810718327144, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.021605752127569242}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-458:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

22:49:15 DISPATCHER: Starting worker discovery
22:49:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:49:15 DISPATCHER: Finished worker discovery
22:50:15 DISPATCHER: Starting worker discovery
22:50:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:50:15 DISPATCHER: Finished worker discovery
22:51:15 DISPATCHER: Starting worker discovery
22:51:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:51:15 DISPATCHER: Finished worker discovery
22:52:15 DISPATCHER: Starting worker discovery
22:52:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:52:15 DISPATCHER: Finished worker discovery
22:53:15 DISPATCHER: Starting worker discovery
22:53:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:53:15 DISPATCHER: Finished worker discovery
22:54:15 DISPATCHER: Starting worker discovery
22:54:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:54:15 DISPATCHER: Finished worker discovery
22:55:15 DISPATCHER: Starting worker discovery
22:55:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:55:15 DISPATCHER: Finished worker discovery
22:56:15 DISPATCHER: Starting worker discovery
22:56:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:56:15 DISPATCHER: Finished worker discovery
22:57:15 DISPATCHER: Starting worker discovery
22:57:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:57:15 DISPATCHER: Finished worker discovery
22:58:15 DISPATCHER: Starting worker discovery
22:58:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:58:15 DISPATCHER: Finished worker discovery
22:59:15 DISPATCHER: Starting worker discovery
22:59:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:59:15 DISPATCHER: Finished worker discovery
23:00:15 DISPATCHER: Starting worker discovery
23:00:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:00:15 DISPATCHER: Finished worker discovery
23:01:15 DISPATCHER: Starting worker discovery
23:01:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:01:15 DISPATCHER: Finished worker discovery
23:02:15 DISPATCHER: Starting worker discovery
23:02:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:02:15 DISPATCHER: Finished worker discovery
23:03:15 DISPATCHER: Starting worker discovery
23:03:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:03:15 DISPATCHER: Finished worker discovery
23:04:15 DISPATCHER: Starting worker discovery
23:04:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:04:15 DISPATCHER: Finished worker discovery
23:05:15 DISPATCHER: Starting worker discovery
23:05:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:05:15 DISPATCHER: Finished worker discovery
23:06:15 DISPATCHER: Starting worker discovery
23:06:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:06:15 DISPATCHER: Finished worker discovery
23:07:15 DISPATCHER: Starting worker discovery
23:07:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:07:15 DISPATCHER: Finished worker discovery
23:08:15 DISPATCHER: Starting worker discovery
23:08:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:08:15 DISPATCHER: Finished worker discovery
23:08:56 WORKER: done with job (1, 0, 8), trying to register it.
23:08:56 WORKER: registered result for job (1, 0, 8) with dispatcher
23:08:56 DISPATCHER: job (1, 0, 8) finished
23:08:56 DISPATCHER: register_result: lock acquired
23:08:56 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
23:08:56 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 26, 'last_n_outputs': 50, 'lr': 0.004464810718327144, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.021605752127569242}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.6782793522825157, 'info': {'music-speech': 0.6782793522825157, 'config': "{'batch_size': 16, 'hidden_dim': 26, 'last_n_outputs': 50, 'lr': 0.004464810718327144, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.021605752127569242}"}}
exception: None

23:08:56 job_callback for (1, 0, 8) started
23:08:56 DISPATCHER: Trying to submit another job.
23:08:56 job_callback for (1, 0, 8) got condition
23:08:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:08:56 Only 2 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
23:08:56 HBMASTER: Trying to run another job!
23:08:56 job_callback for (1, 0, 8) finished
23:08:56 start sampling a new configuration.
23:08:56 done sampling a new configuration.
23:08:56 HBMASTER: schedule new run for iteration 2
23:08:56 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
23:08:56 HBMASTER: submitting job (2, 0, 0) to dispatcher
23:08:56 DISPATCHER: trying to submit job (2, 0, 0)
23:08:56 DISPATCHER: trying to notify the job_runner thread.
23:08:56 HBMASTER: job (2, 0, 0) submitted to dispatcher
23:08:56 DISPATCHER: Trying to submit another job.
23:08:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:08:56 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
23:08:56 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
23:08:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:08:56 WORKER: start processing job (2, 0, 0)
23:08:56 WORKER: args: ()
23:08:56 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 31, 'last_n_outputs': 32, 'lr': 0.016006264666179243, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.02876809116142969}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-459:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:09:15 DISPATCHER: Starting worker discovery
23:09:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:09:15 DISPATCHER: Finished worker discovery
23:10:15 DISPATCHER: Starting worker discovery
23:10:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:10:15 DISPATCHER: Finished worker discovery
23:11:15 DISPATCHER: Starting worker discovery
23:11:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:11:15 DISPATCHER: Finished worker discovery
23:12:15 DISPATCHER: Starting worker discovery
23:12:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:12:15 DISPATCHER: Finished worker discovery
23:13:15 DISPATCHER: Starting worker discovery
23:13:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:13:15 DISPATCHER: Finished worker discovery
23:14:15 DISPATCHER: Starting worker discovery
23:14:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:14:15 DISPATCHER: Finished worker discovery
23:15:15 DISPATCHER: Starting worker discovery
23:15:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:15:15 DISPATCHER: Finished worker discovery
23:15:45 WORKER: done with job (2, 0, 0), trying to register it.
23:15:45 WORKER: registered result for job (2, 0, 0) with dispatcher
23:15:45 DISPATCHER: job (2, 0, 0) finished
23:15:45 DISPATCHER: register_result: lock acquired
23:15:45 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
23:15:45 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 31, 'last_n_outputs': 32, 'lr': 0.016006264666179243, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.02876809116142969}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 31, 'last_n_outputs': 32, 'lr': 0.016006264666179243, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 19, 'weight_decay': 0.02876809116142969}"}}
exception: None

23:15:45 job_callback for (2, 0, 0) started
23:15:45 DISPATCHER: Trying to submit another job.
23:15:45 job_callback for (2, 0, 0) got condition
23:15:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:15:45 Only 7 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
23:15:45 HBMASTER: Trying to run another job!
23:15:45 job_callback for (2, 0, 0) finished
23:15:45 start sampling a new configuration.
23:15:45 best_vector: [0, 0.9549269033237334, 0.13697871861801336, 0.447987168819824, 0.23268355474263125, 0, 0.17123171065457132, 0.9120012171395158], 0.012646778476918339, 0.3114297571088693, 0.003938583149276354
23:15:45 done sampling a new configuration.
23:15:45 HBMASTER: schedule new run for iteration 2
23:15:45 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
23:15:45 HBMASTER: submitting job (2, 0, 1) to dispatcher
23:15:45 DISPATCHER: trying to submit job (2, 0, 1)
23:15:45 DISPATCHER: trying to notify the job_runner thread.
23:15:45 HBMASTER: job (2, 0, 1) submitted to dispatcher
23:15:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:15:45 DISPATCHER: Trying to submit another job.
23:15:45 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
23:15:45 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
23:15:45 WORKER: start processing job (2, 0, 1)
23:15:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:15:45 WORKER: args: ()
23:15:45 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 97, 'last_n_outputs': 7, 'lr': 0.007869992847156655, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.1536529630340564}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-460:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:16:15 DISPATCHER: Starting worker discovery
23:16:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:16:15 DISPATCHER: Finished worker discovery
23:17:15 DISPATCHER: Starting worker discovery
23:17:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:17:15 DISPATCHER: Finished worker discovery
23:18:15 DISPATCHER: Starting worker discovery
23:18:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:18:15 DISPATCHER: Finished worker discovery
23:19:15 DISPATCHER: Starting worker discovery
23:19:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:19:15 DISPATCHER: Finished worker discovery
23:20:15 DISPATCHER: Starting worker discovery
23:20:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:20:15 DISPATCHER: Finished worker discovery
23:21:15 DISPATCHER: Starting worker discovery
23:21:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:21:15 DISPATCHER: Finished worker discovery
23:22:15 DISPATCHER: Starting worker discovery
23:22:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:22:15 DISPATCHER: Finished worker discovery
23:22:34 WORKER: done with job (2, 0, 1), trying to register it.
23:22:34 WORKER: registered result for job (2, 0, 1) with dispatcher
23:22:34 DISPATCHER: job (2, 0, 1) finished
23:22:34 DISPATCHER: register_result: lock acquired
23:22:34 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
23:22:34 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 97, 'last_n_outputs': 7, 'lr': 0.007869992847156655, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.1536529630340564}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5669075108640661, 'info': {'music-speech': 0.5669075108640661, 'config': "{'batch_size': 16, 'hidden_dim': 97, 'last_n_outputs': 7, 'lr': 0.007869992847156655, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.1536529630340564}"}}
exception: None

23:22:34 job_callback for (2, 0, 1) started
23:22:34 DISPATCHER: Trying to submit another job.
23:22:34 job_callback for (2, 0, 1) got condition
23:22:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:22:34 Only 8 run(s) for budget 400.000000 available, need more than 10 -> can't build model!
23:22:34 HBMASTER: Trying to run another job!
23:22:34 job_callback for (2, 0, 1) finished
23:22:34 start sampling a new configuration.
23:22:34 best_vector: [2, 0.3623823945270354, 0.4170217397418608, 0.8368627818434046, 0.032976786145888615, 0, 0.24624906096585952, 0.9876952263636427], 0.005808739234812408, 0.8704551062186002, 0.005056246727634785
23:22:34 done sampling a new configuration.
23:22:34 HBMASTER: schedule new run for iteration 2
23:22:34 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
23:22:34 HBMASTER: submitting job (2, 0, 2) to dispatcher
23:22:34 DISPATCHER: trying to submit job (2, 0, 2)
23:22:34 DISPATCHER: trying to notify the job_runner thread.
23:22:34 HBMASTER: job (2, 0, 2) submitted to dispatcher
23:22:34 DISPATCHER: Trying to submit another job.
23:22:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:22:34 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
23:22:34 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
23:22:34 WORKER: start processing job (2, 0, 2)
23:22:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:22:34 WORKER: args: ()
23:22:34 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 49, 'last_n_outputs': 21, 'lr': 0.04717648327389583, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.19276186347287713}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-461:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:23:15 DISPATCHER: Starting worker discovery
23:23:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:23:15 DISPATCHER: Finished worker discovery
23:24:15 DISPATCHER: Starting worker discovery
23:24:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:24:15 DISPATCHER: Finished worker discovery
23:25:15 DISPATCHER: Starting worker discovery
23:25:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:25:15 DISPATCHER: Finished worker discovery
23:26:15 DISPATCHER: Starting worker discovery
23:26:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:26:15 DISPATCHER: Finished worker discovery
23:27:15 DISPATCHER: Starting worker discovery
23:27:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:27:15 DISPATCHER: Finished worker discovery
23:28:15 DISPATCHER: Starting worker discovery
23:28:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:28:15 DISPATCHER: Finished worker discovery
23:29:15 DISPATCHER: Starting worker discovery
23:29:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:29:15 DISPATCHER: Finished worker discovery
23:29:23 WORKER: done with job (2, 0, 2), trying to register it.
23:29:23 WORKER: registered result for job (2, 0, 2) with dispatcher
23:29:23 DISPATCHER: job (2, 0, 2) finished
23:29:23 DISPATCHER: register_result: lock acquired
23:29:23 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
23:29:23 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 49, 'last_n_outputs': 21, 'lr': 0.04717648327389583, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.19276186347287713}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6579718333117088, 'info': {'music-speech': 0.6579718333117088, 'config': "{'batch_size': 64, 'hidden_dim': 49, 'last_n_outputs': 21, 'lr': 0.04717648327389583, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.19276186347287713}"}}
exception: None

23:29:23 job_callback for (2, 0, 2) started
23:29:23 DISPATCHER: Trying to submit another job.
23:29:23 job_callback for (2, 0, 2) got condition
23:29:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:29:23 HBMASTER: Trying to run another job!
23:29:23 job_callback for (2, 0, 2) finished
23:29:23 start sampling a new configuration.
23:29:23 done sampling a new configuration.
23:29:23 HBMASTER: schedule new run for iteration 2
23:29:23 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
23:29:23 HBMASTER: submitting job (2, 0, 3) to dispatcher
23:29:23 DISPATCHER: trying to submit job (2, 0, 3)
23:29:23 DISPATCHER: trying to notify the job_runner thread.
23:29:23 HBMASTER: job (2, 0, 3) submitted to dispatcher
23:29:23 DISPATCHER: Trying to submit another job.
23:29:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:29:23 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
23:29:23 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
23:29:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:29:23 WORKER: start processing job (2, 0, 3)
23:29:23 WORKER: args: ()
23:29:23 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 70, 'last_n_outputs': 19, 'lr': 0.07557092292600283, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.06628452162165589}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-462:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:30:15 DISPATCHER: Starting worker discovery
23:30:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:30:15 DISPATCHER: Finished worker discovery
23:31:15 DISPATCHER: Starting worker discovery
23:31:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:31:15 DISPATCHER: Finished worker discovery
23:32:15 DISPATCHER: Starting worker discovery
23:32:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:32:15 DISPATCHER: Finished worker discovery
23:33:15 DISPATCHER: Starting worker discovery
23:33:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:33:15 DISPATCHER: Finished worker discovery
23:34:15 DISPATCHER: Starting worker discovery
23:34:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:34:15 DISPATCHER: Finished worker discovery
23:35:15 DISPATCHER: Starting worker discovery
23:35:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:35:15 DISPATCHER: Finished worker discovery
23:36:12 WORKER: done with job (2, 0, 3), trying to register it.
23:36:12 WORKER: registered result for job (2, 0, 3) with dispatcher
23:36:12 DISPATCHER: job (2, 0, 3) finished
23:36:12 DISPATCHER: register_result: lock acquired
23:36:12 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
23:36:12 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 70, 'last_n_outputs': 19, 'lr': 0.07557092292600283, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.06628452162165589}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.20439429117121594, 'info': {'music-speech': 0.20439429117121594, 'config': "{'batch_size': 16, 'hidden_dim': 70, 'last_n_outputs': 19, 'lr': 0.07557092292600283, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 43, 'weight_decay': 0.06628452162165589}"}}
exception: None

23:36:12 job_callback for (2, 0, 3) started
23:36:12 DISPATCHER: Trying to submit another job.
23:36:12 job_callback for (2, 0, 3) got condition
23:36:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:36:12 HBMASTER: Trying to run another job!
23:36:12 job_callback for (2, 0, 3) finished
23:36:12 start sampling a new configuration.
23:36:12 done sampling a new configuration.
23:36:12 HBMASTER: schedule new run for iteration 2
23:36:12 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
23:36:12 HBMASTER: submitting job (2, 0, 4) to dispatcher
23:36:12 DISPATCHER: trying to submit job (2, 0, 4)
23:36:12 DISPATCHER: trying to notify the job_runner thread.
23:36:12 HBMASTER: job (2, 0, 4) submitted to dispatcher
23:36:12 DISPATCHER: Trying to submit another job.
23:36:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:36:12 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
23:36:12 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
23:36:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:36:12 WORKER: start processing job (2, 0, 4)
23:36:12 WORKER: args: ()
23:36:12 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 85, 'last_n_outputs': 9, 'lr': 0.0012755311504199867, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.1529318183385919}, 'budget': 400.0, 'working_directory': '.'}
23:36:15 DISPATCHER: Starting worker discovery
23:36:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:36:15 DISPATCHER: Finished worker discovery
Exception in thread Thread-463:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:37:15 DISPATCHER: Starting worker discovery
23:37:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:37:15 DISPATCHER: Finished worker discovery
23:38:15 DISPATCHER: Starting worker discovery
23:38:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:38:15 DISPATCHER: Finished worker discovery
23:39:15 DISPATCHER: Starting worker discovery
23:39:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:39:15 DISPATCHER: Finished worker discovery
23:40:15 DISPATCHER: Starting worker discovery
23:40:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:40:15 DISPATCHER: Finished worker discovery
23:41:15 DISPATCHER: Starting worker discovery
23:41:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:41:15 DISPATCHER: Finished worker discovery
23:42:15 DISPATCHER: Starting worker discovery
23:42:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:42:15 DISPATCHER: Finished worker discovery
23:43:01 WORKER: done with job (2, 0, 4), trying to register it.
23:43:01 WORKER: registered result for job (2, 0, 4) with dispatcher
23:43:01 DISPATCHER: job (2, 0, 4) finished
23:43:01 DISPATCHER: register_result: lock acquired
23:43:01 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
23:43:01 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 85, 'last_n_outputs': 9, 'lr': 0.0012755311504199867, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.1529318183385919}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.593287727022893, 'info': {'music-speech': 0.593287727022893, 'config': "{'batch_size': 32, 'hidden_dim': 85, 'last_n_outputs': 9, 'lr': 0.0012755311504199867, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.1529318183385919}"}}
exception: None

23:43:01 job_callback for (2, 0, 4) started
23:43:01 DISPATCHER: Trying to submit another job.
23:43:01 job_callback for (2, 0, 4) got condition
23:43:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:43:01 HBMASTER: Trying to run another job!
23:43:01 job_callback for (2, 0, 4) finished
23:43:01 start sampling a new configuration.
23:43:01 best_vector: [2, 0.3280526479024679, 0.24399030570412594, 0.9565971053520563, 0.01440621805792397, 0, 0.11345487879700589, 0.5755885937837855], 0.03030028878337881, 0.9303912382300817, 0.02819112319989687
23:43:01 done sampling a new configuration.
23:43:01 HBMASTER: schedule new run for iteration 2
23:43:01 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
23:43:01 HBMASTER: submitting job (2, 0, 5) to dispatcher
23:43:01 DISPATCHER: trying to submit job (2, 0, 5)
23:43:01 DISPATCHER: trying to notify the job_runner thread.
23:43:01 HBMASTER: job (2, 0, 5) submitted to dispatcher
23:43:01 DISPATCHER: Trying to submit another job.
23:43:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:43:01 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
23:43:01 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
23:43:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:43:01 WORKER: start processing job (2, 0, 5)
23:43:01 WORKER: args: ()
23:43:01 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 46, 'last_n_outputs': 13, 'lr': 0.08188308765285252, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.05608645949564171}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-464:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:43:15 DISPATCHER: Starting worker discovery
23:43:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:43:15 DISPATCHER: Finished worker discovery
23:44:15 DISPATCHER: Starting worker discovery
23:44:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:44:16 DISPATCHER: Finished worker discovery
23:45:16 DISPATCHER: Starting worker discovery
23:45:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:45:16 DISPATCHER: Finished worker discovery
23:46:16 DISPATCHER: Starting worker discovery
23:46:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:46:16 DISPATCHER: Finished worker discovery
23:47:16 DISPATCHER: Starting worker discovery
23:47:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:47:16 DISPATCHER: Finished worker discovery
23:48:16 DISPATCHER: Starting worker discovery
23:48:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:48:16 DISPATCHER: Finished worker discovery
23:49:16 DISPATCHER: Starting worker discovery
23:49:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:49:16 DISPATCHER: Finished worker discovery
23:49:49 WORKER: done with job (2, 0, 5), trying to register it.
23:49:49 WORKER: registered result for job (2, 0, 5) with dispatcher
23:49:49 DISPATCHER: job (2, 0, 5) finished
23:49:49 DISPATCHER: register_result: lock acquired
23:49:49 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
23:49:49 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 46, 'last_n_outputs': 13, 'lr': 0.08188308765285252, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.05608645949564171}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5921540115307514, 'info': {'music-speech': 0.5921540115307514, 'config': "{'batch_size': 64, 'hidden_dim': 46, 'last_n_outputs': 13, 'lr': 0.08188308765285252, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.05608645949564171}"}}
exception: None

23:49:49 job_callback for (2, 0, 5) started
23:49:49 DISPATCHER: Trying to submit another job.
23:49:49 job_callback for (2, 0, 5) got condition
23:49:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
23:49:49 HBMASTER: Trying to run another job!
23:49:49 job_callback for (2, 0, 5) finished
23:49:49 ITERATION: Advancing config (2, 0, 2) to next budget 1200.000000
23:49:49 ITERATION: Advancing config (2, 0, 4) to next budget 1200.000000
23:49:49 HBMASTER: schedule new run for iteration 2
23:49:49 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
23:49:49 HBMASTER: submitting job (2, 0, 2) to dispatcher
23:49:49 DISPATCHER: trying to submit job (2, 0, 2)
23:49:49 DISPATCHER: trying to notify the job_runner thread.
23:49:49 HBMASTER: job (2, 0, 2) submitted to dispatcher
23:49:49 DISPATCHER: Trying to submit another job.
23:49:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
23:49:49 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
23:49:49 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
23:49:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
23:49:49 WORKER: start processing job (2, 0, 2)
23:49:49 WORKER: args: ()
23:49:49 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 49, 'last_n_outputs': 21, 'lr': 0.04717648327389583, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.19276186347287713}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-465:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

23:50:16 DISPATCHER: Starting worker discovery
23:50:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:50:16 DISPATCHER: Finished worker discovery
23:51:16 DISPATCHER: Starting worker discovery
23:51:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:51:16 DISPATCHER: Finished worker discovery
23:52:16 DISPATCHER: Starting worker discovery
23:52:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:52:16 DISPATCHER: Finished worker discovery
23:53:16 DISPATCHER: Starting worker discovery
23:53:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:53:16 DISPATCHER: Finished worker discovery
23:54:16 DISPATCHER: Starting worker discovery
23:54:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:54:16 DISPATCHER: Finished worker discovery
23:55:16 DISPATCHER: Starting worker discovery
23:55:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:55:16 DISPATCHER: Finished worker discovery
23:56:16 DISPATCHER: Starting worker discovery
23:56:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:56:16 DISPATCHER: Finished worker discovery
23:57:16 DISPATCHER: Starting worker discovery
23:57:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:57:16 DISPATCHER: Finished worker discovery
23:58:16 DISPATCHER: Starting worker discovery
23:58:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:58:16 DISPATCHER: Finished worker discovery
23:59:16 DISPATCHER: Starting worker discovery
23:59:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
23:59:16 DISPATCHER: Finished worker discovery
00:00:16 DISPATCHER: Starting worker discovery
00:00:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:00:16 DISPATCHER: Finished worker discovery
00:01:16 DISPATCHER: Starting worker discovery
00:01:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:01:16 DISPATCHER: Finished worker discovery
00:02:16 DISPATCHER: Starting worker discovery
00:02:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:02:16 DISPATCHER: Finished worker discovery
00:03:16 DISPATCHER: Starting worker discovery
00:03:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:03:16 DISPATCHER: Finished worker discovery
00:04:16 DISPATCHER: Starting worker discovery
00:04:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:04:16 DISPATCHER: Finished worker discovery
00:05:16 DISPATCHER: Starting worker discovery
00:05:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:05:16 DISPATCHER: Finished worker discovery
00:06:16 DISPATCHER: Starting worker discovery
00:06:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:06:16 DISPATCHER: Finished worker discovery
00:07:16 DISPATCHER: Starting worker discovery
00:07:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:07:16 DISPATCHER: Finished worker discovery
00:08:16 DISPATCHER: Starting worker discovery
00:08:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:08:16 DISPATCHER: Finished worker discovery
00:09:16 DISPATCHER: Starting worker discovery
00:09:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:09:16 DISPATCHER: Finished worker discovery
00:09:58 WORKER: done with job (2, 0, 2), trying to register it.
00:09:58 DISPATCHER: job (2, 0, 2) finished
00:09:58 WORKER: registered result for job (2, 0, 2) with dispatcher
00:09:58 DISPATCHER: register_result: lock acquired
00:09:58 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:09:58 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 49, 'last_n_outputs': 21, 'lr': 0.04717648327389583, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.19276186347287713}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.6579496557381339, 'info': {'music-speech': 0.6579496557381339, 'config': "{'batch_size': 64, 'hidden_dim': 49, 'last_n_outputs': 21, 'lr': 0.04717648327389583, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.19276186347287713}"}}
exception: None

00:09:58 job_callback for (2, 0, 2) started
00:09:58 DISPATCHER: Trying to submit another job.
00:09:58 job_callback for (2, 0, 2) got condition
00:09:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:09:58 Only 3 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
00:09:58 HBMASTER: Trying to run another job!
00:09:58 job_callback for (2, 0, 2) finished
00:09:58 HBMASTER: schedule new run for iteration 2
00:09:58 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
00:09:58 HBMASTER: submitting job (2, 0, 4) to dispatcher
00:09:58 DISPATCHER: trying to submit job (2, 0, 4)
00:09:58 DISPATCHER: trying to notify the job_runner thread.
00:09:58 HBMASTER: job (2, 0, 4) submitted to dispatcher
00:09:58 DISPATCHER: Trying to submit another job.
00:09:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:09:58 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:09:58 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:09:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:09:58 WORKER: start processing job (2, 0, 4)
00:09:58 WORKER: args: ()
00:09:58 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 85, 'last_n_outputs': 9, 'lr': 0.0012755311504199867, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.1529318183385919}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-466:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

00:10:16 DISPATCHER: Starting worker discovery
00:10:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:10:16 DISPATCHER: Finished worker discovery
00:11:16 DISPATCHER: Starting worker discovery
00:11:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:11:16 DISPATCHER: Finished worker discovery
00:12:16 DISPATCHER: Starting worker discovery
00:12:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:12:16 DISPATCHER: Finished worker discovery
00:13:16 DISPATCHER: Starting worker discovery
00:13:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:13:16 DISPATCHER: Finished worker discovery
00:14:16 DISPATCHER: Starting worker discovery
00:14:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:14:16 DISPATCHER: Finished worker discovery
00:15:16 DISPATCHER: Starting worker discovery
00:15:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:15:16 DISPATCHER: Finished worker discovery
00:16:16 DISPATCHER: Starting worker discovery
00:16:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:16:16 DISPATCHER: Finished worker discovery
00:17:16 DISPATCHER: Starting worker discovery
00:17:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:17:16 DISPATCHER: Finished worker discovery
00:18:16 DISPATCHER: Starting worker discovery
00:18:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:18:16 DISPATCHER: Finished worker discovery
00:19:16 DISPATCHER: Starting worker discovery
00:19:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:19:16 DISPATCHER: Finished worker discovery
00:20:16 DISPATCHER: Starting worker discovery
00:20:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:20:16 DISPATCHER: Finished worker discovery
00:21:16 DISPATCHER: Starting worker discovery
00:21:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:21:16 DISPATCHER: Finished worker discovery
00:22:16 DISPATCHER: Starting worker discovery
00:22:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:22:16 DISPATCHER: Finished worker discovery
00:23:16 DISPATCHER: Starting worker discovery
00:23:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:23:16 DISPATCHER: Finished worker discovery
00:24:16 DISPATCHER: Starting worker discovery
00:24:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:24:16 DISPATCHER: Finished worker discovery
00:25:16 DISPATCHER: Starting worker discovery
00:25:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:25:16 DISPATCHER: Finished worker discovery
00:26:16 DISPATCHER: Starting worker discovery
00:26:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:26:16 DISPATCHER: Finished worker discovery
00:27:16 DISPATCHER: Starting worker discovery
00:27:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:27:16 DISPATCHER: Finished worker discovery
00:28:16 DISPATCHER: Starting worker discovery
00:28:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:28:16 DISPATCHER: Finished worker discovery
00:29:16 DISPATCHER: Starting worker discovery
00:29:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:29:16 DISPATCHER: Finished worker discovery
00:30:07 WORKER: done with job (2, 0, 4), trying to register it.
00:30:07 WORKER: registered result for job (2, 0, 4) with dispatcher
00:30:07 DISPATCHER: job (2, 0, 4) finished
00:30:07 DISPATCHER: register_result: lock acquired
00:30:07 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:30:07 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 85, 'last_n_outputs': 9, 'lr': 0.0012755311504199867, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.1529318183385919}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.2397281886612324, 'info': {'music-speech': 0.2397281886612324, 'config': "{'batch_size': 32, 'hidden_dim': 85, 'last_n_outputs': 9, 'lr': 0.0012755311504199867, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.1529318183385919}"}}
exception: None

00:30:07 job_callback for (2, 0, 4) started
00:30:07 DISPATCHER: Trying to submit another job.
00:30:07 job_callback for (2, 0, 4) got condition
00:30:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:30:07 Only 4 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
00:30:07 HBMASTER: Trying to run another job!
00:30:07 job_callback for (2, 0, 4) finished
00:30:07 start sampling a new configuration.
00:30:07 best_vector: [2, 0.8959202586054013, 0.3980955316653342, 0.30539334822227376, 0.30883690794716234, 0, 0.347136544110482, 0.8536930127722265], 0.02745597994582743, 0.708510983978795, 0.019452863367520255
00:30:07 done sampling a new configuration.
00:30:07 HBMASTER: schedule new run for iteration 3
00:30:07 HBMASTER: trying submitting job (3, 0, 0) to dispatcher
00:30:07 HBMASTER: submitting job (3, 0, 0) to dispatcher
00:30:07 DISPATCHER: trying to submit job (3, 0, 0)
00:30:07 DISPATCHER: trying to notify the job_runner thread.
00:30:07 HBMASTER: job (3, 0, 0) submitted to dispatcher
00:30:07 DISPATCHER: Trying to submit another job.
00:30:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:30:07 DISPATCHER: starting job (3, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:30:07 DISPATCHER: job (3, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:30:07 WORKER: start processing job (3, 0, 0)
00:30:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:30:07 WORKER: args: ()
00:30:07 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 92, 'last_n_outputs': 20, 'lr': 0.0040811888967565895, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.1290268862339465}, 'budget': 1200.0, 'working_directory': '.'}
00:30:16 DISPATCHER: Starting worker discovery
00:30:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:30:16 DISPATCHER: Finished worker discovery
Exception in thread Thread-467:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

00:31:16 DISPATCHER: Starting worker discovery
00:31:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:31:16 DISPATCHER: Finished worker discovery
00:32:16 DISPATCHER: Starting worker discovery
00:32:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:32:16 DISPATCHER: Finished worker discovery
00:33:16 DISPATCHER: Starting worker discovery
00:33:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:33:16 DISPATCHER: Finished worker discovery
00:34:16 DISPATCHER: Starting worker discovery
00:34:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:34:16 DISPATCHER: Finished worker discovery
00:35:16 DISPATCHER: Starting worker discovery
00:35:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:35:16 DISPATCHER: Finished worker discovery
00:36:16 DISPATCHER: Starting worker discovery
00:36:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:36:16 DISPATCHER: Finished worker discovery
00:37:16 DISPATCHER: Starting worker discovery
00:37:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:37:16 DISPATCHER: Finished worker discovery
00:38:16 DISPATCHER: Starting worker discovery
00:38:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:38:16 DISPATCHER: Finished worker discovery
00:39:16 DISPATCHER: Starting worker discovery
00:39:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:39:16 DISPATCHER: Finished worker discovery
00:40:16 DISPATCHER: Starting worker discovery
00:40:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:40:16 DISPATCHER: Finished worker discovery
00:41:16 DISPATCHER: Starting worker discovery
00:41:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:41:16 DISPATCHER: Finished worker discovery
00:42:16 DISPATCHER: Starting worker discovery
00:42:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:42:16 DISPATCHER: Finished worker discovery
00:43:16 DISPATCHER: Starting worker discovery
00:43:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:43:16 DISPATCHER: Finished worker discovery
00:44:16 DISPATCHER: Starting worker discovery
00:44:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:44:17 DISPATCHER: Finished worker discovery
00:45:17 DISPATCHER: Starting worker discovery
00:45:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:45:17 DISPATCHER: Finished worker discovery
00:46:17 DISPATCHER: Starting worker discovery
00:46:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:46:17 DISPATCHER: Finished worker discovery
00:47:17 DISPATCHER: Starting worker discovery
00:47:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:47:17 DISPATCHER: Finished worker discovery
00:48:17 DISPATCHER: Starting worker discovery
00:48:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:48:17 DISPATCHER: Finished worker discovery
00:49:17 DISPATCHER: Starting worker discovery
00:49:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:49:17 DISPATCHER: Finished worker discovery
00:50:16 WORKER: done with job (3, 0, 0), trying to register it.
00:50:16 WORKER: registered result for job (3, 0, 0) with dispatcher
00:50:16 DISPATCHER: job (3, 0, 0) finished
00:50:16 DISPATCHER: register_result: lock acquired
00:50:16 DISPATCHER: job (3, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
00:50:16 job_id: (3, 0, 0)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 92, 'last_n_outputs': 20, 'lr': 0.0040811888967565895, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.1290268862339465}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.858985962259539, 'info': {'music-speech': 0.858985962259539, 'config': "{'batch_size': 64, 'hidden_dim': 92, 'last_n_outputs': 20, 'lr': 0.0040811888967565895, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.1290268862339465}"}}
exception: None

00:50:16 job_callback for (3, 0, 0) started
00:50:16 DISPATCHER: Trying to submit another job.
00:50:16 job_callback for (3, 0, 0) got condition
00:50:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
00:50:16 Only 5 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
00:50:16 HBMASTER: Trying to run another job!
00:50:16 job_callback for (3, 0, 0) finished
00:50:16 start sampling a new configuration.
00:50:16 done sampling a new configuration.
00:50:16 HBMASTER: schedule new run for iteration 3
00:50:16 HBMASTER: trying submitting job (3, 0, 1) to dispatcher
00:50:16 HBMASTER: submitting job (3, 0, 1) to dispatcher
00:50:16 DISPATCHER: trying to submit job (3, 0, 1)
00:50:16 DISPATCHER: trying to notify the job_runner thread.
00:50:16 HBMASTER: job (3, 0, 1) submitted to dispatcher
00:50:16 DISPATCHER: Trying to submit another job.
00:50:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
00:50:16 DISPATCHER: starting job (3, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
00:50:16 DISPATCHER: job (3, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
00:50:16 WORKER: start processing job (3, 0, 1)
00:50:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
00:50:16 WORKER: args: ()
00:50:16 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 85, 'last_n_outputs': 43, 'lr': 0.027985671551272517, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.1921125838470959}, 'budget': 1200.0, 'working_directory': '.'}
00:50:17 DISPATCHER: Starting worker discovery
00:50:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:50:17 DISPATCHER: Finished worker discovery
Exception in thread Thread-468:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

00:51:17 DISPATCHER: Starting worker discovery
00:51:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:51:17 DISPATCHER: Finished worker discovery
00:52:17 DISPATCHER: Starting worker discovery
00:52:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:52:17 DISPATCHER: Finished worker discovery
00:53:17 DISPATCHER: Starting worker discovery
00:53:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:53:17 DISPATCHER: Finished worker discovery
00:54:17 DISPATCHER: Starting worker discovery
00:54:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:54:17 DISPATCHER: Finished worker discovery
00:55:17 DISPATCHER: Starting worker discovery
00:55:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:55:17 DISPATCHER: Finished worker discovery
00:56:17 DISPATCHER: Starting worker discovery
00:56:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:56:17 DISPATCHER: Finished worker discovery
00:57:17 DISPATCHER: Starting worker discovery
00:57:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:57:17 DISPATCHER: Finished worker discovery
00:58:17 DISPATCHER: Starting worker discovery
00:58:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:58:17 DISPATCHER: Finished worker discovery
00:59:17 DISPATCHER: Starting worker discovery
00:59:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
00:59:17 DISPATCHER: Finished worker discovery
01:00:17 DISPATCHER: Starting worker discovery
01:00:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:00:17 DISPATCHER: Finished worker discovery
01:01:17 DISPATCHER: Starting worker discovery
01:01:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:01:17 DISPATCHER: Finished worker discovery
01:02:17 DISPATCHER: Starting worker discovery
01:02:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:02:17 DISPATCHER: Finished worker discovery
01:03:17 DISPATCHER: Starting worker discovery
01:03:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:03:17 DISPATCHER: Finished worker discovery
01:04:17 DISPATCHER: Starting worker discovery
01:04:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:04:17 DISPATCHER: Finished worker discovery
01:05:17 DISPATCHER: Starting worker discovery
01:05:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:05:17 DISPATCHER: Finished worker discovery
01:06:17 DISPATCHER: Starting worker discovery
01:06:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:06:17 DISPATCHER: Finished worker discovery
01:07:17 DISPATCHER: Starting worker discovery
01:07:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:07:17 DISPATCHER: Finished worker discovery
01:08:17 DISPATCHER: Starting worker discovery
01:08:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:08:17 DISPATCHER: Finished worker discovery
01:09:17 DISPATCHER: Starting worker discovery
01:09:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:09:17 DISPATCHER: Finished worker discovery
01:10:17 DISPATCHER: Starting worker discovery
01:10:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:10:17 DISPATCHER: Finished worker discovery
01:10:24 WORKER: done with job (3, 0, 1), trying to register it.
01:10:24 WORKER: registered result for job (3, 0, 1) with dispatcher
01:10:24 DISPATCHER: job (3, 0, 1) finished
01:10:24 DISPATCHER: register_result: lock acquired
01:10:24 DISPATCHER: job (3, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
01:10:24 job_id: (3, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 85, 'last_n_outputs': 43, 'lr': 0.027985671551272517, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.1921125838470959}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 85, 'last_n_outputs': 43, 'lr': 0.027985671551272517, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.1921125838470959}"}}
exception: None

01:10:24 job_callback for (3, 0, 1) started
01:10:24 DISPATCHER: Trying to submit another job.
01:10:24 job_callback for (3, 0, 1) got condition
01:10:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:10:24 Only 6 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
01:10:24 HBMASTER: Trying to run another job!
01:10:24 job_callback for (3, 0, 1) finished
01:10:24 start sampling a new configuration.
01:10:24 done sampling a new configuration.
01:10:24 HBMASTER: schedule new run for iteration 3
01:10:24 HBMASTER: trying submitting job (3, 0, 2) to dispatcher
01:10:24 HBMASTER: submitting job (3, 0, 2) to dispatcher
01:10:24 DISPATCHER: trying to submit job (3, 0, 2)
01:10:24 DISPATCHER: trying to notify the job_runner thread.
01:10:24 HBMASTER: job (3, 0, 2) submitted to dispatcher
01:10:24 DISPATCHER: Trying to submit another job.
01:10:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:10:24 DISPATCHER: starting job (3, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
01:10:24 DISPATCHER: job (3, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
01:10:24 WORKER: start processing job (3, 0, 2)
01:10:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:10:24 WORKER: args: ()
01:10:24 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 34, 'lr': 0.002655372005616149, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.02870456749911463}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-469:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:11:17 DISPATCHER: Starting worker discovery
01:11:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:11:17 DISPATCHER: Finished worker discovery
01:12:17 DISPATCHER: Starting worker discovery
01:12:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:12:17 DISPATCHER: Finished worker discovery
01:13:17 DISPATCHER: Starting worker discovery
01:13:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:13:17 DISPATCHER: Finished worker discovery
01:14:17 DISPATCHER: Starting worker discovery
01:14:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:14:17 DISPATCHER: Finished worker discovery
01:15:17 DISPATCHER: Starting worker discovery
01:15:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:15:17 DISPATCHER: Finished worker discovery
01:16:17 DISPATCHER: Starting worker discovery
01:16:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:16:17 DISPATCHER: Finished worker discovery
01:17:17 DISPATCHER: Starting worker discovery
01:17:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:17:17 DISPATCHER: Finished worker discovery
01:18:17 DISPATCHER: Starting worker discovery
01:18:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:18:17 DISPATCHER: Finished worker discovery
01:19:17 DISPATCHER: Starting worker discovery
01:19:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:19:17 DISPATCHER: Finished worker discovery
01:20:17 DISPATCHER: Starting worker discovery
01:20:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:20:17 DISPATCHER: Finished worker discovery
01:21:17 DISPATCHER: Starting worker discovery
01:21:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:21:17 DISPATCHER: Finished worker discovery
01:22:17 DISPATCHER: Starting worker discovery
01:22:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:22:17 DISPATCHER: Finished worker discovery
01:23:17 DISPATCHER: Starting worker discovery
01:23:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:23:17 DISPATCHER: Finished worker discovery
01:24:17 DISPATCHER: Starting worker discovery
01:24:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:24:17 DISPATCHER: Finished worker discovery
01:25:17 DISPATCHER: Starting worker discovery
01:25:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:25:17 DISPATCHER: Finished worker discovery
01:26:17 DISPATCHER: Starting worker discovery
01:26:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:26:17 DISPATCHER: Finished worker discovery
01:27:17 DISPATCHER: Starting worker discovery
01:27:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:27:17 DISPATCHER: Finished worker discovery
01:28:17 DISPATCHER: Starting worker discovery
01:28:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:28:17 DISPATCHER: Finished worker discovery
01:29:17 DISPATCHER: Starting worker discovery
01:29:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:29:17 DISPATCHER: Finished worker discovery
01:30:17 DISPATCHER: Starting worker discovery
01:30:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:30:17 DISPATCHER: Finished worker discovery
01:30:33 WORKER: done with job (3, 0, 2), trying to register it.
01:30:33 WORKER: registered result for job (3, 0, 2) with dispatcher
01:30:33 DISPATCHER: job (3, 0, 2) finished
01:30:33 DISPATCHER: register_result: lock acquired
01:30:33 DISPATCHER: job (3, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
01:30:33 job_id: (3, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 34, 'lr': 0.002655372005616149, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.02870456749911463}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.4585167266433928, 'info': {'music-speech': 0.4585167266433928, 'config': "{'batch_size': 16, 'hidden_dim': 71, 'last_n_outputs': 34, 'lr': 0.002655372005616149, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 97, 'weight_decay': 0.02870456749911463}"}}
exception: None

01:30:33 job_callback for (3, 0, 2) started
01:30:33 DISPATCHER: Trying to submit another job.
01:30:33 job_callback for (3, 0, 2) got condition
01:30:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:30:33 Only 7 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
01:30:33 HBMASTER: Trying to run another job!
01:30:33 job_callback for (3, 0, 2) finished
01:30:33 start sampling a new configuration.
01:30:33 best_vector: [3, 0.6302481590188944, 0.37489424273749866, 0.9881634417105527, 0.1420159504091033, 0, 0.4395339902062071, 0.15631597314452644], 0.06392145347731308, 0.09468827732666975, 0.006052612313983639
01:30:33 done sampling a new configuration.
01:30:33 HBMASTER: schedule new run for iteration 3
01:30:33 HBMASTER: trying submitting job (3, 0, 3) to dispatcher
01:30:33 HBMASTER: submitting job (3, 0, 3) to dispatcher
01:30:33 DISPATCHER: trying to submit job (3, 0, 3)
01:30:33 DISPATCHER: trying to notify the job_runner thread.
01:30:33 HBMASTER: job (3, 0, 3) submitted to dispatcher
01:30:33 DISPATCHER: Trying to submit another job.
01:30:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:30:33 DISPATCHER: starting job (3, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
01:30:33 DISPATCHER: job (3, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
01:30:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:30:33 WORKER: start processing job (3, 0, 3)
01:30:33 WORKER: args: ()
01:30:33 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 71, 'last_n_outputs': 19, 'lr': 0.09469496403116413, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.015972458553344823}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-470:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:31:17 DISPATCHER: Starting worker discovery
01:31:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:31:17 DISPATCHER: Finished worker discovery
01:32:17 DISPATCHER: Starting worker discovery
01:32:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:32:17 DISPATCHER: Finished worker discovery
01:33:17 DISPATCHER: Starting worker discovery
01:33:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:33:17 DISPATCHER: Finished worker discovery
01:34:17 DISPATCHER: Starting worker discovery
01:34:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:34:17 DISPATCHER: Finished worker discovery
01:35:17 DISPATCHER: Starting worker discovery
01:35:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:35:17 DISPATCHER: Finished worker discovery
01:36:17 DISPATCHER: Starting worker discovery
01:36:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:36:17 DISPATCHER: Finished worker discovery
01:37:17 DISPATCHER: Starting worker discovery
01:37:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:37:17 DISPATCHER: Finished worker discovery
01:38:17 DISPATCHER: Starting worker discovery
01:38:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:38:17 DISPATCHER: Finished worker discovery
01:39:17 DISPATCHER: Starting worker discovery
01:39:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:39:17 DISPATCHER: Finished worker discovery
01:40:17 DISPATCHER: Starting worker discovery
01:40:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:40:17 DISPATCHER: Finished worker discovery
01:41:17 DISPATCHER: Starting worker discovery
01:41:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:41:17 DISPATCHER: Finished worker discovery
01:42:17 DISPATCHER: Starting worker discovery
01:42:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:42:17 DISPATCHER: Finished worker discovery
01:43:17 DISPATCHER: Starting worker discovery
01:43:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:43:17 DISPATCHER: Finished worker discovery
01:44:17 DISPATCHER: Starting worker discovery
01:44:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:44:17 DISPATCHER: Finished worker discovery
01:45:17 DISPATCHER: Starting worker discovery
01:45:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:45:17 DISPATCHER: Finished worker discovery
01:46:17 DISPATCHER: Starting worker discovery
01:46:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:46:17 DISPATCHER: Finished worker discovery
01:47:17 DISPATCHER: Starting worker discovery
01:47:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:47:17 DISPATCHER: Finished worker discovery
01:48:17 DISPATCHER: Starting worker discovery
01:48:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:48:17 DISPATCHER: Finished worker discovery
01:49:17 DISPATCHER: Starting worker discovery
01:49:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:49:17 DISPATCHER: Finished worker discovery
01:50:17 DISPATCHER: Starting worker discovery
01:50:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:50:17 DISPATCHER: Finished worker discovery
01:50:42 WORKER: done with job (3, 0, 3), trying to register it.
01:50:42 WORKER: registered result for job (3, 0, 3) with dispatcher
01:50:42 DISPATCHER: job (3, 0, 3) finished
01:50:42 DISPATCHER: register_result: lock acquired
01:50:42 DISPATCHER: job (3, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
01:50:42 job_id: (3, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 71, 'last_n_outputs': 19, 'lr': 0.09469496403116413, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.015972458553344823}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5050974538934166, 'info': {'music-speech': 0.5050974538934166, 'config': "{'batch_size': 128, 'hidden_dim': 71, 'last_n_outputs': 19, 'lr': 0.09469496403116413, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 49, 'weight_decay': 0.015972458553344823}"}}
exception: None

01:50:42 job_callback for (3, 0, 3) started
01:50:42 DISPATCHER: Trying to submit another job.
01:50:42 job_callback for (3, 0, 3) got condition
01:50:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:50:42 Only 8 run(s) for budget 1200.000000 available, need more than 10 -> can't build model!
01:50:42 HBMASTER: Trying to run another job!
01:50:42 job_callback for (3, 0, 3) finished
01:50:42 start sampling a new configuration.
01:50:42 best_vector: [3, 0.608965790518855, 0.2385177027152301, 0.8036818021336887, 0.148772962618707, 0, 0.2933705239514265, 0.6026997357660495], 0.0228797166692971, 1.7308243095886158, 0.0396007698077193
01:50:42 done sampling a new configuration.
01:50:42 HBMASTER: schedule new run for iteration 4
01:50:42 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
01:50:42 HBMASTER: submitting job (4, 0, 0) to dispatcher
01:50:42 DISPATCHER: trying to submit job (4, 0, 0)
01:50:42 DISPATCHER: trying to notify the job_runner thread.
01:50:42 HBMASTER: job (4, 0, 0) submitted to dispatcher
01:50:42 DISPATCHER: Trying to submit another job.
01:50:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:50:42 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
01:50:42 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
01:50:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:50:42 WORKER: start processing job (4, 0, 0)
01:50:42 WORKER: args: ()
01:50:42 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 69, 'last_n_outputs': 12, 'lr': 0.04049147565105621, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.06083176740228754}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-471:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:51:17 DISPATCHER: Starting worker discovery
01:51:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:51:17 DISPATCHER: Finished worker discovery
01:51:35 WORKER: done with job (4, 0, 0), trying to register it.
01:51:35 WORKER: registered result for job (4, 0, 0) with dispatcher
01:51:35 DISPATCHER: job (4, 0, 0) finished
01:51:35 DISPATCHER: register_result: lock acquired
01:51:35 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
01:51:35 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 69, 'last_n_outputs': 12, 'lr': 0.04049147565105621, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.06083176740228754}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7466686922524389, 'info': {'music-speech': 0.7466686922524389, 'config': "{'batch_size': 128, 'hidden_dim': 69, 'last_n_outputs': 12, 'lr': 0.04049147565105621, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.06083176740228754}"}}
exception: None

01:51:35 job_callback for (4, 0, 0) started
01:51:35 DISPATCHER: Trying to submit another job.
01:51:35 job_callback for (4, 0, 0) got condition
01:51:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:51:35 HBMASTER: Trying to run another job!
01:51:35 job_callback for (4, 0, 0) finished
01:51:35 start sampling a new configuration.
01:51:35 done sampling a new configuration.
01:51:35 HBMASTER: schedule new run for iteration 4
01:51:35 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
01:51:35 HBMASTER: submitting job (4, 0, 1) to dispatcher
01:51:35 DISPATCHER: trying to submit job (4, 0, 1)
01:51:35 DISPATCHER: trying to notify the job_runner thread.
01:51:35 HBMASTER: job (4, 0, 1) submitted to dispatcher
01:51:35 DISPATCHER: Trying to submit another job.
01:51:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:51:35 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
01:51:35 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
01:51:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:51:35 WORKER: start processing job (4, 0, 1)
01:51:35 WORKER: args: ()
01:51:35 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 47, 'last_n_outputs': 41, 'lr': 0.0011039745414345799, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.1958191778553851}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-472:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:52:17 DISPATCHER: Starting worker discovery
01:52:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:52:17 DISPATCHER: Finished worker discovery
01:52:28 WORKER: done with job (4, 0, 1), trying to register it.
01:52:28 WORKER: registered result for job (4, 0, 1) with dispatcher
01:52:28 DISPATCHER: job (4, 0, 1) finished
01:52:28 DISPATCHER: register_result: lock acquired
01:52:28 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
01:52:28 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 47, 'last_n_outputs': 41, 'lr': 0.0011039745414345799, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.1958191778553851}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 47, 'last_n_outputs': 41, 'lr': 0.0011039745414345799, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 28, 'weight_decay': 0.1958191778553851}"}}
exception: None

01:52:28 job_callback for (4, 0, 1) started
01:52:28 DISPATCHER: Trying to submit another job.
01:52:28 job_callback for (4, 0, 1) got condition
01:52:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:52:28 HBMASTER: Trying to run another job!
01:52:28 job_callback for (4, 0, 1) finished
01:52:28 start sampling a new configuration.
01:52:28 best_vector: [0, 0.6243526737151689, 0.38006883318483, 0.8346202748995846, 0.06962894010123877, 0, 0.12184032862893263, 0.7275457448919099], 0.01989074114586314, 1.207553059255262, 0.02401912532154155
01:52:28 done sampling a new configuration.
01:52:28 HBMASTER: schedule new run for iteration 4
01:52:28 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
01:52:28 HBMASTER: submitting job (4, 0, 2) to dispatcher
01:52:28 DISPATCHER: trying to submit job (4, 0, 2)
01:52:28 DISPATCHER: trying to notify the job_runner thread.
01:52:28 HBMASTER: job (4, 0, 2) submitted to dispatcher
01:52:28 DISPATCHER: Trying to submit another job.
01:52:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:52:28 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
01:52:28 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
01:52:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:52:28 WORKER: start processing job (4, 0, 2)
01:52:28 WORKER: args: ()
01:52:28 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 70, 'last_n_outputs': 20, 'lr': 0.04669179281863955, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.0884216952978212}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-473:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:53:17 DISPATCHER: Starting worker discovery
01:53:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:53:17 DISPATCHER: Finished worker discovery
01:53:21 WORKER: done with job (4, 0, 2), trying to register it.
01:53:21 WORKER: registered result for job (4, 0, 2) with dispatcher
01:53:21 DISPATCHER: job (4, 0, 2) finished
01:53:21 DISPATCHER: register_result: lock acquired
01:53:21 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
01:53:21 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 70, 'last_n_outputs': 20, 'lr': 0.04669179281863955, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.0884216952978212}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.09068985739884627, 'info': {'music-speech': 0.09068985739884627, 'config': "{'batch_size': 16, 'hidden_dim': 70, 'last_n_outputs': 20, 'lr': 0.04669179281863955, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.0884216952978212}"}}
exception: None

01:53:21 job_callback for (4, 0, 2) started
01:53:21 DISPATCHER: Trying to submit another job.
01:53:21 job_callback for (4, 0, 2) got condition
01:53:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:53:21 HBMASTER: Trying to run another job!
01:53:21 job_callback for (4, 0, 2) finished
01:53:21 start sampling a new configuration.
01:53:21 best_vector: [1, 0.40486706649176774, 0.5018795004375385, 0.5779856365014944, 0.0799396421671633, 0, 0.13118211395481544, 0.43698507922554664], 0.04878036038912096, 1.3994720426076535, 0.06826675059290058
01:53:21 done sampling a new configuration.
01:53:21 HBMASTER: schedule new run for iteration 4
01:53:21 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
01:53:21 HBMASTER: submitting job (4, 0, 3) to dispatcher
01:53:21 DISPATCHER: trying to submit job (4, 0, 3)
01:53:21 DISPATCHER: trying to notify the job_runner thread.
01:53:21 HBMASTER: job (4, 0, 3) submitted to dispatcher
01:53:21 DISPATCHER: Trying to submit another job.
01:53:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:53:21 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
01:53:21 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
01:53:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:53:21 WORKER: start processing job (4, 0, 3)
01:53:21 WORKER: args: ()
01:53:21 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 52, 'last_n_outputs': 26, 'lr': 0.014320931683972964, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.037028037571834434}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-474:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:54:15 WORKER: done with job (4, 0, 3), trying to register it.
01:54:15 DISPATCHER: job (4, 0, 3) finished
01:54:15 WORKER: registered result for job (4, 0, 3) with dispatcher
01:54:15 DISPATCHER: register_result: lock acquired
01:54:15 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
01:54:15 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 52, 'last_n_outputs': 26, 'lr': 0.014320931683972964, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.037028037571834434}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6408794259495577, 'info': {'music-speech': 0.6408794259495577, 'config': "{'batch_size': 32, 'hidden_dim': 52, 'last_n_outputs': 26, 'lr': 0.014320931683972964, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 21, 'weight_decay': 0.037028037571834434}"}}
exception: None

01:54:15 job_callback for (4, 0, 3) started
01:54:15 job_callback for (4, 0, 3) got condition
01:54:15 DISPATCHER: Trying to submit another job.
01:54:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:54:15 HBMASTER: Trying to run another job!
01:54:15 job_callback for (4, 0, 3) finished
01:54:15 start sampling a new configuration.
01:54:15 done sampling a new configuration.
01:54:15 HBMASTER: schedule new run for iteration 4
01:54:15 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
01:54:15 HBMASTER: submitting job (4, 0, 4) to dispatcher
01:54:15 DISPATCHER: trying to submit job (4, 0, 4)
01:54:15 DISPATCHER: trying to notify the job_runner thread.
01:54:15 HBMASTER: job (4, 0, 4) submitted to dispatcher
01:54:15 DISPATCHER: Trying to submit another job.
01:54:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:54:15 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
01:54:15 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
01:54:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:54:15 WORKER: start processing job (4, 0, 4)
01:54:15 WORKER: args: ()
01:54:15 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 95, 'last_n_outputs': 44, 'lr': 0.0011086368758338211, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.08868048561791866}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:54:17 DISPATCHER: Starting worker discovery
01:54:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:54:17 DISPATCHER: Finished worker discovery
Exception in thread Thread-475:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:55:08 WORKER: done with job (4, 0, 4), trying to register it.
01:55:08 WORKER: registered result for job (4, 0, 4) with dispatcher
01:55:08 DISPATCHER: job (4, 0, 4) finished
01:55:08 DISPATCHER: register_result: lock acquired
01:55:08 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
01:55:08 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 95, 'last_n_outputs': 44, 'lr': 0.0011086368758338211, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.08868048561791866}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 95, 'last_n_outputs': 44, 'lr': 0.0011086368758338211, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.08868048561791866}"}}
exception: None

01:55:08 job_callback for (4, 0, 4) started
01:55:08 DISPATCHER: Trying to submit another job.
01:55:08 job_callback for (4, 0, 4) got condition
01:55:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:55:08 HBMASTER: Trying to run another job!
01:55:08 job_callback for (4, 0, 4) finished
01:55:08 start sampling a new configuration.
01:55:08 best_vector: [1, 0.5768438418714306, 0.23744757657214688, 0.7962649735230933, 0.044327247147017836, 0, 0.05921117014130861, 0.7930065947682448], 0.00875854287279281, 1.3413223901655005, 0.011748029660501461
01:55:08 done sampling a new configuration.
01:55:08 HBMASTER: schedule new run for iteration 4
01:55:08 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
01:55:08 HBMASTER: submitting job (4, 0, 5) to dispatcher
01:55:08 DISPATCHER: trying to submit job (4, 0, 5)
01:55:08 DISPATCHER: trying to notify the job_runner thread.
01:55:08 HBMASTER: job (4, 0, 5) submitted to dispatcher
01:55:08 DISPATCHER: Trying to submit another job.
01:55:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:55:08 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
01:55:08 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
01:55:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:55:08 WORKER: start processing job (4, 0, 5)
01:55:08 WORKER: args: ()
01:55:08 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 66, 'last_n_outputs': 12, 'lr': 0.03913181097802498, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.10757847078670087}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:55:17 DISPATCHER: Starting worker discovery
01:55:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:55:17 DISPATCHER: Finished worker discovery
Exception in thread Thread-476:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:56:01 WORKER: done with job (4, 0, 5), trying to register it.
01:56:01 DISPATCHER: job (4, 0, 5) finished
01:56:01 WORKER: registered result for job (4, 0, 5) with dispatcher
01:56:01 DISPATCHER: register_result: lock acquired
01:56:01 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
01:56:01 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 66, 'last_n_outputs': 12, 'lr': 0.03913181097802498, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.10757847078670087}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5746906827788184, 'info': {'music-speech': 0.5746906827788184, 'config': "{'batch_size': 32, 'hidden_dim': 66, 'last_n_outputs': 12, 'lr': 0.03913181097802498, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.10757847078670087}"}}
exception: None

01:56:01 job_callback for (4, 0, 5) started
01:56:01 DISPATCHER: Trying to submit another job.
01:56:01 job_callback for (4, 0, 5) got condition
01:56:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:56:01 HBMASTER: Trying to run another job!
01:56:01 job_callback for (4, 0, 5) finished
01:56:01 start sampling a new configuration.
01:56:01 best_vector: [3, 0.37691517424322873, 0.200999274631821, 0.454792051371947, 0.06031077625070691, 0, 0.010996163631123546, 0.9693339201173812], 0.018175000442060964, 0.2609696380249801, 0.004743123286468503
01:56:01 done sampling a new configuration.
01:56:01 HBMASTER: schedule new run for iteration 4
01:56:01 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
01:56:01 HBMASTER: submitting job (4, 0, 6) to dispatcher
01:56:01 DISPATCHER: trying to submit job (4, 0, 6)
01:56:01 DISPATCHER: trying to notify the job_runner thread.
01:56:01 HBMASTER: job (4, 0, 6) submitted to dispatcher
01:56:01 DISPATCHER: Trying to submit another job.
01:56:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:56:01 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216
01:56:01 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
01:56:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:56:01 WORKER: start processing job (4, 0, 6)
01:56:01 WORKER: args: ()
01:56:01 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 50, 'last_n_outputs': 11, 'lr': 0.008120524906991647, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 11, 'weight_decay': 0.18244522688906806}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-477:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:56:17 DISPATCHER: Starting worker discovery
01:56:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:56:17 DISPATCHER: Finished worker discovery
01:56:54 WORKER: done with job (4, 0, 6), trying to register it.
01:56:54 WORKER: registered result for job (4, 0, 6) with dispatcher
01:56:54 DISPATCHER: job (4, 0, 6) finished
01:56:54 DISPATCHER: register_result: lock acquired
01:56:54 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
01:56:54 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 50, 'last_n_outputs': 11, 'lr': 0.008120524906991647, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 11, 'weight_decay': 0.18244522688906806}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5929003147158203, 'info': {'music-speech': 0.5929003147158203, 'config': "{'batch_size': 128, 'hidden_dim': 50, 'last_n_outputs': 11, 'lr': 0.008120524906991647, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 11, 'weight_decay': 0.18244522688906806}"}}
exception: None

01:56:54 job_callback for (4, 0, 6) started
01:56:54 DISPATCHER: Trying to submit another job.
01:56:54 job_callback for (4, 0, 6) got condition
01:56:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:56:54 HBMASTER: Trying to run another job!
01:56:54 job_callback for (4, 0, 6) finished
01:56:54 start sampling a new configuration.
01:56:54 done sampling a new configuration.
01:56:54 HBMASTER: schedule new run for iteration 4
01:56:54 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
01:56:54 HBMASTER: submitting job (4, 0, 7) to dispatcher
01:56:54 DISPATCHER: trying to submit job (4, 0, 7)
01:56:54 DISPATCHER: trying to notify the job_runner thread.
01:56:54 HBMASTER: job (4, 0, 7) submitted to dispatcher
01:56:54 DISPATCHER: Trying to submit another job.
01:56:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:56:54 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
01:56:54 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
01:56:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:56:54 WORKER: start processing job (4, 0, 7)
01:56:54 WORKER: args: ()
01:56:54 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 43, 'lr': 0.04501075769448905, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.12305913093668566}, 'budget': 44.44444444444444, 'working_directory': '.'}
01:57:17 DISPATCHER: Starting worker discovery
01:57:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:57:17 DISPATCHER: Finished worker discovery
Exception in thread Thread-478:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:57:47 WORKER: done with job (4, 0, 7), trying to register it.
01:57:47 WORKER: registered result for job (4, 0, 7) with dispatcher
01:57:47 DISPATCHER: job (4, 0, 7) finished
01:57:47 DISPATCHER: register_result: lock acquired
01:57:47 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
01:57:47 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 43, 'lr': 0.04501075769448905, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.12305913093668566}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7797030207812583, 'info': {'music-speech': 0.7797030207812583, 'config': "{'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 43, 'lr': 0.04501075769448905, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.12305913093668566}"}}
exception: None

01:57:47 job_callback for (4, 0, 7) started
01:57:47 DISPATCHER: Trying to submit another job.
01:57:47 job_callback for (4, 0, 7) got condition
01:57:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:57:47 HBMASTER: Trying to run another job!
01:57:47 job_callback for (4, 0, 7) finished
01:57:47 start sampling a new configuration.
01:57:47 best_vector: [0, 0.7159797899282336, 0.45816923095722817, 0.19402713329975096, 0.3399689322918851, 0, 0.10293345755588629, 0.6536384042068585], 0.02792495943297111, 2.0161422350084273, 0.056300690123710036
01:57:47 done sampling a new configuration.
01:57:47 HBMASTER: schedule new run for iteration 4
01:57:47 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
01:57:47 HBMASTER: submitting job (4, 0, 8) to dispatcher
01:57:47 DISPATCHER: trying to submit job (4, 0, 8)
01:57:47 DISPATCHER: trying to notify the job_runner thread.
01:57:47 HBMASTER: job (4, 0, 8) submitted to dispatcher
01:57:47 DISPATCHER: Trying to submit another job.
01:57:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:57:47 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216
01:57:47 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
01:57:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:57:47 WORKER: start processing job (4, 0, 8)
01:57:47 WORKER: args: ()
01:57:47 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 77, 'last_n_outputs': 23, 'lr': 0.0024437358868791654, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.07086032994431084}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-479:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:58:17 DISPATCHER: Starting worker discovery
01:58:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:58:17 DISPATCHER: Finished worker discovery
01:58:40 WORKER: done with job (4, 0, 8), trying to register it.
01:58:40 WORKER: registered result for job (4, 0, 8) with dispatcher
01:58:40 DISPATCHER: job (4, 0, 8) finished
01:58:40 DISPATCHER: register_result: lock acquired
01:58:40 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
01:58:40 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 77, 'last_n_outputs': 23, 'lr': 0.0024437358868791654, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.07086032994431084}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6823050479093434, 'info': {'music-speech': 0.6823050479093434, 'config': "{'batch_size': 16, 'hidden_dim': 77, 'last_n_outputs': 23, 'lr': 0.0024437358868791654, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 19, 'weight_decay': 0.07086032994431084}"}}
exception: None

01:58:40 job_callback for (4, 0, 8) started
01:58:40 job_callback for (4, 0, 8) got condition
01:58:40 DISPATCHER: Trying to submit another job.
01:58:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:58:40 HBMASTER: Trying to run another job!
01:58:40 job_callback for (4, 0, 8) finished
01:58:40 start sampling a new configuration.
01:58:40 best_vector: [0, 0.0857223841913815, 0.772056347557474, 0.564331818489688, 0.0638781211623349, 0, 0.7529763467339186, 0.47750316321327185], 0.13016604635908788, 1.3683521563601593, 0.17811299022033436
01:58:40 done sampling a new configuration.
01:58:40 HBMASTER: schedule new run for iteration 4
01:58:40 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
01:58:40 HBMASTER: submitting job (4, 0, 9) to dispatcher
01:58:40 DISPATCHER: trying to submit job (4, 0, 9)
01:58:40 DISPATCHER: trying to notify the job_runner thread.
01:58:40 HBMASTER: job (4, 0, 9) submitted to dispatcher
01:58:40 DISPATCHER: Trying to submit another job.
01:58:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:58:40 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpul.22021139727314577216
01:58:40 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
01:58:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:58:40 WORKER: start processing job (4, 0, 9)
01:58:40 WORKER: args: ()
01:58:40 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 26, 'last_n_outputs': 39, 'lr': 0.013448183827439593, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.041806704849105675}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-480:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

01:59:17 DISPATCHER: Starting worker discovery
01:59:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:59:17 DISPATCHER: Finished worker discovery
01:59:33 WORKER: done with job (4, 0, 9), trying to register it.
01:59:33 WORKER: registered result for job (4, 0, 9) with dispatcher
01:59:33 DISPATCHER: job (4, 0, 9) finished
01:59:33 DISPATCHER: register_result: lock acquired
01:59:33 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
01:59:33 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 26, 'last_n_outputs': 39, 'lr': 0.013448183827439593, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.041806704849105675}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7036768574178183, 'info': {'music-speech': 0.7036768574178183, 'config': "{'batch_size': 16, 'hidden_dim': 26, 'last_n_outputs': 39, 'lr': 0.013448183827439593, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.041806704849105675}"}}
exception: None

01:59:33 job_callback for (4, 0, 9) started
01:59:33 DISPATCHER: Trying to submit another job.
01:59:33 job_callback for (4, 0, 9) got condition
01:59:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
01:59:33 HBMASTER: Trying to run another job!
01:59:33 job_callback for (4, 0, 9) finished
01:59:33 start sampling a new configuration.
01:59:34 best_vector: [2, 0.5213314594112561, 0.32844788939703934, 0.27228074714068157, 0.4473622381407518, 0, 0.2269406330558374, 0.8983568325507519], 0.030416519588308877, 0.40435127882128385, 0.012298958592825324
01:59:34 done sampling a new configuration.
01:59:34 HBMASTER: schedule new run for iteration 4
01:59:34 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
01:59:34 HBMASTER: submitting job (4, 0, 10) to dispatcher
01:59:34 DISPATCHER: trying to submit job (4, 0, 10)
01:59:34 DISPATCHER: trying to notify the job_runner thread.
01:59:34 HBMASTER: job (4, 0, 10) submitted to dispatcher
01:59:34 DISPATCHER: Trying to submit another job.
01:59:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
01:59:34 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpul.22021139727314577216
01:59:34 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
01:59:34 WORKER: start processing job (4, 0, 10)
01:59:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
01:59:34 WORKER: args: ()
01:59:34 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 62, 'last_n_outputs': 17, 'lr': 0.00350397899665485, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.14749903736713532}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-481:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:00:17 DISPATCHER: Starting worker discovery
02:00:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:00:17 DISPATCHER: Finished worker discovery
02:00:27 WORKER: done with job (4, 0, 10), trying to register it.
02:00:27 WORKER: registered result for job (4, 0, 10) with dispatcher
02:00:27 DISPATCHER: job (4, 0, 10) finished
02:00:27 DISPATCHER: register_result: lock acquired
02:00:27 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
02:00:27 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 62, 'last_n_outputs': 17, 'lr': 0.00350397899665485, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.14749903736713532}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 62, 'last_n_outputs': 17, 'lr': 0.00350397899665485, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.14749903736713532}"}}
exception: None

02:00:27 job_callback for (4, 0, 10) started
02:00:27 DISPATCHER: Trying to submit another job.
02:00:27 job_callback for (4, 0, 10) got condition
02:00:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:00:27 HBMASTER: Trying to run another job!
02:00:27 job_callback for (4, 0, 10) finished
02:00:27 start sampling a new configuration.
02:00:27 best_vector: [0, 0.5419673862189314, 0.07061383058054804, 0.7282901939584703, 0.060741014927684724, 0, 0.4660974496412871, 0.5057809938085971], 0.025497795532216778, 0.5839638071499833, 0.014889789752925145
02:00:27 done sampling a new configuration.
02:00:27 HBMASTER: schedule new run for iteration 4
02:00:27 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
02:00:27 HBMASTER: submitting job (4, 0, 11) to dispatcher
02:00:27 DISPATCHER: trying to submit job (4, 0, 11)
02:00:27 DISPATCHER: trying to notify the job_runner thread.
02:00:27 HBMASTER: job (4, 0, 11) submitted to dispatcher
02:00:27 DISPATCHER: Trying to submit another job.
02:00:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:00:27 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpul.22021139727314577216
02:00:27 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
02:00:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:00:27 WORKER: start processing job (4, 0, 11)
02:00:27 WORKER: args: ()
02:00:27 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 63, 'last_n_outputs': 4, 'lr': 0.028614119590199258, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.04550260329053042}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-482:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:01:17 DISPATCHER: Starting worker discovery
02:01:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:01:17 DISPATCHER: Finished worker discovery
02:01:20 WORKER: done with job (4, 0, 11), trying to register it.
02:01:20 DISPATCHER: job (4, 0, 11) finished
02:01:20 WORKER: registered result for job (4, 0, 11) with dispatcher
02:01:20 DISPATCHER: register_result: lock acquired
02:01:20 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
02:01:20 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 63, 'last_n_outputs': 4, 'lr': 0.028614119590199258, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.04550260329053042}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4158109709079242, 'info': {'music-speech': 0.4158109709079242, 'config': "{'batch_size': 16, 'hidden_dim': 63, 'last_n_outputs': 4, 'lr': 0.028614119590199258, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 52, 'weight_decay': 0.04550260329053042}"}}
exception: None

02:01:20 job_callback for (4, 0, 11) started
02:01:20 DISPATCHER: Trying to submit another job.
02:01:20 job_callback for (4, 0, 11) got condition
02:01:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:01:20 HBMASTER: Trying to run another job!
02:01:20 job_callback for (4, 0, 11) finished
02:01:20 start sampling a new configuration.
02:01:20 best_vector: [2, 0.402413895470696, 0.6564433327478019, 0.9059821761503648, 0.07540204951964624, 0, 0.274226011705739, 0.9925296846814153], 0.009620071961549893, 0.33113198013433054, 0.003185513477662769
02:01:20 done sampling a new configuration.
02:01:20 HBMASTER: schedule new run for iteration 4
02:01:20 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
02:01:20 HBMASTER: submitting job (4, 0, 12) to dispatcher
02:01:20 DISPATCHER: trying to submit job (4, 0, 12)
02:01:20 DISPATCHER: trying to notify the job_runner thread.
02:01:20 HBMASTER: job (4, 0, 12) submitted to dispatcher
02:01:20 DISPATCHER: Trying to submit another job.
02:01:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:01:20 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216
02:01:20 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
02:01:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:01:20 WORKER: start processing job (4, 0, 12)
02:01:20 WORKER: args: ()
02:01:20 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 52, 'last_n_outputs': 33, 'lr': 0.0648581194611869, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.19557389779782858}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-483:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:02:13 WORKER: done with job (4, 0, 12), trying to register it.
02:02:13 WORKER: registered result for job (4, 0, 12) with dispatcher
02:02:13 DISPATCHER: job (4, 0, 12) finished
02:02:13 DISPATCHER: register_result: lock acquired
02:02:13 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
02:02:13 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 52, 'last_n_outputs': 33, 'lr': 0.0648581194611869, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.19557389779782858}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 52, 'last_n_outputs': 33, 'lr': 0.0648581194611869, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.19557389779782858}"}}
exception: None

02:02:13 job_callback for (4, 0, 12) started
02:02:13 DISPATCHER: Trying to submit another job.
02:02:13 job_callback for (4, 0, 12) got condition
02:02:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:02:13 HBMASTER: Trying to run another job!
02:02:13 job_callback for (4, 0, 12) finished
02:02:13 start sampling a new configuration.
02:02:13 best_vector: [2, 0.360982888709779, 0.34128228965945373, 0.7111805376239989, 0.08250775282709202, 0, 0.18900220850378835, 0.5830180656931628], 0.01386781785224148, 3.533095849867903, 0.04899632970047839
02:02:13 done sampling a new configuration.
02:02:13 HBMASTER: schedule new run for iteration 4
02:02:13 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
02:02:13 HBMASTER: submitting job (4, 0, 13) to dispatcher
02:02:13 DISPATCHER: trying to submit job (4, 0, 13)
02:02:13 DISPATCHER: trying to notify the job_runner thread.
02:02:13 HBMASTER: job (4, 0, 13) submitted to dispatcher
02:02:13 DISPATCHER: Trying to submit another job.
02:02:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:02:13 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpul.22021139727314577216
02:02:13 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
02:02:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:02:13 WORKER: start processing job (4, 0, 13)
02:02:13 WORKER: args: ()
02:02:13 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 49, 'last_n_outputs': 18, 'lr': 0.026446065866129725, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.05734875465142935}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:02:17 DISPATCHER: Starting worker discovery
02:02:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:02:17 DISPATCHER: Finished worker discovery
Exception in thread Thread-484:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:03:06 WORKER: done with job (4, 0, 13), trying to register it.
02:03:06 WORKER: registered result for job (4, 0, 13) with dispatcher
02:03:06 DISPATCHER: job (4, 0, 13) finished
02:03:06 DISPATCHER: register_result: lock acquired
02:03:06 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
02:03:06 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 49, 'last_n_outputs': 18, 'lr': 0.026446065866129725, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.05734875465142935}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7643823511064705, 'info': {'music-speech': 0.7643823511064705, 'config': "{'batch_size': 64, 'hidden_dim': 49, 'last_n_outputs': 18, 'lr': 0.026446065866129725, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.05734875465142935}"}}
exception: None

02:03:06 job_callback for (4, 0, 13) started
02:03:06 job_callback for (4, 0, 13) got condition
02:03:06 DISPATCHER: Trying to submit another job.
02:03:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:03:07 HBMASTER: Trying to run another job!
02:03:07 job_callback for (4, 0, 13) finished
02:03:07 start sampling a new configuration.
02:03:07 best_vector: [2, 0.7451927753621868, 0.22577003104310545, 0.4437200396356691, 0.1840391963937248, 0, 0.09532475984986555, 0.8658494705488061], 0.017209704718173433, 0.7605781868375557, 0.013089326010558079
02:03:07 done sampling a new configuration.
02:03:07 HBMASTER: schedule new run for iteration 4
02:03:07 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
02:03:07 HBMASTER: submitting job (4, 0, 14) to dispatcher
02:03:07 DISPATCHER: trying to submit job (4, 0, 14)
02:03:07 DISPATCHER: trying to notify the job_runner thread.
02:03:07 HBMASTER: job (4, 0, 14) submitted to dispatcher
02:03:07 DISPATCHER: Trying to submit another job.
02:03:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:03:07 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpul.22021139727314577216
02:03:07 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
02:03:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:03:07 WORKER: start processing job (4, 0, 14)
02:03:07 WORKER: args: ()
02:03:07 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 80, 'last_n_outputs': 12, 'lr': 0.007716850368667671, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.13381233000562306}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:03:17 DISPATCHER: Starting worker discovery
02:03:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:03:18 DISPATCHER: Finished worker discovery
Exception in thread Thread-485:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:04:02 WORKER: done with job (4, 0, 14), trying to register it.
02:04:02 WORKER: registered result for job (4, 0, 14) with dispatcher
02:04:02 DISPATCHER: job (4, 0, 14) finished
02:04:02 DISPATCHER: register_result: lock acquired
02:04:02 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
02:04:02 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 80, 'last_n_outputs': 12, 'lr': 0.007716850368667671, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.13381233000562306}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8338604213834847, 'info': {'music-speech': 0.8338604213834847, 'config': "{'batch_size': 64, 'hidden_dim': 80, 'last_n_outputs': 12, 'lr': 0.007716850368667671, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.13381233000562306}"}}
exception: None

02:04:02 job_callback for (4, 0, 14) started
02:04:02 DISPATCHER: Trying to submit another job.
02:04:02 job_callback for (4, 0, 14) got condition
02:04:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:04:02 HBMASTER: Trying to run another job!
02:04:02 job_callback for (4, 0, 14) finished
02:04:02 start sampling a new configuration.
02:04:02 done sampling a new configuration.
02:04:03 HBMASTER: schedule new run for iteration 4
02:04:03 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
02:04:03 HBMASTER: submitting job (4, 0, 15) to dispatcher
02:04:03 DISPATCHER: trying to submit job (4, 0, 15)
02:04:03 DISPATCHER: trying to notify the job_runner thread.
02:04:03 HBMASTER: job (4, 0, 15) submitted to dispatcher
02:04:03 DISPATCHER: Trying to submit another job.
02:04:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:04:03 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216
02:04:03 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
02:04:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:04:03 WORKER: start processing job (4, 0, 15)
02:04:03 WORKER: args: ()
02:04:03 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 26, 'last_n_outputs': 50, 'lr': 0.08749883040189921, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.026710729812855032}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:04:18 DISPATCHER: Starting worker discovery
02:04:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:04:18 DISPATCHER: Finished worker discovery
Exception in thread Thread-486:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:04:57 WORKER: done with job (4, 0, 15), trying to register it.
02:04:57 WORKER: registered result for job (4, 0, 15) with dispatcher
02:04:57 DISPATCHER: job (4, 0, 15) finished
02:04:57 DISPATCHER: register_result: lock acquired
02:04:57 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
02:04:57 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 26, 'last_n_outputs': 50, 'lr': 0.08749883040189921, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.026710729812855032}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5900951689467441, 'info': {'music-speech': 0.5900951689467441, 'config': "{'batch_size': 128, 'hidden_dim': 26, 'last_n_outputs': 50, 'lr': 0.08749883040189921, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 62, 'weight_decay': 0.026710729812855032}"}}
exception: None

02:04:57 job_callback for (4, 0, 15) started
02:04:57 DISPATCHER: Trying to submit another job.
02:04:57 job_callback for (4, 0, 15) got condition
02:04:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:04:57 HBMASTER: Trying to run another job!
02:04:57 job_callback for (4, 0, 15) finished
02:04:57 start sampling a new configuration.
02:04:57 done sampling a new configuration.
02:04:57 HBMASTER: schedule new run for iteration 4
02:04:57 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
02:04:57 HBMASTER: submitting job (4, 0, 16) to dispatcher
02:04:57 DISPATCHER: trying to submit job (4, 0, 16)
02:04:57 DISPATCHER: trying to notify the job_runner thread.
02:04:57 HBMASTER: job (4, 0, 16) submitted to dispatcher
02:04:57 DISPATCHER: Trying to submit another job.
02:04:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:04:57 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216
02:04:57 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
02:04:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:04:57 WORKER: start processing job (4, 0, 16)
02:04:57 WORKER: args: ()
02:04:57 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 96, 'last_n_outputs': 33, 'lr': 0.01918801581714145, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.04238725428576945}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-487:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:05:18 DISPATCHER: Starting worker discovery
02:05:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:05:18 DISPATCHER: Finished worker discovery
02:05:49 WORKER: done with job (4, 0, 16), trying to register it.
02:05:49 WORKER: registered result for job (4, 0, 16) with dispatcher
02:05:49 DISPATCHER: job (4, 0, 16) finished
02:05:49 DISPATCHER: register_result: lock acquired
02:05:49 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
02:05:49 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 96, 'last_n_outputs': 33, 'lr': 0.01918801581714145, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.04238725428576945}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.4151203637780504, 'info': {'music-speech': 0.4151203637780504, 'config': "{'batch_size': 16, 'hidden_dim': 96, 'last_n_outputs': 33, 'lr': 0.01918801581714145, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 40, 'weight_decay': 0.04238725428576945}"}}
exception: None

02:05:49 job_callback for (4, 0, 16) started
02:05:49 DISPATCHER: Trying to submit another job.
02:05:49 job_callback for (4, 0, 16) got condition
02:05:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:05:49 HBMASTER: Trying to run another job!
02:05:49 job_callback for (4, 0, 16) finished
02:05:49 start sampling a new configuration.
02:05:50 best_vector: [2, 0.365164405141663, 0.1470258220864688, 0.12180663191647312, 0.325392663239384, 0, 0.06522358872643003, 0.7620643880237903], 0.018767749259103038, 0.29374613437256586, 0.005512953795735104
02:05:50 done sampling a new configuration.
02:05:50 HBMASTER: schedule new run for iteration 4
02:05:50 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
02:05:50 HBMASTER: submitting job (4, 0, 17) to dispatcher
02:05:50 DISPATCHER: trying to submit job (4, 0, 17)
02:05:50 DISPATCHER: trying to notify the job_runner thread.
02:05:50 HBMASTER: job (4, 0, 17) submitted to dispatcher
02:05:50 DISPATCHER: Trying to submit another job.
02:05:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:05:50 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpul.22021139727314577216
02:05:50 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
02:05:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:05:50 WORKER: start processing job (4, 0, 17)
02:05:50 WORKER: args: ()
02:05:50 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 49, 'last_n_outputs': 8, 'lr': 0.0017523193788368924, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.09805474789996628}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-488:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:06:18 DISPATCHER: Starting worker discovery
02:06:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:06:18 DISPATCHER: Finished worker discovery
02:06:42 WORKER: done with job (4, 0, 17), trying to register it.
02:06:42 DISPATCHER: job (4, 0, 17) finished
02:06:42 WORKER: registered result for job (4, 0, 17) with dispatcher
02:06:42 DISPATCHER: register_result: lock acquired
02:06:42 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
02:06:42 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 49, 'last_n_outputs': 8, 'lr': 0.0017523193788368924, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.09805474789996628}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7974144465644876, 'info': {'music-speech': 0.7974144465644876, 'config': "{'batch_size': 64, 'hidden_dim': 49, 'last_n_outputs': 8, 'lr': 0.0017523193788368924, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.09805474789996628}"}}
exception: None

02:06:42 job_callback for (4, 0, 17) started
02:06:42 DISPATCHER: Trying to submit another job.
02:06:42 job_callback for (4, 0, 17) got condition
02:06:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:06:42 HBMASTER: Trying to run another job!
02:06:42 job_callback for (4, 0, 17) finished
02:06:42 start sampling a new configuration.
02:06:42 done sampling a new configuration.
02:06:42 HBMASTER: schedule new run for iteration 4
02:06:42 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
02:06:42 HBMASTER: submitting job (4, 0, 18) to dispatcher
02:06:42 DISPATCHER: trying to submit job (4, 0, 18)
02:06:42 DISPATCHER: trying to notify the job_runner thread.
02:06:42 HBMASTER: job (4, 0, 18) submitted to dispatcher
02:06:42 DISPATCHER: Trying to submit another job.
02:06:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:06:42 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpul.22021139727314577216
02:06:42 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
02:06:42 WORKER: start processing job (4, 0, 18)
02:06:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:06:42 WORKER: args: ()
02:06:42 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 57, 'last_n_outputs': 20, 'lr': 0.03895118000458262, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.010297872664334816}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-489:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:07:18 DISPATCHER: Starting worker discovery
02:07:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:07:18 DISPATCHER: Finished worker discovery
02:07:36 WORKER: done with job (4, 0, 18), trying to register it.
02:07:36 WORKER: registered result for job (4, 0, 18) with dispatcher
02:07:36 DISPATCHER: job (4, 0, 18) finished
02:07:36 DISPATCHER: register_result: lock acquired
02:07:36 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
02:07:36 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 57, 'last_n_outputs': 20, 'lr': 0.03895118000458262, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.010297872664334816}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7176274547974233, 'info': {'music-speech': 0.7176274547974233, 'config': "{'batch_size': 128, 'hidden_dim': 57, 'last_n_outputs': 20, 'lr': 0.03895118000458262, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.010297872664334816}"}}
exception: None

02:07:36 job_callback for (4, 0, 18) started
02:07:36 DISPATCHER: Trying to submit another job.
02:07:36 job_callback for (4, 0, 18) got condition
02:07:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:07:36 HBMASTER: Trying to run another job!
02:07:36 job_callback for (4, 0, 18) finished
02:07:36 start sampling a new configuration.
02:07:36 best_vector: [0, 0.5346227594496409, 0.05132281882399209, 0.43938908211335004, 0.3152912313561459, 0, 0.061948675196111, 0.7158299426218315], 0.019191730528573703, 1.204702482259763, 0.02312032540663321
02:07:36 done sampling a new configuration.
02:07:36 HBMASTER: schedule new run for iteration 4
02:07:36 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
02:07:36 HBMASTER: submitting job (4, 0, 19) to dispatcher
02:07:36 DISPATCHER: trying to submit job (4, 0, 19)
02:07:36 DISPATCHER: trying to notify the job_runner thread.
02:07:36 HBMASTER: job (4, 0, 19) submitted to dispatcher
02:07:36 DISPATCHER: Trying to submit another job.
02:07:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:07:36 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpul.22021139727314577216
02:07:36 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
02:07:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:07:36 WORKER: start processing job (4, 0, 19)
02:07:36 WORKER: args: ()
02:07:36 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 63, 'last_n_outputs': 3, 'lr': 0.007564464067154485, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.08537215164652469}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-490:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:08:18 DISPATCHER: Starting worker discovery
02:08:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:08:18 DISPATCHER: Finished worker discovery
02:08:29 WORKER: done with job (4, 0, 19), trying to register it.
02:08:29 DISPATCHER: job (4, 0, 19) finished
02:08:29 WORKER: registered result for job (4, 0, 19) with dispatcher
02:08:29 DISPATCHER: register_result: lock acquired
02:08:29 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
02:08:29 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 63, 'last_n_outputs': 3, 'lr': 0.007564464067154485, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.08537215164652469}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5922521800398035, 'info': {'music-speech': 0.5922521800398035, 'config': "{'batch_size': 16, 'hidden_dim': 63, 'last_n_outputs': 3, 'lr': 0.007564464067154485, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.08537215164652469}"}}
exception: None

02:08:29 job_callback for (4, 0, 19) started
02:08:29 DISPATCHER: Trying to submit another job.
02:08:29 job_callback for (4, 0, 19) got condition
02:08:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:08:29 HBMASTER: Trying to run another job!
02:08:29 job_callback for (4, 0, 19) finished
02:08:29 start sampling a new configuration.
02:08:29 best_vector: [2, 0.7010620091763899, 0.2982968262186615, 0.28718404738857495, 0.5334337159650461, 1, 0.5573521392139572, 0.6718325006920005], 0.0, inf, 0.005451454248355679
02:08:29 done sampling a new configuration.
02:08:29 HBMASTER: schedule new run for iteration 4
02:08:29 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
02:08:29 HBMASTER: submitting job (4, 0, 20) to dispatcher
02:08:29 DISPATCHER: trying to submit job (4, 0, 20)
02:08:29 DISPATCHER: trying to notify the job_runner thread.
02:08:29 HBMASTER: job (4, 0, 20) submitted to dispatcher
02:08:29 DISPATCHER: Trying to submit another job.
02:08:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:08:29 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216
02:08:29 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
02:08:29 WORKER: start processing job (4, 0, 20)
02:08:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:08:29 WORKER: args: ()
02:08:29 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 76, 'last_n_outputs': 15, 'lr': 0.00375290952666525, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.07482973986497875}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-491:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:09:18 DISPATCHER: Starting worker discovery
02:09:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:09:18 DISPATCHER: Finished worker discovery
02:09:22 WORKER: done with job (4, 0, 20), trying to register it.
02:09:22 WORKER: registered result for job (4, 0, 20) with dispatcher
02:09:22 DISPATCHER: job (4, 0, 20) finished
02:09:22 DISPATCHER: register_result: lock acquired
02:09:22 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
02:09:22 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 76, 'last_n_outputs': 15, 'lr': 0.00375290952666525, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.07482973986497875}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 76, 'last_n_outputs': 15, 'lr': 0.00375290952666525, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.07482973986497875}"}}
exception: None

02:09:22 job_callback for (4, 0, 20) started
02:09:22 DISPATCHER: Trying to submit another job.
02:09:22 job_callback for (4, 0, 20) got condition
02:09:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:09:22 HBMASTER: Trying to run another job!
02:09:22 job_callback for (4, 0, 20) finished
02:09:22 start sampling a new configuration.
02:09:22 best_vector: [0, 0.17132755890492984, 0.8538335181140654, 0.5341598408057338, 0.3538433674530455, 1, 0.0006322531550170263, 0.33023319867844736], 0.0, inf, 0.024629712137446316
02:09:22 done sampling a new configuration.
02:09:22 HBMASTER: schedule new run for iteration 4
02:09:22 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
02:09:22 HBMASTER: submitting job (4, 0, 21) to dispatcher
02:09:22 DISPATCHER: trying to submit job (4, 0, 21)
02:09:22 DISPATCHER: trying to notify the job_runner thread.
02:09:22 HBMASTER: job (4, 0, 21) submitted to dispatcher
02:09:22 DISPATCHER: Trying to submit another job.
02:09:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:09:22 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216
02:09:22 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
02:09:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:09:22 WORKER: start processing job (4, 0, 21)
02:09:22 WORKER: args: ()
02:09:22 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 33, 'last_n_outputs': 43, 'lr': 0.011703605695521792, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.026893250492746625}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-492:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:10:15 WORKER: done with job (4, 0, 21), trying to register it.
02:10:15 WORKER: registered result for job (4, 0, 21) with dispatcher
02:10:15 DISPATCHER: job (4, 0, 21) finished
02:10:15 DISPATCHER: register_result: lock acquired
02:10:15 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
02:10:15 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 33, 'last_n_outputs': 43, 'lr': 0.011703605695521792, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.026893250492746625}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.16937468735035496, 'info': {'music-speech': 0.16937468735035496, 'config': "{'batch_size': 16, 'hidden_dim': 33, 'last_n_outputs': 43, 'lr': 0.011703605695521792, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 10, 'weight_decay': 0.026893250492746625}"}}
exception: None

02:10:15 job_callback for (4, 0, 21) started
02:10:15 job_callback for (4, 0, 21) got condition
02:10:15 DISPATCHER: Trying to submit another job.
02:10:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:10:15 HBMASTER: Trying to run another job!
02:10:15 job_callback for (4, 0, 21) finished
02:10:15 start sampling a new configuration.
02:10:15 done sampling a new configuration.
02:10:15 HBMASTER: schedule new run for iteration 4
02:10:15 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
02:10:15 HBMASTER: submitting job (4, 0, 22) to dispatcher
02:10:15 DISPATCHER: trying to submit job (4, 0, 22)
02:10:15 DISPATCHER: trying to notify the job_runner thread.
02:10:15 HBMASTER: job (4, 0, 22) submitted to dispatcher
02:10:15 DISPATCHER: Trying to submit another job.
02:10:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:10:15 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpul.22021139727314577216
02:10:15 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
02:10:15 WORKER: start processing job (4, 0, 22)
02:10:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:10:15 WORKER: args: ()
02:10:15 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 97, 'last_n_outputs': 44, 'lr': 0.09492693854926137, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.13713233674974387}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:10:18 DISPATCHER: Starting worker discovery
02:10:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:10:18 DISPATCHER: Finished worker discovery
Exception in thread Thread-493:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:11:08 WORKER: done with job (4, 0, 22), trying to register it.
02:11:08 WORKER: registered result for job (4, 0, 22) with dispatcher
02:11:08 DISPATCHER: job (4, 0, 22) finished
02:11:08 DISPATCHER: register_result: lock acquired
02:11:08 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
02:11:08 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 97, 'last_n_outputs': 44, 'lr': 0.09492693854926137, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.13713233674974387}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 97, 'last_n_outputs': 44, 'lr': 0.09492693854926137, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.13713233674974387}"}}
exception: None

02:11:08 job_callback for (4, 0, 22) started
02:11:08 DISPATCHER: Trying to submit another job.
02:11:08 job_callback for (4, 0, 22) got condition
02:11:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:11:08 HBMASTER: Trying to run another job!
02:11:08 job_callback for (4, 0, 22) finished
02:11:08 start sampling a new configuration.
02:11:08 best_vector: [0, 0.767522627536622, 0.23974109171298685, 0.37805757042973137, 0.3036227084124947, 0, 0.4266503925902816, 0.9284388043015779], 0.005649117156704919, 1.0361940558060934, 0.005853581618329857
02:11:08 done sampling a new configuration.
02:11:08 HBMASTER: schedule new run for iteration 4
02:11:08 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
02:11:08 HBMASTER: submitting job (4, 0, 23) to dispatcher
02:11:08 DISPATCHER: trying to submit job (4, 0, 23)
02:11:08 DISPATCHER: trying to notify the job_runner thread.
02:11:08 HBMASTER: job (4, 0, 23) submitted to dispatcher
02:11:08 DISPATCHER: Trying to submit another job.
02:11:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:11:08 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216
02:11:08 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
02:11:08 WORKER: start processing job (4, 0, 23)
02:11:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:11:08 WORKER: args: ()
02:11:08 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 82, 'last_n_outputs': 12, 'lr': 0.005703154552000854, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.16140862338436368}, 'budget': 44.44444444444444, 'working_directory': '.'}
02:11:18 DISPATCHER: Starting worker discovery
02:11:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:11:18 DISPATCHER: Finished worker discovery
Exception in thread Thread-494:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:12:01 WORKER: done with job (4, 0, 23), trying to register it.
02:12:01 DISPATCHER: job (4, 0, 23) finished
02:12:01 WORKER: registered result for job (4, 0, 23) with dispatcher
02:12:01 DISPATCHER: register_result: lock acquired
02:12:01 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
02:12:01 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 82, 'last_n_outputs': 12, 'lr': 0.005703154552000854, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.16140862338436368}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8107336695459962, 'info': {'music-speech': 0.8107336695459962, 'config': "{'batch_size': 16, 'hidden_dim': 82, 'last_n_outputs': 12, 'lr': 0.005703154552000854, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.16140862338436368}"}}
exception: None

02:12:01 job_callback for (4, 0, 23) started
02:12:01 DISPATCHER: Trying to submit another job.
02:12:01 job_callback for (4, 0, 23) got condition
02:12:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:12:01 HBMASTER: Trying to run another job!
02:12:01 job_callback for (4, 0, 23) finished
02:12:01 start sampling a new configuration.
02:12:01 best_vector: [2, 0.307953383916474, 0.28648170000329354, 0.7997976744076091, 0.08193817706437735, 0, 0.22451086395498804, 0.0015697456474659255], 0.020460416559586535, 0.1601843928001995, 0.003277439403036516
02:12:01 done sampling a new configuration.
02:12:01 HBMASTER: schedule new run for iteration 4
02:12:01 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
02:12:01 HBMASTER: submitting job (4, 0, 24) to dispatcher
02:12:01 DISPATCHER: trying to submit job (4, 0, 24)
02:12:01 DISPATCHER: trying to notify the job_runner thread.
02:12:01 HBMASTER: job (4, 0, 24) submitted to dispatcher
02:12:01 DISPATCHER: Trying to submit another job.
02:12:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:12:01 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpul.22021139727314577216
02:12:01 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
02:12:01 WORKER: start processing job (4, 0, 24)
02:12:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:12:01 WORKER: args: ()
02:12:01 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 44, 'last_n_outputs': 15, 'lr': 0.039773640942520734, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.01004713611980055}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-495:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:12:18 DISPATCHER: Starting worker discovery
02:12:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:12:18 DISPATCHER: Finished worker discovery
02:12:54 WORKER: done with job (4, 0, 24), trying to register it.
02:12:54 WORKER: registered result for job (4, 0, 24) with dispatcher
02:12:54 DISPATCHER: job (4, 0, 24) finished
02:12:54 DISPATCHER: register_result: lock acquired
02:12:54 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
02:12:54 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 44, 'last_n_outputs': 15, 'lr': 0.039773640942520734, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.01004713611980055}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6158112067988141, 'info': {'music-speech': 0.6158112067988141, 'config': "{'batch_size': 64, 'hidden_dim': 44, 'last_n_outputs': 15, 'lr': 0.039773640942520734, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 30, 'weight_decay': 0.01004713611980055}"}}
exception: None

02:12:54 job_callback for (4, 0, 24) started
02:12:54 DISPATCHER: Trying to submit another job.
02:12:54 job_callback for (4, 0, 24) got condition
02:12:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:12:54 HBMASTER: Trying to run another job!
02:12:54 job_callback for (4, 0, 24) finished
02:12:54 start sampling a new configuration.
02:12:54 best_vector: [2, 0.6945875254602759, 0.31255757432439085, 0.755270665767998, 0.1381063511799592, 0, 0.45472022558432434, 0.9351515667588154], 0.010243770448232688, 0.3692698403164742, 0.003782715477657502
02:12:54 done sampling a new configuration.
02:12:54 HBMASTER: schedule new run for iteration 4
02:12:54 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
02:12:54 HBMASTER: submitting job (4, 0, 25) to dispatcher
02:12:54 DISPATCHER: trying to submit job (4, 0, 25)
02:12:54 DISPATCHER: trying to notify the job_runner thread.
02:12:54 HBMASTER: job (4, 0, 25) submitted to dispatcher
02:12:54 DISPATCHER: Trying to submit another job.
02:12:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:12:54 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216
02:12:54 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
02:12:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:12:54 WORKER: start processing job (4, 0, 25)
02:12:54 WORKER: args: ()
02:12:54 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 76, 'last_n_outputs': 16, 'lr': 0.03239972555851356, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.16468734905777113}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-496:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:13:18 DISPATCHER: Starting worker discovery
02:13:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:13:18 DISPATCHER: Finished worker discovery
02:13:48 WORKER: done with job (4, 0, 25), trying to register it.
02:13:48 WORKER: registered result for job (4, 0, 25) with dispatcher
02:13:48 DISPATCHER: job (4, 0, 25) finished
02:13:48 DISPATCHER: register_result: lock acquired
02:13:48 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
02:13:48 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 76, 'last_n_outputs': 16, 'lr': 0.03239972555851356, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.16468734905777113}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5895369088945472, 'info': {'music-speech': 0.5895369088945472, 'config': "{'batch_size': 64, 'hidden_dim': 76, 'last_n_outputs': 16, 'lr': 0.03239972555851356, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 51, 'weight_decay': 0.16468734905777113}"}}
exception: None

02:13:48 job_callback for (4, 0, 25) started
02:13:48 DISPATCHER: Trying to submit another job.
02:13:48 job_callback for (4, 0, 25) got condition
02:13:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:13:48 HBMASTER: Trying to run another job!
02:13:48 job_callback for (4, 0, 25) finished
02:13:48 start sampling a new configuration.
02:13:48 best_vector: [1, 0.6162848488092456, 0.4179989633946755, 0.49434424284522993, 0.30570066640503163, 0, 0.016959267658162774, 0.7968605766473459], 0.016385854101762874, 2.028381070637894, 0.033236756286250106
02:13:48 done sampling a new configuration.
02:13:48 HBMASTER: schedule new run for iteration 4
02:13:48 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
02:13:48 HBMASTER: submitting job (4, 0, 26) to dispatcher
02:13:48 DISPATCHER: trying to submit job (4, 0, 26)
02:13:48 DISPATCHER: trying to notify the job_runner thread.
02:13:48 HBMASTER: job (4, 0, 26) submitted to dispatcher
02:13:48 DISPATCHER: Trying to submit another job.
02:13:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:13:48 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpul.22021139727314577216
02:13:48 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
02:13:48 WORKER: start processing job (4, 0, 26)
02:13:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:13:48 WORKER: args: ()
02:13:48 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 69, 'last_n_outputs': 21, 'lr': 0.00974290539907145, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 11, 'weight_decay': 0.10882771549415148}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-497:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:14:18 DISPATCHER: Starting worker discovery
02:14:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:14:18 DISPATCHER: Finished worker discovery
02:14:41 WORKER: done with job (4, 0, 26), trying to register it.
02:14:41 WORKER: registered result for job (4, 0, 26) with dispatcher
02:14:41 DISPATCHER: job (4, 0, 26) finished
02:14:41 DISPATCHER: register_result: lock acquired
02:14:41 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
02:14:41 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 69, 'last_n_outputs': 21, 'lr': 0.00974290539907145, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 11, 'weight_decay': 0.10882771549415148}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6833173229272536, 'info': {'music-speech': 0.6833173229272536, 'config': "{'batch_size': 32, 'hidden_dim': 69, 'last_n_outputs': 21, 'lr': 0.00974290539907145, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 11, 'weight_decay': 0.10882771549415148}"}}
exception: None

02:14:41 job_callback for (4, 0, 26) started
02:14:41 DISPATCHER: Trying to submit another job.
02:14:41 job_callback for (4, 0, 26) got condition
02:14:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:14:41 HBMASTER: Trying to run another job!
02:14:41 job_callback for (4, 0, 26) finished
02:14:41 ITERATION: Advancing config (4, 0, 0) to next budget 133.333333
02:14:41 ITERATION: Advancing config (4, 0, 7) to next budget 133.333333
02:14:41 ITERATION: Advancing config (4, 0, 9) to next budget 133.333333
02:14:41 ITERATION: Advancing config (4, 0, 13) to next budget 133.333333
02:14:41 ITERATION: Advancing config (4, 0, 14) to next budget 133.333333
02:14:41 ITERATION: Advancing config (4, 0, 17) to next budget 133.333333
02:14:41 ITERATION: Advancing config (4, 0, 18) to next budget 133.333333
02:14:41 ITERATION: Advancing config (4, 0, 23) to next budget 133.333333
02:14:41 ITERATION: Advancing config (4, 0, 26) to next budget 133.333333
02:14:41 HBMASTER: schedule new run for iteration 4
02:14:41 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
02:14:41 HBMASTER: submitting job (4, 0, 0) to dispatcher
02:14:41 DISPATCHER: trying to submit job (4, 0, 0)
02:14:41 DISPATCHER: trying to notify the job_runner thread.
02:14:41 HBMASTER: job (4, 0, 0) submitted to dispatcher
02:14:41 DISPATCHER: Trying to submit another job.
02:14:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:14:41 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
02:14:41 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
02:14:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:14:41 WORKER: start processing job (4, 0, 0)
02:14:41 WORKER: args: ()
02:14:41 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 69, 'last_n_outputs': 12, 'lr': 0.04049147565105621, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.06083176740228754}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-498:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:15:18 DISPATCHER: Starting worker discovery
02:15:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:15:18 DISPATCHER: Finished worker discovery
02:16:18 DISPATCHER: Starting worker discovery
02:16:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:16:18 DISPATCHER: Finished worker discovery
02:17:03 WORKER: done with job (4, 0, 0), trying to register it.
02:17:03 WORKER: registered result for job (4, 0, 0) with dispatcher
02:17:03 DISPATCHER: job (4, 0, 0) finished
02:17:03 DISPATCHER: register_result: lock acquired
02:17:03 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
02:17:03 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 69, 'last_n_outputs': 12, 'lr': 0.04049147565105621, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.06083176740228754}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.548251754796477, 'info': {'music-speech': 0.548251754796477, 'config': "{'batch_size': 128, 'hidden_dim': 69, 'last_n_outputs': 12, 'lr': 0.04049147565105621, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 36, 'weight_decay': 0.06083176740228754}"}}
exception: None

02:17:03 job_callback for (4, 0, 0) started
02:17:03 DISPATCHER: Trying to submit another job.
02:17:03 job_callback for (4, 0, 0) got condition
02:17:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:17:03 done building a new model for budget 133.333333 based on 9/16 split
Best loss for this budget:-0.928043





02:17:03 HBMASTER: Trying to run another job!
02:17:03 job_callback for (4, 0, 0) finished
02:17:03 HBMASTER: schedule new run for iteration 4
02:17:03 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
02:17:03 HBMASTER: submitting job (4, 0, 7) to dispatcher
02:17:03 DISPATCHER: trying to submit job (4, 0, 7)
02:17:03 DISPATCHER: trying to notify the job_runner thread.
02:17:03 HBMASTER: job (4, 0, 7) submitted to dispatcher
02:17:03 DISPATCHER: Trying to submit another job.
02:17:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:17:03 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
02:17:03 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
02:17:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:17:03 WORKER: start processing job (4, 0, 7)
02:17:03 WORKER: args: ()
02:17:03 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 43, 'lr': 0.04501075769448905, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.12305913093668566}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:17:18 DISPATCHER: Starting worker discovery
02:17:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:17:18 DISPATCHER: Finished worker discovery
Exception in thread Thread-499:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:18:18 DISPATCHER: Starting worker discovery
02:18:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:18:18 DISPATCHER: Finished worker discovery
02:19:18 DISPATCHER: Starting worker discovery
02:19:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:19:18 DISPATCHER: Finished worker discovery
02:19:25 WORKER: done with job (4, 0, 7), trying to register it.
02:19:25 WORKER: registered result for job (4, 0, 7) with dispatcher
02:19:25 DISPATCHER: job (4, 0, 7) finished
02:19:25 DISPATCHER: register_result: lock acquired
02:19:25 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
02:19:25 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 43, 'lr': 0.04501075769448905, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.12305913093668566}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5376575176830313, 'info': {'music-speech': 0.5376575176830313, 'config': "{'batch_size': 128, 'hidden_dim': 93, 'last_n_outputs': 43, 'lr': 0.04501075769448905, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.12305913093668566}"}}
exception: None

02:19:25 job_callback for (4, 0, 7) started
02:19:25 DISPATCHER: Trying to submit another job.
02:19:25 job_callback for (4, 0, 7) got condition
02:19:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:19:25 done building a new model for budget 133.333333 based on 9/17 split
Best loss for this budget:-0.928043





02:19:25 HBMASTER: Trying to run another job!
02:19:25 job_callback for (4, 0, 7) finished
02:19:25 HBMASTER: schedule new run for iteration 4
02:19:25 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
02:19:25 HBMASTER: submitting job (4, 0, 9) to dispatcher
02:19:25 DISPATCHER: trying to submit job (4, 0, 9)
02:19:25 DISPATCHER: trying to notify the job_runner thread.
02:19:25 HBMASTER: job (4, 0, 9) submitted to dispatcher
02:19:25 DISPATCHER: Trying to submit another job.
02:19:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:19:25 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpul.22021139727314577216
02:19:25 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
02:19:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:19:25 WORKER: start processing job (4, 0, 9)
02:19:25 WORKER: args: ()
02:19:25 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 26, 'last_n_outputs': 39, 'lr': 0.013448183827439593, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.041806704849105675}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-500:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:20:18 DISPATCHER: Starting worker discovery
02:20:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:20:18 DISPATCHER: Finished worker discovery
02:21:18 DISPATCHER: Starting worker discovery
02:21:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:21:18 DISPATCHER: Finished worker discovery
02:21:47 WORKER: done with job (4, 0, 9), trying to register it.
02:21:47 WORKER: registered result for job (4, 0, 9) with dispatcher
02:21:47 DISPATCHER: job (4, 0, 9) finished
02:21:47 DISPATCHER: register_result: lock acquired
02:21:47 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
02:21:47 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 26, 'last_n_outputs': 39, 'lr': 0.013448183827439593, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.041806704849105675}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8581507272321434, 'info': {'music-speech': 0.8581507272321434, 'config': "{'batch_size': 16, 'hidden_dim': 26, 'last_n_outputs': 39, 'lr': 0.013448183827439593, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.041806704849105675}"}}
exception: None

02:21:47 job_callback for (4, 0, 9) started
02:21:47 DISPATCHER: Trying to submit another job.
02:21:47 job_callback for (4, 0, 9) got condition
02:21:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:21:47 done building a new model for budget 133.333333 based on 9/17 split
Best loss for this budget:-0.928043





02:21:47 HBMASTER: Trying to run another job!
02:21:47 job_callback for (4, 0, 9) finished
02:21:47 HBMASTER: schedule new run for iteration 4
02:21:47 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
02:21:47 HBMASTER: submitting job (4, 0, 13) to dispatcher
02:21:47 DISPATCHER: trying to submit job (4, 0, 13)
02:21:47 DISPATCHER: trying to notify the job_runner thread.
02:21:47 HBMASTER: job (4, 0, 13) submitted to dispatcher
02:21:47 DISPATCHER: Trying to submit another job.
02:21:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:21:47 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpul.22021139727314577216
02:21:47 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
02:21:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:21:47 WORKER: start processing job (4, 0, 13)
02:21:47 WORKER: args: ()
02:21:47 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 49, 'last_n_outputs': 18, 'lr': 0.026446065866129725, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.05734875465142935}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-501:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:22:18 DISPATCHER: Starting worker discovery
02:22:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:22:18 DISPATCHER: Finished worker discovery
02:23:18 DISPATCHER: Starting worker discovery
02:23:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:23:18 DISPATCHER: Finished worker discovery
02:24:09 WORKER: done with job (4, 0, 13), trying to register it.
02:24:09 WORKER: registered result for job (4, 0, 13) with dispatcher
02:24:09 DISPATCHER: job (4, 0, 13) finished
02:24:09 DISPATCHER: register_result: lock acquired
02:24:09 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
02:24:09 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 49, 'last_n_outputs': 18, 'lr': 0.026446065866129725, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.05734875465142935}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.589798223014031, 'info': {'music-speech': 0.589798223014031, 'config': "{'batch_size': 64, 'hidden_dim': 49, 'last_n_outputs': 18, 'lr': 0.026446065866129725, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 27, 'weight_decay': 0.05734875465142935}"}}
exception: None

02:24:09 job_callback for (4, 0, 13) started
02:24:09 DISPATCHER: Trying to submit another job.
02:24:09 job_callback for (4, 0, 13) got condition
02:24:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:24:09 done building a new model for budget 133.333333 based on 9/18 split
Best loss for this budget:-0.928043





02:24:09 HBMASTER: Trying to run another job!
02:24:09 job_callback for (4, 0, 13) finished
02:24:09 HBMASTER: schedule new run for iteration 4
02:24:09 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
02:24:09 HBMASTER: submitting job (4, 0, 14) to dispatcher
02:24:09 DISPATCHER: trying to submit job (4, 0, 14)
02:24:09 DISPATCHER: trying to notify the job_runner thread.
02:24:09 HBMASTER: job (4, 0, 14) submitted to dispatcher
02:24:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:24:09 DISPATCHER: Trying to submit another job.
02:24:09 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpul.22021139727314577216
02:24:09 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
02:24:09 WORKER: start processing job (4, 0, 14)
02:24:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:24:09 WORKER: args: ()
02:24:09 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 80, 'last_n_outputs': 12, 'lr': 0.007716850368667671, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.13381233000562306}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:24:18 DISPATCHER: Starting worker discovery
02:24:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:24:18 DISPATCHER: Finished worker discovery
Exception in thread Thread-502:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:25:18 DISPATCHER: Starting worker discovery
02:25:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:25:18 DISPATCHER: Finished worker discovery
02:26:18 DISPATCHER: Starting worker discovery
02:26:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:26:18 DISPATCHER: Finished worker discovery
02:26:31 WORKER: done with job (4, 0, 14), trying to register it.
02:26:31 WORKER: registered result for job (4, 0, 14) with dispatcher
02:26:31 DISPATCHER: job (4, 0, 14) finished
02:26:31 DISPATCHER: register_result: lock acquired
02:26:31 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
02:26:31 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 80, 'last_n_outputs': 12, 'lr': 0.007716850368667671, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.13381233000562306}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7738914228342493, 'info': {'music-speech': 0.7738914228342493, 'config': "{'batch_size': 64, 'hidden_dim': 80, 'last_n_outputs': 12, 'lr': 0.007716850368667671, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.13381233000562306}"}}
exception: None

02:26:31 job_callback for (4, 0, 14) started
02:26:31 DISPATCHER: Trying to submit another job.
02:26:31 job_callback for (4, 0, 14) got condition
02:26:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:26:31 done building a new model for budget 133.333333 based on 9/19 split
Best loss for this budget:-0.928043





02:26:31 HBMASTER: Trying to run another job!
02:26:31 job_callback for (4, 0, 14) finished
02:26:31 HBMASTER: schedule new run for iteration 4
02:26:31 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
02:26:31 HBMASTER: submitting job (4, 0, 17) to dispatcher
02:26:31 DISPATCHER: trying to submit job (4, 0, 17)
02:26:31 DISPATCHER: trying to notify the job_runner thread.
02:26:31 HBMASTER: job (4, 0, 17) submitted to dispatcher
02:26:31 DISPATCHER: Trying to submit another job.
02:26:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:26:31 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpul.22021139727314577216
02:26:31 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
02:26:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:26:31 WORKER: start processing job (4, 0, 17)
02:26:31 WORKER: args: ()
02:26:31 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 49, 'last_n_outputs': 8, 'lr': 0.0017523193788368924, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.09805474789996628}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-503:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:27:18 DISPATCHER: Starting worker discovery
02:27:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:27:18 DISPATCHER: Finished worker discovery
02:28:18 DISPATCHER: Starting worker discovery
02:28:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:28:18 DISPATCHER: Finished worker discovery
02:28:53 WORKER: done with job (4, 0, 17), trying to register it.
02:28:53 WORKER: registered result for job (4, 0, 17) with dispatcher
02:28:53 DISPATCHER: job (4, 0, 17) finished
02:28:53 DISPATCHER: register_result: lock acquired
02:28:53 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
02:28:53 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 49, 'last_n_outputs': 8, 'lr': 0.0017523193788368924, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.09805474789996628}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4651489995227631, 'info': {'music-speech': 0.4651489995227631, 'config': "{'batch_size': 64, 'hidden_dim': 49, 'last_n_outputs': 8, 'lr': 0.0017523193788368924, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 15, 'weight_decay': 0.09805474789996628}"}}
exception: None

02:28:53 job_callback for (4, 0, 17) started
02:28:53 DISPATCHER: Trying to submit another job.
02:28:53 job_callback for (4, 0, 17) got condition
02:28:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:28:53 done building a new model for budget 133.333333 based on 9/20 split
Best loss for this budget:-0.928043





02:28:53 HBMASTER: Trying to run another job!
02:28:53 job_callback for (4, 0, 17) finished
02:28:53 HBMASTER: schedule new run for iteration 4
02:28:53 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
02:28:53 HBMASTER: submitting job (4, 0, 18) to dispatcher
02:28:53 DISPATCHER: trying to submit job (4, 0, 18)
02:28:53 DISPATCHER: trying to notify the job_runner thread.
02:28:53 HBMASTER: job (4, 0, 18) submitted to dispatcher
02:28:53 DISPATCHER: Trying to submit another job.
02:28:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:28:53 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpul.22021139727314577216
02:28:53 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
02:28:53 WORKER: start processing job (4, 0, 18)
02:28:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:28:53 WORKER: args: ()
02:28:53 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 57, 'last_n_outputs': 20, 'lr': 0.03895118000458262, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.010297872664334816}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-504:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:29:18 DISPATCHER: Starting worker discovery
02:29:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:29:18 DISPATCHER: Finished worker discovery
02:30:18 DISPATCHER: Starting worker discovery
02:30:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:30:18 DISPATCHER: Finished worker discovery
02:31:15 WORKER: done with job (4, 0, 18), trying to register it.
02:31:15 WORKER: registered result for job (4, 0, 18) with dispatcher
02:31:15 DISPATCHER: job (4, 0, 18) finished
02:31:15 DISPATCHER: register_result: lock acquired
02:31:15 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
02:31:15 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 57, 'last_n_outputs': 20, 'lr': 0.03895118000458262, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.010297872664334816}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 57, 'last_n_outputs': 20, 'lr': 0.03895118000458262, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 41, 'weight_decay': 0.010297872664334816}"}}
exception: None

02:31:15 job_callback for (4, 0, 18) started
02:31:15 DISPATCHER: Trying to submit another job.
02:31:15 job_callback for (4, 0, 18) got condition
02:31:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:31:15 done building a new model for budget 133.333333 based on 9/21 split
Best loss for this budget:-0.928043





02:31:15 HBMASTER: Trying to run another job!
02:31:15 job_callback for (4, 0, 18) finished
02:31:15 HBMASTER: schedule new run for iteration 4
02:31:15 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
02:31:15 HBMASTER: submitting job (4, 0, 23) to dispatcher
02:31:15 DISPATCHER: trying to submit job (4, 0, 23)
02:31:15 DISPATCHER: trying to notify the job_runner thread.
02:31:15 HBMASTER: job (4, 0, 23) submitted to dispatcher
02:31:15 DISPATCHER: Trying to submit another job.
02:31:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:31:15 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216
02:31:15 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
02:31:15 WORKER: start processing job (4, 0, 23)
02:31:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:31:15 WORKER: args: ()
02:31:15 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 82, 'last_n_outputs': 12, 'lr': 0.005703154552000854, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.16140862338436368}, 'budget': 133.33333333333331, 'working_directory': '.'}
02:31:18 DISPATCHER: Starting worker discovery
02:31:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:31:18 DISPATCHER: Finished worker discovery
Exception in thread Thread-505:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:32:18 DISPATCHER: Starting worker discovery
02:32:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:32:18 DISPATCHER: Finished worker discovery
02:33:18 DISPATCHER: Starting worker discovery
02:33:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:33:18 DISPATCHER: Finished worker discovery
02:33:37 WORKER: done with job (4, 0, 23), trying to register it.
02:33:37 WORKER: registered result for job (4, 0, 23) with dispatcher
02:33:37 DISPATCHER: job (4, 0, 23) finished
02:33:37 DISPATCHER: register_result: lock acquired
02:33:37 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
02:33:37 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 82, 'last_n_outputs': 12, 'lr': 0.005703154552000854, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.16140862338436368}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7686002873885268, 'info': {'music-speech': 0.7686002873885268, 'config': "{'batch_size': 16, 'hidden_dim': 82, 'last_n_outputs': 12, 'lr': 0.005703154552000854, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.16140862338436368}"}}
exception: None

02:33:37 job_callback for (4, 0, 23) started
02:33:37 DISPATCHER: Trying to submit another job.
02:33:37 job_callback for (4, 0, 23) got condition
02:33:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:33:37 done building a new model for budget 133.333333 based on 9/22 split
Best loss for this budget:-0.928043





02:33:37 HBMASTER: Trying to run another job!
02:33:37 job_callback for (4, 0, 23) finished
02:33:37 HBMASTER: schedule new run for iteration 4
02:33:37 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
02:33:37 HBMASTER: submitting job (4, 0, 26) to dispatcher
02:33:37 DISPATCHER: trying to submit job (4, 0, 26)
02:33:37 DISPATCHER: trying to notify the job_runner thread.
02:33:37 HBMASTER: job (4, 0, 26) submitted to dispatcher
02:33:37 DISPATCHER: Trying to submit another job.
02:33:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:33:37 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpul.22021139727314577216
02:33:37 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
02:33:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:33:37 WORKER: start processing job (4, 0, 26)
02:33:37 WORKER: args: ()
02:33:37 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 69, 'last_n_outputs': 21, 'lr': 0.00974290539907145, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 11, 'weight_decay': 0.10882771549415148}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-506:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:34:18 DISPATCHER: Starting worker discovery
02:34:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:34:18 DISPATCHER: Finished worker discovery
02:35:18 DISPATCHER: Starting worker discovery
02:35:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:35:18 DISPATCHER: Finished worker discovery
02:35:59 WORKER: done with job (4, 0, 26), trying to register it.
02:35:59 WORKER: registered result for job (4, 0, 26) with dispatcher
02:35:59 DISPATCHER: job (4, 0, 26) finished
02:35:59 DISPATCHER: register_result: lock acquired
02:35:59 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
02:35:59 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 69, 'last_n_outputs': 21, 'lr': 0.00974290539907145, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 11, 'weight_decay': 0.10882771549415148}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5925995374331929, 'info': {'music-speech': 0.5925995374331929, 'config': "{'batch_size': 32, 'hidden_dim': 69, 'last_n_outputs': 21, 'lr': 0.00974290539907145, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 11, 'weight_decay': 0.10882771549415148}"}}
exception: None

02:35:59 job_callback for (4, 0, 26) started
02:35:59 DISPATCHER: Trying to submit another job.
02:35:59 job_callback for (4, 0, 26) got condition
02:35:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:35:59 done building a new model for budget 133.333333 based on 9/22 split
Best loss for this budget:-0.928043





02:35:59 HBMASTER: Trying to run another job!
02:35:59 job_callback for (4, 0, 26) finished
02:35:59 ITERATION: Advancing config (4, 0, 9) to next budget 400.000000
02:35:59 ITERATION: Advancing config (4, 0, 14) to next budget 400.000000
02:35:59 ITERATION: Advancing config (4, 0, 23) to next budget 400.000000
02:35:59 HBMASTER: schedule new run for iteration 4
02:35:59 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
02:35:59 HBMASTER: submitting job (4, 0, 9) to dispatcher
02:35:59 DISPATCHER: trying to submit job (4, 0, 9)
02:35:59 DISPATCHER: trying to notify the job_runner thread.
02:35:59 HBMASTER: job (4, 0, 9) submitted to dispatcher
02:35:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:35:59 DISPATCHER: Trying to submit another job.
02:35:59 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpul.22021139727314577216
02:35:59 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
02:35:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:35:59 WORKER: start processing job (4, 0, 9)
02:35:59 WORKER: args: ()
02:35:59 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 26, 'last_n_outputs': 39, 'lr': 0.013448183827439593, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.041806704849105675}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-507:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:36:18 DISPATCHER: Starting worker discovery
02:36:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:36:18 DISPATCHER: Finished worker discovery
02:37:18 DISPATCHER: Starting worker discovery
02:37:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:37:18 DISPATCHER: Finished worker discovery
02:38:18 DISPATCHER: Starting worker discovery
02:38:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:38:18 DISPATCHER: Finished worker discovery
02:39:18 DISPATCHER: Starting worker discovery
02:39:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:39:18 DISPATCHER: Finished worker discovery
02:40:18 DISPATCHER: Starting worker discovery
02:40:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:40:18 DISPATCHER: Finished worker discovery
02:41:18 DISPATCHER: Starting worker discovery
02:41:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:41:18 DISPATCHER: Finished worker discovery
02:42:18 DISPATCHER: Starting worker discovery
02:42:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:42:18 DISPATCHER: Finished worker discovery
02:42:48 WORKER: done with job (4, 0, 9), trying to register it.
02:42:48 WORKER: registered result for job (4, 0, 9) with dispatcher
02:42:48 DISPATCHER: job (4, 0, 9) finished
02:42:48 DISPATCHER: register_result: lock acquired
02:42:48 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
02:42:48 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 26, 'last_n_outputs': 39, 'lr': 0.013448183827439593, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.041806704849105675}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5412892220546369, 'info': {'music-speech': 0.5412892220546369, 'config': "{'batch_size': 16, 'hidden_dim': 26, 'last_n_outputs': 39, 'lr': 0.013448183827439593, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 78, 'weight_decay': 0.041806704849105675}"}}
exception: None

02:42:48 job_callback for (4, 0, 9) started
02:42:48 DISPATCHER: Trying to submit another job.
02:42:48 job_callback for (4, 0, 9) got condition
02:42:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:42:49 HBMASTER: Trying to run another job!
02:42:49 job_callback for (4, 0, 9) finished
02:42:49 HBMASTER: schedule new run for iteration 4
02:42:49 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
02:42:49 HBMASTER: submitting job (4, 0, 14) to dispatcher
02:42:49 DISPATCHER: trying to submit job (4, 0, 14)
02:42:49 DISPATCHER: trying to notify the job_runner thread.
02:42:49 HBMASTER: job (4, 0, 14) submitted to dispatcher
02:42:49 DISPATCHER: Trying to submit another job.
02:42:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:42:49 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpul.22021139727314577216
02:42:49 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
02:42:49 WORKER: start processing job (4, 0, 14)
02:42:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:42:49 WORKER: args: ()
02:42:49 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 80, 'last_n_outputs': 12, 'lr': 0.007716850368667671, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.13381233000562306}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-508:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:43:18 DISPATCHER: Starting worker discovery
02:43:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:43:18 DISPATCHER: Finished worker discovery
02:44:18 DISPATCHER: Starting worker discovery
02:44:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:44:18 DISPATCHER: Finished worker discovery
02:45:18 DISPATCHER: Starting worker discovery
02:45:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:45:18 DISPATCHER: Finished worker discovery
02:46:18 DISPATCHER: Starting worker discovery
02:46:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:46:18 DISPATCHER: Finished worker discovery
02:47:18 DISPATCHER: Starting worker discovery
02:47:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:47:18 DISPATCHER: Finished worker discovery
02:48:18 DISPATCHER: Starting worker discovery
02:48:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:48:18 DISPATCHER: Finished worker discovery
02:49:18 DISPATCHER: Starting worker discovery
02:49:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:49:18 DISPATCHER: Finished worker discovery
02:49:38 WORKER: done with job (4, 0, 14), trying to register it.
02:49:38 DISPATCHER: job (4, 0, 14) finished
02:49:38 WORKER: registered result for job (4, 0, 14) with dispatcher
02:49:38 DISPATCHER: register_result: lock acquired
02:49:38 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
02:49:38 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 80, 'last_n_outputs': 12, 'lr': 0.007716850368667671, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.13381233000562306}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5674430245900279, 'info': {'music-speech': 0.5674430245900279, 'config': "{'batch_size': 64, 'hidden_dim': 80, 'last_n_outputs': 12, 'lr': 0.007716850368667671, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.13381233000562306}"}}
exception: None

02:49:38 job_callback for (4, 0, 14) started
02:49:38 DISPATCHER: Trying to submit another job.
02:49:38 job_callback for (4, 0, 14) got condition
02:49:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:49:38 HBMASTER: Trying to run another job!
02:49:38 job_callback for (4, 0, 14) finished
02:49:38 HBMASTER: schedule new run for iteration 4
02:49:38 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
02:49:38 HBMASTER: submitting job (4, 0, 23) to dispatcher
02:49:38 DISPATCHER: trying to submit job (4, 0, 23)
02:49:38 DISPATCHER: trying to notify the job_runner thread.
02:49:38 HBMASTER: job (4, 0, 23) submitted to dispatcher
02:49:38 DISPATCHER: Trying to submit another job.
02:49:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:49:38 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216
02:49:38 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
02:49:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:49:38 WORKER: start processing job (4, 0, 23)
02:49:38 WORKER: args: ()
02:49:38 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 82, 'last_n_outputs': 12, 'lr': 0.005703154552000854, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.16140862338436368}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-509:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:50:18 DISPATCHER: Starting worker discovery
02:50:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:50:18 DISPATCHER: Finished worker discovery
02:51:18 DISPATCHER: Starting worker discovery
02:51:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:51:18 DISPATCHER: Finished worker discovery
02:52:18 DISPATCHER: Starting worker discovery
02:52:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:52:18 DISPATCHER: Finished worker discovery
02:53:18 DISPATCHER: Starting worker discovery
02:53:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:53:19 DISPATCHER: Finished worker discovery
02:54:19 DISPATCHER: Starting worker discovery
02:54:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:54:19 DISPATCHER: Finished worker discovery
02:55:19 DISPATCHER: Starting worker discovery
02:55:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:55:19 DISPATCHER: Finished worker discovery
02:56:19 DISPATCHER: Starting worker discovery
02:56:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:56:19 DISPATCHER: Finished worker discovery
02:56:27 WORKER: done with job (4, 0, 23), trying to register it.
02:56:27 WORKER: registered result for job (4, 0, 23) with dispatcher
02:56:27 DISPATCHER: job (4, 0, 23) finished
02:56:27 DISPATCHER: register_result: lock acquired
02:56:27 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
02:56:27 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 82, 'last_n_outputs': 12, 'lr': 0.005703154552000854, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.16140862338436368}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7930094921706329, 'info': {'music-speech': 0.7930094921706329, 'config': "{'batch_size': 16, 'hidden_dim': 82, 'last_n_outputs': 12, 'lr': 0.005703154552000854, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.16140862338436368}"}}
exception: None

02:56:27 job_callback for (4, 0, 23) started
02:56:27 DISPATCHER: Trying to submit another job.
02:56:27 job_callback for (4, 0, 23) got condition
02:56:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
02:56:27 HBMASTER: Trying to run another job!
02:56:27 job_callback for (4, 0, 23) finished
02:56:27 ITERATION: Advancing config (4, 0, 23) to next budget 1200.000000
02:56:27 HBMASTER: schedule new run for iteration 4
02:56:27 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
02:56:27 HBMASTER: submitting job (4, 0, 23) to dispatcher
02:56:27 DISPATCHER: trying to submit job (4, 0, 23)
02:56:27 DISPATCHER: trying to notify the job_runner thread.
02:56:27 HBMASTER: job (4, 0, 23) submitted to dispatcher
02:56:27 DISPATCHER: Trying to submit another job.
02:56:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
02:56:27 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216
02:56:27 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
02:56:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
02:56:27 WORKER: start processing job (4, 0, 23)
02:56:27 WORKER: args: ()
02:56:27 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 82, 'last_n_outputs': 12, 'lr': 0.005703154552000854, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.16140862338436368}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-510:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

02:57:19 DISPATCHER: Starting worker discovery
02:57:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:57:19 DISPATCHER: Finished worker discovery
02:58:19 DISPATCHER: Starting worker discovery
02:58:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:58:19 DISPATCHER: Finished worker discovery
02:59:19 DISPATCHER: Starting worker discovery
02:59:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:59:19 DISPATCHER: Finished worker discovery
03:00:19 DISPATCHER: Starting worker discovery
03:00:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:00:19 DISPATCHER: Finished worker discovery
03:01:19 DISPATCHER: Starting worker discovery
03:01:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:01:19 DISPATCHER: Finished worker discovery
03:02:19 DISPATCHER: Starting worker discovery
03:02:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:02:19 DISPATCHER: Finished worker discovery
03:03:19 DISPATCHER: Starting worker discovery
03:03:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:03:19 DISPATCHER: Finished worker discovery
03:04:19 DISPATCHER: Starting worker discovery
03:04:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:04:19 DISPATCHER: Finished worker discovery
03:05:19 DISPATCHER: Starting worker discovery
03:05:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:05:19 DISPATCHER: Finished worker discovery
03:06:19 DISPATCHER: Starting worker discovery
03:06:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:06:19 DISPATCHER: Finished worker discovery
03:07:19 DISPATCHER: Starting worker discovery
03:07:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:07:19 DISPATCHER: Finished worker discovery
03:08:19 DISPATCHER: Starting worker discovery
03:08:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:08:19 DISPATCHER: Finished worker discovery
03:09:19 DISPATCHER: Starting worker discovery
03:09:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:09:19 DISPATCHER: Finished worker discovery
03:10:19 DISPATCHER: Starting worker discovery
03:10:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:10:19 DISPATCHER: Finished worker discovery
03:11:19 DISPATCHER: Starting worker discovery
03:11:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:11:19 DISPATCHER: Finished worker discovery
03:12:19 DISPATCHER: Starting worker discovery
03:12:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:12:19 DISPATCHER: Finished worker discovery
03:13:19 DISPATCHER: Starting worker discovery
03:13:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:13:19 DISPATCHER: Finished worker discovery
03:14:19 DISPATCHER: Starting worker discovery
03:14:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:14:19 DISPATCHER: Finished worker discovery
03:15:19 DISPATCHER: Starting worker discovery
03:15:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:15:19 DISPATCHER: Finished worker discovery
03:16:19 DISPATCHER: Starting worker discovery
03:16:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:16:19 DISPATCHER: Finished worker discovery
03:16:35 WORKER: done with job (4, 0, 23), trying to register it.
03:16:35 WORKER: registered result for job (4, 0, 23) with dispatcher
03:16:35 DISPATCHER: job (4, 0, 23) finished
03:16:35 DISPATCHER: register_result: lock acquired
03:16:35 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
03:16:35 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 82, 'last_n_outputs': 12, 'lr': 0.005703154552000854, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.16140862338436368}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.6548346843150562, 'info': {'music-speech': 0.6548346843150562, 'config': "{'batch_size': 16, 'hidden_dim': 82, 'last_n_outputs': 12, 'lr': 0.005703154552000854, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.16140862338436368}"}}
exception: None

03:16:35 job_callback for (4, 0, 23) started
03:16:35 DISPATCHER: Trying to submit another job.
03:16:35 job_callback for (4, 0, 23) got condition
03:16:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:16:35 HBMASTER: Trying to run another job!
03:16:35 job_callback for (4, 0, 23) finished
03:16:35 start sampling a new configuration.
03:16:35 done sampling a new configuration.
03:16:35 HBMASTER: schedule new run for iteration 5
03:16:35 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
03:16:35 HBMASTER: submitting job (5, 0, 0) to dispatcher
03:16:35 DISPATCHER: trying to submit job (5, 0, 0)
03:16:35 DISPATCHER: trying to notify the job_runner thread.
03:16:35 HBMASTER: job (5, 0, 0) submitted to dispatcher
03:16:35 DISPATCHER: Trying to submit another job.
03:16:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:16:35 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
03:16:35 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
03:16:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:16:35 WORKER: start processing job (5, 0, 0)
03:16:35 WORKER: args: ()
03:16:35 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 41, 'last_n_outputs': 31, 'lr': 0.0015965381415456, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.0329267555081671}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-511:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:17:19 DISPATCHER: Starting worker discovery
03:17:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:17:19 DISPATCHER: Finished worker discovery
03:18:19 DISPATCHER: Starting worker discovery
03:18:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:18:19 DISPATCHER: Finished worker discovery
03:18:57 WORKER: done with job (5, 0, 0), trying to register it.
03:18:57 WORKER: registered result for job (5, 0, 0) with dispatcher
03:18:57 DISPATCHER: job (5, 0, 0) finished
03:18:57 DISPATCHER: register_result: lock acquired
03:18:57 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
03:18:57 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 41, 'last_n_outputs': 31, 'lr': 0.0015965381415456, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.0329267555081671}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.10801801297774716, 'info': {'music-speech': 0.10801801297774716, 'config': "{'batch_size': 128, 'hidden_dim': 41, 'last_n_outputs': 31, 'lr': 0.0015965381415456, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 42, 'weight_decay': 0.0329267555081671}"}}
exception: None

03:18:57 job_callback for (5, 0, 0) started
03:18:57 DISPATCHER: Trying to submit another job.
03:18:57 job_callback for (5, 0, 0) got condition
03:18:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:18:57 done building a new model for budget 133.333333 based on 9/23 split
Best loss for this budget:-0.928043





03:18:57 HBMASTER: Trying to run another job!
03:18:57 job_callback for (5, 0, 0) finished
03:18:57 start sampling a new configuration.
03:18:57 done sampling a new configuration.
03:18:57 HBMASTER: schedule new run for iteration 5
03:18:57 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
03:18:57 HBMASTER: submitting job (5, 0, 1) to dispatcher
03:18:57 DISPATCHER: trying to submit job (5, 0, 1)
03:18:57 DISPATCHER: trying to notify the job_runner thread.
03:18:57 HBMASTER: job (5, 0, 1) submitted to dispatcher
03:18:57 DISPATCHER: Trying to submit another job.
03:18:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:18:57 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
03:18:57 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
03:18:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:18:57 WORKER: start processing job (5, 0, 1)
03:18:57 WORKER: args: ()
03:18:57 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 22, 'last_n_outputs': 9, 'lr': 0.021876210227415354, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.07015975221695187}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-512:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:19:19 DISPATCHER: Starting worker discovery
03:19:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:19:19 DISPATCHER: Finished worker discovery
03:20:19 DISPATCHER: Starting worker discovery
03:20:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:20:19 DISPATCHER: Finished worker discovery
03:21:19 DISPATCHER: Starting worker discovery
03:21:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:21:19 DISPATCHER: Finished worker discovery
03:21:20 WORKER: done with job (5, 0, 1), trying to register it.
03:21:20 WORKER: registered result for job (5, 0, 1) with dispatcher
03:21:20 DISPATCHER: job (5, 0, 1) finished
03:21:20 DISPATCHER: register_result: lock acquired
03:21:20 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
03:21:20 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 22, 'last_n_outputs': 9, 'lr': 0.021876210227415354, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.07015975221695187}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.39813592821804417, 'info': {'music-speech': 0.39813592821804417, 'config': "{'batch_size': 16, 'hidden_dim': 22, 'last_n_outputs': 9, 'lr': 0.021876210227415354, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 34, 'weight_decay': 0.07015975221695187}"}}
exception: None

03:21:20 job_callback for (5, 0, 1) started
03:21:20 DISPATCHER: Trying to submit another job.
03:21:20 job_callback for (5, 0, 1) got condition
03:21:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:21:20 done building a new model for budget 133.333333 based on 9/24 split
Best loss for this budget:-0.928043





03:21:20 HBMASTER: Trying to run another job!
03:21:20 job_callback for (5, 0, 1) finished
03:21:20 start sampling a new configuration.
03:21:20 done sampling a new configuration.
03:21:20 HBMASTER: schedule new run for iteration 5
03:21:20 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
03:21:20 HBMASTER: submitting job (5, 0, 2) to dispatcher
03:21:20 DISPATCHER: trying to submit job (5, 0, 2)
03:21:20 DISPATCHER: trying to notify the job_runner thread.
03:21:20 HBMASTER: job (5, 0, 2) submitted to dispatcher
03:21:20 DISPATCHER: Trying to submit another job.
03:21:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:21:20 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
03:21:20 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
03:21:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:21:20 WORKER: start processing job (5, 0, 2)
03:21:20 WORKER: args: ()
03:21:20 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 38, 'last_n_outputs': 4, 'lr': 0.03982833595765514, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.1570192080769134}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-513:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:22:19 DISPATCHER: Starting worker discovery
03:22:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:22:19 DISPATCHER: Finished worker discovery
03:23:19 DISPATCHER: Starting worker discovery
03:23:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:23:19 DISPATCHER: Finished worker discovery
03:23:42 WORKER: done with job (5, 0, 2), trying to register it.
03:23:42 WORKER: registered result for job (5, 0, 2) with dispatcher
03:23:42 DISPATCHER: job (5, 0, 2) finished
03:23:42 DISPATCHER: register_result: lock acquired
03:23:42 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
03:23:42 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 38, 'last_n_outputs': 4, 'lr': 0.03982833595765514, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.1570192080769134}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 38, 'last_n_outputs': 4, 'lr': 0.03982833595765514, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.1570192080769134}"}}
exception: None

03:23:42 job_callback for (5, 0, 2) started
03:23:42 DISPATCHER: Trying to submit another job.
03:23:42 job_callback for (5, 0, 2) got condition
03:23:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:23:42 done building a new model for budget 133.333333 based on 9/25 split
Best loss for this budget:-0.928043





03:23:42 HBMASTER: Trying to run another job!
03:23:42 job_callback for (5, 0, 2) finished
03:23:42 start sampling a new configuration.
03:23:42 best_vector: [0, 0.09511539797096336, 0.9881050463544492, 0.28530052590001914, 0.09769237936486791, 0, 0.8148066819673039, 0.028941580470520534], 0.01952027066149877, 1.1773573617337463, 0.022982334366350846
03:23:42 done sampling a new configuration.
03:23:42 HBMASTER: schedule new run for iteration 5
03:23:42 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
03:23:42 HBMASTER: submitting job (5, 0, 3) to dispatcher
03:23:42 DISPATCHER: trying to submit job (5, 0, 3)
03:23:42 DISPATCHER: trying to notify the job_runner thread.
03:23:42 HBMASTER: job (5, 0, 3) submitted to dispatcher
03:23:42 DISPATCHER: Trying to submit another job.
03:23:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:23:42 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
03:23:42 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
03:23:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:23:42 WORKER: start processing job (5, 0, 3)
03:23:42 WORKER: args: ()
03:23:42 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 27, 'last_n_outputs': 50, 'lr': 0.0037204977977113676, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.010905707975620465}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-514:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:24:19 DISPATCHER: Starting worker discovery
03:24:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:24:19 DISPATCHER: Finished worker discovery
03:25:19 DISPATCHER: Starting worker discovery
03:25:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:25:19 DISPATCHER: Finished worker discovery
03:26:04 WORKER: done with job (5, 0, 3), trying to register it.
03:26:04 WORKER: registered result for job (5, 0, 3) with dispatcher
03:26:04 DISPATCHER: job (5, 0, 3) finished
03:26:04 DISPATCHER: register_result: lock acquired
03:26:04 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
03:26:04 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 27, 'last_n_outputs': 50, 'lr': 0.0037204977977113676, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.010905707975620465}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7689055509495676, 'info': {'music-speech': 0.7689055509495676, 'config': "{'batch_size': 16, 'hidden_dim': 27, 'last_n_outputs': 50, 'lr': 0.0037204977977113676, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.010905707975620465}"}}
exception: None

03:26:04 job_callback for (5, 0, 3) started
03:26:04 DISPATCHER: Trying to submit another job.
03:26:04 job_callback for (5, 0, 3) got condition
03:26:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:26:04 done building a new model for budget 133.333333 based on 9/26 split
Best loss for this budget:-0.928043





03:26:04 HBMASTER: Trying to run another job!
03:26:04 job_callback for (5, 0, 3) finished
03:26:04 start sampling a new configuration.
03:26:04 done sampling a new configuration.
03:26:04 HBMASTER: schedule new run for iteration 5
03:26:04 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
03:26:04 HBMASTER: submitting job (5, 0, 4) to dispatcher
03:26:04 DISPATCHER: trying to submit job (5, 0, 4)
03:26:04 DISPATCHER: trying to notify the job_runner thread.
03:26:04 HBMASTER: job (5, 0, 4) submitted to dispatcher
03:26:04 DISPATCHER: Trying to submit another job.
03:26:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:26:04 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
03:26:04 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
03:26:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:26:04 WORKER: start processing job (5, 0, 4)
03:26:04 WORKER: args: ()
03:26:04 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 24, 'last_n_outputs': 35, 'lr': 0.041728718658975775, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.01977023118549646}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:26:19 DISPATCHER: Starting worker discovery
03:26:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:26:19 DISPATCHER: Finished worker discovery
Exception in thread Thread-515:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:27:19 DISPATCHER: Starting worker discovery
03:27:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:27:19 DISPATCHER: Finished worker discovery
03:28:19 DISPATCHER: Starting worker discovery
03:28:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:28:19 DISPATCHER: Finished worker discovery
03:28:26 WORKER: done with job (5, 0, 4), trying to register it.
03:28:26 WORKER: registered result for job (5, 0, 4) with dispatcher
03:28:26 DISPATCHER: job (5, 0, 4) finished
03:28:26 DISPATCHER: register_result: lock acquired
03:28:26 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
03:28:26 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 24, 'last_n_outputs': 35, 'lr': 0.041728718658975775, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.01977023118549646}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 24, 'last_n_outputs': 35, 'lr': 0.041728718658975775, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.01977023118549646}"}}
exception: None

03:28:26 job_callback for (5, 0, 4) started
03:28:26 DISPATCHER: Trying to submit another job.
03:28:26 job_callback for (5, 0, 4) got condition
03:28:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:28:26 done building a new model for budget 133.333333 based on 9/27 split
Best loss for this budget:-0.928043





03:28:26 HBMASTER: Trying to run another job!
03:28:26 job_callback for (5, 0, 4) finished
03:28:26 start sampling a new configuration.
03:28:26 best_vector: [2, 0.07738589799720075, 0.3357960372989657, 0.595026068990163, 0.0842570230610957, 0, 0.7813921872648024, 0.23601999619187441], 0.03266767411380007, 0.4416059702494989, 0.014426239922819118
03:28:26 done sampling a new configuration.
03:28:26 HBMASTER: schedule new run for iteration 5
03:28:26 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
03:28:26 HBMASTER: submitting job (5, 0, 5) to dispatcher
03:28:26 DISPATCHER: trying to submit job (5, 0, 5)
03:28:26 DISPATCHER: trying to notify the job_runner thread.
03:28:26 HBMASTER: job (5, 0, 5) submitted to dispatcher
03:28:26 DISPATCHER: Trying to submit another job.
03:28:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:28:26 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
03:28:26 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
03:28:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:28:26 WORKER: start processing job (5, 0, 5)
03:28:26 WORKER: args: ()
03:28:26 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 26, 'last_n_outputs': 17, 'lr': 0.015490025688179027, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.02028005341895219}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-516:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:29:19 DISPATCHER: Starting worker discovery
03:29:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:29:19 DISPATCHER: Finished worker discovery
03:30:19 DISPATCHER: Starting worker discovery
03:30:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:30:19 DISPATCHER: Finished worker discovery
03:30:48 WORKER: done with job (5, 0, 5), trying to register it.
03:30:48 DISPATCHER: job (5, 0, 5) finished
03:30:48 WORKER: registered result for job (5, 0, 5) with dispatcher
03:30:48 DISPATCHER: register_result: lock acquired
03:30:48 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
03:30:48 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 26, 'last_n_outputs': 17, 'lr': 0.015490025688179027, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.02028005341895219}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.726473766265344, 'info': {'music-speech': 0.726473766265344, 'config': "{'batch_size': 64, 'hidden_dim': 26, 'last_n_outputs': 17, 'lr': 0.015490025688179027, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.02028005341895219}"}}
exception: None

03:30:48 job_callback for (5, 0, 5) started
03:30:48 DISPATCHER: Trying to submit another job.
03:30:48 job_callback for (5, 0, 5) got condition
03:30:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:30:48 done building a new model for budget 133.333333 based on 9/28 split
Best loss for this budget:-0.928043





03:30:48 HBMASTER: Trying to run another job!
03:30:48 job_callback for (5, 0, 5) finished
03:30:48 start sampling a new configuration.
03:30:48 best_vector: [0, 0.7032700529449739, 0.37647589172818446, 0.3363251347039308, 0.3141127249908294, 0, 0.6764424932776245, 0.2883721264922204], 0.06427029795362957, 0.18396780759268105, 0.011823665807857606
03:30:48 done sampling a new configuration.
03:30:48 HBMASTER: schedule new run for iteration 5
03:30:48 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
03:30:48 HBMASTER: submitting job (5, 0, 6) to dispatcher
03:30:48 DISPATCHER: trying to submit job (5, 0, 6)
03:30:48 DISPATCHER: trying to notify the job_runner thread.
03:30:48 HBMASTER: job (5, 0, 6) submitted to dispatcher
03:30:48 DISPATCHER: Trying to submit another job.
03:30:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:30:48 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216
03:30:48 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
03:30:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:30:48 WORKER: start processing job (5, 0, 6)
03:30:48 WORKER: args: ()
03:30:48 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 19, 'lr': 0.004705982083500557, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.02372361057714541}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-517:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:31:19 DISPATCHER: Starting worker discovery
03:31:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:31:19 DISPATCHER: Finished worker discovery
03:32:19 DISPATCHER: Starting worker discovery
03:32:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:32:19 DISPATCHER: Finished worker discovery
03:33:10 WORKER: done with job (5, 0, 6), trying to register it.
03:33:10 WORKER: registered result for job (5, 0, 6) with dispatcher
03:33:10 DISPATCHER: job (5, 0, 6) finished
03:33:10 DISPATCHER: register_result: lock acquired
03:33:10 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
03:33:10 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 19, 'lr': 0.004705982083500557, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.02372361057714541}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.789288653874917, 'info': {'music-speech': 0.789288653874917, 'config': "{'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 19, 'lr': 0.004705982083500557, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.02372361057714541}"}}
exception: None

03:33:10 job_callback for (5, 0, 6) started
03:33:10 DISPATCHER: Trying to submit another job.
03:33:10 job_callback for (5, 0, 6) got condition
03:33:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:33:10 done building a new model for budget 133.333333 based on 9/28 split
Best loss for this budget:-0.928043





03:33:10 HBMASTER: Trying to run another job!
03:33:10 job_callback for (5, 0, 6) finished
03:33:10 start sampling a new configuration.
03:33:10 best_vector: [1, 0.9194518332863408, 0.3666310751706179, 0.5072240580786008, 0.3802515804825688, 0, 0.9430973179960234, 0.4011033079923845], 0.004251604758521552, 0.4534553497029274, 0.0019279129225740204
03:33:10 done sampling a new configuration.
03:33:10 HBMASTER: schedule new run for iteration 5
03:33:10 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
03:33:10 HBMASTER: submitting job (5, 0, 7) to dispatcher
03:33:10 DISPATCHER: trying to submit job (5, 0, 7)
03:33:10 DISPATCHER: trying to notify the job_runner thread.
03:33:10 HBMASTER: job (5, 0, 7) submitted to dispatcher
03:33:10 DISPATCHER: Trying to submit another job.
03:33:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:33:10 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
03:33:10 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
03:33:10 WORKER: start processing job (5, 0, 7)
03:33:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:33:10 WORKER: args: ()
03:33:10 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 94, 'last_n_outputs': 19, 'lr': 0.010338275853626172, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.03325427125923552}, 'budget': 133.33333333333331, 'working_directory': '.'}
03:33:19 DISPATCHER: Starting worker discovery
03:33:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:33:19 DISPATCHER: Finished worker discovery
Exception in thread Thread-518:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:34:19 DISPATCHER: Starting worker discovery
03:34:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:34:19 DISPATCHER: Finished worker discovery
03:35:19 DISPATCHER: Starting worker discovery
03:35:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:35:19 DISPATCHER: Finished worker discovery
03:35:32 WORKER: done with job (5, 0, 7), trying to register it.
03:35:32 WORKER: registered result for job (5, 0, 7) with dispatcher
03:35:32 DISPATCHER: job (5, 0, 7) finished
03:35:32 DISPATCHER: register_result: lock acquired
03:35:32 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
03:35:32 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 94, 'last_n_outputs': 19, 'lr': 0.010338275853626172, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.03325427125923552}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.696603655269869, 'info': {'music-speech': 0.696603655269869, 'config': "{'batch_size': 32, 'hidden_dim': 94, 'last_n_outputs': 19, 'lr': 0.010338275853626172, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 95, 'weight_decay': 0.03325427125923552}"}}
exception: None

03:35:32 job_callback for (5, 0, 7) started
03:35:32 DISPATCHER: Trying to submit another job.
03:35:32 job_callback for (5, 0, 7) got condition
03:35:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:35:32 done building a new model for budget 133.333333 based on 9/29 split
Best loss for this budget:-0.928043





03:35:32 HBMASTER: Trying to run another job!
03:35:32 job_callback for (5, 0, 7) finished
03:35:32 start sampling a new configuration.
03:35:32 done sampling a new configuration.
03:35:32 HBMASTER: schedule new run for iteration 5
03:35:32 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
03:35:32 HBMASTER: submitting job (5, 0, 8) to dispatcher
03:35:32 DISPATCHER: trying to submit job (5, 0, 8)
03:35:32 DISPATCHER: trying to notify the job_runner thread.
03:35:32 HBMASTER: job (5, 0, 8) submitted to dispatcher
03:35:32 DISPATCHER: Trying to submit another job.
03:35:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:35:32 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216
03:35:32 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
03:35:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:35:32 WORKER: start processing job (5, 0, 8)
03:35:32 WORKER: args: ()
03:35:32 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 36, 'lr': 0.003895632994204597, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.031173513333410858}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-519:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:36:19 DISPATCHER: Starting worker discovery
03:36:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:36:19 DISPATCHER: Finished worker discovery
03:37:19 DISPATCHER: Starting worker discovery
03:37:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:37:19 DISPATCHER: Finished worker discovery
03:37:54 WORKER: done with job (5, 0, 8), trying to register it.
03:37:54 WORKER: registered result for job (5, 0, 8) with dispatcher
03:37:54 DISPATCHER: job (5, 0, 8) finished
03:37:54 DISPATCHER: register_result: lock acquired
03:37:54 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
03:37:54 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 36, 'lr': 0.003895632994204597, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.031173513333410858}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6382473772648384, 'info': {'music-speech': 0.6382473772648384, 'config': "{'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 36, 'lr': 0.003895632994204597, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.031173513333410858}"}}
exception: None

03:37:54 job_callback for (5, 0, 8) started
03:37:54 DISPATCHER: Trying to submit another job.
03:37:54 job_callback for (5, 0, 8) got condition
03:37:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:37:54 done building a new model for budget 133.333333 based on 9/30 split
Best loss for this budget:-0.928043





03:37:54 HBMASTER: Trying to run another job!
03:37:54 job_callback for (5, 0, 8) finished
03:37:54 ITERATION: Advancing config (5, 0, 3) to next budget 400.000000
03:37:54 ITERATION: Advancing config (5, 0, 5) to next budget 400.000000
03:37:54 ITERATION: Advancing config (5, 0, 6) to next budget 400.000000
03:37:54 HBMASTER: schedule new run for iteration 5
03:37:54 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
03:37:54 HBMASTER: submitting job (5, 0, 3) to dispatcher
03:37:54 DISPATCHER: trying to submit job (5, 0, 3)
03:37:54 DISPATCHER: trying to notify the job_runner thread.
03:37:54 HBMASTER: job (5, 0, 3) submitted to dispatcher
03:37:54 DISPATCHER: Trying to submit another job.
03:37:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:37:54 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
03:37:54 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
03:37:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:37:54 WORKER: start processing job (5, 0, 3)
03:37:54 WORKER: args: ()
03:37:54 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 27, 'last_n_outputs': 50, 'lr': 0.0037204977977113676, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.010905707975620465}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-520:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:38:19 DISPATCHER: Starting worker discovery
03:38:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:38:19 DISPATCHER: Finished worker discovery
03:39:19 DISPATCHER: Starting worker discovery
03:39:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:39:19 DISPATCHER: Finished worker discovery
03:40:19 DISPATCHER: Starting worker discovery
03:40:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:40:19 DISPATCHER: Finished worker discovery
03:41:19 DISPATCHER: Starting worker discovery
03:41:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:41:19 DISPATCHER: Finished worker discovery
03:42:19 DISPATCHER: Starting worker discovery
03:42:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:42:19 DISPATCHER: Finished worker discovery
03:43:19 DISPATCHER: Starting worker discovery
03:43:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:43:19 DISPATCHER: Finished worker discovery
03:44:19 DISPATCHER: Starting worker discovery
03:44:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:44:19 DISPATCHER: Finished worker discovery
03:44:43 WORKER: done with job (5, 0, 3), trying to register it.
03:44:43 WORKER: registered result for job (5, 0, 3) with dispatcher
03:44:43 DISPATCHER: job (5, 0, 3) finished
03:44:43 DISPATCHER: register_result: lock acquired
03:44:43 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
03:44:43 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 27, 'last_n_outputs': 50, 'lr': 0.0037204977977113676, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.010905707975620465}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7854136969979031, 'info': {'music-speech': 0.7854136969979031, 'config': "{'batch_size': 16, 'hidden_dim': 27, 'last_n_outputs': 50, 'lr': 0.0037204977977113676, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 84, 'weight_decay': 0.010905707975620465}"}}
exception: None

03:44:43 job_callback for (5, 0, 3) started
03:44:43 DISPATCHER: Trying to submit another job.
03:44:43 job_callback for (5, 0, 3) got condition
03:44:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:44:43 HBMASTER: Trying to run another job!
03:44:43 job_callback for (5, 0, 3) finished
03:44:43 HBMASTER: schedule new run for iteration 5
03:44:43 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
03:44:43 HBMASTER: submitting job (5, 0, 5) to dispatcher
03:44:43 DISPATCHER: trying to submit job (5, 0, 5)
03:44:43 DISPATCHER: trying to notify the job_runner thread.
03:44:43 HBMASTER: job (5, 0, 5) submitted to dispatcher
03:44:43 DISPATCHER: Trying to submit another job.
03:44:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:44:43 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
03:44:43 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
03:44:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:44:43 WORKER: start processing job (5, 0, 5)
03:44:43 WORKER: args: ()
03:44:43 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 26, 'last_n_outputs': 17, 'lr': 0.015490025688179027, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.02028005341895219}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-521:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:45:19 DISPATCHER: Starting worker discovery
03:45:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:45:19 DISPATCHER: Finished worker discovery
03:46:19 DISPATCHER: Starting worker discovery
03:46:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:46:19 DISPATCHER: Finished worker discovery
03:47:19 DISPATCHER: Starting worker discovery
03:47:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:47:19 DISPATCHER: Finished worker discovery
03:48:19 DISPATCHER: Starting worker discovery
03:48:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:48:19 DISPATCHER: Finished worker discovery
03:49:19 DISPATCHER: Starting worker discovery
03:49:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:49:19 DISPATCHER: Finished worker discovery
03:50:19 DISPATCHER: Starting worker discovery
03:50:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:50:19 DISPATCHER: Finished worker discovery
03:51:19 DISPATCHER: Starting worker discovery
03:51:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:51:19 DISPATCHER: Finished worker discovery
03:51:32 WORKER: done with job (5, 0, 5), trying to register it.
03:51:32 WORKER: registered result for job (5, 0, 5) with dispatcher
03:51:32 DISPATCHER: job (5, 0, 5) finished
03:51:32 DISPATCHER: register_result: lock acquired
03:51:32 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
03:51:32 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 26, 'last_n_outputs': 17, 'lr': 0.015490025688179027, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.02028005341895219}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6538196460824025, 'info': {'music-speech': 0.6538196460824025, 'config': "{'batch_size': 64, 'hidden_dim': 26, 'last_n_outputs': 17, 'lr': 0.015490025688179027, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.02028005341895219}"}}
exception: None

03:51:32 job_callback for (5, 0, 5) started
03:51:32 DISPATCHER: Trying to submit another job.
03:51:32 job_callback for (5, 0, 5) got condition
03:51:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:51:32 HBMASTER: Trying to run another job!
03:51:32 job_callback for (5, 0, 5) finished
03:51:32 HBMASTER: schedule new run for iteration 5
03:51:32 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
03:51:32 HBMASTER: submitting job (5, 0, 6) to dispatcher
03:51:32 DISPATCHER: trying to submit job (5, 0, 6)
03:51:32 DISPATCHER: trying to notify the job_runner thread.
03:51:32 HBMASTER: job (5, 0, 6) submitted to dispatcher
03:51:32 DISPATCHER: Trying to submit another job.
03:51:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:51:32 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216
03:51:32 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
03:51:32 WORKER: start processing job (5, 0, 6)
03:51:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:51:32 WORKER: args: ()
03:51:32 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 19, 'lr': 0.004705982083500557, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.02372361057714541}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-522:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:52:19 DISPATCHER: Starting worker discovery
03:52:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:52:19 DISPATCHER: Finished worker discovery
03:53:19 DISPATCHER: Starting worker discovery
03:53:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:53:19 DISPATCHER: Finished worker discovery
03:54:19 DISPATCHER: Starting worker discovery
03:54:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:54:19 DISPATCHER: Finished worker discovery
03:55:19 DISPATCHER: Starting worker discovery
03:55:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:55:19 DISPATCHER: Finished worker discovery
03:56:19 DISPATCHER: Starting worker discovery
03:56:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:56:19 DISPATCHER: Finished worker discovery
03:57:19 DISPATCHER: Starting worker discovery
03:57:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:57:19 DISPATCHER: Finished worker discovery
03:58:19 DISPATCHER: Starting worker discovery
03:58:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:58:19 DISPATCHER: Finished worker discovery
03:58:21 WORKER: done with job (5, 0, 6), trying to register it.
03:58:21 WORKER: registered result for job (5, 0, 6) with dispatcher
03:58:21 DISPATCHER: job (5, 0, 6) finished
03:58:21 DISPATCHER: register_result: lock acquired
03:58:21 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
03:58:21 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 19, 'lr': 0.004705982083500557, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.02372361057714541}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8558693199473091, 'info': {'music-speech': 0.8558693199473091, 'config': "{'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 19, 'lr': 0.004705982083500557, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.02372361057714541}"}}
exception: None

03:58:21 job_callback for (5, 0, 6) started
03:58:21 DISPATCHER: Trying to submit another job.
03:58:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
03:58:21 job_callback for (5, 0, 6) got condition
03:58:22 done building a new model for budget 400.000000 based on 9/15 split
Best loss for this budget:-0.994929





03:58:22 HBMASTER: Trying to run another job!
03:58:22 job_callback for (5, 0, 6) finished
03:58:22 ITERATION: Advancing config (5, 0, 6) to next budget 1200.000000
03:58:22 HBMASTER: schedule new run for iteration 5
03:58:22 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
03:58:22 HBMASTER: submitting job (5, 0, 6) to dispatcher
03:58:22 DISPATCHER: trying to submit job (5, 0, 6)
03:58:22 DISPATCHER: trying to notify the job_runner thread.
03:58:22 HBMASTER: job (5, 0, 6) submitted to dispatcher
03:58:22 DISPATCHER: Trying to submit another job.
03:58:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
03:58:22 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216
03:58:22 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
03:58:22 WORKER: start processing job (5, 0, 6)
03:58:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
03:58:22 WORKER: args: ()
03:58:22 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 19, 'lr': 0.004705982083500557, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.02372361057714541}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-523:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

03:59:19 DISPATCHER: Starting worker discovery
03:59:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:59:19 DISPATCHER: Finished worker discovery
04:00:19 DISPATCHER: Starting worker discovery
04:00:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:00:19 DISPATCHER: Finished worker discovery
04:01:19 DISPATCHER: Starting worker discovery
04:01:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:01:19 DISPATCHER: Finished worker discovery
04:02:19 DISPATCHER: Starting worker discovery
04:02:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:02:19 DISPATCHER: Finished worker discovery
04:03:19 DISPATCHER: Starting worker discovery
04:03:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:03:19 DISPATCHER: Finished worker discovery
04:04:19 DISPATCHER: Starting worker discovery
04:04:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:04:19 DISPATCHER: Finished worker discovery
04:05:19 DISPATCHER: Starting worker discovery
04:05:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:05:19 DISPATCHER: Finished worker discovery
04:06:19 DISPATCHER: Starting worker discovery
04:06:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:06:19 DISPATCHER: Finished worker discovery
04:07:19 DISPATCHER: Starting worker discovery
04:07:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:07:19 DISPATCHER: Finished worker discovery
04:08:19 DISPATCHER: Starting worker discovery
04:08:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:08:19 DISPATCHER: Finished worker discovery
04:09:19 DISPATCHER: Starting worker discovery
04:09:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:09:19 DISPATCHER: Finished worker discovery
04:10:19 DISPATCHER: Starting worker discovery
04:10:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:10:19 DISPATCHER: Finished worker discovery
04:11:19 DISPATCHER: Starting worker discovery
04:11:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:11:19 DISPATCHER: Finished worker discovery
04:12:19 DISPATCHER: Starting worker discovery
04:12:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:12:19 DISPATCHER: Finished worker discovery
04:13:19 DISPATCHER: Starting worker discovery
04:13:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:13:19 DISPATCHER: Finished worker discovery
04:14:19 DISPATCHER: Starting worker discovery
04:14:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:14:20 DISPATCHER: Finished worker discovery
04:15:20 DISPATCHER: Starting worker discovery
04:15:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:15:20 DISPATCHER: Finished worker discovery
04:16:20 DISPATCHER: Starting worker discovery
04:16:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:16:20 DISPATCHER: Finished worker discovery
04:17:20 DISPATCHER: Starting worker discovery
04:17:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:17:20 DISPATCHER: Finished worker discovery
04:18:20 DISPATCHER: Starting worker discovery
04:18:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:18:20 DISPATCHER: Finished worker discovery
04:18:31 WORKER: done with job (5, 0, 6), trying to register it.
04:18:31 WORKER: registered result for job (5, 0, 6) with dispatcher
04:18:31 DISPATCHER: job (5, 0, 6) finished
04:18:31 DISPATCHER: register_result: lock acquired
04:18:31 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
04:18:31 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 19, 'lr': 0.004705982083500557, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.02372361057714541}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.6964314853511545, 'info': {'music-speech': 0.6964314853511545, 'config': "{'batch_size': 16, 'hidden_dim': 76, 'last_n_outputs': 19, 'lr': 0.004705982083500557, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.02372361057714541}"}}
exception: None

04:18:31 job_callback for (5, 0, 6) started
04:18:31 DISPATCHER: Trying to submit another job.
04:18:31 job_callback for (5, 0, 6) got condition
04:18:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:18:31 HBMASTER: Trying to run another job!
04:18:31 job_callback for (5, 0, 6) finished
04:18:31 start sampling a new configuration.
04:18:31 best_vector: [3, 0.9731968758804538, 0.31360330366604805, 0.12699765997358, 0.2980965983466118, 0, 0.7898646450580167, 0.09515568442018696], 0.002716978437101302, 0.42274152480576066, 0.0011485796073645769
04:18:31 done sampling a new configuration.
04:18:31 HBMASTER: schedule new run for iteration 6
04:18:31 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
04:18:31 HBMASTER: submitting job (6, 0, 0) to dispatcher
04:18:31 DISPATCHER: trying to submit job (6, 0, 0)
04:18:31 DISPATCHER: trying to notify the job_runner thread.
04:18:31 HBMASTER: job (6, 0, 0) submitted to dispatcher
04:18:31 DISPATCHER: Trying to submit another job.
04:18:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:18:31 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
04:18:31 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
04:18:31 WORKER: start processing job (6, 0, 0)
04:18:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:18:31 WORKER: args: ()
04:18:31 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 98, 'last_n_outputs': 16, 'lr': 0.001794714286492504, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.013298430860098135}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-524:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:19:20 DISPATCHER: Starting worker discovery
04:19:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:19:20 DISPATCHER: Finished worker discovery
04:20:20 DISPATCHER: Starting worker discovery
04:20:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:20:20 DISPATCHER: Finished worker discovery
04:21:20 DISPATCHER: Starting worker discovery
04:21:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:21:20 DISPATCHER: Finished worker discovery
04:22:20 DISPATCHER: Starting worker discovery
04:22:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:22:20 DISPATCHER: Finished worker discovery
04:23:20 DISPATCHER: Starting worker discovery
04:23:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:23:20 DISPATCHER: Finished worker discovery
04:24:20 DISPATCHER: Starting worker discovery
04:24:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:24:20 DISPATCHER: Finished worker discovery
04:25:20 DISPATCHER: Starting worker discovery
04:25:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:25:20 DISPATCHER: Finished worker discovery
04:25:20 WORKER: done with job (6, 0, 0), trying to register it.
04:25:20 WORKER: registered result for job (6, 0, 0) with dispatcher
04:25:20 DISPATCHER: job (6, 0, 0) finished
04:25:20 DISPATCHER: register_result: lock acquired
04:25:20 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
04:25:20 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 98, 'last_n_outputs': 16, 'lr': 0.001794714286492504, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.013298430860098135}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8896042022483819, 'info': {'music-speech': 0.8896042022483819, 'config': "{'batch_size': 128, 'hidden_dim': 98, 'last_n_outputs': 16, 'lr': 0.001794714286492504, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.013298430860098135}"}}
exception: None

04:25:20 job_callback for (6, 0, 0) started
04:25:20 DISPATCHER: Trying to submit another job.
04:25:20 job_callback for (6, 0, 0) got condition
04:25:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:25:20 done building a new model for budget 400.000000 based on 9/16 split
Best loss for this budget:-0.994929





04:25:20 HBMASTER: Trying to run another job!
04:25:20 job_callback for (6, 0, 0) finished
04:25:20 start sampling a new configuration.
04:25:20 done sampling a new configuration.
04:25:20 HBMASTER: schedule new run for iteration 6
04:25:20 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
04:25:20 HBMASTER: submitting job (6, 0, 1) to dispatcher
04:25:20 DISPATCHER: trying to submit job (6, 0, 1)
04:25:20 DISPATCHER: trying to notify the job_runner thread.
04:25:20 HBMASTER: job (6, 0, 1) submitted to dispatcher
04:25:20 DISPATCHER: Trying to submit another job.
04:25:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:25:20 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
04:25:20 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
04:25:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:25:20 WORKER: start processing job (6, 0, 1)
04:25:20 WORKER: args: ()
04:25:20 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 25, 'last_n_outputs': 17, 'lr': 0.042667529400080347, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.015252691816373013}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-525:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:26:20 DISPATCHER: Starting worker discovery
04:26:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:26:20 DISPATCHER: Finished worker discovery
04:27:20 DISPATCHER: Starting worker discovery
04:27:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:27:20 DISPATCHER: Finished worker discovery
04:28:20 DISPATCHER: Starting worker discovery
04:28:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:28:20 DISPATCHER: Finished worker discovery
04:29:20 DISPATCHER: Starting worker discovery
04:29:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:29:20 DISPATCHER: Finished worker discovery
04:30:20 DISPATCHER: Starting worker discovery
04:30:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:30:20 DISPATCHER: Finished worker discovery
04:31:20 DISPATCHER: Starting worker discovery
04:31:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:31:20 DISPATCHER: Finished worker discovery
04:32:08 WORKER: done with job (6, 0, 1), trying to register it.
04:32:08 WORKER: registered result for job (6, 0, 1) with dispatcher
04:32:08 DISPATCHER: job (6, 0, 1) finished
04:32:08 DISPATCHER: register_result: lock acquired
04:32:08 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
04:32:08 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 25, 'last_n_outputs': 17, 'lr': 0.042667529400080347, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.015252691816373013}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7690691368470133, 'info': {'music-speech': 0.7690691368470133, 'config': "{'batch_size': 128, 'hidden_dim': 25, 'last_n_outputs': 17, 'lr': 0.042667529400080347, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.015252691816373013}"}}
exception: None

04:32:08 job_callback for (6, 0, 1) started
04:32:08 DISPATCHER: Trying to submit another job.
04:32:08 job_callback for (6, 0, 1) got condition
04:32:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:32:08 done building a new model for budget 400.000000 based on 9/17 split
Best loss for this budget:-0.994929





04:32:08 HBMASTER: Trying to run another job!
04:32:08 job_callback for (6, 0, 1) finished
04:32:08 start sampling a new configuration.
04:32:08 best_vector: [0, 0.8594342118384558, 0.4366514143446696, 0.3051853787490704, 0.5199028296293757, 0, 0.5897323752312701, 0.03851235418024246], 0.022027816223318546, 0.02023248139939495, 0.00044567738200758286
04:32:08 done sampling a new configuration.
04:32:08 HBMASTER: schedule new run for iteration 6
04:32:08 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
04:32:08 HBMASTER: submitting job (6, 0, 2) to dispatcher
04:32:08 DISPATCHER: trying to submit job (6, 0, 2)
04:32:08 DISPATCHER: trying to notify the job_runner thread.
04:32:08 HBMASTER: job (6, 0, 2) submitted to dispatcher
04:32:08 DISPATCHER: Trying to submit another job.
04:32:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:32:08 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
04:32:08 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
04:32:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:32:08 WORKER: start processing job (6, 0, 2)
04:32:08 WORKER: args: ()
04:32:08 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 89, 'last_n_outputs': 22, 'lr': 0.0040772820712030545, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.01122291640364351}, 'budget': 400.0, 'working_directory': '.'}
04:32:20 DISPATCHER: Starting worker discovery
04:32:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:32:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-526:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:33:20 DISPATCHER: Starting worker discovery
04:33:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:33:20 DISPATCHER: Finished worker discovery
04:34:20 DISPATCHER: Starting worker discovery
04:34:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:34:20 DISPATCHER: Finished worker discovery
04:35:20 DISPATCHER: Starting worker discovery
04:35:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:35:20 DISPATCHER: Finished worker discovery
04:36:20 DISPATCHER: Starting worker discovery
04:36:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:36:20 DISPATCHER: Finished worker discovery
04:37:20 DISPATCHER: Starting worker discovery
04:37:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:37:20 DISPATCHER: Finished worker discovery
04:38:20 DISPATCHER: Starting worker discovery
04:38:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:38:20 DISPATCHER: Finished worker discovery
04:38:57 WORKER: done with job (6, 0, 2), trying to register it.
04:38:57 WORKER: registered result for job (6, 0, 2) with dispatcher
04:38:57 DISPATCHER: job (6, 0, 2) finished
04:38:57 DISPATCHER: register_result: lock acquired
04:38:57 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
04:38:57 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 89, 'last_n_outputs': 22, 'lr': 0.0040772820712030545, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.01122291640364351}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8287587728334006, 'info': {'music-speech': 0.8287587728334006, 'config': "{'batch_size': 16, 'hidden_dim': 89, 'last_n_outputs': 22, 'lr': 0.0040772820712030545, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.01122291640364351}"}}
exception: None

04:38:57 job_callback for (6, 0, 2) started
04:38:57 DISPATCHER: Trying to submit another job.
04:38:57 job_callback for (6, 0, 2) got condition
04:38:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:38:57 done building a new model for budget 400.000000 based on 9/17 split
Best loss for this budget:-0.994929





04:38:57 HBMASTER: Trying to run another job!
04:38:57 job_callback for (6, 0, 2) finished
04:38:57 start sampling a new configuration.
04:38:57 best_vector: [2, 0.8593352074887226, 0.12745273675930796, 0.2713879872968368, 0.48562920001622156, 0, 0.8803109530152871, 0.2367305958539621], 0.00047560676620800075, 0.6508981819873659, 0.0003095715794656779
04:38:57 done sampling a new configuration.
04:38:57 HBMASTER: schedule new run for iteration 6
04:38:57 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
04:38:57 HBMASTER: submitting job (6, 0, 3) to dispatcher
04:38:57 DISPATCHER: trying to submit job (6, 0, 3)
04:38:57 DISPATCHER: trying to notify the job_runner thread.
04:38:57 HBMASTER: job (6, 0, 3) submitted to dispatcher
04:38:57 DISPATCHER: Trying to submit another job.
04:38:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:38:57 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
04:38:57 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
04:38:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:38:57 WORKER: start processing job (6, 0, 3)
04:38:57 WORKER: args: ()
04:38:57 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 89, 'last_n_outputs': 7, 'lr': 0.003489602622328884, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.02032327089770661}, 'budget': 400.0, 'working_directory': '.'}
04:39:20 DISPATCHER: Starting worker discovery
04:39:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:39:20 DISPATCHER: Finished worker discovery
Exception in thread Thread-527:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:40:20 DISPATCHER: Starting worker discovery
04:40:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:40:20 DISPATCHER: Finished worker discovery
04:41:20 DISPATCHER: Starting worker discovery
04:41:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:41:20 DISPATCHER: Finished worker discovery
04:42:20 DISPATCHER: Starting worker discovery
04:42:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:42:20 DISPATCHER: Finished worker discovery
04:43:20 DISPATCHER: Starting worker discovery
04:43:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:43:20 DISPATCHER: Finished worker discovery
04:44:20 DISPATCHER: Starting worker discovery
04:44:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:44:20 DISPATCHER: Finished worker discovery
04:45:20 DISPATCHER: Starting worker discovery
04:45:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:45:20 DISPATCHER: Finished worker discovery
04:45:46 WORKER: done with job (6, 0, 3), trying to register it.
04:45:46 DISPATCHER: job (6, 0, 3) finished
04:45:46 WORKER: registered result for job (6, 0, 3) with dispatcher
04:45:46 DISPATCHER: register_result: lock acquired
04:45:46 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
04:45:46 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 89, 'last_n_outputs': 7, 'lr': 0.003489602622328884, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.02032327089770661}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7557203101483836, 'info': {'music-speech': 0.7557203101483836, 'config': "{'batch_size': 64, 'hidden_dim': 89, 'last_n_outputs': 7, 'lr': 0.003489602622328884, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.02032327089770661}"}}
exception: None

04:45:46 job_callback for (6, 0, 3) started
04:45:46 DISPATCHER: Trying to submit another job.
04:45:46 job_callback for (6, 0, 3) got condition
04:45:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:45:46 done building a new model for budget 400.000000 based on 9/18 split
Best loss for this budget:-0.994929





04:45:46 HBMASTER: Trying to run another job!
04:45:46 job_callback for (6, 0, 3) finished
04:45:46 start sampling a new configuration.
04:45:46 done sampling a new configuration.
04:45:46 HBMASTER: schedule new run for iteration 6
04:45:46 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
04:45:46 HBMASTER: submitting job (6, 0, 4) to dispatcher
04:45:46 DISPATCHER: trying to submit job (6, 0, 4)
04:45:46 DISPATCHER: trying to notify the job_runner thread.
04:45:46 HBMASTER: job (6, 0, 4) submitted to dispatcher
04:45:46 DISPATCHER: Trying to submit another job.
04:45:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:45:46 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
04:45:46 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
04:45:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:45:46 WORKER: start processing job (6, 0, 4)
04:45:46 WORKER: args: ()
04:45:46 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 83, 'last_n_outputs': 34, 'lr': 0.030881538864560885, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.09401139979160707}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-528:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:46:20 DISPATCHER: Starting worker discovery
04:46:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:46:20 DISPATCHER: Finished worker discovery
04:47:20 DISPATCHER: Starting worker discovery
04:47:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:47:20 DISPATCHER: Finished worker discovery
04:48:20 DISPATCHER: Starting worker discovery
04:48:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:48:20 DISPATCHER: Finished worker discovery
04:49:20 DISPATCHER: Starting worker discovery
04:49:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:49:20 DISPATCHER: Finished worker discovery
04:50:20 DISPATCHER: Starting worker discovery
04:50:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:50:20 DISPATCHER: Finished worker discovery
04:51:20 DISPATCHER: Starting worker discovery
04:51:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:51:20 DISPATCHER: Finished worker discovery
04:52:20 DISPATCHER: Starting worker discovery
04:52:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:52:20 DISPATCHER: Finished worker discovery
04:52:34 WORKER: done with job (6, 0, 4), trying to register it.
04:52:34 WORKER: registered result for job (6, 0, 4) with dispatcher
04:52:34 DISPATCHER: job (6, 0, 4) finished
04:52:34 DISPATCHER: register_result: lock acquired
04:52:34 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
04:52:34 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 83, 'last_n_outputs': 34, 'lr': 0.030881538864560885, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.09401139979160707}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5832879167207968, 'info': {'music-speech': 0.5832879167207968, 'config': "{'batch_size': 64, 'hidden_dim': 83, 'last_n_outputs': 34, 'lr': 0.030881538864560885, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 98, 'weight_decay': 0.09401139979160707}"}}
exception: None

04:52:34 job_callback for (6, 0, 4) started
04:52:34 DISPATCHER: Trying to submit another job.
04:52:34 job_callback for (6, 0, 4) got condition
04:52:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:52:34 done building a new model for budget 400.000000 based on 9/19 split
Best loss for this budget:-0.994929





04:52:34 HBMASTER: Trying to run another job!
04:52:34 job_callback for (6, 0, 4) finished
04:52:34 start sampling a new configuration.
04:52:35 best_vector: [1, 0.5928429109833454, 0.3939769100888799, 0.47779772438619483, 0.5188975692873449, 0, 0.8785285358393466, 0.2928113067317843], 0.013840399923110536, 1.0013815117048124, 0.013859520597603597
04:52:35 done sampling a new configuration.
04:52:35 HBMASTER: schedule new run for iteration 6
04:52:35 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
04:52:35 HBMASTER: submitting job (6, 0, 5) to dispatcher
04:52:35 DISPATCHER: trying to submit job (6, 0, 5)
04:52:35 DISPATCHER: trying to notify the job_runner thread.
04:52:35 HBMASTER: job (6, 0, 5) submitted to dispatcher
04:52:35 DISPATCHER: Trying to submit another job.
04:52:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:52:35 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
04:52:35 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
04:52:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:52:35 WORKER: start processing job (6, 0, 5)
04:52:35 WORKER: args: ()
04:52:35 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 68, 'last_n_outputs': 20, 'lr': 0.009028081038589441, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.024041208400127533}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-529:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

04:53:20 DISPATCHER: Starting worker discovery
04:53:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:53:20 DISPATCHER: Finished worker discovery
04:54:20 DISPATCHER: Starting worker discovery
04:54:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:54:20 DISPATCHER: Finished worker discovery
04:55:20 DISPATCHER: Starting worker discovery
04:55:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:55:20 DISPATCHER: Finished worker discovery
04:56:20 DISPATCHER: Starting worker discovery
04:56:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:56:20 DISPATCHER: Finished worker discovery
04:57:20 DISPATCHER: Starting worker discovery
04:57:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:57:20 DISPATCHER: Finished worker discovery
04:58:20 DISPATCHER: Starting worker discovery
04:58:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:58:20 DISPATCHER: Finished worker discovery
04:59:20 DISPATCHER: Starting worker discovery
04:59:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:59:20 DISPATCHER: Finished worker discovery
04:59:23 WORKER: done with job (6, 0, 5), trying to register it.
04:59:23 WORKER: registered result for job (6, 0, 5) with dispatcher
04:59:23 DISPATCHER: job (6, 0, 5) finished
04:59:23 DISPATCHER: register_result: lock acquired
04:59:23 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
04:59:23 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 68, 'last_n_outputs': 20, 'lr': 0.009028081038589441, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.024041208400127533}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.49140681335932396, 'info': {'music-speech': 0.49140681335932396, 'config': "{'batch_size': 32, 'hidden_dim': 68, 'last_n_outputs': 20, 'lr': 0.009028081038589441, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.024041208400127533}"}}
exception: None

04:59:23 job_callback for (6, 0, 5) started
04:59:23 DISPATCHER: Trying to submit another job.
04:59:23 job_callback for (6, 0, 5) got condition
04:59:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
04:59:23 done building a new model for budget 400.000000 based on 9/20 split
Best loss for this budget:-0.994929





04:59:23 HBMASTER: Trying to run another job!
04:59:23 job_callback for (6, 0, 5) finished
04:59:23 ITERATION: Advancing config (6, 0, 0) to next budget 1200.000000
04:59:23 ITERATION: Advancing config (6, 0, 2) to next budget 1200.000000
04:59:23 HBMASTER: schedule new run for iteration 6
04:59:23 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
04:59:23 HBMASTER: submitting job (6, 0, 0) to dispatcher
04:59:23 DISPATCHER: trying to submit job (6, 0, 0)
04:59:23 DISPATCHER: trying to notify the job_runner thread.
04:59:23 HBMASTER: job (6, 0, 0) submitted to dispatcher
04:59:23 DISPATCHER: Trying to submit another job.
04:59:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
04:59:23 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
04:59:23 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
04:59:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
04:59:23 WORKER: start processing job (6, 0, 0)
04:59:23 WORKER: args: ()
04:59:23 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 98, 'last_n_outputs': 16, 'lr': 0.001794714286492504, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.013298430860098135}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-530:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:00:20 DISPATCHER: Starting worker discovery
05:00:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:00:20 DISPATCHER: Finished worker discovery
05:01:20 DISPATCHER: Starting worker discovery
05:01:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:01:20 DISPATCHER: Finished worker discovery
05:02:20 DISPATCHER: Starting worker discovery
05:02:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:02:20 DISPATCHER: Finished worker discovery
05:03:20 DISPATCHER: Starting worker discovery
05:03:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:03:20 DISPATCHER: Finished worker discovery
05:04:20 DISPATCHER: Starting worker discovery
05:04:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:04:20 DISPATCHER: Finished worker discovery
05:05:20 DISPATCHER: Starting worker discovery
05:05:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:05:20 DISPATCHER: Finished worker discovery
05:06:20 DISPATCHER: Starting worker discovery
05:06:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:06:20 DISPATCHER: Finished worker discovery
05:07:20 DISPATCHER: Starting worker discovery
05:07:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:07:20 DISPATCHER: Finished worker discovery
05:08:20 DISPATCHER: Starting worker discovery
05:08:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:08:20 DISPATCHER: Finished worker discovery
05:09:20 DISPATCHER: Starting worker discovery
05:09:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:09:20 DISPATCHER: Finished worker discovery
05:10:20 DISPATCHER: Starting worker discovery
05:10:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:10:20 DISPATCHER: Finished worker discovery
05:11:20 DISPATCHER: Starting worker discovery
05:11:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:11:20 DISPATCHER: Finished worker discovery
05:12:20 DISPATCHER: Starting worker discovery
05:12:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:12:20 DISPATCHER: Finished worker discovery
05:13:20 DISPATCHER: Starting worker discovery
05:13:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:13:21 DISPATCHER: Finished worker discovery
05:14:21 DISPATCHER: Starting worker discovery
05:14:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:14:21 DISPATCHER: Finished worker discovery
05:15:21 DISPATCHER: Starting worker discovery
05:15:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:15:21 DISPATCHER: Finished worker discovery
05:16:21 DISPATCHER: Starting worker discovery
05:16:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:16:21 DISPATCHER: Finished worker discovery
05:17:21 DISPATCHER: Starting worker discovery
05:17:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:17:21 DISPATCHER: Finished worker discovery
05:18:21 DISPATCHER: Starting worker discovery
05:18:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:18:21 DISPATCHER: Finished worker discovery
05:19:21 DISPATCHER: Starting worker discovery
05:19:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:19:21 DISPATCHER: Finished worker discovery
05:19:32 WORKER: done with job (6, 0, 0), trying to register it.
05:19:32 DISPATCHER: job (6, 0, 0) finished
05:19:32 WORKER: registered result for job (6, 0, 0) with dispatcher
05:19:32 DISPATCHER: register_result: lock acquired
05:19:32 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
05:19:32 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 98, 'last_n_outputs': 16, 'lr': 0.001794714286492504, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.013298430860098135}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.8248903302638981, 'info': {'music-speech': 0.8248903302638981, 'config': "{'batch_size': 128, 'hidden_dim': 98, 'last_n_outputs': 16, 'lr': 0.001794714286492504, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.013298430860098135}"}}
exception: None

05:19:32 job_callback for (6, 0, 0) started
05:19:32 DISPATCHER: Trying to submit another job.
05:19:32 job_callback for (6, 0, 0) got condition
05:19:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:19:32 HBMASTER: Trying to run another job!
05:19:32 job_callback for (6, 0, 0) finished
05:19:32 HBMASTER: schedule new run for iteration 6
05:19:32 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
05:19:32 HBMASTER: submitting job (6, 0, 2) to dispatcher
05:19:32 DISPATCHER: trying to submit job (6, 0, 2)
05:19:32 DISPATCHER: trying to notify the job_runner thread.
05:19:32 HBMASTER: job (6, 0, 2) submitted to dispatcher
05:19:32 DISPATCHER: Trying to submit another job.
05:19:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:19:32 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
05:19:32 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
05:19:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:19:32 WORKER: start processing job (6, 0, 2)
05:19:32 WORKER: args: ()
05:19:32 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 89, 'last_n_outputs': 22, 'lr': 0.0040772820712030545, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.01122291640364351}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-531:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:20:21 DISPATCHER: Starting worker discovery
05:20:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:20:21 DISPATCHER: Finished worker discovery
05:21:21 DISPATCHER: Starting worker discovery
05:21:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:21:21 DISPATCHER: Finished worker discovery
05:22:21 DISPATCHER: Starting worker discovery
05:22:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:22:21 DISPATCHER: Finished worker discovery
05:23:21 DISPATCHER: Starting worker discovery
05:23:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:23:21 DISPATCHER: Finished worker discovery
05:24:21 DISPATCHER: Starting worker discovery
05:24:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:24:21 DISPATCHER: Finished worker discovery
05:25:21 DISPATCHER: Starting worker discovery
05:25:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:25:21 DISPATCHER: Finished worker discovery
05:26:21 DISPATCHER: Starting worker discovery
05:26:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:26:21 DISPATCHER: Finished worker discovery
05:27:21 DISPATCHER: Starting worker discovery
05:27:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:27:21 DISPATCHER: Finished worker discovery
05:28:21 DISPATCHER: Starting worker discovery
05:28:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:28:21 DISPATCHER: Finished worker discovery
05:29:21 DISPATCHER: Starting worker discovery
05:29:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:29:21 DISPATCHER: Finished worker discovery
05:30:21 DISPATCHER: Starting worker discovery
05:30:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:30:21 DISPATCHER: Finished worker discovery
05:31:21 DISPATCHER: Starting worker discovery
05:31:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:31:21 DISPATCHER: Finished worker discovery
05:32:21 DISPATCHER: Starting worker discovery
05:32:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:32:21 DISPATCHER: Finished worker discovery
05:33:21 DISPATCHER: Starting worker discovery
05:33:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:33:21 DISPATCHER: Finished worker discovery
05:34:21 DISPATCHER: Starting worker discovery
05:34:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:34:21 DISPATCHER: Finished worker discovery
05:35:21 DISPATCHER: Starting worker discovery
05:35:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:35:21 DISPATCHER: Finished worker discovery
05:36:21 DISPATCHER: Starting worker discovery
05:36:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:36:21 DISPATCHER: Finished worker discovery
05:37:21 DISPATCHER: Starting worker discovery
05:37:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:37:21 DISPATCHER: Finished worker discovery
05:38:21 DISPATCHER: Starting worker discovery
05:38:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:38:21 DISPATCHER: Finished worker discovery
05:39:21 DISPATCHER: Starting worker discovery
05:39:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:39:21 DISPATCHER: Finished worker discovery
05:39:41 WORKER: done with job (6, 0, 2), trying to register it.
05:39:41 WORKER: registered result for job (6, 0, 2) with dispatcher
05:39:41 DISPATCHER: job (6, 0, 2) finished
05:39:41 DISPATCHER: register_result: lock acquired
05:39:41 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
05:39:41 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 89, 'last_n_outputs': 22, 'lr': 0.0040772820712030545, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.01122291640364351}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.8048972871704899, 'info': {'music-speech': 0.8048972871704899, 'config': "{'batch_size': 16, 'hidden_dim': 89, 'last_n_outputs': 22, 'lr': 0.0040772820712030545, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 63, 'weight_decay': 0.01122291640364351}"}}
exception: None

05:39:41 job_callback for (6, 0, 2) started
05:39:41 DISPATCHER: Trying to submit another job.
05:39:41 job_callback for (6, 0, 2) got condition
05:39:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:39:41 HBMASTER: Trying to run another job!
05:39:41 job_callback for (6, 0, 2) finished
05:39:41 start sampling a new configuration.
05:39:41 done sampling a new configuration.
05:39:41 HBMASTER: schedule new run for iteration 7
05:39:41 HBMASTER: trying submitting job (7, 0, 0) to dispatcher
05:39:41 HBMASTER: submitting job (7, 0, 0) to dispatcher
05:39:41 DISPATCHER: trying to submit job (7, 0, 0)
05:39:41 DISPATCHER: trying to notify the job_runner thread.
05:39:41 HBMASTER: job (7, 0, 0) submitted to dispatcher
05:39:41 DISPATCHER: Trying to submit another job.
05:39:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:39:41 DISPATCHER: starting job (7, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
05:39:41 DISPATCHER: job (7, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
05:39:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:39:41 WORKER: start processing job (7, 0, 0)
05:39:41 WORKER: args: ()
05:39:41 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 22, 'last_n_outputs': 48, 'lr': 0.003056493735643488, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.030924692956637124}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-532:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

05:40:21 DISPATCHER: Starting worker discovery
05:40:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:40:21 DISPATCHER: Finished worker discovery
05:41:21 DISPATCHER: Starting worker discovery
05:41:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:41:21 DISPATCHER: Finished worker discovery
05:42:21 DISPATCHER: Starting worker discovery
05:42:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:42:21 DISPATCHER: Finished worker discovery
05:43:21 DISPATCHER: Starting worker discovery
05:43:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:43:21 DISPATCHER: Finished worker discovery
05:44:21 DISPATCHER: Starting worker discovery
05:44:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:44:21 DISPATCHER: Finished worker discovery
05:45:21 DISPATCHER: Starting worker discovery
05:45:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:45:21 DISPATCHER: Finished worker discovery
05:46:21 DISPATCHER: Starting worker discovery
05:46:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:46:21 DISPATCHER: Finished worker discovery
05:47:21 DISPATCHER: Starting worker discovery
05:47:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:47:21 DISPATCHER: Finished worker discovery
05:48:21 DISPATCHER: Starting worker discovery
05:48:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:48:21 DISPATCHER: Finished worker discovery
05:49:21 DISPATCHER: Starting worker discovery
05:49:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:49:21 DISPATCHER: Finished worker discovery
05:50:21 DISPATCHER: Starting worker discovery
05:50:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:50:21 DISPATCHER: Finished worker discovery
05:51:21 DISPATCHER: Starting worker discovery
05:51:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:51:21 DISPATCHER: Finished worker discovery
05:52:21 DISPATCHER: Starting worker discovery
05:52:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:52:21 DISPATCHER: Finished worker discovery
05:53:21 DISPATCHER: Starting worker discovery
05:53:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:53:21 DISPATCHER: Finished worker discovery
05:54:21 DISPATCHER: Starting worker discovery
05:54:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:54:21 DISPATCHER: Finished worker discovery
05:55:21 DISPATCHER: Starting worker discovery
05:55:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:55:21 DISPATCHER: Finished worker discovery
05:56:21 DISPATCHER: Starting worker discovery
05:56:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:56:21 DISPATCHER: Finished worker discovery
05:57:21 DISPATCHER: Starting worker discovery
05:57:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:57:21 DISPATCHER: Finished worker discovery
05:58:21 DISPATCHER: Starting worker discovery
05:58:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:58:21 DISPATCHER: Finished worker discovery
05:59:21 DISPATCHER: Starting worker discovery
05:59:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:59:21 DISPATCHER: Finished worker discovery
05:59:49 WORKER: done with job (7, 0, 0), trying to register it.
05:59:49 WORKER: registered result for job (7, 0, 0) with dispatcher
05:59:49 DISPATCHER: job (7, 0, 0) finished
05:59:49 DISPATCHER: register_result: lock acquired
05:59:49 DISPATCHER: job (7, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
05:59:49 job_id: (7, 0, 0)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 22, 'last_n_outputs': 48, 'lr': 0.003056493735643488, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.030924692956637124}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 22, 'last_n_outputs': 48, 'lr': 0.003056493735643488, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.030924692956637124}"}}
exception: None

05:59:49 job_callback for (7, 0, 0) started
05:59:49 DISPATCHER: Trying to submit another job.
05:59:49 job_callback for (7, 0, 0) got condition
05:59:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
05:59:49 HBMASTER: Trying to run another job!
05:59:49 job_callback for (7, 0, 0) finished
05:59:49 start sampling a new configuration.
05:59:49 best_vector: [2, 0.846604264223293, 0.7580361780433184, 0.3743256086602937, 0.30373003529911574, 0, 0.5510495548648401, 0.07274847134464835], 0.024563213887228704, 0.9016902395570704, 0.02214841021426681
05:59:49 done sampling a new configuration.
05:59:49 HBMASTER: schedule new run for iteration 7
05:59:49 HBMASTER: trying submitting job (7, 0, 1) to dispatcher
05:59:49 HBMASTER: submitting job (7, 0, 1) to dispatcher
05:59:49 DISPATCHER: trying to submit job (7, 0, 1)
05:59:49 DISPATCHER: trying to notify the job_runner thread.
05:59:49 HBMASTER: job (7, 0, 1) submitted to dispatcher
05:59:49 DISPATCHER: Trying to submit another job.
05:59:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
05:59:49 DISPATCHER: starting job (7, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
05:59:49 DISPATCHER: job (7, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
05:59:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
05:59:49 WORKER: start processing job (7, 0, 1)
05:59:49 WORKER: args: ()
05:59:49 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 88, 'last_n_outputs': 38, 'lr': 0.005605975782758126, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.012435061667774552}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-533:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:00:21 DISPATCHER: Starting worker discovery
06:00:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:00:21 DISPATCHER: Finished worker discovery
06:01:21 DISPATCHER: Starting worker discovery
06:01:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:01:21 DISPATCHER: Finished worker discovery
06:02:21 DISPATCHER: Starting worker discovery
06:02:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:02:21 DISPATCHER: Finished worker discovery
06:03:21 DISPATCHER: Starting worker discovery
06:03:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:03:21 DISPATCHER: Finished worker discovery
06:04:21 DISPATCHER: Starting worker discovery
06:04:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:04:21 DISPATCHER: Finished worker discovery
06:05:21 DISPATCHER: Starting worker discovery
06:05:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:05:21 DISPATCHER: Finished worker discovery
06:06:21 DISPATCHER: Starting worker discovery
06:06:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:06:21 DISPATCHER: Finished worker discovery
06:07:21 DISPATCHER: Starting worker discovery
06:07:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:07:21 DISPATCHER: Finished worker discovery
06:08:21 DISPATCHER: Starting worker discovery
06:08:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:08:21 DISPATCHER: Finished worker discovery
06:09:21 DISPATCHER: Starting worker discovery
06:09:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:09:21 DISPATCHER: Finished worker discovery
06:10:21 DISPATCHER: Starting worker discovery
06:10:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:10:21 DISPATCHER: Finished worker discovery
06:11:21 DISPATCHER: Starting worker discovery
06:11:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:11:21 DISPATCHER: Finished worker discovery
06:12:21 DISPATCHER: Starting worker discovery
06:12:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:12:21 DISPATCHER: Finished worker discovery
06:13:21 DISPATCHER: Starting worker discovery
06:13:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:13:21 DISPATCHER: Finished worker discovery
06:14:21 DISPATCHER: Starting worker discovery
06:14:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:14:21 DISPATCHER: Finished worker discovery
06:15:21 DISPATCHER: Starting worker discovery
06:15:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:15:21 DISPATCHER: Finished worker discovery
06:16:21 DISPATCHER: Starting worker discovery
06:16:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:16:21 DISPATCHER: Finished worker discovery
06:17:21 DISPATCHER: Starting worker discovery
06:17:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:17:21 DISPATCHER: Finished worker discovery
06:18:21 DISPATCHER: Starting worker discovery
06:18:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:18:21 DISPATCHER: Finished worker discovery
06:19:21 DISPATCHER: Starting worker discovery
06:19:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:19:21 DISPATCHER: Finished worker discovery
06:19:58 WORKER: done with job (7, 0, 1), trying to register it.
06:19:58 WORKER: registered result for job (7, 0, 1) with dispatcher
06:19:58 DISPATCHER: job (7, 0, 1) finished
06:19:58 DISPATCHER: register_result: lock acquired
06:19:58 DISPATCHER: job (7, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
06:19:58 job_id: (7, 0, 1)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 88, 'last_n_outputs': 38, 'lr': 0.005605975782758126, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.012435061667774552}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.831824203986515, 'info': {'music-speech': 0.831824203986515, 'config': "{'batch_size': 64, 'hidden_dim': 88, 'last_n_outputs': 38, 'lr': 0.005605975782758126, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 60, 'weight_decay': 0.012435061667774552}"}}
exception: None

06:19:58 job_callback for (7, 0, 1) started
06:19:58 DISPATCHER: Trying to submit another job.
06:19:58 job_callback for (7, 0, 1) got condition
06:19:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:19:58 HBMASTER: Trying to run another job!
06:19:58 job_callback for (7, 0, 1) finished
06:19:58 start sampling a new configuration.
06:19:58 best_vector: [0, 0.9396513034740644, 0.44520945657571276, 0.2653419232952452, 0.37759049772562037, 0, 0.042313299658422954, 0.3030697010244531], 0.017000830313641815, 0.2957260395639543, 0.005027588217952113
06:19:58 done sampling a new configuration.
06:19:58 HBMASTER: schedule new run for iteration 7
06:19:58 HBMASTER: trying submitting job (7, 0, 2) to dispatcher
06:19:58 HBMASTER: submitting job (7, 0, 2) to dispatcher
06:19:58 DISPATCHER: trying to submit job (7, 0, 2)
06:19:58 DISPATCHER: trying to notify the job_runner thread.
06:19:58 HBMASTER: job (7, 0, 2) submitted to dispatcher
06:19:58 DISPATCHER: Trying to submit another job.
06:19:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:19:58 DISPATCHER: starting job (7, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
06:19:58 DISPATCHER: job (7, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
06:19:58 WORKER: start processing job (7, 0, 2)
06:19:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:19:58 WORKER: args: ()
06:19:58 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 96, 'last_n_outputs': 23, 'lr': 0.003393781255060662, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.02479149814072057}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-534:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:20:21 DISPATCHER: Starting worker discovery
06:20:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:20:21 DISPATCHER: Finished worker discovery
06:21:21 DISPATCHER: Starting worker discovery
06:21:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:21:21 DISPATCHER: Finished worker discovery
06:22:21 DISPATCHER: Starting worker discovery
06:22:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:22:21 DISPATCHER: Finished worker discovery
06:23:21 DISPATCHER: Starting worker discovery
06:23:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:23:21 DISPATCHER: Finished worker discovery
06:24:21 DISPATCHER: Starting worker discovery
06:24:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:24:21 DISPATCHER: Finished worker discovery
06:25:21 DISPATCHER: Starting worker discovery
06:25:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:25:21 DISPATCHER: Finished worker discovery
06:26:21 DISPATCHER: Starting worker discovery
06:26:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:26:21 DISPATCHER: Finished worker discovery
06:27:21 DISPATCHER: Starting worker discovery
06:27:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:27:21 DISPATCHER: Finished worker discovery
06:28:21 DISPATCHER: Starting worker discovery
06:28:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:28:21 DISPATCHER: Finished worker discovery
06:29:21 DISPATCHER: Starting worker discovery
06:29:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:29:21 DISPATCHER: Finished worker discovery
06:30:21 DISPATCHER: Starting worker discovery
06:30:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:30:21 DISPATCHER: Finished worker discovery
06:31:21 DISPATCHER: Starting worker discovery
06:31:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:31:21 DISPATCHER: Finished worker discovery
06:32:21 DISPATCHER: Starting worker discovery
06:32:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:32:21 DISPATCHER: Finished worker discovery
06:33:21 DISPATCHER: Starting worker discovery
06:33:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:33:21 DISPATCHER: Finished worker discovery
06:34:21 DISPATCHER: Starting worker discovery
06:34:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:34:21 DISPATCHER: Finished worker discovery
06:35:21 DISPATCHER: Starting worker discovery
06:35:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:35:21 DISPATCHER: Finished worker discovery
06:36:21 DISPATCHER: Starting worker discovery
06:36:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:36:21 DISPATCHER: Finished worker discovery
06:37:21 DISPATCHER: Starting worker discovery
06:37:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:37:21 DISPATCHER: Finished worker discovery
06:38:21 DISPATCHER: Starting worker discovery
06:38:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:38:21 DISPATCHER: Finished worker discovery
06:39:21 DISPATCHER: Starting worker discovery
06:39:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:39:21 DISPATCHER: Finished worker discovery
06:40:07 WORKER: done with job (7, 0, 2), trying to register it.
06:40:07 DISPATCHER: job (7, 0, 2) finished
06:40:07 WORKER: registered result for job (7, 0, 2) with dispatcher
06:40:07 DISPATCHER: register_result: lock acquired
06:40:07 DISPATCHER: job (7, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
06:40:07 job_id: (7, 0, 2)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 96, 'last_n_outputs': 23, 'lr': 0.003393781255060662, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.02479149814072057}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.7315104456438491, 'info': {'music-speech': 0.7315104456438491, 'config': "{'batch_size': 16, 'hidden_dim': 96, 'last_n_outputs': 23, 'lr': 0.003393781255060662, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.02479149814072057}"}}
exception: None

06:40:07 job_callback for (7, 0, 2) started
06:40:07 DISPATCHER: Trying to submit another job.
06:40:07 job_callback for (7, 0, 2) got condition
06:40:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
06:40:07 HBMASTER: Trying to run another job!
06:40:07 job_callback for (7, 0, 2) finished
06:40:07 start sampling a new configuration.
06:40:07 best_vector: [2, 0.8620959765532022, 0.7117372691926777, 0.35507367980023574, 0.3552979842398305, 0, 0.32280933774440457, 0.15620975248711194], 0.020642509416224482, 0.6150124081345357, 0.012695399426012048
06:40:07 done sampling a new configuration.
06:40:07 HBMASTER: schedule new run for iteration 7
06:40:07 HBMASTER: trying submitting job (7, 0, 3) to dispatcher
06:40:07 HBMASTER: submitting job (7, 0, 3) to dispatcher
06:40:07 DISPATCHER: trying to submit job (7, 0, 3)
06:40:07 DISPATCHER: trying to notify the job_runner thread.
06:40:07 HBMASTER: job (7, 0, 3) submitted to dispatcher
06:40:07 DISPATCHER: Trying to submit another job.
06:40:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
06:40:07 DISPATCHER: starting job (7, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
06:40:07 DISPATCHER: job (7, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
06:40:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
06:40:07 WORKER: start processing job (7, 0, 3)
06:40:07 WORKER: args: ()
06:40:07 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 89, 'last_n_outputs': 36, 'lr': 0.005130354314979586, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.015967376787420683}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-535:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

06:40:21 DISPATCHER: Starting worker discovery
06:40:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:40:21 DISPATCHER: Finished worker discovery
06:41:21 DISPATCHER: Starting worker discovery
06:41:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:41:21 DISPATCHER: Finished worker discovery
06:42:21 DISPATCHER: Starting worker discovery
06:42:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:42:21 DISPATCHER: Finished worker discovery
06:43:21 DISPATCHER: Starting worker discovery
06:43:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:43:21 DISPATCHER: Finished worker discovery
06:44:21 DISPATCHER: Starting worker discovery
06:44:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:44:21 DISPATCHER: Finished worker discovery
06:45:21 DISPATCHER: Starting worker discovery
06:45:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:45:21 DISPATCHER: Finished worker discovery
06:46:21 DISPATCHER: Starting worker discovery
06:46:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:46:21 DISPATCHER: Finished worker discovery
06:47:21 DISPATCHER: Starting worker discovery
06:47:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:47:21 DISPATCHER: Finished worker discovery
06:48:21 DISPATCHER: Starting worker discovery
06:48:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:48:21 DISPATCHER: Finished worker discovery
06:49:21 DISPATCHER: Starting worker discovery
06:49:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:49:21 DISPATCHER: Finished worker discovery
06:50:21 DISPATCHER: Starting worker discovery
06:50:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:50:21 DISPATCHER: Finished worker discovery
06:51:21 DISPATCHER: Starting worker discovery
06:51:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:51:21 DISPATCHER: Finished worker discovery
06:52:21 DISPATCHER: Starting worker discovery
06:52:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:52:21 DISPATCHER: Finished worker discovery
06:53:21 DISPATCHER: Starting worker discovery
06:53:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:53:21 DISPATCHER: Finished worker discovery
06:54:21 DISPATCHER: Starting worker discovery
06:54:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:54:21 DISPATCHER: Finished worker discovery
06:55:21 DISPATCHER: Starting worker discovery
06:55:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:55:21 DISPATCHER: Finished worker discovery
06:56:21 DISPATCHER: Starting worker discovery
06:56:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:56:21 DISPATCHER: Finished worker discovery
06:57:21 DISPATCHER: Starting worker discovery
06:57:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:57:21 DISPATCHER: Finished worker discovery
06:58:21 DISPATCHER: Starting worker discovery
06:58:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:58:21 DISPATCHER: Finished worker discovery
06:59:21 DISPATCHER: Starting worker discovery
06:59:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:59:21 DISPATCHER: Finished worker discovery
07:00:16 WORKER: done with job (7, 0, 3), trying to register it.
07:00:16 WORKER: registered result for job (7, 0, 3) with dispatcher
07:00:16 DISPATCHER: job (7, 0, 3) finished
07:00:16 DISPATCHER: register_result: lock acquired
07:00:16 DISPATCHER: job (7, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:00:16 job_id: (7, 0, 3)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 89, 'last_n_outputs': 36, 'lr': 0.005130354314979586, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.015967376787420683}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.6547917613330887, 'info': {'music-speech': 0.6547917613330887, 'config': "{'batch_size': 64, 'hidden_dim': 89, 'last_n_outputs': 36, 'lr': 0.005130354314979586, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 39, 'weight_decay': 0.015967376787420683}"}}
exception: None

07:00:16 job_callback for (7, 0, 3) started
07:00:16 DISPATCHER: Trying to submit another job.
07:00:16 job_callback for (7, 0, 3) got condition
07:00:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:00:16 HBMASTER: Trying to run another job!
07:00:16 job_callback for (7, 0, 3) finished
07:00:16 start sampling a new configuration.
07:00:16 best_vector: [2, 0.9150585866153965, 0.16013999121735986, 0.10598278413734316, 0.328553687655171, 0, 0.5182560747918081, 0.22561806147405183], 0.005632507812038738, 1.5970906149201485, 0.008995625365071487
07:00:16 done sampling a new configuration.
07:00:16 HBMASTER: schedule new run for iteration 8
07:00:16 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
07:00:16 HBMASTER: submitting job (8, 0, 0) to dispatcher
07:00:16 DISPATCHER: trying to submit job (8, 0, 0)
07:00:16 DISPATCHER: trying to notify the job_runner thread.
07:00:16 HBMASTER: job (8, 0, 0) submitted to dispatcher
07:00:16 DISPATCHER: Trying to submit another job.
07:00:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:00:16 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:00:16 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:00:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:00:16 WORKER: start processing job (8, 0, 0)
07:00:16 WORKER: args: ()
07:00:16 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 9, 'lr': 0.0016291668639488728, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.01965784315149041}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:00:21 DISPATCHER: Starting worker discovery
07:00:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:00:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-536:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:01:09 WORKER: done with job (8, 0, 0), trying to register it.
07:01:09 WORKER: registered result for job (8, 0, 0) with dispatcher
07:01:09 DISPATCHER: job (8, 0, 0) finished
07:01:09 DISPATCHER: register_result: lock acquired
07:01:09 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:01:09 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 9, 'lr': 0.0016291668639488728, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.01965784315149041}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7903226243776426, 'info': {'music-speech': 0.7903226243776426, 'config': "{'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 9, 'lr': 0.0016291668639488728, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.01965784315149041}"}}
exception: None

07:01:09 job_callback for (8, 0, 0) started
07:01:09 DISPATCHER: Trying to submit another job.
07:01:09 job_callback for (8, 0, 0) got condition
07:01:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:01:09 HBMASTER: Trying to run another job!
07:01:09 job_callback for (8, 0, 0) finished
07:01:09 start sampling a new configuration.
07:01:09 best_vector: [1, 0.9870090630296169, 0.07249352184487129, 0.4040584033304525, 0.5157187184499845, 0, 0.8573915114283481, 0.27418815320445167], 0.021553896433365517, 2.1924446385560272, 0.04725572467532411
07:01:09 done sampling a new configuration.
07:01:09 HBMASTER: schedule new run for iteration 8
07:01:09 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
07:01:09 HBMASTER: submitting job (8, 0, 1) to dispatcher
07:01:09 DISPATCHER: trying to submit job (8, 0, 1)
07:01:09 DISPATCHER: trying to notify the job_runner thread.
07:01:09 HBMASTER: job (8, 0, 1) submitted to dispatcher
07:01:09 DISPATCHER: Trying to submit another job.
07:01:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:01:09 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:01:09 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:01:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:01:09 WORKER: start processing job (8, 0, 1)
07:01:09 WORKER: args: ()
07:01:09 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 4, 'lr': 0.006428605961023538, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.02273667802536862}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:01:22 DISPATCHER: Starting worker discovery
07:01:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:01:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-537:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:02:02 WORKER: done with job (8, 0, 1), trying to register it.
07:02:02 WORKER: registered result for job (8, 0, 1) with dispatcher
07:02:02 DISPATCHER: job (8, 0, 1) finished
07:02:02 DISPATCHER: register_result: lock acquired
07:02:02 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:02:02 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 4, 'lr': 0.006428605961023538, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.02273667802536862}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.781509230013058, 'info': {'music-speech': 0.781509230013058, 'config': "{'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 4, 'lr': 0.006428605961023538, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 88, 'weight_decay': 0.02273667802536862}"}}
exception: None

07:02:02 job_callback for (8, 0, 1) started
07:02:02 job_callback for (8, 0, 1) got condition
07:02:02 DISPATCHER: Trying to submit another job.
07:02:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:02:02 HBMASTER: Trying to run another job!
07:02:02 job_callback for (8, 0, 1) finished
07:02:02 start sampling a new configuration.
07:02:02 done sampling a new configuration.
07:02:02 HBMASTER: schedule new run for iteration 8
07:02:02 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
07:02:02 HBMASTER: submitting job (8, 0, 2) to dispatcher
07:02:02 DISPATCHER: trying to submit job (8, 0, 2)
07:02:02 DISPATCHER: trying to notify the job_runner thread.
07:02:02 HBMASTER: job (8, 0, 2) submitted to dispatcher
07:02:02 DISPATCHER: Trying to submit another job.
07:02:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:02:02 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:02:02 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:02:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:02:02 WORKER: start processing job (8, 0, 2)
07:02:02 WORKER: args: ()
07:02:02 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 100, 'last_n_outputs': 43, 'lr': 0.042214200058394255, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.0649206345922886}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-538:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:02:22 DISPATCHER: Starting worker discovery
07:02:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:02:22 DISPATCHER: Finished worker discovery
07:02:55 WORKER: done with job (8, 0, 2), trying to register it.
07:02:55 WORKER: registered result for job (8, 0, 2) with dispatcher
07:02:55 DISPATCHER: job (8, 0, 2) finished
07:02:55 DISPATCHER: register_result: lock acquired
07:02:55 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:02:55 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 100, 'last_n_outputs': 43, 'lr': 0.042214200058394255, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.0649206345922886}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2714239239647983, 'info': {'music-speech': 0.2714239239647983, 'config': "{'batch_size': 64, 'hidden_dim': 100, 'last_n_outputs': 43, 'lr': 0.042214200058394255, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.0649206345922886}"}}
exception: None

07:02:55 job_callback for (8, 0, 2) started
07:02:55 DISPATCHER: Trying to submit another job.
07:02:55 job_callback for (8, 0, 2) got condition
07:02:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:02:55 HBMASTER: Trying to run another job!
07:02:55 job_callback for (8, 0, 2) finished
07:02:55 start sampling a new configuration.
07:02:55 best_vector: [0, 0.9880217328818459, 0.07954078633008049, 0.12504813668929946, 0.3593875406713894, 0, 0.9906563586753135, 0.2907577730842811], 0.007759236692468144, 1.5372119888875253, 0.01192759166827802
07:02:55 done sampling a new configuration.
07:02:55 HBMASTER: schedule new run for iteration 8
07:02:55 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
07:02:55 HBMASTER: submitting job (8, 0, 3) to dispatcher
07:02:55 DISPATCHER: trying to submit job (8, 0, 3)
07:02:55 DISPATCHER: trying to notify the job_runner thread.
07:02:55 HBMASTER: job (8, 0, 3) submitted to dispatcher
07:02:55 DISPATCHER: Trying to submit another job.
07:02:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:02:55 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:02:55 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:02:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:02:55 WORKER: start processing job (8, 0, 3)
07:02:55 WORKER: args: ()
07:02:55 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 4, 'lr': 0.001778673658529631, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.023893764793741733}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-539:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:03:22 DISPATCHER: Starting worker discovery
07:03:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:03:22 DISPATCHER: Finished worker discovery
07:03:48 WORKER: done with job (8, 0, 3), trying to register it.
07:03:48 WORKER: registered result for job (8, 0, 3) with dispatcher
07:03:48 DISPATCHER: job (8, 0, 3) finished
07:03:48 DISPATCHER: register_result: lock acquired
07:03:48 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:03:48 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 4, 'lr': 0.001778673658529631, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.023893764793741733}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8277907792081108, 'info': {'music-speech': 0.8277907792081108, 'config': "{'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 4, 'lr': 0.001778673658529631, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.023893764793741733}"}}
exception: None

07:03:48 job_callback for (8, 0, 3) started
07:03:48 DISPATCHER: Trying to submit another job.
07:03:48 job_callback for (8, 0, 3) got condition
07:03:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:03:48 HBMASTER: Trying to run another job!
07:03:48 job_callback for (8, 0, 3) finished
07:03:48 start sampling a new configuration.
07:03:48 done sampling a new configuration.
07:03:48 HBMASTER: schedule new run for iteration 8
07:03:48 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
07:03:48 HBMASTER: submitting job (8, 0, 4) to dispatcher
07:03:48 DISPATCHER: trying to submit job (8, 0, 4)
07:03:48 DISPATCHER: trying to notify the job_runner thread.
07:03:48 HBMASTER: job (8, 0, 4) submitted to dispatcher
07:03:48 DISPATCHER: Trying to submit another job.
07:03:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:03:48 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:03:48 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:03:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:03:48 WORKER: start processing job (8, 0, 4)
07:03:48 WORKER: args: ()
07:03:48 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 51, 'last_n_outputs': 32, 'lr': 0.006833057728694011, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 53, 'weight_decay': 0.19801021654891515}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-540:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:04:22 DISPATCHER: Starting worker discovery
07:04:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:04:22 DISPATCHER: Finished worker discovery
07:04:41 WORKER: done with job (8, 0, 4), trying to register it.
07:04:41 WORKER: registered result for job (8, 0, 4) with dispatcher
07:04:41 DISPATCHER: job (8, 0, 4) finished
07:04:41 DISPATCHER: register_result: lock acquired
07:04:41 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:04:41 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 51, 'last_n_outputs': 32, 'lr': 0.006833057728694011, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 53, 'weight_decay': 0.19801021654891515}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 51, 'last_n_outputs': 32, 'lr': 0.006833057728694011, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 53, 'weight_decay': 0.19801021654891515}"}}
exception: None

07:04:41 job_callback for (8, 0, 4) started
07:04:41 DISPATCHER: Trying to submit another job.
07:04:41 job_callback for (8, 0, 4) got condition
07:04:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:04:41 HBMASTER: Trying to run another job!
07:04:41 job_callback for (8, 0, 4) finished
07:04:41 start sampling a new configuration.
07:04:41 best_vector: [1, 0.23779188936906903, 0.34586112162220534, 0.2618873027335888, 0.40727128831419696, 0, 0.35490569490765794, 0.7227497626525439], 0.023927620367019772, 0.7483669628430696, 0.017906640582128562
07:04:41 done sampling a new configuration.
07:04:41 HBMASTER: schedule new run for iteration 8
07:04:41 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
07:04:41 HBMASTER: submitting job (8, 0, 5) to dispatcher
07:04:41 DISPATCHER: trying to submit job (8, 0, 5)
07:04:41 DISPATCHER: trying to notify the job_runner thread.
07:04:41 HBMASTER: job (8, 0, 5) submitted to dispatcher
07:04:41 DISPATCHER: Trying to submit another job.
07:04:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:04:41 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:04:41 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:04:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:04:41 WORKER: start processing job (8, 0, 5)
07:04:41 WORKER: args: ()
07:04:41 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 39, 'last_n_outputs': 18, 'lr': 0.0033402164111182406, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.08716038111659165}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-541:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:05:22 DISPATCHER: Starting worker discovery
07:05:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:05:22 DISPATCHER: Finished worker discovery
07:05:34 WORKER: done with job (8, 0, 5), trying to register it.
07:05:34 WORKER: registered result for job (8, 0, 5) with dispatcher
07:05:34 DISPATCHER: job (8, 0, 5) finished
07:05:34 DISPATCHER: register_result: lock acquired
07:05:34 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:05:34 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 39, 'last_n_outputs': 18, 'lr': 0.0033402164111182406, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.08716038111659165}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9226814721680241, 'info': {'music-speech': 0.9226814721680241, 'config': "{'batch_size': 32, 'hidden_dim': 39, 'last_n_outputs': 18, 'lr': 0.0033402164111182406, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.08716038111659165}"}}
exception: None

07:05:34 job_callback for (8, 0, 5) started
07:05:34 DISPATCHER: Trying to submit another job.
07:05:34 job_callback for (8, 0, 5) got condition
07:05:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:05:34 HBMASTER: Trying to run another job!
07:05:34 job_callback for (8, 0, 5) finished
07:05:34 start sampling a new configuration.
07:05:34 best_vector: [1, 0.8818578524357616, 0.5560419698648694, 0.12191478658919214, 0.26891671870024425, 0, 0.3183404384937214, 0.06179925113012463], 0.014388915914286943, 0.4795017431145894, 0.0068995102624298445
07:05:34 done sampling a new configuration.
07:05:34 HBMASTER: schedule new run for iteration 8
07:05:34 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
07:05:34 HBMASTER: submitting job (8, 0, 6) to dispatcher
07:05:34 DISPATCHER: trying to submit job (8, 0, 6)
07:05:34 DISPATCHER: trying to notify the job_runner thread.
07:05:34 HBMASTER: job (8, 0, 6) submitted to dispatcher
07:05:34 DISPATCHER: Trying to submit another job.
07:05:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:05:34 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:05:34 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:05:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:05:34 WORKER: start processing job (8, 0, 6)
07:05:34 WORKER: args: ()
07:05:34 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 91, 'last_n_outputs': 28, 'lr': 0.0017531923751203417, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.012033796955495167}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-542:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:06:22 DISPATCHER: Starting worker discovery
07:06:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:06:22 DISPATCHER: Finished worker discovery
07:06:27 WORKER: done with job (8, 0, 6), trying to register it.
07:06:27 WORKER: registered result for job (8, 0, 6) with dispatcher
07:06:27 DISPATCHER: job (8, 0, 6) finished
07:06:27 DISPATCHER: register_result: lock acquired
07:06:27 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:06:27 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 91, 'last_n_outputs': 28, 'lr': 0.0017531923751203417, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.012033796955495167}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5892164613525117, 'info': {'music-speech': 0.5892164613525117, 'config': "{'batch_size': 32, 'hidden_dim': 91, 'last_n_outputs': 28, 'lr': 0.0017531923751203417, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 38, 'weight_decay': 0.012033796955495167}"}}
exception: None

07:06:27 job_callback for (8, 0, 6) started
07:06:27 DISPATCHER: Trying to submit another job.
07:06:27 job_callback for (8, 0, 6) got condition
07:06:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:06:27 HBMASTER: Trying to run another job!
07:06:27 job_callback for (8, 0, 6) finished
07:06:27 start sampling a new configuration.
07:06:27 done sampling a new configuration.
07:06:27 HBMASTER: schedule new run for iteration 8
07:06:27 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
07:06:27 HBMASTER: submitting job (8, 0, 7) to dispatcher
07:06:27 DISPATCHER: trying to submit job (8, 0, 7)
07:06:27 DISPATCHER: trying to notify the job_runner thread.
07:06:27 HBMASTER: job (8, 0, 7) submitted to dispatcher
07:06:27 DISPATCHER: Trying to submit another job.
07:06:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:06:27 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:06:27 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:06:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:06:27 WORKER: start processing job (8, 0, 7)
07:06:27 WORKER: args: ()
07:06:27 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 63, 'last_n_outputs': 46, 'lr': 0.05013380989309154, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.027530280418981572}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-543:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:07:20 WORKER: done with job (8, 0, 7), trying to register it.
07:07:20 WORKER: registered result for job (8, 0, 7) with dispatcher
07:07:20 DISPATCHER: job (8, 0, 7) finished
07:07:20 DISPATCHER: register_result: lock acquired
07:07:20 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:07:20 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 63, 'last_n_outputs': 46, 'lr': 0.05013380989309154, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.027530280418981572}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 32, 'hidden_dim': 63, 'last_n_outputs': 46, 'lr': 0.05013380989309154, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 26, 'weight_decay': 0.027530280418981572}"}}
exception: None

07:07:20 job_callback for (8, 0, 7) started
07:07:20 DISPATCHER: Trying to submit another job.
07:07:20 job_callback for (8, 0, 7) got condition
07:07:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:07:20 HBMASTER: Trying to run another job!
07:07:20 job_callback for (8, 0, 7) finished
07:07:20 start sampling a new configuration.
07:07:20 done sampling a new configuration.
07:07:20 HBMASTER: schedule new run for iteration 8
07:07:20 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
07:07:20 HBMASTER: submitting job (8, 0, 8) to dispatcher
07:07:20 DISPATCHER: trying to submit job (8, 0, 8)
07:07:20 DISPATCHER: trying to notify the job_runner thread.
07:07:20 HBMASTER: job (8, 0, 8) submitted to dispatcher
07:07:20 DISPATCHER: Trying to submit another job.
07:07:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:07:20 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:07:20 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:07:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:07:20 WORKER: start processing job (8, 0, 8)
07:07:20 WORKER: args: ()
07:07:20 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 16, 'lr': 0.005747672886562264, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.05541767240402749}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:07:22 DISPATCHER: Starting worker discovery
07:07:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:07:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-544:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:08:13 WORKER: done with job (8, 0, 8), trying to register it.
07:08:13 WORKER: registered result for job (8, 0, 8) with dispatcher
07:08:13 DISPATCHER: job (8, 0, 8) finished
07:08:13 DISPATCHER: register_result: lock acquired
07:08:13 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:08:13 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 16, 'lr': 0.005747672886562264, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.05541767240402749}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 69, 'last_n_outputs': 16, 'lr': 0.005747672886562264, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 67, 'weight_decay': 0.05541767240402749}"}}
exception: None

07:08:13 job_callback for (8, 0, 8) started
07:08:13 DISPATCHER: Trying to submit another job.
07:08:13 job_callback for (8, 0, 8) got condition
07:08:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:08:13 HBMASTER: Trying to run another job!
07:08:13 job_callback for (8, 0, 8) finished
07:08:13 start sampling a new configuration.
07:08:13 best_vector: [1, 0.9889873081030197, 0.026190945950717026, 0.24269464748661546, 0.562624562498665, 0, 0.9970923803635448, 0.23314991579063185], 0.008875746238195177, 2.0107261328483284, 0.017846694909669288
07:08:13 done sampling a new configuration.
07:08:13 HBMASTER: schedule new run for iteration 8
07:08:13 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
07:08:13 HBMASTER: submitting job (8, 0, 9) to dispatcher
07:08:13 DISPATCHER: trying to submit job (8, 0, 9)
07:08:13 DISPATCHER: trying to notify the job_runner thread.
07:08:13 HBMASTER: job (8, 0, 9) submitted to dispatcher
07:08:13 DISPATCHER: Trying to submit another job.
07:08:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:08:13 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:08:13 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:08:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:08:13 WORKER: start processing job (8, 0, 9)
07:08:13 WORKER: args: ()
07:08:13 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 100, 'last_n_outputs': 2, 'lr': 0.0030576607257632193, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.02010643313457557}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:08:22 DISPATCHER: Starting worker discovery
07:08:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:08:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-545:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:09:06 WORKER: done with job (8, 0, 9), trying to register it.
07:09:06 WORKER: registered result for job (8, 0, 9) with dispatcher
07:09:06 DISPATCHER: job (8, 0, 9) finished
07:09:06 DISPATCHER: register_result: lock acquired
07:09:06 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:09:06 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 100, 'last_n_outputs': 2, 'lr': 0.0030576607257632193, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.02010643313457557}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7085160676135308, 'info': {'music-speech': 0.7085160676135308, 'config': "{'batch_size': 32, 'hidden_dim': 100, 'last_n_outputs': 2, 'lr': 0.0030576607257632193, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.02010643313457557}"}}
exception: None

07:09:06 job_callback for (8, 0, 9) started
07:09:06 job_callback for (8, 0, 9) got condition
07:09:06 DISPATCHER: Trying to submit another job.
07:09:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:09:06 HBMASTER: Trying to run another job!
07:09:06 job_callback for (8, 0, 9) finished
07:09:06 start sampling a new configuration.
07:09:06 done sampling a new configuration.
07:09:06 HBMASTER: schedule new run for iteration 8
07:09:06 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
07:09:06 HBMASTER: submitting job (8, 0, 10) to dispatcher
07:09:06 DISPATCHER: trying to submit job (8, 0, 10)
07:09:06 DISPATCHER: trying to notify the job_runner thread.
07:09:06 HBMASTER: job (8, 0, 10) submitted to dispatcher
07:09:06 DISPATCHER: Trying to submit another job.
07:09:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:09:06 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:09:06 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:09:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:09:06 WORKER: start processing job (8, 0, 10)
07:09:06 WORKER: args: ()
07:09:06 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 69, 'last_n_outputs': 27, 'lr': 0.0013863942900447142, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.08021324070496097}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:09:22 DISPATCHER: Starting worker discovery
07:09:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:09:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-546:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:09:59 WORKER: done with job (8, 0, 10), trying to register it.
07:09:59 WORKER: registered result for job (8, 0, 10) with dispatcher
07:09:59 DISPATCHER: job (8, 0, 10) finished
07:09:59 DISPATCHER: register_result: lock acquired
07:09:59 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:09:59 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 69, 'last_n_outputs': 27, 'lr': 0.0013863942900447142, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.08021324070496097}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 69, 'last_n_outputs': 27, 'lr': 0.0013863942900447142, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 54, 'weight_decay': 0.08021324070496097}"}}
exception: None

07:09:59 job_callback for (8, 0, 10) started
07:09:59 DISPATCHER: Trying to submit another job.
07:09:59 job_callback for (8, 0, 10) got condition
07:09:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:09:59 HBMASTER: Trying to run another job!
07:09:59 job_callback for (8, 0, 10) finished
07:09:59 start sampling a new configuration.
07:09:59 best_vector: [2, 0.15762420795421828, 0.08788671778502644, 0.14244268699460758, 0.39663128301190376, 0, 0.4737931663924368, 0.6171558476800516], 0.05988021443718533, 0.06038919984012931, 0.003616118236116981
07:09:59 done sampling a new configuration.
07:09:59 HBMASTER: schedule new run for iteration 8
07:09:59 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
07:09:59 HBMASTER: submitting job (8, 0, 11) to dispatcher
07:09:59 DISPATCHER: trying to submit job (8, 0, 11)
07:09:59 DISPATCHER: trying to notify the job_runner thread.
07:09:59 HBMASTER: job (8, 0, 11) submitted to dispatcher
07:09:59 DISPATCHER: Trying to submit another job.
07:09:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:09:59 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:09:59 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:09:59 WORKER: start processing job (8, 0, 11)
07:09:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:09:59 WORKER: args: ()
07:09:59 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 32, 'last_n_outputs': 5, 'lr': 0.0019270162368304497, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 53, 'weight_decay': 0.06352406329873396}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-547:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:10:22 DISPATCHER: Starting worker discovery
07:10:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:10:22 DISPATCHER: Finished worker discovery
07:10:52 WORKER: done with job (8, 0, 11), trying to register it.
07:10:53 WORKER: registered result for job (8, 0, 11) with dispatcher
07:10:53 DISPATCHER: job (8, 0, 11) finished
07:10:53 DISPATCHER: register_result: lock acquired
07:10:53 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:10:53 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 32, 'last_n_outputs': 5, 'lr': 0.0019270162368304497, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 53, 'weight_decay': 0.06352406329873396}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7008834389652213, 'info': {'music-speech': 0.7008834389652213, 'config': "{'batch_size': 64, 'hidden_dim': 32, 'last_n_outputs': 5, 'lr': 0.0019270162368304497, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 53, 'weight_decay': 0.06352406329873396}"}}
exception: None

07:10:53 job_callback for (8, 0, 11) started
07:10:53 DISPATCHER: Trying to submit another job.
07:10:53 job_callback for (8, 0, 11) got condition
07:10:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:10:53 HBMASTER: Trying to run another job!
07:10:53 job_callback for (8, 0, 11) finished
07:10:53 start sampling a new configuration.
07:10:53 best_vector: [3, 0.9175324681481061, 0.3112199176414744, 0.07095630108552975, 0.5019899784272329, 0, 0.26106928994920736, 0.12998378468309035], 0.00791926409861834, 0.3225154574718823, 0.0025540850836065477
07:10:53 done sampling a new configuration.
07:10:53 HBMASTER: schedule new run for iteration 8
07:10:53 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
07:10:53 HBMASTER: submitting job (8, 0, 12) to dispatcher
07:10:53 DISPATCHER: trying to submit job (8, 0, 12)
07:10:53 DISPATCHER: trying to notify the job_runner thread.
07:10:53 HBMASTER: job (8, 0, 12) submitted to dispatcher
07:10:53 DISPATCHER: Trying to submit another job.
07:10:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:10:53 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:10:53 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:10:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:10:53 WORKER: start processing job (8, 0, 12)
07:10:53 WORKER: args: ()
07:10:53 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 94, 'last_n_outputs': 16, 'lr': 0.0013864767849064766, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 33, 'weight_decay': 0.014760898802665616}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-548:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:11:22 DISPATCHER: Starting worker discovery
07:11:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:11:22 DISPATCHER: Finished worker discovery
07:11:46 WORKER: done with job (8, 0, 12), trying to register it.
07:11:46 WORKER: registered result for job (8, 0, 12) with dispatcher
07:11:46 DISPATCHER: job (8, 0, 12) finished
07:11:46 DISPATCHER: register_result: lock acquired
07:11:46 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:11:46 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 94, 'last_n_outputs': 16, 'lr': 0.0013864767849064766, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 33, 'weight_decay': 0.014760898802665616}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9216565794194655, 'info': {'music-speech': 0.9216565794194655, 'config': "{'batch_size': 128, 'hidden_dim': 94, 'last_n_outputs': 16, 'lr': 0.0013864767849064766, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 33, 'weight_decay': 0.014760898802665616}"}}
exception: None

07:11:46 job_callback for (8, 0, 12) started
07:11:46 DISPATCHER: Trying to submit another job.
07:11:46 job_callback for (8, 0, 12) got condition
07:11:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:11:46 HBMASTER: Trying to run another job!
07:11:46 job_callback for (8, 0, 12) finished
07:11:46 start sampling a new configuration.
07:11:46 done sampling a new configuration.
07:11:46 HBMASTER: schedule new run for iteration 8
07:11:46 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
07:11:46 HBMASTER: submitting job (8, 0, 13) to dispatcher
07:11:46 DISPATCHER: trying to submit job (8, 0, 13)
07:11:46 DISPATCHER: trying to notify the job_runner thread.
07:11:46 HBMASTER: job (8, 0, 13) submitted to dispatcher
07:11:46 DISPATCHER: Trying to submit another job.
07:11:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:11:46 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:11:46 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:11:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:11:46 WORKER: start processing job (8, 0, 13)
07:11:46 WORKER: args: ()
07:11:46 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 79, 'last_n_outputs': 40, 'lr': 0.01191773012003012, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.02509021963926106}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-549:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:12:22 DISPATCHER: Starting worker discovery
07:12:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:12:22 DISPATCHER: Finished worker discovery
07:12:39 WORKER: done with job (8, 0, 13), trying to register it.
07:12:39 WORKER: registered result for job (8, 0, 13) with dispatcher
07:12:39 DISPATCHER: job (8, 0, 13) finished
07:12:39 DISPATCHER: register_result: lock acquired
07:12:39 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:12:39 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 79, 'last_n_outputs': 40, 'lr': 0.01191773012003012, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.02509021963926106}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.929342581568774, 'info': {'music-speech': 0.929342581568774, 'config': "{'batch_size': 32, 'hidden_dim': 79, 'last_n_outputs': 40, 'lr': 0.01191773012003012, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.02509021963926106}"}}
exception: None

07:12:39 job_callback for (8, 0, 13) started
07:12:39 DISPATCHER: Trying to submit another job.
07:12:39 job_callback for (8, 0, 13) got condition
07:12:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:12:39 HBMASTER: Trying to run another job!
07:12:39 job_callback for (8, 0, 13) finished
07:12:39 start sampling a new configuration.
07:12:39 done sampling a new configuration.
07:12:39 HBMASTER: schedule new run for iteration 8
07:12:39 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
07:12:39 HBMASTER: submitting job (8, 0, 14) to dispatcher
07:12:39 DISPATCHER: trying to submit job (8, 0, 14)
07:12:39 DISPATCHER: trying to notify the job_runner thread.
07:12:39 HBMASTER: job (8, 0, 14) submitted to dispatcher
07:12:39 DISPATCHER: Trying to submit another job.
07:12:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:12:39 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:12:39 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:12:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:12:39 WORKER: start processing job (8, 0, 14)
07:12:39 WORKER: args: ()
07:12:39 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 67, 'last_n_outputs': 15, 'lr': 0.0016289975296062778, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.07236670646623766}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-550:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:13:22 DISPATCHER: Starting worker discovery
07:13:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:13:22 DISPATCHER: Finished worker discovery
07:13:32 WORKER: done with job (8, 0, 14), trying to register it.
07:13:32 WORKER: registered result for job (8, 0, 14) with dispatcher
07:13:32 DISPATCHER: job (8, 0, 14) finished
07:13:32 DISPATCHER: register_result: lock acquired
07:13:32 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:13:32 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 67, 'last_n_outputs': 15, 'lr': 0.0016289975296062778, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.07236670646623766}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.06589555036757767, 'info': {'music-speech': 0.06589555036757767, 'config': "{'batch_size': 16, 'hidden_dim': 67, 'last_n_outputs': 15, 'lr': 0.0016289975296062778, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.07236670646623766}"}}
exception: None

07:13:32 job_callback for (8, 0, 14) started
07:13:32 DISPATCHER: Trying to submit another job.
07:13:32 job_callback for (8, 0, 14) got condition
07:13:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:13:32 HBMASTER: Trying to run another job!
07:13:32 job_callback for (8, 0, 14) finished
07:13:32 start sampling a new configuration.
07:13:32 best_vector: [2, 0.6935806719373241, 0.14265774802598236, 0.06930659916384002, 0.10890375307812883, 0, 0.8564405709732011, 0.11126404096034648], 0.006835311169689042, 0.4449658862852392, 0.0030414802926560795
07:13:32 done sampling a new configuration.
07:13:32 HBMASTER: schedule new run for iteration 8
07:13:32 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
07:13:32 HBMASTER: submitting job (8, 0, 15) to dispatcher
07:13:32 DISPATCHER: trying to submit job (8, 0, 15)
07:13:32 DISPATCHER: trying to notify the job_runner thread.
07:13:32 HBMASTER: job (8, 0, 15) submitted to dispatcher
07:13:32 DISPATCHER: Trying to submit another job.
07:13:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:13:32 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:13:32 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:13:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:13:32 WORKER: start processing job (8, 0, 15)
07:13:32 WORKER: args: ()
07:13:32 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 76, 'last_n_outputs': 8, 'lr': 0.001375983411938926, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.013955900187888729}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-551:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:14:22 DISPATCHER: Starting worker discovery
07:14:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:14:22 DISPATCHER: Finished worker discovery
07:14:25 WORKER: done with job (8, 0, 15), trying to register it.
07:14:25 WORKER: registered result for job (8, 0, 15) with dispatcher
07:14:25 DISPATCHER: job (8, 0, 15) finished
07:14:25 DISPATCHER: register_result: lock acquired
07:14:25 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:14:25 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 76, 'last_n_outputs': 8, 'lr': 0.001375983411938926, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.013955900187888729}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7669624093377261, 'info': {'music-speech': 0.7669624093377261, 'config': "{'batch_size': 64, 'hidden_dim': 76, 'last_n_outputs': 8, 'lr': 0.001375983411938926, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 87, 'weight_decay': 0.013955900187888729}"}}
exception: None

07:14:25 job_callback for (8, 0, 15) started
07:14:25 DISPATCHER: Trying to submit another job.
07:14:25 job_callback for (8, 0, 15) got condition
07:14:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:14:25 HBMASTER: Trying to run another job!
07:14:25 job_callback for (8, 0, 15) finished
07:14:25 start sampling a new configuration.
07:14:25 done sampling a new configuration.
07:14:25 HBMASTER: schedule new run for iteration 8
07:14:25 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
07:14:25 HBMASTER: submitting job (8, 0, 16) to dispatcher
07:14:25 DISPATCHER: trying to submit job (8, 0, 16)
07:14:25 DISPATCHER: trying to notify the job_runner thread.
07:14:25 HBMASTER: job (8, 0, 16) submitted to dispatcher
07:14:25 DISPATCHER: Trying to submit another job.
07:14:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:14:25 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:14:25 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:14:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:14:25 WORKER: start processing job (8, 0, 16)
07:14:25 WORKER: args: ()
07:14:25 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 87, 'last_n_outputs': 30, 'lr': 0.030673075450079006, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.02396418631522295}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-552:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:15:18 WORKER: done with job (8, 0, 16), trying to register it.
07:15:18 WORKER: registered result for job (8, 0, 16) with dispatcher
07:15:18 DISPATCHER: job (8, 0, 16) finished
07:15:18 DISPATCHER: register_result: lock acquired
07:15:18 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:15:18 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 87, 'last_n_outputs': 30, 'lr': 0.030673075450079006, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.02396418631522295}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6389799582778337, 'info': {'music-speech': 0.6389799582778337, 'config': "{'batch_size': 128, 'hidden_dim': 87, 'last_n_outputs': 30, 'lr': 0.030673075450079006, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 77, 'weight_decay': 0.02396418631522295}"}}
exception: None

07:15:18 job_callback for (8, 0, 16) started
07:15:18 DISPATCHER: Trying to submit another job.
07:15:18 job_callback for (8, 0, 16) got condition
07:15:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:15:18 HBMASTER: Trying to run another job!
07:15:18 job_callback for (8, 0, 16) finished
07:15:18 start sampling a new configuration.
07:15:18 best_vector: [1, 0.6571509977890652, 0.10103979403918026, 0.0021421897146969154, 0.35098766575115226, 0, 0.35997295429594867, 0.35852236431404827], 0.018756342777857923, 0.24150544586907177, 0.004529758925439721
07:15:18 done sampling a new configuration.
07:15:18 HBMASTER: schedule new run for iteration 8
07:15:18 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
07:15:18 HBMASTER: submitting job (8, 0, 17) to dispatcher
07:15:18 DISPATCHER: trying to submit job (8, 0, 17)
07:15:18 DISPATCHER: trying to notify the job_runner thread.
07:15:18 HBMASTER: job (8, 0, 17) submitted to dispatcher
07:15:18 DISPATCHER: Trying to submit another job.
07:15:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:15:18 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:15:18 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:15:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:15:18 WORKER: start processing job (8, 0, 17)
07:15:18 WORKER: args: ()
07:15:18 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 73, 'last_n_outputs': 6, 'lr': 0.0010099139691914396, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.02927172726946888}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:15:22 DISPATCHER: Starting worker discovery
07:15:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:15:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-553:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:16:11 WORKER: done with job (8, 0, 17), trying to register it.
07:16:11 DISPATCHER: job (8, 0, 17) finished
07:16:11 WORKER: registered result for job (8, 0, 17) with dispatcher
07:16:11 DISPATCHER: register_result: lock acquired
07:16:11 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:16:11 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 73, 'last_n_outputs': 6, 'lr': 0.0010099139691914396, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.02927172726946888}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7030117428109148, 'info': {'music-speech': 0.7030117428109148, 'config': "{'batch_size': 32, 'hidden_dim': 73, 'last_n_outputs': 6, 'lr': 0.0010099139691914396, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.02927172726946888}"}}
exception: None

07:16:11 job_callback for (8, 0, 17) started
07:16:11 job_callback for (8, 0, 17) got condition
07:16:11 DISPATCHER: Trying to submit another job.
07:16:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:16:11 HBMASTER: Trying to run another job!
07:16:11 job_callback for (8, 0, 17) finished
07:16:11 start sampling a new configuration.
07:16:11 done sampling a new configuration.
07:16:11 HBMASTER: schedule new run for iteration 8
07:16:11 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
07:16:11 HBMASTER: submitting job (8, 0, 18) to dispatcher
07:16:11 DISPATCHER: trying to submit job (8, 0, 18)
07:16:11 DISPATCHER: trying to notify the job_runner thread.
07:16:11 HBMASTER: job (8, 0, 18) submitted to dispatcher
07:16:11 DISPATCHER: Trying to submit another job.
07:16:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:16:11 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:16:11 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:16:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:16:11 WORKER: start processing job (8, 0, 18)
07:16:11 WORKER: args: ()
07:16:11 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 43, 'last_n_outputs': 38, 'lr': 0.017746258428887638, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.027517943298564353}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:16:22 DISPATCHER: Starting worker discovery
07:16:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:16:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-554:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:17:04 WORKER: done with job (8, 0, 18), trying to register it.
07:17:04 WORKER: registered result for job (8, 0, 18) with dispatcher
07:17:04 DISPATCHER: job (8, 0, 18) finished
07:17:04 DISPATCHER: register_result: lock acquired
07:17:04 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:17:04 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 43, 'last_n_outputs': 38, 'lr': 0.017746258428887638, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.027517943298564353}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 43, 'last_n_outputs': 38, 'lr': 0.017746258428887638, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.027517943298564353}"}}
exception: None

07:17:04 job_callback for (8, 0, 18) started
07:17:04 DISPATCHER: Trying to submit another job.
07:17:04 job_callback for (8, 0, 18) got condition
07:17:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:17:04 HBMASTER: Trying to run another job!
07:17:04 job_callback for (8, 0, 18) finished
07:17:04 start sampling a new configuration.
07:17:04 best_vector: [1, 0.41571860682244427, 0.24037863341684831, 0.043675332858648, 0.3079565194689384, 0, 0.21891474500227287, 0.3840227938050378], 0.02234243087754688, 0.2183179233650479, 0.004877753112113159
07:17:04 done sampling a new configuration.
07:17:04 HBMASTER: schedule new run for iteration 8
07:17:04 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
07:17:04 HBMASTER: submitting job (8, 0, 19) to dispatcher
07:17:04 DISPATCHER: trying to submit job (8, 0, 19)
07:17:04 DISPATCHER: trying to notify the job_runner thread.
07:17:04 HBMASTER: job (8, 0, 19) submitted to dispatcher
07:17:04 DISPATCHER: Trying to submit another job.
07:17:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:17:04 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:17:04 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:17:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:17:04 WORKER: start processing job (8, 0, 19)
07:17:04 WORKER: args: ()
07:17:04 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 53, 'last_n_outputs': 13, 'lr': 0.0012227865856020016, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.03159549572788287}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-555:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:17:22 DISPATCHER: Starting worker discovery
07:17:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:17:22 DISPATCHER: Finished worker discovery
07:17:58 WORKER: done with job (8, 0, 19), trying to register it.
07:17:58 DISPATCHER: job (8, 0, 19) finished
07:17:58 WORKER: registered result for job (8, 0, 19) with dispatcher
07:17:58 DISPATCHER: register_result: lock acquired
07:17:58 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:17:58 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 53, 'last_n_outputs': 13, 'lr': 0.0012227865856020016, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.03159549572788287}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7926651899594527, 'info': {'music-speech': 0.7926651899594527, 'config': "{'batch_size': 32, 'hidden_dim': 53, 'last_n_outputs': 13, 'lr': 0.0012227865856020016, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.03159549572788287}"}}
exception: None

07:17:58 job_callback for (8, 0, 19) started
07:17:58 DISPATCHER: Trying to submit another job.
07:17:58 job_callback for (8, 0, 19) got condition
07:17:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:17:58 HBMASTER: Trying to run another job!
07:17:58 job_callback for (8, 0, 19) finished
07:17:58 start sampling a new configuration.
07:17:58 done sampling a new configuration.
07:17:58 HBMASTER: schedule new run for iteration 8
07:17:58 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
07:17:58 HBMASTER: submitting job (8, 0, 20) to dispatcher
07:17:58 DISPATCHER: trying to submit job (8, 0, 20)
07:17:58 DISPATCHER: trying to notify the job_runner thread.
07:17:58 HBMASTER: job (8, 0, 20) submitted to dispatcher
07:17:58 DISPATCHER: Trying to submit another job.
07:17:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:17:58 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:17:58 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:17:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:17:58 WORKER: start processing job (8, 0, 20)
07:17:58 WORKER: args: ()
07:17:58 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 79, 'last_n_outputs': 35, 'lr': 0.020940656604604792, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.021911021670016562}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:18:22 DISPATCHER: Starting worker discovery
07:18:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:18:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-556:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:18:51 WORKER: done with job (8, 0, 20), trying to register it.
07:18:51 WORKER: registered result for job (8, 0, 20) with dispatcher
07:18:51 DISPATCHER: job (8, 0, 20) finished
07:18:51 DISPATCHER: register_result: lock acquired
07:18:51 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:18:51 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 79, 'last_n_outputs': 35, 'lr': 0.020940656604604792, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.021911021670016562}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 79, 'last_n_outputs': 35, 'lr': 0.020940656604604792, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.021911021670016562}"}}
exception: None

07:18:51 job_callback for (8, 0, 20) started
07:18:51 job_callback for (8, 0, 20) got condition
07:18:51 DISPATCHER: Trying to submit another job.
07:18:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:18:51 HBMASTER: Trying to run another job!
07:18:51 job_callback for (8, 0, 20) finished
07:18:51 start sampling a new configuration.
07:18:51 best_vector: [3, 0.6512564496281362, 0.874595144547807, 0.1963899951745208, 0.4334395048290663, 0, 0.15253892342482533, 0.6930905638304293], 0.029673179688783607, 0.1297148504363976, 0.0038490520653029167
07:18:51 done sampling a new configuration.
07:18:51 HBMASTER: schedule new run for iteration 8
07:18:51 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
07:18:51 HBMASTER: submitting job (8, 0, 21) to dispatcher
07:18:51 DISPATCHER: trying to submit job (8, 0, 21)
07:18:51 DISPATCHER: trying to notify the job_runner thread.
07:18:51 HBMASTER: job (8, 0, 21) submitted to dispatcher
07:18:51 DISPATCHER: Trying to submit another job.
07:18:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:18:51 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:18:51 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:18:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:18:51 WORKER: start processing job (8, 0, 21)
07:18:51 WORKER: args: ()
07:18:51 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 72, 'last_n_outputs': 44, 'lr': 0.002470472309062781, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.07975016922103793}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-557:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:19:22 DISPATCHER: Starting worker discovery
07:19:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:19:22 DISPATCHER: Finished worker discovery
07:19:44 WORKER: done with job (8, 0, 21), trying to register it.
07:19:44 WORKER: registered result for job (8, 0, 21) with dispatcher
07:19:44 DISPATCHER: job (8, 0, 21) finished
07:19:44 DISPATCHER: register_result: lock acquired
07:19:44 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:19:44 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 72, 'last_n_outputs': 44, 'lr': 0.002470472309062781, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.07975016922103793}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8982551106646187, 'info': {'music-speech': 0.8982551106646187, 'config': "{'batch_size': 128, 'hidden_dim': 72, 'last_n_outputs': 44, 'lr': 0.002470472309062781, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.07975016922103793}"}}
exception: None

07:19:44 job_callback for (8, 0, 21) started
07:19:44 DISPATCHER: Trying to submit another job.
07:19:44 job_callback for (8, 0, 21) got condition
07:19:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:19:45 HBMASTER: Trying to run another job!
07:19:45 job_callback for (8, 0, 21) finished
07:19:45 start sampling a new configuration.
07:19:45 best_vector: [3, 0.7009513276210776, 0.10910947764196521, 0.16773859438338648, 0.31236942298495485, 0, 0.3405546945513521, 0.036574273513597676], 0.01151092806199264, 0.34187313295556293, 0.00393527703977953
07:19:45 done sampling a new configuration.
07:19:45 HBMASTER: schedule new run for iteration 8
07:19:45 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
07:19:45 HBMASTER: submitting job (8, 0, 22) to dispatcher
07:19:45 DISPATCHER: trying to submit job (8, 0, 22)
07:19:45 DISPATCHER: trying to notify the job_runner thread.
07:19:45 HBMASTER: job (8, 0, 22) submitted to dispatcher
07:19:45 DISPATCHER: Trying to submit another job.
07:19:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:19:45 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:19:45 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:19:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:19:45 WORKER: start processing job (8, 0, 22)
07:19:45 WORKER: args: ()
07:19:45 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 76, 'last_n_outputs': 6, 'lr': 0.0021650961550666726, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.011157945271451773}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-558:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:20:22 DISPATCHER: Starting worker discovery
07:20:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:20:22 DISPATCHER: Finished worker discovery
07:20:38 WORKER: done with job (8, 0, 22), trying to register it.
07:20:38 WORKER: registered result for job (8, 0, 22) with dispatcher
07:20:38 DISPATCHER: job (8, 0, 22) finished
07:20:38 DISPATCHER: register_result: lock acquired
07:20:38 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:20:38 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 76, 'last_n_outputs': 6, 'lr': 0.0021650961550666726, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.011157945271451773}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9893063278969654, 'info': {'music-speech': 0.9893063278969654, 'config': "{'batch_size': 128, 'hidden_dim': 76, 'last_n_outputs': 6, 'lr': 0.0021650961550666726, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.011157945271451773}"}}
exception: None

07:20:38 job_callback for (8, 0, 22) started
07:20:38 DISPATCHER: Trying to submit another job.
07:20:38 job_callback for (8, 0, 22) got condition
07:20:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:20:38 HBMASTER: Trying to run another job!
07:20:38 job_callback for (8, 0, 22) finished
07:20:38 start sampling a new configuration.
07:20:38 done sampling a new configuration.
07:20:38 HBMASTER: schedule new run for iteration 8
07:20:38 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
07:20:38 HBMASTER: submitting job (8, 0, 23) to dispatcher
07:20:38 DISPATCHER: trying to submit job (8, 0, 23)
07:20:38 DISPATCHER: trying to notify the job_runner thread.
07:20:38 HBMASTER: job (8, 0, 23) submitted to dispatcher
07:20:38 DISPATCHER: Trying to submit another job.
07:20:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:20:38 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:20:38 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:20:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:20:38 WORKER: start processing job (8, 0, 23)
07:20:38 WORKER: args: ()
07:20:38 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 99, 'last_n_outputs': 3, 'lr': 0.0034437376089809977, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.02790747000384932}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-559:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:21:22 DISPATCHER: Starting worker discovery
07:21:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:21:22 DISPATCHER: Finished worker discovery
07:21:31 WORKER: done with job (8, 0, 23), trying to register it.
07:21:31 WORKER: registered result for job (8, 0, 23) with dispatcher
07:21:31 DISPATCHER: job (8, 0, 23) finished
07:21:31 DISPATCHER: register_result: lock acquired
07:21:31 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:21:31 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 99, 'last_n_outputs': 3, 'lr': 0.0034437376089809977, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.02790747000384932}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5363688342889172, 'info': {'music-speech': 0.5363688342889172, 'config': "{'batch_size': 128, 'hidden_dim': 99, 'last_n_outputs': 3, 'lr': 0.0034437376089809977, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.02790747000384932}"}}
exception: None

07:21:31 job_callback for (8, 0, 23) started
07:21:31 DISPATCHER: Trying to submit another job.
07:21:31 job_callback for (8, 0, 23) got condition
07:21:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:21:31 HBMASTER: Trying to run another job!
07:21:31 job_callback for (8, 0, 23) finished
07:21:31 start sampling a new configuration.
07:21:31 best_vector: [1, 0.3181791732420973, 0.1327957257829225, 0.7426620757413682, 0.3186392027874817, 0, 0.16202760800677452, 0.08546328460521825], 0.01907851152960976, 1.1241864775212427, 0.021447804672820415
07:21:31 done sampling a new configuration.
07:21:31 HBMASTER: schedule new run for iteration 8
07:21:31 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
07:21:31 HBMASTER: submitting job (8, 0, 24) to dispatcher
07:21:31 DISPATCHER: trying to submit job (8, 0, 24)
07:21:31 DISPATCHER: trying to notify the job_runner thread.
07:21:31 HBMASTER: job (8, 0, 24) submitted to dispatcher
07:21:31 DISPATCHER: Trying to submit another job.
07:21:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:21:31 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:21:31 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:21:31 WORKER: start processing job (8, 0, 24)
07:21:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:21:31 WORKER: args: ()
07:21:31 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 45, 'last_n_outputs': 7, 'lr': 0.03057202115850764, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.012917851770411643}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-560:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:22:22 DISPATCHER: Starting worker discovery
07:22:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:22:22 DISPATCHER: Finished worker discovery
07:22:24 WORKER: done with job (8, 0, 24), trying to register it.
07:22:24 WORKER: registered result for job (8, 0, 24) with dispatcher
07:22:24 DISPATCHER: job (8, 0, 24) finished
07:22:24 DISPATCHER: register_result: lock acquired
07:22:24 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:22:24 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 45, 'last_n_outputs': 7, 'lr': 0.03057202115850764, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.012917851770411643}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6153070549519483, 'info': {'music-speech': 0.6153070549519483, 'config': "{'batch_size': 32, 'hidden_dim': 45, 'last_n_outputs': 7, 'lr': 0.03057202115850764, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.012917851770411643}"}}
exception: None

07:22:24 job_callback for (8, 0, 24) started
07:22:24 DISPATCHER: Trying to submit another job.
07:22:24 job_callback for (8, 0, 24) got condition
07:22:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:22:24 HBMASTER: Trying to run another job!
07:22:24 job_callback for (8, 0, 24) finished
07:22:24 start sampling a new configuration.
07:22:24 done sampling a new configuration.
07:22:24 HBMASTER: schedule new run for iteration 8
07:22:24 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
07:22:24 HBMASTER: submitting job (8, 0, 25) to dispatcher
07:22:24 DISPATCHER: trying to submit job (8, 0, 25)
07:22:24 DISPATCHER: trying to notify the job_runner thread.
07:22:24 HBMASTER: job (8, 0, 25) submitted to dispatcher
07:22:24 DISPATCHER: Trying to submit another job.
07:22:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:22:24 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:22:24 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:22:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:22:24 WORKER: start processing job (8, 0, 25)
07:22:24 WORKER: args: ()
07:22:24 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 47, 'last_n_outputs': 8, 'lr': 0.002559109988051146, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.10034159967203121}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-561:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:23:17 WORKER: done with job (8, 0, 25), trying to register it.
07:23:17 WORKER: registered result for job (8, 0, 25) with dispatcher
07:23:17 DISPATCHER: job (8, 0, 25) finished
07:23:17 DISPATCHER: register_result: lock acquired
07:23:17 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:23:17 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 47, 'last_n_outputs': 8, 'lr': 0.002559109988051146, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.10034159967203121}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 47, 'last_n_outputs': 8, 'lr': 0.002559109988051146, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.10034159967203121}"}}
exception: None

07:23:17 job_callback for (8, 0, 25) started
07:23:17 DISPATCHER: Trying to submit another job.
07:23:17 job_callback for (8, 0, 25) got condition
07:23:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:23:17 HBMASTER: Trying to run another job!
07:23:17 job_callback for (8, 0, 25) finished
07:23:17 start sampling a new configuration.
07:23:17 best_vector: [1, 0.9535723045361967, 0.4255274652080254, 0.29523019291056585, 0.23316947850519765, 0, 0.7145484214261737, 0.4251334441030419], 0.012227484371657736, 2.1813449004976366, 0.026672360680030153
07:23:17 done sampling a new configuration.
07:23:17 HBMASTER: schedule new run for iteration 8
07:23:17 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
07:23:17 HBMASTER: submitting job (8, 0, 26) to dispatcher
07:23:17 DISPATCHER: trying to submit job (8, 0, 26)
07:23:17 DISPATCHER: trying to notify the job_runner thread.
07:23:17 HBMASTER: job (8, 0, 26) submitted to dispatcher
07:23:17 DISPATCHER: Trying to submit another job.
07:23:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:23:17 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:23:17 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:23:17 WORKER: start processing job (8, 0, 26)
07:23:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:23:17 WORKER: args: ()
07:23:17 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 97, 'last_n_outputs': 22, 'lr': 0.0038945778168496346, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.035736446274343074}, 'budget': 44.44444444444444, 'working_directory': '.'}
07:23:22 DISPATCHER: Starting worker discovery
07:23:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:23:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-562:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:24:10 WORKER: done with job (8, 0, 26), trying to register it.
07:24:10 WORKER: registered result for job (8, 0, 26) with dispatcher
07:24:10 DISPATCHER: job (8, 0, 26) finished
07:24:10 DISPATCHER: register_result: lock acquired
07:24:10 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:24:10 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 97, 'last_n_outputs': 22, 'lr': 0.0038945778168496346, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.035736446274343074}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7878567333896772, 'info': {'music-speech': 0.7878567333896772, 'config': "{'batch_size': 32, 'hidden_dim': 97, 'last_n_outputs': 22, 'lr': 0.0038945778168496346, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.035736446274343074}"}}
exception: None

07:24:10 job_callback for (8, 0, 26) started
07:24:10 job_callback for (8, 0, 26) got condition
07:24:10 DISPATCHER: Trying to submit another job.
07:24:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:24:10 HBMASTER: Trying to run another job!
07:24:10 job_callback for (8, 0, 26) finished
07:24:10 ITERATION: Advancing config (8, 0, 0) to next budget 133.333333
07:24:10 ITERATION: Advancing config (8, 0, 3) to next budget 133.333333
07:24:10 ITERATION: Advancing config (8, 0, 5) to next budget 133.333333
07:24:10 ITERATION: Advancing config (8, 0, 12) to next budget 133.333333
07:24:10 ITERATION: Advancing config (8, 0, 13) to next budget 133.333333
07:24:10 ITERATION: Advancing config (8, 0, 19) to next budget 133.333333
07:24:10 ITERATION: Advancing config (8, 0, 21) to next budget 133.333333
07:24:10 ITERATION: Advancing config (8, 0, 22) to next budget 133.333333
07:24:10 ITERATION: Advancing config (8, 0, 26) to next budget 133.333333
07:24:10 HBMASTER: schedule new run for iteration 8
07:24:10 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
07:24:10 HBMASTER: submitting job (8, 0, 0) to dispatcher
07:24:10 DISPATCHER: trying to submit job (8, 0, 0)
07:24:10 DISPATCHER: trying to notify the job_runner thread.
07:24:10 HBMASTER: job (8, 0, 0) submitted to dispatcher
07:24:10 DISPATCHER: Trying to submit another job.
07:24:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:24:10 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:24:10 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:24:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:24:10 WORKER: start processing job (8, 0, 0)
07:24:10 WORKER: args: ()
07:24:10 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 9, 'lr': 0.0016291668639488728, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.01965784315149041}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:24:22 DISPATCHER: Starting worker discovery
07:24:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:24:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-563:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:25:22 DISPATCHER: Starting worker discovery
07:25:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:25:22 DISPATCHER: Finished worker discovery
07:26:22 DISPATCHER: Starting worker discovery
07:26:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:26:22 DISPATCHER: Finished worker discovery
07:26:32 WORKER: done with job (8, 0, 0), trying to register it.
07:26:32 WORKER: registered result for job (8, 0, 0) with dispatcher
07:26:32 DISPATCHER: job (8, 0, 0) finished
07:26:32 DISPATCHER: register_result: lock acquired
07:26:32 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:26:32 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 9, 'lr': 0.0016291668639488728, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.01965784315149041}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8322704382663663, 'info': {'music-speech': 0.8322704382663663, 'config': "{'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 9, 'lr': 0.0016291668639488728, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.01965784315149041}"}}
exception: None

07:26:32 job_callback for (8, 0, 0) started
07:26:32 DISPATCHER: Trying to submit another job.
07:26:32 job_callback for (8, 0, 0) got condition
07:26:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:26:32 HBMASTER: Trying to run another job!
07:26:32 job_callback for (8, 0, 0) finished
07:26:32 HBMASTER: schedule new run for iteration 8
07:26:32 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
07:26:32 HBMASTER: submitting job (8, 0, 3) to dispatcher
07:26:32 DISPATCHER: trying to submit job (8, 0, 3)
07:26:32 DISPATCHER: trying to notify the job_runner thread.
07:26:32 HBMASTER: job (8, 0, 3) submitted to dispatcher
07:26:32 DISPATCHER: Trying to submit another job.
07:26:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:26:32 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:26:32 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:26:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:26:32 WORKER: start processing job (8, 0, 3)
07:26:32 WORKER: args: ()
07:26:32 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 4, 'lr': 0.001778673658529631, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.023893764793741733}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-564:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:27:22 DISPATCHER: Starting worker discovery
07:27:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:27:22 DISPATCHER: Finished worker discovery
07:28:22 DISPATCHER: Starting worker discovery
07:28:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:28:22 DISPATCHER: Finished worker discovery
07:28:54 WORKER: done with job (8, 0, 3), trying to register it.
07:28:54 WORKER: registered result for job (8, 0, 3) with dispatcher
07:28:54 DISPATCHER: job (8, 0, 3) finished
07:28:54 DISPATCHER: register_result: lock acquired
07:28:54 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:28:54 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 4, 'lr': 0.001778673658529631, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.023893764793741733}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7385229876419489, 'info': {'music-speech': 0.7385229876419489, 'config': "{'batch_size': 16, 'hidden_dim': 100, 'last_n_outputs': 4, 'lr': 0.001778673658529631, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 100, 'weight_decay': 0.023893764793741733}"}}
exception: None

07:28:54 job_callback for (8, 0, 3) started
07:28:54 DISPATCHER: Trying to submit another job.
07:28:54 job_callback for (8, 0, 3) got condition
07:28:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:28:54 HBMASTER: Trying to run another job!
07:28:54 job_callback for (8, 0, 3) finished
07:28:54 HBMASTER: schedule new run for iteration 8
07:28:54 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
07:28:54 HBMASTER: submitting job (8, 0, 5) to dispatcher
07:28:54 DISPATCHER: trying to submit job (8, 0, 5)
07:28:54 DISPATCHER: trying to notify the job_runner thread.
07:28:54 HBMASTER: job (8, 0, 5) submitted to dispatcher
07:28:54 DISPATCHER: Trying to submit another job.
07:28:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:28:54 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:28:54 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:28:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:28:54 WORKER: start processing job (8, 0, 5)
07:28:54 WORKER: args: ()
07:28:54 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 39, 'last_n_outputs': 18, 'lr': 0.0033402164111182406, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.08716038111659165}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-565:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:29:22 DISPATCHER: Starting worker discovery
07:29:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:29:22 DISPATCHER: Finished worker discovery
07:30:22 DISPATCHER: Starting worker discovery
07:30:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:30:22 DISPATCHER: Finished worker discovery
07:31:16 WORKER: done with job (8, 0, 5), trying to register it.
07:31:16 WORKER: registered result for job (8, 0, 5) with dispatcher
07:31:16 DISPATCHER: job (8, 0, 5) finished
07:31:16 DISPATCHER: register_result: lock acquired
07:31:16 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:31:16 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 39, 'last_n_outputs': 18, 'lr': 0.0033402164111182406, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.08716038111659165}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8088356100174783, 'info': {'music-speech': 0.8088356100174783, 'config': "{'batch_size': 32, 'hidden_dim': 39, 'last_n_outputs': 18, 'lr': 0.0033402164111182406, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.08716038111659165}"}}
exception: None

07:31:16 job_callback for (8, 0, 5) started
07:31:16 DISPATCHER: Trying to submit another job.
07:31:16 job_callback for (8, 0, 5) got condition
07:31:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:31:16 HBMASTER: Trying to run another job!
07:31:16 job_callback for (8, 0, 5) finished
07:31:16 HBMASTER: schedule new run for iteration 8
07:31:16 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
07:31:16 HBMASTER: submitting job (8, 0, 12) to dispatcher
07:31:16 DISPATCHER: trying to submit job (8, 0, 12)
07:31:16 DISPATCHER: trying to notify the job_runner thread.
07:31:16 HBMASTER: job (8, 0, 12) submitted to dispatcher
07:31:16 DISPATCHER: Trying to submit another job.
07:31:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:31:16 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:31:16 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:31:16 WORKER: start processing job (8, 0, 12)
07:31:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:31:16 WORKER: args: ()
07:31:16 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 94, 'last_n_outputs': 16, 'lr': 0.0013864767849064766, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 33, 'weight_decay': 0.014760898802665616}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:31:22 DISPATCHER: Starting worker discovery
07:31:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:31:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-566:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:32:22 DISPATCHER: Starting worker discovery
07:32:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:32:22 DISPATCHER: Finished worker discovery
07:33:22 DISPATCHER: Starting worker discovery
07:33:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:33:22 DISPATCHER: Finished worker discovery
07:33:38 WORKER: done with job (8, 0, 12), trying to register it.
07:33:38 DISPATCHER: job (8, 0, 12) finished
07:33:38 WORKER: registered result for job (8, 0, 12) with dispatcher
07:33:38 DISPATCHER: register_result: lock acquired
07:33:38 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:33:38 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 94, 'last_n_outputs': 16, 'lr': 0.0013864767849064766, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 33, 'weight_decay': 0.014760898802665616}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6764889376596184, 'info': {'music-speech': 0.6764889376596184, 'config': "{'batch_size': 128, 'hidden_dim': 94, 'last_n_outputs': 16, 'lr': 0.0013864767849064766, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 33, 'weight_decay': 0.014760898802665616}"}}
exception: None

07:33:38 job_callback for (8, 0, 12) started
07:33:38 DISPATCHER: Trying to submit another job.
07:33:38 job_callback for (8, 0, 12) got condition
07:33:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:33:38 HBMASTER: Trying to run another job!
07:33:38 job_callback for (8, 0, 12) finished
07:33:38 HBMASTER: schedule new run for iteration 8
07:33:38 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
07:33:38 HBMASTER: submitting job (8, 0, 13) to dispatcher
07:33:38 DISPATCHER: trying to submit job (8, 0, 13)
07:33:38 DISPATCHER: trying to notify the job_runner thread.
07:33:38 HBMASTER: job (8, 0, 13) submitted to dispatcher
07:33:38 DISPATCHER: Trying to submit another job.
07:33:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:33:38 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:33:38 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:33:38 WORKER: start processing job (8, 0, 13)
07:33:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:33:38 WORKER: args: ()
07:33:38 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 79, 'last_n_outputs': 40, 'lr': 0.01191773012003012, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.02509021963926106}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-567:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:34:22 DISPATCHER: Starting worker discovery
07:34:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:34:22 DISPATCHER: Finished worker discovery
07:35:22 DISPATCHER: Starting worker discovery
07:35:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:35:22 DISPATCHER: Finished worker discovery
07:36:00 WORKER: done with job (8, 0, 13), trying to register it.
07:36:00 WORKER: registered result for job (8, 0, 13) with dispatcher
07:36:00 DISPATCHER: job (8, 0, 13) finished
07:36:00 DISPATCHER: register_result: lock acquired
07:36:00 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:36:00 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 79, 'last_n_outputs': 40, 'lr': 0.01191773012003012, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.02509021963926106}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5008730055429256, 'info': {'music-speech': 0.5008730055429256, 'config': "{'batch_size': 32, 'hidden_dim': 79, 'last_n_outputs': 40, 'lr': 0.01191773012003012, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.02509021963926106}"}}
exception: None

07:36:00 job_callback for (8, 0, 13) started
07:36:00 DISPATCHER: Trying to submit another job.
07:36:00 job_callback for (8, 0, 13) got condition
07:36:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:36:00 HBMASTER: Trying to run another job!
07:36:00 job_callback for (8, 0, 13) finished
07:36:00 HBMASTER: schedule new run for iteration 8
07:36:00 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
07:36:00 HBMASTER: submitting job (8, 0, 19) to dispatcher
07:36:00 DISPATCHER: trying to submit job (8, 0, 19)
07:36:00 DISPATCHER: trying to notify the job_runner thread.
07:36:00 HBMASTER: job (8, 0, 19) submitted to dispatcher
07:36:00 DISPATCHER: Trying to submit another job.
07:36:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:36:00 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:36:00 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:36:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:36:00 WORKER: start processing job (8, 0, 19)
07:36:00 WORKER: args: ()
07:36:00 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 53, 'last_n_outputs': 13, 'lr': 0.0012227865856020016, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.03159549572788287}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-568:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:36:22 DISPATCHER: Starting worker discovery
07:36:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:36:22 DISPATCHER: Finished worker discovery
07:37:22 DISPATCHER: Starting worker discovery
07:37:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:37:22 DISPATCHER: Finished worker discovery
07:38:22 DISPATCHER: Starting worker discovery
07:38:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:38:22 DISPATCHER: Finished worker discovery
07:38:22 WORKER: done with job (8, 0, 19), trying to register it.
07:38:22 WORKER: registered result for job (8, 0, 19) with dispatcher
07:38:22 DISPATCHER: job (8, 0, 19) finished
07:38:22 DISPATCHER: register_result: lock acquired
07:38:22 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:38:22 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 53, 'last_n_outputs': 13, 'lr': 0.0012227865856020016, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.03159549572788287}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7290171034788433, 'info': {'music-speech': 0.7290171034788433, 'config': "{'batch_size': 32, 'hidden_dim': 53, 'last_n_outputs': 13, 'lr': 0.0012227865856020016, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.03159549572788287}"}}
exception: None

07:38:22 job_callback for (8, 0, 19) started
07:38:22 DISPATCHER: Trying to submit another job.
07:38:22 job_callback for (8, 0, 19) got condition
07:38:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:38:22 HBMASTER: Trying to run another job!
07:38:22 job_callback for (8, 0, 19) finished
07:38:22 HBMASTER: schedule new run for iteration 8
07:38:22 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
07:38:22 HBMASTER: submitting job (8, 0, 21) to dispatcher
07:38:22 DISPATCHER: trying to submit job (8, 0, 21)
07:38:22 DISPATCHER: trying to notify the job_runner thread.
07:38:22 HBMASTER: job (8, 0, 21) submitted to dispatcher
07:38:22 DISPATCHER: Trying to submit another job.
07:38:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:38:22 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:38:22 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:38:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:38:22 WORKER: start processing job (8, 0, 21)
07:38:22 WORKER: args: ()
07:38:22 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 72, 'last_n_outputs': 44, 'lr': 0.002470472309062781, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.07975016922103793}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-569:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:39:22 DISPATCHER: Starting worker discovery
07:39:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:39:22 DISPATCHER: Finished worker discovery
07:40:22 DISPATCHER: Starting worker discovery
07:40:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:40:22 DISPATCHER: Finished worker discovery
07:40:44 WORKER: done with job (8, 0, 21), trying to register it.
07:40:44 WORKER: registered result for job (8, 0, 21) with dispatcher
07:40:44 DISPATCHER: job (8, 0, 21) finished
07:40:44 DISPATCHER: register_result: lock acquired
07:40:44 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:40:44 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 72, 'last_n_outputs': 44, 'lr': 0.002470472309062781, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.07975016922103793}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8354732390991475, 'info': {'music-speech': 0.8354732390991475, 'config': "{'batch_size': 128, 'hidden_dim': 72, 'last_n_outputs': 44, 'lr': 0.002470472309062781, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.07975016922103793}"}}
exception: None

07:40:44 job_callback for (8, 0, 21) started
07:40:44 DISPATCHER: Trying to submit another job.
07:40:44 job_callback for (8, 0, 21) got condition
07:40:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:40:44 HBMASTER: Trying to run another job!
07:40:44 job_callback for (8, 0, 21) finished
07:40:44 HBMASTER: schedule new run for iteration 8
07:40:44 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
07:40:44 HBMASTER: submitting job (8, 0, 22) to dispatcher
07:40:44 DISPATCHER: trying to submit job (8, 0, 22)
07:40:44 DISPATCHER: trying to notify the job_runner thread.
07:40:44 HBMASTER: job (8, 0, 22) submitted to dispatcher
07:40:44 DISPATCHER: Trying to submit another job.
07:40:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:40:44 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:40:44 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:40:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:40:44 WORKER: start processing job (8, 0, 22)
07:40:44 WORKER: args: ()
07:40:44 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 76, 'last_n_outputs': 6, 'lr': 0.0021650961550666726, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.011157945271451773}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-570:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:41:22 DISPATCHER: Starting worker discovery
07:41:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:41:22 DISPATCHER: Finished worker discovery
07:42:22 DISPATCHER: Starting worker discovery
07:42:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:42:22 DISPATCHER: Finished worker discovery
07:43:06 WORKER: done with job (8, 0, 22), trying to register it.
07:43:06 WORKER: registered result for job (8, 0, 22) with dispatcher
07:43:06 DISPATCHER: job (8, 0, 22) finished
07:43:06 DISPATCHER: register_result: lock acquired
07:43:06 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:43:06 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 76, 'last_n_outputs': 6, 'lr': 0.0021650961550666726, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.011157945271451773}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5459069691679045, 'info': {'music-speech': 0.5459069691679045, 'config': "{'batch_size': 128, 'hidden_dim': 76, 'last_n_outputs': 6, 'lr': 0.0021650961550666726, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 40, 'weight_decay': 0.011157945271451773}"}}
exception: None

07:43:06 job_callback for (8, 0, 22) started
07:43:06 DISPATCHER: Trying to submit another job.
07:43:06 job_callback for (8, 0, 22) got condition
07:43:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:43:06 HBMASTER: Trying to run another job!
07:43:06 job_callback for (8, 0, 22) finished
07:43:06 HBMASTER: schedule new run for iteration 8
07:43:06 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
07:43:06 HBMASTER: submitting job (8, 0, 26) to dispatcher
07:43:06 DISPATCHER: trying to submit job (8, 0, 26)
07:43:06 DISPATCHER: trying to notify the job_runner thread.
07:43:06 HBMASTER: job (8, 0, 26) submitted to dispatcher
07:43:06 DISPATCHER: Trying to submit another job.
07:43:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:43:06 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:43:06 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:43:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:43:06 WORKER: start processing job (8, 0, 26)
07:43:06 WORKER: args: ()
07:43:06 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 97, 'last_n_outputs': 22, 'lr': 0.0038945778168496346, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.035736446274343074}, 'budget': 133.33333333333331, 'working_directory': '.'}
07:43:22 DISPATCHER: Starting worker discovery
07:43:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:43:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-571:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:44:22 DISPATCHER: Starting worker discovery
07:44:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:44:22 DISPATCHER: Finished worker discovery
07:45:22 DISPATCHER: Starting worker discovery
07:45:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:45:22 DISPATCHER: Finished worker discovery
07:45:28 WORKER: done with job (8, 0, 26), trying to register it.
07:45:28 WORKER: registered result for job (8, 0, 26) with dispatcher
07:45:28 DISPATCHER: job (8, 0, 26) finished
07:45:28 DISPATCHER: register_result: lock acquired
07:45:28 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:45:28 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 97, 'last_n_outputs': 22, 'lr': 0.0038945778168496346, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.035736446274343074}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6477049208240037, 'info': {'music-speech': 0.6477049208240037, 'config': "{'batch_size': 32, 'hidden_dim': 97, 'last_n_outputs': 22, 'lr': 0.0038945778168496346, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 75, 'weight_decay': 0.035736446274343074}"}}
exception: None

07:45:28 job_callback for (8, 0, 26) started
07:45:28 DISPATCHER: Trying to submit another job.
07:45:28 job_callback for (8, 0, 26) got condition
07:45:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:45:28 HBMASTER: Trying to run another job!
07:45:28 job_callback for (8, 0, 26) finished
07:45:28 ITERATION: Advancing config (8, 0, 0) to next budget 400.000000
07:45:28 ITERATION: Advancing config (8, 0, 5) to next budget 400.000000
07:45:28 ITERATION: Advancing config (8, 0, 21) to next budget 400.000000
07:45:28 HBMASTER: schedule new run for iteration 8
07:45:28 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
07:45:28 HBMASTER: submitting job (8, 0, 0) to dispatcher
07:45:28 DISPATCHER: trying to submit job (8, 0, 0)
07:45:28 DISPATCHER: trying to notify the job_runner thread.
07:45:28 HBMASTER: job (8, 0, 0) submitted to dispatcher
07:45:28 DISPATCHER: Trying to submit another job.
07:45:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:45:28 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:45:28 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:45:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:45:28 WORKER: start processing job (8, 0, 0)
07:45:28 WORKER: args: ()
07:45:28 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 9, 'lr': 0.0016291668639488728, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.01965784315149041}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-572:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:46:22 DISPATCHER: Starting worker discovery
07:46:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:46:22 DISPATCHER: Finished worker discovery
07:47:22 DISPATCHER: Starting worker discovery
07:47:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:47:22 DISPATCHER: Finished worker discovery
07:48:22 DISPATCHER: Starting worker discovery
07:48:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:48:22 DISPATCHER: Finished worker discovery
07:49:22 DISPATCHER: Starting worker discovery
07:49:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:49:22 DISPATCHER: Finished worker discovery
07:50:22 DISPATCHER: Starting worker discovery
07:50:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:50:22 DISPATCHER: Finished worker discovery
07:51:22 DISPATCHER: Starting worker discovery
07:51:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:51:22 DISPATCHER: Finished worker discovery
07:52:17 WORKER: done with job (8, 0, 0), trying to register it.
07:52:17 WORKER: registered result for job (8, 0, 0) with dispatcher
07:52:17 DISPATCHER: job (8, 0, 0) finished
07:52:17 DISPATCHER: register_result: lock acquired
07:52:17 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:52:17 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 9, 'lr': 0.0016291668639488728, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.01965784315149041}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9877863972708671, 'info': {'music-speech': 0.9877863972708671, 'config': "{'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 9, 'lr': 0.0016291668639488728, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.01965784315149041}"}}
exception: None

07:52:17 job_callback for (8, 0, 0) started
07:52:17 DISPATCHER: Trying to submit another job.
07:52:17 job_callback for (8, 0, 0) got condition
07:52:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:52:17 done building a new model for budget 400.000000 based on 9/21 split
Best loss for this budget:-0.994929





07:52:17 HBMASTER: Trying to run another job!
07:52:17 job_callback for (8, 0, 0) finished
07:52:17 HBMASTER: schedule new run for iteration 8
07:52:17 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
07:52:17 HBMASTER: submitting job (8, 0, 5) to dispatcher
07:52:17 DISPATCHER: trying to submit job (8, 0, 5)
07:52:17 DISPATCHER: trying to notify the job_runner thread.
07:52:17 HBMASTER: job (8, 0, 5) submitted to dispatcher
07:52:17 DISPATCHER: Trying to submit another job.
07:52:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:52:17 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:52:17 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:52:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:52:17 WORKER: start processing job (8, 0, 5)
07:52:17 WORKER: args: ()
07:52:17 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 39, 'last_n_outputs': 18, 'lr': 0.0033402164111182406, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.08716038111659165}, 'budget': 400.0, 'working_directory': '.'}
07:52:22 DISPATCHER: Starting worker discovery
07:52:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:52:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-573:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:53:22 DISPATCHER: Starting worker discovery
07:53:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:53:22 DISPATCHER: Finished worker discovery
07:54:22 DISPATCHER: Starting worker discovery
07:54:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:54:22 DISPATCHER: Finished worker discovery
07:55:22 DISPATCHER: Starting worker discovery
07:55:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:55:22 DISPATCHER: Finished worker discovery
07:56:22 DISPATCHER: Starting worker discovery
07:56:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:56:22 DISPATCHER: Finished worker discovery
07:57:22 DISPATCHER: Starting worker discovery
07:57:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:57:22 DISPATCHER: Finished worker discovery
07:58:22 DISPATCHER: Starting worker discovery
07:58:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:58:22 DISPATCHER: Finished worker discovery
07:59:06 WORKER: done with job (8, 0, 5), trying to register it.
07:59:06 WORKER: registered result for job (8, 0, 5) with dispatcher
07:59:06 DISPATCHER: job (8, 0, 5) finished
07:59:06 DISPATCHER: register_result: lock acquired
07:59:06 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
07:59:06 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 39, 'last_n_outputs': 18, 'lr': 0.0033402164111182406, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.08716038111659165}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7907578673978658, 'info': {'music-speech': 0.7907578673978658, 'config': "{'batch_size': 32, 'hidden_dim': 39, 'last_n_outputs': 18, 'lr': 0.0033402164111182406, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.08716038111659165}"}}
exception: None

07:59:06 job_callback for (8, 0, 5) started
07:59:06 DISPATCHER: Trying to submit another job.
07:59:06 job_callback for (8, 0, 5) got condition
07:59:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
07:59:06 done building a new model for budget 400.000000 based on 9/22 split
Best loss for this budget:-0.994929





07:59:06 HBMASTER: Trying to run another job!
07:59:06 job_callback for (8, 0, 5) finished
07:59:06 HBMASTER: schedule new run for iteration 8
07:59:06 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
07:59:06 HBMASTER: submitting job (8, 0, 21) to dispatcher
07:59:06 DISPATCHER: trying to submit job (8, 0, 21)
07:59:06 DISPATCHER: trying to notify the job_runner thread.
07:59:06 HBMASTER: job (8, 0, 21) submitted to dispatcher
07:59:06 DISPATCHER: Trying to submit another job.
07:59:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
07:59:06 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216
07:59:06 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
07:59:06 WORKER: start processing job (8, 0, 21)
07:59:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
07:59:06 WORKER: args: ()
07:59:06 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 72, 'last_n_outputs': 44, 'lr': 0.002470472309062781, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.07975016922103793}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-574:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

07:59:22 DISPATCHER: Starting worker discovery
07:59:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
07:59:22 DISPATCHER: Finished worker discovery
08:00:22 DISPATCHER: Starting worker discovery
08:00:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:00:22 DISPATCHER: Finished worker discovery
08:01:22 DISPATCHER: Starting worker discovery
08:01:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:01:22 DISPATCHER: Finished worker discovery
08:02:22 DISPATCHER: Starting worker discovery
08:02:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:02:22 DISPATCHER: Finished worker discovery
08:03:22 DISPATCHER: Starting worker discovery
08:03:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:03:22 DISPATCHER: Finished worker discovery
08:04:22 DISPATCHER: Starting worker discovery
08:04:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:04:22 DISPATCHER: Finished worker discovery
08:05:22 DISPATCHER: Starting worker discovery
08:05:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:05:22 DISPATCHER: Finished worker discovery
08:05:55 WORKER: done with job (8, 0, 21), trying to register it.
08:05:55 WORKER: registered result for job (8, 0, 21) with dispatcher
08:05:55 DISPATCHER: job (8, 0, 21) finished
08:05:55 DISPATCHER: register_result: lock acquired
08:05:55 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:05:55 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 72, 'last_n_outputs': 44, 'lr': 0.002470472309062781, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.07975016922103793}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6788837147497113, 'info': {'music-speech': 0.6788837147497113, 'config': "{'batch_size': 128, 'hidden_dim': 72, 'last_n_outputs': 44, 'lr': 0.002470472309062781, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 23, 'weight_decay': 0.07975016922103793}"}}
exception: None

08:05:55 job_callback for (8, 0, 21) started
08:05:55 DISPATCHER: Trying to submit another job.
08:05:55 job_callback for (8, 0, 21) got condition
08:05:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:05:55 done building a new model for budget 400.000000 based on 9/22 split
Best loss for this budget:-0.994929





08:05:55 HBMASTER: Trying to run another job!
08:05:55 job_callback for (8, 0, 21) finished
08:05:55 ITERATION: Advancing config (8, 0, 0) to next budget 1200.000000
08:05:55 HBMASTER: schedule new run for iteration 8
08:05:55 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
08:05:55 HBMASTER: submitting job (8, 0, 0) to dispatcher
08:05:55 DISPATCHER: trying to submit job (8, 0, 0)
08:05:55 DISPATCHER: trying to notify the job_runner thread.
08:05:55 HBMASTER: job (8, 0, 0) submitted to dispatcher
08:05:55 DISPATCHER: Trying to submit another job.
08:05:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:05:55 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:05:55 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:05:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:05:55 WORKER: start processing job (8, 0, 0)
08:05:55 WORKER: args: ()
08:05:55 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 9, 'lr': 0.0016291668639488728, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.01965784315149041}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-575:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:06:22 DISPATCHER: Starting worker discovery
08:06:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:06:22 DISPATCHER: Finished worker discovery
08:07:22 DISPATCHER: Starting worker discovery
08:07:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:07:22 DISPATCHER: Finished worker discovery
08:08:22 DISPATCHER: Starting worker discovery
08:08:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:08:22 DISPATCHER: Finished worker discovery
08:09:22 DISPATCHER: Starting worker discovery
08:09:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:09:22 DISPATCHER: Finished worker discovery
08:10:22 DISPATCHER: Starting worker discovery
08:10:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:10:22 DISPATCHER: Finished worker discovery
08:11:22 DISPATCHER: Starting worker discovery
08:11:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:11:22 DISPATCHER: Finished worker discovery
08:12:22 DISPATCHER: Starting worker discovery
08:12:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:12:22 DISPATCHER: Finished worker discovery
08:13:22 DISPATCHER: Starting worker discovery
08:13:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:13:22 DISPATCHER: Finished worker discovery
08:14:22 DISPATCHER: Starting worker discovery
08:14:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:14:22 DISPATCHER: Finished worker discovery
08:15:22 DISPATCHER: Starting worker discovery
08:15:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:15:22 DISPATCHER: Finished worker discovery
08:16:22 DISPATCHER: Starting worker discovery
08:16:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:16:22 DISPATCHER: Finished worker discovery
08:17:22 DISPATCHER: Starting worker discovery
08:17:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:17:22 DISPATCHER: Finished worker discovery
08:18:22 DISPATCHER: Starting worker discovery
08:18:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:18:22 DISPATCHER: Finished worker discovery
08:19:22 DISPATCHER: Starting worker discovery
08:19:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:19:22 DISPATCHER: Finished worker discovery
08:20:22 DISPATCHER: Starting worker discovery
08:20:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:20:22 DISPATCHER: Finished worker discovery
08:21:22 DISPATCHER: Starting worker discovery
08:21:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:21:22 DISPATCHER: Finished worker discovery
08:22:22 DISPATCHER: Starting worker discovery
08:22:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:22:22 DISPATCHER: Finished worker discovery
08:23:22 DISPATCHER: Starting worker discovery
08:23:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:23:22 DISPATCHER: Finished worker discovery
08:24:22 DISPATCHER: Starting worker discovery
08:24:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:24:22 DISPATCHER: Finished worker discovery
08:25:22 DISPATCHER: Starting worker discovery
08:25:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:25:22 DISPATCHER: Finished worker discovery
08:26:03 WORKER: done with job (8, 0, 0), trying to register it.
08:26:03 WORKER: registered result for job (8, 0, 0) with dispatcher
08:26:03 DISPATCHER: job (8, 0, 0) finished
08:26:03 DISPATCHER: register_result: lock acquired
08:26:03 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:26:03 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 9, 'lr': 0.0016291668639488728, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.01965784315149041}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.8249670768371749, 'info': {'music-speech': 0.8249670768371749, 'config': "{'batch_size': 64, 'hidden_dim': 94, 'last_n_outputs': 9, 'lr': 0.0016291668639488728, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.01965784315149041}"}}
exception: None

08:26:03 job_callback for (8, 0, 0) started
08:26:03 DISPATCHER: Trying to submit another job.
08:26:03 job_callback for (8, 0, 0) got condition
08:26:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:26:03 HBMASTER: Trying to run another job!
08:26:03 job_callback for (8, 0, 0) finished
08:26:03 start sampling a new configuration.
08:26:04 best_vector: [2, 0.2112857878663772, 0.0375392746102699, 0.23090979762378688, 0.48881833704605226, 0, 0.42124008872704144, 0.8780150893497437], 0.001221182152528343, 1.2750324127124848, 0.0015570468262996386
08:26:04 done sampling a new configuration.
08:26:04 HBMASTER: schedule new run for iteration 9
08:26:04 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
08:26:04 HBMASTER: submitting job (9, 0, 0) to dispatcher
08:26:04 DISPATCHER: trying to submit job (9, 0, 0)
08:26:04 DISPATCHER: trying to notify the job_runner thread.
08:26:04 HBMASTER: job (9, 0, 0) submitted to dispatcher
08:26:04 DISPATCHER: Trying to submit another job.
08:26:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:26:04 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:26:04 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:26:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:26:04 WORKER: start processing job (9, 0, 0)
08:26:04 WORKER: args: ()
08:26:04 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 37, 'last_n_outputs': 2, 'lr': 0.002896140288957065, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.13877906842226206}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-576:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:26:22 DISPATCHER: Starting worker discovery
08:26:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:26:22 DISPATCHER: Finished worker discovery
08:27:22 DISPATCHER: Starting worker discovery
08:27:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:27:22 DISPATCHER: Finished worker discovery
08:28:22 DISPATCHER: Starting worker discovery
08:28:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:28:22 DISPATCHER: Finished worker discovery
08:28:25 WORKER: done with job (9, 0, 0), trying to register it.
08:28:25 WORKER: registered result for job (9, 0, 0) with dispatcher
08:28:25 DISPATCHER: job (9, 0, 0) finished
08:28:25 DISPATCHER: register_result: lock acquired
08:28:25 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:28:25 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 37, 'last_n_outputs': 2, 'lr': 0.002896140288957065, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.13877906842226206}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 64, 'hidden_dim': 37, 'last_n_outputs': 2, 'lr': 0.002896140288957065, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 48, 'weight_decay': 0.13877906842226206}"}}
exception: None

08:28:25 job_callback for (9, 0, 0) started
08:28:25 DISPATCHER: Trying to submit another job.
08:28:25 job_callback for (9, 0, 0) got condition
08:28:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:28:25 HBMASTER: Trying to run another job!
08:28:25 job_callback for (9, 0, 0) finished
08:28:25 start sampling a new configuration.
08:28:25 done sampling a new configuration.
08:28:25 HBMASTER: schedule new run for iteration 9
08:28:25 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
08:28:25 HBMASTER: submitting job (9, 0, 1) to dispatcher
08:28:25 DISPATCHER: trying to submit job (9, 0, 1)
08:28:25 DISPATCHER: trying to notify the job_runner thread.
08:28:25 HBMASTER: job (9, 0, 1) submitted to dispatcher
08:28:25 DISPATCHER: Trying to submit another job.
08:28:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:28:25 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:28:25 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:28:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:28:25 WORKER: start processing job (9, 0, 1)
08:28:25 WORKER: args: ()
08:28:25 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 39, 'last_n_outputs': 9, 'lr': 0.09524451227868569, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.018281342841265747}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-577:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:29:22 DISPATCHER: Starting worker discovery
08:29:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:29:22 DISPATCHER: Finished worker discovery
08:30:22 DISPATCHER: Starting worker discovery
08:30:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:30:22 DISPATCHER: Finished worker discovery
08:30:48 WORKER: done with job (9, 0, 1), trying to register it.
08:30:48 WORKER: registered result for job (9, 0, 1) with dispatcher
08:30:48 DISPATCHER: job (9, 0, 1) finished
08:30:48 DISPATCHER: register_result: lock acquired
08:30:48 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:30:48 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 39, 'last_n_outputs': 9, 'lr': 0.09524451227868569, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.018281342841265747}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7043185912958184, 'info': {'music-speech': 0.7043185912958184, 'config': "{'batch_size': 128, 'hidden_dim': 39, 'last_n_outputs': 9, 'lr': 0.09524451227868569, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.018281342841265747}"}}
exception: None

08:30:48 job_callback for (9, 0, 1) started
08:30:48 DISPATCHER: Trying to submit another job.
08:30:48 job_callback for (9, 0, 1) got condition
08:30:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:30:48 HBMASTER: Trying to run another job!
08:30:48 job_callback for (9, 0, 1) finished
08:30:48 start sampling a new configuration.
08:30:48 done sampling a new configuration.
08:30:48 HBMASTER: schedule new run for iteration 9
08:30:48 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
08:30:48 HBMASTER: submitting job (9, 0, 2) to dispatcher
08:30:48 DISPATCHER: trying to submit job (9, 0, 2)
08:30:48 DISPATCHER: trying to notify the job_runner thread.
08:30:48 HBMASTER: job (9, 0, 2) submitted to dispatcher
08:30:48 DISPATCHER: Trying to submit another job.
08:30:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:30:48 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:30:48 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:30:48 WORKER: start processing job (9, 0, 2)
08:30:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:30:48 WORKER: args: ()
08:30:48 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 91, 'last_n_outputs': 35, 'lr': 0.022126519337603564, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.012489541934324451}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-578:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:31:22 DISPATCHER: Starting worker discovery
08:31:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:31:22 DISPATCHER: Finished worker discovery
08:32:22 DISPATCHER: Starting worker discovery
08:32:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:32:22 DISPATCHER: Finished worker discovery
08:33:09 WORKER: done with job (9, 0, 2), trying to register it.
08:33:09 DISPATCHER: job (9, 0, 2) finished
08:33:09 WORKER: registered result for job (9, 0, 2) with dispatcher
08:33:09 DISPATCHER: register_result: lock acquired
08:33:09 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:33:09 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 91, 'last_n_outputs': 35, 'lr': 0.022126519337603564, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.012489541934324451}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4695590400513885, 'info': {'music-speech': 0.4695590400513885, 'config': "{'batch_size': 128, 'hidden_dim': 91, 'last_n_outputs': 35, 'lr': 0.022126519337603564, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.012489541934324451}"}}
exception: None

08:33:09 job_callback for (9, 0, 2) started
08:33:09 DISPATCHER: Trying to submit another job.
08:33:09 job_callback for (9, 0, 2) got condition
08:33:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:33:09 HBMASTER: Trying to run another job!
08:33:09 job_callback for (9, 0, 2) finished
08:33:09 start sampling a new configuration.
08:33:09 done sampling a new configuration.
08:33:09 HBMASTER: schedule new run for iteration 9
08:33:09 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
08:33:09 HBMASTER: submitting job (9, 0, 3) to dispatcher
08:33:09 DISPATCHER: trying to submit job (9, 0, 3)
08:33:09 DISPATCHER: trying to notify the job_runner thread.
08:33:09 HBMASTER: job (9, 0, 3) submitted to dispatcher
08:33:09 DISPATCHER: Trying to submit another job.
08:33:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:33:09 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:33:09 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:33:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:33:09 WORKER: start processing job (9, 0, 3)
08:33:09 WORKER: args: ()
08:33:09 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 91, 'last_n_outputs': 6, 'lr': 0.015833866889369486, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.010821658612691165}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:33:22 DISPATCHER: Starting worker discovery
08:33:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:33:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-579:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:34:22 DISPATCHER: Starting worker discovery
08:34:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:34:22 DISPATCHER: Finished worker discovery
08:35:22 DISPATCHER: Starting worker discovery
08:35:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:35:22 DISPATCHER: Finished worker discovery
08:35:31 WORKER: done with job (9, 0, 3), trying to register it.
08:35:31 WORKER: registered result for job (9, 0, 3) with dispatcher
08:35:31 DISPATCHER: job (9, 0, 3) finished
08:35:31 DISPATCHER: register_result: lock acquired
08:35:31 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:35:31 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 91, 'last_n_outputs': 6, 'lr': 0.015833866889369486, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.010821658612691165}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 91, 'last_n_outputs': 6, 'lr': 0.015833866889369486, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 44, 'weight_decay': 0.010821658612691165}"}}
exception: None

08:35:31 job_callback for (9, 0, 3) started
08:35:31 DISPATCHER: Trying to submit another job.
08:35:31 job_callback for (9, 0, 3) got condition
08:35:31 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:35:31 HBMASTER: Trying to run another job!
08:35:31 job_callback for (9, 0, 3) finished
08:35:31 start sampling a new configuration.
08:35:31 best_vector: [1, 0.9831825534477862, 0.2645403215558917, 0.10720910104212712, 0.15520935368554456, 0, 0.2678871801996434, 0.0475981497549548], 0.001854392813248848, 0.6726303034986986, 0.0012473208007813782
08:35:31 done sampling a new configuration.
08:35:31 HBMASTER: schedule new run for iteration 9
08:35:31 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
08:35:31 HBMASTER: submitting job (9, 0, 4) to dispatcher
08:35:31 DISPATCHER: trying to submit job (9, 0, 4)
08:35:31 DISPATCHER: trying to notify the job_runner thread.
08:35:31 HBMASTER: job (9, 0, 4) submitted to dispatcher
08:35:31 DISPATCHER: Trying to submit another job.
08:35:31 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:35:31 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:35:31 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:35:31 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:35:31 WORKER: start processing job (9, 0, 4)
08:35:31 WORKER: args: ()
08:35:31 WORKER: kwargs: {'config': {'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 14, 'lr': 0.0016383934462865207, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.011532583840733057}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-580:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:36:22 DISPATCHER: Starting worker discovery
08:36:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:36:22 DISPATCHER: Finished worker discovery
08:37:22 DISPATCHER: Starting worker discovery
08:37:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:37:22 DISPATCHER: Finished worker discovery
08:37:53 WORKER: done with job (9, 0, 4), trying to register it.
08:37:53 DISPATCHER: job (9, 0, 4) finished
08:37:53 WORKER: registered result for job (9, 0, 4) with dispatcher
08:37:53 DISPATCHER: register_result: lock acquired
08:37:53 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:37:53 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 14, 'lr': 0.0016383934462865207, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.011532583840733057}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6818691239160428, 'info': {'music-speech': 0.6818691239160428, 'config': "{'batch_size': 32, 'hidden_dim': 99, 'last_n_outputs': 14, 'lr': 0.0016383934462865207, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 34, 'weight_decay': 0.011532583840733057}"}}
exception: None

08:37:53 job_callback for (9, 0, 4) started
08:37:53 DISPATCHER: Trying to submit another job.
08:37:53 job_callback for (9, 0, 4) got condition
08:37:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:37:53 HBMASTER: Trying to run another job!
08:37:53 job_callback for (9, 0, 4) finished
08:37:53 start sampling a new configuration.
08:37:53 done sampling a new configuration.
08:37:53 HBMASTER: schedule new run for iteration 9
08:37:53 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
08:37:53 HBMASTER: submitting job (9, 0, 5) to dispatcher
08:37:53 DISPATCHER: trying to submit job (9, 0, 5)
08:37:53 DISPATCHER: trying to notify the job_runner thread.
08:37:53 HBMASTER: job (9, 0, 5) submitted to dispatcher
08:37:53 DISPATCHER: Trying to submit another job.
08:37:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:37:53 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:37:53 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:37:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:37:53 WORKER: start processing job (9, 0, 5)
08:37:53 WORKER: args: ()
08:37:53 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 23, 'last_n_outputs': 9, 'lr': 0.0043164185993877155, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.08696696440025299}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-581:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:38:22 DISPATCHER: Starting worker discovery
08:38:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:38:22 DISPATCHER: Finished worker discovery
08:39:22 DISPATCHER: Starting worker discovery
08:39:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:39:22 DISPATCHER: Finished worker discovery
08:40:15 WORKER: done with job (9, 0, 5), trying to register it.
08:40:15 WORKER: registered result for job (9, 0, 5) with dispatcher
08:40:15 DISPATCHER: job (9, 0, 5) finished
08:40:15 DISPATCHER: register_result: lock acquired
08:40:15 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:40:15 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 23, 'last_n_outputs': 9, 'lr': 0.0043164185993877155, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.08696696440025299}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9158256115995513, 'info': {'music-speech': 0.9158256115995513, 'config': "{'batch_size': 64, 'hidden_dim': 23, 'last_n_outputs': 9, 'lr': 0.0043164185993877155, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.08696696440025299}"}}
exception: None

08:40:15 job_callback for (9, 0, 5) started
08:40:15 DISPATCHER: Trying to submit another job.
08:40:15 job_callback for (9, 0, 5) got condition
08:40:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:40:15 HBMASTER: Trying to run another job!
08:40:15 job_callback for (9, 0, 5) finished
08:40:15 start sampling a new configuration.
08:40:16 best_vector: [3, 0.10357694713980892, 0.17599034704042799, 0.25653167657779075, 0.6270010162732765, 0, 0.1740359882426375, 0.6436516009056922], 0.003944742659100954, 0.9252079195364495, 0.003649707148733475
08:40:16 done sampling a new configuration.
08:40:16 HBMASTER: schedule new run for iteration 9
08:40:16 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
08:40:16 HBMASTER: submitting job (9, 0, 6) to dispatcher
08:40:16 DISPATCHER: trying to submit job (9, 0, 6)
08:40:16 DISPATCHER: trying to notify the job_runner thread.
08:40:16 HBMASTER: job (9, 0, 6) submitted to dispatcher
08:40:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:40:16 DISPATCHER: Trying to submit another job.
08:40:16 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:40:16 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:40:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:40:16 WORKER: start processing job (9, 0, 6)
08:40:16 WORKER: args: ()
08:40:16 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 28, 'last_n_outputs': 9, 'lr': 0.003258842362339537, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.06877174426452569}, 'budget': 133.33333333333331, 'working_directory': '.'}
08:40:22 DISPATCHER: Starting worker discovery
08:40:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:40:22 DISPATCHER: Finished worker discovery
Exception in thread Thread-582:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:41:22 DISPATCHER: Starting worker discovery
08:41:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:41:22 DISPATCHER: Finished worker discovery
08:42:22 DISPATCHER: Starting worker discovery
08:42:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:42:22 DISPATCHER: Finished worker discovery
08:42:37 WORKER: done with job (9, 0, 6), trying to register it.
08:42:37 WORKER: registered result for job (9, 0, 6) with dispatcher
08:42:37 DISPATCHER: job (9, 0, 6) finished
08:42:37 DISPATCHER: register_result: lock acquired
08:42:37 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:42:37 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 28, 'last_n_outputs': 9, 'lr': 0.003258842362339537, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.06877174426452569}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 128, 'hidden_dim': 28, 'last_n_outputs': 9, 'lr': 0.003258842362339537, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.06877174426452569}"}}
exception: None

08:42:37 job_callback for (9, 0, 6) started
08:42:38 DISPATCHER: Trying to submit another job.
08:42:38 job_callback for (9, 0, 6) got condition
08:42:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:42:38 HBMASTER: Trying to run another job!
08:42:38 job_callback for (9, 0, 6) finished
08:42:38 start sampling a new configuration.
08:42:38 done sampling a new configuration.
08:42:38 HBMASTER: schedule new run for iteration 9
08:42:38 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
08:42:38 HBMASTER: submitting job (9, 0, 7) to dispatcher
08:42:38 DISPATCHER: trying to submit job (9, 0, 7)
08:42:38 DISPATCHER: trying to notify the job_runner thread.
08:42:38 HBMASTER: job (9, 0, 7) submitted to dispatcher
08:42:38 DISPATCHER: Trying to submit another job.
08:42:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:42:38 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:42:38 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:42:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:42:38 WORKER: start processing job (9, 0, 7)
08:42:38 WORKER: args: ()
08:42:38 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 100, 'last_n_outputs': 19, 'lr': 0.014598409601802522, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.03546934260196228}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-583:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:43:22 DISPATCHER: Starting worker discovery
08:43:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:43:22 DISPATCHER: Finished worker discovery
08:44:22 DISPATCHER: Starting worker discovery
08:44:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:44:22 DISPATCHER: Finished worker discovery
08:45:00 WORKER: done with job (9, 0, 7), trying to register it.
08:45:00 WORKER: registered result for job (9, 0, 7) with dispatcher
08:45:00 DISPATCHER: job (9, 0, 7) finished
08:45:00 DISPATCHER: register_result: lock acquired
08:45:00 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:45:00 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 100, 'last_n_outputs': 19, 'lr': 0.014598409601802522, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.03546934260196228}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7513524560838666, 'info': {'music-speech': 0.7513524560838666, 'config': "{'batch_size': 128, 'hidden_dim': 100, 'last_n_outputs': 19, 'lr': 0.014598409601802522, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.03546934260196228}"}}
exception: None

08:45:00 job_callback for (9, 0, 7) started
08:45:00 DISPATCHER: Trying to submit another job.
08:45:00 job_callback for (9, 0, 7) got condition
08:45:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:45:00 HBMASTER: Trying to run another job!
08:45:00 job_callback for (9, 0, 7) finished
08:45:00 start sampling a new configuration.
08:45:00 best_vector: [0, 0.4892707064716741, 0.252377603890523, 0.8591206480909206, 0.49761855067520416, 1, 0.04679159646552805, 0.5311677124071048], 0.0, inf, 0.05095021606449172
08:45:00 done sampling a new configuration.
08:45:00 HBMASTER: schedule new run for iteration 9
08:45:00 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
08:45:00 HBMASTER: submitting job (9, 0, 8) to dispatcher
08:45:00 DISPATCHER: trying to submit job (9, 0, 8)
08:45:00 DISPATCHER: trying to notify the job_runner thread.
08:45:00 HBMASTER: job (9, 0, 8) submitted to dispatcher
08:45:00 DISPATCHER: Trying to submit another job.
08:45:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:45:00 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:45:00 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:45:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:45:00 WORKER: start processing job (9, 0, 8)
08:45:00 WORKER: args: ()
08:45:00 WORKER: kwargs: {'config': {'batch_size': 16, 'hidden_dim': 59, 'last_n_outputs': 13, 'lr': 0.0522686515575145, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.04909814979570066}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-584:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:45:22 DISPATCHER: Starting worker discovery
08:45:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:45:22 DISPATCHER: Finished worker discovery
08:46:22 DISPATCHER: Starting worker discovery
08:46:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:46:23 DISPATCHER: Finished worker discovery
08:47:22 WORKER: done with job (9, 0, 8), trying to register it.
08:47:22 DISPATCHER: job (9, 0, 8) finished
08:47:22 WORKER: registered result for job (9, 0, 8) with dispatcher
08:47:22 DISPATCHER: register_result: lock acquired
08:47:22 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:47:22 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 16, 'hidden_dim': 59, 'last_n_outputs': 13, 'lr': 0.0522686515575145, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.04909814979570066}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 16, 'hidden_dim': 59, 'last_n_outputs': 13, 'lr': 0.0522686515575145, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.04909814979570066}"}}
exception: None

08:47:22 job_callback for (9, 0, 8) started
08:47:22 DISPATCHER: Trying to submit another job.
08:47:22 job_callback for (9, 0, 8) got condition
08:47:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:47:22 HBMASTER: Trying to run another job!
08:47:22 job_callback for (9, 0, 8) finished
08:47:22 ITERATION: Advancing config (9, 0, 1) to next budget 400.000000
08:47:22 ITERATION: Advancing config (9, 0, 5) to next budget 400.000000
08:47:22 ITERATION: Advancing config (9, 0, 7) to next budget 400.000000
08:47:22 HBMASTER: schedule new run for iteration 9
08:47:22 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
08:47:22 HBMASTER: submitting job (9, 0, 1) to dispatcher
08:47:22 DISPATCHER: trying to submit job (9, 0, 1)
08:47:22 DISPATCHER: trying to notify the job_runner thread.
08:47:22 HBMASTER: job (9, 0, 1) submitted to dispatcher
08:47:22 DISPATCHER: Trying to submit another job.
08:47:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:47:22 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:47:22 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:47:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:47:22 WORKER: start processing job (9, 0, 1)
08:47:22 WORKER: args: ()
08:47:22 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 39, 'last_n_outputs': 9, 'lr': 0.09524451227868569, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.018281342841265747}, 'budget': 400.0, 'working_directory': '.'}
08:47:23 DISPATCHER: Starting worker discovery
08:47:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:47:23 DISPATCHER: Finished worker discovery
Exception in thread Thread-585:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:48:23 DISPATCHER: Starting worker discovery
08:48:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:48:23 DISPATCHER: Finished worker discovery
08:49:23 DISPATCHER: Starting worker discovery
08:49:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:49:23 DISPATCHER: Finished worker discovery
08:50:23 DISPATCHER: Starting worker discovery
08:50:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:50:23 DISPATCHER: Finished worker discovery
08:51:23 DISPATCHER: Starting worker discovery
08:51:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:51:23 DISPATCHER: Finished worker discovery
08:52:23 DISPATCHER: Starting worker discovery
08:52:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:52:23 DISPATCHER: Finished worker discovery
08:53:23 DISPATCHER: Starting worker discovery
08:53:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:53:23 DISPATCHER: Finished worker discovery
08:54:11 WORKER: done with job (9, 0, 1), trying to register it.
08:54:11 WORKER: registered result for job (9, 0, 1) with dispatcher
08:54:11 DISPATCHER: job (9, 0, 1) finished
08:54:11 DISPATCHER: register_result: lock acquired
08:54:11 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
08:54:11 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 39, 'last_n_outputs': 9, 'lr': 0.09524451227868569, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.018281342841265747}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.40910324585143726, 'info': {'music-speech': 0.40910324585143726, 'config': "{'batch_size': 128, 'hidden_dim': 39, 'last_n_outputs': 9, 'lr': 0.09524451227868569, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.018281342841265747}"}}
exception: None

08:54:11 job_callback for (9, 0, 1) started
08:54:11 DISPATCHER: Trying to submit another job.
08:54:11 job_callback for (9, 0, 1) got condition
08:54:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
08:54:11 done building a new model for budget 400.000000 based on 9/23 split
Best loss for this budget:-0.994929





08:54:11 HBMASTER: Trying to run another job!
08:54:11 job_callback for (9, 0, 1) finished
08:54:11 HBMASTER: schedule new run for iteration 9
08:54:11 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
08:54:11 HBMASTER: submitting job (9, 0, 5) to dispatcher
08:54:11 DISPATCHER: trying to submit job (9, 0, 5)
08:54:11 DISPATCHER: trying to notify the job_runner thread.
08:54:11 HBMASTER: job (9, 0, 5) submitted to dispatcher
08:54:11 DISPATCHER: Trying to submit another job.
08:54:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
08:54:11 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
08:54:11 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
08:54:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
08:54:11 WORKER: start processing job (9, 0, 5)
08:54:11 WORKER: args: ()
08:54:11 WORKER: kwargs: {'config': {'batch_size': 64, 'hidden_dim': 23, 'last_n_outputs': 9, 'lr': 0.0043164185993877155, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.08696696440025299}, 'budget': 400.0, 'working_directory': '.'}
08:54:23 DISPATCHER: Starting worker discovery
08:54:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:54:23 DISPATCHER: Finished worker discovery
Exception in thread Thread-586:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

08:55:23 DISPATCHER: Starting worker discovery
08:55:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:55:23 DISPATCHER: Finished worker discovery
08:56:23 DISPATCHER: Starting worker discovery
08:56:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:56:23 DISPATCHER: Finished worker discovery
08:57:23 DISPATCHER: Starting worker discovery
08:57:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:57:23 DISPATCHER: Finished worker discovery
08:58:23 DISPATCHER: Starting worker discovery
08:58:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:58:23 DISPATCHER: Finished worker discovery
08:59:23 DISPATCHER: Starting worker discovery
08:59:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
08:59:23 DISPATCHER: Finished worker discovery
09:00:23 DISPATCHER: Starting worker discovery
09:00:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:00:23 DISPATCHER: Finished worker discovery
09:00:59 WORKER: done with job (9, 0, 5), trying to register it.
09:00:59 WORKER: registered result for job (9, 0, 5) with dispatcher
09:00:59 DISPATCHER: job (9, 0, 5) finished
09:00:59 DISPATCHER: register_result: lock acquired
09:00:59 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:00:59 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 64, 'hidden_dim': 23, 'last_n_outputs': 9, 'lr': 0.0043164185993877155, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.08696696440025299}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6955570878736245, 'info': {'music-speech': 0.6955570878736245, 'config': "{'batch_size': 64, 'hidden_dim': 23, 'last_n_outputs': 9, 'lr': 0.0043164185993877155, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 92, 'weight_decay': 0.08696696440025299}"}}
exception: None

09:00:59 job_callback for (9, 0, 5) started
09:00:59 DISPATCHER: Trying to submit another job.
09:00:59 job_callback for (9, 0, 5) got condition
09:00:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:00:59 done building a new model for budget 400.000000 based on 9/24 split
Best loss for this budget:-0.994929





09:00:59 HBMASTER: Trying to run another job!
09:00:59 job_callback for (9, 0, 5) finished
09:00:59 HBMASTER: schedule new run for iteration 9
09:00:59 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
09:00:59 HBMASTER: submitting job (9, 0, 7) to dispatcher
09:00:59 DISPATCHER: trying to submit job (9, 0, 7)
09:00:59 DISPATCHER: trying to notify the job_runner thread.
09:00:59 HBMASTER: job (9, 0, 7) submitted to dispatcher
09:00:59 DISPATCHER: Trying to submit another job.
09:00:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:00:59 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:00:59 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:00:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:00:59 WORKER: start processing job (9, 0, 7)
09:00:59 WORKER: args: ()
09:00:59 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 100, 'last_n_outputs': 19, 'lr': 0.014598409601802522, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.03546934260196228}, 'budget': 400.0, 'working_directory': '.'}
09:01:23 DISPATCHER: Starting worker discovery
09:01:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:01:23 DISPATCHER: Finished worker discovery
Exception in thread Thread-587:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:02:23 DISPATCHER: Starting worker discovery
09:02:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:02:23 DISPATCHER: Finished worker discovery
09:03:23 DISPATCHER: Starting worker discovery
09:03:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:03:23 DISPATCHER: Finished worker discovery
09:04:23 DISPATCHER: Starting worker discovery
09:04:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:04:23 DISPATCHER: Finished worker discovery
09:05:23 DISPATCHER: Starting worker discovery
09:05:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:05:23 DISPATCHER: Finished worker discovery
09:06:23 DISPATCHER: Starting worker discovery
09:06:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:06:23 DISPATCHER: Finished worker discovery
09:07:23 DISPATCHER: Starting worker discovery
09:07:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:07:23 DISPATCHER: Finished worker discovery
09:07:48 WORKER: done with job (9, 0, 7), trying to register it.
09:07:48 WORKER: registered result for job (9, 0, 7) with dispatcher
09:07:48 DISPATCHER: job (9, 0, 7) finished
09:07:48 DISPATCHER: register_result: lock acquired
09:07:48 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:07:48 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 100, 'last_n_outputs': 19, 'lr': 0.014598409601802522, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.03546934260196228}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7329925394825917, 'info': {'music-speech': 0.7329925394825917, 'config': "{'batch_size': 128, 'hidden_dim': 100, 'last_n_outputs': 19, 'lr': 0.014598409601802522, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.03546934260196228}"}}
exception: None

09:07:48 job_callback for (9, 0, 7) started
09:07:48 DISPATCHER: Trying to submit another job.
09:07:48 job_callback for (9, 0, 7) got condition
09:07:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:07:49 done building a new model for budget 400.000000 based on 9/25 split
Best loss for this budget:-0.994929





09:07:49 HBMASTER: Trying to run another job!
09:07:49 job_callback for (9, 0, 7) finished
09:07:49 ITERATION: Advancing config (9, 0, 7) to next budget 1200.000000
09:07:49 HBMASTER: schedule new run for iteration 9
09:07:49 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
09:07:49 HBMASTER: submitting job (9, 0, 7) to dispatcher
09:07:49 DISPATCHER: trying to submit job (9, 0, 7)
09:07:49 DISPATCHER: trying to notify the job_runner thread.
09:07:49 HBMASTER: job (9, 0, 7) submitted to dispatcher
09:07:49 DISPATCHER: Trying to submit another job.
09:07:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:07:49 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:07:49 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:07:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:07:49 WORKER: start processing job (9, 0, 7)
09:07:49 WORKER: args: ()
09:07:49 WORKER: kwargs: {'config': {'batch_size': 128, 'hidden_dim': 100, 'last_n_outputs': 19, 'lr': 0.014598409601802522, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.03546934260196228}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-588:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 235, in trainloop
    loss.backward()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: cudnn RNN backward can only be called in training mode

09:08:23 DISPATCHER: Starting worker discovery
09:08:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:08:23 DISPATCHER: Finished worker discovery
09:09:23 DISPATCHER: Starting worker discovery
09:09:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:09:23 DISPATCHER: Finished worker discovery
09:10:23 DISPATCHER: Starting worker discovery
09:10:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:10:23 DISPATCHER: Finished worker discovery
09:11:23 DISPATCHER: Starting worker discovery
09:11:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:11:23 DISPATCHER: Finished worker discovery
09:12:23 DISPATCHER: Starting worker discovery
09:12:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:12:23 DISPATCHER: Finished worker discovery
09:13:23 DISPATCHER: Starting worker discovery
09:13:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:13:23 DISPATCHER: Finished worker discovery
09:14:23 DISPATCHER: Starting worker discovery
09:14:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:14:23 DISPATCHER: Finished worker discovery
09:15:23 DISPATCHER: Starting worker discovery
09:15:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:15:23 DISPATCHER: Finished worker discovery
09:16:23 DISPATCHER: Starting worker discovery
09:16:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:16:23 DISPATCHER: Finished worker discovery
09:17:23 DISPATCHER: Starting worker discovery
09:17:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:17:23 DISPATCHER: Finished worker discovery
09:18:23 DISPATCHER: Starting worker discovery
09:18:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:18:23 DISPATCHER: Finished worker discovery
09:19:23 DISPATCHER: Starting worker discovery
09:19:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:19:23 DISPATCHER: Finished worker discovery
09:20:23 DISPATCHER: Starting worker discovery
09:20:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:20:23 DISPATCHER: Finished worker discovery
09:21:23 DISPATCHER: Starting worker discovery
09:21:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:21:23 DISPATCHER: Finished worker discovery
09:22:23 DISPATCHER: Starting worker discovery
09:22:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:22:23 DISPATCHER: Finished worker discovery
09:23:23 DISPATCHER: Starting worker discovery
09:23:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:23:23 DISPATCHER: Finished worker discovery
09:24:23 DISPATCHER: Starting worker discovery
09:24:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:24:23 DISPATCHER: Finished worker discovery
09:25:23 DISPATCHER: Starting worker discovery
09:25:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:25:23 DISPATCHER: Finished worker discovery
09:26:23 DISPATCHER: Starting worker discovery
09:26:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:26:23 DISPATCHER: Finished worker discovery
09:27:23 DISPATCHER: Starting worker discovery
09:27:23 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:27:23 DISPATCHER: Finished worker discovery
09:27:58 WORKER: done with job (9, 0, 7), trying to register it.
09:27:58 WORKER: registered result for job (9, 0, 7) with dispatcher
09:27:58 DISPATCHER: job (9, 0, 7) finished
09:27:58 DISPATCHER: register_result: lock acquired
09:27:58 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:27:58 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 128, 'hidden_dim': 100, 'last_n_outputs': 19, 'lr': 0.014598409601802522, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.03546934260196228}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5753992592521047, 'info': {'music-speech': 0.5753992592521047, 'config': "{'batch_size': 128, 'hidden_dim': 100, 'last_n_outputs': 19, 'lr': 0.014598409601802522, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 69, 'weight_decay': 0.03546934260196228}"}}
exception: None

09:27:58 job_callback for (9, 0, 7) started
09:27:58 DISPATCHER: Trying to submit another job.
09:27:58 job_callback for (9, 0, 7) got condition
09:27:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:27:58 done building a new model for budget 1200.000000 based on 9/15 split
Best loss for this budget:-0.858986





09:27:58 HBMASTER: Trying to run another job!
09:27:58 job_callback for (9, 0, 7) finished
09:27:58 HBMASTER: shutdown initiated, shutdown_workers = True
09:27:58 WORKER: shutting down now!
09:27:59 DISPATCHER: Dispatcher shutting down
09:27:59 DISPATCHER: discover_workers shutting down
09:27:59 DISPATCHER: 'discover_worker' thread exited
09:27:59 DISPATCHER: Trying to submit another job.
09:27:59 DISPATCHER: job_runner shutting down
09:27:59 DISPATCHER: 'job_runner' thread exited
09:27:59 DISPATCHER: shut down complete
09:27:59 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7f13f05b2a90; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:39879>
09:27:59 WORKER: No dispatcher found. Waiting for one to initiate contact.
09:27:59 WORKER: start listening for jobs
09:27:59 wait_for_workers trying to get the condition
09:27:59 DISPATCHER: started the 'discover_worker' thread
09:27:59 DISPATCHER: started the 'job_runner' thread
09:27:59 DISPATCHER: Pyro daemon running on localhost:36799
09:27:59 DISPATCHER: Starting worker discovery
09:27:59 DISPATCHER: Found 1 potential workers, 0 currently in the pool.
09:27:59 DISPATCHER: discovered new worker, hpbandster.run_0.worker.metagpul.22021139727314577216
09:27:59 HBMASTER: number of workers changed to 1
09:27:59 Enough workers to start this run!
09:27:59 adjust_queue_size: lock accquired
09:27:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:27:59 HBMASTER: starting run at 1583915279.3103168
09:27:59 HBMASTER: adjusted queue size to (0, 1)
09:27:59 DISPATCHER: Finished worker discovery
09:27:59 start sampling a new configuration.
09:27:59 DISPATCHER: Trying to submit another job.
09:27:59 done sampling a new configuration.
09:27:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:27:59 HBMASTER: schedule new run for iteration 0
09:27:59 HBMASTER: trying submitting job (0, 0, 0) to dispatcher
09:27:59 HBMASTER: submitting job (0, 0, 0) to dispatcher
09:27:59 DISPATCHER: trying to submit job (0, 0, 0)
09:27:59 DISPATCHER: trying to notify the job_runner thread.
09:27:59 HBMASTER: job (0, 0, 0) submitted to dispatcher
09:27:59 DISPATCHER: Trying to submit another job.
09:27:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:27:59 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:27:59 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:27:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:27:59 WORKER: start processing job (0, 0, 0)
09:27:59 WORKER: args: ()
09:27:59 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.01046276395165131, 'num_filters_1': 43, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.19279758549751724, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 75, 'num_filters_3': 89, 'num_filters_4': 37, 'num_filters_5': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:28:52 WORKER: done with job (0, 0, 0), trying to register it.
09:28:52 DISPATCHER: job (0, 0, 0) finished
09:28:52 WORKER: registered result for job (0, 0, 0) with dispatcher
09:28:52 DISPATCHER: register_result: lock acquired
09:28:52 DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:28:52 job_id: (0, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.01046276395165131, 'num_filters_1': 43, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.19279758549751724, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 75, 'num_filters_3': 89, 'num_filters_4': 37, 'num_filters_5': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6815898863592317, 'info': {'music-speech': 0.6815898863592317, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.01046276395165131, 'num_filters_1': 43, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.19279758549751724, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 75, 'num_filters_3': 89, 'num_filters_4': 37, 'num_filters_5': 21}"}}
exception: None

09:28:52 job_callback for (0, 0, 0) started
09:28:52 DISPATCHER: Trying to submit another job.
09:28:52 job_callback for (0, 0, 0) got condition
09:28:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:28:52 Only 1 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
09:28:52 HBMASTER: Trying to run another job!
09:28:52 job_callback for (0, 0, 0) finished
09:28:52 start sampling a new configuration.
09:28:52 done sampling a new configuration.
09:28:52 HBMASTER: schedule new run for iteration 0
09:28:52 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
09:28:52 HBMASTER: submitting job (0, 0, 1) to dispatcher
09:28:52 DISPATCHER: trying to submit job (0, 0, 1)
09:28:52 DISPATCHER: trying to notify the job_runner thread.
09:28:52 HBMASTER: job (0, 0, 1) submitted to dispatcher
09:28:52 DISPATCHER: Trying to submit another job.
09:28:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:28:52 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:28:52 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:28:52 WORKER: start processing job (0, 0, 1)
09:28:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:28:52 WORKER: args: ()
09:28:52 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0026759955745375265, 'num_filters_1': 19, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.03700965918762469, 'kernel_size_2': 5, 'num_filters_2': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:28:59 DISPATCHER: Starting worker discovery
09:28:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:28:59 DISPATCHER: Finished worker discovery
09:29:46 WORKER: done with job (0, 0, 1), trying to register it.
09:29:46 WORKER: registered result for job (0, 0, 1) with dispatcher
09:29:46 DISPATCHER: job (0, 0, 1) finished
09:29:46 DISPATCHER: register_result: lock acquired
09:29:46 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:29:46 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0026759955745375265, 'num_filters_1': 19, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.03700965918762469, 'kernel_size_2': 5, 'num_filters_2': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8937086194058961, 'info': {'music-speech': 0.8937086194058961, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0026759955745375265, 'num_filters_1': 19, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.03700965918762469, 'kernel_size_2': 5, 'num_filters_2': 21}"}}
exception: None

09:29:46 job_callback for (0, 0, 1) started
09:29:46 job_callback for (0, 0, 1) got condition
09:29:46 DISPATCHER: Trying to submit another job.
09:29:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:29:46 Only 2 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
09:29:46 HBMASTER: Trying to run another job!
09:29:46 job_callback for (0, 0, 1) finished
09:29:46 start sampling a new configuration.
09:29:46 done sampling a new configuration.
09:29:46 HBMASTER: schedule new run for iteration 0
09:29:46 HBMASTER: trying submitting job (0, 0, 2) to dispatcher
09:29:46 HBMASTER: submitting job (0, 0, 2) to dispatcher
09:29:46 DISPATCHER: trying to submit job (0, 0, 2)
09:29:46 DISPATCHER: trying to notify the job_runner thread.
09:29:46 HBMASTER: job (0, 0, 2) submitted to dispatcher
09:29:46 DISPATCHER: Trying to submit another job.
09:29:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:29:46 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:29:46 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:29:46 WORKER: start processing job (0, 0, 2)
09:29:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:29:46 WORKER: args: ()
09:29:46 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.004136847428245059, 'num_filters_1': 64, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.08343361334232682, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 73, 'num_filters_3': 37, 'num_filters_4': 99}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:29:59 DISPATCHER: Starting worker discovery
09:29:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:29:59 DISPATCHER: Finished worker discovery
09:30:41 WORKER: done with job (0, 0, 2), trying to register it.
09:30:41 DISPATCHER: job (0, 0, 2) finished
09:30:41 WORKER: registered result for job (0, 0, 2) with dispatcher
09:30:41 DISPATCHER: register_result: lock acquired
09:30:41 DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:30:41 job_id: (0, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.004136847428245059, 'num_filters_1': 64, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.08343361334232682, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 73, 'num_filters_3': 37, 'num_filters_4': 99}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.48259885003260294, 'info': {'music-speech': 0.48259885003260294, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.004136847428245059, 'num_filters_1': 64, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 88, 'weight_decay': 0.08343361334232682, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 73, 'num_filters_3': 37, 'num_filters_4': 99}"}}
exception: None

09:30:41 job_callback for (0, 0, 2) started
09:30:41 DISPATCHER: Trying to submit another job.
09:30:41 job_callback for (0, 0, 2) got condition
09:30:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:30:41 Only 3 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
09:30:41 HBMASTER: Trying to run another job!
09:30:41 job_callback for (0, 0, 2) finished
09:30:41 start sampling a new configuration.
09:30:41 done sampling a new configuration.
09:30:41 HBMASTER: schedule new run for iteration 0
09:30:41 HBMASTER: trying submitting job (0, 0, 3) to dispatcher
09:30:41 HBMASTER: submitting job (0, 0, 3) to dispatcher
09:30:41 DISPATCHER: trying to submit job (0, 0, 3)
09:30:41 DISPATCHER: trying to notify the job_runner thread.
09:30:41 HBMASTER: job (0, 0, 3) submitted to dispatcher
09:30:41 DISPATCHER: Trying to submit another job.
09:30:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:30:41 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:30:41 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:30:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:30:41 WORKER: start processing job (0, 0, 3)
09:30:41 WORKER: args: ()
09:30:41 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.03229732701380316, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.03657001449801485, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 111, 'num_filters_3': 127, 'num_filters_4': 62, 'num_filters_5': 107}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:30:59 DISPATCHER: Starting worker discovery
09:30:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:30:59 DISPATCHER: Finished worker discovery
09:31:36 WORKER: done with job (0, 0, 3), trying to register it.
09:31:36 DISPATCHER: job (0, 0, 3) finished
09:31:36 WORKER: registered result for job (0, 0, 3) with dispatcher
09:31:36 DISPATCHER: register_result: lock acquired
09:31:36 DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:31:36 job_id: (0, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.03229732701380316, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.03657001449801485, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 111, 'num_filters_3': 127, 'num_filters_4': 62, 'num_filters_5': 107}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.03229732701380316, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 71, 'weight_decay': 0.03657001449801485, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 3, 'num_filters_2': 111, 'num_filters_3': 127, 'num_filters_4': 62, 'num_filters_5': 107}"}}
exception: None

09:31:36 job_callback for (0, 0, 3) started
09:31:36 DISPATCHER: Trying to submit another job.
09:31:36 job_callback for (0, 0, 3) got condition
09:31:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:31:36 Only 4 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
09:31:36 HBMASTER: Trying to run another job!
09:31:36 job_callback for (0, 0, 3) finished
09:31:36 start sampling a new configuration.
09:31:36 done sampling a new configuration.
09:31:36 HBMASTER: schedule new run for iteration 0
09:31:36 HBMASTER: trying submitting job (0, 0, 4) to dispatcher
09:31:36 HBMASTER: submitting job (0, 0, 4) to dispatcher
09:31:36 DISPATCHER: trying to submit job (0, 0, 4)
09:31:36 DISPATCHER: trying to notify the job_runner thread.
09:31:36 HBMASTER: job (0, 0, 4) submitted to dispatcher
09:31:36 DISPATCHER: Trying to submit another job.
09:31:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:31:36 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:31:36 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:31:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:31:36 WORKER: start processing job (0, 0, 4)
09:31:36 WORKER: args: ()
09:31:36 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.008494189125607609, 'num_filters_1': 100, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.012879522594906897, 'kernel_size_2': 3, 'num_filters_2': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:31:59 DISPATCHER: Starting worker discovery
09:31:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:31:59 DISPATCHER: Finished worker discovery
09:32:30 WORKER: done with job (0, 0, 4), trying to register it.
09:32:30 DISPATCHER: job (0, 0, 4) finished
09:32:30 WORKER: registered result for job (0, 0, 4) with dispatcher
09:32:30 DISPATCHER: register_result: lock acquired
09:32:30 DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:32:30 job_id: (0, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.008494189125607609, 'num_filters_1': 100, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.012879522594906897, 'kernel_size_2': 3, 'num_filters_2': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5687462921400673, 'info': {'music-speech': 0.5687462921400673, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.008494189125607609, 'num_filters_1': 100, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.012879522594906897, 'kernel_size_2': 3, 'num_filters_2': 18}"}}
exception: None

09:32:30 job_callback for (0, 0, 4) started
09:32:30 DISPATCHER: Trying to submit another job.
09:32:30 job_callback for (0, 0, 4) got condition
09:32:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:32:30 Only 5 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
09:32:30 HBMASTER: Trying to run another job!
09:32:30 job_callback for (0, 0, 4) finished
09:32:30 start sampling a new configuration.
09:32:30 done sampling a new configuration.
09:32:30 HBMASTER: schedule new run for iteration 0
09:32:30 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
09:32:30 HBMASTER: submitting job (0, 0, 5) to dispatcher
09:32:30 DISPATCHER: trying to submit job (0, 0, 5)
09:32:30 DISPATCHER: trying to notify the job_runner thread.
09:32:30 HBMASTER: job (0, 0, 5) submitted to dispatcher
09:32:30 DISPATCHER: Trying to submit another job.
09:32:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:32:30 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:32:30 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:32:30 WORKER: start processing job (0, 0, 5)
09:32:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:32:30 WORKER: args: ()
09:32:30 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.008593505525023888, 'num_filters_1': 126, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.02632406429832292, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 65, 'num_filters_3': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-607:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372032559808512 is out of bounds for axis 0 with size 2

09:32:59 DISPATCHER: Starting worker discovery
09:32:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:32:59 DISPATCHER: Finished worker discovery
09:33:23 WORKER: done with job (0, 0, 5), trying to register it.
09:33:23 WORKER: registered result for job (0, 0, 5) with dispatcher
09:33:23 DISPATCHER: job (0, 0, 5) finished
09:33:23 DISPATCHER: register_result: lock acquired
09:33:23 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:33:23 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.008593505525023888, 'num_filters_1': 126, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.02632406429832292, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 65, 'num_filters_3': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8372153380593362, 'info': {'music-speech': 0.8372153380593362, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.008593505525023888, 'num_filters_1': 126, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.02632406429832292, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 65, 'num_filters_3': 19}"}}
exception: None

09:33:23 DISPATCHER: Trying to submit another job.
09:33:23 job_callback for (0, 0, 5) started
09:33:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:33:23 job_callback for (0, 0, 5) got condition
09:33:23 Only 6 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
09:33:23 HBMASTER: Trying to run another job!
09:33:23 job_callback for (0, 0, 5) finished
09:33:23 start sampling a new configuration.
09:33:23 done sampling a new configuration.
09:33:23 HBMASTER: schedule new run for iteration 0
09:33:23 HBMASTER: trying submitting job (0, 0, 6) to dispatcher
09:33:23 HBMASTER: submitting job (0, 0, 6) to dispatcher
09:33:23 DISPATCHER: trying to submit job (0, 0, 6)
09:33:23 DISPATCHER: trying to notify the job_runner thread.
09:33:23 HBMASTER: job (0, 0, 6) submitted to dispatcher
09:33:23 DISPATCHER: Trying to submit another job.
09:33:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:33:23 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:33:23 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:33:23 WORKER: start processing job (0, 0, 6)
09:33:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:33:23 WORKER: args: ()
09:33:23 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0020648816132314684, 'num_filters_1': 34, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.09192039181980796, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 82, 'num_filters_3': 33, 'num_filters_4': 20, 'num_filters_5': 59}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:33:59 DISPATCHER: Starting worker discovery
09:33:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:33:59 DISPATCHER: Finished worker discovery
09:34:16 WORKER: done with job (0, 0, 6), trying to register it.
09:34:16 DISPATCHER: job (0, 0, 6) finished
09:34:16 WORKER: registered result for job (0, 0, 6) with dispatcher
09:34:16 DISPATCHER: register_result: lock acquired
09:34:16 DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:34:16 job_id: (0, 0, 6)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0020648816132314684, 'num_filters_1': 34, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.09192039181980796, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 82, 'num_filters_3': 33, 'num_filters_4': 20, 'num_filters_5': 59}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.665972859061274, 'info': {'music-speech': 0.665972859061274, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0020648816132314684, 'num_filters_1': 34, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.09192039181980796, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 82, 'num_filters_3': 33, 'num_filters_4': 20, 'num_filters_5': 59}"}}
exception: None

09:34:16 job_callback for (0, 0, 6) started
09:34:16 DISPATCHER: Trying to submit another job.
09:34:16 job_callback for (0, 0, 6) got condition
09:34:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:34:16 Only 7 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
09:34:16 HBMASTER: Trying to run another job!
09:34:16 job_callback for (0, 0, 6) finished
09:34:16 start sampling a new configuration.
09:34:16 done sampling a new configuration.
09:34:16 HBMASTER: schedule new run for iteration 0
09:34:16 HBMASTER: trying submitting job (0, 0, 7) to dispatcher
09:34:16 HBMASTER: submitting job (0, 0, 7) to dispatcher
09:34:16 DISPATCHER: trying to submit job (0, 0, 7)
09:34:16 DISPATCHER: trying to notify the job_runner thread.
09:34:16 HBMASTER: job (0, 0, 7) submitted to dispatcher
09:34:16 DISPATCHER: Trying to submit another job.
09:34:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:34:16 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:34:16 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:34:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:34:16 WORKER: start processing job (0, 0, 7)
09:34:16 WORKER: args: ()
09:34:16 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.046392906175641076, 'num_filters_1': 100, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.06875275086676791, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 45, 'num_filters_3': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:34:59 DISPATCHER: Starting worker discovery
09:34:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:34:59 DISPATCHER: Finished worker discovery
09:35:10 WORKER: done with job (0, 0, 7), trying to register it.
09:35:10 WORKER: registered result for job (0, 0, 7) with dispatcher
09:35:10 DISPATCHER: job (0, 0, 7) finished
09:35:10 DISPATCHER: register_result: lock acquired
09:35:10 DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:35:10 job_id: (0, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.046392906175641076, 'num_filters_1': 100, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.06875275086676791, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 45, 'num_filters_3': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0036233267755183393, 'info': {'music-speech': 0.0036233267755183393, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.046392906175641076, 'num_filters_1': 100, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.06875275086676791, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 45, 'num_filters_3': 18}"}}
exception: None

09:35:10 job_callback for (0, 0, 7) started
09:35:10 job_callback for (0, 0, 7) got condition
09:35:10 DISPATCHER: Trying to submit another job.
09:35:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:35:10 Only 8 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
09:35:10 HBMASTER: Trying to run another job!
09:35:10 job_callback for (0, 0, 7) finished
09:35:10 start sampling a new configuration.
09:35:10 done sampling a new configuration.
09:35:10 HBMASTER: schedule new run for iteration 0
09:35:10 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
09:35:10 HBMASTER: submitting job (0, 0, 8) to dispatcher
09:35:10 DISPATCHER: trying to submit job (0, 0, 8)
09:35:10 DISPATCHER: trying to notify the job_runner thread.
09:35:10 HBMASTER: job (0, 0, 8) submitted to dispatcher
09:35:10 DISPATCHER: Trying to submit another job.
09:35:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:35:10 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:35:10 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:35:10 WORKER: start processing job (0, 0, 8)
09:35:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:35:10 WORKER: args: ()
09:35:10 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0026326000571681605, 'num_filters_1': 68, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.024178187377917198, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 87, 'num_filters_3': 98, 'num_filters_4': 32, 'num_filters_5': 35}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:35:59 DISPATCHER: Starting worker discovery
09:35:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:35:59 DISPATCHER: Finished worker discovery
09:36:03 WORKER: done with job (0, 0, 8), trying to register it.
09:36:03 DISPATCHER: job (0, 0, 8) finished
09:36:03 WORKER: registered result for job (0, 0, 8) with dispatcher
09:36:03 DISPATCHER: register_result: lock acquired
09:36:03 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:36:03 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0026326000571681605, 'num_filters_1': 68, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.024178187377917198, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 87, 'num_filters_3': 98, 'num_filters_4': 32, 'num_filters_5': 35}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8408476748167268, 'info': {'music-speech': 0.8408476748167268, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0026326000571681605, 'num_filters_1': 68, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.024178187377917198, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 87, 'num_filters_3': 98, 'num_filters_4': 32, 'num_filters_5': 35}"}}
exception: None

09:36:03 job_callback for (0, 0, 8) started
09:36:03 DISPATCHER: Trying to submit another job.
09:36:03 job_callback for (0, 0, 8) got condition
09:36:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:36:03 Only 9 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
09:36:03 HBMASTER: Trying to run another job!
09:36:03 job_callback for (0, 0, 8) finished
09:36:03 start sampling a new configuration.
09:36:03 done sampling a new configuration.
09:36:03 HBMASTER: schedule new run for iteration 0
09:36:03 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
09:36:03 HBMASTER: submitting job (0, 0, 9) to dispatcher
09:36:03 DISPATCHER: trying to submit job (0, 0, 9)
09:36:03 DISPATCHER: trying to notify the job_runner thread.
09:36:03 HBMASTER: job (0, 0, 9) submitted to dispatcher
09:36:03 DISPATCHER: Trying to submit another job.
09:36:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:36:03 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:36:03 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:36:03 WORKER: start processing job (0, 0, 9)
09:36:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:36:03 WORKER: args: ()
09:36:03 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0010340879715748813, 'num_filters_1': 104, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.09414967749811681, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 57, 'num_filters_3': 25, 'num_filters_4': 79, 'num_filters_5': 63}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:36:57 WORKER: done with job (0, 0, 9), trying to register it.
09:36:57 WORKER: registered result for job (0, 0, 9) with dispatcher
09:36:57 DISPATCHER: job (0, 0, 9) finished
09:36:57 DISPATCHER: register_result: lock acquired
09:36:57 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:36:57 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0010340879715748813, 'num_filters_1': 104, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.09414967749811681, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 57, 'num_filters_3': 25, 'num_filters_4': 79, 'num_filters_5': 63}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9321546593048395, 'info': {'music-speech': 0.9321546593048395, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0010340879715748813, 'num_filters_1': 104, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.09414967749811681, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 57, 'num_filters_3': 25, 'num_filters_4': 79, 'num_filters_5': 63}"}}
exception: None

09:36:57 job_callback for (0, 0, 9) started
09:36:57 job_callback for (0, 0, 9) got condition
09:36:57 DISPATCHER: Trying to submit another job.
09:36:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:36:57 Only 10 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
09:36:57 HBMASTER: Trying to run another job!
09:36:57 job_callback for (0, 0, 9) finished
09:36:57 start sampling a new configuration.
09:36:57 done sampling a new configuration.
09:36:57 HBMASTER: schedule new run for iteration 0
09:36:57 HBMASTER: trying submitting job (0, 0, 10) to dispatcher
09:36:57 HBMASTER: submitting job (0, 0, 10) to dispatcher
09:36:57 DISPATCHER: trying to submit job (0, 0, 10)
09:36:57 DISPATCHER: trying to notify the job_runner thread.
09:36:57 HBMASTER: job (0, 0, 10) submitted to dispatcher
09:36:57 DISPATCHER: Trying to submit another job.
09:36:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:36:57 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:36:57 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:36:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:36:57 WORKER: start processing job (0, 0, 10)
09:36:57 WORKER: args: ()
09:36:57 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.03887051098710554, 'num_filters_1': 37, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.03079170251130183, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 26, 'num_filters_3': 26, 'num_filters_4': 82, 'num_filters_5': 37}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:36:59 DISPATCHER: Starting worker discovery
09:36:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:36:59 DISPATCHER: Finished worker discovery
09:37:50 WORKER: done with job (0, 0, 10), trying to register it.
09:37:50 WORKER: registered result for job (0, 0, 10) with dispatcher
09:37:50 DISPATCHER: job (0, 0, 10) finished
09:37:50 DISPATCHER: register_result: lock acquired
09:37:50 DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:37:50 job_id: (0, 0, 10)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.03887051098710554, 'num_filters_1': 37, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.03079170251130183, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 26, 'num_filters_3': 26, 'num_filters_4': 82, 'num_filters_5': 37}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.03887051098710554, 'num_filters_1': 37, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 83, 'weight_decay': 0.03079170251130183, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 26, 'num_filters_3': 26, 'num_filters_4': 82, 'num_filters_5': 37}"}}
exception: None

09:37:50 job_callback for (0, 0, 10) started
09:37:50 DISPATCHER: Trying to submit another job.
09:37:50 job_callback for (0, 0, 10) got condition
09:37:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:37:50 Only 11 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
09:37:50 HBMASTER: Trying to run another job!
09:37:50 job_callback for (0, 0, 10) finished
09:37:50 start sampling a new configuration.
09:37:50 done sampling a new configuration.
09:37:50 HBMASTER: schedule new run for iteration 0
09:37:50 HBMASTER: trying submitting job (0, 0, 11) to dispatcher
09:37:50 HBMASTER: submitting job (0, 0, 11) to dispatcher
09:37:50 DISPATCHER: trying to submit job (0, 0, 11)
09:37:50 DISPATCHER: trying to notify the job_runner thread.
09:37:50 HBMASTER: job (0, 0, 11) submitted to dispatcher
09:37:50 DISPATCHER: Trying to submit another job.
09:37:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:37:50 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:37:50 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:37:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:37:50 WORKER: start processing job (0, 0, 11)
09:37:50 WORKER: args: ()
09:37:50 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.024987181970740353, 'num_filters_1': 46, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.1262099764288956}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:37:59 DISPATCHER: Starting worker discovery
09:37:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:37:59 DISPATCHER: Finished worker discovery
09:38:44 WORKER: done with job (0, 0, 11), trying to register it.
09:38:44 WORKER: registered result for job (0, 0, 11) with dispatcher
09:38:44 DISPATCHER: job (0, 0, 11) finished
09:38:44 DISPATCHER: register_result: lock acquired
09:38:44 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:38:44 job_id: (0, 0, 11)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.024987181970740353, 'num_filters_1': 46, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.1262099764288956}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.005237774886902764, 'info': {'music-speech': 0.005237774886902764, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.024987181970740353, 'num_filters_1': 46, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 24, 'weight_decay': 0.1262099764288956}"}}
exception: None

09:38:44 job_callback for (0, 0, 11) started
09:38:44 job_callback for (0, 0, 11) got condition
09:38:44 DISPATCHER: Trying to submit another job.
09:38:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:38:44 Only 12 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
09:38:44 HBMASTER: Trying to run another job!
09:38:44 job_callback for (0, 0, 11) finished
09:38:44 start sampling a new configuration.
09:38:44 done sampling a new configuration.
09:38:44 HBMASTER: schedule new run for iteration 0
09:38:44 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
09:38:44 HBMASTER: submitting job (0, 0, 12) to dispatcher
09:38:44 DISPATCHER: trying to submit job (0, 0, 12)
09:38:44 DISPATCHER: trying to notify the job_runner thread.
09:38:44 HBMASTER: job (0, 0, 12) submitted to dispatcher
09:38:44 DISPATCHER: Trying to submit another job.
09:38:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:38:44 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:38:44 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:38:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:38:44 WORKER: start processing job (0, 0, 12)
09:38:44 WORKER: args: ()
09:38:44 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003197151779422022, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.050814383556602616, 'kernel_size_2': 3, 'num_filters_2': 61}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:38:59 DISPATCHER: Starting worker discovery
09:38:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:38:59 DISPATCHER: Finished worker discovery
09:39:37 WORKER: done with job (0, 0, 12), trying to register it.
09:39:37 WORKER: registered result for job (0, 0, 12) with dispatcher
09:39:37 DISPATCHER: job (0, 0, 12) finished
09:39:37 DISPATCHER: register_result: lock acquired
09:39:37 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:39:37 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003197151779422022, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.050814383556602616, 'kernel_size_2': 3, 'num_filters_2': 61}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7438918007621722, 'info': {'music-speech': 0.7438918007621722, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003197151779422022, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.050814383556602616, 'kernel_size_2': 3, 'num_filters_2': 61}"}}
exception: None

09:39:37 job_callback for (0, 0, 12) started
09:39:37 DISPATCHER: Trying to submit another job.
09:39:37 job_callback for (0, 0, 12) got condition
09:39:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:39:37 Only 13 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
09:39:37 HBMASTER: Trying to run another job!
09:39:37 job_callback for (0, 0, 12) finished
09:39:37 start sampling a new configuration.
09:39:37 done sampling a new configuration.
09:39:37 HBMASTER: schedule new run for iteration 0
09:39:37 HBMASTER: trying submitting job (0, 0, 13) to dispatcher
09:39:37 HBMASTER: submitting job (0, 0, 13) to dispatcher
09:39:37 DISPATCHER: trying to submit job (0, 0, 13)
09:39:37 DISPATCHER: trying to notify the job_runner thread.
09:39:37 HBMASTER: job (0, 0, 13) submitted to dispatcher
09:39:37 DISPATCHER: Trying to submit another job.
09:39:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:39:37 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:39:37 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:39:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:39:37 WORKER: start processing job (0, 0, 13)
09:39:37 WORKER: args: ()
09:39:37 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.012700696504598945, 'num_filters_1': 98, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.014277730831656621, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 127, 'num_filters_3': 87, 'num_filters_4': 27, 'num_filters_5': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:39:59 DISPATCHER: Starting worker discovery
09:39:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:39:59 DISPATCHER: Finished worker discovery
09:40:30 WORKER: done with job (0, 0, 13), trying to register it.
09:40:30 WORKER: registered result for job (0, 0, 13) with dispatcher
09:40:30 DISPATCHER: job (0, 0, 13) finished
09:40:30 DISPATCHER: register_result: lock acquired
09:40:30 DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:40:30 job_id: (0, 0, 13)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.012700696504598945, 'num_filters_1': 98, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.014277730831656621, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 127, 'num_filters_3': 87, 'num_filters_4': 27, 'num_filters_5': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5631764762107448, 'info': {'music-speech': 0.5631764762107448, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.012700696504598945, 'num_filters_1': 98, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.014277730831656621, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 127, 'num_filters_3': 87, 'num_filters_4': 27, 'num_filters_5': 17}"}}
exception: None

09:40:30 job_callback for (0, 0, 13) started
09:40:30 DISPATCHER: Trying to submit another job.
09:40:30 job_callback for (0, 0, 13) got condition
09:40:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:40:30 Only 14 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
09:40:30 HBMASTER: Trying to run another job!
09:40:30 job_callback for (0, 0, 13) finished
09:40:30 start sampling a new configuration.
09:40:30 done sampling a new configuration.
09:40:30 HBMASTER: schedule new run for iteration 0
09:40:30 HBMASTER: trying submitting job (0, 0, 14) to dispatcher
09:40:30 HBMASTER: submitting job (0, 0, 14) to dispatcher
09:40:30 DISPATCHER: trying to submit job (0, 0, 14)
09:40:30 DISPATCHER: trying to notify the job_runner thread.
09:40:30 HBMASTER: job (0, 0, 14) submitted to dispatcher
09:40:30 DISPATCHER: Trying to submit another job.
09:40:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:40:30 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:40:30 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:40:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:40:30 WORKER: start processing job (0, 0, 14)
09:40:30 WORKER: args: ()
09:40:30 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.04251559680511404, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.19641247959448865, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 115, 'num_filters_3': 105, 'num_filters_4': 36}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:40:59 DISPATCHER: Starting worker discovery
09:40:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:40:59 DISPATCHER: Finished worker discovery
09:41:24 WORKER: done with job (0, 0, 14), trying to register it.
09:41:24 WORKER: registered result for job (0, 0, 14) with dispatcher
09:41:24 DISPATCHER: job (0, 0, 14) finished
09:41:24 DISPATCHER: register_result: lock acquired
09:41:24 DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:41:24 job_id: (0, 0, 14)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.04251559680511404, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.19641247959448865, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 115, 'num_filters_3': 105, 'num_filters_4': 36}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.00020211980501802526, 'info': {'music-speech': 0.00020211980501802526, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.04251559680511404, 'num_filters_1': 22, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.19641247959448865, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 115, 'num_filters_3': 105, 'num_filters_4': 36}"}}
exception: None

09:41:24 job_callback for (0, 0, 14) started
09:41:24 DISPATCHER: Trying to submit another job.
09:41:24 job_callback for (0, 0, 14) got condition
09:41:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:41:24 Only 15 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
09:41:24 HBMASTER: Trying to run another job!
09:41:24 job_callback for (0, 0, 14) finished
09:41:24 start sampling a new configuration.
09:41:24 done sampling a new configuration.
09:41:24 HBMASTER: schedule new run for iteration 0
09:41:24 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
09:41:24 HBMASTER: submitting job (0, 0, 15) to dispatcher
09:41:24 DISPATCHER: trying to submit job (0, 0, 15)
09:41:24 DISPATCHER: trying to notify the job_runner thread.
09:41:24 HBMASTER: job (0, 0, 15) submitted to dispatcher
09:41:24 DISPATCHER: Trying to submit another job.
09:41:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:41:24 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:41:24 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:41:24 WORKER: start processing job (0, 0, 15)
09:41:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:41:24 WORKER: args: ()
09:41:24 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.008646606551333345, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.16798787921454883, 'kernel_size_2': 3, 'num_filters_2': 46}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:41:59 DISPATCHER: Starting worker discovery
09:41:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:41:59 DISPATCHER: Finished worker discovery
09:42:23 WORKER: done with job (0, 0, 15), trying to register it.
09:42:23 WORKER: registered result for job (0, 0, 15) with dispatcher
09:42:23 DISPATCHER: job (0, 0, 15) finished
09:42:23 DISPATCHER: register_result: lock acquired
09:42:23 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:42:23 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.008646606551333345, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.16798787921454883, 'kernel_size_2': 3, 'num_filters_2': 46}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7321991189213473, 'info': {'music-speech': 0.7321991189213473, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.008646606551333345, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.16798787921454883, 'kernel_size_2': 3, 'num_filters_2': 46}"}}
exception: None

09:42:23 job_callback for (0, 0, 15) started
09:42:23 job_callback for (0, 0, 15) got condition
09:42:23 DISPATCHER: Trying to submit another job.
09:42:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:42:23 Only 16 run(s) for budget 44.444444 available, need more than 18 -> can't build model!
09:42:23 HBMASTER: Trying to run another job!
09:42:23 job_callback for (0, 0, 15) finished
09:42:23 start sampling a new configuration.
09:42:23 done sampling a new configuration.
09:42:23 HBMASTER: schedule new run for iteration 0
09:42:23 HBMASTER: trying submitting job (0, 0, 16) to dispatcher
09:42:23 HBMASTER: submitting job (0, 0, 16) to dispatcher
09:42:23 DISPATCHER: trying to submit job (0, 0, 16)
09:42:23 DISPATCHER: trying to notify the job_runner thread.
09:42:23 HBMASTER: job (0, 0, 16) submitted to dispatcher
09:42:23 DISPATCHER: Trying to submit another job.
09:42:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:42:23 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:42:23 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:42:23 WORKER: start processing job (0, 0, 16)
09:42:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:42:23 WORKER: args: ()
09:42:23 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.018187152590042183, 'num_filters_1': 56, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.19961510926010825, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 25, 'num_filters_3': 57, 'num_filters_4': 98}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:42:59 DISPATCHER: Starting worker discovery
09:42:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:42:59 DISPATCHER: Finished worker discovery
09:43:17 WORKER: done with job (0, 0, 16), trying to register it.
09:43:17 WORKER: registered result for job (0, 0, 16) with dispatcher
09:43:17 DISPATCHER: job (0, 0, 16) finished
09:43:17 DISPATCHER: register_result: lock acquired
09:43:17 DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:43:17 job_id: (0, 0, 16)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.018187152590042183, 'num_filters_1': 56, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.19961510926010825, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 25, 'num_filters_3': 57, 'num_filters_4': 98}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.018187152590042183, 'num_filters_1': 56, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.19961510926010825, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 25, 'num_filters_3': 57, 'num_filters_4': 98}"}}
exception: None

09:43:17 job_callback for (0, 0, 16) started
09:43:17 DISPATCHER: Trying to submit another job.
09:43:17 job_callback for (0, 0, 16) got condition
09:43:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:43:17 HBMASTER: Trying to run another job!
09:43:17 job_callback for (0, 0, 16) finished
09:43:17 start sampling a new configuration.
09:43:17 done sampling a new configuration.
09:43:17 HBMASTER: schedule new run for iteration 0
09:43:17 HBMASTER: trying submitting job (0, 0, 17) to dispatcher
09:43:17 HBMASTER: submitting job (0, 0, 17) to dispatcher
09:43:17 DISPATCHER: trying to submit job (0, 0, 17)
09:43:17 DISPATCHER: trying to notify the job_runner thread.
09:43:17 HBMASTER: job (0, 0, 17) submitted to dispatcher
09:43:17 DISPATCHER: Trying to submit another job.
09:43:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:43:17 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:43:17 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:43:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:43:17 WORKER: start processing job (0, 0, 17)
09:43:17 WORKER: args: ()
09:43:17 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.036407701509983896, 'num_filters_1': 39, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 33, 'weight_decay': 0.08766144636249112, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 55, 'num_filters_3': 35, 'num_filters_4': 18, 'num_filters_5': 81}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:43:59 DISPATCHER: Starting worker discovery
09:43:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:43:59 DISPATCHER: Finished worker discovery
09:44:11 WORKER: done with job (0, 0, 17), trying to register it.
09:44:11 WORKER: registered result for job (0, 0, 17) with dispatcher
09:44:11 DISPATCHER: job (0, 0, 17) finished
09:44:11 DISPATCHER: register_result: lock acquired
09:44:11 DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:44:11 job_id: (0, 0, 17)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.036407701509983896, 'num_filters_1': 39, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 33, 'weight_decay': 0.08766144636249112, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 55, 'num_filters_3': 35, 'num_filters_4': 18, 'num_filters_5': 81}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.036407701509983896, 'num_filters_1': 39, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 33, 'weight_decay': 0.08766144636249112, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 5, 'num_filters_2': 55, 'num_filters_3': 35, 'num_filters_4': 18, 'num_filters_5': 81}"}}
exception: None

09:44:11 job_callback for (0, 0, 17) started
09:44:11 DISPATCHER: Trying to submit another job.
09:44:11 job_callback for (0, 0, 17) got condition
09:44:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:44:11 HBMASTER: Trying to run another job!
09:44:11 job_callback for (0, 0, 17) finished
09:44:11 start sampling a new configuration.
09:44:11 done sampling a new configuration.
09:44:11 HBMASTER: schedule new run for iteration 0
09:44:11 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
09:44:11 HBMASTER: submitting job (0, 0, 18) to dispatcher
09:44:11 DISPATCHER: trying to submit job (0, 0, 18)
09:44:11 DISPATCHER: trying to notify the job_runner thread.
09:44:11 HBMASTER: job (0, 0, 18) submitted to dispatcher
09:44:11 DISPATCHER: Trying to submit another job.
09:44:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:44:11 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:44:11 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:44:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:44:11 WORKER: start processing job (0, 0, 18)
09:44:11 WORKER: args: ()
09:44:11 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.06846452224407075, 'num_filters_1': 56, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.014819454329965972, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 45, 'num_filters_3': 22, 'num_filters_4': 53, 'num_filters_5': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-620:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

09:44:59 DISPATCHER: Starting worker discovery
09:44:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:44:59 DISPATCHER: Finished worker discovery
09:45:05 WORKER: done with job (0, 0, 18), trying to register it.
09:45:05 DISPATCHER: job (0, 0, 18) finished
09:45:05 WORKER: registered result for job (0, 0, 18) with dispatcher
09:45:05 DISPATCHER: register_result: lock acquired
09:45:05 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:45:05 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.06846452224407075, 'num_filters_1': 56, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.014819454329965972, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 45, 'num_filters_3': 22, 'num_filters_4': 53, 'num_filters_5': 27}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7485278173104056, 'info': {'music-speech': 0.7485278173104056, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.06846452224407075, 'num_filters_1': 56, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.014819454329965972, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 45, 'num_filters_3': 22, 'num_filters_4': 53, 'num_filters_5': 27}"}}
exception: None

09:45:05 job_callback for (0, 0, 18) started
09:45:05 DISPATCHER: Trying to submit another job.
09:45:05 job_callback for (0, 0, 18) got condition
09:45:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:45:05 HBMASTER: Trying to run another job!
09:45:05 job_callback for (0, 0, 18) finished
09:45:05 start sampling a new configuration.
09:45:05 done sampling a new configuration.
09:45:05 HBMASTER: schedule new run for iteration 0
09:45:05 HBMASTER: trying submitting job (0, 0, 19) to dispatcher
09:45:05 HBMASTER: submitting job (0, 0, 19) to dispatcher
09:45:05 DISPATCHER: trying to submit job (0, 0, 19)
09:45:05 DISPATCHER: trying to notify the job_runner thread.
09:45:05 HBMASTER: job (0, 0, 19) submitted to dispatcher
09:45:05 DISPATCHER: Trying to submit another job.
09:45:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:45:05 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:45:05 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:45:05 WORKER: start processing job (0, 0, 19)
09:45:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:45:05 WORKER: args: ()
09:45:05 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0836564564859554, 'num_filters_1': 90, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.10635824902253088, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 18, 'num_filters_3': 22, 'num_filters_4': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-621:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

09:45:58 WORKER: done with job (0, 0, 19), trying to register it.
09:45:58 WORKER: registered result for job (0, 0, 19) with dispatcher
09:45:58 DISPATCHER: job (0, 0, 19) finished
09:45:58 DISPATCHER: register_result: lock acquired
09:45:58 DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:45:58 job_id: (0, 0, 19)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0836564564859554, 'num_filters_1': 90, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.10635824902253088, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 18, 'num_filters_3': 22, 'num_filters_4': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.47832274476791836, 'info': {'music-speech': 0.47832274476791836, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0836564564859554, 'num_filters_1': 90, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 22, 'weight_decay': 0.10635824902253088, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 18, 'num_filters_3': 22, 'num_filters_4': 26}"}}
exception: None

09:45:58 job_callback for (0, 0, 19) started
09:45:58 DISPATCHER: Trying to submit another job.
09:45:58 job_callback for (0, 0, 19) got condition
09:45:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:45:58 HBMASTER: Trying to run another job!
09:45:58 job_callback for (0, 0, 19) finished
09:45:58 start sampling a new configuration.
09:45:58 done sampling a new configuration.
09:45:58 HBMASTER: schedule new run for iteration 0
09:45:58 HBMASTER: trying submitting job (0, 0, 20) to dispatcher
09:45:58 HBMASTER: submitting job (0, 0, 20) to dispatcher
09:45:58 DISPATCHER: trying to submit job (0, 0, 20)
09:45:58 DISPATCHER: trying to notify the job_runner thread.
09:45:58 HBMASTER: job (0, 0, 20) submitted to dispatcher
09:45:58 DISPATCHER: Trying to submit another job.
09:45:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:45:58 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:45:58 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:45:58 WORKER: start processing job (0, 0, 20)
09:45:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:45:58 WORKER: args: ()
09:45:58 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.02221624849249378, 'num_filters_1': 101, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.0528716286297236}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:45:59 DISPATCHER: Starting worker discovery
09:45:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:45:59 DISPATCHER: Finished worker discovery
09:46:52 WORKER: done with job (0, 0, 20), trying to register it.
09:46:52 WORKER: registered result for job (0, 0, 20) with dispatcher
09:46:52 DISPATCHER: job (0, 0, 20) finished
09:46:52 DISPATCHER: register_result: lock acquired
09:46:52 DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:46:52 job_id: (0, 0, 20)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.02221624849249378, 'num_filters_1': 101, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.0528716286297236}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.38763516277421267, 'info': {'music-speech': 0.38763516277421267, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.02221624849249378, 'num_filters_1': 101, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 50, 'weight_decay': 0.0528716286297236}"}}
exception: None

09:46:52 job_callback for (0, 0, 20) started
09:46:52 DISPATCHER: Trying to submit another job.
09:46:52 job_callback for (0, 0, 20) got condition
09:46:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:46:52 HBMASTER: Trying to run another job!
09:46:52 job_callback for (0, 0, 20) finished
09:46:52 start sampling a new configuration.
09:46:52 done sampling a new configuration.
09:46:52 HBMASTER: schedule new run for iteration 0
09:46:52 HBMASTER: trying submitting job (0, 0, 21) to dispatcher
09:46:52 HBMASTER: submitting job (0, 0, 21) to dispatcher
09:46:52 DISPATCHER: trying to submit job (0, 0, 21)
09:46:52 DISPATCHER: trying to notify the job_runner thread.
09:46:52 HBMASTER: job (0, 0, 21) submitted to dispatcher
09:46:52 DISPATCHER: Trying to submit another job.
09:46:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:46:52 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:46:52 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:46:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:46:52 WORKER: start processing job (0, 0, 21)
09:46:52 WORKER: args: ()
09:46:52 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0025053369921449005, 'num_filters_1': 45, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.059036541156816474, 'kernel_size_2': 3, 'num_filters_2': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:46:59 DISPATCHER: Starting worker discovery
09:46:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:46:59 DISPATCHER: Finished worker discovery
09:47:45 WORKER: done with job (0, 0, 21), trying to register it.
09:47:46 WORKER: registered result for job (0, 0, 21) with dispatcher
09:47:46 DISPATCHER: job (0, 0, 21) finished
09:47:46 DISPATCHER: register_result: lock acquired
09:47:46 DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:47:46 job_id: (0, 0, 21)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0025053369921449005, 'num_filters_1': 45, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.059036541156816474, 'kernel_size_2': 3, 'num_filters_2': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5559414139346506, 'info': {'music-speech': 0.5559414139346506, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0025053369921449005, 'num_filters_1': 45, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 51, 'weight_decay': 0.059036541156816474, 'kernel_size_2': 3, 'num_filters_2': 19}"}}
exception: None

09:47:46 job_callback for (0, 0, 21) started
09:47:46 DISPATCHER: Trying to submit another job.
09:47:46 job_callback for (0, 0, 21) got condition
09:47:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:47:46 HBMASTER: Trying to run another job!
09:47:46 job_callback for (0, 0, 21) finished
09:47:46 start sampling a new configuration.
09:47:46 done sampling a new configuration.
09:47:46 HBMASTER: schedule new run for iteration 0
09:47:46 HBMASTER: trying submitting job (0, 0, 22) to dispatcher
09:47:46 HBMASTER: submitting job (0, 0, 22) to dispatcher
09:47:46 DISPATCHER: trying to submit job (0, 0, 22)
09:47:46 DISPATCHER: trying to notify the job_runner thread.
09:47:46 HBMASTER: job (0, 0, 22) submitted to dispatcher
09:47:46 DISPATCHER: Trying to submit another job.
09:47:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:47:46 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:47:46 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:47:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:47:46 WORKER: start processing job (0, 0, 22)
09:47:46 WORKER: args: ()
09:47:46 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.017677146264045592, 'num_filters_1': 99, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.07823214888605313, 'kernel_size_2': 7, 'num_filters_2': 22}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:47:59 DISPATCHER: Starting worker discovery
09:47:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:47:59 DISPATCHER: Finished worker discovery
09:48:39 WORKER: done with job (0, 0, 22), trying to register it.
09:48:39 WORKER: registered result for job (0, 0, 22) with dispatcher
09:48:39 DISPATCHER: job (0, 0, 22) finished
09:48:39 DISPATCHER: register_result: lock acquired
09:48:39 DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:48:39 job_id: (0, 0, 22)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.017677146264045592, 'num_filters_1': 99, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.07823214888605313, 'kernel_size_2': 7, 'num_filters_2': 22}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.017677146264045592, 'num_filters_1': 99, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.07823214888605313, 'kernel_size_2': 7, 'num_filters_2': 22}"}}
exception: None

09:48:39 job_callback for (0, 0, 22) started
09:48:39 DISPATCHER: Trying to submit another job.
09:48:39 job_callback for (0, 0, 22) got condition
09:48:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:48:39 HBMASTER: Trying to run another job!
09:48:39 job_callback for (0, 0, 22) finished
09:48:39 start sampling a new configuration.
09:48:39 done sampling a new configuration.
09:48:39 HBMASTER: schedule new run for iteration 0
09:48:39 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
09:48:39 HBMASTER: submitting job (0, 0, 23) to dispatcher
09:48:39 DISPATCHER: trying to submit job (0, 0, 23)
09:48:39 DISPATCHER: trying to notify the job_runner thread.
09:48:39 HBMASTER: job (0, 0, 23) submitted to dispatcher
09:48:39 DISPATCHER: Trying to submit another job.
09:48:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:48:39 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:48:39 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:48:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:48:39 WORKER: start processing job (0, 0, 23)
09:48:39 WORKER: args: ()
09:48:39 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.00533812072494003, 'num_filters_1': 60, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.10020871500490447, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 76, 'num_filters_3': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:48:59 DISPATCHER: Starting worker discovery
09:48:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:48:59 DISPATCHER: Finished worker discovery
09:49:32 WORKER: done with job (0, 0, 23), trying to register it.
09:49:32 WORKER: registered result for job (0, 0, 23) with dispatcher
09:49:32 DISPATCHER: job (0, 0, 23) finished
09:49:32 DISPATCHER: register_result: lock acquired
09:49:32 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:49:32 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.00533812072494003, 'num_filters_1': 60, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.10020871500490447, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 76, 'num_filters_3': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8952916509158835, 'info': {'music-speech': 0.8952916509158835, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.00533812072494003, 'num_filters_1': 60, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.10020871500490447, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 76, 'num_filters_3': 23}"}}
exception: None

09:49:32 job_callback for (0, 0, 23) started
09:49:32 job_callback for (0, 0, 23) got condition
09:49:32 DISPATCHER: Trying to submit another job.
09:49:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:49:32 HBMASTER: Trying to run another job!
09:49:32 job_callback for (0, 0, 23) finished
09:49:32 start sampling a new configuration.
09:49:32 done sampling a new configuration.
09:49:32 HBMASTER: schedule new run for iteration 0
09:49:32 HBMASTER: trying submitting job (0, 0, 24) to dispatcher
09:49:32 HBMASTER: submitting job (0, 0, 24) to dispatcher
09:49:32 DISPATCHER: trying to submit job (0, 0, 24)
09:49:32 DISPATCHER: trying to notify the job_runner thread.
09:49:32 HBMASTER: job (0, 0, 24) submitted to dispatcher
09:49:32 DISPATCHER: Trying to submit another job.
09:49:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:49:32 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:49:32 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:49:32 WORKER: start processing job (0, 0, 24)
09:49:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:49:32 WORKER: args: ()
09:49:32 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.04438579717526581, 'num_filters_1': 83, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.1281096593419258, 'kernel_size_2': 3, 'num_filters_2': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-626:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

09:49:59 DISPATCHER: Starting worker discovery
09:49:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:49:59 DISPATCHER: Finished worker discovery
09:50:25 WORKER: done with job (0, 0, 24), trying to register it.
09:50:25 WORKER: registered result for job (0, 0, 24) with dispatcher
09:50:25 DISPATCHER: job (0, 0, 24) finished
09:50:25 DISPATCHER: register_result: lock acquired
09:50:25 DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:50:25 job_id: (0, 0, 24)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.04438579717526581, 'num_filters_1': 83, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.1281096593419258, 'kernel_size_2': 3, 'num_filters_2': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6358144841176903, 'info': {'music-speech': 0.6358144841176903, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.04438579717526581, 'num_filters_1': 83, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.1281096593419258, 'kernel_size_2': 3, 'num_filters_2': 24}"}}
exception: None

09:50:25 job_callback for (0, 0, 24) started
09:50:25 DISPATCHER: Trying to submit another job.
09:50:25 job_callback for (0, 0, 24) got condition
09:50:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:50:25 HBMASTER: Trying to run another job!
09:50:25 job_callback for (0, 0, 24) finished
09:50:25 start sampling a new configuration.
09:50:25 done sampling a new configuration.
09:50:25 HBMASTER: schedule new run for iteration 0
09:50:25 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
09:50:25 HBMASTER: submitting job (0, 0, 25) to dispatcher
09:50:25 DISPATCHER: trying to submit job (0, 0, 25)
09:50:25 DISPATCHER: trying to notify the job_runner thread.
09:50:25 HBMASTER: job (0, 0, 25) submitted to dispatcher
09:50:25 DISPATCHER: Trying to submit another job.
09:50:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:50:25 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:50:25 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:50:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:50:25 WORKER: start processing job (0, 0, 25)
09:50:25 WORKER: args: ()
09:50:25 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.007642895780597091, 'num_filters_1': 73, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.07652372726903192, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 83, 'num_filters_3': 36, 'num_filters_4': 70}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-627:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

09:50:59 DISPATCHER: Starting worker discovery
09:50:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:50:59 DISPATCHER: Finished worker discovery
09:51:18 WORKER: done with job (0, 0, 25), trying to register it.
09:51:18 WORKER: registered result for job (0, 0, 25) with dispatcher
09:51:18 DISPATCHER: job (0, 0, 25) finished
09:51:18 DISPATCHER: register_result: lock acquired
09:51:18 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:51:18 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.007642895780597091, 'num_filters_1': 73, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.07652372726903192, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 83, 'num_filters_3': 36, 'num_filters_4': 70}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9938495655963748, 'info': {'music-speech': 0.9938495655963748, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.007642895780597091, 'num_filters_1': 73, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.07652372726903192, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 83, 'num_filters_3': 36, 'num_filters_4': 70}"}}
exception: None

09:51:18 job_callback for (0, 0, 25) started
09:51:18 DISPATCHER: Trying to submit another job.
09:51:18 job_callback for (0, 0, 25) got condition
09:51:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:51:18 HBMASTER: Trying to run another job!
09:51:18 job_callback for (0, 0, 25) finished
09:51:18 start sampling a new configuration.
09:51:18 done sampling a new configuration.
09:51:18 HBMASTER: schedule new run for iteration 0
09:51:18 HBMASTER: trying submitting job (0, 0, 26) to dispatcher
09:51:18 HBMASTER: submitting job (0, 0, 26) to dispatcher
09:51:18 DISPATCHER: trying to submit job (0, 0, 26)
09:51:18 DISPATCHER: trying to notify the job_runner thread.
09:51:18 HBMASTER: job (0, 0, 26) submitted to dispatcher
09:51:18 DISPATCHER: Trying to submit another job.
09:51:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:51:18 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:51:18 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:51:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:51:18 WORKER: start processing job (0, 0, 26)
09:51:18 WORKER: args: ()
09:51:18 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0018711364243362697, 'num_filters_1': 58, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.06063887916380693, 'kernel_size_2': 3, 'num_filters_2': 75}, 'budget': 44.44444444444444, 'working_directory': '.'}
09:51:59 DISPATCHER: Starting worker discovery
09:51:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:51:59 DISPATCHER: Finished worker discovery
09:52:11 WORKER: done with job (0, 0, 26), trying to register it.
09:52:11 WORKER: registered result for job (0, 0, 26) with dispatcher
09:52:11 DISPATCHER: job (0, 0, 26) finished
09:52:11 DISPATCHER: register_result: lock acquired
09:52:11 DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:52:11 job_id: (0, 0, 26)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0018711364243362697, 'num_filters_1': 58, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.06063887916380693, 'kernel_size_2': 3, 'num_filters_2': 75}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6519451960182046, 'info': {'music-speech': 0.6519451960182046, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0018711364243362697, 'num_filters_1': 58, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 29, 'weight_decay': 0.06063887916380693, 'kernel_size_2': 3, 'num_filters_2': 75}"}}
exception: None

09:52:11 job_callback for (0, 0, 26) started
09:52:11 DISPATCHER: Trying to submit another job.
09:52:11 job_callback for (0, 0, 26) got condition
09:52:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:52:11 HBMASTER: Trying to run another job!
09:52:11 job_callback for (0, 0, 26) finished
09:52:11 ITERATION: Advancing config (0, 0, 1) to next budget 133.333333
09:52:11 ITERATION: Advancing config (0, 0, 5) to next budget 133.333333
09:52:11 ITERATION: Advancing config (0, 0, 8) to next budget 133.333333
09:52:11 ITERATION: Advancing config (0, 0, 9) to next budget 133.333333
09:52:11 ITERATION: Advancing config (0, 0, 12) to next budget 133.333333
09:52:11 ITERATION: Advancing config (0, 0, 15) to next budget 133.333333
09:52:11 ITERATION: Advancing config (0, 0, 18) to next budget 133.333333
09:52:11 ITERATION: Advancing config (0, 0, 23) to next budget 133.333333
09:52:11 ITERATION: Advancing config (0, 0, 25) to next budget 133.333333
09:52:11 HBMASTER: schedule new run for iteration 0
09:52:11 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
09:52:11 HBMASTER: submitting job (0, 0, 1) to dispatcher
09:52:11 DISPATCHER: trying to submit job (0, 0, 1)
09:52:11 DISPATCHER: trying to notify the job_runner thread.
09:52:11 HBMASTER: job (0, 0, 1) submitted to dispatcher
09:52:11 DISPATCHER: Trying to submit another job.
09:52:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:52:11 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:52:11 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:52:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:52:12 WORKER: start processing job (0, 0, 1)
09:52:12 WORKER: args: ()
09:52:12 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0026759955745375265, 'num_filters_1': 19, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.03700965918762469, 'kernel_size_2': 5, 'num_filters_2': 21}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:52:59 DISPATCHER: Starting worker discovery
09:52:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:52:59 DISPATCHER: Finished worker discovery
09:53:59 DISPATCHER: Starting worker discovery
09:53:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:53:59 DISPATCHER: Finished worker discovery
09:54:34 WORKER: done with job (0, 0, 1), trying to register it.
09:54:34 WORKER: registered result for job (0, 0, 1) with dispatcher
09:54:34 DISPATCHER: job (0, 0, 1) finished
09:54:34 DISPATCHER: register_result: lock acquired
09:54:34 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:54:34 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0026759955745375265, 'num_filters_1': 19, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.03700965918762469, 'kernel_size_2': 5, 'num_filters_2': 21}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8019615037548287, 'info': {'music-speech': 0.8019615037548287, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0026759955745375265, 'num_filters_1': 19, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.03700965918762469, 'kernel_size_2': 5, 'num_filters_2': 21}"}}
exception: None

09:54:34 job_callback for (0, 0, 1) started
09:54:34 job_callback for (0, 0, 1) got condition
09:54:34 DISPATCHER: Trying to submit another job.
09:54:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:54:34 Only 1 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
09:54:34 HBMASTER: Trying to run another job!
09:54:34 job_callback for (0, 0, 1) finished
09:54:34 HBMASTER: schedule new run for iteration 0
09:54:34 HBMASTER: trying submitting job (0, 0, 5) to dispatcher
09:54:34 HBMASTER: submitting job (0, 0, 5) to dispatcher
09:54:34 DISPATCHER: trying to submit job (0, 0, 5)
09:54:34 DISPATCHER: trying to notify the job_runner thread.
09:54:34 HBMASTER: job (0, 0, 5) submitted to dispatcher
09:54:34 DISPATCHER: Trying to submit another job.
09:54:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:54:34 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:54:34 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:54:34 WORKER: start processing job (0, 0, 5)
09:54:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:54:34 WORKER: args: ()
09:54:34 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.008593505525023888, 'num_filters_1': 126, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.02632406429832292, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 65, 'num_filters_3': 19}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:54:59 DISPATCHER: Starting worker discovery
09:54:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:54:59 DISPATCHER: Finished worker discovery
09:55:59 DISPATCHER: Starting worker discovery
09:55:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:55:59 DISPATCHER: Finished worker discovery
09:56:58 WORKER: done with job (0, 0, 5), trying to register it.
09:56:58 WORKER: registered result for job (0, 0, 5) with dispatcher
09:56:58 DISPATCHER: job (0, 0, 5) finished
09:56:58 DISPATCHER: register_result: lock acquired
09:56:58 DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:56:58 job_id: (0, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.008593505525023888, 'num_filters_1': 126, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.02632406429832292, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 65, 'num_filters_3': 19}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0008032963261967588, 'info': {'music-speech': 0.0008032963261967588, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.008593505525023888, 'num_filters_1': 126, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.02632406429832292, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 65, 'num_filters_3': 19}"}}
exception: None

09:56:58 job_callback for (0, 0, 5) started
09:56:58 DISPATCHER: Trying to submit another job.
09:56:58 job_callback for (0, 0, 5) got condition
09:56:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:56:58 Only 2 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
09:56:58 HBMASTER: Trying to run another job!
09:56:58 job_callback for (0, 0, 5) finished
09:56:58 HBMASTER: schedule new run for iteration 0
09:56:58 HBMASTER: trying submitting job (0, 0, 8) to dispatcher
09:56:58 HBMASTER: submitting job (0, 0, 8) to dispatcher
09:56:58 DISPATCHER: trying to submit job (0, 0, 8)
09:56:58 DISPATCHER: trying to notify the job_runner thread.
09:56:58 HBMASTER: job (0, 0, 8) submitted to dispatcher
09:56:58 DISPATCHER: Trying to submit another job.
09:56:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:56:58 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:56:58 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:56:58 WORKER: start processing job (0, 0, 8)
09:56:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:56:58 WORKER: args: ()
09:56:58 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0026326000571681605, 'num_filters_1': 68, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.024178187377917198, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 87, 'num_filters_3': 98, 'num_filters_4': 32, 'num_filters_5': 35}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:56:59 DISPATCHER: Starting worker discovery
09:56:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:56:59 DISPATCHER: Finished worker discovery
09:57:59 DISPATCHER: Starting worker discovery
09:57:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:57:59 DISPATCHER: Finished worker discovery
09:58:59 DISPATCHER: Starting worker discovery
09:58:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:58:59 DISPATCHER: Finished worker discovery
09:59:20 WORKER: done with job (0, 0, 8), trying to register it.
09:59:20 WORKER: registered result for job (0, 0, 8) with dispatcher
09:59:20 DISPATCHER: job (0, 0, 8) finished
09:59:20 DISPATCHER: register_result: lock acquired
09:59:20 DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
09:59:20 job_id: (0, 0, 8)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0026326000571681605, 'num_filters_1': 68, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.024178187377917198, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 87, 'num_filters_3': 98, 'num_filters_4': 32, 'num_filters_5': 35}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5767587483454637, 'info': {'music-speech': 0.5767587483454637, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0026326000571681605, 'num_filters_1': 68, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 38, 'weight_decay': 0.024178187377917198, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 87, 'num_filters_3': 98, 'num_filters_4': 32, 'num_filters_5': 35}"}}
exception: None

09:59:20 job_callback for (0, 0, 8) started
09:59:20 job_callback for (0, 0, 8) got condition
09:59:20 DISPATCHER: Trying to submit another job.
09:59:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
09:59:20 Only 3 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
09:59:20 HBMASTER: Trying to run another job!
09:59:20 job_callback for (0, 0, 8) finished
09:59:20 HBMASTER: schedule new run for iteration 0
09:59:20 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
09:59:20 HBMASTER: submitting job (0, 0, 9) to dispatcher
09:59:20 DISPATCHER: trying to submit job (0, 0, 9)
09:59:20 DISPATCHER: trying to notify the job_runner thread.
09:59:20 HBMASTER: job (0, 0, 9) submitted to dispatcher
09:59:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
09:59:20 DISPATCHER: Trying to submit another job.
09:59:20 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpul.22021139727314577216
09:59:20 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
09:59:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
09:59:20 WORKER: start processing job (0, 0, 9)
09:59:20 WORKER: args: ()
09:59:20 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0010340879715748813, 'num_filters_1': 104, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.09414967749811681, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 57, 'num_filters_3': 25, 'num_filters_4': 79, 'num_filters_5': 63}, 'budget': 133.33333333333331, 'working_directory': '.'}
09:59:59 DISPATCHER: Starting worker discovery
09:59:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
09:59:59 DISPATCHER: Finished worker discovery
10:00:59 DISPATCHER: Starting worker discovery
10:00:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:00:59 DISPATCHER: Finished worker discovery
10:01:43 WORKER: done with job (0, 0, 9), trying to register it.
10:01:43 DISPATCHER: job (0, 0, 9) finished
10:01:43 WORKER: registered result for job (0, 0, 9) with dispatcher
10:01:43 DISPATCHER: register_result: lock acquired
10:01:43 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
10:01:43 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0010340879715748813, 'num_filters_1': 104, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.09414967749811681, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 57, 'num_filters_3': 25, 'num_filters_4': 79, 'num_filters_5': 63}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7716713970628528, 'info': {'music-speech': 0.7716713970628528, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0010340879715748813, 'num_filters_1': 104, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.09414967749811681, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 57, 'num_filters_3': 25, 'num_filters_4': 79, 'num_filters_5': 63}"}}
exception: None

10:01:43 job_callback for (0, 0, 9) started
10:01:43 DISPATCHER: Trying to submit another job.
10:01:43 job_callback for (0, 0, 9) got condition
10:01:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:01:43 Only 4 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
10:01:43 HBMASTER: Trying to run another job!
10:01:43 job_callback for (0, 0, 9) finished
10:01:43 HBMASTER: schedule new run for iteration 0
10:01:43 HBMASTER: trying submitting job (0, 0, 12) to dispatcher
10:01:43 HBMASTER: submitting job (0, 0, 12) to dispatcher
10:01:43 DISPATCHER: trying to submit job (0, 0, 12)
10:01:43 DISPATCHER: trying to notify the job_runner thread.
10:01:43 HBMASTER: job (0, 0, 12) submitted to dispatcher
10:01:43 DISPATCHER: Trying to submit another job.
10:01:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:01:43 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216
10:01:43 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
10:01:43 WORKER: start processing job (0, 0, 12)
10:01:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:01:43 WORKER: args: ()
10:01:43 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003197151779422022, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.050814383556602616, 'kernel_size_2': 3, 'num_filters_2': 61}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:01:59 DISPATCHER: Starting worker discovery
10:01:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:01:59 DISPATCHER: Finished worker discovery
10:02:59 DISPATCHER: Starting worker discovery
10:02:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:02:59 DISPATCHER: Finished worker discovery
10:03:59 DISPATCHER: Starting worker discovery
10:03:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:03:59 DISPATCHER: Finished worker discovery
10:04:05 WORKER: done with job (0, 0, 12), trying to register it.
10:04:05 WORKER: registered result for job (0, 0, 12) with dispatcher
10:04:05 DISPATCHER: job (0, 0, 12) finished
10:04:05 DISPATCHER: register_result: lock acquired
10:04:05 DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
10:04:05 job_id: (0, 0, 12)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003197151779422022, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.050814383556602616, 'kernel_size_2': 3, 'num_filters_2': 61}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6663927713195339, 'info': {'music-speech': 0.6663927713195339, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.003197151779422022, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 32, 'weight_decay': 0.050814383556602616, 'kernel_size_2': 3, 'num_filters_2': 61}"}}
exception: None

10:04:05 job_callback for (0, 0, 12) started
10:04:05 DISPATCHER: Trying to submit another job.
10:04:05 job_callback for (0, 0, 12) got condition
10:04:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:04:05 Only 5 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
10:04:05 HBMASTER: Trying to run another job!
10:04:05 job_callback for (0, 0, 12) finished
10:04:05 HBMASTER: schedule new run for iteration 0
10:04:05 HBMASTER: trying submitting job (0, 0, 15) to dispatcher
10:04:05 HBMASTER: submitting job (0, 0, 15) to dispatcher
10:04:05 DISPATCHER: trying to submit job (0, 0, 15)
10:04:05 DISPATCHER: trying to notify the job_runner thread.
10:04:05 HBMASTER: job (0, 0, 15) submitted to dispatcher
10:04:05 DISPATCHER: Trying to submit another job.
10:04:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:04:05 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216
10:04:05 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
10:04:05 WORKER: start processing job (0, 0, 15)
10:04:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:04:05 WORKER: args: ()
10:04:05 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.008646606551333345, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.16798787921454883, 'kernel_size_2': 3, 'num_filters_2': 46}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:04:59 DISPATCHER: Starting worker discovery
10:04:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:04:59 DISPATCHER: Finished worker discovery
10:05:59 DISPATCHER: Starting worker discovery
10:05:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:05:59 DISPATCHER: Finished worker discovery
10:06:29 WORKER: done with job (0, 0, 15), trying to register it.
10:06:29 WORKER: registered result for job (0, 0, 15) with dispatcher
10:06:29 DISPATCHER: job (0, 0, 15) finished
10:06:29 DISPATCHER: register_result: lock acquired
10:06:29 DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
10:06:29 job_id: (0, 0, 15)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.008646606551333345, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.16798787921454883, 'kernel_size_2': 3, 'num_filters_2': 46}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6405312750722408, 'info': {'music-speech': 0.6405312750722408, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.008646606551333345, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 56, 'weight_decay': 0.16798787921454883, 'kernel_size_2': 3, 'num_filters_2': 46}"}}
exception: None

10:06:29 job_callback for (0, 0, 15) started
10:06:29 job_callback for (0, 0, 15) got condition
10:06:29 DISPATCHER: Trying to submit another job.
10:06:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:06:29 Only 6 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
10:06:29 HBMASTER: Trying to run another job!
10:06:29 job_callback for (0, 0, 15) finished
10:06:29 HBMASTER: schedule new run for iteration 0
10:06:29 HBMASTER: trying submitting job (0, 0, 18) to dispatcher
10:06:29 HBMASTER: submitting job (0, 0, 18) to dispatcher
10:06:29 DISPATCHER: trying to submit job (0, 0, 18)
10:06:29 DISPATCHER: trying to notify the job_runner thread.
10:06:29 HBMASTER: job (0, 0, 18) submitted to dispatcher
10:06:29 DISPATCHER: Trying to submit another job.
10:06:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:06:29 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.metagpul.22021139727314577216
10:06:29 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
10:06:29 WORKER: start processing job (0, 0, 18)
10:06:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:06:29 WORKER: args: ()
10:06:29 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.06846452224407075, 'num_filters_1': 56, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.014819454329965972, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 45, 'num_filters_3': 22, 'num_filters_4': 53, 'num_filters_5': 27}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:06:59 DISPATCHER: Starting worker discovery
10:06:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:06:59 DISPATCHER: Finished worker discovery
Exception in thread Thread-635:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

10:07:59 DISPATCHER: Starting worker discovery
10:08:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:08:00 DISPATCHER: Finished worker discovery
10:08:50 WORKER: done with job (0, 0, 18), trying to register it.
10:08:51 DISPATCHER: job (0, 0, 18) finished
10:08:51 WORKER: registered result for job (0, 0, 18) with dispatcher
10:08:51 DISPATCHER: register_result: lock acquired
10:08:51 DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
10:08:51 job_id: (0, 0, 18)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.06846452224407075, 'num_filters_1': 56, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.014819454329965972, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 45, 'num_filters_3': 22, 'num_filters_4': 53, 'num_filters_5': 27}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.18325324001221427, 'info': {'music-speech': 0.18325324001221427, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.06846452224407075, 'num_filters_1': 56, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 49, 'weight_decay': 0.014819454329965972, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 45, 'num_filters_3': 22, 'num_filters_4': 53, 'num_filters_5': 27}"}}
exception: None

10:08:51 job_callback for (0, 0, 18) started
10:08:51 DISPATCHER: Trying to submit another job.
10:08:51 job_callback for (0, 0, 18) got condition
10:08:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:08:51 Only 7 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
10:08:51 HBMASTER: Trying to run another job!
10:08:51 job_callback for (0, 0, 18) finished
10:08:51 HBMASTER: schedule new run for iteration 0
10:08:51 HBMASTER: trying submitting job (0, 0, 23) to dispatcher
10:08:51 HBMASTER: submitting job (0, 0, 23) to dispatcher
10:08:51 DISPATCHER: trying to submit job (0, 0, 23)
10:08:51 DISPATCHER: trying to notify the job_runner thread.
10:08:51 HBMASTER: job (0, 0, 23) submitted to dispatcher
10:08:51 DISPATCHER: Trying to submit another job.
10:08:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:08:51 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216
10:08:51 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
10:08:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:08:51 WORKER: start processing job (0, 0, 23)
10:08:51 WORKER: args: ()
10:08:51 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.00533812072494003, 'num_filters_1': 60, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.10020871500490447, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 76, 'num_filters_3': 23}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:09:00 DISPATCHER: Starting worker discovery
10:09:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:09:00 DISPATCHER: Finished worker discovery
10:10:00 DISPATCHER: Starting worker discovery
10:10:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:10:00 DISPATCHER: Finished worker discovery
10:11:00 DISPATCHER: Starting worker discovery
10:11:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:11:00 DISPATCHER: Finished worker discovery
10:11:13 WORKER: done with job (0, 0, 23), trying to register it.
10:11:13 WORKER: registered result for job (0, 0, 23) with dispatcher
10:11:13 DISPATCHER: job (0, 0, 23) finished
10:11:13 DISPATCHER: register_result: lock acquired
10:11:13 DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
10:11:13 job_id: (0, 0, 23)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.00533812072494003, 'num_filters_1': 60, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.10020871500490447, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 76, 'num_filters_3': 23}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7506895620690034, 'info': {'music-speech': 0.7506895620690034, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.00533812072494003, 'num_filters_1': 60, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 13, 'weight_decay': 0.10020871500490447, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 76, 'num_filters_3': 23}"}}
exception: None

10:11:13 job_callback for (0, 0, 23) started
10:11:13 DISPATCHER: Trying to submit another job.
10:11:13 job_callback for (0, 0, 23) got condition
10:11:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:11:13 Only 8 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
10:11:13 HBMASTER: Trying to run another job!
10:11:13 job_callback for (0, 0, 23) finished
10:11:13 HBMASTER: schedule new run for iteration 0
10:11:13 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
10:11:13 HBMASTER: submitting job (0, 0, 25) to dispatcher
10:11:13 DISPATCHER: trying to submit job (0, 0, 25)
10:11:13 DISPATCHER: trying to notify the job_runner thread.
10:11:13 HBMASTER: job (0, 0, 25) submitted to dispatcher
10:11:13 DISPATCHER: Trying to submit another job.
10:11:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:11:13 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216
10:11:13 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
10:11:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:11:13 WORKER: start processing job (0, 0, 25)
10:11:13 WORKER: args: ()
10:11:13 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.007642895780597091, 'num_filters_1': 73, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.07652372726903192, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 83, 'num_filters_3': 36, 'num_filters_4': 70}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-637:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

10:12:00 DISPATCHER: Starting worker discovery
10:12:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:12:00 DISPATCHER: Finished worker discovery
10:13:00 DISPATCHER: Starting worker discovery
10:13:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:13:00 DISPATCHER: Finished worker discovery
10:13:35 WORKER: done with job (0, 0, 25), trying to register it.
10:13:35 DISPATCHER: job (0, 0, 25) finished
10:13:35 WORKER: registered result for job (0, 0, 25) with dispatcher
10:13:35 DISPATCHER: register_result: lock acquired
10:13:35 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
10:13:35 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.007642895780597091, 'num_filters_1': 73, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.07652372726903192, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 83, 'num_filters_3': 36, 'num_filters_4': 70}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8380619745892885, 'info': {'music-speech': 0.8380619745892885, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.007642895780597091, 'num_filters_1': 73, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.07652372726903192, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 83, 'num_filters_3': 36, 'num_filters_4': 70}"}}
exception: None

10:13:35 job_callback for (0, 0, 25) started
10:13:35 DISPATCHER: Trying to submit another job.
10:13:35 job_callback for (0, 0, 25) got condition
10:13:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:13:35 Only 9 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
10:13:35 HBMASTER: Trying to run another job!
10:13:35 job_callback for (0, 0, 25) finished
10:13:35 ITERATION: Advancing config (0, 0, 1) to next budget 400.000000
10:13:35 ITERATION: Advancing config (0, 0, 9) to next budget 400.000000
10:13:35 ITERATION: Advancing config (0, 0, 25) to next budget 400.000000
10:13:35 HBMASTER: schedule new run for iteration 0
10:13:35 HBMASTER: trying submitting job (0, 0, 1) to dispatcher
10:13:35 HBMASTER: submitting job (0, 0, 1) to dispatcher
10:13:35 DISPATCHER: trying to submit job (0, 0, 1)
10:13:35 DISPATCHER: trying to notify the job_runner thread.
10:13:35 HBMASTER: job (0, 0, 1) submitted to dispatcher
10:13:35 DISPATCHER: Trying to submit another job.
10:13:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:13:35 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
10:13:35 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
10:13:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:13:35 WORKER: start processing job (0, 0, 1)
10:13:35 WORKER: args: ()
10:13:35 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0026759955745375265, 'num_filters_1': 19, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.03700965918762469, 'kernel_size_2': 5, 'num_filters_2': 21}, 'budget': 400.0, 'working_directory': '.'}
10:14:00 DISPATCHER: Starting worker discovery
10:14:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:14:00 DISPATCHER: Finished worker discovery
10:15:00 DISPATCHER: Starting worker discovery
10:15:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:15:00 DISPATCHER: Finished worker discovery
10:16:00 DISPATCHER: Starting worker discovery
10:16:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:16:00 DISPATCHER: Finished worker discovery
10:17:00 DISPATCHER: Starting worker discovery
10:17:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:17:00 DISPATCHER: Finished worker discovery
10:18:00 DISPATCHER: Starting worker discovery
10:18:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:18:00 DISPATCHER: Finished worker discovery
10:19:00 DISPATCHER: Starting worker discovery
10:19:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:19:00 DISPATCHER: Finished worker discovery
10:20:00 DISPATCHER: Starting worker discovery
10:20:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:20:00 DISPATCHER: Finished worker discovery
10:20:25 WORKER: done with job (0, 0, 1), trying to register it.
10:20:25 WORKER: registered result for job (0, 0, 1) with dispatcher
10:20:25 DISPATCHER: job (0, 0, 1) finished
10:20:25 DISPATCHER: register_result: lock acquired
10:20:25 DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
10:20:25 job_id: (0, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0026759955745375265, 'num_filters_1': 19, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.03700965918762469, 'kernel_size_2': 5, 'num_filters_2': 21}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8590614535429693, 'info': {'music-speech': 0.8590614535429693, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0026759955745375265, 'num_filters_1': 19, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.03700965918762469, 'kernel_size_2': 5, 'num_filters_2': 21}"}}
exception: None

10:20:25 job_callback for (0, 0, 1) started
10:20:25 DISPATCHER: Trying to submit another job.
10:20:25 job_callback for (0, 0, 1) got condition
10:20:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:20:25 Only 1 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
10:20:25 HBMASTER: Trying to run another job!
10:20:25 job_callback for (0, 0, 1) finished
10:20:25 HBMASTER: schedule new run for iteration 0
10:20:25 HBMASTER: trying submitting job (0, 0, 9) to dispatcher
10:20:25 HBMASTER: submitting job (0, 0, 9) to dispatcher
10:20:25 DISPATCHER: trying to submit job (0, 0, 9)
10:20:25 DISPATCHER: trying to notify the job_runner thread.
10:20:25 HBMASTER: job (0, 0, 9) submitted to dispatcher
10:20:25 DISPATCHER: Trying to submit another job.
10:20:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:20:25 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.metagpul.22021139727314577216
10:20:25 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
10:20:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:20:25 WORKER: start processing job (0, 0, 9)
10:20:25 WORKER: args: ()
10:20:25 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0010340879715748813, 'num_filters_1': 104, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.09414967749811681, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 57, 'num_filters_3': 25, 'num_filters_4': 79, 'num_filters_5': 63}, 'budget': 400.0, 'working_directory': '.'}
10:21:00 DISPATCHER: Starting worker discovery
10:21:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:21:00 DISPATCHER: Finished worker discovery
10:22:00 DISPATCHER: Starting worker discovery
10:22:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:22:00 DISPATCHER: Finished worker discovery
10:23:00 DISPATCHER: Starting worker discovery
10:23:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:23:00 DISPATCHER: Finished worker discovery
10:24:00 DISPATCHER: Starting worker discovery
10:24:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:24:00 DISPATCHER: Finished worker discovery
10:25:00 DISPATCHER: Starting worker discovery
10:25:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:25:00 DISPATCHER: Finished worker discovery
10:26:00 DISPATCHER: Starting worker discovery
10:26:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:26:00 DISPATCHER: Finished worker discovery
10:27:00 DISPATCHER: Starting worker discovery
10:27:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:27:00 DISPATCHER: Finished worker discovery
10:27:14 WORKER: done with job (0, 0, 9), trying to register it.
10:27:14 WORKER: registered result for job (0, 0, 9) with dispatcher
10:27:14 DISPATCHER: job (0, 0, 9) finished
10:27:14 DISPATCHER: register_result: lock acquired
10:27:14 DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
10:27:14 job_id: (0, 0, 9)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0010340879715748813, 'num_filters_1': 104, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.09414967749811681, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 57, 'num_filters_3': 25, 'num_filters_4': 79, 'num_filters_5': 63}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7021604674381099, 'info': {'music-speech': 0.7021604674381099, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0010340879715748813, 'num_filters_1': 104, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 84, 'weight_decay': 0.09414967749811681, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 57, 'num_filters_3': 25, 'num_filters_4': 79, 'num_filters_5': 63}"}}
exception: None

10:27:14 job_callback for (0, 0, 9) started
10:27:14 DISPATCHER: Trying to submit another job.
10:27:14 job_callback for (0, 0, 9) got condition
10:27:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:27:14 Only 2 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
10:27:14 HBMASTER: Trying to run another job!
10:27:14 job_callback for (0, 0, 9) finished
10:27:14 HBMASTER: schedule new run for iteration 0
10:27:14 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
10:27:14 HBMASTER: submitting job (0, 0, 25) to dispatcher
10:27:14 DISPATCHER: trying to submit job (0, 0, 25)
10:27:14 DISPATCHER: trying to notify the job_runner thread.
10:27:14 HBMASTER: job (0, 0, 25) submitted to dispatcher
10:27:14 DISPATCHER: Trying to submit another job.
10:27:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:27:14 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216
10:27:14 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
10:27:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:27:14 WORKER: start processing job (0, 0, 25)
10:27:14 WORKER: args: ()
10:27:14 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.007642895780597091, 'num_filters_1': 73, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.07652372726903192, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 83, 'num_filters_3': 36, 'num_filters_4': 70}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-640:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

10:28:00 DISPATCHER: Starting worker discovery
10:28:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:28:00 DISPATCHER: Finished worker discovery
10:29:00 DISPATCHER: Starting worker discovery
10:29:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:29:00 DISPATCHER: Finished worker discovery
10:30:00 DISPATCHER: Starting worker discovery
10:30:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:30:00 DISPATCHER: Finished worker discovery
10:31:00 DISPATCHER: Starting worker discovery
10:31:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:31:00 DISPATCHER: Finished worker discovery
10:32:00 DISPATCHER: Starting worker discovery
10:32:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:32:00 DISPATCHER: Finished worker discovery
10:33:00 DISPATCHER: Starting worker discovery
10:33:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:33:00 DISPATCHER: Finished worker discovery
10:34:00 DISPATCHER: Starting worker discovery
10:34:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:34:00 DISPATCHER: Finished worker discovery
10:34:03 WORKER: done with job (0, 0, 25), trying to register it.
10:34:03 WORKER: registered result for job (0, 0, 25) with dispatcher
10:34:03 DISPATCHER: job (0, 0, 25) finished
10:34:03 DISPATCHER: register_result: lock acquired
10:34:03 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
10:34:03 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.007642895780597091, 'num_filters_1': 73, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.07652372726903192, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 83, 'num_filters_3': 36, 'num_filters_4': 70}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.9288368815000021, 'info': {'music-speech': 0.9288368815000021, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.007642895780597091, 'num_filters_1': 73, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.07652372726903192, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 83, 'num_filters_3': 36, 'num_filters_4': 70}"}}
exception: None

10:34:03 job_callback for (0, 0, 25) started
10:34:03 DISPATCHER: Trying to submit another job.
10:34:03 job_callback for (0, 0, 25) got condition
10:34:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:34:03 Only 3 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
10:34:03 HBMASTER: Trying to run another job!
10:34:03 job_callback for (0, 0, 25) finished
10:34:03 ITERATION: Advancing config (0, 0, 25) to next budget 1200.000000
10:34:03 HBMASTER: schedule new run for iteration 0
10:34:03 HBMASTER: trying submitting job (0, 0, 25) to dispatcher
10:34:03 HBMASTER: submitting job (0, 0, 25) to dispatcher
10:34:03 DISPATCHER: trying to submit job (0, 0, 25)
10:34:03 DISPATCHER: trying to notify the job_runner thread.
10:34:03 HBMASTER: job (0, 0, 25) submitted to dispatcher
10:34:03 DISPATCHER: Trying to submit another job.
10:34:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:34:03 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216
10:34:03 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
10:34:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:34:03 WORKER: start processing job (0, 0, 25)
10:34:03 WORKER: args: ()
10:34:03 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.007642895780597091, 'num_filters_1': 73, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.07652372726903192, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 83, 'num_filters_3': 36, 'num_filters_4': 70}, 'budget': 1200.0, 'working_directory': '.'}
10:35:00 DISPATCHER: Starting worker discovery
10:35:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:35:00 DISPATCHER: Finished worker discovery
10:36:00 DISPATCHER: Starting worker discovery
10:36:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:36:00 DISPATCHER: Finished worker discovery
10:37:00 DISPATCHER: Starting worker discovery
10:37:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:37:00 DISPATCHER: Finished worker discovery
10:38:00 DISPATCHER: Starting worker discovery
10:38:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:38:00 DISPATCHER: Finished worker discovery
10:39:00 DISPATCHER: Starting worker discovery
10:39:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:39:00 DISPATCHER: Finished worker discovery
10:40:00 DISPATCHER: Starting worker discovery
10:40:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:40:00 DISPATCHER: Finished worker discovery
10:41:00 DISPATCHER: Starting worker discovery
10:41:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:41:00 DISPATCHER: Finished worker discovery
10:42:00 DISPATCHER: Starting worker discovery
10:42:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:42:00 DISPATCHER: Finished worker discovery
10:43:00 DISPATCHER: Starting worker discovery
10:43:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:43:00 DISPATCHER: Finished worker discovery
10:44:00 DISPATCHER: Starting worker discovery
10:44:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:44:00 DISPATCHER: Finished worker discovery
10:45:00 DISPATCHER: Starting worker discovery
10:45:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:45:00 DISPATCHER: Finished worker discovery
10:46:00 DISPATCHER: Starting worker discovery
10:46:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:46:00 DISPATCHER: Finished worker discovery
10:47:00 DISPATCHER: Starting worker discovery
10:47:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:47:00 DISPATCHER: Finished worker discovery
10:48:00 DISPATCHER: Starting worker discovery
10:48:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:48:00 DISPATCHER: Finished worker discovery
10:49:00 DISPATCHER: Starting worker discovery
10:49:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:49:00 DISPATCHER: Finished worker discovery
10:50:00 DISPATCHER: Starting worker discovery
10:50:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:50:00 DISPATCHER: Finished worker discovery
10:51:00 DISPATCHER: Starting worker discovery
10:51:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:51:00 DISPATCHER: Finished worker discovery
10:52:00 DISPATCHER: Starting worker discovery
10:52:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:52:00 DISPATCHER: Finished worker discovery
10:53:00 DISPATCHER: Starting worker discovery
10:53:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:53:00 DISPATCHER: Finished worker discovery
10:54:00 DISPATCHER: Starting worker discovery
10:54:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:54:00 DISPATCHER: Finished worker discovery
10:54:14 WORKER: done with job (0, 0, 25), trying to register it.
10:54:14 WORKER: registered result for job (0, 0, 25) with dispatcher
10:54:14 DISPATCHER: job (0, 0, 25) finished
10:54:14 DISPATCHER: register_result: lock acquired
10:54:14 DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
10:54:14 job_id: (0, 0, 25)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.007642895780597091, 'num_filters_1': 73, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.07652372726903192, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 83, 'num_filters_3': 36, 'num_filters_4': 70}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.2662128438699489, 'info': {'music-speech': 0.2662128438699489, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.007642895780597091, 'num_filters_1': 73, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 87, 'weight_decay': 0.07652372726903192, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 83, 'num_filters_3': 36, 'num_filters_4': 70}"}}
exception: None

10:54:14 job_callback for (0, 0, 25) started
10:54:14 DISPATCHER: Trying to submit another job.
10:54:14 job_callback for (0, 0, 25) got condition
10:54:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:54:15 Only 1 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
10:54:15 HBMASTER: Trying to run another job!
10:54:15 job_callback for (0, 0, 25) finished
10:54:15 start sampling a new configuration.
10:54:15 done sampling a new configuration.
10:54:15 HBMASTER: schedule new run for iteration 1
10:54:15 HBMASTER: trying submitting job (1, 0, 0) to dispatcher
10:54:15 HBMASTER: submitting job (1, 0, 0) to dispatcher
10:54:15 DISPATCHER: trying to submit job (1, 0, 0)
10:54:15 DISPATCHER: trying to notify the job_runner thread.
10:54:15 HBMASTER: job (1, 0, 0) submitted to dispatcher
10:54:15 DISPATCHER: Trying to submit another job.
10:54:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:54:15 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
10:54:15 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
10:54:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:54:15 WORKER: start processing job (1, 0, 0)
10:54:15 WORKER: args: ()
10:54:15 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001114391982485749, 'num_filters_1': 114, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.07874132464655546, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 99, 'num_filters_3': 16}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:55:00 DISPATCHER: Starting worker discovery
10:55:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:55:00 DISPATCHER: Finished worker discovery
10:56:00 DISPATCHER: Starting worker discovery
10:56:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:56:00 DISPATCHER: Finished worker discovery
10:56:37 WORKER: done with job (1, 0, 0), trying to register it.
10:56:37 WORKER: registered result for job (1, 0, 0) with dispatcher
10:56:37 DISPATCHER: job (1, 0, 0) finished
10:56:37 DISPATCHER: register_result: lock acquired
10:56:37 DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
10:56:37 job_id: (1, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001114391982485749, 'num_filters_1': 114, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.07874132464655546, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 99, 'num_filters_3': 16}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.576910825887421, 'info': {'music-speech': 0.576910825887421, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.001114391982485749, 'num_filters_1': 114, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 25, 'weight_decay': 0.07874132464655546, 'kernel_size_2': 7, 'kernel_size_3': 3, 'num_filters_2': 99, 'num_filters_3': 16}"}}
exception: None

10:56:37 job_callback for (1, 0, 0) started
10:56:37 job_callback for (1, 0, 0) got condition
10:56:37 DISPATCHER: Trying to submit another job.
10:56:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:56:37 Only 10 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
10:56:37 HBMASTER: Trying to run another job!
10:56:37 job_callback for (1, 0, 0) finished
10:56:37 start sampling a new configuration.
10:56:37 done sampling a new configuration.
10:56:37 HBMASTER: schedule new run for iteration 1
10:56:37 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
10:56:37 HBMASTER: submitting job (1, 0, 1) to dispatcher
10:56:37 DISPATCHER: trying to submit job (1, 0, 1)
10:56:37 DISPATCHER: trying to notify the job_runner thread.
10:56:37 HBMASTER: job (1, 0, 1) submitted to dispatcher
10:56:37 DISPATCHER: Trying to submit another job.
10:56:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:56:37 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
10:56:37 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
10:56:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:56:37 WORKER: start processing job (1, 0, 1)
10:56:37 WORKER: args: ()
10:56:37 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.06503467023333032, 'num_filters_1': 68, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 11, 'weight_decay': 0.010425224865114902}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:57:00 DISPATCHER: Starting worker discovery
10:57:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:57:00 DISPATCHER: Finished worker discovery
10:58:00 DISPATCHER: Starting worker discovery
10:58:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:58:00 DISPATCHER: Finished worker discovery
10:58:59 WORKER: done with job (1, 0, 1), trying to register it.
10:58:59 DISPATCHER: job (1, 0, 1) finished
10:58:59 WORKER: registered result for job (1, 0, 1) with dispatcher
10:58:59 DISPATCHER: register_result: lock acquired
10:58:59 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
10:58:59 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.06503467023333032, 'num_filters_1': 68, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 11, 'weight_decay': 0.010425224865114902}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8327377757074623, 'info': {'music-speech': 0.8327377757074623, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.06503467023333032, 'num_filters_1': 68, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 11, 'weight_decay': 0.010425224865114902}"}}
exception: None

10:58:59 job_callback for (1, 0, 1) started
10:58:59 DISPATCHER: Trying to submit another job.
10:58:59 job_callback for (1, 0, 1) got condition
10:58:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
10:58:59 Only 11 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
10:58:59 HBMASTER: Trying to run another job!
10:58:59 job_callback for (1, 0, 1) finished
10:58:59 start sampling a new configuration.
10:58:59 done sampling a new configuration.
10:58:59 HBMASTER: schedule new run for iteration 1
10:58:59 HBMASTER: trying submitting job (1, 0, 2) to dispatcher
10:58:59 HBMASTER: submitting job (1, 0, 2) to dispatcher
10:58:59 DISPATCHER: trying to submit job (1, 0, 2)
10:58:59 DISPATCHER: trying to notify the job_runner thread.
10:58:59 HBMASTER: job (1, 0, 2) submitted to dispatcher
10:58:59 DISPATCHER: Trying to submit another job.
10:58:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
10:58:59 DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
10:58:59 DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
10:58:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
10:58:59 WORKER: start processing job (1, 0, 2)
10:58:59 WORKER: args: ()
10:58:59 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.013102836813704985, 'num_filters_1': 49, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.012046971156223862, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 60, 'num_filters_3': 33}, 'budget': 133.33333333333331, 'working_directory': '.'}
10:59:00 DISPATCHER: Starting worker discovery
10:59:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
10:59:00 DISPATCHER: Finished worker discovery
Exception in thread Thread-644:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

11:00:00 DISPATCHER: Starting worker discovery
11:00:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:00:00 DISPATCHER: Finished worker discovery
11:01:00 DISPATCHER: Starting worker discovery
11:01:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:01:00 DISPATCHER: Finished worker discovery
11:01:22 WORKER: done with job (1, 0, 2), trying to register it.
11:01:22 WORKER: registered result for job (1, 0, 2) with dispatcher
11:01:22 DISPATCHER: job (1, 0, 2) finished
11:01:22 DISPATCHER: register_result: lock acquired
11:01:22 DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
11:01:22 job_id: (1, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.013102836813704985, 'num_filters_1': 49, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.012046971156223862, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 60, 'num_filters_3': 33}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0025301385400018257, 'info': {'music-speech': 0.0025301385400018257, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.013102836813704985, 'num_filters_1': 49, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 46, 'weight_decay': 0.012046971156223862, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 60, 'num_filters_3': 33}"}}
exception: None

11:01:22 job_callback for (1, 0, 2) started
11:01:22 DISPATCHER: Trying to submit another job.
11:01:22 job_callback for (1, 0, 2) got condition
11:01:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:01:22 Only 12 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:01:22 HBMASTER: Trying to run another job!
11:01:22 job_callback for (1, 0, 2) finished
11:01:22 start sampling a new configuration.
11:01:22 done sampling a new configuration.
11:01:22 HBMASTER: schedule new run for iteration 1
11:01:22 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
11:01:22 HBMASTER: submitting job (1, 0, 3) to dispatcher
11:01:22 DISPATCHER: trying to submit job (1, 0, 3)
11:01:22 DISPATCHER: trying to notify the job_runner thread.
11:01:22 HBMASTER: job (1, 0, 3) submitted to dispatcher
11:01:22 DISPATCHER: Trying to submit another job.
11:01:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:01:22 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
11:01:22 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
11:01:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:01:22 WORKER: start processing job (1, 0, 3)
11:01:22 WORKER: args: ()
11:01:22 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.016307759328169295, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.011034583150462034, 'kernel_size_2': 7, 'num_filters_2': 40}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:02:00 DISPATCHER: Starting worker discovery
11:02:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:02:00 DISPATCHER: Finished worker discovery
Exception in thread Thread-645:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

11:03:00 DISPATCHER: Starting worker discovery
11:03:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:03:00 DISPATCHER: Finished worker discovery
11:03:44 WORKER: done with job (1, 0, 3), trying to register it.
11:03:44 WORKER: registered result for job (1, 0, 3) with dispatcher
11:03:44 DISPATCHER: job (1, 0, 3) finished
11:03:44 DISPATCHER: register_result: lock acquired
11:03:44 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
11:03:44 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.016307759328169295, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.011034583150462034, 'kernel_size_2': 7, 'num_filters_2': 40}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7198861320784521, 'info': {'music-speech': 0.7198861320784521, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.016307759328169295, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.011034583150462034, 'kernel_size_2': 7, 'num_filters_2': 40}"}}
exception: None

11:03:44 job_callback for (1, 0, 3) started
11:03:44 DISPATCHER: Trying to submit another job.
11:03:44 job_callback for (1, 0, 3) got condition
11:03:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:03:45 Only 13 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:03:45 HBMASTER: Trying to run another job!
11:03:45 job_callback for (1, 0, 3) finished
11:03:45 start sampling a new configuration.
11:03:45 done sampling a new configuration.
11:03:45 HBMASTER: schedule new run for iteration 1
11:03:45 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
11:03:45 HBMASTER: submitting job (1, 0, 4) to dispatcher
11:03:45 DISPATCHER: trying to submit job (1, 0, 4)
11:03:45 DISPATCHER: trying to notify the job_runner thread.
11:03:45 HBMASTER: job (1, 0, 4) submitted to dispatcher
11:03:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:03:45 DISPATCHER: Trying to submit another job.
11:03:45 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
11:03:45 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
11:03:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:03:45 WORKER: start processing job (1, 0, 4)
11:03:45 WORKER: args: ()
11:03:45 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.013233184443364318, 'num_filters_1': 42, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.013697935597424262, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 114, 'num_filters_3': 78}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:04:00 DISPATCHER: Starting worker discovery
11:04:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:04:00 DISPATCHER: Finished worker discovery
11:05:00 DISPATCHER: Starting worker discovery
11:05:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:05:00 DISPATCHER: Finished worker discovery
11:06:00 DISPATCHER: Starting worker discovery
11:06:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:06:00 DISPATCHER: Finished worker discovery
11:06:11 WORKER: done with job (1, 0, 4), trying to register it.
11:06:11 WORKER: registered result for job (1, 0, 4) with dispatcher
11:06:11 DISPATCHER: job (1, 0, 4) finished
11:06:11 DISPATCHER: register_result: lock acquired
11:06:11 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
11:06:11 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.013233184443364318, 'num_filters_1': 42, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.013697935597424262, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 114, 'num_filters_3': 78}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7636483224178738, 'info': {'music-speech': 0.7636483224178738, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.013233184443364318, 'num_filters_1': 42, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.013697935597424262, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 114, 'num_filters_3': 78}"}}
exception: None

11:06:11 job_callback for (1, 0, 4) started
11:06:11 DISPATCHER: Trying to submit another job.
11:06:11 job_callback for (1, 0, 4) got condition
11:06:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:06:11 Only 14 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:06:11 HBMASTER: Trying to run another job!
11:06:11 job_callback for (1, 0, 4) finished
11:06:11 start sampling a new configuration.
11:06:11 done sampling a new configuration.
11:06:11 HBMASTER: schedule new run for iteration 1
11:06:11 HBMASTER: trying submitting job (1, 0, 5) to dispatcher
11:06:11 HBMASTER: submitting job (1, 0, 5) to dispatcher
11:06:11 DISPATCHER: trying to submit job (1, 0, 5)
11:06:11 DISPATCHER: trying to notify the job_runner thread.
11:06:11 HBMASTER: job (1, 0, 5) submitted to dispatcher
11:06:11 DISPATCHER: Trying to submit another job.
11:06:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:06:11 DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
11:06:11 DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
11:06:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:06:11 WORKER: start processing job (1, 0, 5)
11:06:11 WORKER: args: ()
11:06:11 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0011864329096356065, 'num_filters_1': 62, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.019739755835530427, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 43, 'num_filters_3': 55}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:07:00 DISPATCHER: Starting worker discovery
11:07:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:07:00 DISPATCHER: Finished worker discovery
11:08:00 DISPATCHER: Starting worker discovery
11:08:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:08:00 DISPATCHER: Finished worker discovery
11:08:34 WORKER: done with job (1, 0, 5), trying to register it.
11:08:34 WORKER: registered result for job (1, 0, 5) with dispatcher
11:08:34 DISPATCHER: job (1, 0, 5) finished
11:08:34 DISPATCHER: register_result: lock acquired
11:08:34 DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
11:08:34 job_id: (1, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0011864329096356065, 'num_filters_1': 62, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.019739755835530427, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 43, 'num_filters_3': 55}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.713119825214318, 'info': {'music-speech': 0.713119825214318, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0011864329096356065, 'num_filters_1': 62, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.019739755835530427, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 43, 'num_filters_3': 55}"}}
exception: None

11:08:34 job_callback for (1, 0, 5) started
11:08:34 DISPATCHER: Trying to submit another job.
11:08:34 job_callback for (1, 0, 5) got condition
11:08:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:08:34 Only 15 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:08:34 HBMASTER: Trying to run another job!
11:08:34 job_callback for (1, 0, 5) finished
11:08:34 start sampling a new configuration.
11:08:34 done sampling a new configuration.
11:08:34 HBMASTER: schedule new run for iteration 1
11:08:34 HBMASTER: trying submitting job (1, 0, 6) to dispatcher
11:08:34 HBMASTER: submitting job (1, 0, 6) to dispatcher
11:08:34 DISPATCHER: trying to submit job (1, 0, 6)
11:08:34 DISPATCHER: trying to notify the job_runner thread.
11:08:34 HBMASTER: job (1, 0, 6) submitted to dispatcher
11:08:34 DISPATCHER: Trying to submit another job.
11:08:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:08:34 DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216
11:08:34 DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
11:08:34 WORKER: start processing job (1, 0, 6)
11:08:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:08:34 WORKER: args: ()
11:08:34 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.01194448909541433, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.09678439961268959, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 27, 'num_filters_3': 105, 'num_filters_4': 40}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-648:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

11:09:00 DISPATCHER: Starting worker discovery
11:09:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:09:00 DISPATCHER: Finished worker discovery
11:10:00 DISPATCHER: Starting worker discovery
11:10:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:10:00 DISPATCHER: Finished worker discovery
11:10:56 WORKER: done with job (1, 0, 6), trying to register it.
11:10:56 DISPATCHER: job (1, 0, 6) finished
11:10:56 WORKER: registered result for job (1, 0, 6) with dispatcher
11:10:56 DISPATCHER: register_result: lock acquired
11:10:56 DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
11:10:56 job_id: (1, 0, 6)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.01194448909541433, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.09678439961268959, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 27, 'num_filters_3': 105, 'num_filters_4': 40}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6352569652175866, 'info': {'music-speech': 0.6352569652175866, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.01194448909541433, 'num_filters_1': 37, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.09678439961268959, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 27, 'num_filters_3': 105, 'num_filters_4': 40}"}}
exception: None

11:10:56 job_callback for (1, 0, 6) started
11:10:56 DISPATCHER: Trying to submit another job.
11:10:56 job_callback for (1, 0, 6) got condition
11:10:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:10:56 Only 16 run(s) for budget 133.333333 available, need more than 18 -> can't build model!
11:10:56 HBMASTER: Trying to run another job!
11:10:56 job_callback for (1, 0, 6) finished
11:10:56 start sampling a new configuration.
11:10:56 done sampling a new configuration.
11:10:56 HBMASTER: schedule new run for iteration 1
11:10:56 HBMASTER: trying submitting job (1, 0, 7) to dispatcher
11:10:56 HBMASTER: submitting job (1, 0, 7) to dispatcher
11:10:56 DISPATCHER: trying to submit job (1, 0, 7)
11:10:56 DISPATCHER: trying to notify the job_runner thread.
11:10:56 HBMASTER: job (1, 0, 7) submitted to dispatcher
11:10:56 DISPATCHER: Trying to submit another job.
11:10:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:10:56 DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
11:10:56 DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
11:10:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:10:56 WORKER: start processing job (1, 0, 7)
11:10:56 WORKER: args: ()
11:10:56 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.010124623849133561, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.06101651473881543}, 'budget': 133.33333333333331, 'working_directory': '.'}
11:11:00 DISPATCHER: Starting worker discovery
11:11:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:11:00 DISPATCHER: Finished worker discovery
11:12:00 DISPATCHER: Starting worker discovery
11:12:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:12:00 DISPATCHER: Finished worker discovery
11:13:00 DISPATCHER: Starting worker discovery
11:13:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:13:00 DISPATCHER: Finished worker discovery
11:13:19 WORKER: done with job (1, 0, 7), trying to register it.
11:13:19 WORKER: registered result for job (1, 0, 7) with dispatcher
11:13:19 DISPATCHER: job (1, 0, 7) finished
11:13:19 DISPATCHER: register_result: lock acquired
11:13:19 DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
11:13:19 job_id: (1, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.010124623849133561, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.06101651473881543}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4132643737138826, 'info': {'music-speech': 0.4132643737138826, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.010124623849133561, 'num_filters_1': 22, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.06101651473881543}"}}
exception: None

11:13:19 job_callback for (1, 0, 7) started
11:13:19 job_callback for (1, 0, 7) got condition
11:13:19 DISPATCHER: Trying to submit another job.
11:13:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:13:19 HBMASTER: Trying to run another job!
11:13:19 job_callback for (1, 0, 7) finished
11:13:19 start sampling a new configuration.
11:13:19 done sampling a new configuration.
11:13:19 HBMASTER: schedule new run for iteration 1
11:13:19 HBMASTER: trying submitting job (1, 0, 8) to dispatcher
11:13:19 HBMASTER: submitting job (1, 0, 8) to dispatcher
11:13:19 DISPATCHER: trying to submit job (1, 0, 8)
11:13:19 DISPATCHER: trying to notify the job_runner thread.
11:13:19 HBMASTER: job (1, 0, 8) submitted to dispatcher
11:13:19 DISPATCHER: Trying to submit another job.
11:13:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:13:19 DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216
11:13:19 DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
11:13:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:13:19 WORKER: start processing job (1, 0, 8)
11:13:19 WORKER: args: ()
11:13:19 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.034206050278566026, 'num_filters_1': 30, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.17556525130690234, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 24, 'num_filters_3': 83, 'num_filters_4': 112, 'num_filters_5': 68}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-650:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

11:14:00 DISPATCHER: Starting worker discovery
11:14:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:14:00 DISPATCHER: Finished worker discovery
11:15:00 DISPATCHER: Starting worker discovery
11:15:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:15:00 DISPATCHER: Finished worker discovery
11:15:40 WORKER: done with job (1, 0, 8), trying to register it.
11:15:40 WORKER: registered result for job (1, 0, 8) with dispatcher
11:15:40 DISPATCHER: job (1, 0, 8) finished
11:15:40 DISPATCHER: register_result: lock acquired
11:15:40 DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
11:15:40 job_id: (1, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.034206050278566026, 'num_filters_1': 30, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.17556525130690234, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 24, 'num_filters_3': 83, 'num_filters_4': 112, 'num_filters_5': 68}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6803365845427015, 'info': {'music-speech': 0.6803365845427015, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.034206050278566026, 'num_filters_1': 30, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.17556525130690234, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 24, 'num_filters_3': 83, 'num_filters_4': 112, 'num_filters_5': 68}"}}
exception: None

11:15:40 job_callback for (1, 0, 8) started
11:15:40 DISPATCHER: Trying to submit another job.
11:15:40 job_callback for (1, 0, 8) got condition
11:15:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:15:40 HBMASTER: Trying to run another job!
11:15:40 job_callback for (1, 0, 8) finished
11:15:40 ITERATION: Advancing config (1, 0, 1) to next budget 400.000000
11:15:40 ITERATION: Advancing config (1, 0, 3) to next budget 400.000000
11:15:40 ITERATION: Advancing config (1, 0, 4) to next budget 400.000000
11:15:40 HBMASTER: schedule new run for iteration 1
11:15:40 HBMASTER: trying submitting job (1, 0, 1) to dispatcher
11:15:40 HBMASTER: submitting job (1, 0, 1) to dispatcher
11:15:40 DISPATCHER: trying to submit job (1, 0, 1)
11:15:40 DISPATCHER: trying to notify the job_runner thread.
11:15:40 HBMASTER: job (1, 0, 1) submitted to dispatcher
11:15:40 DISPATCHER: Trying to submit another job.
11:15:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:15:40 DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
11:15:40 DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
11:15:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:15:40 WORKER: start processing job (1, 0, 1)
11:15:40 WORKER: args: ()
11:15:40 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.06503467023333032, 'num_filters_1': 68, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 11, 'weight_decay': 0.010425224865114902}, 'budget': 400.0, 'working_directory': '.'}
11:16:00 DISPATCHER: Starting worker discovery
11:16:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:16:00 DISPATCHER: Finished worker discovery
11:17:00 DISPATCHER: Starting worker discovery
11:17:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:17:00 DISPATCHER: Finished worker discovery
11:18:00 DISPATCHER: Starting worker discovery
11:18:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:18:00 DISPATCHER: Finished worker discovery
11:19:00 DISPATCHER: Starting worker discovery
11:19:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:19:00 DISPATCHER: Finished worker discovery
11:20:00 DISPATCHER: Starting worker discovery
11:20:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:20:00 DISPATCHER: Finished worker discovery
11:21:00 DISPATCHER: Starting worker discovery
11:21:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:21:01 DISPATCHER: Finished worker discovery
11:22:01 DISPATCHER: Starting worker discovery
11:22:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:22:01 DISPATCHER: Finished worker discovery
11:22:30 WORKER: done with job (1, 0, 1), trying to register it.
11:22:30 DISPATCHER: job (1, 0, 1) finished
11:22:30 WORKER: registered result for job (1, 0, 1) with dispatcher
11:22:30 DISPATCHER: register_result: lock acquired
11:22:30 DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
11:22:30 job_id: (1, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.06503467023333032, 'num_filters_1': 68, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 11, 'weight_decay': 0.010425224865114902}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7127571039791306, 'info': {'music-speech': 0.7127571039791306, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.06503467023333032, 'num_filters_1': 68, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 11, 'weight_decay': 0.010425224865114902}"}}
exception: None

11:22:30 job_callback for (1, 0, 1) started
11:22:30 DISPATCHER: Trying to submit another job.
11:22:30 job_callback for (1, 0, 1) got condition
11:22:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:22:30 Only 4 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
11:22:30 HBMASTER: Trying to run another job!
11:22:30 job_callback for (1, 0, 1) finished
11:22:30 HBMASTER: schedule new run for iteration 1
11:22:30 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
11:22:30 HBMASTER: submitting job (1, 0, 3) to dispatcher
11:22:30 DISPATCHER: trying to submit job (1, 0, 3)
11:22:30 DISPATCHER: trying to notify the job_runner thread.
11:22:30 HBMASTER: job (1, 0, 3) submitted to dispatcher
11:22:30 DISPATCHER: Trying to submit another job.
11:22:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:22:30 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
11:22:30 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
11:22:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:22:30 WORKER: start processing job (1, 0, 3)
11:22:30 WORKER: args: ()
11:22:30 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.016307759328169295, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.011034583150462034, 'kernel_size_2': 7, 'num_filters_2': 40}, 'budget': 400.0, 'working_directory': '.'}
11:23:01 DISPATCHER: Starting worker discovery
11:23:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:23:01 DISPATCHER: Finished worker discovery
11:24:01 DISPATCHER: Starting worker discovery
11:24:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:24:01 DISPATCHER: Finished worker discovery
Exception in thread Thread-652:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

11:25:01 DISPATCHER: Starting worker discovery
11:25:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:25:01 DISPATCHER: Finished worker discovery
11:26:01 DISPATCHER: Starting worker discovery
11:26:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:26:01 DISPATCHER: Finished worker discovery
11:27:01 DISPATCHER: Starting worker discovery
11:27:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:27:01 DISPATCHER: Finished worker discovery
11:28:01 DISPATCHER: Starting worker discovery
11:28:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:28:01 DISPATCHER: Finished worker discovery
11:29:01 DISPATCHER: Starting worker discovery
11:29:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:29:01 DISPATCHER: Finished worker discovery
11:29:19 WORKER: done with job (1, 0, 3), trying to register it.
11:29:19 WORKER: registered result for job (1, 0, 3) with dispatcher
11:29:19 DISPATCHER: job (1, 0, 3) finished
11:29:19 DISPATCHER: register_result: lock acquired
11:29:19 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
11:29:19 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.016307759328169295, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.011034583150462034, 'kernel_size_2': 7, 'num_filters_2': 40}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7245183773942652, 'info': {'music-speech': 0.7245183773942652, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.016307759328169295, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.011034583150462034, 'kernel_size_2': 7, 'num_filters_2': 40}"}}
exception: None

11:29:19 job_callback for (1, 0, 3) started
11:29:19 DISPATCHER: Trying to submit another job.
11:29:19 job_callback for (1, 0, 3) got condition
11:29:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:29:19 Only 5 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
11:29:19 HBMASTER: Trying to run another job!
11:29:19 job_callback for (1, 0, 3) finished
11:29:19 HBMASTER: schedule new run for iteration 1
11:29:19 HBMASTER: trying submitting job (1, 0, 4) to dispatcher
11:29:19 HBMASTER: submitting job (1, 0, 4) to dispatcher
11:29:19 DISPATCHER: trying to submit job (1, 0, 4)
11:29:19 DISPATCHER: trying to notify the job_runner thread.
11:29:19 HBMASTER: job (1, 0, 4) submitted to dispatcher
11:29:19 DISPATCHER: Trying to submit another job.
11:29:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:29:19 DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
11:29:19 DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
11:29:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:29:19 WORKER: start processing job (1, 0, 4)
11:29:19 WORKER: args: ()
11:29:19 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.013233184443364318, 'num_filters_1': 42, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.013697935597424262, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 114, 'num_filters_3': 78}, 'budget': 400.0, 'working_directory': '.'}
11:30:01 DISPATCHER: Starting worker discovery
11:30:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:30:01 DISPATCHER: Finished worker discovery
11:31:01 DISPATCHER: Starting worker discovery
11:31:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:31:01 DISPATCHER: Finished worker discovery
11:32:01 DISPATCHER: Starting worker discovery
11:32:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:32:01 DISPATCHER: Finished worker discovery
11:33:01 DISPATCHER: Starting worker discovery
11:33:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:33:01 DISPATCHER: Finished worker discovery
11:34:01 DISPATCHER: Starting worker discovery
11:34:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:34:01 DISPATCHER: Finished worker discovery
11:35:01 DISPATCHER: Starting worker discovery
11:35:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:35:01 DISPATCHER: Finished worker discovery
11:36:01 DISPATCHER: Starting worker discovery
11:36:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:36:01 DISPATCHER: Finished worker discovery
11:36:13 WORKER: done with job (1, 0, 4), trying to register it.
11:36:13 WORKER: registered result for job (1, 0, 4) with dispatcher
11:36:13 DISPATCHER: job (1, 0, 4) finished
11:36:13 DISPATCHER: register_result: lock acquired
11:36:13 DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
11:36:13 job_id: (1, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.013233184443364318, 'num_filters_1': 42, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.013697935597424262, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 114, 'num_filters_3': 78}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7207089040862569, 'info': {'music-speech': 0.7207089040862569, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.013233184443364318, 'num_filters_1': 42, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 89, 'weight_decay': 0.013697935597424262, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 114, 'num_filters_3': 78}"}}
exception: None

11:36:13 job_callback for (1, 0, 4) started
11:36:13 DISPATCHER: Trying to submit another job.
11:36:13 job_callback for (1, 0, 4) got condition
11:36:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:36:13 Only 6 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
11:36:13 HBMASTER: Trying to run another job!
11:36:13 job_callback for (1, 0, 4) finished
11:36:13 ITERATION: Advancing config (1, 0, 3) to next budget 1200.000000
11:36:13 HBMASTER: schedule new run for iteration 1
11:36:13 HBMASTER: trying submitting job (1, 0, 3) to dispatcher
11:36:13 HBMASTER: submitting job (1, 0, 3) to dispatcher
11:36:13 DISPATCHER: trying to submit job (1, 0, 3)
11:36:13 DISPATCHER: trying to notify the job_runner thread.
11:36:13 HBMASTER: job (1, 0, 3) submitted to dispatcher
11:36:13 DISPATCHER: Trying to submit another job.
11:36:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:36:13 DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
11:36:13 DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
11:36:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:36:13 WORKER: start processing job (1, 0, 3)
11:36:13 WORKER: args: ()
11:36:13 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.016307759328169295, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.011034583150462034, 'kernel_size_2': 7, 'num_filters_2': 40}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-654:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

11:37:01 DISPATCHER: Starting worker discovery
11:37:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:37:01 DISPATCHER: Finished worker discovery
11:38:01 DISPATCHER: Starting worker discovery
11:38:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:38:01 DISPATCHER: Finished worker discovery
11:39:01 DISPATCHER: Starting worker discovery
11:39:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:39:01 DISPATCHER: Finished worker discovery
11:40:01 DISPATCHER: Starting worker discovery
11:40:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:40:01 DISPATCHER: Finished worker discovery
11:41:01 DISPATCHER: Starting worker discovery
11:41:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:41:01 DISPATCHER: Finished worker discovery
11:42:01 DISPATCHER: Starting worker discovery
11:42:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:42:01 DISPATCHER: Finished worker discovery
11:43:01 DISPATCHER: Starting worker discovery
11:43:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:43:01 DISPATCHER: Finished worker discovery
11:44:01 DISPATCHER: Starting worker discovery
11:44:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:44:01 DISPATCHER: Finished worker discovery
11:45:01 DISPATCHER: Starting worker discovery
11:45:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:45:01 DISPATCHER: Finished worker discovery
11:46:01 DISPATCHER: Starting worker discovery
11:46:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:46:01 DISPATCHER: Finished worker discovery
11:47:01 DISPATCHER: Starting worker discovery
11:47:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:47:01 DISPATCHER: Finished worker discovery
11:48:01 DISPATCHER: Starting worker discovery
11:48:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:48:01 DISPATCHER: Finished worker discovery
11:49:01 DISPATCHER: Starting worker discovery
11:49:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:49:01 DISPATCHER: Finished worker discovery
11:50:01 DISPATCHER: Starting worker discovery
11:50:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:50:01 DISPATCHER: Finished worker discovery
11:51:01 DISPATCHER: Starting worker discovery
11:51:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:51:01 DISPATCHER: Finished worker discovery
11:52:01 DISPATCHER: Starting worker discovery
11:52:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:52:01 DISPATCHER: Finished worker discovery
11:53:01 DISPATCHER: Starting worker discovery
11:53:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:53:01 DISPATCHER: Finished worker discovery
11:54:01 DISPATCHER: Starting worker discovery
11:54:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:54:01 DISPATCHER: Finished worker discovery
11:55:01 DISPATCHER: Starting worker discovery
11:55:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:55:01 DISPATCHER: Finished worker discovery
11:56:01 DISPATCHER: Starting worker discovery
11:56:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:56:01 DISPATCHER: Finished worker discovery
11:56:21 WORKER: done with job (1, 0, 3), trying to register it.
11:56:21 WORKER: registered result for job (1, 0, 3) with dispatcher
11:56:21 DISPATCHER: job (1, 0, 3) finished
11:56:21 DISPATCHER: register_result: lock acquired
11:56:21 DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
11:56:21 job_id: (1, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.016307759328169295, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.011034583150462034, 'kernel_size_2': 7, 'num_filters_2': 40}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5908580669857693, 'info': {'music-speech': 0.5908580669857693, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.016307759328169295, 'num_filters_1': 23, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.011034583150462034, 'kernel_size_2': 7, 'num_filters_2': 40}"}}
exception: None

11:56:21 job_callback for (1, 0, 3) started
11:56:21 DISPATCHER: Trying to submit another job.
11:56:21 job_callback for (1, 0, 3) got condition
11:56:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
11:56:21 Only 2 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
11:56:21 HBMASTER: Trying to run another job!
11:56:21 job_callback for (1, 0, 3) finished
11:56:21 start sampling a new configuration.
11:56:21 done sampling a new configuration.
11:56:22 HBMASTER: schedule new run for iteration 2
11:56:22 HBMASTER: trying submitting job (2, 0, 0) to dispatcher
11:56:22 HBMASTER: submitting job (2, 0, 0) to dispatcher
11:56:22 DISPATCHER: trying to submit job (2, 0, 0)
11:56:22 DISPATCHER: trying to notify the job_runner thread.
11:56:22 HBMASTER: job (2, 0, 0) submitted to dispatcher
11:56:22 DISPATCHER: Trying to submit another job.
11:56:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
11:56:22 DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
11:56:22 DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
11:56:22 WORKER: start processing job (2, 0, 0)
11:56:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
11:56:22 WORKER: args: ()
11:56:22 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0018223346998569327, 'num_filters_1': 18, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.033538413483337776, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 29, 'num_filters_3': 16}, 'budget': 400.0, 'working_directory': '.'}
11:57:01 DISPATCHER: Starting worker discovery
11:57:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:57:01 DISPATCHER: Finished worker discovery
11:58:01 DISPATCHER: Starting worker discovery
11:58:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:58:01 DISPATCHER: Finished worker discovery
11:59:01 DISPATCHER: Starting worker discovery
11:59:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
11:59:01 DISPATCHER: Finished worker discovery
12:00:01 DISPATCHER: Starting worker discovery
12:00:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:00:01 DISPATCHER: Finished worker discovery
12:01:01 DISPATCHER: Starting worker discovery
12:01:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:01:01 DISPATCHER: Finished worker discovery
12:02:01 DISPATCHER: Starting worker discovery
12:02:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:02:01 DISPATCHER: Finished worker discovery
12:03:01 DISPATCHER: Starting worker discovery
12:03:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:03:01 DISPATCHER: Finished worker discovery
12:03:11 WORKER: done with job (2, 0, 0), trying to register it.
12:03:11 WORKER: registered result for job (2, 0, 0) with dispatcher
12:03:11 DISPATCHER: job (2, 0, 0) finished
12:03:11 DISPATCHER: register_result: lock acquired
12:03:11 DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
12:03:11 job_id: (2, 0, 0)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0018223346998569327, 'num_filters_1': 18, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.033538413483337776, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 29, 'num_filters_3': 16}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6779929425860216, 'info': {'music-speech': 0.6779929425860216, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0018223346998569327, 'num_filters_1': 18, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 72, 'weight_decay': 0.033538413483337776, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 29, 'num_filters_3': 16}"}}
exception: None

12:03:11 job_callback for (2, 0, 0) started
12:03:11 DISPATCHER: Trying to submit another job.
12:03:11 job_callback for (2, 0, 0) got condition
12:03:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:03:11 Only 7 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
12:03:11 HBMASTER: Trying to run another job!
12:03:11 job_callback for (2, 0, 0) finished
12:03:11 start sampling a new configuration.
12:03:11 done sampling a new configuration.
12:03:11 HBMASTER: schedule new run for iteration 2
12:03:11 HBMASTER: trying submitting job (2, 0, 1) to dispatcher
12:03:11 HBMASTER: submitting job (2, 0, 1) to dispatcher
12:03:11 DISPATCHER: trying to submit job (2, 0, 1)
12:03:11 DISPATCHER: trying to notify the job_runner thread.
12:03:11 HBMASTER: job (2, 0, 1) submitted to dispatcher
12:03:11 DISPATCHER: Trying to submit another job.
12:03:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:03:11 DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
12:03:11 DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
12:03:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:03:11 WORKER: start processing job (2, 0, 1)
12:03:11 WORKER: args: ()
12:03:11 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.09410957604047573, 'num_filters_1': 70, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.016670810706984496}, 'budget': 400.0, 'working_directory': '.'}
12:04:01 DISPATCHER: Starting worker discovery
12:04:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:04:01 DISPATCHER: Finished worker discovery
12:05:01 DISPATCHER: Starting worker discovery
12:05:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:05:01 DISPATCHER: Finished worker discovery
12:06:01 DISPATCHER: Starting worker discovery
12:06:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:06:01 DISPATCHER: Finished worker discovery
12:07:01 DISPATCHER: Starting worker discovery
12:07:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:07:01 DISPATCHER: Finished worker discovery
12:08:01 DISPATCHER: Starting worker discovery
12:08:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:08:01 DISPATCHER: Finished worker discovery
12:09:01 DISPATCHER: Starting worker discovery
12:09:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:09:01 DISPATCHER: Finished worker discovery
12:10:01 DISPATCHER: Starting worker discovery
12:10:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:10:01 DISPATCHER: Finished worker discovery
12:10:03 WORKER: done with job (2, 0, 1), trying to register it.
12:10:03 WORKER: registered result for job (2, 0, 1) with dispatcher
12:10:03 DISPATCHER: job (2, 0, 1) finished
12:10:03 DISPATCHER: register_result: lock acquired
12:10:03 DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
12:10:03 job_id: (2, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.09410957604047573, 'num_filters_1': 70, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.016670810706984496}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5313304646251831, 'info': {'music-speech': 0.5313304646251831, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.09410957604047573, 'num_filters_1': 70, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 93, 'weight_decay': 0.016670810706984496}"}}
exception: None

12:10:03 job_callback for (2, 0, 1) started
12:10:03 DISPATCHER: Trying to submit another job.
12:10:03 job_callback for (2, 0, 1) got condition
12:10:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:10:03 Only 8 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
12:10:03 HBMASTER: Trying to run another job!
12:10:03 job_callback for (2, 0, 1) finished
12:10:03 start sampling a new configuration.
12:10:03 done sampling a new configuration.
12:10:03 HBMASTER: schedule new run for iteration 2
12:10:03 HBMASTER: trying submitting job (2, 0, 2) to dispatcher
12:10:03 HBMASTER: submitting job (2, 0, 2) to dispatcher
12:10:03 DISPATCHER: trying to submit job (2, 0, 2)
12:10:03 DISPATCHER: trying to notify the job_runner thread.
12:10:03 HBMASTER: job (2, 0, 2) submitted to dispatcher
12:10:03 DISPATCHER: Trying to submit another job.
12:10:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:10:03 DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
12:10:03 DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
12:10:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:10:03 WORKER: start processing job (2, 0, 2)
12:10:03 WORKER: args: ()
12:10:03 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.06578280857991536, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.06578130802384642, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 89, 'num_filters_3': 127, 'num_filters_4': 65}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-657:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

12:11:01 DISPATCHER: Starting worker discovery
12:11:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:11:01 DISPATCHER: Finished worker discovery
12:12:01 DISPATCHER: Starting worker discovery
12:12:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:12:01 DISPATCHER: Finished worker discovery
12:13:01 DISPATCHER: Starting worker discovery
12:13:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:13:01 DISPATCHER: Finished worker discovery
12:14:01 DISPATCHER: Starting worker discovery
12:14:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:14:01 DISPATCHER: Finished worker discovery
12:15:01 DISPATCHER: Starting worker discovery
12:15:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:15:01 DISPATCHER: Finished worker discovery
12:16:01 DISPATCHER: Starting worker discovery
12:16:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:16:01 DISPATCHER: Finished worker discovery
12:16:51 WORKER: done with job (2, 0, 2), trying to register it.
12:16:51 WORKER: registered result for job (2, 0, 2) with dispatcher
12:16:51 DISPATCHER: job (2, 0, 2) finished
12:16:51 DISPATCHER: register_result: lock acquired
12:16:51 DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
12:16:51 job_id: (2, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.06578280857991536, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.06578130802384642, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 89, 'num_filters_3': 127, 'num_filters_4': 65}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5904832896771832, 'info': {'music-speech': 0.5904832896771832, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.06578280857991536, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 25, 'weight_decay': 0.06578130802384642, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 89, 'num_filters_3': 127, 'num_filters_4': 65}"}}
exception: None

12:16:51 job_callback for (2, 0, 2) started
12:16:51 DISPATCHER: Trying to submit another job.
12:16:51 job_callback for (2, 0, 2) got condition
12:16:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:16:51 Only 9 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
12:16:51 HBMASTER: Trying to run another job!
12:16:51 job_callback for (2, 0, 2) finished
12:16:51 start sampling a new configuration.
12:16:51 done sampling a new configuration.
12:16:51 HBMASTER: schedule new run for iteration 2
12:16:51 HBMASTER: trying submitting job (2, 0, 3) to dispatcher
12:16:51 HBMASTER: submitting job (2, 0, 3) to dispatcher
12:16:51 DISPATCHER: trying to submit job (2, 0, 3)
12:16:51 DISPATCHER: trying to notify the job_runner thread.
12:16:51 HBMASTER: job (2, 0, 3) submitted to dispatcher
12:16:51 DISPATCHER: Trying to submit another job.
12:16:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:16:51 DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
12:16:51 DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
12:16:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:16:51 WORKER: start processing job (2, 0, 3)
12:16:51 WORKER: args: ()
12:16:51 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0014012354016534536, 'num_filters_1': 63, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 68, 'weight_decay': 0.09162695563174747, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 18, 'num_filters_3': 28, 'num_filters_4': 115, 'num_filters_5': 34}, 'budget': 400.0, 'working_directory': '.'}
12:17:01 DISPATCHER: Starting worker discovery
12:17:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:17:01 DISPATCHER: Finished worker discovery
12:18:01 DISPATCHER: Starting worker discovery
12:18:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:18:01 DISPATCHER: Finished worker discovery
12:19:01 DISPATCHER: Starting worker discovery
12:19:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:19:01 DISPATCHER: Finished worker discovery
12:20:01 DISPATCHER: Starting worker discovery
12:20:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:20:01 DISPATCHER: Finished worker discovery
12:21:01 DISPATCHER: Starting worker discovery
12:21:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:21:01 DISPATCHER: Finished worker discovery
12:22:01 DISPATCHER: Starting worker discovery
12:22:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:22:01 DISPATCHER: Finished worker discovery
12:23:01 DISPATCHER: Starting worker discovery
12:23:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:23:01 DISPATCHER: Finished worker discovery
12:23:41 WORKER: done with job (2, 0, 3), trying to register it.
12:23:41 WORKER: registered result for job (2, 0, 3) with dispatcher
12:23:41 DISPATCHER: job (2, 0, 3) finished
12:23:41 DISPATCHER: register_result: lock acquired
12:23:41 DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
12:23:41 job_id: (2, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0014012354016534536, 'num_filters_1': 63, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 68, 'weight_decay': 0.09162695563174747, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 18, 'num_filters_3': 28, 'num_filters_4': 115, 'num_filters_5': 34}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6268357090144523, 'info': {'music-speech': 0.6268357090144523, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0014012354016534536, 'num_filters_1': 63, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 68, 'weight_decay': 0.09162695563174747, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 18, 'num_filters_3': 28, 'num_filters_4': 115, 'num_filters_5': 34}"}}
exception: None

12:23:41 job_callback for (2, 0, 3) started
12:23:41 DISPATCHER: Trying to submit another job.
12:23:41 job_callback for (2, 0, 3) got condition
12:23:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:23:41 Only 10 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
12:23:41 HBMASTER: Trying to run another job!
12:23:41 job_callback for (2, 0, 3) finished
12:23:41 start sampling a new configuration.
12:23:41 done sampling a new configuration.
12:23:41 HBMASTER: schedule new run for iteration 2
12:23:41 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
12:23:41 HBMASTER: submitting job (2, 0, 4) to dispatcher
12:23:41 DISPATCHER: trying to submit job (2, 0, 4)
12:23:41 DISPATCHER: trying to notify the job_runner thread.
12:23:41 HBMASTER: job (2, 0, 4) submitted to dispatcher
12:23:41 DISPATCHER: Trying to submit another job.
12:23:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:23:41 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
12:23:41 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
12:23:41 WORKER: start processing job (2, 0, 4)
12:23:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:23:41 WORKER: args: ()
12:23:41 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.003097764547908943, 'num_filters_1': 70, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.08448525556163518, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 49, 'num_filters_3': 44, 'num_filters_4': 21, 'num_filters_5': 88}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-659:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

12:24:01 DISPATCHER: Starting worker discovery
12:24:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:24:01 DISPATCHER: Finished worker discovery
12:25:01 DISPATCHER: Starting worker discovery
12:25:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:25:01 DISPATCHER: Finished worker discovery
12:26:01 DISPATCHER: Starting worker discovery
12:26:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:26:01 DISPATCHER: Finished worker discovery
12:27:01 DISPATCHER: Starting worker discovery
12:27:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:27:01 DISPATCHER: Finished worker discovery
12:28:01 DISPATCHER: Starting worker discovery
12:28:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:28:01 DISPATCHER: Finished worker discovery
12:29:01 DISPATCHER: Starting worker discovery
12:29:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:29:01 DISPATCHER: Finished worker discovery
12:30:01 DISPATCHER: Starting worker discovery
12:30:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:30:01 DISPATCHER: Finished worker discovery
12:30:30 WORKER: done with job (2, 0, 4), trying to register it.
12:30:30 WORKER: registered result for job (2, 0, 4) with dispatcher
12:30:30 DISPATCHER: job (2, 0, 4) finished
12:30:30 DISPATCHER: register_result: lock acquired
12:30:30 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
12:30:30 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.003097764547908943, 'num_filters_1': 70, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.08448525556163518, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 49, 'num_filters_3': 44, 'num_filters_4': 21, 'num_filters_5': 88}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7744965286808155, 'info': {'music-speech': 0.7744965286808155, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.003097764547908943, 'num_filters_1': 70, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.08448525556163518, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 49, 'num_filters_3': 44, 'num_filters_4': 21, 'num_filters_5': 88}"}}
exception: None

12:30:30 job_callback for (2, 0, 4) started
12:30:30 DISPATCHER: Trying to submit another job.
12:30:30 job_callback for (2, 0, 4) got condition
12:30:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:30:30 Only 11 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
12:30:30 HBMASTER: Trying to run another job!
12:30:30 job_callback for (2, 0, 4) finished
12:30:30 start sampling a new configuration.
12:30:30 done sampling a new configuration.
12:30:30 HBMASTER: schedule new run for iteration 2
12:30:30 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
12:30:30 HBMASTER: submitting job (2, 0, 5) to dispatcher
12:30:30 DISPATCHER: trying to submit job (2, 0, 5)
12:30:30 DISPATCHER: trying to notify the job_runner thread.
12:30:30 HBMASTER: job (2, 0, 5) submitted to dispatcher
12:30:30 DISPATCHER: Trying to submit another job.
12:30:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:30:30 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
12:30:30 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
12:30:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:30:30 WORKER: start processing job (2, 0, 5)
12:30:30 WORKER: args: ()
12:30:30 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0023392990954256114, 'num_filters_1': 106, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.010171228463415886, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 21, 'num_filters_3': 34}, 'budget': 400.0, 'working_directory': '.'}
12:31:01 DISPATCHER: Starting worker discovery
12:31:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:31:01 DISPATCHER: Finished worker discovery
12:32:01 DISPATCHER: Starting worker discovery
12:32:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:32:01 DISPATCHER: Finished worker discovery
12:33:01 DISPATCHER: Starting worker discovery
12:33:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:33:01 DISPATCHER: Finished worker discovery
12:34:01 DISPATCHER: Starting worker discovery
12:34:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:34:01 DISPATCHER: Finished worker discovery
12:35:01 DISPATCHER: Starting worker discovery
12:35:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:35:01 DISPATCHER: Finished worker discovery
12:36:01 DISPATCHER: Starting worker discovery
12:36:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:36:01 DISPATCHER: Finished worker discovery
12:37:01 DISPATCHER: Starting worker discovery
12:37:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:37:01 DISPATCHER: Finished worker discovery
12:37:19 WORKER: done with job (2, 0, 5), trying to register it.
12:37:19 WORKER: registered result for job (2, 0, 5) with dispatcher
12:37:19 DISPATCHER: job (2, 0, 5) finished
12:37:19 DISPATCHER: register_result: lock acquired
12:37:19 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
12:37:19 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0023392990954256114, 'num_filters_1': 106, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.010171228463415886, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 21, 'num_filters_3': 34}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7078424545506675, 'info': {'music-speech': 0.7078424545506675, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0023392990954256114, 'num_filters_1': 106, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.010171228463415886, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 21, 'num_filters_3': 34}"}}
exception: None

12:37:19 job_callback for (2, 0, 5) started
12:37:19 job_callback for (2, 0, 5) got condition
12:37:19 DISPATCHER: Trying to submit another job.
12:37:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:37:19 Only 12 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
12:37:19 HBMASTER: Trying to run another job!
12:37:19 job_callback for (2, 0, 5) finished
12:37:19 ITERATION: Advancing config (2, 0, 4) to next budget 1200.000000
12:37:19 ITERATION: Advancing config (2, 0, 5) to next budget 1200.000000
12:37:19 HBMASTER: schedule new run for iteration 2
12:37:19 HBMASTER: trying submitting job (2, 0, 4) to dispatcher
12:37:19 HBMASTER: submitting job (2, 0, 4) to dispatcher
12:37:19 DISPATCHER: trying to submit job (2, 0, 4)
12:37:19 DISPATCHER: trying to notify the job_runner thread.
12:37:19 HBMASTER: job (2, 0, 4) submitted to dispatcher
12:37:19 DISPATCHER: Trying to submit another job.
12:37:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:37:19 DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
12:37:19 DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
12:37:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:37:19 WORKER: start processing job (2, 0, 4)
12:37:19 WORKER: args: ()
12:37:19 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.003097764547908943, 'num_filters_1': 70, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.08448525556163518, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 49, 'num_filters_3': 44, 'num_filters_4': 21, 'num_filters_5': 88}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-661:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

12:38:01 DISPATCHER: Starting worker discovery
12:38:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:38:01 DISPATCHER: Finished worker discovery
12:39:01 DISPATCHER: Starting worker discovery
12:39:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:39:01 DISPATCHER: Finished worker discovery
12:40:01 DISPATCHER: Starting worker discovery
12:40:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:40:01 DISPATCHER: Finished worker discovery
12:41:01 DISPATCHER: Starting worker discovery
12:41:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:41:01 DISPATCHER: Finished worker discovery
12:42:01 DISPATCHER: Starting worker discovery
12:42:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:42:01 DISPATCHER: Finished worker discovery
12:43:01 DISPATCHER: Starting worker discovery
12:43:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:43:01 DISPATCHER: Finished worker discovery
12:44:01 DISPATCHER: Starting worker discovery
12:44:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:44:01 DISPATCHER: Finished worker discovery
12:45:01 DISPATCHER: Starting worker discovery
12:45:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:45:01 DISPATCHER: Finished worker discovery
12:46:01 DISPATCHER: Starting worker discovery
12:46:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:46:01 DISPATCHER: Finished worker discovery
12:47:01 DISPATCHER: Starting worker discovery
12:47:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:47:01 DISPATCHER: Finished worker discovery
12:48:01 DISPATCHER: Starting worker discovery
12:48:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:48:01 DISPATCHER: Finished worker discovery
12:49:01 DISPATCHER: Starting worker discovery
12:49:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:49:01 DISPATCHER: Finished worker discovery
12:50:01 DISPATCHER: Starting worker discovery
12:50:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:50:01 DISPATCHER: Finished worker discovery
12:51:01 DISPATCHER: Starting worker discovery
12:51:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:51:01 DISPATCHER: Finished worker discovery
12:52:01 DISPATCHER: Starting worker discovery
12:52:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:52:01 DISPATCHER: Finished worker discovery
12:53:01 DISPATCHER: Starting worker discovery
12:53:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:53:01 DISPATCHER: Finished worker discovery
12:54:01 DISPATCHER: Starting worker discovery
12:54:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:54:01 DISPATCHER: Finished worker discovery
12:55:01 DISPATCHER: Starting worker discovery
12:55:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:55:01 DISPATCHER: Finished worker discovery
12:56:01 DISPATCHER: Starting worker discovery
12:56:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:56:01 DISPATCHER: Finished worker discovery
12:57:01 DISPATCHER: Starting worker discovery
12:57:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:57:01 DISPATCHER: Finished worker discovery
12:57:28 WORKER: done with job (2, 0, 4), trying to register it.
12:57:28 WORKER: registered result for job (2, 0, 4) with dispatcher
12:57:28 DISPATCHER: job (2, 0, 4) finished
12:57:28 DISPATCHER: register_result: lock acquired
12:57:28 DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
12:57:28 job_id: (2, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.003097764547908943, 'num_filters_1': 70, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.08448525556163518, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 49, 'num_filters_3': 44, 'num_filters_4': 21, 'num_filters_5': 88}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5324715457902245, 'info': {'music-speech': 0.5324715457902245, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.003097764547908943, 'num_filters_1': 70, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.08448525556163518, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 49, 'num_filters_3': 44, 'num_filters_4': 21, 'num_filters_5': 88}"}}
exception: None

12:57:28 job_callback for (2, 0, 4) started
12:57:28 DISPATCHER: Trying to submit another job.
12:57:28 job_callback for (2, 0, 4) got condition
12:57:28 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:57:28 Only 3 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
12:57:28 HBMASTER: Trying to run another job!
12:57:28 job_callback for (2, 0, 4) finished
12:57:28 HBMASTER: schedule new run for iteration 2
12:57:28 HBMASTER: trying submitting job (2, 0, 5) to dispatcher
12:57:28 HBMASTER: submitting job (2, 0, 5) to dispatcher
12:57:28 DISPATCHER: trying to submit job (2, 0, 5)
12:57:28 DISPATCHER: trying to notify the job_runner thread.
12:57:28 HBMASTER: job (2, 0, 5) submitted to dispatcher
12:57:28 DISPATCHER: Trying to submit another job.
12:57:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:57:28 DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
12:57:28 DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
12:57:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:57:28 WORKER: start processing job (2, 0, 5)
12:57:28 WORKER: args: ()
12:57:28 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0023392990954256114, 'num_filters_1': 106, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.010171228463415886, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 21, 'num_filters_3': 34}, 'budget': 1200.0, 'working_directory': '.'}
12:58:01 DISPATCHER: Starting worker discovery
12:58:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:58:02 DISPATCHER: Finished worker discovery
12:59:02 DISPATCHER: Starting worker discovery
12:59:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:59:02 DISPATCHER: Finished worker discovery
13:00:02 DISPATCHER: Starting worker discovery
13:00:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:00:02 DISPATCHER: Finished worker discovery
13:01:02 DISPATCHER: Starting worker discovery
13:01:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:01:02 DISPATCHER: Finished worker discovery
13:02:02 DISPATCHER: Starting worker discovery
13:02:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:02:02 DISPATCHER: Finished worker discovery
13:03:02 DISPATCHER: Starting worker discovery
13:03:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:03:02 DISPATCHER: Finished worker discovery
13:04:02 DISPATCHER: Starting worker discovery
13:04:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:04:02 DISPATCHER: Finished worker discovery
13:05:02 DISPATCHER: Starting worker discovery
13:05:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:05:02 DISPATCHER: Finished worker discovery
13:06:02 DISPATCHER: Starting worker discovery
13:06:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:06:02 DISPATCHER: Finished worker discovery
13:07:02 DISPATCHER: Starting worker discovery
13:07:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:07:02 DISPATCHER: Finished worker discovery
13:08:02 DISPATCHER: Starting worker discovery
13:08:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:08:02 DISPATCHER: Finished worker discovery
13:09:02 DISPATCHER: Starting worker discovery
13:09:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:09:02 DISPATCHER: Finished worker discovery
13:10:02 DISPATCHER: Starting worker discovery
13:10:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:10:02 DISPATCHER: Finished worker discovery
13:11:02 DISPATCHER: Starting worker discovery
13:11:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:11:02 DISPATCHER: Finished worker discovery
13:12:02 DISPATCHER: Starting worker discovery
13:12:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:12:02 DISPATCHER: Finished worker discovery
13:13:02 DISPATCHER: Starting worker discovery
13:13:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:13:02 DISPATCHER: Finished worker discovery
13:14:02 DISPATCHER: Starting worker discovery
13:14:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:14:02 DISPATCHER: Finished worker discovery
13:15:02 DISPATCHER: Starting worker discovery
13:15:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:15:02 DISPATCHER: Finished worker discovery
13:16:02 DISPATCHER: Starting worker discovery
13:16:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:16:02 DISPATCHER: Finished worker discovery
13:17:02 DISPATCHER: Starting worker discovery
13:17:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:17:02 DISPATCHER: Finished worker discovery
13:17:39 WORKER: done with job (2, 0, 5), trying to register it.
13:17:39 WORKER: registered result for job (2, 0, 5) with dispatcher
13:17:39 DISPATCHER: job (2, 0, 5) finished
13:17:39 DISPATCHER: register_result: lock acquired
13:17:39 DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:17:39 job_id: (2, 0, 5)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0023392990954256114, 'num_filters_1': 106, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.010171228463415886, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 21, 'num_filters_3': 34}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.6573423575638718, 'info': {'music-speech': 0.6573423575638718, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0023392990954256114, 'num_filters_1': 106, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 35, 'weight_decay': 0.010171228463415886, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 21, 'num_filters_3': 34}"}}
exception: None

13:17:39 job_callback for (2, 0, 5) started
13:17:39 DISPATCHER: Trying to submit another job.
13:17:39 job_callback for (2, 0, 5) got condition
13:17:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:17:39 Only 4 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
13:17:39 HBMASTER: Trying to run another job!
13:17:39 job_callback for (2, 0, 5) finished
13:17:39 start sampling a new configuration.
13:17:39 done sampling a new configuration.
13:17:39 HBMASTER: schedule new run for iteration 3
13:17:39 HBMASTER: trying submitting job (3, 0, 0) to dispatcher
13:17:39 HBMASTER: submitting job (3, 0, 0) to dispatcher
13:17:39 DISPATCHER: trying to submit job (3, 0, 0)
13:17:39 DISPATCHER: trying to notify the job_runner thread.
13:17:39 HBMASTER: job (3, 0, 0) submitted to dispatcher
13:17:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:17:39 DISPATCHER: Trying to submit another job.
13:17:39 DISPATCHER: starting job (3, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:17:39 DISPATCHER: job (3, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:17:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:17:39 WORKER: start processing job (3, 0, 0)
13:17:39 WORKER: args: ()
13:17:39 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.001370702317733387, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.0780612631511112, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 25, 'num_filters_3': 19}, 'budget': 1200.0, 'working_directory': '.'}
13:18:02 DISPATCHER: Starting worker discovery
13:18:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:18:02 DISPATCHER: Finished worker discovery
13:19:02 DISPATCHER: Starting worker discovery
13:19:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:19:02 DISPATCHER: Finished worker discovery
13:20:02 DISPATCHER: Starting worker discovery
13:20:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:20:02 DISPATCHER: Finished worker discovery
13:21:02 DISPATCHER: Starting worker discovery
13:21:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:21:02 DISPATCHER: Finished worker discovery
13:22:02 DISPATCHER: Starting worker discovery
13:22:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:22:02 DISPATCHER: Finished worker discovery
13:23:02 DISPATCHER: Starting worker discovery
13:23:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:23:02 DISPATCHER: Finished worker discovery
13:24:02 DISPATCHER: Starting worker discovery
13:24:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:24:02 DISPATCHER: Finished worker discovery
13:25:02 DISPATCHER: Starting worker discovery
13:25:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:25:02 DISPATCHER: Finished worker discovery
13:26:02 DISPATCHER: Starting worker discovery
13:26:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:26:02 DISPATCHER: Finished worker discovery
13:27:02 DISPATCHER: Starting worker discovery
13:27:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:27:02 DISPATCHER: Finished worker discovery
13:28:02 DISPATCHER: Starting worker discovery
13:28:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:28:02 DISPATCHER: Finished worker discovery
13:29:02 DISPATCHER: Starting worker discovery
13:29:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:29:02 DISPATCHER: Finished worker discovery
13:30:02 DISPATCHER: Starting worker discovery
13:30:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:30:02 DISPATCHER: Finished worker discovery
13:31:02 DISPATCHER: Starting worker discovery
13:31:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:31:02 DISPATCHER: Finished worker discovery
13:32:02 DISPATCHER: Starting worker discovery
13:32:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:32:02 DISPATCHER: Finished worker discovery
13:33:02 DISPATCHER: Starting worker discovery
13:33:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:33:02 DISPATCHER: Finished worker discovery
13:34:02 DISPATCHER: Starting worker discovery
13:34:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:34:02 DISPATCHER: Finished worker discovery
13:35:02 DISPATCHER: Starting worker discovery
13:35:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:35:02 DISPATCHER: Finished worker discovery
13:36:02 DISPATCHER: Starting worker discovery
13:36:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:36:02 DISPATCHER: Finished worker discovery
13:37:02 DISPATCHER: Starting worker discovery
13:37:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:37:02 DISPATCHER: Finished worker discovery
13:37:48 WORKER: done with job (3, 0, 0), trying to register it.
13:37:48 WORKER: registered result for job (3, 0, 0) with dispatcher
13:37:48 DISPATCHER: job (3, 0, 0) finished
13:37:48 DISPATCHER: register_result: lock acquired
13:37:48 DISPATCHER: job (3, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:37:48 job_id: (3, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.001370702317733387, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.0780612631511112, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 25, 'num_filters_3': 19}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.5323412309955408, 'info': {'music-speech': 0.5323412309955408, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.001370702317733387, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 39, 'weight_decay': 0.0780612631511112, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 25, 'num_filters_3': 19}"}}
exception: None

13:37:48 job_callback for (3, 0, 0) started
13:37:48 DISPATCHER: Trying to submit another job.
13:37:48 job_callback for (3, 0, 0) got condition
13:37:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:37:48 Only 5 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
13:37:48 HBMASTER: Trying to run another job!
13:37:48 job_callback for (3, 0, 0) finished
13:37:48 start sampling a new configuration.
13:37:48 done sampling a new configuration.
13:37:48 HBMASTER: schedule new run for iteration 3
13:37:48 HBMASTER: trying submitting job (3, 0, 1) to dispatcher
13:37:48 HBMASTER: submitting job (3, 0, 1) to dispatcher
13:37:48 DISPATCHER: trying to submit job (3, 0, 1)
13:37:48 DISPATCHER: trying to notify the job_runner thread.
13:37:48 HBMASTER: job (3, 0, 1) submitted to dispatcher
13:37:48 DISPATCHER: Trying to submit another job.
13:37:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:37:48 DISPATCHER: starting job (3, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:37:48 DISPATCHER: job (3, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:37:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:37:48 WORKER: start processing job (3, 0, 1)
13:37:48 WORKER: args: ()
13:37:48 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0019019340477252585, 'num_filters_1': 18, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.10593616108310422, 'kernel_size_2': 5, 'num_filters_2': 72}, 'budget': 1200.0, 'working_directory': '.'}
13:38:02 DISPATCHER: Starting worker discovery
13:38:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:38:02 DISPATCHER: Finished worker discovery
13:39:02 DISPATCHER: Starting worker discovery
13:39:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:39:02 DISPATCHER: Finished worker discovery
13:40:02 DISPATCHER: Starting worker discovery
13:40:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:40:02 DISPATCHER: Finished worker discovery
13:41:02 DISPATCHER: Starting worker discovery
13:41:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:41:02 DISPATCHER: Finished worker discovery
13:42:02 DISPATCHER: Starting worker discovery
13:42:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:42:02 DISPATCHER: Finished worker discovery
13:43:02 DISPATCHER: Starting worker discovery
13:43:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:43:02 DISPATCHER: Finished worker discovery
13:44:02 DISPATCHER: Starting worker discovery
13:44:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:44:02 DISPATCHER: Finished worker discovery
13:45:02 DISPATCHER: Starting worker discovery
13:45:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:45:02 DISPATCHER: Finished worker discovery
13:46:02 DISPATCHER: Starting worker discovery
13:46:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:46:02 DISPATCHER: Finished worker discovery
13:47:02 DISPATCHER: Starting worker discovery
13:47:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:47:02 DISPATCHER: Finished worker discovery
13:48:02 DISPATCHER: Starting worker discovery
13:48:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:48:02 DISPATCHER: Finished worker discovery
13:49:02 DISPATCHER: Starting worker discovery
13:49:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:49:02 DISPATCHER: Finished worker discovery
13:50:02 DISPATCHER: Starting worker discovery
13:50:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:50:02 DISPATCHER: Finished worker discovery
13:51:02 DISPATCHER: Starting worker discovery
13:51:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:51:02 DISPATCHER: Finished worker discovery
13:52:02 DISPATCHER: Starting worker discovery
13:52:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:52:02 DISPATCHER: Finished worker discovery
13:53:02 DISPATCHER: Starting worker discovery
13:53:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:53:02 DISPATCHER: Finished worker discovery
13:54:02 DISPATCHER: Starting worker discovery
13:54:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:54:02 DISPATCHER: Finished worker discovery
13:55:02 DISPATCHER: Starting worker discovery
13:55:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:55:02 DISPATCHER: Finished worker discovery
13:56:02 DISPATCHER: Starting worker discovery
13:56:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:56:02 DISPATCHER: Finished worker discovery
13:57:02 DISPATCHER: Starting worker discovery
13:57:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:57:02 DISPATCHER: Finished worker discovery
13:58:02 DISPATCHER: Starting worker discovery
13:58:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:58:03 DISPATCHER: Finished worker discovery
13:58:06 WORKER: done with job (3, 0, 1), trying to register it.
13:58:06 WORKER: registered result for job (3, 0, 1) with dispatcher
13:58:06 DISPATCHER: job (3, 0, 1) finished
13:58:06 DISPATCHER: register_result: lock acquired
13:58:06 DISPATCHER: job (3, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:58:06 job_id: (3, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0019019340477252585, 'num_filters_1': 18, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.10593616108310422, 'kernel_size_2': 5, 'num_filters_2': 72}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.46605979608157766, 'info': {'music-speech': 0.46605979608157766, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0019019340477252585, 'num_filters_1': 18, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 75, 'weight_decay': 0.10593616108310422, 'kernel_size_2': 5, 'num_filters_2': 72}"}}
exception: None

13:58:06 job_callback for (3, 0, 1) started
13:58:06 DISPATCHER: Trying to submit another job.
13:58:06 job_callback for (3, 0, 1) got condition
13:58:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:58:07 Only 6 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
13:58:07 HBMASTER: Trying to run another job!
13:58:07 job_callback for (3, 0, 1) finished
13:58:07 start sampling a new configuration.
13:58:07 done sampling a new configuration.
13:58:07 HBMASTER: schedule new run for iteration 3
13:58:07 HBMASTER: trying submitting job (3, 0, 2) to dispatcher
13:58:07 HBMASTER: submitting job (3, 0, 2) to dispatcher
13:58:07 DISPATCHER: trying to submit job (3, 0, 2)
13:58:07 DISPATCHER: trying to notify the job_runner thread.
13:58:07 HBMASTER: job (3, 0, 2) submitted to dispatcher
13:58:07 DISPATCHER: Trying to submit another job.
13:58:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:58:07 DISPATCHER: starting job (3, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:58:07 DISPATCHER: job (3, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:58:07 WORKER: start processing job (3, 0, 2)
13:58:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:58:07 WORKER: args: ()
13:58:07 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.015154263009473314, 'num_filters_1': 21, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.016996055556161172, 'kernel_size_2': 5, 'num_filters_2': 39}, 'budget': 1200.0, 'working_directory': '.'}
13:59:03 DISPATCHER: Starting worker discovery
13:59:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:59:03 DISPATCHER: Finished worker discovery
14:00:03 DISPATCHER: Starting worker discovery
14:00:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:00:03 DISPATCHER: Finished worker discovery
14:01:03 DISPATCHER: Starting worker discovery
14:01:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:01:03 DISPATCHER: Finished worker discovery
14:02:03 DISPATCHER: Starting worker discovery
14:02:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:02:03 DISPATCHER: Finished worker discovery
14:03:03 DISPATCHER: Starting worker discovery
14:03:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:03:03 DISPATCHER: Finished worker discovery
14:04:03 DISPATCHER: Starting worker discovery
14:04:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:04:03 DISPATCHER: Finished worker discovery
14:05:03 DISPATCHER: Starting worker discovery
14:05:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:05:03 DISPATCHER: Finished worker discovery
14:06:03 DISPATCHER: Starting worker discovery
14:06:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:06:03 DISPATCHER: Finished worker discovery
14:07:03 DISPATCHER: Starting worker discovery
14:07:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:07:03 DISPATCHER: Finished worker discovery
14:08:03 DISPATCHER: Starting worker discovery
14:08:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:08:03 DISPATCHER: Finished worker discovery
14:09:03 DISPATCHER: Starting worker discovery
14:09:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:09:03 DISPATCHER: Finished worker discovery
14:10:03 DISPATCHER: Starting worker discovery
14:10:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:10:03 DISPATCHER: Finished worker discovery
14:11:03 DISPATCHER: Starting worker discovery
14:11:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:11:03 DISPATCHER: Finished worker discovery
14:12:03 DISPATCHER: Starting worker discovery
14:12:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:12:03 DISPATCHER: Finished worker discovery
14:13:03 DISPATCHER: Starting worker discovery
14:13:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:13:03 DISPATCHER: Finished worker discovery
14:14:03 DISPATCHER: Starting worker discovery
14:14:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:14:03 DISPATCHER: Finished worker discovery
14:15:03 DISPATCHER: Starting worker discovery
14:15:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:15:03 DISPATCHER: Finished worker discovery
14:16:03 DISPATCHER: Starting worker discovery
14:16:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:16:03 DISPATCHER: Finished worker discovery
14:17:03 DISPATCHER: Starting worker discovery
14:17:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:17:03 DISPATCHER: Finished worker discovery
14:18:03 DISPATCHER: Starting worker discovery
14:18:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:18:03 DISPATCHER: Finished worker discovery
14:18:19 WORKER: done with job (3, 0, 2), trying to register it.
14:18:19 WORKER: registered result for job (3, 0, 2) with dispatcher
14:18:19 DISPATCHER: job (3, 0, 2) finished
14:18:19 DISPATCHER: register_result: lock acquired
14:18:19 DISPATCHER: job (3, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:18:19 job_id: (3, 0, 2)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.015154263009473314, 'num_filters_1': 21, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.016996055556161172, 'kernel_size_2': 5, 'num_filters_2': 39}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.6320887410468807, 'info': {'music-speech': 0.6320887410468807, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.015154263009473314, 'num_filters_1': 21, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 46, 'weight_decay': 0.016996055556161172, 'kernel_size_2': 5, 'num_filters_2': 39}"}}
exception: None

14:18:19 job_callback for (3, 0, 2) started
14:18:19 DISPATCHER: Trying to submit another job.
14:18:19 job_callback for (3, 0, 2) got condition
14:18:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:18:19 Only 7 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
14:18:19 HBMASTER: Trying to run another job!
14:18:19 job_callback for (3, 0, 2) finished
14:18:19 start sampling a new configuration.
14:18:19 done sampling a new configuration.
14:18:19 HBMASTER: schedule new run for iteration 3
14:18:19 HBMASTER: trying submitting job (3, 0, 3) to dispatcher
14:18:19 HBMASTER: submitting job (3, 0, 3) to dispatcher
14:18:19 DISPATCHER: trying to submit job (3, 0, 3)
14:18:19 DISPATCHER: trying to notify the job_runner thread.
14:18:19 HBMASTER: job (3, 0, 3) submitted to dispatcher
14:18:19 DISPATCHER: Trying to submit another job.
14:18:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:18:19 DISPATCHER: starting job (3, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:18:19 DISPATCHER: job (3, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:18:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:18:19 WORKER: start processing job (3, 0, 3)
14:18:19 WORKER: args: ()
14:18:19 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.09708640198178746, 'num_filters_1': 40, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.013692266779410477}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-666:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 4607182418800017408 is out of bounds for axis 0 with size 2

14:19:03 DISPATCHER: Starting worker discovery
14:19:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:19:03 DISPATCHER: Finished worker discovery
14:20:03 DISPATCHER: Starting worker discovery
14:20:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:20:03 DISPATCHER: Finished worker discovery
14:21:03 DISPATCHER: Starting worker discovery
14:21:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:21:03 DISPATCHER: Finished worker discovery
14:22:03 DISPATCHER: Starting worker discovery
14:22:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:22:03 DISPATCHER: Finished worker discovery
14:23:03 DISPATCHER: Starting worker discovery
14:23:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:23:03 DISPATCHER: Finished worker discovery
14:24:03 DISPATCHER: Starting worker discovery
14:24:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:24:03 DISPATCHER: Finished worker discovery
14:25:03 DISPATCHER: Starting worker discovery
14:25:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:25:03 DISPATCHER: Finished worker discovery
14:26:03 DISPATCHER: Starting worker discovery
14:26:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:26:03 DISPATCHER: Finished worker discovery
14:27:03 DISPATCHER: Starting worker discovery
14:27:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:27:03 DISPATCHER: Finished worker discovery
14:28:03 DISPATCHER: Starting worker discovery
14:28:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:28:03 DISPATCHER: Finished worker discovery
14:29:03 DISPATCHER: Starting worker discovery
14:29:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:29:03 DISPATCHER: Finished worker discovery
14:30:03 DISPATCHER: Starting worker discovery
14:30:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:30:03 DISPATCHER: Finished worker discovery
14:31:03 DISPATCHER: Starting worker discovery
14:31:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:31:03 DISPATCHER: Finished worker discovery
14:32:03 DISPATCHER: Starting worker discovery
14:32:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:32:03 DISPATCHER: Finished worker discovery
14:33:03 DISPATCHER: Starting worker discovery
14:33:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:33:03 DISPATCHER: Finished worker discovery
14:34:03 DISPATCHER: Starting worker discovery
14:34:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:34:03 DISPATCHER: Finished worker discovery
14:35:03 DISPATCHER: Starting worker discovery
14:35:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:35:03 DISPATCHER: Finished worker discovery
14:36:03 DISPATCHER: Starting worker discovery
14:36:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:36:03 DISPATCHER: Finished worker discovery
14:37:03 DISPATCHER: Starting worker discovery
14:37:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:37:03 DISPATCHER: Finished worker discovery
14:38:03 DISPATCHER: Starting worker discovery
14:38:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:38:03 DISPATCHER: Finished worker discovery
14:38:27 WORKER: done with job (3, 0, 3), trying to register it.
14:38:27 DISPATCHER: job (3, 0, 3) finished
14:38:27 WORKER: registered result for job (3, 0, 3) with dispatcher
14:38:27 DISPATCHER: register_result: lock acquired
14:38:27 DISPATCHER: job (3, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:38:27 job_id: (3, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.09708640198178746, 'num_filters_1': 40, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.013692266779410477}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.271984340289082, 'info': {'music-speech': 0.271984340289082, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.09708640198178746, 'num_filters_1': 40, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 59, 'weight_decay': 0.013692266779410477}"}}
exception: None

14:38:27 job_callback for (3, 0, 3) started
14:38:27 DISPATCHER: Trying to submit another job.
14:38:27 job_callback for (3, 0, 3) got condition
14:38:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:38:27 Only 8 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
14:38:27 HBMASTER: Trying to run another job!
14:38:27 job_callback for (3, 0, 3) finished
14:38:27 start sampling a new configuration.
14:38:27 done sampling a new configuration.
14:38:27 HBMASTER: schedule new run for iteration 4
14:38:27 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
14:38:27 HBMASTER: submitting job (4, 0, 0) to dispatcher
14:38:27 DISPATCHER: trying to submit job (4, 0, 0)
14:38:27 DISPATCHER: trying to notify the job_runner thread.
14:38:27 HBMASTER: job (4, 0, 0) submitted to dispatcher
14:38:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:38:27 DISPATCHER: Trying to submit another job.
14:38:27 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:38:27 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:38:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:38:27 WORKER: start processing job (4, 0, 0)
14:38:27 WORKER: args: ()
14:38:27 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0019755857740739965, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.02438709303401629, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 43, 'num_filters_3': 52, 'num_filters_4': 113, 'num_filters_5': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:39:03 DISPATCHER: Starting worker discovery
14:39:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:39:03 DISPATCHER: Finished worker discovery
14:39:21 WORKER: done with job (4, 0, 0), trying to register it.
14:39:21 WORKER: registered result for job (4, 0, 0) with dispatcher
14:39:21 DISPATCHER: job (4, 0, 0) finished
14:39:21 DISPATCHER: register_result: lock acquired
14:39:21 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:39:21 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0019755857740739965, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.02438709303401629, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 43, 'num_filters_3': 52, 'num_filters_4': 113, 'num_filters_5': 21}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9080558891384656, 'info': {'music-speech': 0.9080558891384656, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0019755857740739965, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.02438709303401629, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 43, 'num_filters_3': 52, 'num_filters_4': 113, 'num_filters_5': 21}"}}
exception: None

14:39:21 job_callback for (4, 0, 0) started
14:39:21 DISPATCHER: Trying to submit another job.
14:39:21 job_callback for (4, 0, 0) got condition
14:39:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:39:21 HBMASTER: Trying to run another job!
14:39:21 job_callback for (4, 0, 0) finished
14:39:21 start sampling a new configuration.
14:39:21 done sampling a new configuration.
14:39:21 HBMASTER: schedule new run for iteration 4
14:39:21 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
14:39:21 HBMASTER: submitting job (4, 0, 1) to dispatcher
14:39:21 DISPATCHER: trying to submit job (4, 0, 1)
14:39:21 DISPATCHER: trying to notify the job_runner thread.
14:39:21 HBMASTER: job (4, 0, 1) submitted to dispatcher
14:39:21 DISPATCHER: Trying to submit another job.
14:39:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:39:21 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:39:21 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:39:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:39:21 WORKER: start processing job (4, 0, 1)
14:39:21 WORKER: args: ()
14:39:21 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.011988808063322285, 'num_filters_1': 65, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.06177496009036832, 'kernel_size_2': 3, 'num_filters_2': 85}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-668:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

14:40:03 DISPATCHER: Starting worker discovery
14:40:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:40:03 DISPATCHER: Finished worker discovery
14:40:14 WORKER: done with job (4, 0, 1), trying to register it.
14:40:14 WORKER: registered result for job (4, 0, 1) with dispatcher
14:40:14 DISPATCHER: job (4, 0, 1) finished
14:40:14 DISPATCHER: register_result: lock acquired
14:40:14 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:40:14 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.011988808063322285, 'num_filters_1': 65, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.06177496009036832, 'kernel_size_2': 3, 'num_filters_2': 85}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8409582243108311, 'info': {'music-speech': 0.8409582243108311, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.011988808063322285, 'num_filters_1': 65, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.06177496009036832, 'kernel_size_2': 3, 'num_filters_2': 85}"}}
exception: None

14:40:14 job_callback for (4, 0, 1) started
14:40:14 DISPATCHER: Trying to submit another job.
14:40:14 job_callback for (4, 0, 1) got condition
14:40:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:40:14 HBMASTER: Trying to run another job!
14:40:14 job_callback for (4, 0, 1) finished
14:40:14 start sampling a new configuration.
14:40:14 done sampling a new configuration.
14:40:14 HBMASTER: schedule new run for iteration 4
14:40:14 HBMASTER: trying submitting job (4, 0, 2) to dispatcher
14:40:14 HBMASTER: submitting job (4, 0, 2) to dispatcher
14:40:14 DISPATCHER: trying to submit job (4, 0, 2)
14:40:14 DISPATCHER: trying to notify the job_runner thread.
14:40:14 HBMASTER: job (4, 0, 2) submitted to dispatcher
14:40:14 DISPATCHER: Trying to submit another job.
14:40:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:40:14 DISPATCHER: starting job (4, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:40:14 DISPATCHER: job (4, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:40:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:40:14 WORKER: start processing job (4, 0, 2)
14:40:14 WORKER: args: ()
14:40:14 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.042712161421677566, 'num_filters_1': 39, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.05200123652334212}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-669:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

14:41:03 DISPATCHER: Starting worker discovery
14:41:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:41:03 DISPATCHER: Finished worker discovery
14:41:07 WORKER: done with job (4, 0, 2), trying to register it.
14:41:07 WORKER: registered result for job (4, 0, 2) with dispatcher
14:41:07 DISPATCHER: job (4, 0, 2) finished
14:41:07 DISPATCHER: register_result: lock acquired
14:41:07 DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:41:07 job_id: (4, 0, 2)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.042712161421677566, 'num_filters_1': 39, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.05200123652334212}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5538975903814043, 'info': {'music-speech': 0.5538975903814043, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.042712161421677566, 'num_filters_1': 39, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.05200123652334212}"}}
exception: None

14:41:07 job_callback for (4, 0, 2) started
14:41:07 DISPATCHER: Trying to submit another job.
14:41:07 job_callback for (4, 0, 2) got condition
14:41:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:41:07 HBMASTER: Trying to run another job!
14:41:07 job_callback for (4, 0, 2) finished
14:41:07 start sampling a new configuration.
14:41:07 done sampling a new configuration.
14:41:07 HBMASTER: schedule new run for iteration 4
14:41:07 HBMASTER: trying submitting job (4, 0, 3) to dispatcher
14:41:07 HBMASTER: submitting job (4, 0, 3) to dispatcher
14:41:07 DISPATCHER: trying to submit job (4, 0, 3)
14:41:07 DISPATCHER: trying to notify the job_runner thread.
14:41:07 HBMASTER: job (4, 0, 3) submitted to dispatcher
14:41:07 DISPATCHER: Trying to submit another job.
14:41:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:41:07 DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:41:07 DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:41:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:41:07 WORKER: start processing job (4, 0, 3)
14:41:07 WORKER: args: ()
14:41:07 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.054994796130529794, 'num_filters_1': 25, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.06009587067493494}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:42:03 DISPATCHER: Starting worker discovery
14:42:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:42:03 DISPATCHER: Finished worker discovery
14:42:26 WORKER: done with job (4, 0, 3), trying to register it.
14:42:27 WORKER: registered result for job (4, 0, 3) with dispatcher
14:42:27 DISPATCHER: job (4, 0, 3) finished
14:42:27 DISPATCHER: register_result: lock acquired
14:42:27 DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:42:27 job_id: (4, 0, 3)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.054994796130529794, 'num_filters_1': 25, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.06009587067493494}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2016527657736036, 'info': {'music-speech': 0.2016527657736036, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.054994796130529794, 'num_filters_1': 25, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 65, 'weight_decay': 0.06009587067493494}"}}
exception: None

14:42:27 job_callback for (4, 0, 3) started
14:42:27 DISPATCHER: Trying to submit another job.
14:42:27 job_callback for (4, 0, 3) got condition
14:42:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:42:27 HBMASTER: Trying to run another job!
14:42:27 job_callback for (4, 0, 3) finished
14:42:27 start sampling a new configuration.
14:42:27 done sampling a new configuration.
14:42:28 HBMASTER: schedule new run for iteration 4
14:42:28 HBMASTER: trying submitting job (4, 0, 4) to dispatcher
14:42:28 HBMASTER: submitting job (4, 0, 4) to dispatcher
14:42:28 DISPATCHER: trying to submit job (4, 0, 4)
14:42:28 DISPATCHER: trying to notify the job_runner thread.
14:42:28 HBMASTER: job (4, 0, 4) submitted to dispatcher
14:42:28 DISPATCHER: Trying to submit another job.
14:42:28 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:42:28 DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:42:28 DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:42:28 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:42:28 WORKER: start processing job (4, 0, 4)
14:42:28 WORKER: args: ()
14:42:28 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.028046363320768448, 'num_filters_1': 66, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.011964323394976356, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 58, 'num_filters_3': 52, 'num_filters_4': 51}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:43:03 DISPATCHER: Starting worker discovery
14:43:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:43:03 DISPATCHER: Finished worker discovery
14:43:23 WORKER: done with job (4, 0, 4), trying to register it.
14:43:23 WORKER: registered result for job (4, 0, 4) with dispatcher
14:43:23 DISPATCHER: job (4, 0, 4) finished
14:43:23 DISPATCHER: register_result: lock acquired
14:43:23 DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:43:23 job_id: (4, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.028046363320768448, 'num_filters_1': 66, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.011964323394976356, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 58, 'num_filters_3': 52, 'num_filters_4': 51}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': 0.06270880026544967, 'info': {'music-speech': -0.06270880026544967, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.028046363320768448, 'num_filters_1': 66, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 57, 'weight_decay': 0.011964323394976356, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 58, 'num_filters_3': 52, 'num_filters_4': 51}"}}
exception: None

14:43:23 job_callback for (4, 0, 4) started
14:43:23 DISPATCHER: Trying to submit another job.
14:43:23 job_callback for (4, 0, 4) got condition
14:43:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:43:23 HBMASTER: Trying to run another job!
14:43:23 job_callback for (4, 0, 4) finished
14:43:23 start sampling a new configuration.
14:43:23 done sampling a new configuration.
14:43:23 HBMASTER: schedule new run for iteration 4
14:43:23 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
14:43:23 HBMASTER: submitting job (4, 0, 5) to dispatcher
14:43:23 DISPATCHER: trying to submit job (4, 0, 5)
14:43:23 DISPATCHER: trying to notify the job_runner thread.
14:43:23 HBMASTER: job (4, 0, 5) submitted to dispatcher
14:43:23 DISPATCHER: Trying to submit another job.
14:43:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:43:23 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:43:23 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:43:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:43:23 WORKER: start processing job (4, 0, 5)
14:43:23 WORKER: args: ()
14:43:23 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.017705029813328495, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.017270919489236286, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 95, 'num_filters_3': 117, 'num_filters_4': 85}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-672:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

14:44:03 DISPATCHER: Starting worker discovery
14:44:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:44:03 DISPATCHER: Finished worker discovery
14:44:16 WORKER: done with job (4, 0, 5), trying to register it.
14:44:16 WORKER: registered result for job (4, 0, 5) with dispatcher
14:44:16 DISPATCHER: job (4, 0, 5) finished
14:44:16 DISPATCHER: register_result: lock acquired
14:44:16 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:44:16 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.017705029813328495, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.017270919489236286, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 95, 'num_filters_3': 117, 'num_filters_4': 85}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8615331846393001, 'info': {'music-speech': 0.8615331846393001, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.017705029813328495, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.017270919489236286, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 95, 'num_filters_3': 117, 'num_filters_4': 85}"}}
exception: None

14:44:16 job_callback for (4, 0, 5) started
14:44:16 DISPATCHER: Trying to submit another job.
14:44:16 job_callback for (4, 0, 5) got condition
14:44:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:44:16 HBMASTER: Trying to run another job!
14:44:16 job_callback for (4, 0, 5) finished
14:44:16 start sampling a new configuration.
14:44:16 done sampling a new configuration.
14:44:16 HBMASTER: schedule new run for iteration 4
14:44:16 HBMASTER: trying submitting job (4, 0, 6) to dispatcher
14:44:16 HBMASTER: submitting job (4, 0, 6) to dispatcher
14:44:16 DISPATCHER: trying to submit job (4, 0, 6)
14:44:16 DISPATCHER: trying to notify the job_runner thread.
14:44:16 HBMASTER: job (4, 0, 6) submitted to dispatcher
14:44:16 DISPATCHER: Trying to submit another job.
14:44:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:44:16 DISPATCHER: starting job (4, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:44:16 DISPATCHER: job (4, 0, 6) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:44:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:44:16 WORKER: start processing job (4, 0, 6)
14:44:16 WORKER: args: ()
14:44:16 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0033227267589346168, 'num_filters_1': 48, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.03464141027161206, 'kernel_size_2': 3, 'num_filters_2': 42}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:45:03 DISPATCHER: Starting worker discovery
14:45:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:45:03 DISPATCHER: Finished worker discovery
14:45:10 WORKER: done with job (4, 0, 6), trying to register it.
14:45:10 WORKER: registered result for job (4, 0, 6) with dispatcher
14:45:10 DISPATCHER: job (4, 0, 6) finished
14:45:10 DISPATCHER: register_result: lock acquired
14:45:10 DISPATCHER: job (4, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:45:10 job_id: (4, 0, 6)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0033227267589346168, 'num_filters_1': 48, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.03464141027161206, 'kernel_size_2': 3, 'num_filters_2': 42}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5595331287798441, 'info': {'music-speech': 0.5595331287798441, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0033227267589346168, 'num_filters_1': 48, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.03464141027161206, 'kernel_size_2': 3, 'num_filters_2': 42}"}}
exception: None

14:45:10 job_callback for (4, 0, 6) started
14:45:10 DISPATCHER: Trying to submit another job.
14:45:10 job_callback for (4, 0, 6) got condition
14:45:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:45:10 done building a new model for budget 44.444444 based on 17/28 split
Best loss for this budget:-0.993850





14:45:10 HBMASTER: Trying to run another job!
14:45:10 job_callback for (4, 0, 6) finished
14:45:10 start sampling a new configuration.
14:45:10 best_vector: [0, 0, 0.06420996546921193, 0.014876842629251819, 0.7707727488629651, 1, 0.8356907021709223, 0.17106784739808412, 0, 1, 0, 2, 0.3820612807017768, 0.2622456303810192, 0.03672775471263434, 0.4499027372262975], 0.006751691655173786, 3.7332950652392813e-07, 2.520605713827753e-09
14:45:10 done sampling a new configuration.
14:45:10 HBMASTER: schedule new run for iteration 4
14:45:10 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
14:45:10 HBMASTER: submitting job (4, 0, 7) to dispatcher
14:45:10 DISPATCHER: trying to submit job (4, 0, 7)
14:45:10 DISPATCHER: trying to notify the job_runner thread.
14:45:10 HBMASTER: job (4, 0, 7) submitted to dispatcher
14:45:10 DISPATCHER: Trying to submit another job.
14:45:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:45:10 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:45:10 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:45:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:45:10 WORKER: start processing job (4, 0, 7)
14:45:10 WORKER: args: ()
14:45:10 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0013440639443655818, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.016694153434981165, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 35, 'num_filters_3': 27, 'num_filters_4': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:46:03 DISPATCHER: Starting worker discovery
14:46:03 WORKER: done with job (4, 0, 7), trying to register it.
14:46:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:46:03 WORKER: registered result for job (4, 0, 7) with dispatcher
14:46:03 DISPATCHER: job (4, 0, 7) finished
14:46:03 DISPATCHER: Finished worker discovery
14:46:03 DISPATCHER: register_result: lock acquired
14:46:03 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:46:03 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0013440639443655818, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.016694153434981165, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 35, 'num_filters_3': 27, 'num_filters_4': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9303939979568268, 'info': {'music-speech': 0.9303939979568268, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0013440639443655818, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.016694153434981165, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 35, 'num_filters_3': 27, 'num_filters_4': 17}"}}
exception: None

14:46:03 job_callback for (4, 0, 7) started
14:46:03 DISPATCHER: Trying to submit another job.
14:46:03 job_callback for (4, 0, 7) got condition
14:46:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:46:03 done building a new model for budget 44.444444 based on 17/29 split
Best loss for this budget:-0.993850





14:46:03 HBMASTER: Trying to run another job!
14:46:03 job_callback for (4, 0, 7) finished
14:46:03 start sampling a new configuration.
14:46:03 done sampling a new configuration.
14:46:03 HBMASTER: schedule new run for iteration 4
14:46:03 HBMASTER: trying submitting job (4, 0, 8) to dispatcher
14:46:03 HBMASTER: submitting job (4, 0, 8) to dispatcher
14:46:03 DISPATCHER: trying to submit job (4, 0, 8)
14:46:03 DISPATCHER: trying to notify the job_runner thread.
14:46:03 HBMASTER: job (4, 0, 8) submitted to dispatcher
14:46:03 DISPATCHER: Trying to submit another job.
14:46:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:46:03 DISPATCHER: starting job (4, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:46:03 DISPATCHER: job (4, 0, 8) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:46:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:46:03 WORKER: start processing job (4, 0, 8)
14:46:03 WORKER: args: ()
14:46:03 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.08690009520159173, 'num_filters_1': 112, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 68, 'weight_decay': 0.034827789877688184}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-675:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

14:46:56 WORKER: done with job (4, 0, 8), trying to register it.
14:46:56 WORKER: registered result for job (4, 0, 8) with dispatcher
14:46:56 DISPATCHER: job (4, 0, 8) finished
14:46:56 DISPATCHER: register_result: lock acquired
14:46:56 DISPATCHER: job (4, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:46:56 job_id: (4, 0, 8)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.08690009520159173, 'num_filters_1': 112, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 68, 'weight_decay': 0.034827789877688184}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5443314960441441, 'info': {'music-speech': 0.5443314960441441, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.08690009520159173, 'num_filters_1': 112, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 68, 'weight_decay': 0.034827789877688184}"}}
exception: None

14:46:56 job_callback for (4, 0, 8) started
14:46:56 job_callback for (4, 0, 8) got condition
14:46:56 DISPATCHER: Trying to submit another job.
14:46:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:46:56 done building a new model for budget 44.444444 based on 17/30 split
Best loss for this budget:-0.993850





14:46:56 HBMASTER: Trying to run another job!
14:46:56 job_callback for (4, 0, 8) finished
14:46:56 start sampling a new configuration.
14:46:56 best_vector: [2, 1, 0.09644352902674025, 5.0142957030430146e-05, 0.013201389804269381, 0, 0.09092696728494296, 0.5828010443124783, 0, 1, 0, 1, 0.7204038665530276, 0.24397916540502237, 0.6378724176464188, 0.014183641200910174], 0.0013372863124431027, 0.00014126865896665542, 1.8891664401330088e-07
14:46:56 done sampling a new configuration.
14:46:56 HBMASTER: schedule new run for iteration 4
14:46:56 HBMASTER: trying submitting job (4, 0, 9) to dispatcher
14:46:56 HBMASTER: submitting job (4, 0, 9) to dispatcher
14:46:56 DISPATCHER: trying to submit job (4, 0, 9)
14:46:56 DISPATCHER: trying to notify the job_runner thread.
14:46:56 HBMASTER: job (4, 0, 9) submitted to dispatcher
14:46:56 DISPATCHER: Trying to submit another job.
14:46:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:46:56 DISPATCHER: starting job (4, 0, 9) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:46:56 DISPATCHER: job (4, 0, 9) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:46:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:46:56 WORKER: start processing job (4, 0, 9)
14:46:56 WORKER: args: ()
14:46:56 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0015591469807641858, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.05731148216684746}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:47:03 DISPATCHER: Starting worker discovery
14:47:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:47:03 DISPATCHER: Finished worker discovery
14:47:50 WORKER: done with job (4, 0, 9), trying to register it.
14:47:50 WORKER: registered result for job (4, 0, 9) with dispatcher
14:47:50 DISPATCHER: job (4, 0, 9) finished
14:47:50 DISPATCHER: register_result: lock acquired
14:47:50 DISPATCHER: job (4, 0, 9) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:47:50 job_id: (4, 0, 9)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0015591469807641858, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.05731148216684746}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5660920483004058, 'info': {'music-speech': 0.5660920483004058, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0015591469807641858, 'num_filters_1': 16, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 18, 'weight_decay': 0.05731148216684746}"}}
exception: None

14:47:50 job_callback for (4, 0, 9) started
14:47:50 DISPATCHER: Trying to submit another job.
14:47:50 job_callback for (4, 0, 9) got condition
14:47:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:47:50 done building a new model for budget 44.444444 based on 17/31 split
Best loss for this budget:-0.993850





14:47:50 HBMASTER: Trying to run another job!
14:47:50 job_callback for (4, 0, 9) finished
14:47:50 start sampling a new configuration.
14:47:50 best_vector: [0, 0, 0.19477171521639813, 0.07901928979109873, 0.7781257967097869, 1, 0.8980350875451999, 0.5152014265411361, 2, 2, 1, 2, 0.4766638237332624, 0.0034140200754112504, 0.03645448163597487, 0.5853153580159224], 0.002224471246600112, 0.00013278039868464778, 2.953661789860983e-07
14:47:50 done sampling a new configuration.
14:47:50 HBMASTER: schedule new run for iteration 4
14:47:50 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
14:47:50 HBMASTER: submitting job (4, 0, 10) to dispatcher
14:47:50 DISPATCHER: trying to submit job (4, 0, 10)
14:47:50 DISPATCHER: trying to notify the job_runner thread.
14:47:50 HBMASTER: job (4, 0, 10) submitted to dispatcher
14:47:50 DISPATCHER: Trying to submit another job.
14:47:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:47:50 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:47:50 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:47:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:47:50 WORKER: start processing job (4, 0, 10)
14:47:50 WORKER: args: ()
14:47:50 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0024521296600740444, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.04680502803810719, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 42, 'num_filters_3': 16, 'num_filters_4': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:48:03 DISPATCHER: Starting worker discovery
14:48:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:48:03 DISPATCHER: Finished worker discovery
14:48:43 WORKER: done with job (4, 0, 10), trying to register it.
14:48:43 WORKER: registered result for job (4, 0, 10) with dispatcher
14:48:43 DISPATCHER: job (4, 0, 10) finished
14:48:43 DISPATCHER: register_result: lock acquired
14:48:43 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:48:43 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0024521296600740444, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.04680502803810719, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 42, 'num_filters_3': 16, 'num_filters_4': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8922960880780983, 'info': {'music-speech': 0.8922960880780983, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0024521296600740444, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.04680502803810719, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 42, 'num_filters_3': 16, 'num_filters_4': 17}"}}
exception: None

14:48:43 job_callback for (4, 0, 10) started
14:48:43 DISPATCHER: Trying to submit another job.
14:48:43 job_callback for (4, 0, 10) got condition
14:48:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:48:43 done building a new model for budget 44.444444 based on 17/32 split
Best loss for this budget:-0.993850





14:48:43 HBMASTER: Trying to run another job!
14:48:43 job_callback for (4, 0, 10) finished
14:48:43 start sampling a new configuration.
14:48:43 best_vector: [3, 2, 0.15297468399172884, 0.0419813253370066, 0.5993355573356626, 1, 0.06952658568981554, 0.017547433043450744, 0, 0, 0, 2, 0.8060382511957143, 0.0898770316809378, 0.09006916479521915, 0.3658978035937654], 0.0030400947828446967, 1.43243035732126e-05, 4.3547240560807276e-08
14:48:43 done sampling a new configuration.
14:48:43 HBMASTER: schedule new run for iteration 4
14:48:43 HBMASTER: trying submitting job (4, 0, 11) to dispatcher
14:48:43 HBMASTER: submitting job (4, 0, 11) to dispatcher
14:48:43 DISPATCHER: trying to submit job (4, 0, 11)
14:48:43 DISPATCHER: trying to notify the job_runner thread.
14:48:43 HBMASTER: job (4, 0, 11) submitted to dispatcher
14:48:43 DISPATCHER: Trying to submit another job.
14:48:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:48:43 DISPATCHER: starting job (4, 0, 11) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:48:43 DISPATCHER: job (4, 0, 11) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:48:43 WORKER: start processing job (4, 0, 11)
14:48:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:48:43 WORKER: args: ()
14:48:43 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0020227833396930434, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.010539736096113384, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 85, 'num_filters_3': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:49:03 DISPATCHER: Starting worker discovery
14:49:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:49:03 DISPATCHER: Finished worker discovery
14:49:36 WORKER: done with job (4, 0, 11), trying to register it.
14:49:36 WORKER: registered result for job (4, 0, 11) with dispatcher
14:49:36 DISPATCHER: job (4, 0, 11) finished
14:49:36 DISPATCHER: register_result: lock acquired
14:49:36 DISPATCHER: job (4, 0, 11) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:49:36 job_id: (4, 0, 11)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0020227833396930434, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.010539736096113384, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 85, 'num_filters_3': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5432492587878199, 'info': {'music-speech': 0.5432492587878199, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0020227833396930434, 'num_filters_1': 17, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 16, 'weight_decay': 0.010539736096113384, 'kernel_size_2': 3, 'kernel_size_3': 3, 'num_filters_2': 85, 'num_filters_3': 19}"}}
exception: None

14:49:36 job_callback for (4, 0, 11) started
14:49:36 job_callback for (4, 0, 11) got condition
14:49:36 DISPATCHER: Trying to submit another job.
14:49:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:49:36 done building a new model for budget 44.444444 based on 17/33 split
Best loss for this budget:-0.993850





14:49:36 HBMASTER: Trying to run another job!
14:49:36 job_callback for (4, 0, 11) finished
14:49:36 start sampling a new configuration.
14:49:36 best_vector: [0, 0, 0.6302868922874053, 0.9669947285188116, 0.8869073283917607, 1, 0.7588056376217622, 0.11310053750877691, 0, 1, 2, 2, 0.40511050179205604, 0.027173434576017202, 0.03608385527382796, 0.09671946218135524], 0.006534628539603459, 6.0827070396064905e-05, 3.974823101905944e-07
14:49:36 done sampling a new configuration.
14:49:36 HBMASTER: schedule new run for iteration 4
14:49:36 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
14:49:36 HBMASTER: submitting job (4, 0, 12) to dispatcher
14:49:36 DISPATCHER: trying to submit job (4, 0, 12)
14:49:36 DISPATCHER: trying to notify the job_runner thread.
14:49:36 HBMASTER: job (4, 0, 12) submitted to dispatcher
14:49:36 DISPATCHER: Trying to submit another job.
14:49:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:49:36 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:49:36 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:49:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:49:36 WORKER: start processing job (4, 0, 12)
14:49:36 WORKER: args: ()
14:49:36 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.01822106614077037, 'num_filters_1': 120, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.014032892291474556, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 37, 'num_filters_3': 16, 'num_filters_4': 17, 'num_filters_5': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-679:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

14:50:03 DISPATCHER: Starting worker discovery
14:50:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:50:03 DISPATCHER: Finished worker discovery
14:50:29 WORKER: done with job (4, 0, 12), trying to register it.
14:50:29 WORKER: registered result for job (4, 0, 12) with dispatcher
14:50:29 DISPATCHER: job (4, 0, 12) finished
14:50:29 DISPATCHER: register_result: lock acquired
14:50:29 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:50:29 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.01822106614077037, 'num_filters_1': 120, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.014032892291474556, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 37, 'num_filters_3': 16, 'num_filters_4': 17, 'num_filters_5': 19}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.930620993244871, 'info': {'music-speech': 0.930620993244871, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.01822106614077037, 'num_filters_1': 120, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.014032892291474556, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 37, 'num_filters_3': 16, 'num_filters_4': 17, 'num_filters_5': 19}"}}
exception: None

14:50:29 job_callback for (4, 0, 12) started
14:50:29 DISPATCHER: Trying to submit another job.
14:50:29 job_callback for (4, 0, 12) got condition
14:50:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:50:29 done building a new model for budget 44.444444 based on 17/34 split
Best loss for this budget:-0.993850





14:50:29 HBMASTER: Trying to run another job!
14:50:29 job_callback for (4, 0, 12) finished
14:50:29 start sampling a new configuration.
14:50:30 best_vector: [1, 1, 0.24982827158548054, 0.32855836994775156, 0.5377550887514387, 1, 0.7309283458246207, 0.3649418049134466, 0, 1, 0, 1, 0.28884909024444405, 0.07693637540395659, 0.05485699434789339, 0.44186319867330676], 0.0010192438228117592, 0.0009283414293388074, 9.462062673138186e-07
14:50:30 done sampling a new configuration.
14:50:30 HBMASTER: schedule new run for iteration 4
14:50:30 HBMASTER: trying submitting job (4, 0, 13) to dispatcher
14:50:30 HBMASTER: submitting job (4, 0, 13) to dispatcher
14:50:30 DISPATCHER: trying to submit job (4, 0, 13)
14:50:30 DISPATCHER: trying to notify the job_runner thread.
14:50:30 HBMASTER: job (4, 0, 13) submitted to dispatcher
14:50:30 DISPATCHER: Trying to submit another job.
14:50:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:50:30 DISPATCHER: starting job (4, 0, 13) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:50:30 DISPATCHER: job (4, 0, 13) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:50:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:50:30 WORKER: start processing job (4, 0, 13)
14:50:30 WORKER: args: ()
14:50:30 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.003159777797635174, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.029840097296663814, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 29, 'num_filters_3': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:51:03 DISPATCHER: Starting worker discovery
14:51:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:51:03 DISPATCHER: Finished worker discovery
14:51:23 WORKER: done with job (4, 0, 13), trying to register it.
14:51:23 DISPATCHER: job (4, 0, 13) finished
14:51:23 WORKER: registered result for job (4, 0, 13) with dispatcher
14:51:23 DISPATCHER: register_result: lock acquired
14:51:23 DISPATCHER: job (4, 0, 13) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:51:23 job_id: (4, 0, 13)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.003159777797635174, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.029840097296663814, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 29, 'num_filters_3': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5674392723335668, 'info': {'music-speech': 0.5674392723335668, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.003159777797635174, 'num_filters_1': 31, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.029840097296663814, 'kernel_size_2': 3, 'kernel_size_3': 5, 'num_filters_2': 29, 'num_filters_3': 18}"}}
exception: None

14:51:23 job_callback for (4, 0, 13) started
14:51:23 DISPATCHER: Trying to submit another job.
14:51:23 job_callback for (4, 0, 13) got condition
14:51:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:51:23 done building a new model for budget 44.444444 based on 17/34 split
Best loss for this budget:-0.993850





14:51:23 HBMASTER: Trying to run another job!
14:51:23 job_callback for (4, 0, 13) finished
14:51:23 start sampling a new configuration.
14:51:23 best_vector: [1, 2, 0.4018066027961926, 0.1761767350613006, 0.9559592159729345, 1, 0.6775969628948985, 0.19030278277514368, 0, 1, 0, 2, 0.4654824991904098, 0.23976408939613658, 0.012843877940798554, 0.24736851303206525], 0.0028893428761597195, 0.0007593536036816727, 2.194032925283852e-06
14:51:23 done sampling a new configuration.
14:51:23 HBMASTER: schedule new run for iteration 4
14:51:23 HBMASTER: trying submitting job (4, 0, 14) to dispatcher
14:51:23 HBMASTER: submitting job (4, 0, 14) to dispatcher
14:51:23 DISPATCHER: trying to submit job (4, 0, 14)
14:51:23 DISPATCHER: trying to notify the job_runner thread.
14:51:23 HBMASTER: job (4, 0, 14) submitted to dispatcher
14:51:23 DISPATCHER: Trying to submit another job.
14:51:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:51:23 DISPATCHER: starting job (4, 0, 14) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:51:23 DISPATCHER: job (4, 0, 14) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:51:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:51:23 WORKER: start processing job (4, 0, 14)
14:51:23 WORKER: args: ()
14:51:23 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0063622862608333905, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.01768437145873833, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 41, 'num_filters_3': 26, 'num_filters_4': 16, 'num_filters_5': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-681:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

14:52:03 DISPATCHER: Starting worker discovery
14:52:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:52:03 DISPATCHER: Finished worker discovery
14:52:16 WORKER: done with job (4, 0, 14), trying to register it.
14:52:16 DISPATCHER: job (4, 0, 14) finished
14:52:16 WORKER: registered result for job (4, 0, 14) with dispatcher
14:52:16 DISPATCHER: register_result: lock acquired
14:52:16 DISPATCHER: job (4, 0, 14) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:52:16 job_id: (4, 0, 14)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0063622862608333905, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.01768437145873833, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 41, 'num_filters_3': 26, 'num_filters_4': 16, 'num_filters_5': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8407362680250242, 'info': {'music-speech': 0.8407362680250242, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0063622862608333905, 'num_filters_1': 22, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 71, 'weight_decay': 0.01768437145873833, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 41, 'num_filters_3': 26, 'num_filters_4': 16, 'num_filters_5': 26}"}}
exception: None

14:52:16 job_callback for (4, 0, 14) started
14:52:16 DISPATCHER: Trying to submit another job.
14:52:16 job_callback for (4, 0, 14) got condition
14:52:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:52:16 done building a new model for budget 44.444444 based on 17/35 split
Best loss for this budget:-0.993850





14:52:16 HBMASTER: Trying to run another job!
14:52:16 job_callback for (4, 0, 14) finished
14:52:16 start sampling a new configuration.
14:52:16 best_vector: [0, 0, 0.36180661449056156, 0.24881961587297374, 0.7598173116106852, 1, 0.6668623834270886, 0.13606947126951424, 2, 1, 1, 2, 0.8049352073232918, 0.19919294630565165, 0.22294696655891572, 0.3027065098051275], 0.0438768132041457, 0.0002931324806940867, 1.2861719099482288e-05
14:52:16 done sampling a new configuration.
14:52:16 HBMASTER: schedule new run for iteration 4
14:52:16 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
14:52:16 HBMASTER: submitting job (4, 0, 15) to dispatcher
14:52:16 DISPATCHER: trying to submit job (4, 0, 15)
14:52:16 DISPATCHER: trying to notify the job_runner thread.
14:52:16 HBMASTER: job (4, 0, 15) submitted to dispatcher
14:52:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:52:16 DISPATCHER: Trying to submit another job.
14:52:16 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:52:16 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:52:16 WORKER: start processing job (4, 0, 15)
14:52:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:52:16 WORKER: args: ()
14:52:16 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.00529191949813948, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.01503247407782858, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 85, 'num_filters_3': 24, 'num_filters_4': 25}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-682:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

14:53:03 DISPATCHER: Starting worker discovery
14:53:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:53:03 DISPATCHER: Finished worker discovery
14:53:09 WORKER: done with job (4, 0, 15), trying to register it.
14:53:09 WORKER: registered result for job (4, 0, 15) with dispatcher
14:53:09 DISPATCHER: job (4, 0, 15) finished
14:53:09 DISPATCHER: register_result: lock acquired
14:53:09 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:53:09 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.00529191949813948, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.01503247407782858, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 85, 'num_filters_3': 24, 'num_filters_4': 25}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9079475792380973, 'info': {'music-speech': 0.9079475792380973, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.00529191949813948, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.01503247407782858, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 85, 'num_filters_3': 24, 'num_filters_4': 25}"}}
exception: None

14:53:09 job_callback for (4, 0, 15) started
14:53:09 DISPATCHER: Trying to submit another job.
14:53:09 job_callback for (4, 0, 15) got condition
14:53:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:53:09 done building a new model for budget 44.444444 based on 17/36 split
Best loss for this budget:-0.993850





14:53:09 HBMASTER: Trying to run another job!
14:53:09 job_callback for (4, 0, 15) finished
14:53:09 start sampling a new configuration.
14:53:09 best_vector: [2, 1, 0.2750971018701143, 0.09769549549679676, 0.7756332358145863, 1, 0.4164766248598279, 0.17669623301926135, 2, 2, 1, 2, 0.8535348470382458, 0.8130984449475869, 0.6069985950742116, 0.2230226290193062], 0.001300877549732326, 0.0039172696450208025, 5.09588813745548e-06
14:53:09 done sampling a new configuration.
14:53:09 HBMASTER: schedule new run for iteration 4
14:53:09 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
14:53:09 HBMASTER: submitting job (4, 0, 16) to dispatcher
14:53:09 DISPATCHER: trying to submit job (4, 0, 16)
14:53:09 DISPATCHER: trying to notify the job_runner thread.
14:53:09 HBMASTER: job (4, 0, 16) submitted to dispatcher
14:53:09 DISPATCHER: Trying to submit another job.
14:53:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:53:09 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:53:09 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:53:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:53:09 WORKER: start processing job (4, 0, 16)
14:53:09 WORKER: args: ()
14:53:09 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0035497208684275644, 'num_filters_1': 19, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.01697802228447983, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 94, 'num_filters_3': 87, 'num_filters_4': 56}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:54:03 WORKER: done with job (4, 0, 16), trying to register it.
14:54:03 WORKER: registered result for job (4, 0, 16) with dispatcher
14:54:03 DISPATCHER: job (4, 0, 16) finished
14:54:03 DISPATCHER: register_result: lock acquired
14:54:03 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:54:03 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0035497208684275644, 'num_filters_1': 19, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.01697802228447983, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 94, 'num_filters_3': 87, 'num_filters_4': 56}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9201473295258255, 'info': {'music-speech': 0.9201473295258255, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0035497208684275644, 'num_filters_1': 19, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.01697802228447983, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 94, 'num_filters_3': 87, 'num_filters_4': 56}"}}
exception: None

14:54:03 job_callback for (4, 0, 16) started
14:54:03 DISPATCHER: Trying to submit another job.
14:54:03 job_callback for (4, 0, 16) got condition
14:54:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:54:03 done building a new model for budget 44.444444 based on 17/37 split
Best loss for this budget:-0.993850





14:54:03 HBMASTER: Trying to run another job!
14:54:03 job_callback for (4, 0, 16) finished
14:54:03 start sampling a new configuration.
14:54:03 done sampling a new configuration.
14:54:03 HBMASTER: schedule new run for iteration 4
14:54:03 HBMASTER: trying submitting job (4, 0, 17) to dispatcher
14:54:03 HBMASTER: submitting job (4, 0, 17) to dispatcher
14:54:03 DISPATCHER: trying to submit job (4, 0, 17)
14:54:03 DISPATCHER: trying to notify the job_runner thread.
14:54:03 HBMASTER: job (4, 0, 17) submitted to dispatcher
14:54:03 DISPATCHER: Trying to submit another job.
14:54:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:54:03 DISPATCHER: starting job (4, 0, 17) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:54:03 DISPATCHER: job (4, 0, 17) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:54:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:54:03 WORKER: start processing job (4, 0, 17)
14:54:03 WORKER: args: ()
14:54:03 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.06906327551023334, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.07434012136717626, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 27, 'num_filters_3': 58, 'num_filters_4': 30}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:54:03 DISPATCHER: Starting worker discovery
14:54:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:54:03 DISPATCHER: Finished worker discovery
Exception in thread Thread-684:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

14:54:56 WORKER: done with job (4, 0, 17), trying to register it.
14:54:56 WORKER: registered result for job (4, 0, 17) with dispatcher
14:54:56 DISPATCHER: job (4, 0, 17) finished
14:54:56 DISPATCHER: register_result: lock acquired
14:54:56 DISPATCHER: job (4, 0, 17) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:54:56 job_id: (4, 0, 17)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.06906327551023334, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.07434012136717626, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 27, 'num_filters_3': 58, 'num_filters_4': 30}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.2966469094949382, 'info': {'music-speech': 0.2966469094949382, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.06906327551023334, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 27, 'weight_decay': 0.07434012136717626, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 27, 'num_filters_3': 58, 'num_filters_4': 30}"}}
exception: None

14:54:56 job_callback for (4, 0, 17) started
14:54:56 DISPATCHER: Trying to submit another job.
14:54:56 job_callback for (4, 0, 17) got condition
14:54:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:54:56 done building a new model for budget 44.444444 based on 17/38 split
Best loss for this budget:-0.993850





14:54:56 HBMASTER: Trying to run another job!
14:54:56 job_callback for (4, 0, 17) finished
14:54:56 start sampling a new configuration.
14:54:56 done sampling a new configuration.
14:54:56 HBMASTER: schedule new run for iteration 4
14:54:56 HBMASTER: trying submitting job (4, 0, 18) to dispatcher
14:54:56 HBMASTER: submitting job (4, 0, 18) to dispatcher
14:54:56 DISPATCHER: trying to submit job (4, 0, 18)
14:54:56 DISPATCHER: trying to notify the job_runner thread.
14:54:56 HBMASTER: job (4, 0, 18) submitted to dispatcher
14:54:56 DISPATCHER: Trying to submit another job.
14:54:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:54:56 DISPATCHER: starting job (4, 0, 18) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:54:56 DISPATCHER: job (4, 0, 18) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:54:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:54:56 WORKER: start processing job (4, 0, 18)
14:54:56 WORKER: args: ()
14:54:56 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003195072317944172, 'num_filters_1': 35, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.012990480663036567, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 37, 'num_filters_3': 60, 'num_filters_4': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:55:03 DISPATCHER: Starting worker discovery
14:55:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:55:03 DISPATCHER: Finished worker discovery
14:55:49 WORKER: done with job (4, 0, 18), trying to register it.
14:55:49 WORKER: registered result for job (4, 0, 18) with dispatcher
14:55:49 DISPATCHER: job (4, 0, 18) finished
14:55:49 DISPATCHER: register_result: lock acquired
14:55:49 DISPATCHER: job (4, 0, 18) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:55:49 job_id: (4, 0, 18)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003195072317944172, 'num_filters_1': 35, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.012990480663036567, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 37, 'num_filters_3': 60, 'num_filters_4': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8404302925693857, 'info': {'music-speech': 0.8404302925693857, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.003195072317944172, 'num_filters_1': 35, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 12, 'weight_decay': 0.012990480663036567, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 37, 'num_filters_3': 60, 'num_filters_4': 26}"}}
exception: None

14:55:49 job_callback for (4, 0, 18) started
14:55:49 job_callback for (4, 0, 18) got condition
14:55:49 DISPATCHER: Trying to submit another job.
14:55:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:55:49 done building a new model for budget 44.444444 based on 17/39 split
Best loss for this budget:-0.993850





14:55:49 HBMASTER: Trying to run another job!
14:55:49 job_callback for (4, 0, 18) finished
14:55:49 start sampling a new configuration.
14:55:49 done sampling a new configuration.
14:55:49 HBMASTER: schedule new run for iteration 4
14:55:49 HBMASTER: trying submitting job (4, 0, 19) to dispatcher
14:55:49 HBMASTER: submitting job (4, 0, 19) to dispatcher
14:55:49 DISPATCHER: trying to submit job (4, 0, 19)
14:55:49 DISPATCHER: trying to notify the job_runner thread.
14:55:49 HBMASTER: job (4, 0, 19) submitted to dispatcher
14:55:49 DISPATCHER: Trying to submit another job.
14:55:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:55:49 DISPATCHER: starting job (4, 0, 19) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:55:49 DISPATCHER: job (4, 0, 19) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:55:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:55:49 WORKER: start processing job (4, 0, 19)
14:55:49 WORKER: args: ()
14:55:49 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0018844625535543883, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.08912184314257109, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 17, 'num_filters_3': 52}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:56:03 DISPATCHER: Starting worker discovery
14:56:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:56:03 DISPATCHER: Finished worker discovery
14:56:42 WORKER: done with job (4, 0, 19), trying to register it.
14:56:42 DISPATCHER: job (4, 0, 19) finished
14:56:42 WORKER: registered result for job (4, 0, 19) with dispatcher
14:56:42 DISPATCHER: register_result: lock acquired
14:56:42 DISPATCHER: job (4, 0, 19) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:56:42 job_id: (4, 0, 19)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0018844625535543883, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.08912184314257109, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 17, 'num_filters_3': 52}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6023495318852622, 'info': {'music-speech': 0.6023495318852622, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0018844625535543883, 'num_filters_1': 20, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 23, 'weight_decay': 0.08912184314257109, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 17, 'num_filters_3': 52}"}}
exception: None

14:56:42 job_callback for (4, 0, 19) started
14:56:42 DISPATCHER: Trying to submit another job.
14:56:42 job_callback for (4, 0, 19) got condition
14:56:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:56:42 done building a new model for budget 44.444444 based on 17/39 split
Best loss for this budget:-0.993850





14:56:42 HBMASTER: Trying to run another job!
14:56:42 job_callback for (4, 0, 19) finished
14:56:42 start sampling a new configuration.
14:56:42 best_vector: [0, 0, 0.6328492252478087, 0.07118695606174485, 0.9610654527402362, 1, 0.47371087140419593, 0.04487152787683524, 1, 1, 1, 2, 0.5573980074875247, 0.6046979044835905, 0.8746016725263592, 0.009936157990810157], 0.0022100811190543107, 0.0005766580329178179, 1.2744610307026684e-06
14:56:42 done sampling a new configuration.
14:56:42 HBMASTER: schedule new run for iteration 4
14:56:42 HBMASTER: trying submitting job (4, 0, 20) to dispatcher
14:56:42 HBMASTER: submitting job (4, 0, 20) to dispatcher
14:56:42 DISPATCHER: trying to submit job (4, 0, 20)
14:56:42 DISPATCHER: trying to notify the job_runner thread.
14:56:42 HBMASTER: job (4, 0, 20) submitted to dispatcher
14:56:42 DISPATCHER: Trying to submit another job.
14:56:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:56:42 DISPATCHER: starting job (4, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:56:42 DISPATCHER: job (4, 0, 20) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:56:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:56:42 WORKER: start processing job (4, 0, 20)
14:56:42 WORKER: args: ()
14:56:42 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.018437347895619023, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.011438766734570716, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 50, 'num_filters_3': 56, 'num_filters_4': 99, 'num_filters_5': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-687:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

14:57:03 DISPATCHER: Starting worker discovery
14:57:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:57:03 DISPATCHER: Finished worker discovery
14:57:36 WORKER: done with job (4, 0, 20), trying to register it.
14:57:36 DISPATCHER: job (4, 0, 20) finished
14:57:36 WORKER: registered result for job (4, 0, 20) with dispatcher
14:57:36 DISPATCHER: register_result: lock acquired
14:57:36 DISPATCHER: job (4, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:57:36 job_id: (4, 0, 20)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.018437347895619023, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.011438766734570716, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 50, 'num_filters_3': 56, 'num_filters_4': 99, 'num_filters_5': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6356042427959563, 'info': {'music-speech': 0.6356042427959563, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.018437347895619023, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.011438766734570716, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 50, 'num_filters_3': 56, 'num_filters_4': 99, 'num_filters_5': 16}"}}
exception: None

14:57:36 job_callback for (4, 0, 20) started
14:57:36 DISPATCHER: Trying to submit another job.
14:57:36 job_callback for (4, 0, 20) got condition
14:57:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:57:36 done building a new model for budget 44.444444 based on 17/40 split
Best loss for this budget:-0.993850





14:57:36 HBMASTER: Trying to run another job!
14:57:36 job_callback for (4, 0, 20) finished
14:57:36 start sampling a new configuration.
14:57:36 done sampling a new configuration.
14:57:36 HBMASTER: schedule new run for iteration 4
14:57:36 HBMASTER: trying submitting job (4, 0, 21) to dispatcher
14:57:36 HBMASTER: submitting job (4, 0, 21) to dispatcher
14:57:36 DISPATCHER: trying to submit job (4, 0, 21)
14:57:36 DISPATCHER: trying to notify the job_runner thread.
14:57:36 HBMASTER: job (4, 0, 21) submitted to dispatcher
14:57:36 DISPATCHER: Trying to submit another job.
14:57:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:57:36 DISPATCHER: starting job (4, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:57:36 DISPATCHER: job (4, 0, 21) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:57:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:57:36 WORKER: start processing job (4, 0, 21)
14:57:36 WORKER: args: ()
14:57:36 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.021626459405606976, 'num_filters_1': 36, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.1246340503257775, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 26, 'num_filters_3': 49}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:58:03 DISPATCHER: Starting worker discovery
14:58:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:58:03 DISPATCHER: Finished worker discovery
14:58:29 WORKER: done with job (4, 0, 21), trying to register it.
14:58:29 WORKER: registered result for job (4, 0, 21) with dispatcher
14:58:29 DISPATCHER: job (4, 0, 21) finished
14:58:29 DISPATCHER: register_result: lock acquired
14:58:29 DISPATCHER: job (4, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:58:29 job_id: (4, 0, 21)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.021626459405606976, 'num_filters_1': 36, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.1246340503257775, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 26, 'num_filters_3': 49}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.009449440674490836, 'info': {'music-speech': 0.009449440674490836, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.021626459405606976, 'num_filters_1': 36, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 94, 'weight_decay': 0.1246340503257775, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 26, 'num_filters_3': 49}"}}
exception: None

14:58:29 job_callback for (4, 0, 21) started
14:58:29 job_callback for (4, 0, 21) got condition
14:58:29 DISPATCHER: Trying to submit another job.
14:58:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:58:29 done building a new model for budget 44.444444 based on 17/41 split
Best loss for this budget:-0.993850





14:58:29 HBMASTER: Trying to run another job!
14:58:29 job_callback for (4, 0, 21) finished
14:58:29 start sampling a new configuration.
14:58:30 best_vector: [0, 2, 0.11499774171102736, 0.3357192901953763, 0.7540718072788365, 1, 0.3429402949801774, 0.24273379181752575, 2, 1, 1, 2, 0.86941994160185, 0.7602734188591347, 0.04388725766258475, 0.35565870740782685], 0.003354162403051045, 0.006658222201764153, 2.2332758580317074e-05
14:58:30 done sampling a new configuration.
14:58:30 HBMASTER: schedule new run for iteration 4
14:58:30 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
14:58:30 HBMASTER: submitting job (4, 0, 22) to dispatcher
14:58:30 DISPATCHER: trying to submit job (4, 0, 22)
14:58:30 DISPATCHER: trying to notify the job_runner thread.
14:58:30 HBMASTER: job (4, 0, 22) submitted to dispatcher
14:58:30 DISPATCHER: Trying to submit another job.
14:58:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:58:30 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:58:30 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:58:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:58:30 WORKER: start processing job (4, 0, 22)
14:58:30 WORKER: args: ()
14:58:30 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0016982259911506729, 'num_filters_1': 32, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.02069207024703155, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 97, 'num_filters_3': 77, 'num_filters_4': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:59:03 DISPATCHER: Starting worker discovery
14:59:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:59:03 DISPATCHER: Finished worker discovery
14:59:23 WORKER: done with job (4, 0, 22), trying to register it.
14:59:23 WORKER: registered result for job (4, 0, 22) with dispatcher
14:59:23 DISPATCHER: job (4, 0, 22) finished
14:59:23 DISPATCHER: register_result: lock acquired
14:59:23 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:59:23 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0016982259911506729, 'num_filters_1': 32, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.02069207024703155, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 97, 'num_filters_3': 77, 'num_filters_4': 17}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8448008240000777, 'info': {'music-speech': 0.8448008240000777, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0016982259911506729, 'num_filters_1': 32, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.02069207024703155, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 97, 'num_filters_3': 77, 'num_filters_4': 17}"}}
exception: None

14:59:23 job_callback for (4, 0, 22) started
14:59:23 job_callback for (4, 0, 22) got condition
14:59:23 DISPATCHER: Trying to submit another job.
14:59:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:59:23 done building a new model for budget 44.444444 based on 17/42 split
Best loss for this budget:-0.993850





14:59:23 HBMASTER: Trying to run another job!
14:59:23 job_callback for (4, 0, 22) finished
14:59:23 start sampling a new configuration.
14:59:23 done sampling a new configuration.
14:59:23 HBMASTER: schedule new run for iteration 4
14:59:23 HBMASTER: trying submitting job (4, 0, 23) to dispatcher
14:59:23 HBMASTER: submitting job (4, 0, 23) to dispatcher
14:59:23 DISPATCHER: trying to submit job (4, 0, 23)
14:59:23 DISPATCHER: trying to notify the job_runner thread.
14:59:23 HBMASTER: job (4, 0, 23) submitted to dispatcher
14:59:23 DISPATCHER: Trying to submit another job.
14:59:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:59:23 DISPATCHER: starting job (4, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:59:23 DISPATCHER: job (4, 0, 23) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:59:23 WORKER: start processing job (4, 0, 23)
14:59:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:59:23 WORKER: args: ()
14:59:23 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0011030465472813052, 'num_filters_1': 47, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.0809914061094872}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:00:03 DISPATCHER: Starting worker discovery
15:00:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:00:03 DISPATCHER: Finished worker discovery
15:00:16 WORKER: done with job (4, 0, 23), trying to register it.
15:00:16 WORKER: registered result for job (4, 0, 23) with dispatcher
15:00:16 DISPATCHER: job (4, 0, 23) finished
15:00:16 DISPATCHER: register_result: lock acquired
15:00:16 DISPATCHER: job (4, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
15:00:16 job_id: (4, 0, 23)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0011030465472813052, 'num_filters_1': 47, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.0809914061094872}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.48327662609970296, 'info': {'music-speech': 0.48327662609970296, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.0011030465472813052, 'num_filters_1': 47, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.0809914061094872}"}}
exception: None

15:00:16 job_callback for (4, 0, 23) started
15:00:16 job_callback for (4, 0, 23) got condition
15:00:16 DISPATCHER: Trying to submit another job.
15:00:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:00:16 done building a new model for budget 44.444444 based on 17/43 split
Best loss for this budget:-0.993850





15:00:16 HBMASTER: Trying to run another job!
15:00:16 job_callback for (4, 0, 23) finished
15:00:16 start sampling a new configuration.
15:00:16 best_vector: [0, 0, 0.21028605916050436, 0.02282694045389219, 0.6552547758128985, 1, 0.8086228944275742, 0.10579020427649428, 2, 0, 1, 2, 0.8885375348214991, 0.7745207747176076, 0.20841445739650405, 0.1521998287766734], 0.00025979322467346627, 0.0022651027525586232, 5.884583483039493e-07
15:00:16 done sampling a new configuration.
15:00:16 HBMASTER: schedule new run for iteration 4
15:00:16 HBMASTER: trying submitting job (4, 0, 24) to dispatcher
15:00:16 HBMASTER: submitting job (4, 0, 24) to dispatcher
15:00:16 DISPATCHER: trying to submit job (4, 0, 24)
15:00:16 DISPATCHER: trying to notify the job_runner thread.
15:00:16 HBMASTER: job (4, 0, 24) submitted to dispatcher
15:00:16 DISPATCHER: Trying to submit another job.
15:00:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:00:16 DISPATCHER: starting job (4, 0, 24) on hpbandster.run_0.worker.metagpul.22021139727314577216
15:00:16 DISPATCHER: job (4, 0, 24) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
15:00:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:00:16 WORKER: start processing job (4, 0, 24)
15:00:16 WORKER: args: ()
15:00:16 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002633735261677957, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.013728915405670962, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 102, 'num_filters_3': 80, 'num_filters_4': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:01:03 DISPATCHER: Starting worker discovery
15:01:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:01:03 DISPATCHER: Finished worker discovery
15:01:10 WORKER: done with job (4, 0, 24), trying to register it.
15:01:10 DISPATCHER: job (4, 0, 24) finished
15:01:10 WORKER: registered result for job (4, 0, 24) with dispatcher
15:01:10 DISPATCHER: register_result: lock acquired
15:01:10 DISPATCHER: job (4, 0, 24) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
15:01:10 job_id: (4, 0, 24)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002633735261677957, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.013728915405670962, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 102, 'num_filters_3': 80, 'num_filters_4': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7491619779570838, 'info': {'music-speech': 0.7491619779570838, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002633735261677957, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.013728915405670962, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 102, 'num_filters_3': 80, 'num_filters_4': 24}"}}
exception: None

15:01:10 job_callback for (4, 0, 24) started
15:01:10 DISPATCHER: Trying to submit another job.
15:01:10 job_callback for (4, 0, 24) got condition
15:01:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:01:10 done building a new model for budget 44.444444 based on 17/44 split
Best loss for this budget:-0.993850





15:01:10 HBMASTER: Trying to run another job!
15:01:10 job_callback for (4, 0, 24) finished
15:01:10 start sampling a new configuration.
15:01:10 done sampling a new configuration.
15:01:10 HBMASTER: schedule new run for iteration 4
15:01:10 HBMASTER: trying submitting job (4, 0, 25) to dispatcher
15:01:10 HBMASTER: submitting job (4, 0, 25) to dispatcher
15:01:10 DISPATCHER: trying to submit job (4, 0, 25)
15:01:10 DISPATCHER: trying to notify the job_runner thread.
15:01:10 HBMASTER: job (4, 0, 25) submitted to dispatcher
15:01:10 DISPATCHER: Trying to submit another job.
15:01:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:01:10 DISPATCHER: starting job (4, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216
15:01:10 DISPATCHER: job (4, 0, 25) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
15:01:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:01:10 WORKER: start processing job (4, 0, 25)
15:01:10 WORKER: args: ()
15:01:10 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0010985564764730536, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.01111055450042851, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 16, 'num_filters_3': 88, 'num_filters_4': 25, 'num_filters_5': 52}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:02:03 DISPATCHER: Starting worker discovery
15:02:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:02:03 DISPATCHER: Finished worker discovery
15:02:04 WORKER: done with job (4, 0, 25), trying to register it.
15:02:04 WORKER: registered result for job (4, 0, 25) with dispatcher
15:02:04 DISPATCHER: job (4, 0, 25) finished
15:02:04 DISPATCHER: register_result: lock acquired
15:02:04 DISPATCHER: job (4, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
15:02:04 job_id: (4, 0, 25)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0010985564764730536, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.01111055450042851, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 16, 'num_filters_3': 88, 'num_filters_4': 25, 'num_filters_5': 52}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8380650328833564, 'info': {'music-speech': 0.8380650328833564, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0010985564764730536, 'num_filters_1': 36, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.01111055450042851, 'kernel_size_2': 5, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 16, 'num_filters_3': 88, 'num_filters_4': 25, 'num_filters_5': 52}"}}
exception: None

15:02:04 job_callback for (4, 0, 25) started
15:02:04 DISPATCHER: Trying to submit another job.
15:02:04 job_callback for (4, 0, 25) got condition
15:02:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:02:04 done building a new model for budget 44.444444 based on 17/45 split
Best loss for this budget:-0.993850





15:02:04 HBMASTER: Trying to run another job!
15:02:04 job_callback for (4, 0, 25) finished
15:02:04 start sampling a new configuration.
15:02:04 best_vector: [2, 1, 0.17025953251123158, 0.04749928354876855, 0.7547444693651069, 1, 0.7120126928193495, 0.05035812837607745, 0, 2, 1, 2, 0.49647753977694253, 0.047617497562983, 0.059957273800864345, 0.12351573927340768], 0.0005312613430263292, 0.009453952857856837, 5.022519692172627e-06
15:02:04 done sampling a new configuration.
15:02:04 HBMASTER: schedule new run for iteration 4
15:02:04 HBMASTER: trying submitting job (4, 0, 26) to dispatcher
15:02:04 HBMASTER: submitting job (4, 0, 26) to dispatcher
15:02:04 DISPATCHER: trying to submit job (4, 0, 26)
15:02:04 DISPATCHER: trying to notify the job_runner thread.
15:02:04 HBMASTER: job (4, 0, 26) submitted to dispatcher
15:02:04 DISPATCHER: Trying to submit another job.
15:02:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:02:04 DISPATCHER: starting job (4, 0, 26) on hpbandster.run_0.worker.metagpul.22021139727314577216
15:02:04 DISPATCHER: job (4, 0, 26) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
15:02:04 WORKER: start processing job (4, 0, 26)
15:02:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:02:04 WORKER: args: ()
15:02:04 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0021903779810028465, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.01162833234123823, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 44, 'num_filters_3': 17, 'num_filters_4': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
15:02:58 WORKER: done with job (4, 0, 26), trying to register it.
15:02:58 WORKER: registered result for job (4, 0, 26) with dispatcher
15:02:58 DISPATCHER: job (4, 0, 26) finished
15:02:58 DISPATCHER: register_result: lock acquired
15:02:58 DISPATCHER: job (4, 0, 26) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
15:02:58 job_id: (4, 0, 26)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0021903779810028465, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.01162833234123823, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 44, 'num_filters_3': 17, 'num_filters_4': 18}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8041032777704633, 'info': {'music-speech': 0.8041032777704633, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0021903779810028465, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 74, 'weight_decay': 0.01162833234123823, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 44, 'num_filters_3': 17, 'num_filters_4': 18}"}}
exception: None

15:02:58 job_callback for (4, 0, 26) started
15:02:58 job_callback for (4, 0, 26) got condition
15:02:58 DISPATCHER: Trying to submit another job.
15:02:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:02:58 done building a new model for budget 44.444444 based on 17/45 split
Best loss for this budget:-0.993850





15:02:58 HBMASTER: Trying to run another job!
15:02:58 job_callback for (4, 0, 26) finished
15:02:58 ITERATION: Advancing config (4, 0, 0) to next budget 133.333333
15:02:58 ITERATION: Advancing config (4, 0, 1) to next budget 133.333333
15:02:58 ITERATION: Advancing config (4, 0, 5) to next budget 133.333333
15:02:58 ITERATION: Advancing config (4, 0, 7) to next budget 133.333333
15:02:58 ITERATION: Advancing config (4, 0, 10) to next budget 133.333333
15:02:58 ITERATION: Advancing config (4, 0, 12) to next budget 133.333333
15:02:58 ITERATION: Advancing config (4, 0, 15) to next budget 133.333333
15:02:58 ITERATION: Advancing config (4, 0, 16) to next budget 133.333333
15:02:58 ITERATION: Advancing config (4, 0, 22) to next budget 133.333333
15:02:58 HBMASTER: schedule new run for iteration 4
15:02:58 HBMASTER: trying submitting job (4, 0, 0) to dispatcher
15:02:58 HBMASTER: submitting job (4, 0, 0) to dispatcher
15:02:58 DISPATCHER: trying to submit job (4, 0, 0)
15:02:58 DISPATCHER: trying to notify the job_runner thread.
15:02:58 HBMASTER: job (4, 0, 0) submitted to dispatcher
15:02:58 DISPATCHER: Trying to submit another job.
15:02:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:02:58 DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
15:02:58 DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
15:02:58 WORKER: start processing job (4, 0, 0)
15:02:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:02:58 WORKER: args: ()
15:02:58 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0019755857740739965, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.02438709303401629, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 43, 'num_filters_3': 52, 'num_filters_4': 113, 'num_filters_5': 21}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:03:03 DISPATCHER: Starting worker discovery
15:03:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:03:03 DISPATCHER: Finished worker discovery
15:04:03 DISPATCHER: Starting worker discovery
15:04:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:04:03 DISPATCHER: Finished worker discovery
15:05:03 DISPATCHER: Starting worker discovery
15:05:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:05:03 DISPATCHER: Finished worker discovery
15:05:21 WORKER: done with job (4, 0, 0), trying to register it.
15:05:21 WORKER: registered result for job (4, 0, 0) with dispatcher
15:05:21 DISPATCHER: job (4, 0, 0) finished
15:05:21 DISPATCHER: register_result: lock acquired
15:05:21 DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
15:05:21 job_id: (4, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0019755857740739965, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.02438709303401629, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 43, 'num_filters_3': 52, 'num_filters_4': 113, 'num_filters_5': 21}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7019007200445331, 'info': {'music-speech': 0.7019007200445331, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.0019755857740739965, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 73, 'weight_decay': 0.02438709303401629, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 43, 'num_filters_3': 52, 'num_filters_4': 113, 'num_filters_5': 21}"}}
exception: None

15:05:21 job_callback for (4, 0, 0) started
15:05:21 job_callback for (4, 0, 0) got condition
15:05:21 DISPATCHER: Trying to submit another job.
15:05:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:05:21 HBMASTER: Trying to run another job!
15:05:21 job_callback for (4, 0, 0) finished
15:05:21 HBMASTER: schedule new run for iteration 4
15:05:21 HBMASTER: trying submitting job (4, 0, 1) to dispatcher
15:05:21 HBMASTER: submitting job (4, 0, 1) to dispatcher
15:05:21 DISPATCHER: trying to submit job (4, 0, 1)
15:05:21 DISPATCHER: trying to notify the job_runner thread.
15:05:21 HBMASTER: job (4, 0, 1) submitted to dispatcher
15:05:21 DISPATCHER: Trying to submit another job.
15:05:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:05:21 DISPATCHER: starting job (4, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
15:05:21 DISPATCHER: job (4, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
15:05:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:05:21 WORKER: start processing job (4, 0, 1)
15:05:21 WORKER: args: ()
15:05:21 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.011988808063322285, 'num_filters_1': 65, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.06177496009036832, 'kernel_size_2': 3, 'num_filters_2': 85}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-695:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

15:06:03 DISPATCHER: Starting worker discovery
15:06:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:06:03 DISPATCHER: Finished worker discovery
15:07:03 DISPATCHER: Starting worker discovery
15:07:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:07:03 DISPATCHER: Finished worker discovery
15:07:43 WORKER: done with job (4, 0, 1), trying to register it.
15:07:43 DISPATCHER: job (4, 0, 1) finished
15:07:43 WORKER: registered result for job (4, 0, 1) with dispatcher
15:07:43 DISPATCHER: register_result: lock acquired
15:07:43 DISPATCHER: job (4, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
15:07:43 job_id: (4, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.011988808063322285, 'num_filters_1': 65, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.06177496009036832, 'kernel_size_2': 3, 'num_filters_2': 85}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.007609710499500019, 'info': {'music-speech': 0.007609710499500019, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.011988808063322285, 'num_filters_1': 65, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.06177496009036832, 'kernel_size_2': 3, 'num_filters_2': 85}"}}
exception: None

15:07:43 job_callback for (4, 0, 1) started
15:07:43 DISPATCHER: Trying to submit another job.
15:07:43 job_callback for (4, 0, 1) got condition
15:07:43 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:07:43 HBMASTER: Trying to run another job!
15:07:43 job_callback for (4, 0, 1) finished
15:07:43 HBMASTER: schedule new run for iteration 4
15:07:43 HBMASTER: trying submitting job (4, 0, 5) to dispatcher
15:07:43 HBMASTER: submitting job (4, 0, 5) to dispatcher
15:07:43 DISPATCHER: trying to submit job (4, 0, 5)
15:07:43 DISPATCHER: trying to notify the job_runner thread.
15:07:43 HBMASTER: job (4, 0, 5) submitted to dispatcher
15:07:43 DISPATCHER: Trying to submit another job.
15:07:43 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:07:43 DISPATCHER: starting job (4, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
15:07:43 DISPATCHER: job (4, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
15:07:43 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:07:43 WORKER: start processing job (4, 0, 5)
15:07:43 WORKER: args: ()
15:07:43 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.017705029813328495, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.017270919489236286, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 95, 'num_filters_3': 117, 'num_filters_4': 85}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-696:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

15:08:03 DISPATCHER: Starting worker discovery
15:08:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:08:03 DISPATCHER: Finished worker discovery
15:09:03 DISPATCHER: Starting worker discovery
15:09:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:09:03 DISPATCHER: Finished worker discovery
15:10:03 DISPATCHER: Starting worker discovery
15:10:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:10:03 DISPATCHER: Finished worker discovery
15:10:05 WORKER: done with job (4, 0, 5), trying to register it.
15:10:05 WORKER: registered result for job (4, 0, 5) with dispatcher
15:10:05 DISPATCHER: job (4, 0, 5) finished
15:10:05 DISPATCHER: register_result: lock acquired
15:10:05 DISPATCHER: job (4, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
15:10:05 job_id: (4, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.017705029813328495, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.017270919489236286, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 95, 'num_filters_3': 117, 'num_filters_4': 85}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4987325948887636, 'info': {'music-speech': 0.4987325948887636, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.017705029813328495, 'num_filters_1': 20, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.017270919489236286, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 95, 'num_filters_3': 117, 'num_filters_4': 85}"}}
exception: None

15:10:05 job_callback for (4, 0, 5) started
15:10:05 DISPATCHER: Trying to submit another job.
15:10:05 job_callback for (4, 0, 5) got condition
15:10:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:10:05 HBMASTER: Trying to run another job!
15:10:05 job_callback for (4, 0, 5) finished
15:10:05 HBMASTER: schedule new run for iteration 4
15:10:05 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
15:10:05 HBMASTER: submitting job (4, 0, 7) to dispatcher
15:10:05 DISPATCHER: trying to submit job (4, 0, 7)
15:10:05 DISPATCHER: trying to notify the job_runner thread.
15:10:05 HBMASTER: job (4, 0, 7) submitted to dispatcher
15:10:05 DISPATCHER: Trying to submit another job.
15:10:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:10:05 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
15:10:05 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
15:10:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:10:05 WORKER: start processing job (4, 0, 7)
15:10:05 WORKER: args: ()
15:10:05 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0013440639443655818, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.016694153434981165, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 35, 'num_filters_3': 27, 'num_filters_4': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:11:03 DISPATCHER: Starting worker discovery
15:11:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:11:03 DISPATCHER: Finished worker discovery
15:12:03 DISPATCHER: Starting worker discovery
15:12:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:12:04 DISPATCHER: Finished worker discovery
15:12:27 WORKER: done with job (4, 0, 7), trying to register it.
15:12:27 WORKER: registered result for job (4, 0, 7) with dispatcher
15:12:27 DISPATCHER: job (4, 0, 7) finished
15:12:27 DISPATCHER: register_result: lock acquired
15:12:27 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
15:12:27 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0013440639443655818, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.016694153434981165, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 35, 'num_filters_3': 27, 'num_filters_4': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9159967194273989, 'info': {'music-speech': 0.9159967194273989, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0013440639443655818, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.016694153434981165, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 35, 'num_filters_3': 27, 'num_filters_4': 17}"}}
exception: None

15:12:27 job_callback for (4, 0, 7) started
15:12:27 job_callback for (4, 0, 7) got condition
15:12:27 DISPATCHER: Trying to submit another job.
15:12:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:12:27 HBMASTER: Trying to run another job!
15:12:27 job_callback for (4, 0, 7) finished
15:12:27 HBMASTER: schedule new run for iteration 4
15:12:27 HBMASTER: trying submitting job (4, 0, 10) to dispatcher
15:12:27 HBMASTER: submitting job (4, 0, 10) to dispatcher
15:12:27 DISPATCHER: trying to submit job (4, 0, 10)
15:12:27 DISPATCHER: trying to notify the job_runner thread.
15:12:27 HBMASTER: job (4, 0, 10) submitted to dispatcher
15:12:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:12:27 DISPATCHER: Trying to submit another job.
15:12:27 DISPATCHER: starting job (4, 0, 10) on hpbandster.run_0.worker.metagpul.22021139727314577216
15:12:27 DISPATCHER: job (4, 0, 10) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
15:12:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:12:27 WORKER: start processing job (4, 0, 10)
15:12:27 WORKER: args: ()
15:12:27 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0024521296600740444, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.04680502803810719, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 42, 'num_filters_3': 16, 'num_filters_4': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:13:04 DISPATCHER: Starting worker discovery
15:13:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:13:04 DISPATCHER: Finished worker discovery
15:14:04 DISPATCHER: Starting worker discovery
15:14:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:14:04 DISPATCHER: Finished worker discovery
15:14:50 WORKER: done with job (4, 0, 10), trying to register it.
15:14:50 WORKER: registered result for job (4, 0, 10) with dispatcher
15:14:50 DISPATCHER: job (4, 0, 10) finished
15:14:50 DISPATCHER: register_result: lock acquired
15:14:50 DISPATCHER: job (4, 0, 10) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
15:14:50 job_id: (4, 0, 10)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0024521296600740444, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.04680502803810719, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 42, 'num_filters_3': 16, 'num_filters_4': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5786889640090417, 'info': {'music-speech': 0.5786889640090417, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0024521296600740444, 'num_filters_1': 18, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.04680502803810719, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 42, 'num_filters_3': 16, 'num_filters_4': 17}"}}
exception: None

15:14:50 job_callback for (4, 0, 10) started
15:14:50 job_callback for (4, 0, 10) got condition
15:14:50 DISPATCHER: Trying to submit another job.
15:14:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:14:50 HBMASTER: Trying to run another job!
15:14:50 job_callback for (4, 0, 10) finished
15:14:50 HBMASTER: schedule new run for iteration 4
15:14:50 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
15:14:50 HBMASTER: submitting job (4, 0, 12) to dispatcher
15:14:50 DISPATCHER: trying to submit job (4, 0, 12)
15:14:50 DISPATCHER: trying to notify the job_runner thread.
15:14:50 HBMASTER: job (4, 0, 12) submitted to dispatcher
15:14:50 DISPATCHER: Trying to submit another job.
15:14:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:14:50 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216
15:14:50 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
15:14:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:14:50 WORKER: start processing job (4, 0, 12)
15:14:50 WORKER: args: ()
15:14:50 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.01822106614077037, 'num_filters_1': 120, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.014032892291474556, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 37, 'num_filters_3': 16, 'num_filters_4': 17, 'num_filters_5': 19}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-699:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

15:15:04 DISPATCHER: Starting worker discovery
15:15:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:15:04 DISPATCHER: Finished worker discovery
15:16:04 DISPATCHER: Starting worker discovery
15:16:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:16:04 DISPATCHER: Finished worker discovery
15:17:04 DISPATCHER: Starting worker discovery
15:17:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:17:04 DISPATCHER: Finished worker discovery
15:17:12 WORKER: done with job (4, 0, 12), trying to register it.
15:17:12 WORKER: registered result for job (4, 0, 12) with dispatcher
15:17:12 DISPATCHER: job (4, 0, 12) finished
15:17:12 DISPATCHER: register_result: lock acquired
15:17:12 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
15:17:12 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.01822106614077037, 'num_filters_1': 120, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.014032892291474556, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 37, 'num_filters_3': 16, 'num_filters_4': 17, 'num_filters_5': 19}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7745719566472086, 'info': {'music-speech': 0.7745719566472086, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.01822106614077037, 'num_filters_1': 120, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.014032892291474556, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 37, 'num_filters_3': 16, 'num_filters_4': 17, 'num_filters_5': 19}"}}
exception: None

15:17:12 job_callback for (4, 0, 12) started
15:17:12 DISPATCHER: Trying to submit another job.
15:17:12 job_callback for (4, 0, 12) got condition
15:17:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:17:12 HBMASTER: Trying to run another job!
15:17:12 job_callback for (4, 0, 12) finished
15:17:12 HBMASTER: schedule new run for iteration 4
15:17:12 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
15:17:12 HBMASTER: submitting job (4, 0, 15) to dispatcher
15:17:12 DISPATCHER: trying to submit job (4, 0, 15)
15:17:12 DISPATCHER: trying to notify the job_runner thread.
15:17:12 HBMASTER: job (4, 0, 15) submitted to dispatcher
15:17:12 DISPATCHER: Trying to submit another job.
15:17:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:17:12 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216
15:17:12 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
15:17:12 WORKER: start processing job (4, 0, 15)
15:17:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:17:12 WORKER: args: ()
15:17:12 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.00529191949813948, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.01503247407782858, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 85, 'num_filters_3': 24, 'num_filters_4': 25}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-700:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

15:18:04 DISPATCHER: Starting worker discovery
15:18:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:18:04 DISPATCHER: Finished worker discovery
15:19:04 DISPATCHER: Starting worker discovery
15:19:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:19:04 DISPATCHER: Finished worker discovery
15:19:34 WORKER: done with job (4, 0, 15), trying to register it.
15:19:34 WORKER: registered result for job (4, 0, 15) with dispatcher
15:19:34 DISPATCHER: job (4, 0, 15) finished
15:19:34 DISPATCHER: register_result: lock acquired
15:19:34 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
15:19:34 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.00529191949813948, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.01503247407782858, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 85, 'num_filters_3': 24, 'num_filters_4': 25}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8411221957862653, 'info': {'music-speech': 0.8411221957862653, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.00529191949813948, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.01503247407782858, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 85, 'num_filters_3': 24, 'num_filters_4': 25}"}}
exception: None

15:19:34 job_callback for (4, 0, 15) started
15:19:34 DISPATCHER: Trying to submit another job.
15:19:34 job_callback for (4, 0, 15) got condition
15:19:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:19:34 HBMASTER: Trying to run another job!
15:19:34 job_callback for (4, 0, 15) finished
15:19:34 HBMASTER: schedule new run for iteration 4
15:19:34 HBMASTER: trying submitting job (4, 0, 16) to dispatcher
15:19:34 HBMASTER: submitting job (4, 0, 16) to dispatcher
15:19:34 DISPATCHER: trying to submit job (4, 0, 16)
15:19:34 DISPATCHER: trying to notify the job_runner thread.
15:19:34 HBMASTER: job (4, 0, 16) submitted to dispatcher
15:19:34 DISPATCHER: Trying to submit another job.
15:19:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:19:34 DISPATCHER: starting job (4, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216
15:19:34 DISPATCHER: job (4, 0, 16) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
15:19:34 WORKER: start processing job (4, 0, 16)
15:19:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:19:34 WORKER: args: ()
15:19:34 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0035497208684275644, 'num_filters_1': 19, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.01697802228447983, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 94, 'num_filters_3': 87, 'num_filters_4': 56}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:20:04 DISPATCHER: Starting worker discovery
15:20:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:20:04 DISPATCHER: Finished worker discovery
15:21:04 DISPATCHER: Starting worker discovery
15:21:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:21:04 DISPATCHER: Finished worker discovery
15:21:57 WORKER: done with job (4, 0, 16), trying to register it.
15:21:57 WORKER: registered result for job (4, 0, 16) with dispatcher
15:21:57 DISPATCHER: job (4, 0, 16) finished
15:21:57 DISPATCHER: register_result: lock acquired
15:21:57 DISPATCHER: job (4, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
15:21:57 job_id: (4, 0, 16)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0035497208684275644, 'num_filters_1': 19, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.01697802228447983, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 94, 'num_filters_3': 87, 'num_filters_4': 56}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6505801473721007, 'info': {'music-speech': 0.6505801473721007, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.0035497208684275644, 'num_filters_1': 19, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 47, 'weight_decay': 0.01697802228447983, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 94, 'num_filters_3': 87, 'num_filters_4': 56}"}}
exception: None

15:21:57 job_callback for (4, 0, 16) started
15:21:57 DISPATCHER: Trying to submit another job.
15:21:57 job_callback for (4, 0, 16) got condition
15:21:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:21:57 HBMASTER: Trying to run another job!
15:21:57 job_callback for (4, 0, 16) finished
15:21:57 HBMASTER: schedule new run for iteration 4
15:21:57 HBMASTER: trying submitting job (4, 0, 22) to dispatcher
15:21:57 HBMASTER: submitting job (4, 0, 22) to dispatcher
15:21:57 DISPATCHER: trying to submit job (4, 0, 22)
15:21:57 DISPATCHER: trying to notify the job_runner thread.
15:21:57 HBMASTER: job (4, 0, 22) submitted to dispatcher
15:21:57 DISPATCHER: Trying to submit another job.
15:21:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:21:57 DISPATCHER: starting job (4, 0, 22) on hpbandster.run_0.worker.metagpul.22021139727314577216
15:21:57 DISPATCHER: job (4, 0, 22) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
15:21:57 WORKER: start processing job (4, 0, 22)
15:21:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:21:57 WORKER: args: ()
15:21:57 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0016982259911506729, 'num_filters_1': 32, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.02069207024703155, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 97, 'num_filters_3': 77, 'num_filters_4': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:22:04 DISPATCHER: Starting worker discovery
15:22:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:22:04 DISPATCHER: Finished worker discovery
15:23:04 DISPATCHER: Starting worker discovery
15:23:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:23:04 DISPATCHER: Finished worker discovery
15:24:04 DISPATCHER: Starting worker discovery
15:24:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:24:04 DISPATCHER: Finished worker discovery
15:24:19 WORKER: done with job (4, 0, 22), trying to register it.
15:24:19 WORKER: registered result for job (4, 0, 22) with dispatcher
15:24:19 DISPATCHER: job (4, 0, 22) finished
15:24:19 DISPATCHER: register_result: lock acquired
15:24:19 DISPATCHER: job (4, 0, 22) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
15:24:19 job_id: (4, 0, 22)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0016982259911506729, 'num_filters_1': 32, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.02069207024703155, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 97, 'num_filters_3': 77, 'num_filters_4': 17}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6174260789834156, 'info': {'music-speech': 0.6174260789834156, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0016982259911506729, 'num_filters_1': 32, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 41, 'weight_decay': 0.02069207024703155, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 97, 'num_filters_3': 77, 'num_filters_4': 17}"}}
exception: None

15:24:19 job_callback for (4, 0, 22) started
15:24:19 DISPATCHER: Trying to submit another job.
15:24:19 job_callback for (4, 0, 22) got condition
15:24:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:24:19 HBMASTER: Trying to run another job!
15:24:19 job_callback for (4, 0, 22) finished
15:24:19 ITERATION: Advancing config (4, 0, 7) to next budget 400.000000
15:24:19 ITERATION: Advancing config (4, 0, 12) to next budget 400.000000
15:24:19 ITERATION: Advancing config (4, 0, 15) to next budget 400.000000
15:24:19 HBMASTER: schedule new run for iteration 4
15:24:19 HBMASTER: trying submitting job (4, 0, 7) to dispatcher
15:24:19 HBMASTER: submitting job (4, 0, 7) to dispatcher
15:24:19 DISPATCHER: trying to submit job (4, 0, 7)
15:24:19 DISPATCHER: trying to notify the job_runner thread.
15:24:19 HBMASTER: job (4, 0, 7) submitted to dispatcher
15:24:19 DISPATCHER: Trying to submit another job.
15:24:19 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:24:19 DISPATCHER: starting job (4, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
15:24:19 DISPATCHER: job (4, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
15:24:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:24:19 WORKER: start processing job (4, 0, 7)
15:24:19 WORKER: args: ()
15:24:19 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0013440639443655818, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.016694153434981165, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 35, 'num_filters_3': 27, 'num_filters_4': 17}, 'budget': 400.0, 'working_directory': '.'}
15:25:04 DISPATCHER: Starting worker discovery
15:25:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:25:04 DISPATCHER: Finished worker discovery
15:26:04 DISPATCHER: Starting worker discovery
15:26:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:26:04 DISPATCHER: Finished worker discovery
15:27:04 DISPATCHER: Starting worker discovery
15:27:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:27:04 DISPATCHER: Finished worker discovery
15:28:04 DISPATCHER: Starting worker discovery
15:28:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:28:04 DISPATCHER: Finished worker discovery
15:29:04 DISPATCHER: Starting worker discovery
15:29:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:29:04 DISPATCHER: Finished worker discovery
15:30:04 DISPATCHER: Starting worker discovery
15:30:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:30:04 DISPATCHER: Finished worker discovery
15:31:04 DISPATCHER: Starting worker discovery
15:31:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:31:04 DISPATCHER: Finished worker discovery
15:31:09 WORKER: done with job (4, 0, 7), trying to register it.
15:31:09 WORKER: registered result for job (4, 0, 7) with dispatcher
15:31:09 DISPATCHER: job (4, 0, 7) finished
15:31:09 DISPATCHER: register_result: lock acquired
15:31:09 DISPATCHER: job (4, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
15:31:09 job_id: (4, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0013440639443655818, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.016694153434981165, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 35, 'num_filters_3': 27, 'num_filters_4': 17}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5590056178885537, 'info': {'music-speech': 0.5590056178885537, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0013440639443655818, 'num_filters_1': 16, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.016694153434981165, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 3, 'num_filters_2': 35, 'num_filters_3': 27, 'num_filters_4': 17}"}}
exception: None

15:31:09 job_callback for (4, 0, 7) started
15:31:09 DISPATCHER: Trying to submit another job.
15:31:09 job_callback for (4, 0, 7) got condition
15:31:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:31:09 Only 13 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
15:31:09 HBMASTER: Trying to run another job!
15:31:09 job_callback for (4, 0, 7) finished
15:31:09 HBMASTER: schedule new run for iteration 4
15:31:09 HBMASTER: trying submitting job (4, 0, 12) to dispatcher
15:31:09 HBMASTER: submitting job (4, 0, 12) to dispatcher
15:31:09 DISPATCHER: trying to submit job (4, 0, 12)
15:31:09 DISPATCHER: trying to notify the job_runner thread.
15:31:09 HBMASTER: job (4, 0, 12) submitted to dispatcher
15:31:09 DISPATCHER: Trying to submit another job.
15:31:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:31:09 DISPATCHER: starting job (4, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216
15:31:09 DISPATCHER: job (4, 0, 12) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
15:31:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:31:09 WORKER: start processing job (4, 0, 12)
15:31:09 WORKER: args: ()
15:31:09 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.01822106614077037, 'num_filters_1': 120, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.014032892291474556, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 37, 'num_filters_3': 16, 'num_filters_4': 17, 'num_filters_5': 19}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-704:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

15:32:04 DISPATCHER: Starting worker discovery
15:32:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:32:04 DISPATCHER: Finished worker discovery
15:33:04 DISPATCHER: Starting worker discovery
15:33:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:33:04 DISPATCHER: Finished worker discovery
15:34:04 DISPATCHER: Starting worker discovery
15:34:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:34:04 DISPATCHER: Finished worker discovery
15:35:04 DISPATCHER: Starting worker discovery
15:35:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:35:04 DISPATCHER: Finished worker discovery
15:36:04 DISPATCHER: Starting worker discovery
15:36:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:36:04 DISPATCHER: Finished worker discovery
15:37:04 DISPATCHER: Starting worker discovery
15:37:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:37:04 DISPATCHER: Finished worker discovery
15:37:57 WORKER: done with job (4, 0, 12), trying to register it.
15:37:57 DISPATCHER: job (4, 0, 12) finished
15:37:57 WORKER: registered result for job (4, 0, 12) with dispatcher
15:37:57 DISPATCHER: register_result: lock acquired
15:37:57 DISPATCHER: job (4, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
15:37:57 job_id: (4, 0, 12)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.01822106614077037, 'num_filters_1': 120, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.014032892291474556, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 37, 'num_filters_3': 16, 'num_filters_4': 17, 'num_filters_5': 19}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8410487470024898, 'info': {'music-speech': 0.8410487470024898, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.01822106614077037, 'num_filters_1': 120, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.014032892291474556, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 37, 'num_filters_3': 16, 'num_filters_4': 17, 'num_filters_5': 19}"}}
exception: None

15:37:57 job_callback for (4, 0, 12) started
15:37:57 DISPATCHER: Trying to submit another job.
15:37:57 job_callback for (4, 0, 12) got condition
15:37:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:37:57 Only 14 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
15:37:57 HBMASTER: Trying to run another job!
15:37:57 job_callback for (4, 0, 12) finished
15:37:57 HBMASTER: schedule new run for iteration 4
15:37:57 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
15:37:57 HBMASTER: submitting job (4, 0, 15) to dispatcher
15:37:57 DISPATCHER: trying to submit job (4, 0, 15)
15:37:57 DISPATCHER: trying to notify the job_runner thread.
15:37:57 HBMASTER: job (4, 0, 15) submitted to dispatcher
15:37:57 DISPATCHER: Trying to submit another job.
15:37:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:37:57 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216
15:37:57 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
15:37:57 WORKER: start processing job (4, 0, 15)
15:37:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:37:57 WORKER: args: ()
15:37:57 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.00529191949813948, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.01503247407782858, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 85, 'num_filters_3': 24, 'num_filters_4': 25}, 'budget': 400.0, 'working_directory': '.'}
15:38:04 DISPATCHER: Starting worker discovery
15:38:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:38:04 DISPATCHER: Finished worker discovery
Exception in thread Thread-705:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

15:39:04 DISPATCHER: Starting worker discovery
15:39:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:39:04 DISPATCHER: Finished worker discovery
15:40:04 DISPATCHER: Starting worker discovery
15:40:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:40:04 DISPATCHER: Finished worker discovery
15:41:04 DISPATCHER: Starting worker discovery
15:41:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:41:04 DISPATCHER: Finished worker discovery
15:42:04 DISPATCHER: Starting worker discovery
15:42:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:42:04 DISPATCHER: Finished worker discovery
15:43:04 DISPATCHER: Starting worker discovery
15:43:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:43:04 DISPATCHER: Finished worker discovery
15:44:04 DISPATCHER: Starting worker discovery
15:44:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:44:04 DISPATCHER: Finished worker discovery
15:44:46 WORKER: done with job (4, 0, 15), trying to register it.
15:44:46 DISPATCHER: job (4, 0, 15) finished
15:44:46 WORKER: registered result for job (4, 0, 15) with dispatcher
15:44:46 DISPATCHER: register_result: lock acquired
15:44:46 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
15:44:46 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.00529191949813948, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.01503247407782858, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 85, 'num_filters_3': 24, 'num_filters_4': 25}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8412602885521743, 'info': {'music-speech': 0.8412602885521743, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.00529191949813948, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.01503247407782858, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 85, 'num_filters_3': 24, 'num_filters_4': 25}"}}
exception: None

15:44:46 job_callback for (4, 0, 15) started
15:44:46 DISPATCHER: Trying to submit another job.
15:44:46 job_callback for (4, 0, 15) got condition
15:44:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:44:46 Only 15 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
15:44:46 HBMASTER: Trying to run another job!
15:44:46 job_callback for (4, 0, 15) finished
15:44:46 ITERATION: Advancing config (4, 0, 15) to next budget 1200.000000
15:44:46 HBMASTER: schedule new run for iteration 4
15:44:46 HBMASTER: trying submitting job (4, 0, 15) to dispatcher
15:44:46 HBMASTER: submitting job (4, 0, 15) to dispatcher
15:44:46 DISPATCHER: trying to submit job (4, 0, 15)
15:44:46 DISPATCHER: trying to notify the job_runner thread.
15:44:46 HBMASTER: job (4, 0, 15) submitted to dispatcher
15:44:46 DISPATCHER: Trying to submit another job.
15:44:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:44:46 DISPATCHER: starting job (4, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216
15:44:46 DISPATCHER: job (4, 0, 15) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
15:44:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:44:46 WORKER: start processing job (4, 0, 15)
15:44:46 WORKER: args: ()
15:44:46 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.00529191949813948, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.01503247407782858, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 85, 'num_filters_3': 24, 'num_filters_4': 25}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-706:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

15:45:04 DISPATCHER: Starting worker discovery
15:45:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:45:04 DISPATCHER: Finished worker discovery
15:46:04 DISPATCHER: Starting worker discovery
15:46:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:46:04 DISPATCHER: Finished worker discovery
15:47:04 DISPATCHER: Starting worker discovery
15:47:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:47:04 DISPATCHER: Finished worker discovery
15:48:04 DISPATCHER: Starting worker discovery
15:48:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:48:04 DISPATCHER: Finished worker discovery
15:49:04 DISPATCHER: Starting worker discovery
15:49:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:49:04 DISPATCHER: Finished worker discovery
15:50:04 DISPATCHER: Starting worker discovery
15:50:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:50:04 DISPATCHER: Finished worker discovery
15:51:04 DISPATCHER: Starting worker discovery
15:51:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:51:04 DISPATCHER: Finished worker discovery
15:52:04 DISPATCHER: Starting worker discovery
15:52:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:52:04 DISPATCHER: Finished worker discovery
15:53:04 DISPATCHER: Starting worker discovery
15:53:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:53:04 DISPATCHER: Finished worker discovery
15:54:04 DISPATCHER: Starting worker discovery
15:54:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:54:04 DISPATCHER: Finished worker discovery
15:55:04 DISPATCHER: Starting worker discovery
15:55:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:55:04 DISPATCHER: Finished worker discovery
15:56:04 DISPATCHER: Starting worker discovery
15:56:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:56:04 DISPATCHER: Finished worker discovery
15:57:04 DISPATCHER: Starting worker discovery
15:57:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:57:04 DISPATCHER: Finished worker discovery
15:58:04 DISPATCHER: Starting worker discovery
15:58:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:58:04 DISPATCHER: Finished worker discovery
15:59:04 DISPATCHER: Starting worker discovery
15:59:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:59:04 DISPATCHER: Finished worker discovery
16:00:04 DISPATCHER: Starting worker discovery
16:00:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:00:04 DISPATCHER: Finished worker discovery
16:01:04 DISPATCHER: Starting worker discovery
16:01:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:01:04 DISPATCHER: Finished worker discovery
16:02:04 DISPATCHER: Starting worker discovery
16:02:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:02:04 DISPATCHER: Finished worker discovery
16:03:04 DISPATCHER: Starting worker discovery
16:03:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:03:04 DISPATCHER: Finished worker discovery
16:04:04 DISPATCHER: Starting worker discovery
16:04:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:04:04 DISPATCHER: Finished worker discovery
16:04:55 WORKER: done with job (4, 0, 15), trying to register it.
16:04:55 DISPATCHER: job (4, 0, 15) finished
16:04:55 WORKER: registered result for job (4, 0, 15) with dispatcher
16:04:55 DISPATCHER: register_result: lock acquired
16:04:55 DISPATCHER: job (4, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
16:04:55 job_id: (4, 0, 15)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.00529191949813948, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.01503247407782858, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 85, 'num_filters_3': 24, 'num_filters_4': 25}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.532652511751886, 'info': {'music-speech': 0.532652511751886, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.00529191949813948, 'num_filters_1': 26, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 70, 'weight_decay': 0.01503247407782858, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 85, 'num_filters_3': 24, 'num_filters_4': 25}"}}
exception: None

16:04:55 job_callback for (4, 0, 15) started
16:04:55 DISPATCHER: Trying to submit another job.
16:04:55 job_callback for (4, 0, 15) got condition
16:04:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:04:55 Only 9 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
16:04:55 HBMASTER: Trying to run another job!
16:04:55 job_callback for (4, 0, 15) finished
16:04:55 start sampling a new configuration.
16:04:55 done sampling a new configuration.
16:04:55 HBMASTER: schedule new run for iteration 5
16:04:55 HBMASTER: trying submitting job (5, 0, 0) to dispatcher
16:04:55 HBMASTER: submitting job (5, 0, 0) to dispatcher
16:04:55 DISPATCHER: trying to submit job (5, 0, 0)
16:04:55 DISPATCHER: trying to notify the job_runner thread.
16:04:55 HBMASTER: job (5, 0, 0) submitted to dispatcher
16:04:55 DISPATCHER: Trying to submit another job.
16:04:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:04:55 DISPATCHER: starting job (5, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
16:04:55 DISPATCHER: job (5, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
16:04:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:04:55 WORKER: start processing job (5, 0, 0)
16:04:55 WORKER: args: ()
16:04:55 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.06572336701673173, 'num_filters_1': 66, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.02931846583186932, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 50, 'num_filters_3': 26, 'num_filters_4': 90, 'num_filters_5': 63}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:05:04 DISPATCHER: Starting worker discovery
16:05:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:05:04 DISPATCHER: Finished worker discovery
Exception in thread Thread-707:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

16:06:04 DISPATCHER: Starting worker discovery
16:06:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:06:04 DISPATCHER: Finished worker discovery
16:07:04 DISPATCHER: Starting worker discovery
16:07:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:07:04 DISPATCHER: Finished worker discovery
16:07:17 WORKER: done with job (5, 0, 0), trying to register it.
16:07:17 DISPATCHER: job (5, 0, 0) finished
16:07:17 WORKER: registered result for job (5, 0, 0) with dispatcher
16:07:17 DISPATCHER: register_result: lock acquired
16:07:17 DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
16:07:17 job_id: (5, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.06572336701673173, 'num_filters_1': 66, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.02931846583186932, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 50, 'num_filters_3': 26, 'num_filters_4': 90, 'num_filters_5': 63}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5912724821825452, 'info': {'music-speech': 0.5912724821825452, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.06572336701673173, 'num_filters_1': 66, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 44, 'weight_decay': 0.02931846583186932, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 5, 'kernel_size_5': 5, 'num_filters_2': 50, 'num_filters_3': 26, 'num_filters_4': 90, 'num_filters_5': 63}"}}
exception: None

16:07:17 job_callback for (5, 0, 0) started
16:07:17 DISPATCHER: Trying to submit another job.
16:07:17 job_callback for (5, 0, 0) got condition
16:07:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:07:17 HBMASTER: Trying to run another job!
16:07:17 job_callback for (5, 0, 0) finished
16:07:17 start sampling a new configuration.
16:07:17 done sampling a new configuration.
16:07:17 HBMASTER: schedule new run for iteration 5
16:07:17 HBMASTER: trying submitting job (5, 0, 1) to dispatcher
16:07:17 HBMASTER: submitting job (5, 0, 1) to dispatcher
16:07:17 DISPATCHER: trying to submit job (5, 0, 1)
16:07:17 DISPATCHER: trying to notify the job_runner thread.
16:07:17 HBMASTER: job (5, 0, 1) submitted to dispatcher
16:07:17 DISPATCHER: Trying to submit another job.
16:07:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:07:17 DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
16:07:17 DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
16:07:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:07:17 WORKER: start processing job (5, 0, 1)
16:07:17 WORKER: args: ()
16:07:17 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004462741277565981, 'num_filters_1': 29, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.016761859646795545, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 22, 'num_filters_3': 97}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:08:04 DISPATCHER: Starting worker discovery
16:08:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:08:04 DISPATCHER: Finished worker discovery
16:09:04 DISPATCHER: Starting worker discovery
16:09:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:09:04 DISPATCHER: Finished worker discovery
16:09:39 WORKER: done with job (5, 0, 1), trying to register it.
16:09:39 DISPATCHER: job (5, 0, 1) finished
16:09:39 WORKER: registered result for job (5, 0, 1) with dispatcher
16:09:39 DISPATCHER: register_result: lock acquired
16:09:39 DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
16:09:39 job_id: (5, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004462741277565981, 'num_filters_1': 29, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.016761859646795545, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 22, 'num_filters_3': 97}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8000943530999463, 'info': {'music-speech': 0.8000943530999463, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.004462741277565981, 'num_filters_1': 29, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 29, 'weight_decay': 0.016761859646795545, 'kernel_size_2': 7, 'kernel_size_3': 7, 'num_filters_2': 22, 'num_filters_3': 97}"}}
exception: None

16:09:39 job_callback for (5, 0, 1) started
16:09:39 job_callback for (5, 0, 1) got condition
16:09:39 DISPATCHER: Trying to submit another job.
16:09:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:09:39 HBMASTER: Trying to run another job!
16:09:39 job_callback for (5, 0, 1) finished
16:09:39 start sampling a new configuration.
16:09:39 best_vector: [0, 2, 0.2482875621217741, 0.4362466907698555, 0.8721691567915147, 1, 0.928181794648582, 0.33927071531178243, 0, 1, 1, 2, 0.3567172612684735, 0.4918353285198853, 0.8168523758682763, 0.06170579887806793], 0.0043688520577196705, 0.00513733230452937, 2.2444244809832878e-05
16:09:39 done sampling a new configuration.
16:09:39 HBMASTER: schedule new run for iteration 5
16:09:39 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
16:09:39 HBMASTER: submitting job (5, 0, 2) to dispatcher
16:09:39 DISPATCHER: trying to submit job (5, 0, 2)
16:09:39 DISPATCHER: trying to notify the job_runner thread.
16:09:39 HBMASTER: job (5, 0, 2) submitted to dispatcher
16:09:39 DISPATCHER: Trying to submit another job.
16:09:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:09:39 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
16:09:39 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
16:09:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:09:39 WORKER: start processing job (5, 0, 2)
16:09:39 WORKER: args: ()
16:09:39 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0031374377970968207, 'num_filters_1': 39, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.027631303763084075, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 33, 'num_filters_3': 44, 'num_filters_4': 87, 'num_filters_5': 18}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-709:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

16:10:04 DISPATCHER: Starting worker discovery
16:10:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:10:04 DISPATCHER: Finished worker discovery
16:11:04 DISPATCHER: Starting worker discovery
16:11:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:11:04 DISPATCHER: Finished worker discovery
16:12:01 WORKER: done with job (5, 0, 2), trying to register it.
16:12:01 DISPATCHER: job (5, 0, 2) finished
16:12:01 WORKER: registered result for job (5, 0, 2) with dispatcher
16:12:01 DISPATCHER: register_result: lock acquired
16:12:01 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
16:12:01 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0031374377970968207, 'num_filters_1': 39, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.027631303763084075, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 33, 'num_filters_3': 44, 'num_filters_4': 87, 'num_filters_5': 18}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9314780118673498, 'info': {'music-speech': 0.9314780118673498, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0031374377970968207, 'num_filters_1': 39, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.027631303763084075, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 33, 'num_filters_3': 44, 'num_filters_4': 87, 'num_filters_5': 18}"}}
exception: None

16:12:01 job_callback for (5, 0, 2) started
16:12:01 DISPATCHER: Trying to submit another job.
16:12:01 job_callback for (5, 0, 2) got condition
16:12:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:12:01 HBMASTER: Trying to run another job!
16:12:01 job_callback for (5, 0, 2) finished
16:12:01 start sampling a new configuration.
16:12:01 best_vector: [3, 0, 0.2820186888927173, 0.6459679517782437, 0.5612124505470685, 1, 0.4256754816478189, 0.039428442627372155, 1, 1, 1, 2, 0.7403249970158243, 0.31063593028065983, 0.5809342592124356, 0.8428252975211159], 0.014819937304446872, 0.0009962484520783296, 1.4764339599453088e-05
16:12:01 done sampling a new configuration.
16:12:01 HBMASTER: schedule new run for iteration 5
16:12:01 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
16:12:01 HBMASTER: submitting job (5, 0, 3) to dispatcher
16:12:01 DISPATCHER: trying to submit job (5, 0, 3)
16:12:01 DISPATCHER: trying to notify the job_runner thread.
16:12:01 HBMASTER: job (5, 0, 3) submitted to dispatcher
16:12:01 DISPATCHER: Trying to submit another job.
16:12:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:12:01 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
16:12:01 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
16:12:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:12:01 WORKER: start processing job (5, 0, 3)
16:12:01 WORKER: args: ()
16:12:01 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0036646911364966654, 'num_filters_1': 61, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.011253758379863713, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 74, 'num_filters_3': 30}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:12:04 DISPATCHER: Starting worker discovery
16:12:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:12:04 DISPATCHER: Finished worker discovery
16:13:04 DISPATCHER: Starting worker discovery
16:13:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:13:04 DISPATCHER: Finished worker discovery
16:14:04 DISPATCHER: Starting worker discovery
16:14:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:14:04 DISPATCHER: Finished worker discovery
16:14:25 WORKER: done with job (5, 0, 3), trying to register it.
16:14:25 WORKER: registered result for job (5, 0, 3) with dispatcher
16:14:25 DISPATCHER: job (5, 0, 3) finished
16:14:25 DISPATCHER: register_result: lock acquired
16:14:25 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
16:14:25 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0036646911364966654, 'num_filters_1': 61, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.011253758379863713, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 74, 'num_filters_3': 30}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9181941344560686, 'info': {'music-speech': 0.9181941344560686, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0036646911364966654, 'num_filters_1': 61, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.011253758379863713, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 74, 'num_filters_3': 30}"}}
exception: None

16:14:25 job_callback for (5, 0, 3) started
16:14:25 DISPATCHER: Trying to submit another job.
16:14:25 job_callback for (5, 0, 3) got condition
16:14:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:14:25 HBMASTER: Trying to run another job!
16:14:25 job_callback for (5, 0, 3) finished
16:14:25 start sampling a new configuration.
16:14:25 best_vector: [0, 2, 0.4134648582884381, 0.1520455490698064, 0.5274720162080213, 1, 0.49641778974680295, 0.17956954826323163, 2, 1, 0, 2, 0.8925098898721338, 0.6922554897100373, 0.7218804275914327, 0.7915729690204518], 0.005046008203890885, 0.004310526152852803, 2.175095033038146e-05
16:14:25 done sampling a new configuration.
16:14:25 HBMASTER: schedule new run for iteration 5
16:14:25 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
16:14:25 HBMASTER: submitting job (5, 0, 4) to dispatcher
16:14:25 DISPATCHER: trying to submit job (5, 0, 4)
16:14:25 DISPATCHER: trying to notify the job_runner thread.
16:14:25 HBMASTER: job (5, 0, 4) submitted to dispatcher
16:14:25 DISPATCHER: Trying to submit another job.
16:14:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:14:25 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
16:14:25 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
16:14:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:14:25 WORKER: start processing job (5, 0, 4)
16:14:25 WORKER: args: ()
16:14:25 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006713202019947269, 'num_filters_1': 21, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.017124794499956023, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 102, 'num_filters_3': 67}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-711:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

16:15:04 DISPATCHER: Starting worker discovery
16:15:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:15:04 DISPATCHER: Finished worker discovery
16:16:04 DISPATCHER: Starting worker discovery
16:16:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:16:04 DISPATCHER: Finished worker discovery
16:16:47 WORKER: done with job (5, 0, 4), trying to register it.
16:16:47 WORKER: registered result for job (5, 0, 4) with dispatcher
16:16:47 DISPATCHER: job (5, 0, 4) finished
16:16:47 DISPATCHER: register_result: lock acquired
16:16:47 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
16:16:47 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006713202019947269, 'num_filters_1': 21, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.017124794499956023, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 102, 'num_filters_3': 67}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.841504321863962, 'info': {'music-speech': 0.841504321863962, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006713202019947269, 'num_filters_1': 21, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.017124794499956023, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 102, 'num_filters_3': 67}"}}
exception: None

16:16:47 job_callback for (5, 0, 4) started
16:16:47 DISPATCHER: Trying to submit another job.
16:16:47 job_callback for (5, 0, 4) got condition
16:16:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:16:47 HBMASTER: Trying to run another job!
16:16:47 job_callback for (5, 0, 4) finished
16:16:47 start sampling a new configuration.
16:16:47 best_vector: [0, 0, 0.17414847288072435, 0.5896438125423984, 0.5970317842533711, 1, 0.06432711092142263, 0.19652303933062754, 1, 0, 0, 2, 0.6920072726377532, 0.5753724540001309, 0.6698194311205448, 0.6948383560287157], 0.0040707835092392425, 0.0017225954051104107, 7.012312968214752e-06
16:16:47 done sampling a new configuration.
16:16:47 HBMASTER: schedule new run for iteration 5
16:16:47 HBMASTER: trying submitting job (5, 0, 5) to dispatcher
16:16:47 HBMASTER: submitting job (5, 0, 5) to dispatcher
16:16:47 DISPATCHER: trying to submit job (5, 0, 5)
16:16:47 DISPATCHER: trying to notify the job_runner thread.
16:16:47 HBMASTER: job (5, 0, 5) submitted to dispatcher
16:16:47 DISPATCHER: Trying to submit another job.
16:16:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:16:47 DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
16:16:47 DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
16:16:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:16:47 WORKER: start processing job (5, 0, 5)
16:16:47 WORKER: args: ()
16:16:47 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002229959346965776, 'num_filters_1': 54, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.018016995455755795, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 67, 'num_filters_3': 52}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:17:04 DISPATCHER: Starting worker discovery
16:17:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:17:04 DISPATCHER: Finished worker discovery
16:18:04 DISPATCHER: Starting worker discovery
16:18:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:18:04 DISPATCHER: Finished worker discovery
16:19:04 DISPATCHER: Starting worker discovery
16:19:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:19:04 DISPATCHER: Finished worker discovery
16:19:10 WORKER: done with job (5, 0, 5), trying to register it.
16:19:10 WORKER: registered result for job (5, 0, 5) with dispatcher
16:19:10 DISPATCHER: job (5, 0, 5) finished
16:19:10 DISPATCHER: register_result: lock acquired
16:19:10 DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
16:19:10 job_id: (5, 0, 5)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002229959346965776, 'num_filters_1': 54, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.018016995455755795, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 67, 'num_filters_3': 52}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5775588492191566, 'info': {'music-speech': 0.5775588492191566, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.002229959346965776, 'num_filters_1': 54, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 15, 'weight_decay': 0.018016995455755795, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 67, 'num_filters_3': 52}"}}
exception: None

16:19:10 job_callback for (5, 0, 5) started
16:19:10 DISPATCHER: Trying to submit another job.
16:19:10 job_callback for (5, 0, 5) got condition
16:19:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:19:10 HBMASTER: Trying to run another job!
16:19:10 job_callback for (5, 0, 5) finished
16:19:10 start sampling a new configuration.
16:19:10 done sampling a new configuration.
16:19:10 HBMASTER: schedule new run for iteration 5
16:19:10 HBMASTER: trying submitting job (5, 0, 6) to dispatcher
16:19:10 HBMASTER: submitting job (5, 0, 6) to dispatcher
16:19:10 DISPATCHER: trying to submit job (5, 0, 6)
16:19:10 DISPATCHER: trying to notify the job_runner thread.
16:19:10 HBMASTER: job (5, 0, 6) submitted to dispatcher
16:19:10 DISPATCHER: Trying to submit another job.
16:19:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:19:10 DISPATCHER: starting job (5, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216
16:19:10 DISPATCHER: job (5, 0, 6) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
16:19:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:19:10 WORKER: start processing job (5, 0, 6)
16:19:10 WORKER: args: ()
16:19:10 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.09376423350082498, 'num_filters_1': 77, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.05780548214063474, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 56, 'num_filters_3': 38, 'num_filters_4': 111, 'num_filters_5': 100}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:20:04 DISPATCHER: Starting worker discovery
16:20:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:20:04 DISPATCHER: Finished worker discovery
16:21:04 DISPATCHER: Starting worker discovery
16:21:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:21:04 DISPATCHER: Finished worker discovery
16:21:33 WORKER: done with job (5, 0, 6), trying to register it.
16:21:33 DISPATCHER: job (5, 0, 6) finished
16:21:33 WORKER: registered result for job (5, 0, 6) with dispatcher
16:21:33 DISPATCHER: register_result: lock acquired
16:21:33 DISPATCHER: job (5, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
16:21:33 job_id: (5, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.09376423350082498, 'num_filters_1': 77, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.05780548214063474, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 56, 'num_filters_3': 38, 'num_filters_4': 111, 'num_filters_5': 100}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.09376423350082498, 'num_filters_1': 77, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 85, 'weight_decay': 0.05780548214063474, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 56, 'num_filters_3': 38, 'num_filters_4': 111, 'num_filters_5': 100}"}}
exception: None

16:21:33 job_callback for (5, 0, 6) started
16:21:33 DISPATCHER: Trying to submit another job.
16:21:33 job_callback for (5, 0, 6) got condition
16:21:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:21:33 done building a new model for budget 133.333333 based on 17/28 split
Best loss for this budget:-0.931478





16:21:33 HBMASTER: Trying to run another job!
16:21:33 job_callback for (5, 0, 6) finished
16:21:33 start sampling a new configuration.
16:21:33 best_vector: [3, 0, 0.2576613096759027, 0.08710809973326122, 0.09003343009392717, 0, 0.4140823547914978, 0.7303946416440045, 1, 1, 0, 2, 0.7471904584478618, 0.741204680105979, 0.13236388618953557, 0.007114901958490988], 7.560385876242108e-29, 0.00013226838105478424, -6.373433515264953e-05
16:21:33 done sampling a new configuration.
16:21:33 HBMASTER: schedule new run for iteration 5
16:21:33 HBMASTER: trying submitting job (5, 0, 7) to dispatcher
16:21:33 HBMASTER: submitting job (5, 0, 7) to dispatcher
16:21:33 DISPATCHER: trying to submit job (5, 0, 7)
16:21:33 DISPATCHER: trying to notify the job_runner thread.
16:21:33 HBMASTER: job (5, 0, 7) submitted to dispatcher
16:21:33 DISPATCHER: Trying to submit another job.
16:21:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:21:33 DISPATCHER: starting job (5, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
16:21:33 DISPATCHER: job (5, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
16:21:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:21:33 WORKER: start processing job (5, 0, 7)
16:21:33 WORKER: args: ()
16:21:33 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0032758395304176846, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.08917956250170081}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:22:04 DISPATCHER: Starting worker discovery
16:22:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:22:04 DISPATCHER: Finished worker discovery
16:23:04 DISPATCHER: Starting worker discovery
16:23:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:23:04 DISPATCHER: Finished worker discovery
16:23:56 WORKER: done with job (5, 0, 7), trying to register it.
16:23:56 WORKER: registered result for job (5, 0, 7) with dispatcher
16:23:56 DISPATCHER: job (5, 0, 7) finished
16:23:56 DISPATCHER: register_result: lock acquired
16:23:56 DISPATCHER: job (5, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
16:23:56 job_id: (5, 0, 7)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0032758395304176846, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.08917956250170081}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6611923750977812, 'info': {'music-speech': 0.6611923750977812, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0032758395304176846, 'num_filters_1': 19, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.08917956250170081}"}}
exception: None

16:23:56 job_callback for (5, 0, 7) started
16:23:56 job_callback for (5, 0, 7) got condition
16:23:56 DISPATCHER: Trying to submit another job.
16:23:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:23:56 done building a new model for budget 133.333333 based on 17/29 split
Best loss for this budget:-0.931478





16:23:56 HBMASTER: Trying to run another job!
16:23:56 job_callback for (5, 0, 7) finished
16:23:56 start sampling a new configuration.
16:23:56 done sampling a new configuration.
16:23:56 HBMASTER: schedule new run for iteration 5
16:23:56 HBMASTER: trying submitting job (5, 0, 8) to dispatcher
16:23:56 HBMASTER: submitting job (5, 0, 8) to dispatcher
16:23:56 DISPATCHER: trying to submit job (5, 0, 8)
16:23:56 DISPATCHER: trying to notify the job_runner thread.
16:23:56 HBMASTER: job (5, 0, 8) submitted to dispatcher
16:23:56 DISPATCHER: Trying to submit another job.
16:23:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:23:56 DISPATCHER: starting job (5, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216
16:23:56 DISPATCHER: job (5, 0, 8) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
16:23:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:23:56 WORKER: start processing job (5, 0, 8)
16:23:56 WORKER: args: ()
16:23:56 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.022436320357999074, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.030502831605945368}, 'budget': 133.33333333333331, 'working_directory': '.'}
16:24:04 DISPATCHER: Starting worker discovery
16:24:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:24:04 DISPATCHER: Finished worker discovery
16:25:04 DISPATCHER: Starting worker discovery
16:25:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:25:04 DISPATCHER: Finished worker discovery
16:26:04 DISPATCHER: Starting worker discovery
16:26:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:26:04 DISPATCHER: Finished worker discovery
16:26:20 WORKER: done with job (5, 0, 8), trying to register it.
16:26:20 WORKER: registered result for job (5, 0, 8) with dispatcher
16:26:20 DISPATCHER: job (5, 0, 8) finished
16:26:20 DISPATCHER: register_result: lock acquired
16:26:20 DISPATCHER: job (5, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
16:26:20 job_id: (5, 0, 8)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.022436320357999074, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.030502831605945368}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.4040533603589273, 'info': {'music-speech': 0.4040533603589273, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.022436320357999074, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 76, 'weight_decay': 0.030502831605945368}"}}
exception: None

16:26:20 job_callback for (5, 0, 8) started
16:26:20 job_callback for (5, 0, 8) got condition
16:26:20 DISPATCHER: Trying to submit another job.
16:26:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:26:20 done building a new model for budget 133.333333 based on 17/30 split
Best loss for this budget:-0.931478





16:26:20 HBMASTER: Trying to run another job!
16:26:20 job_callback for (5, 0, 8) finished
16:26:20 ITERATION: Advancing config (5, 0, 2) to next budget 400.000000
16:26:20 ITERATION: Advancing config (5, 0, 3) to next budget 400.000000
16:26:20 ITERATION: Advancing config (5, 0, 4) to next budget 400.000000
16:26:20 HBMASTER: schedule new run for iteration 5
16:26:20 HBMASTER: trying submitting job (5, 0, 2) to dispatcher
16:26:20 HBMASTER: submitting job (5, 0, 2) to dispatcher
16:26:20 DISPATCHER: trying to submit job (5, 0, 2)
16:26:20 DISPATCHER: trying to notify the job_runner thread.
16:26:20 HBMASTER: job (5, 0, 2) submitted to dispatcher
16:26:20 DISPATCHER: Trying to submit another job.
16:26:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:26:20 DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
16:26:20 DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
16:26:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:26:20 WORKER: start processing job (5, 0, 2)
16:26:20 WORKER: args: ()
16:26:20 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0031374377970968207, 'num_filters_1': 39, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.027631303763084075, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 33, 'num_filters_3': 44, 'num_filters_4': 87, 'num_filters_5': 18}, 'budget': 400.0, 'working_directory': '.'}
16:27:04 DISPATCHER: Starting worker discovery
16:27:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:27:04 DISPATCHER: Finished worker discovery
16:28:04 DISPATCHER: Starting worker discovery
16:28:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:28:04 DISPATCHER: Finished worker discovery
16:29:04 DISPATCHER: Starting worker discovery
16:29:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:29:04 DISPATCHER: Finished worker discovery
16:30:04 DISPATCHER: Starting worker discovery
16:30:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:30:04 DISPATCHER: Finished worker discovery
16:31:04 DISPATCHER: Starting worker discovery
16:31:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:31:04 DISPATCHER: Finished worker discovery
16:32:04 DISPATCHER: Starting worker discovery
16:32:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:32:04 DISPATCHER: Finished worker discovery
16:33:04 DISPATCHER: Starting worker discovery
16:33:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:33:04 DISPATCHER: Finished worker discovery
16:33:09 WORKER: done with job (5, 0, 2), trying to register it.
16:33:09 WORKER: registered result for job (5, 0, 2) with dispatcher
16:33:09 DISPATCHER: job (5, 0, 2) finished
16:33:09 DISPATCHER: register_result: lock acquired
16:33:09 DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
16:33:09 job_id: (5, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0031374377970968207, 'num_filters_1': 39, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.027631303763084075, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 33, 'num_filters_3': 44, 'num_filters_4': 87, 'num_filters_5': 18}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.5815195392790962, 'info': {'music-speech': 0.5815195392790962, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0031374377970968207, 'num_filters_1': 39, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 94, 'weight_decay': 0.027631303763084075, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 33, 'num_filters_3': 44, 'num_filters_4': 87, 'num_filters_5': 18}"}}
exception: None

16:33:09 job_callback for (5, 0, 2) started
16:33:09 DISPATCHER: Trying to submit another job.
16:33:09 job_callback for (5, 0, 2) got condition
16:33:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:33:09 Only 16 run(s) for budget 400.000000 available, need more than 18 -> can't build model!
16:33:09 HBMASTER: Trying to run another job!
16:33:09 job_callback for (5, 0, 2) finished
16:33:09 HBMASTER: schedule new run for iteration 5
16:33:09 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
16:33:09 HBMASTER: submitting job (5, 0, 3) to dispatcher
16:33:09 DISPATCHER: trying to submit job (5, 0, 3)
16:33:09 DISPATCHER: trying to notify the job_runner thread.
16:33:09 HBMASTER: job (5, 0, 3) submitted to dispatcher
16:33:09 DISPATCHER: Trying to submit another job.
16:33:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:33:09 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
16:33:09 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
16:33:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:33:09 WORKER: start processing job (5, 0, 3)
16:33:09 WORKER: args: ()
16:33:09 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0036646911364966654, 'num_filters_1': 61, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.011253758379863713, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 74, 'num_filters_3': 30}, 'budget': 400.0, 'working_directory': '.'}
16:34:04 DISPATCHER: Starting worker discovery
16:34:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:34:04 DISPATCHER: Finished worker discovery
16:35:04 DISPATCHER: Starting worker discovery
16:35:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:35:04 DISPATCHER: Finished worker discovery
16:36:04 DISPATCHER: Starting worker discovery
16:36:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:36:04 DISPATCHER: Finished worker discovery
16:37:04 DISPATCHER: Starting worker discovery
16:37:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:37:04 DISPATCHER: Finished worker discovery
16:38:04 DISPATCHER: Starting worker discovery
16:38:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:38:04 DISPATCHER: Finished worker discovery
16:39:04 DISPATCHER: Starting worker discovery
16:39:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:39:04 DISPATCHER: Finished worker discovery
16:39:59 WORKER: done with job (5, 0, 3), trying to register it.
16:39:59 WORKER: registered result for job (5, 0, 3) with dispatcher
16:39:59 DISPATCHER: job (5, 0, 3) finished
16:39:59 DISPATCHER: register_result: lock acquired
16:39:59 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
16:39:59 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0036646911364966654, 'num_filters_1': 61, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.011253758379863713, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 74, 'num_filters_3': 30}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8472015940294116, 'info': {'music-speech': 0.8472015940294116, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0036646911364966654, 'num_filters_1': 61, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.011253758379863713, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 74, 'num_filters_3': 30}"}}
exception: None

16:39:59 job_callback for (5, 0, 3) started
16:39:59 DISPATCHER: Trying to submit another job.
16:39:59 job_callback for (5, 0, 3) got condition
16:39:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:39:59 HBMASTER: Trying to run another job!
16:39:59 job_callback for (5, 0, 3) finished
16:39:59 HBMASTER: schedule new run for iteration 5
16:39:59 HBMASTER: trying submitting job (5, 0, 4) to dispatcher
16:39:59 HBMASTER: submitting job (5, 0, 4) to dispatcher
16:39:59 DISPATCHER: trying to submit job (5, 0, 4)
16:39:59 DISPATCHER: trying to notify the job_runner thread.
16:39:59 HBMASTER: job (5, 0, 4) submitted to dispatcher
16:39:59 DISPATCHER: Trying to submit another job.
16:39:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:39:59 DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
16:39:59 DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
16:39:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:39:59 WORKER: start processing job (5, 0, 4)
16:39:59 WORKER: args: ()
16:39:59 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006713202019947269, 'num_filters_1': 21, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.017124794499956023, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 102, 'num_filters_3': 67}, 'budget': 400.0, 'working_directory': '.'}
16:40:04 DISPATCHER: Starting worker discovery
16:40:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:40:04 DISPATCHER: Finished worker discovery
Exception in thread Thread-718:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

16:41:04 DISPATCHER: Starting worker discovery
16:41:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:41:04 DISPATCHER: Finished worker discovery
16:42:04 DISPATCHER: Starting worker discovery
16:42:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:42:04 DISPATCHER: Finished worker discovery
16:43:04 DISPATCHER: Starting worker discovery
16:43:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:43:04 DISPATCHER: Finished worker discovery
16:44:04 DISPATCHER: Starting worker discovery
16:44:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:44:04 DISPATCHER: Finished worker discovery
16:45:04 DISPATCHER: Starting worker discovery
16:45:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:45:04 DISPATCHER: Finished worker discovery
16:46:04 DISPATCHER: Starting worker discovery
16:46:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:46:04 DISPATCHER: Finished worker discovery
16:46:47 WORKER: done with job (5, 0, 4), trying to register it.
16:46:47 WORKER: registered result for job (5, 0, 4) with dispatcher
16:46:47 DISPATCHER: job (5, 0, 4) finished
16:46:47 DISPATCHER: register_result: lock acquired
16:46:47 DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
16:46:47 job_id: (5, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006713202019947269, 'num_filters_1': 21, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.017124794499956023, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 102, 'num_filters_3': 67}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8172552473407328, 'info': {'music-speech': 0.8172552473407328, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.006713202019947269, 'num_filters_1': 21, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 55, 'weight_decay': 0.017124794499956023, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 102, 'num_filters_3': 67}"}}
exception: None

16:46:47 job_callback for (5, 0, 4) started
16:46:47 DISPATCHER: Trying to submit another job.
16:46:47 job_callback for (5, 0, 4) got condition
16:46:47 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:46:47 HBMASTER: Trying to run another job!
16:46:47 job_callback for (5, 0, 4) finished
16:46:47 ITERATION: Advancing config (5, 0, 3) to next budget 1200.000000
16:46:47 HBMASTER: schedule new run for iteration 5
16:46:47 HBMASTER: trying submitting job (5, 0, 3) to dispatcher
16:46:47 HBMASTER: submitting job (5, 0, 3) to dispatcher
16:46:47 DISPATCHER: trying to submit job (5, 0, 3)
16:46:47 DISPATCHER: trying to notify the job_runner thread.
16:46:47 HBMASTER: job (5, 0, 3) submitted to dispatcher
16:46:47 DISPATCHER: Trying to submit another job.
16:46:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:46:47 DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
16:46:47 DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
16:46:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:46:47 WORKER: start processing job (5, 0, 3)
16:46:47 WORKER: args: ()
16:46:47 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0036646911364966654, 'num_filters_1': 61, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.011253758379863713, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 74, 'num_filters_3': 30}, 'budget': 1200.0, 'working_directory': '.'}
16:47:04 DISPATCHER: Starting worker discovery
16:47:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:47:04 DISPATCHER: Finished worker discovery
16:48:04 DISPATCHER: Starting worker discovery
16:48:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:48:04 DISPATCHER: Finished worker discovery
16:49:04 DISPATCHER: Starting worker discovery
16:49:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:49:04 DISPATCHER: Finished worker discovery
16:50:04 DISPATCHER: Starting worker discovery
16:50:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:50:04 DISPATCHER: Finished worker discovery
16:51:04 DISPATCHER: Starting worker discovery
16:51:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:51:04 DISPATCHER: Finished worker discovery
16:52:04 DISPATCHER: Starting worker discovery
16:52:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:52:04 DISPATCHER: Finished worker discovery
16:53:04 DISPATCHER: Starting worker discovery
16:53:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:53:04 DISPATCHER: Finished worker discovery
16:54:04 DISPATCHER: Starting worker discovery
16:54:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:54:04 DISPATCHER: Finished worker discovery
16:55:04 DISPATCHER: Starting worker discovery
16:55:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:55:04 DISPATCHER: Finished worker discovery
16:56:04 DISPATCHER: Starting worker discovery
16:56:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:56:04 DISPATCHER: Finished worker discovery
16:57:04 DISPATCHER: Starting worker discovery
16:57:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:57:04 DISPATCHER: Finished worker discovery
16:58:04 DISPATCHER: Starting worker discovery
16:58:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:58:04 DISPATCHER: Finished worker discovery
16:59:04 DISPATCHER: Starting worker discovery
16:59:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:59:04 DISPATCHER: Finished worker discovery
17:00:04 DISPATCHER: Starting worker discovery
17:00:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:00:04 DISPATCHER: Finished worker discovery
17:01:04 DISPATCHER: Starting worker discovery
17:01:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:01:04 DISPATCHER: Finished worker discovery
17:02:04 DISPATCHER: Starting worker discovery
17:02:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:02:04 DISPATCHER: Finished worker discovery
17:03:04 DISPATCHER: Starting worker discovery
17:03:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:03:04 DISPATCHER: Finished worker discovery
17:04:04 DISPATCHER: Starting worker discovery
17:04:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:04:04 DISPATCHER: Finished worker discovery
17:05:04 DISPATCHER: Starting worker discovery
17:05:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:05:04 DISPATCHER: Finished worker discovery
17:06:04 DISPATCHER: Starting worker discovery
17:06:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:06:04 DISPATCHER: Finished worker discovery
17:07:00 WORKER: done with job (5, 0, 3), trying to register it.
17:07:00 WORKER: registered result for job (5, 0, 3) with dispatcher
17:07:00 DISPATCHER: job (5, 0, 3) finished
17:07:00 DISPATCHER: register_result: lock acquired
17:07:00 DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
17:07:00 job_id: (5, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0036646911364966654, 'num_filters_1': 61, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.011253758379863713, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 74, 'num_filters_3': 30}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.8388896792269072, 'info': {'music-speech': 0.8388896792269072, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.0036646911364966654, 'num_filters_1': 61, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 48, 'weight_decay': 0.011253758379863713, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 74, 'num_filters_3': 30}"}}
exception: None

17:07:00 job_callback for (5, 0, 3) started
17:07:00 DISPATCHER: Trying to submit another job.
17:07:00 job_callback for (5, 0, 3) got condition
17:07:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:07:00 Only 10 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
17:07:00 HBMASTER: Trying to run another job!
17:07:00 job_callback for (5, 0, 3) finished
17:07:00 start sampling a new configuration.
17:07:00 done sampling a new configuration.
17:07:00 HBMASTER: schedule new run for iteration 6
17:07:00 HBMASTER: trying submitting job (6, 0, 0) to dispatcher
17:07:00 HBMASTER: submitting job (6, 0, 0) to dispatcher
17:07:00 DISPATCHER: trying to submit job (6, 0, 0)
17:07:00 DISPATCHER: trying to notify the job_runner thread.
17:07:00 HBMASTER: job (6, 0, 0) submitted to dispatcher
17:07:00 DISPATCHER: Trying to submit another job.
17:07:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:07:00 DISPATCHER: starting job (6, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
17:07:00 DISPATCHER: job (6, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
17:07:00 WORKER: start processing job (6, 0, 0)
17:07:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:07:00 WORKER: args: ()
17:07:00 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.011156756486189254, 'num_filters_1': 65, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.02398681742915999, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 91, 'num_filters_3': 117, 'num_filters_4': 18, 'num_filters_5': 56}, 'budget': 400.0, 'working_directory': '.'}
17:07:04 DISPATCHER: Starting worker discovery
17:07:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:07:04 DISPATCHER: Finished worker discovery
17:08:04 DISPATCHER: Starting worker discovery
17:08:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:08:05 DISPATCHER: Finished worker discovery
17:09:05 DISPATCHER: Starting worker discovery
17:09:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:09:05 DISPATCHER: Finished worker discovery
17:10:05 DISPATCHER: Starting worker discovery
17:10:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:10:05 DISPATCHER: Finished worker discovery
17:11:05 DISPATCHER: Starting worker discovery
17:11:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:11:05 DISPATCHER: Finished worker discovery
17:12:05 DISPATCHER: Starting worker discovery
17:12:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:12:05 DISPATCHER: Finished worker discovery
17:13:05 DISPATCHER: Starting worker discovery
17:13:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:13:05 DISPATCHER: Finished worker discovery
17:13:51 WORKER: done with job (6, 0, 0), trying to register it.
17:13:51 WORKER: registered result for job (6, 0, 0) with dispatcher
17:13:51 DISPATCHER: job (6, 0, 0) finished
17:13:51 DISPATCHER: register_result: lock acquired
17:13:51 DISPATCHER: job (6, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
17:13:51 job_id: (6, 0, 0)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.011156756486189254, 'num_filters_1': 65, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.02398681742915999, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 91, 'num_filters_3': 117, 'num_filters_4': 18, 'num_filters_5': 56}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': 0.00473581557287806, 'info': {'music-speech': -0.00473581557287806, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.011156756486189254, 'num_filters_1': 65, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.02398681742915999, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 3, 'num_filters_2': 91, 'num_filters_3': 117, 'num_filters_4': 18, 'num_filters_5': 56}"}}
exception: None

17:13:51 job_callback for (6, 0, 0) started
17:13:51 DISPATCHER: Trying to submit another job.
17:13:51 job_callback for (6, 0, 0) got condition
17:13:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:13:51 HBMASTER: Trying to run another job!
17:13:51 job_callback for (6, 0, 0) finished
17:13:51 start sampling a new configuration.
17:13:51 done sampling a new configuration.
17:13:51 HBMASTER: schedule new run for iteration 6
17:13:51 HBMASTER: trying submitting job (6, 0, 1) to dispatcher
17:13:51 HBMASTER: submitting job (6, 0, 1) to dispatcher
17:13:51 DISPATCHER: trying to submit job (6, 0, 1)
17:13:51 DISPATCHER: trying to notify the job_runner thread.
17:13:51 HBMASTER: job (6, 0, 1) submitted to dispatcher
17:13:51 DISPATCHER: Trying to submit another job.
17:13:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:13:51 DISPATCHER: starting job (6, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
17:13:51 DISPATCHER: job (6, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
17:13:51 WORKER: start processing job (6, 0, 1)
17:13:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:13:51 WORKER: args: ()
17:13:51 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.026807114074385477, 'num_filters_1': 38, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.03031798830702164, 'kernel_size_2': 5, 'num_filters_2': 77}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-721:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

17:14:05 DISPATCHER: Starting worker discovery
17:14:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:14:05 DISPATCHER: Finished worker discovery
17:15:05 DISPATCHER: Starting worker discovery
17:15:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:15:05 DISPATCHER: Finished worker discovery
17:16:05 DISPATCHER: Starting worker discovery
17:16:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:16:05 DISPATCHER: Finished worker discovery
17:17:05 DISPATCHER: Starting worker discovery
17:17:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:17:05 DISPATCHER: Finished worker discovery
17:18:05 DISPATCHER: Starting worker discovery
17:18:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:18:05 DISPATCHER: Finished worker discovery
17:19:05 DISPATCHER: Starting worker discovery
17:19:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:19:05 DISPATCHER: Finished worker discovery
17:20:05 DISPATCHER: Starting worker discovery
17:20:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:20:05 DISPATCHER: Finished worker discovery
17:20:39 WORKER: done with job (6, 0, 1), trying to register it.
17:20:39 WORKER: registered result for job (6, 0, 1) with dispatcher
17:20:39 DISPATCHER: job (6, 0, 1) finished
17:20:39 DISPATCHER: register_result: lock acquired
17:20:39 DISPATCHER: job (6, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
17:20:39 job_id: (6, 0, 1)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.026807114074385477, 'num_filters_1': 38, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.03031798830702164, 'kernel_size_2': 5, 'num_filters_2': 77}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.36345597892368503, 'info': {'music-speech': 0.36345597892368503, 'config': "{'batch_size': 64, 'kernel_size_1': 5, 'lr': 0.026807114074385477, 'num_filters_1': 38, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 14, 'weight_decay': 0.03031798830702164, 'kernel_size_2': 5, 'num_filters_2': 77}"}}
exception: None

17:20:39 job_callback for (6, 0, 1) started
17:20:39 DISPATCHER: Trying to submit another job.
17:20:39 job_callback for (6, 0, 1) got condition
17:20:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:20:39 HBMASTER: Trying to run another job!
17:20:39 job_callback for (6, 0, 1) finished
17:20:39 start sampling a new configuration.
17:20:39 done sampling a new configuration.
17:20:39 HBMASTER: schedule new run for iteration 6
17:20:39 HBMASTER: trying submitting job (6, 0, 2) to dispatcher
17:20:39 HBMASTER: submitting job (6, 0, 2) to dispatcher
17:20:39 DISPATCHER: trying to submit job (6, 0, 2)
17:20:39 DISPATCHER: trying to notify the job_runner thread.
17:20:39 HBMASTER: job (6, 0, 2) submitted to dispatcher
17:20:39 DISPATCHER: Trying to submit another job.
17:20:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:20:39 DISPATCHER: starting job (6, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
17:20:39 DISPATCHER: job (6, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
17:20:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:20:39 WORKER: start processing job (6, 0, 2)
17:20:39 WORKER: args: ()
17:20:39 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00797055466493805, 'num_filters_1': 101, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.025674405300278688, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 35, 'num_filters_3': 68, 'num_filters_4': 37, 'num_filters_5': 27}, 'budget': 400.0, 'working_directory': '.'}
17:21:05 DISPATCHER: Starting worker discovery
17:21:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:21:05 DISPATCHER: Finished worker discovery
17:22:05 DISPATCHER: Starting worker discovery
17:22:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:22:05 DISPATCHER: Finished worker discovery
17:23:05 DISPATCHER: Starting worker discovery
17:23:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:23:05 DISPATCHER: Finished worker discovery
17:24:05 DISPATCHER: Starting worker discovery
17:24:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:24:05 DISPATCHER: Finished worker discovery
17:25:05 DISPATCHER: Starting worker discovery
17:25:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:25:05 DISPATCHER: Finished worker discovery
17:26:05 DISPATCHER: Starting worker discovery
17:26:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:26:05 DISPATCHER: Finished worker discovery
17:27:05 DISPATCHER: Starting worker discovery
17:27:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:27:05 DISPATCHER: Finished worker discovery
17:27:29 WORKER: done with job (6, 0, 2), trying to register it.
17:27:29 WORKER: registered result for job (6, 0, 2) with dispatcher
17:27:29 DISPATCHER: job (6, 0, 2) finished
17:27:29 DISPATCHER: register_result: lock acquired
17:27:29 DISPATCHER: job (6, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
17:27:29 job_id: (6, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00797055466493805, 'num_filters_1': 101, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.025674405300278688, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 35, 'num_filters_3': 68, 'num_filters_4': 37, 'num_filters_5': 27}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.00016076228801088338, 'info': {'music-speech': 0.00016076228801088338, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00797055466493805, 'num_filters_1': 101, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 12, 'weight_decay': 0.025674405300278688, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 7, 'kernel_size_5': 3, 'num_filters_2': 35, 'num_filters_3': 68, 'num_filters_4': 37, 'num_filters_5': 27}"}}
exception: None

17:27:29 job_callback for (6, 0, 2) started
17:27:29 DISPATCHER: Trying to submit another job.
17:27:29 job_callback for (6, 0, 2) got condition
17:27:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:27:29 HBMASTER: Trying to run another job!
17:27:29 job_callback for (6, 0, 2) finished
17:27:29 start sampling a new configuration.
17:27:29 best_vector: [0, 0, 0.3903230691619197, 0.2635391132238697, 0.7106301618010742, 1, 0.5503253726869621, 0.6506684606394877, 0, 0, 2, 2, 0.11532455431913058, 0.5436272021604441, 0.5293321992391812, 0.5502691935935355], 7.374095430445592e-29, 0.00013560985336198358, -0.00010229542203882915
17:27:29 done sampling a new configuration.
17:27:29 HBMASTER: schedule new run for iteration 6
17:27:29 HBMASTER: trying submitting job (6, 0, 3) to dispatcher
17:27:29 HBMASTER: submitting job (6, 0, 3) to dispatcher
17:27:29 DISPATCHER: trying to submit job (6, 0, 3)
17:27:29 DISPATCHER: trying to notify the job_runner thread.
17:27:29 HBMASTER: job (6, 0, 3) submitted to dispatcher
17:27:29 DISPATCHER: Trying to submit another job.
17:27:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:27:29 DISPATCHER: starting job (6, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
17:27:29 DISPATCHER: job (6, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
17:27:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:27:29 WORKER: start processing job (6, 0, 3)
17:27:29 WORKER: args: ()
17:27:29 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.00603456734498559, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.0702326708797441, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 20, 'num_filters_3': 49, 'num_filters_4': 47}, 'budget': 400.0, 'working_directory': '.'}
17:28:05 DISPATCHER: Starting worker discovery
17:28:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:28:05 DISPATCHER: Finished worker discovery
17:29:05 DISPATCHER: Starting worker discovery
17:29:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:29:05 DISPATCHER: Finished worker discovery
17:30:05 DISPATCHER: Starting worker discovery
17:30:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:30:05 DISPATCHER: Finished worker discovery
17:31:05 DISPATCHER: Starting worker discovery
17:31:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:31:05 DISPATCHER: Finished worker discovery
17:32:05 DISPATCHER: Starting worker discovery
17:32:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:32:05 DISPATCHER: Finished worker discovery
17:33:05 DISPATCHER: Starting worker discovery
17:33:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:33:05 DISPATCHER: Finished worker discovery
17:34:05 DISPATCHER: Starting worker discovery
17:34:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:34:05 DISPATCHER: Finished worker discovery
17:34:18 WORKER: done with job (6, 0, 3), trying to register it.
17:34:18 WORKER: registered result for job (6, 0, 3) with dispatcher
17:34:18 DISPATCHER: job (6, 0, 3) finished
17:34:18 DISPATCHER: register_result: lock acquired
17:34:18 DISPATCHER: job (6, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
17:34:18 job_id: (6, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.00603456734498559, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.0702326708797441, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 20, 'num_filters_3': 49, 'num_filters_4': 47}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.04793673177449727, 'info': {'music-speech': 0.04793673177449727, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.00603456734498559, 'num_filters_1': 27, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 60, 'weight_decay': 0.0702326708797441, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 20, 'num_filters_3': 49, 'num_filters_4': 47}"}}
exception: None

17:34:18 job_callback for (6, 0, 3) started
17:34:18 DISPATCHER: Trying to submit another job.
17:34:18 job_callback for (6, 0, 3) got condition
17:34:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:34:18 HBMASTER: Trying to run another job!
17:34:18 job_callback for (6, 0, 3) finished
17:34:18 start sampling a new configuration.
17:34:18 best_vector: [3, 0, 0.6548340231580847, 0.5959575677339134, 0.68702557175112, 1, 0.515935929393316, 0.8742328141029565, 0, 1, 1, 2, 0.7703847757175961, 0.021378375202335986, 0.7211385360542973, 0.13319397700232416], 1.415651813416805e-29, 0.0007063883862702149, -1.1755924404197683e-05
17:34:18 done sampling a new configuration.
17:34:18 HBMASTER: schedule new run for iteration 6
17:34:18 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
17:34:18 HBMASTER: submitting job (6, 0, 4) to dispatcher
17:34:18 DISPATCHER: trying to submit job (6, 0, 4)
17:34:18 DISPATCHER: trying to notify the job_runner thread.
17:34:18 HBMASTER: job (6, 0, 4) submitted to dispatcher
17:34:18 DISPATCHER: Trying to submit another job.
17:34:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:34:18 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
17:34:18 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
17:34:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:34:18 WORKER: start processing job (6, 0, 4)
17:34:18 WORKER: args: ()
17:34:18 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.02040177935270465, 'num_filters_1': 55, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.1372154816310358, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 79, 'num_filters_3': 16, 'num_filters_4': 71}, 'budget': 400.0, 'working_directory': '.'}
Exception in thread Thread-724:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

17:35:05 DISPATCHER: Starting worker discovery
17:35:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:35:05 DISPATCHER: Finished worker discovery
17:36:05 DISPATCHER: Starting worker discovery
17:36:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:36:05 DISPATCHER: Finished worker discovery
17:37:05 DISPATCHER: Starting worker discovery
17:37:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:37:05 DISPATCHER: Finished worker discovery
17:38:05 DISPATCHER: Starting worker discovery
17:38:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:38:05 DISPATCHER: Finished worker discovery
17:39:05 DISPATCHER: Starting worker discovery
17:39:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:39:05 DISPATCHER: Finished worker discovery
17:40:05 DISPATCHER: Starting worker discovery
17:40:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:40:05 DISPATCHER: Finished worker discovery
17:41:05 DISPATCHER: Starting worker discovery
17:41:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:41:05 DISPATCHER: Finished worker discovery
17:41:07 WORKER: done with job (6, 0, 4), trying to register it.
17:41:07 WORKER: registered result for job (6, 0, 4) with dispatcher
17:41:07 DISPATCHER: job (6, 0, 4) finished
17:41:07 DISPATCHER: register_result: lock acquired
17:41:07 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
17:41:07 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.02040177935270465, 'num_filters_1': 55, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.1372154816310358, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 79, 'num_filters_3': 16, 'num_filters_4': 71}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.43455528727716297, 'info': {'music-speech': 0.43455528727716297, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.02040177935270465, 'num_filters_1': 55, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.1372154816310358, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 79, 'num_filters_3': 16, 'num_filters_4': 71}"}}
exception: None

17:41:07 job_callback for (6, 0, 4) started
17:41:07 DISPATCHER: Trying to submit another job.
17:41:07 job_callback for (6, 0, 4) got condition
17:41:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:41:08 HBMASTER: Trying to run another job!
17:41:08 job_callback for (6, 0, 4) finished
17:41:08 start sampling a new configuration.
17:41:08 best_vector: [3, 2, 0.3074176646229606, 0.10286234909149214, 0.5784632336951375, 0, 0.7292854938714062, 0.027075273686991697, 0, 2, 1, 2, 0.3508272989694627, 0.05111562854733842, 0.8207573947117273, 0.03397403157039003], 4.342162737621598e-29, 0.00023029998192738074, -1.8014236498059592e-06
17:41:08 done sampling a new configuration.
17:41:08 HBMASTER: schedule new run for iteration 6
17:41:08 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
17:41:08 HBMASTER: submitting job (6, 0, 5) to dispatcher
17:41:08 DISPATCHER: trying to submit job (6, 0, 5)
17:41:08 DISPATCHER: trying to notify the job_runner thread.
17:41:08 HBMASTER: job (6, 0, 5) submitted to dispatcher
17:41:08 DISPATCHER: Trying to submit another job.
17:41:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:41:08 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
17:41:08 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
17:41:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:41:08 WORKER: start processing job (6, 0, 5)
17:41:08 WORKER: args: ()
17:41:08 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004119412943502646, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.010844904780392252, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 33, 'num_filters_3': 17}, 'budget': 400.0, 'working_directory': '.'}
17:42:05 DISPATCHER: Starting worker discovery
17:42:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:42:05 DISPATCHER: Finished worker discovery
17:43:05 DISPATCHER: Starting worker discovery
17:43:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:43:05 DISPATCHER: Finished worker discovery
17:44:05 DISPATCHER: Starting worker discovery
17:44:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:44:05 DISPATCHER: Finished worker discovery
17:45:05 DISPATCHER: Starting worker discovery
17:45:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:45:05 DISPATCHER: Finished worker discovery
17:46:05 DISPATCHER: Starting worker discovery
17:46:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:46:05 DISPATCHER: Finished worker discovery
17:47:05 DISPATCHER: Starting worker discovery
17:47:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:47:05 DISPATCHER: Finished worker discovery
17:47:58 WORKER: done with job (6, 0, 5), trying to register it.
17:47:58 WORKER: registered result for job (6, 0, 5) with dispatcher
17:47:58 DISPATCHER: job (6, 0, 5) finished
17:47:58 DISPATCHER: register_result: lock acquired
17:47:58 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
17:47:58 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004119412943502646, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.010844904780392252, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 33, 'num_filters_3': 17}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8394253716366982, 'info': {'music-speech': 0.8394253716366982, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004119412943502646, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.010844904780392252, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 33, 'num_filters_3': 17}"}}
exception: None

17:47:58 job_callback for (6, 0, 5) started
17:47:58 job_callback for (6, 0, 5) got condition
17:47:58 DISPATCHER: Trying to submit another job.
17:47:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
17:47:58 HBMASTER: Trying to run another job!
17:47:58 job_callback for (6, 0, 5) finished
17:47:58 ITERATION: Advancing config (6, 0, 4) to next budget 1200.000000
17:47:58 ITERATION: Advancing config (6, 0, 5) to next budget 1200.000000
17:47:58 HBMASTER: schedule new run for iteration 6
17:47:58 HBMASTER: trying submitting job (6, 0, 4) to dispatcher
17:47:58 HBMASTER: submitting job (6, 0, 4) to dispatcher
17:47:58 DISPATCHER: trying to submit job (6, 0, 4)
17:47:58 DISPATCHER: trying to notify the job_runner thread.
17:47:58 HBMASTER: job (6, 0, 4) submitted to dispatcher
17:47:58 DISPATCHER: Trying to submit another job.
17:47:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
17:47:58 DISPATCHER: starting job (6, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
17:47:58 DISPATCHER: job (6, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
17:47:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
17:47:58 WORKER: start processing job (6, 0, 4)
17:47:58 WORKER: args: ()
17:47:58 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.02040177935270465, 'num_filters_1': 55, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.1372154816310358, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 79, 'num_filters_3': 16, 'num_filters_4': 71}, 'budget': 1200.0, 'working_directory': '.'}
17:48:05 DISPATCHER: Starting worker discovery
17:48:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:48:05 DISPATCHER: Finished worker discovery
Exception in thread Thread-726:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
    self.trainloop(criterion, optimizer, steps_to_train)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    onehot_preds = np.squeeze(np.eye(self.output_dim)[preds.reshape(-1)])
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

17:49:05 DISPATCHER: Starting worker discovery
17:49:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:49:05 DISPATCHER: Finished worker discovery
17:50:05 DISPATCHER: Starting worker discovery
17:50:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:50:05 DISPATCHER: Finished worker discovery
17:51:05 DISPATCHER: Starting worker discovery
17:51:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:51:05 DISPATCHER: Finished worker discovery
17:52:05 DISPATCHER: Starting worker discovery
17:52:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:52:05 DISPATCHER: Finished worker discovery
17:53:05 DISPATCHER: Starting worker discovery
17:53:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:53:05 DISPATCHER: Finished worker discovery
17:54:05 DISPATCHER: Starting worker discovery
17:54:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:54:05 DISPATCHER: Finished worker discovery
17:55:05 DISPATCHER: Starting worker discovery
17:55:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:55:05 DISPATCHER: Finished worker discovery
17:56:05 DISPATCHER: Starting worker discovery
17:56:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:56:05 DISPATCHER: Finished worker discovery
17:57:05 DISPATCHER: Starting worker discovery
17:57:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:57:05 DISPATCHER: Finished worker discovery
17:58:05 DISPATCHER: Starting worker discovery
17:58:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:58:05 DISPATCHER: Finished worker discovery
17:59:05 DISPATCHER: Starting worker discovery
17:59:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
17:59:05 DISPATCHER: Finished worker discovery
18:00:05 DISPATCHER: Starting worker discovery
18:00:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:00:05 DISPATCHER: Finished worker discovery
18:01:05 DISPATCHER: Starting worker discovery
18:01:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:01:05 DISPATCHER: Finished worker discovery
18:02:05 DISPATCHER: Starting worker discovery
18:02:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:02:05 DISPATCHER: Finished worker discovery
18:03:05 DISPATCHER: Starting worker discovery
18:03:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:03:05 DISPATCHER: Finished worker discovery
18:04:05 DISPATCHER: Starting worker discovery
18:04:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:04:05 DISPATCHER: Finished worker discovery
18:05:05 DISPATCHER: Starting worker discovery
18:05:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:05:05 DISPATCHER: Finished worker discovery
18:06:05 DISPATCHER: Starting worker discovery
18:06:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:06:05 DISPATCHER: Finished worker discovery
18:07:05 DISPATCHER: Starting worker discovery
18:07:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:07:05 DISPATCHER: Finished worker discovery
18:08:05 DISPATCHER: Starting worker discovery
18:08:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:08:05 DISPATCHER: Finished worker discovery
18:08:06 WORKER: done with job (6, 0, 4), trying to register it.
18:08:06 WORKER: registered result for job (6, 0, 4) with dispatcher
18:08:06 DISPATCHER: job (6, 0, 4) finished
18:08:06 DISPATCHER: register_result: lock acquired
18:08:06 DISPATCHER: job (6, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
18:08:06 job_id: (6, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.02040177935270465, 'num_filters_1': 55, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.1372154816310358, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 79, 'num_filters_3': 16, 'num_filters_4': 71}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.657861783131716, 'info': {'music-speech': 0.657861783131716, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.02040177935270465, 'num_filters_1': 55, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 56, 'weight_decay': 0.1372154816310358, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 79, 'num_filters_3': 16, 'num_filters_4': 71}"}}
exception: None

18:08:06 job_callback for (6, 0, 4) started
18:08:06 DISPATCHER: Trying to submit another job.
18:08:06 job_callback for (6, 0, 4) got condition
18:08:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
18:08:06 Only 11 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
18:08:06 HBMASTER: Trying to run another job!
18:08:06 job_callback for (6, 0, 4) finished
18:08:06 HBMASTER: schedule new run for iteration 6
18:08:06 HBMASTER: trying submitting job (6, 0, 5) to dispatcher
18:08:06 HBMASTER: submitting job (6, 0, 5) to dispatcher
18:08:06 DISPATCHER: trying to submit job (6, 0, 5)
18:08:06 DISPATCHER: trying to notify the job_runner thread.
18:08:06 HBMASTER: job (6, 0, 5) submitted to dispatcher
18:08:06 DISPATCHER: Trying to submit another job.
18:08:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
18:08:06 DISPATCHER: starting job (6, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
18:08:06 DISPATCHER: job (6, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
18:08:06 WORKER: start processing job (6, 0, 5)
18:08:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
18:08:06 WORKER: args: ()
18:08:06 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004119412943502646, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.010844904780392252, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 33, 'num_filters_3': 17}, 'budget': 1200.0, 'working_directory': '.'}
18:09:05 DISPATCHER: Starting worker discovery
18:09:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:09:05 DISPATCHER: Finished worker discovery
18:10:05 DISPATCHER: Starting worker discovery
18:10:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:10:05 DISPATCHER: Finished worker discovery
18:11:05 DISPATCHER: Starting worker discovery
18:11:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:11:05 DISPATCHER: Finished worker discovery
18:12:05 DISPATCHER: Starting worker discovery
18:12:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:12:05 DISPATCHER: Finished worker discovery
18:13:05 DISPATCHER: Starting worker discovery
18:13:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:13:05 DISPATCHER: Finished worker discovery
18:14:05 DISPATCHER: Starting worker discovery
18:14:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:14:05 DISPATCHER: Finished worker discovery
18:15:05 DISPATCHER: Starting worker discovery
18:15:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:15:05 DISPATCHER: Finished worker discovery
18:16:05 DISPATCHER: Starting worker discovery
18:16:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:16:05 DISPATCHER: Finished worker discovery
18:17:05 DISPATCHER: Starting worker discovery
18:17:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:17:05 DISPATCHER: Finished worker discovery
18:18:14 DISPATCHER: Starting worker discovery
18:25:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:25:39 DISPATCHER: Finished worker discovery
18:27:14 DISPATCHER: Starting worker discovery
18:28:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:28:04 DISPATCHER: Finished worker discovery
18:29:04 DISPATCHER: Starting worker discovery
18:29:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:29:45 DISPATCHER: Finished worker discovery
18:30:48 DISPATCHER: Starting worker discovery
18:31:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:31:02 DISPATCHER: Finished worker discovery
18:32:25 DISPATCHER: Starting worker discovery
18:33:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:34:06 DISPATCHER: Finished worker discovery
18:35:15 DISPATCHER: Starting worker discovery
18:35:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:35:17 DISPATCHER: Finished worker discovery
18:36:17 DISPATCHER: Starting worker discovery
18:37:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:37:22 DISPATCHER: Finished worker discovery
18:38:43 DISPATCHER: Starting worker discovery
18:38:44 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:38:44 DISPATCHER: Finished worker discovery
18:39:48 DISPATCHER: Starting worker discovery
18:40:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:40:40 DISPATCHER: Finished worker discovery
18:41:41 DISPATCHER: Starting worker discovery
18:42:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:42:44 DISPATCHER: Finished worker discovery
18:43:58 DISPATCHER: Starting worker discovery
18:43:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:43:58 DISPATCHER: Finished worker discovery
18:45:04 DISPATCHER: Starting worker discovery
18:45:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:45:37 DISPATCHER: Finished worker discovery
18:46:38 DISPATCHER: Starting worker discovery
18:48:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:49:02 DISPATCHER: Finished worker discovery
18:50:06 DISPATCHER: Starting worker discovery
18:50:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:50:13 DISPATCHER: Finished worker discovery
18:51:22 DISPATCHER: Starting worker discovery
18:51:35 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:51:35 DISPATCHER: Finished worker discovery
18:52:36 DISPATCHER: Starting worker discovery
18:53:36 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:53:53 DISPATCHER: Finished worker discovery
18:54:57 DISPATCHER: Starting worker discovery
18:57:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
18:58:42 DISPATCHER: Finished worker discovery
18:59:50 DISPATCHER: Starting worker discovery
19:01:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:01:14 DISPATCHER: Finished worker discovery
19:02:17 DISPATCHER: Starting worker discovery
19:03:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:03:19 DISPATCHER: Finished worker discovery
19:04:26 DISPATCHER: Starting worker discovery
19:04:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:04:50 DISPATCHER: Finished worker discovery
19:06:04 DISPATCHER: Starting worker discovery
19:06:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:06:08 DISPATCHER: Finished worker discovery
19:07:12 DISPATCHER: Starting worker discovery
19:07:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:08:11 DISPATCHER: Finished worker discovery
19:09:13 DISPATCHER: Starting worker discovery
19:11:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:11:07 DISPATCHER: Finished worker discovery
19:12:38 DISPATCHER: Starting worker discovery
19:12:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:12:51 DISPATCHER: Finished worker discovery
19:13:52 DISPATCHER: Starting worker discovery
19:14:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:14:53 DISPATCHER: Finished worker discovery
19:15:57 DISPATCHER: Starting worker discovery
19:15:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:15:58 DISPATCHER: Finished worker discovery
19:16:58 DISPATCHER: Starting worker discovery
19:18:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:18:53 DISPATCHER: Finished worker discovery
19:19:55 DISPATCHER: Starting worker discovery
19:20:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:20:27 DISPATCHER: Finished worker discovery
19:21:33 DISPATCHER: Starting worker discovery
19:21:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:21:37 DISPATCHER: Finished worker discovery
19:22:40 DISPATCHER: Starting worker discovery
19:23:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:24:04 DISPATCHER: Finished worker discovery
19:25:04 DISPATCHER: Starting worker discovery
19:25:41 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:26:19 DISPATCHER: Finished worker discovery
19:27:20 DISPATCHER: Starting worker discovery
19:27:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:27:20 DISPATCHER: Finished worker discovery
19:28:31 DISPATCHER: Starting worker discovery
19:28:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:28:52 DISPATCHER: Finished worker discovery
19:29:55 DISPATCHER: Starting worker discovery
19:31:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:32:02 DISPATCHER: Finished worker discovery
19:33:04 DISPATCHER: Starting worker discovery
19:33:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:33:18 DISPATCHER: Finished worker discovery
19:34:28 DISPATCHER: Starting worker discovery
19:34:46 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:35:31 DISPATCHER: Finished worker discovery
19:36:33 DISPATCHER: Starting worker discovery
19:37:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:37:43 DISPATCHER: Finished worker discovery
19:38:43 DISPATCHER: Starting worker discovery
19:40:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:41:48 DISPATCHER: Finished worker discovery
19:42:53 DISPATCHER: Starting worker discovery
19:43:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:43:13 DISPATCHER: Finished worker discovery
19:45:01 DISPATCHER: Starting worker discovery
19:46:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:46:38 DISPATCHER: Finished worker discovery
19:47:44 DISPATCHER: Starting worker discovery
19:48:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:48:26 DISPATCHER: Finished worker discovery
19:49:28 DISPATCHER: Starting worker discovery
19:50:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:50:13 DISPATCHER: Finished worker discovery
19:51:14 DISPATCHER: Starting worker discovery
19:51:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:51:55 DISPATCHER: Finished worker discovery
19:53:02 DISPATCHER: Starting worker discovery
19:53:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:53:33 DISPATCHER: Finished worker discovery
19:54:34 DISPATCHER: Starting worker discovery
19:56:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:56:03 DISPATCHER: Finished worker discovery
19:57:10 DISPATCHER: Starting worker discovery
19:57:31 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
19:57:35 DISPATCHER: Finished worker discovery
19:58:42 DISPATCHER: Starting worker discovery
19:59:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:00:28 DISPATCHER: Finished worker discovery
20:01:30 DISPATCHER: Starting worker discovery
20:02:09 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:02:09 DISPATCHER: Finished worker discovery
20:03:40 DISPATCHER: Starting worker discovery
20:04:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:04:40 DISPATCHER: Finished worker discovery
20:05:45 DISPATCHER: Starting worker discovery
20:06:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:06:26 DISPATCHER: Finished worker discovery
20:07:47 DISPATCHER: Starting worker discovery
20:07:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:07:56 DISPATCHER: Finished worker discovery
20:08:58 DISPATCHER: Starting worker discovery
20:11:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:11:07 DISPATCHER: Finished worker discovery
20:12:09 DISPATCHER: Starting worker discovery
20:12:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:12:11 DISPATCHER: Finished worker discovery
20:13:29 DISPATCHER: Starting worker discovery
20:13:30 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:13:30 DISPATCHER: Finished worker discovery
20:14:38 DISPATCHER: Starting worker discovery
20:15:00 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:15:36 DISPATCHER: Finished worker discovery
20:16:36 DISPATCHER: Starting worker discovery
20:17:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:17:59 DISPATCHER: Finished worker discovery
20:19:03 DISPATCHER: Starting worker discovery
20:20:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:20:03 DISPATCHER: Finished worker discovery
20:21:10 DISPATCHER: Starting worker discovery
20:22:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:22:48 DISPATCHER: Finished worker discovery
20:23:52 DISPATCHER: Starting worker discovery
20:24:24 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:24:39 DISPATCHER: Finished worker discovery
20:25:54 DISPATCHER: Starting worker discovery
20:27:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:27:38 DISPATCHER: Finished worker discovery
20:28:41 DISPATCHER: Starting worker discovery
20:29:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:29:08 DISPATCHER: Finished worker discovery
20:30:36 DISPATCHER: Starting worker discovery
20:31:40 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:31:40 DISPATCHER: Finished worker discovery
20:32:43 DISPATCHER: Starting worker discovery
20:32:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:32:43 DISPATCHER: Finished worker discovery
20:33:55 DISPATCHER: Starting worker discovery
20:35:02 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:35:43 DISPATCHER: Finished worker discovery
20:36:46 DISPATCHER: Starting worker discovery
20:36:55 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:36:55 DISPATCHER: Finished worker discovery
20:37:56 DISPATCHER: Starting worker discovery
20:37:56 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:37:56 DISPATCHER: Finished worker discovery
20:38:56 DISPATCHER: Starting worker discovery
20:41:54 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:43:30 DISPATCHER: Finished worker discovery
20:44:35 DISPATCHER: Starting worker discovery
20:46:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:46:27 DISPATCHER: Finished worker discovery
20:47:39 DISPATCHER: Starting worker discovery
20:48:27 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:48:27 DISPATCHER: Finished worker discovery
20:49:42 DISPATCHER: Starting worker discovery
20:51:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:52:27 DISPATCHER: Finished worker discovery
20:53:51 DISPATCHER: Starting worker discovery
20:54:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:54:51 DISPATCHER: Finished worker discovery
20:55:57 DISPATCHER: Starting worker discovery
20:56:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
20:57:07 DISPATCHER: Finished worker discovery
20:59:20 DISPATCHER: Starting worker discovery
21:09:06 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:09:48 DISPATCHER: Finished worker discovery
21:11:30 DISPATCHER: Starting worker discovery
21:11:42 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:11:42 DISPATCHER: Finished worker discovery
21:12:52 DISPATCHER: Starting worker discovery
21:15:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:15:15 DISPATCHER: Finished worker discovery
21:16:34 DISPATCHER: Starting worker discovery
21:18:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:18:23 DISPATCHER: Finished worker discovery
21:19:44 DISPATCHER: Starting worker discovery
21:26:37 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:34:21 DISPATCHER: Finished worker discovery
21:36:57 DISPATCHER: Starting worker discovery
21:38:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:38:13 DISPATCHER: Finished worker discovery
21:39:13 DISPATCHER: Starting worker discovery
21:41:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:42:48 DISPATCHER: Finished worker discovery
21:44:27 DISPATCHER: Starting worker discovery
21:47:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
21:52:06 DISPATCHER: Finished worker discovery
21:55:12 DISPATCHER: Starting worker discovery
21:59:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:08:39 DISPATCHER: Finished worker discovery
22:09:41 DISPATCHER: Starting worker discovery
22:13:33 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:30:08 DISPATCHER: Finished worker discovery
22:33:41 DISPATCHER: Starting worker discovery
22:36:04 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
22:43:42 DISPATCHER: Finished worker discovery
22:44:46 DISPATCHER: Starting worker discovery
01:43:01 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
01:54:41 DISPATCHER: Finished worker discovery
01:55:54 DISPATCHER: Starting worker discovery
02:11:05 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:23:22 DISPATCHER: Finished worker discovery
02:24:43 DISPATCHER: Starting worker discovery
02:33:08 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:33:08 DISPATCHER: Finished worker discovery
02:34:26 DISPATCHER: Starting worker discovery
02:39:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
02:55:02 DISPATCHER: Finished worker discovery
02:57:56 DISPATCHER: Starting worker discovery
03:00:50 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:19:37 DISPATCHER: Finished worker discovery
03:21:16 DISPATCHER: Starting worker discovery
03:34:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
03:55:50 DISPATCHER: Finished worker discovery
03:57:22 DISPATCHER: Starting worker discovery
04:00:45 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:00:48 DISPATCHER: Finished worker discovery
04:01:50 DISPATCHER: Starting worker discovery
04:02:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:02:38 DISPATCHER: Finished worker discovery
04:04:12 DISPATCHER: Starting worker discovery
04:04:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:04:22 DISPATCHER: Finished worker discovery
04:05:34 DISPATCHER: Starting worker discovery
04:05:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:05:39 DISPATCHER: Finished worker discovery
04:07:45 DISPATCHER: Starting worker discovery
04:15:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:15:25 DISPATCHER: Finished worker discovery
04:16:26 DISPATCHER: Starting worker discovery
04:16:32 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:19:16 DISPATCHER: Finished worker discovery
04:20:35 DISPATCHER: Starting worker discovery
04:25:03 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:25:03 DISPATCHER: Finished worker discovery
04:26:09 DISPATCHER: Starting worker discovery
04:26:51 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:26:51 DISPATCHER: Finished worker discovery
04:28:04 DISPATCHER: Starting worker discovery
04:31:48 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:35:14 DISPATCHER: Finished worker discovery
04:36:30 DISPATCHER: Starting worker discovery
04:37:59 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:39:01 DISPATCHER: Finished worker discovery
04:40:56 DISPATCHER: Starting worker discovery
04:52:34 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:52:44 DISPATCHER: Finished worker discovery
04:53:46 DISPATCHER: Starting worker discovery
04:55:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
04:58:49 DISPATCHER: Finished worker discovery
05:01:52 DISPATCHER: Starting worker discovery
05:09:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:09:19 DISPATCHER: Finished worker discovery
05:10:30 DISPATCHER: Starting worker discovery
05:16:58 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:20:21 DISPATCHER: Finished worker discovery
05:21:49 DISPATCHER: Starting worker discovery
05:24:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:24:44 DISPATCHER: Finished worker discovery
05:25:57 DISPATCHER: Starting worker discovery
05:40:10 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
05:47:49 DISPATCHER: Finished worker discovery
05:50:26 DISPATCHER: Starting worker discovery
05:52:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
06:01:25 DISPATCHER: Finished worker discovery
06:03:31 DISPATCHER: Starting worker discovery
10:58:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:46:52 DISPATCHER: Finished worker discovery
12:46:59 WORKER: done with job (6, 0, 5), trying to register it.
12:46:59 WORKER: registered result for job (6, 0, 5) with dispatcher
12:46:59 DISPATCHER: job (6, 0, 5) finished
12:46:59 DISPATCHER: register_result: lock acquired
12:46:59 DISPATCHER: job (6, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
12:46:59 job_id: (6, 0, 5)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004119412943502646, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.010844904780392252, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 33, 'num_filters_3': 17}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': 0, 'info': {'music-speech': 0, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.004119412943502646, 'num_filters_1': 19, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 76, 'weight_decay': 0.010844904780392252, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 33, 'num_filters_3': 17}"}}
exception: None

12:46:59 job_callback for (6, 0, 5) started
12:46:59 DISPATCHER: Trying to submit another job.
12:46:59 job_callback for (6, 0, 5) got condition
12:46:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
12:46:59 Only 12 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
12:46:59 HBMASTER: Trying to run another job!
12:46:59 job_callback for (6, 0, 5) finished
12:46:59 start sampling a new configuration.
12:46:59 best_vector: [0, 2, 0.32381674061977833, 0.45585915582304626, 0.2151800125819584, 0, 0.35718190968244357, 0.6010807758967506, 1, 1, 1, 2, 0.12945964543777316, 0.3447479260070527, 0.4191683139918879, 0.25499882093260434], 1.6536337553719017e-29, 0.0006047288262902569, -9.517818217433918e-06
12:46:59 done sampling a new configuration.
12:46:59 HBMASTER: schedule new run for iteration 7
12:46:59 HBMASTER: trying submitting job (7, 0, 0) to dispatcher
12:46:59 HBMASTER: submitting job (7, 0, 0) to dispatcher
12:46:59 DISPATCHER: trying to submit job (7, 0, 0)
12:46:59 DISPATCHER: trying to notify the job_runner thread.
12:46:59 HBMASTER: job (7, 0, 0) submitted to dispatcher
12:46:59 DISPATCHER: Trying to submit another job.
12:46:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
12:46:59 DISPATCHER: starting job (7, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
12:46:59 DISPATCHER: job (7, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
12:46:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
12:46:59 WORKER: start processing job (7, 0, 0)
12:46:59 WORKER: args: ()
12:46:59 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.004442561833719185, 'num_filters_1': 41, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.06053744942889862, 'kernel_size_2': 5, 'num_filters_2': 20}, 'budget': 1200.0, 'working_directory': '.'}
12:47:52 DISPATCHER: Starting worker discovery
12:47:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:47:52 DISPATCHER: Finished worker discovery
12:48:52 DISPATCHER: Starting worker discovery
12:48:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:48:52 DISPATCHER: Finished worker discovery
12:49:52 DISPATCHER: Starting worker discovery
12:49:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:49:52 DISPATCHER: Finished worker discovery
12:50:52 DISPATCHER: Starting worker discovery
12:50:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:50:52 DISPATCHER: Finished worker discovery
12:51:52 DISPATCHER: Starting worker discovery
12:51:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:51:52 DISPATCHER: Finished worker discovery
12:52:52 DISPATCHER: Starting worker discovery
12:52:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:52:52 DISPATCHER: Finished worker discovery
12:53:52 DISPATCHER: Starting worker discovery
12:53:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:53:52 DISPATCHER: Finished worker discovery
12:54:52 DISPATCHER: Starting worker discovery
12:54:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:54:52 DISPATCHER: Finished worker discovery
12:55:52 DISPATCHER: Starting worker discovery
12:55:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:55:52 DISPATCHER: Finished worker discovery
12:56:52 DISPATCHER: Starting worker discovery
12:56:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:56:52 DISPATCHER: Finished worker discovery
12:57:52 DISPATCHER: Starting worker discovery
12:57:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:57:52 DISPATCHER: Finished worker discovery
12:58:52 DISPATCHER: Starting worker discovery
12:58:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:58:52 DISPATCHER: Finished worker discovery
12:59:52 DISPATCHER: Starting worker discovery
12:59:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
12:59:52 DISPATCHER: Finished worker discovery
13:00:52 DISPATCHER: Starting worker discovery
13:00:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:00:52 DISPATCHER: Finished worker discovery
13:01:52 DISPATCHER: Starting worker discovery
13:01:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:01:52 DISPATCHER: Finished worker discovery
13:02:52 DISPATCHER: Starting worker discovery
13:02:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:02:52 DISPATCHER: Finished worker discovery
13:03:52 DISPATCHER: Starting worker discovery
13:03:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:03:52 DISPATCHER: Finished worker discovery
13:04:52 DISPATCHER: Starting worker discovery
13:04:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:04:52 DISPATCHER: Finished worker discovery
13:05:52 DISPATCHER: Starting worker discovery
13:05:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:05:52 DISPATCHER: Finished worker discovery
13:06:52 DISPATCHER: Starting worker discovery
13:06:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:06:52 DISPATCHER: Finished worker discovery
13:07:13 WORKER: done with job (7, 0, 0), trying to register it.
13:07:13 WORKER: registered result for job (7, 0, 0) with dispatcher
13:07:13 DISPATCHER: job (7, 0, 0) finished
13:07:13 DISPATCHER: register_result: lock acquired
13:07:13 DISPATCHER: job (7, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:07:13 job_id: (7, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.004442561833719185, 'num_filters_1': 41, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.06053744942889862, 'kernel_size_2': 5, 'num_filters_2': 20}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.8728569330257966, 'info': {'music-speech': 0.8728569330257966, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.004442561833719185, 'num_filters_1': 41, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 42, 'weight_decay': 0.06053744942889862, 'kernel_size_2': 5, 'num_filters_2': 20}"}}
exception: None

13:07:13 job_callback for (7, 0, 0) started
13:07:13 DISPATCHER: Trying to submit another job.
13:07:13 job_callback for (7, 0, 0) got condition
13:07:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:07:13 Only 13 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
13:07:13 HBMASTER: Trying to run another job!
13:07:13 job_callback for (7, 0, 0) finished
13:07:13 start sampling a new configuration.
13:07:13 done sampling a new configuration.
13:07:13 HBMASTER: schedule new run for iteration 7
13:07:13 HBMASTER: trying submitting job (7, 0, 1) to dispatcher
13:07:13 HBMASTER: submitting job (7, 0, 1) to dispatcher
13:07:13 DISPATCHER: trying to submit job (7, 0, 1)
13:07:13 DISPATCHER: trying to notify the job_runner thread.
13:07:13 HBMASTER: job (7, 0, 1) submitted to dispatcher
13:07:13 DISPATCHER: Trying to submit another job.
13:07:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:07:13 DISPATCHER: starting job (7, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:07:13 DISPATCHER: job (7, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:07:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:07:13 WORKER: start processing job (7, 0, 1)
13:07:13 WORKER: args: ()
13:07:13 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.058241422954736596, 'num_filters_1': 108, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.05544326500163944, 'kernel_size_2': 3, 'num_filters_2': 44}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-729:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    preds = np.concatenate(preds)
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

13:07:52 DISPATCHER: Starting worker discovery
13:07:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:07:52 DISPATCHER: Finished worker discovery
13:08:52 DISPATCHER: Starting worker discovery
13:08:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:08:52 DISPATCHER: Finished worker discovery
13:09:52 DISPATCHER: Starting worker discovery
13:09:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:09:52 DISPATCHER: Finished worker discovery
13:10:52 DISPATCHER: Starting worker discovery
13:10:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:10:52 DISPATCHER: Finished worker discovery
13:11:52 DISPATCHER: Starting worker discovery
13:11:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:11:52 DISPATCHER: Finished worker discovery
13:12:52 DISPATCHER: Starting worker discovery
13:12:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:12:52 DISPATCHER: Finished worker discovery
13:13:52 DISPATCHER: Starting worker discovery
13:13:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:13:52 DISPATCHER: Finished worker discovery
13:14:52 DISPATCHER: Starting worker discovery
13:14:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:14:52 DISPATCHER: Finished worker discovery
13:15:52 DISPATCHER: Starting worker discovery
13:15:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:15:52 DISPATCHER: Finished worker discovery
13:16:52 DISPATCHER: Starting worker discovery
13:16:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:16:52 DISPATCHER: Finished worker discovery
13:17:52 DISPATCHER: Starting worker discovery
13:17:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:17:52 DISPATCHER: Finished worker discovery
13:18:52 DISPATCHER: Starting worker discovery
13:18:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:18:52 DISPATCHER: Finished worker discovery
13:19:52 DISPATCHER: Starting worker discovery
13:19:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:19:52 DISPATCHER: Finished worker discovery
13:20:52 DISPATCHER: Starting worker discovery
13:20:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:20:52 DISPATCHER: Finished worker discovery
13:21:52 DISPATCHER: Starting worker discovery
13:21:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:21:52 DISPATCHER: Finished worker discovery
13:22:52 DISPATCHER: Starting worker discovery
13:22:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:22:52 DISPATCHER: Finished worker discovery
13:23:52 DISPATCHER: Starting worker discovery
13:23:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:23:52 DISPATCHER: Finished worker discovery
13:24:52 DISPATCHER: Starting worker discovery
13:24:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:24:52 DISPATCHER: Finished worker discovery
13:25:52 DISPATCHER: Starting worker discovery
13:25:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:25:52 DISPATCHER: Finished worker discovery
13:26:52 DISPATCHER: Starting worker discovery
13:26:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:26:52 DISPATCHER: Finished worker discovery
13:27:22 WORKER: done with job (7, 0, 1), trying to register it.
13:27:22 WORKER: registered result for job (7, 0, 1) with dispatcher
13:27:22 DISPATCHER: job (7, 0, 1) finished
13:27:22 DISPATCHER: register_result: lock acquired
13:27:22 DISPATCHER: job (7, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:27:22 job_id: (7, 0, 1)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.058241422954736596, 'num_filters_1': 108, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.05544326500163944, 'kernel_size_2': 3, 'num_filters_2': 44}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.47663054606801436, 'info': {'music-speech': 0.47663054606801436, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.058241422954736596, 'num_filters_1': 108, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.05544326500163944, 'kernel_size_2': 3, 'num_filters_2': 44}"}}
exception: None

13:27:22 job_callback for (7, 0, 1) started
13:27:22 DISPATCHER: Trying to submit another job.
13:27:22 job_callback for (7, 0, 1) got condition
13:27:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:27:22 Only 14 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
13:27:22 HBMASTER: Trying to run another job!
13:27:22 job_callback for (7, 0, 1) finished
13:27:22 start sampling a new configuration.
13:27:22 best_vector: [0, 0, 0.8639300547201281, 0.4484512976346869, 0.9778451300560821, 1, 0.8375969167130008, 0.8491335890347653, 2, 0, 1, 2, 0.43548140682567976, 0.7305699457924888, 0.7179496525475286, 0.30391119961572444], 7.613430037150066e-30, 0.0013134684302876052, -0.00014573523794667717
13:27:22 done sampling a new configuration.
13:27:22 HBMASTER: schedule new run for iteration 7
13:27:22 HBMASTER: trying submitting job (7, 0, 2) to dispatcher
13:27:22 HBMASTER: submitting job (7, 0, 2) to dispatcher
13:27:22 DISPATCHER: trying to submit job (7, 0, 2)
13:27:22 DISPATCHER: trying to notify the job_runner thread.
13:27:22 HBMASTER: job (7, 0, 2) submitted to dispatcher
13:27:22 DISPATCHER: Trying to submit another job.
13:27:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:27:22 DISPATCHER: starting job (7, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:27:22 DISPATCHER: job (7, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:27:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:27:22 WORKER: start processing job (7, 0, 2)
13:27:22 WORKER: args: ()
13:27:22 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.053439219864409075, 'num_filters_1': 40, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.1272765133642167, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 39, 'num_filters_3': 73, 'num_filters_4': 71, 'num_filters_5': 29}, 'budget': 1200.0, 'working_directory': '.'}
13:27:52 DISPATCHER: Starting worker discovery
13:27:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:27:52 DISPATCHER: Finished worker discovery
13:28:52 DISPATCHER: Starting worker discovery
13:28:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:28:52 DISPATCHER: Finished worker discovery
13:29:52 DISPATCHER: Starting worker discovery
13:29:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:29:52 DISPATCHER: Finished worker discovery
13:30:52 DISPATCHER: Starting worker discovery
13:30:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:30:52 DISPATCHER: Finished worker discovery
13:31:52 DISPATCHER: Starting worker discovery
13:31:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:31:52 DISPATCHER: Finished worker discovery
13:32:52 DISPATCHER: Starting worker discovery
13:32:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:32:52 DISPATCHER: Finished worker discovery
13:33:52 DISPATCHER: Starting worker discovery
13:33:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:33:52 DISPATCHER: Finished worker discovery
13:34:52 DISPATCHER: Starting worker discovery
13:34:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:34:52 DISPATCHER: Finished worker discovery
13:35:52 DISPATCHER: Starting worker discovery
13:35:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:35:52 DISPATCHER: Finished worker discovery
13:36:52 DISPATCHER: Starting worker discovery
13:36:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:36:52 DISPATCHER: Finished worker discovery
13:37:52 DISPATCHER: Starting worker discovery
13:37:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:37:52 DISPATCHER: Finished worker discovery
13:38:52 DISPATCHER: Starting worker discovery
13:38:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:38:52 DISPATCHER: Finished worker discovery
13:39:52 DISPATCHER: Starting worker discovery
13:39:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:39:52 DISPATCHER: Finished worker discovery
13:40:52 DISPATCHER: Starting worker discovery
13:40:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:40:52 DISPATCHER: Finished worker discovery
13:41:52 DISPATCHER: Starting worker discovery
13:41:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:41:52 DISPATCHER: Finished worker discovery
13:42:52 DISPATCHER: Starting worker discovery
13:42:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:42:52 DISPATCHER: Finished worker discovery
13:43:52 DISPATCHER: Starting worker discovery
13:43:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:43:52 DISPATCHER: Finished worker discovery
13:44:52 DISPATCHER: Starting worker discovery
13:44:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:44:52 DISPATCHER: Finished worker discovery
13:45:52 DISPATCHER: Starting worker discovery
13:45:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:45:52 DISPATCHER: Finished worker discovery
13:46:52 DISPATCHER: Starting worker discovery
13:46:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:46:52 DISPATCHER: Finished worker discovery
13:47:33 WORKER: done with job (7, 0, 2), trying to register it.
13:47:33 WORKER: registered result for job (7, 0, 2) with dispatcher
13:47:33 DISPATCHER: job (7, 0, 2) finished
13:47:33 DISPATCHER: register_result: lock acquired
13:47:33 DISPATCHER: job (7, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
13:47:33 job_id: (7, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.053439219864409075, 'num_filters_1': 40, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.1272765133642167, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 39, 'num_filters_3': 73, 'num_filters_4': 71, 'num_filters_5': 29}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.053439219864409075, 'num_filters_1': 40, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.1272765133642167, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 39, 'num_filters_3': 73, 'num_filters_4': 71, 'num_filters_5': 29}"}}
exception: None

13:47:33 job_callback for (7, 0, 2) started
13:47:33 DISPATCHER: Trying to submit another job.
13:47:33 job_callback for (7, 0, 2) got condition
13:47:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
13:47:33 Only 15 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
13:47:33 HBMASTER: Trying to run another job!
13:47:33 job_callback for (7, 0, 2) finished
13:47:33 start sampling a new configuration.
13:47:33 best_vector: [0, 0, 0.5209930176582523, 0.5265286588798037, 0.7428832975559816, 1, 0.5895157818006722, 0.8825520655300144, 2, 2, 0, 2, 0.05445377077886793, 0.9988912807919879, 0.9043307734694357, 0.5969250176086173], 3.2263819397975436e-29, 0.00030994470545007773, -5.298043099203578e-05
13:47:33 done sampling a new configuration.
13:47:33 HBMASTER: schedule new run for iteration 7
13:47:33 HBMASTER: trying submitting job (7, 0, 3) to dispatcher
13:47:33 HBMASTER: submitting job (7, 0, 3) to dispatcher
13:47:33 DISPATCHER: trying to submit job (7, 0, 3)
13:47:33 DISPATCHER: trying to notify the job_runner thread.
13:47:33 HBMASTER: job (7, 0, 3) submitted to dispatcher
13:47:33 DISPATCHER: Trying to submit another job.
13:47:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
13:47:33 DISPATCHER: starting job (7, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
13:47:33 DISPATCHER: job (7, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
13:47:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
13:47:33 WORKER: start processing job (7, 0, 3)
13:47:33 WORKER: args: ()
13:47:33 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.011015038902553191, 'num_filters_1': 47, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.14067816993226862, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 17, 'num_filters_3': 128, 'num_filters_4': 105}, 'budget': 1200.0, 'working_directory': '.'}
Exception in thread Thread-731:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    preds = np.concatenate(preds)
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

13:47:52 DISPATCHER: Starting worker discovery
13:47:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:47:52 DISPATCHER: Finished worker discovery
13:48:52 DISPATCHER: Starting worker discovery
13:48:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:48:52 DISPATCHER: Finished worker discovery
13:49:52 DISPATCHER: Starting worker discovery
13:49:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:49:52 DISPATCHER: Finished worker discovery
13:50:52 DISPATCHER: Starting worker discovery
13:50:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:50:52 DISPATCHER: Finished worker discovery
13:51:52 DISPATCHER: Starting worker discovery
13:51:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:51:52 DISPATCHER: Finished worker discovery
13:52:52 DISPATCHER: Starting worker discovery
13:52:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:52:52 DISPATCHER: Finished worker discovery
13:53:52 DISPATCHER: Starting worker discovery
13:53:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:53:52 DISPATCHER: Finished worker discovery
13:54:52 DISPATCHER: Starting worker discovery
13:54:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:54:52 DISPATCHER: Finished worker discovery
13:55:52 DISPATCHER: Starting worker discovery
13:55:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:55:52 DISPATCHER: Finished worker discovery
13:56:52 DISPATCHER: Starting worker discovery
13:56:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:56:52 DISPATCHER: Finished worker discovery
13:57:52 DISPATCHER: Starting worker discovery
13:57:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:57:52 DISPATCHER: Finished worker discovery
13:58:52 DISPATCHER: Starting worker discovery
13:58:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:58:52 DISPATCHER: Finished worker discovery
13:59:52 DISPATCHER: Starting worker discovery
13:59:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
13:59:52 DISPATCHER: Finished worker discovery
14:00:52 DISPATCHER: Starting worker discovery
14:00:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:00:52 DISPATCHER: Finished worker discovery
14:01:52 DISPATCHER: Starting worker discovery
14:01:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:01:52 DISPATCHER: Finished worker discovery
14:02:52 DISPATCHER: Starting worker discovery
14:02:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:02:52 DISPATCHER: Finished worker discovery
14:03:52 DISPATCHER: Starting worker discovery
14:03:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:03:52 DISPATCHER: Finished worker discovery
14:04:52 DISPATCHER: Starting worker discovery
14:04:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:04:52 DISPATCHER: Finished worker discovery
14:05:52 DISPATCHER: Starting worker discovery
14:05:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:05:52 DISPATCHER: Finished worker discovery
14:06:52 DISPATCHER: Starting worker discovery
14:06:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:06:52 DISPATCHER: Finished worker discovery
14:07:41 WORKER: done with job (7, 0, 3), trying to register it.
14:07:41 DISPATCHER: job (7, 0, 3) finished
14:07:41 WORKER: registered result for job (7, 0, 3) with dispatcher
14:07:41 DISPATCHER: register_result: lock acquired
14:07:41 DISPATCHER: job (7, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:07:41 job_id: (7, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.011015038902553191, 'num_filters_1': 47, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.14067816993226862, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 17, 'num_filters_3': 128, 'num_filters_4': 105}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.7986454830532094, 'info': {'music-speech': 0.7986454830532094, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.011015038902553191, 'num_filters_1': 47, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 63, 'weight_decay': 0.14067816993226862, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 3, 'num_filters_2': 17, 'num_filters_3': 128, 'num_filters_4': 105}"}}
exception: None

14:07:41 job_callback for (7, 0, 3) started
14:07:41 DISPATCHER: Trying to submit another job.
14:07:41 job_callback for (7, 0, 3) got condition
14:07:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:07:41 Only 16 run(s) for budget 1200.000000 available, need more than 18 -> can't build model!
14:07:41 HBMASTER: Trying to run another job!
14:07:41 job_callback for (7, 0, 3) finished
14:07:41 start sampling a new configuration.
14:07:41 done sampling a new configuration.
14:07:41 HBMASTER: schedule new run for iteration 8
14:07:41 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
14:07:41 HBMASTER: submitting job (8, 0, 0) to dispatcher
14:07:41 DISPATCHER: trying to submit job (8, 0, 0)
14:07:41 DISPATCHER: trying to notify the job_runner thread.
14:07:41 HBMASTER: job (8, 0, 0) submitted to dispatcher
14:07:41 DISPATCHER: Trying to submit another job.
14:07:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:07:41 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:07:41 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:07:41 WORKER: start processing job (8, 0, 0)
14:07:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:07:41 WORKER: args: ()
14:07:41 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.010332471523778256, 'num_filters_1': 82, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.011419450147202371, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 19, 'num_filters_3': 23, 'num_filters_4': 81}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:07:52 DISPATCHER: Starting worker discovery
14:07:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:07:52 DISPATCHER: Finished worker discovery
14:08:35 WORKER: done with job (8, 0, 0), trying to register it.
14:08:35 WORKER: registered result for job (8, 0, 0) with dispatcher
14:08:35 DISPATCHER: job (8, 0, 0) finished
14:08:35 DISPATCHER: register_result: lock acquired
14:08:35 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:08:35 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.010332471523778256, 'num_filters_1': 82, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.011419450147202371, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 19, 'num_filters_3': 23, 'num_filters_4': 81}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8128942132105436, 'info': {'music-speech': 0.8128942132105436, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.010332471523778256, 'num_filters_1': 82, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.011419450147202371, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 19, 'num_filters_3': 23, 'num_filters_4': 81}"}}
exception: None

14:08:35 job_callback for (8, 0, 0) started
14:08:35 DISPATCHER: Trying to submit another job.
14:08:35 job_callback for (8, 0, 0) got condition
14:08:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:08:35 HBMASTER: Trying to run another job!
14:08:35 job_callback for (8, 0, 0) finished
14:08:35 start sampling a new configuration.
14:08:35 done sampling a new configuration.
14:08:35 HBMASTER: schedule new run for iteration 8
14:08:35 HBMASTER: trying submitting job (8, 0, 1) to dispatcher
14:08:35 HBMASTER: submitting job (8, 0, 1) to dispatcher
14:08:35 DISPATCHER: trying to submit job (8, 0, 1)
14:08:35 DISPATCHER: trying to notify the job_runner thread.
14:08:35 HBMASTER: job (8, 0, 1) submitted to dispatcher
14:08:35 DISPATCHER: Trying to submit another job.
14:08:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:08:35 DISPATCHER: starting job (8, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:08:35 DISPATCHER: job (8, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:08:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:08:35 WORKER: start processing job (8, 0, 1)
14:08:35 WORKER: args: ()
14:08:35 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001849170824556542, 'num_filters_1': 23, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.1375353582381881, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 33, 'num_filters_3': 17, 'num_filters_4': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:08:52 DISPATCHER: Starting worker discovery
14:08:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:08:52 DISPATCHER: Finished worker discovery
14:09:29 WORKER: done with job (8, 0, 1), trying to register it.
14:09:29 WORKER: registered result for job (8, 0, 1) with dispatcher
14:09:29 DISPATCHER: job (8, 0, 1) finished
14:09:29 DISPATCHER: register_result: lock acquired
14:09:29 DISPATCHER: job (8, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:09:29 job_id: (8, 0, 1)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001849170824556542, 'num_filters_1': 23, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.1375353582381881, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 33, 'num_filters_3': 17, 'num_filters_4': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5809157726391351, 'info': {'music-speech': 0.5809157726391351, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.001849170824556542, 'num_filters_1': 23, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 86, 'weight_decay': 0.1375353582381881, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 5, 'num_filters_2': 33, 'num_filters_3': 17, 'num_filters_4': 16}"}}
exception: None

14:09:29 job_callback for (8, 0, 1) started
14:09:29 job_callback for (8, 0, 1) got condition
14:09:29 DISPATCHER: Trying to submit another job.
14:09:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:09:29 HBMASTER: Trying to run another job!
14:09:29 job_callback for (8, 0, 1) finished
14:09:29 start sampling a new configuration.
14:09:29 best_vector: [0, 2, 0.6062940198685799, 0.20333978612796277, 0.8234195366326867, 1, 0.809027918755491, 0.7616926897010947, 0, 2, 2, 2, 0.6509018686496801, 0.5197577711166773, 0.24060633510757234, 0.520019529271713], 4.410283914981382e-28, 2.267427719569436e-05, -2.0429324082254394e-05
14:09:29 done sampling a new configuration.
14:09:29 HBMASTER: schedule new run for iteration 8
14:09:29 HBMASTER: trying submitting job (8, 0, 2) to dispatcher
14:09:29 HBMASTER: submitting job (8, 0, 2) to dispatcher
14:09:29 DISPATCHER: trying to submit job (8, 0, 2)
14:09:29 DISPATCHER: trying to notify the job_runner thread.
14:09:29 HBMASTER: job (8, 0, 2) submitted to dispatcher
14:09:29 DISPATCHER: Trying to submit another job.
14:09:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:09:29 DISPATCHER: starting job (8, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:09:29 DISPATCHER: job (8, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:09:29 WORKER: start processing job (8, 0, 2)
14:09:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:09:29 WORKER: args: ()
14:09:29 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0163150361246538, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.09794562385545527, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 61, 'num_filters_3': 47, 'num_filters_4': 26, 'num_filters_5': 47}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-734:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    preds = np.concatenate(preds)
IndexError: index 1397541109 is out of bounds for axis 0 with size 2

14:09:52 DISPATCHER: Starting worker discovery
14:09:52 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:09:53 DISPATCHER: Finished worker discovery
14:10:22 WORKER: done with job (8, 0, 2), trying to register it.
14:10:22 WORKER: registered result for job (8, 0, 2) with dispatcher
14:10:22 DISPATCHER: job (8, 0, 2) finished
14:10:22 DISPATCHER: register_result: lock acquired
14:10:22 DISPATCHER: job (8, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:10:22 job_id: (8, 0, 2)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0163150361246538, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.09794562385545527, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 61, 'num_filters_3': 47, 'num_filters_4': 26, 'num_filters_5': 47}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6836363140626368, 'info': {'music-speech': 0.6836363140626368, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.0163150361246538, 'num_filters_1': 24, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 83, 'weight_decay': 0.09794562385545527, 'kernel_size_2': 3, 'kernel_size_3': 7, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 61, 'num_filters_3': 47, 'num_filters_4': 26, 'num_filters_5': 47}"}}
exception: None

14:10:22 job_callback for (8, 0, 2) started
14:10:22 DISPATCHER: Trying to submit another job.
14:10:22 job_callback for (8, 0, 2) got condition
14:10:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:10:22 HBMASTER: Trying to run another job!
14:10:22 job_callback for (8, 0, 2) finished
14:10:22 start sampling a new configuration.
14:10:22 best_vector: [3, 1, 0.3578877415121939, 0.06502859563908936, 0.13976861730179058, 0, 0.08468302349996978, 0.8102452095009434, 1, 0, 0, 2, 0.19694385818487858, 0.7869484047441402, 0.8103258140291749, 0.7330765414472556], 1.1484644074588293e-28, 8.707278984924472e-05, -1.3377447885748874e-05
14:10:22 done sampling a new configuration.
14:10:22 HBMASTER: schedule new run for iteration 8
14:10:22 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
14:10:22 HBMASTER: submitting job (8, 0, 3) to dispatcher
14:10:22 DISPATCHER: trying to submit job (8, 0, 3)
14:10:22 DISPATCHER: trying to notify the job_runner thread.
14:10:22 HBMASTER: job (8, 0, 3) submitted to dispatcher
14:10:22 DISPATCHER: Trying to submit another job.
14:10:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:10:22 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:10:22 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:10:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:10:22 WORKER: start processing job (8, 0, 3)
14:10:22 WORKER: args: ()
14:10:22 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0051972724396819525, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.11328002114293537}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:10:53 DISPATCHER: Starting worker discovery
14:10:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:10:53 DISPATCHER: Finished worker discovery
14:11:16 WORKER: done with job (8, 0, 3), trying to register it.
14:11:16 WORKER: registered result for job (8, 0, 3) with dispatcher
14:11:16 DISPATCHER: job (8, 0, 3) finished
14:11:16 DISPATCHER: register_result: lock acquired
14:11:16 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:11:16 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0051972724396819525, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.11328002114293537}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8982655102669813, 'info': {'music-speech': 0.8982655102669813, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0051972724396819525, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.11328002114293537}"}}
exception: None

14:11:16 job_callback for (8, 0, 3) started
14:11:16 job_callback for (8, 0, 3) got condition
14:11:16 DISPATCHER: Trying to submit another job.
14:11:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:11:16 HBMASTER: Trying to run another job!
14:11:16 job_callback for (8, 0, 3) finished
14:11:16 start sampling a new configuration.
14:11:16 best_vector: [0, 2, 0.31913668800125067, 0.6634756078861468, 0.5349693694203318, 1, 0.8831720345493008, 0.849566001361893, 2, 1, 2, 2, 0.25654365035141025, 0.9195830981307656, 0.8512416954567076, 0.859639831749381], 7.248651894585525e-29, 0.00013795668691815138, -3.081161141540711e-06
14:11:16 done sampling a new configuration.
14:11:16 HBMASTER: schedule new run for iteration 8
14:11:16 HBMASTER: trying submitting job (8, 0, 4) to dispatcher
14:11:16 HBMASTER: submitting job (8, 0, 4) to dispatcher
14:11:16 DISPATCHER: trying to submit job (8, 0, 4)
14:11:16 DISPATCHER: trying to notify the job_runner thread.
14:11:16 HBMASTER: job (8, 0, 4) submitted to dispatcher
14:11:16 DISPATCHER: Trying to submit another job.
14:11:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:11:16 DISPATCHER: starting job (8, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:11:16 DISPATCHER: job (8, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:11:16 WORKER: start processing job (8, 0, 4)
14:11:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:11:16 WORKER: args: ()
14:11:16 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00434783822079694, 'num_filters_1': 63, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.1274414931195275, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 27, 'num_filters_3': 108}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:11:53 DISPATCHER: Starting worker discovery
14:11:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:11:53 DISPATCHER: Finished worker discovery
14:12:09 WORKER: done with job (8, 0, 4), trying to register it.
14:12:09 WORKER: registered result for job (8, 0, 4) with dispatcher
14:12:09 DISPATCHER: job (8, 0, 4) finished
14:12:09 DISPATCHER: register_result: lock acquired
14:12:09 DISPATCHER: job (8, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:12:09 job_id: (8, 0, 4)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00434783822079694, 'num_filters_1': 63, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.1274414931195275, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 27, 'num_filters_3': 108}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5707818141223171, 'info': {'music-speech': 0.5707818141223171, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.00434783822079694, 'num_filters_1': 63, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 90, 'weight_decay': 0.1274414931195275, 'kernel_size_2': 7, 'kernel_size_3': 5, 'num_filters_2': 27, 'num_filters_3': 108}"}}
exception: None

14:12:09 job_callback for (8, 0, 4) started
14:12:09 DISPATCHER: Trying to submit another job.
14:12:09 job_callback for (8, 0, 4) got condition
14:12:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:12:09 HBMASTER: Trying to run another job!
14:12:09 job_callback for (8, 0, 4) finished
14:12:09 start sampling a new configuration.
14:12:09 best_vector: [1, 0, 0.8184371889872633, 0.7666415989288355, 0.3815178156382204, 0, 0.29896638703802103, 0.011678401066529898, 1, 1, 2, 2, 0.46736216584441814, 0.8504428446891046, 0.762407002646726, 0.5704541641045904], 4.14501484217112e-29, 0.00024125365965546445, -2.7945174358929836e-05
14:12:09 done sampling a new configuration.
14:12:09 HBMASTER: schedule new run for iteration 8
14:12:09 HBMASTER: trying submitting job (8, 0, 5) to dispatcher
14:12:09 HBMASTER: submitting job (8, 0, 5) to dispatcher
14:12:09 DISPATCHER: trying to submit job (8, 0, 5)
14:12:09 DISPATCHER: trying to notify the job_runner thread.
14:12:09 HBMASTER: job (8, 0, 5) submitted to dispatcher
14:12:09 DISPATCHER: Trying to submit another job.
14:12:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:12:09 DISPATCHER: starting job (8, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:12:09 DISPATCHER: job (8, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:12:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:12:09 WORKER: start processing job (8, 0, 5)
14:12:09 WORKER: args: ()
14:12:09 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.043338550115750135, 'num_filters_1': 78, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.010356045505226279, 'kernel_size_2': 5, 'num_filters_2': 42}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:12:53 DISPATCHER: Starting worker discovery
14:12:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:12:53 DISPATCHER: Finished worker discovery
14:13:02 WORKER: done with job (8, 0, 5), trying to register it.
14:13:02 WORKER: registered result for job (8, 0, 5) with dispatcher
14:13:02 DISPATCHER: job (8, 0, 5) finished
14:13:02 DISPATCHER: register_result: lock acquired
14:13:02 DISPATCHER: job (8, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:13:02 job_id: (8, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.043338550115750135, 'num_filters_1': 78, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.010356045505226279, 'kernel_size_2': 5, 'num_filters_2': 42}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0005415675388855178, 'info': {'music-speech': 0.0005415675388855178, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.043338550115750135, 'num_filters_1': 78, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 37, 'weight_decay': 0.010356045505226279, 'kernel_size_2': 5, 'num_filters_2': 42}"}}
exception: None

14:13:02 job_callback for (8, 0, 5) started
14:13:02 DISPATCHER: Trying to submit another job.
14:13:02 job_callback for (8, 0, 5) got condition
14:13:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:13:02 HBMASTER: Trying to run another job!
14:13:02 job_callback for (8, 0, 5) finished
14:13:02 start sampling a new configuration.
14:13:02 done sampling a new configuration.
14:13:02 HBMASTER: schedule new run for iteration 8
14:13:02 HBMASTER: trying submitting job (8, 0, 6) to dispatcher
14:13:02 HBMASTER: submitting job (8, 0, 6) to dispatcher
14:13:02 DISPATCHER: trying to submit job (8, 0, 6)
14:13:02 DISPATCHER: trying to notify the job_runner thread.
14:13:02 HBMASTER: job (8, 0, 6) submitted to dispatcher
14:13:02 DISPATCHER: Trying to submit another job.
14:13:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:13:02 DISPATCHER: starting job (8, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:13:02 DISPATCHER: job (8, 0, 6) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:13:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:13:02 WORKER: start processing job (8, 0, 6)
14:13:02 WORKER: args: ()
14:13:02 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.03412444255361201, 'num_filters_1': 66, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.1910539308458915, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 23, 'num_filters_3': 109}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:13:53 DISPATCHER: Starting worker discovery
14:13:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:13:53 DISPATCHER: Finished worker discovery
14:13:56 WORKER: done with job (8, 0, 6), trying to register it.
14:13:56 WORKER: registered result for job (8, 0, 6) with dispatcher
14:13:56 DISPATCHER: job (8, 0, 6) finished
14:13:56 DISPATCHER: register_result: lock acquired
14:13:56 DISPATCHER: job (8, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:13:56 job_id: (8, 0, 6)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.03412444255361201, 'num_filters_1': 66, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.1910539308458915, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 23, 'num_filters_3': 109}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.03412444255361201, 'num_filters_1': 66, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 99, 'weight_decay': 0.1910539308458915, 'kernel_size_2': 5, 'kernel_size_3': 3, 'num_filters_2': 23, 'num_filters_3': 109}"}}
exception: None

14:13:56 job_callback for (8, 0, 6) started
14:13:56 DISPATCHER: Trying to submit another job.
14:13:56 job_callback for (8, 0, 6) got condition
14:13:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:13:56 HBMASTER: Trying to run another job!
14:13:56 job_callback for (8, 0, 6) finished
14:13:56 start sampling a new configuration.
14:13:56 best_vector: [0, 0, 0.1017826797846123, 0.5474179113892381, 0.6549194145064057, 1, 0.8920797679042075, 0.22045196485855353, 2, 2, 2, 2, 0.3617884069839632, 0.7343649818140179, 0.9035860087296687, 0.23220593614738008], 6.92811162013377e-30, 0.0014433947586726264, -4.658278299220164e-06
14:13:56 done sampling a new configuration.
14:13:56 HBMASTER: schedule new run for iteration 8
14:13:56 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
14:13:56 HBMASTER: submitting job (8, 0, 7) to dispatcher
14:13:56 DISPATCHER: trying to submit job (8, 0, 7)
14:13:56 DISPATCHER: trying to notify the job_runner thread.
14:13:56 HBMASTER: job (8, 0, 7) submitted to dispatcher
14:13:56 DISPATCHER: Trying to submit another job.
14:13:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:13:56 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:13:56 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:13:56 WORKER: start processing job (8, 0, 7)
14:13:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:13:56 WORKER: args: ()
14:13:56 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0015979579972019017, 'num_filters_1': 49, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.019355955674000377, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 33, 'num_filters_3': 73, 'num_filters_4': 105}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:14:49 WORKER: done with job (8, 0, 7), trying to register it.
14:14:49 WORKER: registered result for job (8, 0, 7) with dispatcher
14:14:49 DISPATCHER: job (8, 0, 7) finished
14:14:49 DISPATCHER: register_result: lock acquired
14:14:49 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:14:49 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0015979579972019017, 'num_filters_1': 49, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.019355955674000377, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 33, 'num_filters_3': 73, 'num_filters_4': 105}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.9293077982053399, 'info': {'music-speech': 0.9293077982053399, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0015979579972019017, 'num_filters_1': 49, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.019355955674000377, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 33, 'num_filters_3': 73, 'num_filters_4': 105}"}}
exception: None

14:14:49 job_callback for (8, 0, 7) started
14:14:49 DISPATCHER: Trying to submit another job.
14:14:49 job_callback for (8, 0, 7) got condition
14:14:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:14:49 HBMASTER: Trying to run another job!
14:14:49 job_callback for (8, 0, 7) finished
14:14:49 start sampling a new configuration.
14:14:49 best_vector: [1, 2, 0.3708993965700412, 0.37877890284332283, 0.4239728857586954, 1, 0.955615464514643, 0.6062822954539493, 0, 2, 0, 2, 0.968145284341493, 0.7595157590858199, 0.7356206684036062, 0.8415789303969545], 1.4799274124532642e-29, 0.0006757088162468103, -2.9790845968288783e-05
14:14:49 done sampling a new configuration.
14:14:49 HBMASTER: schedule new run for iteration 8
14:14:49 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
14:14:49 HBMASTER: submitting job (8, 0, 8) to dispatcher
14:14:49 DISPATCHER: trying to submit job (8, 0, 8)
14:14:49 DISPATCHER: trying to notify the job_runner thread.
14:14:49 HBMASTER: job (8, 0, 8) submitted to dispatcher
14:14:49 DISPATCHER: Trying to submit another job.
14:14:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:14:49 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:14:49 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:14:49 WORKER: start processing job (8, 0, 8)
14:14:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:14:49 WORKER: args: ()
14:14:49 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005518217232983417, 'num_filters_1': 35, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.061488153630871345, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 120, 'num_filters_3': 77}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:14:53 DISPATCHER: Starting worker discovery
14:14:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:14:53 DISPATCHER: Finished worker discovery
Exception in thread Thread-740:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    preds = np.concatenate(preds)
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

14:15:42 WORKER: done with job (8, 0, 8), trying to register it.
14:15:42 DISPATCHER: job (8, 0, 8) finished
14:15:42 WORKER: registered result for job (8, 0, 8) with dispatcher
14:15:42 DISPATCHER: register_result: lock acquired
14:15:42 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:15:42 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005518217232983417, 'num_filters_1': 35, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.061488153630871345, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 120, 'num_filters_3': 77}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.93051585913149, 'info': {'music-speech': 0.93051585913149, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005518217232983417, 'num_filters_1': 35, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.061488153630871345, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 120, 'num_filters_3': 77}"}}
exception: None

14:15:42 job_callback for (8, 0, 8) started
14:15:42 DISPATCHER: Trying to submit another job.
14:15:42 job_callback for (8, 0, 8) got condition
14:15:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:15:42 HBMASTER: Trying to run another job!
14:15:42 job_callback for (8, 0, 8) finished
14:15:42 start sampling a new configuration.
14:15:42 done sampling a new configuration.
14:15:42 HBMASTER: schedule new run for iteration 8
14:15:42 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
14:15:42 HBMASTER: submitting job (8, 0, 9) to dispatcher
14:15:42 DISPATCHER: trying to submit job (8, 0, 9)
14:15:42 DISPATCHER: trying to notify the job_runner thread.
14:15:42 HBMASTER: job (8, 0, 9) submitted to dispatcher
14:15:42 DISPATCHER: Trying to submit another job.
14:15:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:15:42 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:15:42 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:15:42 WORKER: start processing job (8, 0, 9)
14:15:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:15:42 WORKER: args: ()
14:15:42 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.019966331739349332, 'num_filters_1': 24, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.01268651489722277, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 26, 'num_filters_3': 16, 'num_filters_4': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:15:53 DISPATCHER: Starting worker discovery
14:15:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:15:53 DISPATCHER: Finished worker discovery
Exception in thread Thread-741:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    preds = np.concatenate(preds)
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

14:16:35 WORKER: done with job (8, 0, 9), trying to register it.
14:16:35 DISPATCHER: job (8, 0, 9) finished
14:16:35 WORKER: registered result for job (8, 0, 9) with dispatcher
14:16:35 DISPATCHER: register_result: lock acquired
14:16:35 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:16:35 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.019966331739349332, 'num_filters_1': 24, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.01268651489722277, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 26, 'num_filters_3': 16, 'num_filters_4': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7473237711048546, 'info': {'music-speech': 0.7473237711048546, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.019966331739349332, 'num_filters_1': 24, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.01268651489722277, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 26, 'num_filters_3': 16, 'num_filters_4': 16}"}}
exception: None

14:16:35 job_callback for (8, 0, 9) started
14:16:35 DISPATCHER: Trying to submit another job.
14:16:35 job_callback for (8, 0, 9) got condition
14:16:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:16:35 HBMASTER: Trying to run another job!
14:16:35 job_callback for (8, 0, 9) finished
14:16:35 start sampling a new configuration.
14:16:35 best_vector: [3, 2, 0.4758845532300263, 0.175436282060353, 0.24386807993889273, 0, 0.23471208888153564, 0.8738144969701387, 0, 0, 1, 2, 0.20757391773773287, 0.4204635670026947, 0.8964296683254961, 0.33269229978878523], 2.4568174950689603e-29, 0.00040703064106596616, -1.0182724622048107e-05
14:16:35 done sampling a new configuration.
14:16:35 HBMASTER: schedule new run for iteration 8
14:16:35 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
14:16:35 HBMASTER: submitting job (8, 0, 10) to dispatcher
14:16:35 DISPATCHER: trying to submit job (8, 0, 10)
14:16:35 DISPATCHER: trying to notify the job_runner thread.
14:16:35 HBMASTER: job (8, 0, 10) submitted to dispatcher
14:16:35 DISPATCHER: Trying to submit another job.
14:16:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:16:35 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:16:35 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:16:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:16:35 WORKER: start processing job (8, 0, 10)
14:16:35 WORKER: args: ()
14:16:35 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.00894888869577269, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.13704363553455187, 'kernel_size_2': 3, 'num_filters_2': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:16:53 DISPATCHER: Starting worker discovery
14:16:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:16:53 DISPATCHER: Finished worker discovery
14:17:29 WORKER: done with job (8, 0, 10), trying to register it.
14:17:29 WORKER: registered result for job (8, 0, 10) with dispatcher
14:17:29 DISPATCHER: job (8, 0, 10) finished
14:17:29 DISPATCHER: register_result: lock acquired
14:17:29 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:17:29 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.00894888869577269, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.13704363553455187, 'kernel_size_2': 3, 'num_filters_2': 24}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8251290401079808, 'info': {'music-speech': 0.8251290401079808, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.00894888869577269, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.13704363553455187, 'kernel_size_2': 3, 'num_filters_2': 24}"}}
exception: None

14:17:29 job_callback for (8, 0, 10) started
14:17:29 DISPATCHER: Trying to submit another job.
14:17:29 job_callback for (8, 0, 10) got condition
14:17:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:17:29 HBMASTER: Trying to run another job!
14:17:29 job_callback for (8, 0, 10) finished
14:17:29 start sampling a new configuration.
14:17:29 done sampling a new configuration.
14:17:29 HBMASTER: schedule new run for iteration 8
14:17:29 HBMASTER: trying submitting job (8, 0, 11) to dispatcher
14:17:29 HBMASTER: submitting job (8, 0, 11) to dispatcher
14:17:29 DISPATCHER: trying to submit job (8, 0, 11)
14:17:29 DISPATCHER: trying to notify the job_runner thread.
14:17:29 HBMASTER: job (8, 0, 11) submitted to dispatcher
14:17:29 DISPATCHER: Trying to submit another job.
14:17:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:17:29 DISPATCHER: starting job (8, 0, 11) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:17:29 DISPATCHER: job (8, 0, 11) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:17:29 WORKER: start processing job (8, 0, 11)
14:17:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:17:29 WORKER: args: ()
14:17:29 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.03628476812142987, 'num_filters_1': 115, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.0354079671894138, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 33, 'num_filters_3': 60, 'num_filters_4': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:17:53 DISPATCHER: Starting worker discovery
14:17:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:17:53 DISPATCHER: Finished worker discovery
14:18:23 WORKER: done with job (8, 0, 11), trying to register it.
14:18:23 DISPATCHER: job (8, 0, 11) finished
14:18:23 WORKER: registered result for job (8, 0, 11) with dispatcher
14:18:23 DISPATCHER: register_result: lock acquired
14:18:23 DISPATCHER: job (8, 0, 11) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:18:23 job_id: (8, 0, 11)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.03628476812142987, 'num_filters_1': 115, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.0354079671894138, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 33, 'num_filters_3': 60, 'num_filters_4': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.03628476812142987, 'num_filters_1': 115, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 62, 'weight_decay': 0.0354079671894138, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 33, 'num_filters_3': 60, 'num_filters_4': 23}"}}
exception: None

14:18:23 job_callback for (8, 0, 11) started
14:18:23 DISPATCHER: Trying to submit another job.
14:18:23 job_callback for (8, 0, 11) got condition
14:18:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:18:23 HBMASTER: Trying to run another job!
14:18:23 job_callback for (8, 0, 11) finished
14:18:23 start sampling a new configuration.
14:18:24 best_vector: [3, 2, 0.08014031139127786, 0.9190677820788313, 0.6230022964349451, 0, 0.7988639466780426, 0.9723090197580861, 0, 0, 1, 2, 0.5284346079999289, 0.19474130055853484, 0.5087997914082074, 0.0766684003472674], 1.6394764422307005e-29, 0.0006099508198113432, -3.2337020430508e-06
14:18:24 done sampling a new configuration.
14:18:24 HBMASTER: schedule new run for iteration 8
14:18:24 HBMASTER: trying submitting job (8, 0, 12) to dispatcher
14:18:24 HBMASTER: submitting job (8, 0, 12) to dispatcher
14:18:24 DISPATCHER: trying to submit job (8, 0, 12)
14:18:24 DISPATCHER: trying to notify the job_runner thread.
14:18:24 HBMASTER: job (8, 0, 12) submitted to dispatcher
14:18:24 DISPATCHER: Trying to submit another job.
14:18:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:18:24 DISPATCHER: starting job (8, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:18:24 DISPATCHER: job (8, 0, 12) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:18:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:18:24 WORKER: start processing job (8, 0, 12)
14:18:24 WORKER: args: ()
14:18:24 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0014463740547950418, 'num_filters_1': 108, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.18407855638106432, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 47, 'num_filters_3': 23, 'num_filters_4': 45}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:18:53 DISPATCHER: Starting worker discovery
14:18:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:18:53 DISPATCHER: Finished worker discovery
14:19:18 WORKER: done with job (8, 0, 12), trying to register it.
14:19:18 WORKER: registered result for job (8, 0, 12) with dispatcher
14:19:18 DISPATCHER: job (8, 0, 12) finished
14:19:18 DISPATCHER: register_result: lock acquired
14:19:18 DISPATCHER: job (8, 0, 12) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:19:18 job_id: (8, 0, 12)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0014463740547950418, 'num_filters_1': 108, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.18407855638106432, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 47, 'num_filters_3': 23, 'num_filters_4': 45}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.5687847801388294, 'info': {'music-speech': 0.5687847801388294, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0014463740547950418, 'num_filters_1': 108, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 82, 'weight_decay': 0.18407855638106432, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'num_filters_2': 47, 'num_filters_3': 23, 'num_filters_4': 45}"}}
exception: None

14:19:18 job_callback for (8, 0, 12) started
14:19:18 DISPATCHER: Trying to submit another job.
14:19:18 job_callback for (8, 0, 12) got condition
14:19:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:19:18 HBMASTER: Trying to run another job!
14:19:18 job_callback for (8, 0, 12) finished
14:19:18 start sampling a new configuration.
14:19:18 best_vector: [1, 0, 0.28554805897613394, 0.5390788423188645, 0.855242971595668, 1, 0.995930814821476, 0.8521422482544989, 0, 0, 2, 2, 0.9487680000170842, 0.6847345971608462, 0.7604182593637602, 0.6602519952115938], 1.4216912263595725e-28, 7.033876143138561e-05, -5.728408839535599e-06
14:19:18 done sampling a new configuration.
14:19:18 HBMASTER: schedule new run for iteration 8
14:19:18 HBMASTER: trying submitting job (8, 0, 13) to dispatcher
14:19:18 HBMASTER: submitting job (8, 0, 13) to dispatcher
14:19:18 DISPATCHER: trying to submit job (8, 0, 13)
14:19:18 DISPATCHER: trying to notify the job_runner thread.
14:19:18 HBMASTER: job (8, 0, 13) submitted to dispatcher
14:19:18 DISPATCHER: Trying to submit another job.
14:19:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:19:18 DISPATCHER: starting job (8, 0, 13) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:19:18 DISPATCHER: job (8, 0, 13) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:19:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:19:18 WORKER: start processing job (8, 0, 13)
14:19:18 WORKER: args: ()
14:19:18 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.003724741330201348, 'num_filters_1': 48, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.12842885940846654, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 115, 'num_filters_3': 66, 'num_filters_4': 77, 'num_filters_5': 63}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:19:53 DISPATCHER: Starting worker discovery
14:19:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:19:53 DISPATCHER: Finished worker discovery
14:20:13 WORKER: done with job (8, 0, 13), trying to register it.
14:20:13 DISPATCHER: job (8, 0, 13) finished
14:20:13 WORKER: registered result for job (8, 0, 13) with dispatcher
14:20:13 DISPATCHER: register_result: lock acquired
14:20:13 DISPATCHER: job (8, 0, 13) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:20:13 job_id: (8, 0, 13)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.003724741330201348, 'num_filters_1': 48, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.12842885940846654, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 115, 'num_filters_3': 66, 'num_filters_4': 77, 'num_filters_5': 63}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.3817019360207669, 'info': {'music-speech': 0.3817019360207669, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.003724741330201348, 'num_filters_1': 48, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 100, 'weight_decay': 0.12842885940846654, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 7, 'kernel_size_5': 7, 'num_filters_2': 115, 'num_filters_3': 66, 'num_filters_4': 77, 'num_filters_5': 63}"}}
exception: None

14:20:13 job_callback for (8, 0, 13) started
14:20:13 DISPATCHER: Trying to submit another job.
14:20:13 job_callback for (8, 0, 13) got condition
14:20:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:20:13 HBMASTER: Trying to run another job!
14:20:13 job_callback for (8, 0, 13) finished
14:20:13 start sampling a new configuration.
14:20:13 best_vector: [0, 1, 0.6513784998164462, 0.3315718438253767, 0.9175499918007637, 1, 0.7417116140293548, 0.9762309156714095, 2, 0, 1, 2, 0.36872702866601426, 0.8225456174985014, 0.20848664148200668, 0.7508136672844097], 2.8202439748379154e-29, 0.0003545792523348878, -3.561906970925994e-05
14:20:13 done sampling a new configuration.
14:20:13 HBMASTER: schedule new run for iteration 8
14:20:13 HBMASTER: trying submitting job (8, 0, 14) to dispatcher
14:20:13 HBMASTER: submitting job (8, 0, 14) to dispatcher
14:20:13 DISPATCHER: trying to submit job (8, 0, 14)
14:20:13 DISPATCHER: trying to notify the job_runner thread.
14:20:13 HBMASTER: job (8, 0, 14) submitted to dispatcher
14:20:13 DISPATCHER: Trying to submit another job.
14:20:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:20:13 DISPATCHER: starting job (8, 0, 14) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:20:13 DISPATCHER: job (8, 0, 14) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:20:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:20:13 WORKER: start processing job (8, 0, 14)
14:20:13 WORKER: args: ()
14:20:13 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.02007968981307822, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.1862540409708431, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 34, 'num_filters_3': 88, 'num_filters_4': 24, 'num_filters_5': 76}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-746:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    preds = np.concatenate(preds)
IndexError: index 1580557694 is out of bounds for axis 0 with size 2

14:20:53 DISPATCHER: Starting worker discovery
14:20:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:20:53 DISPATCHER: Finished worker discovery
14:21:06 WORKER: done with job (8, 0, 14), trying to register it.
14:21:06 WORKER: registered result for job (8, 0, 14) with dispatcher
14:21:06 DISPATCHER: job (8, 0, 14) finished
14:21:06 DISPATCHER: register_result: lock acquired
14:21:06 DISPATCHER: job (8, 0, 14) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:21:06 job_id: (8, 0, 14)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.02007968981307822, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.1862540409708431, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 34, 'num_filters_3': 88, 'num_filters_4': 24, 'num_filters_5': 76}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6595118027528168, 'info': {'music-speech': 0.6595118027528168, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.02007968981307822, 'num_filters_1': 31, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 77, 'weight_decay': 0.1862540409708431, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 5, 'kernel_size_5': 7, 'num_filters_2': 34, 'num_filters_3': 88, 'num_filters_4': 24, 'num_filters_5': 76}"}}
exception: None

14:21:06 job_callback for (8, 0, 14) started
14:21:06 DISPATCHER: Trying to submit another job.
14:21:06 job_callback for (8, 0, 14) got condition
14:21:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:21:06 HBMASTER: Trying to run another job!
14:21:06 job_callback for (8, 0, 14) finished
14:21:06 start sampling a new configuration.
14:21:06 done sampling a new configuration.
14:21:06 HBMASTER: schedule new run for iteration 8
14:21:06 HBMASTER: trying submitting job (8, 0, 15) to dispatcher
14:21:06 HBMASTER: submitting job (8, 0, 15) to dispatcher
14:21:06 DISPATCHER: trying to submit job (8, 0, 15)
14:21:06 DISPATCHER: trying to notify the job_runner thread.
14:21:06 HBMASTER: job (8, 0, 15) submitted to dispatcher
14:21:06 DISPATCHER: Trying to submit another job.
14:21:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:21:06 DISPATCHER: starting job (8, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:21:06 DISPATCHER: job (8, 0, 15) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:21:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:21:06 WORKER: start processing job (8, 0, 15)
14:21:06 WORKER: args: ()
14:21:06 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.004321601115314549, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.04973880093227482, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 102, 'num_filters_3': 74, 'num_filters_4': 82, 'num_filters_5': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:21:53 DISPATCHER: Starting worker discovery
14:21:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:21:53 DISPATCHER: Finished worker discovery
14:22:00 WORKER: done with job (8, 0, 15), trying to register it.
14:22:00 DISPATCHER: job (8, 0, 15) finished
14:22:00 WORKER: registered result for job (8, 0, 15) with dispatcher
14:22:00 DISPATCHER: register_result: lock acquired
14:22:00 DISPATCHER: job (8, 0, 15) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:22:00 job_id: (8, 0, 15)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.004321601115314549, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.04973880093227482, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 102, 'num_filters_3': 74, 'num_filters_4': 82, 'num_filters_5': 23}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.003692785593204499, 'info': {'music-speech': 0.003692785593204499, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.004321601115314549, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 47, 'weight_decay': 0.04973880093227482, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 102, 'num_filters_3': 74, 'num_filters_4': 82, 'num_filters_5': 23}"}}
exception: None

14:22:00 job_callback for (8, 0, 15) started
14:22:00 DISPATCHER: Trying to submit another job.
14:22:00 job_callback for (8, 0, 15) got condition
14:22:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:22:00 HBMASTER: Trying to run another job!
14:22:00 job_callback for (8, 0, 15) finished
14:22:00 start sampling a new configuration.
14:22:00 done sampling a new configuration.
14:22:00 HBMASTER: schedule new run for iteration 8
14:22:00 HBMASTER: trying submitting job (8, 0, 16) to dispatcher
14:22:00 HBMASTER: submitting job (8, 0, 16) to dispatcher
14:22:00 DISPATCHER: trying to submit job (8, 0, 16)
14:22:00 DISPATCHER: trying to notify the job_runner thread.
14:22:00 HBMASTER: job (8, 0, 16) submitted to dispatcher
14:22:00 DISPATCHER: Trying to submit another job.
14:22:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:22:00 DISPATCHER: starting job (8, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:22:00 DISPATCHER: job (8, 0, 16) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:22:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:22:00 WORKER: start processing job (8, 0, 16)
14:22:00 WORKER: args: ()
14:22:00 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.014024404191263976, 'num_filters_1': 52, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.011313043581243312, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 21, 'num_filters_3': 36}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-748:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    preds = np.concatenate(preds)
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

14:22:53 DISPATCHER: Starting worker discovery
14:22:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:22:53 DISPATCHER: Finished worker discovery
14:22:53 WORKER: done with job (8, 0, 16), trying to register it.
14:22:53 WORKER: registered result for job (8, 0, 16) with dispatcher
14:22:53 DISPATCHER: job (8, 0, 16) finished
14:22:53 DISPATCHER: register_result: lock acquired
14:22:53 DISPATCHER: job (8, 0, 16) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:22:53 job_id: (8, 0, 16)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.014024404191263976, 'num_filters_1': 52, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.011313043581243312, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 21, 'num_filters_3': 36}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7077596422929021, 'info': {'music-speech': 0.7077596422929021, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.014024404191263976, 'num_filters_1': 52, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 79, 'weight_decay': 0.011313043581243312, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 21, 'num_filters_3': 36}"}}
exception: None

14:22:53 job_callback for (8, 0, 16) started
14:22:53 DISPATCHER: Trying to submit another job.
14:22:53 job_callback for (8, 0, 16) got condition
14:22:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:22:53 HBMASTER: Trying to run another job!
14:22:53 job_callback for (8, 0, 16) finished
14:22:53 start sampling a new configuration.
14:22:53 done sampling a new configuration.
14:22:53 HBMASTER: schedule new run for iteration 8
14:22:53 HBMASTER: trying submitting job (8, 0, 17) to dispatcher
14:22:53 HBMASTER: submitting job (8, 0, 17) to dispatcher
14:22:53 DISPATCHER: trying to submit job (8, 0, 17)
14:22:53 DISPATCHER: trying to notify the job_runner thread.
14:22:53 HBMASTER: job (8, 0, 17) submitted to dispatcher
14:22:53 DISPATCHER: Trying to submit another job.
14:22:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:22:53 DISPATCHER: starting job (8, 0, 17) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:22:53 DISPATCHER: job (8, 0, 17) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:22:53 WORKER: start processing job (8, 0, 17)
14:22:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:22:53 WORKER: args: ()
14:22:53 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.013543249096932367, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.06789388582786685, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 107, 'num_filters_3': 77, 'num_filters_4': 22}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:23:46 WORKER: done with job (8, 0, 17), trying to register it.
14:23:46 WORKER: registered result for job (8, 0, 17) with dispatcher
14:23:46 DISPATCHER: job (8, 0, 17) finished
14:23:46 DISPATCHER: register_result: lock acquired
14:23:46 DISPATCHER: job (8, 0, 17) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:23:46 job_id: (8, 0, 17)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.013543249096932367, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.06789388582786685, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 107, 'num_filters_3': 77, 'num_filters_4': 22}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.36426054799249397, 'info': {'music-speech': 0.36426054799249397, 'config': "{'batch_size': 64, 'kernel_size_1': 7, 'lr': 0.013543249096932367, 'num_filters_1': 17, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 17, 'weight_decay': 0.06789388582786685, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 7, 'num_filters_2': 107, 'num_filters_3': 77, 'num_filters_4': 22}"}}
exception: None

14:23:46 job_callback for (8, 0, 17) started
14:23:46 DISPATCHER: Trying to submit another job.
14:23:46 job_callback for (8, 0, 17) got condition
14:23:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:23:46 HBMASTER: Trying to run another job!
14:23:46 job_callback for (8, 0, 17) finished
14:23:46 start sampling a new configuration.
14:23:46 best_vector: [1, 0, 0.6630089735600053, 0.853882700898676, 0.20988834391832661, 0, 0.7846816422755887, 0.9048089216180771, 0, 2, 0, 2, 0.8808398798161087, 0.1507222313136481, 0.9677145852991158, 0.8931266129427461], 4.304413987038995e-28, 2.3231966140131885e-05, -6.295714597908185e-05
14:23:46 done sampling a new configuration.
14:23:46 HBMASTER: schedule new run for iteration 8
14:23:46 HBMASTER: trying submitting job (8, 0, 18) to dispatcher
14:23:46 HBMASTER: submitting job (8, 0, 18) to dispatcher
14:23:46 DISPATCHER: trying to submit job (8, 0, 18)
14:23:46 DISPATCHER: trying to notify the job_runner thread.
14:23:46 HBMASTER: job (8, 0, 18) submitted to dispatcher
14:23:46 DISPATCHER: Trying to submit another job.
14:23:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:23:46 DISPATCHER: starting job (8, 0, 18) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:23:46 DISPATCHER: job (8, 0, 18) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:23:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:23:46 WORKER: start processing job (8, 0, 18)
14:23:46 WORKER: args: ()
14:23:46 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.02118448677846136, 'num_filters_1': 94, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.1503777378409035, 'kernel_size_2': 3, 'num_filters_2': 100}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:23:53 DISPATCHER: Starting worker discovery
14:23:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:23:53 DISPATCHER: Finished worker discovery
14:24:40 WORKER: done with job (8, 0, 18), trying to register it.
14:24:40 WORKER: registered result for job (8, 0, 18) with dispatcher
14:24:40 DISPATCHER: job (8, 0, 18) finished
14:24:40 DISPATCHER: register_result: lock acquired
14:24:40 DISPATCHER: job (8, 0, 18) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:24:40 job_id: (8, 0, 18)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.02118448677846136, 'num_filters_1': 94, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.1503777378409035, 'kernel_size_2': 3, 'num_filters_2': 100}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.0, 'info': {'music-speech': 0.0, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.02118448677846136, 'num_filters_1': 94, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 81, 'weight_decay': 0.1503777378409035, 'kernel_size_2': 3, 'num_filters_2': 100}"}}
exception: None

14:24:40 job_callback for (8, 0, 18) started
14:24:40 DISPATCHER: Trying to submit another job.
14:24:40 job_callback for (8, 0, 18) got condition
14:24:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:24:40 HBMASTER: Trying to run another job!
14:24:40 job_callback for (8, 0, 18) finished
14:24:40 start sampling a new configuration.
14:24:40 best_vector: [3, 1, 0.745591445892515, 0.06927521255379274, 0.8652664290774329, 1, 0.474408715942358, 0.777513453506102, 0, 0, 0, 2, 0.29909264641875555, 0.6960721192270782, 0.554457334251886, 0.9567033260602655], 3.494792811250369e-29, 0.0002861399957047009, -3.008264294393112e-06
14:24:40 done sampling a new configuration.
14:24:40 HBMASTER: schedule new run for iteration 8
14:24:40 HBMASTER: trying submitting job (8, 0, 19) to dispatcher
14:24:40 HBMASTER: submitting job (8, 0, 19) to dispatcher
14:24:40 DISPATCHER: trying to submit job (8, 0, 19)
14:24:40 DISPATCHER: trying to notify the job_runner thread.
14:24:40 HBMASTER: job (8, 0, 19) submitted to dispatcher
14:24:40 DISPATCHER: Trying to submit another job.
14:24:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:24:40 DISPATCHER: starting job (8, 0, 19) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:24:40 DISPATCHER: job (8, 0, 19) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:24:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:24:40 WORKER: start processing job (8, 0, 19)
14:24:40 WORKER: args: ()
14:24:40 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.030987239712001114, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.10269949901523578, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 29, 'num_filters_3': 68, 'num_filters_4': 50, 'num_filters_5': 117}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-751:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    preds = np.concatenate(preds)
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

14:24:53 DISPATCHER: Starting worker discovery
14:24:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:24:53 DISPATCHER: Finished worker discovery
14:25:33 WORKER: done with job (8, 0, 19), trying to register it.
14:25:33 WORKER: registered result for job (8, 0, 19) with dispatcher
14:25:33 DISPATCHER: job (8, 0, 19) finished
14:25:33 DISPATCHER: register_result: lock acquired
14:25:33 DISPATCHER: job (8, 0, 19) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:25:33 job_id: (8, 0, 19)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.030987239712001114, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.10269949901523578, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 29, 'num_filters_3': 68, 'num_filters_4': 50, 'num_filters_5': 117}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.45226716895989033, 'info': {'music-speech': 0.45226716895989033, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.030987239712001114, 'num_filters_1': 18, 'num_layers': 5, 'optimizer': 'SGD', 'steps_to_train': 53, 'weight_decay': 0.10269949901523578, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 29, 'num_filters_3': 68, 'num_filters_4': 50, 'num_filters_5': 117}"}}
exception: None

14:25:33 job_callback for (8, 0, 19) started
14:25:33 DISPATCHER: Trying to submit another job.
14:25:33 job_callback for (8, 0, 19) got condition
14:25:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:25:33 HBMASTER: Trying to run another job!
14:25:33 job_callback for (8, 0, 19) finished
14:25:33 start sampling a new configuration.
14:25:34 best_vector: [3, 1, 0.6107965370471473, 0.9592791791199351, 0.7076856012925512, 1, 0.5654803070462374, 0.2874077839617378, 2, 1, 1, 2, 0.7580570592519241, 0.04056539498610695, 0.4188581736983884, 0.1864851811137918], 1.5581595435306714e-29, 0.0006417828034054047, -0.0012016878843861027
14:25:34 done sampling a new configuration.
14:25:34 HBMASTER: schedule new run for iteration 8
14:25:34 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
14:25:34 HBMASTER: submitting job (8, 0, 20) to dispatcher
14:25:34 DISPATCHER: trying to submit job (8, 0, 20)
14:25:34 DISPATCHER: trying to notify the job_runner thread.
14:25:34 HBMASTER: job (8, 0, 20) submitted to dispatcher
14:25:34 DISPATCHER: Trying to submit another job.
14:25:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:25:34 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:25:34 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:25:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:25:34 WORKER: start processing job (8, 0, 20)
14:25:34 WORKER: args: ()
14:25:34 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.016656857643545377, 'num_filters_1': 118, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.0236551740540297, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 77, 'num_filters_3': 17, 'num_filters_4': 38}, 'budget': 44.44444444444444, 'working_directory': '.'}
Exception in thread Thread-752:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    preds = np.concatenate(preds)
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

14:25:53 DISPATCHER: Starting worker discovery
14:25:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:25:53 DISPATCHER: Finished worker discovery
14:26:27 WORKER: done with job (8, 0, 20), trying to register it.
14:26:27 WORKER: registered result for job (8, 0, 20) with dispatcher
14:26:27 DISPATCHER: job (8, 0, 20) finished
14:26:27 DISPATCHER: register_result: lock acquired
14:26:27 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:26:27 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.016656857643545377, 'num_filters_1': 118, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.0236551740540297, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 77, 'num_filters_3': 17, 'num_filters_4': 38}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.7711653382371102, 'info': {'music-speech': 0.7711653382371102, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.016656857643545377, 'num_filters_1': 118, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.0236551740540297, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 77, 'num_filters_3': 17, 'num_filters_4': 38}"}}
exception: None

14:26:27 job_callback for (8, 0, 20) started
14:26:27 DISPATCHER: Trying to submit another job.
14:26:27 job_callback for (8, 0, 20) got condition
14:26:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:26:27 HBMASTER: Trying to run another job!
14:26:27 job_callback for (8, 0, 20) finished
14:26:27 start sampling a new configuration.
14:26:27 best_vector: [1, 2, 0.746365179744695, 0.48669223292107533, 0.3690383197833209, 0, 0.08773898178295392, 0.17609591896027332, 1, 0, 1, 2, 0.2880119856092317, 0.8813841813486429, 0.7690842244402976, 0.8024230364025309], 5.560455915365105e-30, 0.0017984136826563423, -3.215549171742973e-06
14:26:27 done sampling a new configuration.
14:26:27 HBMASTER: schedule new run for iteration 8
14:26:27 HBMASTER: trying submitting job (8, 0, 21) to dispatcher
14:26:27 HBMASTER: submitting job (8, 0, 21) to dispatcher
14:26:27 DISPATCHER: trying to submit job (8, 0, 21)
14:26:27 DISPATCHER: trying to notify the job_runner thread.
14:26:27 HBMASTER: job (8, 0, 21) submitted to dispatcher
14:26:27 DISPATCHER: Trying to submit another job.
14:26:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:26:27 DISPATCHER: starting job (8, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:26:27 DISPATCHER: job (8, 0, 21) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:26:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:26:27 WORKER: start processing job (8, 0, 21)
14:26:27 WORKER: args: ()
14:26:27 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.031097849647264454, 'num_filters_1': 43, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.0169475167838209, 'kernel_size_2': 5, 'num_filters_2': 29}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:26:53 DISPATCHER: Starting worker discovery
14:26:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:26:53 DISPATCHER: Finished worker discovery
14:27:20 WORKER: done with job (8, 0, 21), trying to register it.
14:27:20 WORKER: registered result for job (8, 0, 21) with dispatcher
14:27:20 DISPATCHER: job (8, 0, 21) finished
14:27:20 DISPATCHER: register_result: lock acquired
14:27:20 DISPATCHER: job (8, 0, 21) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:27:20 job_id: (8, 0, 21)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.031097849647264454, 'num_filters_1': 43, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.0169475167838209, 'kernel_size_2': 5, 'num_filters_2': 29}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.00034476519131224987, 'info': {'music-speech': 0.00034476519131224987, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.031097849647264454, 'num_filters_1': 43, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.0169475167838209, 'kernel_size_2': 5, 'num_filters_2': 29}"}}
exception: None

14:27:20 job_callback for (8, 0, 21) started
14:27:20 DISPATCHER: Trying to submit another job.
14:27:20 job_callback for (8, 0, 21) got condition
14:27:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:27:20 HBMASTER: Trying to run another job!
14:27:20 job_callback for (8, 0, 21) finished
14:27:20 start sampling a new configuration.
14:27:20 done sampling a new configuration.
14:27:20 HBMASTER: schedule new run for iteration 8
14:27:20 HBMASTER: trying submitting job (8, 0, 22) to dispatcher
14:27:20 HBMASTER: submitting job (8, 0, 22) to dispatcher
14:27:20 DISPATCHER: trying to submit job (8, 0, 22)
14:27:20 DISPATCHER: trying to notify the job_runner thread.
14:27:20 HBMASTER: job (8, 0, 22) submitted to dispatcher
14:27:20 DISPATCHER: Trying to submit another job.
14:27:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:27:20 DISPATCHER: starting job (8, 0, 22) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:27:20 DISPATCHER: job (8, 0, 22) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:27:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:27:20 WORKER: start processing job (8, 0, 22)
14:27:20 WORKER: args: ()
14:27:20 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0011398014645449162, 'num_filters_1': 67, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.023484406658078393, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 39, 'num_filters_3': 56, 'num_filters_4': 51, 'num_filters_5': 37}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:27:53 DISPATCHER: Starting worker discovery
14:27:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:27:53 DISPATCHER: Finished worker discovery
14:28:14 WORKER: done with job (8, 0, 22), trying to register it.
14:28:14 WORKER: registered result for job (8, 0, 22) with dispatcher
14:28:14 DISPATCHER: job (8, 0, 22) finished
14:28:14 DISPATCHER: register_result: lock acquired
14:28:14 DISPATCHER: job (8, 0, 22) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:28:14 job_id: (8, 0, 22)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0011398014645449162, 'num_filters_1': 67, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.023484406658078393, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 39, 'num_filters_3': 56, 'num_filters_4': 51, 'num_filters_5': 37}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6764520189665374, 'info': {'music-speech': 0.6764520189665374, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0011398014645449162, 'num_filters_1': 67, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 58, 'weight_decay': 0.023484406658078393, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 39, 'num_filters_3': 56, 'num_filters_4': 51, 'num_filters_5': 37}"}}
exception: None

14:28:14 job_callback for (8, 0, 22) started
14:28:14 DISPATCHER: Trying to submit another job.
14:28:14 job_callback for (8, 0, 22) got condition
14:28:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:28:14 HBMASTER: Trying to run another job!
14:28:14 job_callback for (8, 0, 22) finished
14:28:14 start sampling a new configuration.
14:28:14 best_vector: [1, 1, 0.3794817008992124, 0.9005998001083602, 0.4571109299875623, 0, 0.5167753740267428, 0.3055996820977963, 1, 2, 1, 2, 0.3799176563128058, 0.7507578033965612, 0.9779685956580934, 0.9343464370079171], 7.378511576094418e-30, 0.0013552868890792178, -2.095218674707764e-06
14:28:14 done sampling a new configuration.
14:28:14 HBMASTER: schedule new run for iteration 8
14:28:14 HBMASTER: trying submitting job (8, 0, 23) to dispatcher
14:28:14 HBMASTER: submitting job (8, 0, 23) to dispatcher
14:28:14 DISPATCHER: trying to submit job (8, 0, 23)
14:28:14 DISPATCHER: trying to notify the job_runner thread.
14:28:14 HBMASTER: job (8, 0, 23) submitted to dispatcher
14:28:14 DISPATCHER: Trying to submit another job.
14:28:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:28:14 DISPATCHER: starting job (8, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:28:14 DISPATCHER: job (8, 0, 23) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:28:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:28:14 WORKER: start processing job (8, 0, 23)
14:28:14 WORKER: args: ()
14:28:14 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.005740680831797742, 'num_filters_1': 104, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.024980110380489532, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 35, 'num_filters_3': 76}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:28:53 DISPATCHER: Starting worker discovery
14:28:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:28:53 DISPATCHER: Finished worker discovery
14:29:08 WORKER: done with job (8, 0, 23), trying to register it.
14:29:08 WORKER: registered result for job (8, 0, 23) with dispatcher
14:29:08 DISPATCHER: job (8, 0, 23) finished
14:29:08 DISPATCHER: register_result: lock acquired
14:29:08 DISPATCHER: job (8, 0, 23) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:29:08 job_id: (8, 0, 23)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.005740680831797742, 'num_filters_1': 104, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.024980110380489532, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 35, 'num_filters_3': 76}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6551883776835103, 'info': {'music-speech': 0.6551883776835103, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.005740680831797742, 'num_filters_1': 104, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 57, 'weight_decay': 0.024980110380489532, 'kernel_size_2': 5, 'kernel_size_3': 7, 'num_filters_2': 35, 'num_filters_3': 76}"}}
exception: None

14:29:08 job_callback for (8, 0, 23) started
14:29:08 job_callback for (8, 0, 23) got condition
14:29:08 DISPATCHER: Trying to submit another job.
14:29:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:29:08 HBMASTER: Trying to run another job!
14:29:08 job_callback for (8, 0, 23) finished
14:29:08 start sampling a new configuration.
14:29:08 done sampling a new configuration.
14:29:08 HBMASTER: schedule new run for iteration 8
14:29:08 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
14:29:08 HBMASTER: submitting job (8, 0, 24) to dispatcher
14:29:08 DISPATCHER: trying to submit job (8, 0, 24)
14:29:08 DISPATCHER: trying to notify the job_runner thread.
14:29:08 HBMASTER: job (8, 0, 24) submitted to dispatcher
14:29:08 DISPATCHER: Trying to submit another job.
14:29:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:29:08 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:29:08 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:29:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:29:08 WORKER: start processing job (8, 0, 24)
14:29:08 WORKER: args: ()
14:29:08 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001951476654726059, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.08956471111236476, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 21, 'num_filters_3': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:29:53 DISPATCHER: Starting worker discovery
14:29:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:29:53 DISPATCHER: Finished worker discovery
14:30:03 WORKER: done with job (8, 0, 24), trying to register it.
14:30:03 DISPATCHER: job (8, 0, 24) finished
14:30:03 WORKER: registered result for job (8, 0, 24) with dispatcher
14:30:03 DISPATCHER: register_result: lock acquired
14:30:03 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:30:03 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001951476654726059, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.08956471111236476, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 21, 'num_filters_3': 16}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8113128617546695, 'info': {'music-speech': 0.8113128617546695, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001951476654726059, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.08956471111236476, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 21, 'num_filters_3': 16}"}}
exception: None

14:30:03 job_callback for (8, 0, 24) started
14:30:03 DISPATCHER: Trying to submit another job.
14:30:03 job_callback for (8, 0, 24) got condition
14:30:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:30:03 HBMASTER: Trying to run another job!
14:30:03 job_callback for (8, 0, 24) finished
14:30:03 start sampling a new configuration.
14:30:03 best_vector: [3, 2, 0.00015535202409289184, 0.016112512385777544, 0.22240462604632455, 1, 0.28084331241267235, 0.6748291260642839, 2, 1, 2, 2, 0.24747576865351248, 0.3458454205228656, 0.6525170215965664, 0.8448894766589035], 5.682023500218569e-30, 0.0017599364028704444, -5.916717938702943e-06
14:30:03 done sampling a new configuration.
14:30:03 HBMASTER: schedule new run for iteration 8
14:30:03 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
14:30:03 HBMASTER: submitting job (8, 0, 25) to dispatcher
14:30:03 DISPATCHER: trying to submit job (8, 0, 25)
14:30:03 DISPATCHER: trying to notify the job_runner thread.
14:30:03 HBMASTER: job (8, 0, 25) submitted to dispatcher
14:30:03 DISPATCHER: Trying to submit another job.
14:30:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:30:03 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:30:03 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:30:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:30:03 WORKER: start processing job (8, 0, 25)
14:30:03 WORKER: args: ()
14:30:03 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0010007156784854095, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.07550451721134617, 'kernel_size_2': 7, 'num_filters_2': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:30:53 DISPATCHER: Starting worker discovery
14:30:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:30:53 DISPATCHER: Finished worker discovery
14:30:57 WORKER: done with job (8, 0, 25), trying to register it.
14:30:57 WORKER: registered result for job (8, 0, 25) with dispatcher
14:30:57 DISPATCHER: job (8, 0, 25) finished
14:30:57 DISPATCHER: register_result: lock acquired
14:30:57 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:30:57 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0010007156784854095, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.07550451721134617, 'kernel_size_2': 7, 'num_filters_2': 26}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.8134996175408008, 'info': {'music-speech': 0.8134996175408008, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0010007156784854095, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.07550451721134617, 'kernel_size_2': 7, 'num_filters_2': 26}"}}
exception: None

14:30:57 job_callback for (8, 0, 25) started
14:30:57 DISPATCHER: Trying to submit another job.
14:30:57 job_callback for (8, 0, 25) got condition
14:30:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:30:57 HBMASTER: Trying to run another job!
14:30:57 job_callback for (8, 0, 25) finished
14:30:57 start sampling a new configuration.
14:30:57 best_vector: [0, 1, 0.04388481272053582, 0.46561094814690185, 0.23896589705177745, 1, 0.3051621396853721, 0.14865910135148216, 2, 1, 0, 2, 0.5699303795801627, 0.7910719827135015, 0.07262603733637255, 0.7038932396019522], 5.298086378149125e-27, 1.8874739455443681e-06, -1.1344291945599276e-05
14:30:57 done sampling a new configuration.
14:30:57 HBMASTER: schedule new run for iteration 8
14:30:57 HBMASTER: trying submitting job (8, 0, 26) to dispatcher
14:30:57 HBMASTER: submitting job (8, 0, 26) to dispatcher
14:30:57 DISPATCHER: trying to submit job (8, 0, 26)
14:30:57 DISPATCHER: trying to notify the job_runner thread.
14:30:57 HBMASTER: job (8, 0, 26) submitted to dispatcher
14:30:57 DISPATCHER: Trying to submit another job.
14:30:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:30:57 DISPATCHER: starting job (8, 0, 26) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:30:57 DISPATCHER: job (8, 0, 26) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:30:57 WORKER: start processing job (8, 0, 26)
14:30:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:30:57 WORKER: args: ()
14:30:57 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0012239667652626258, 'num_filters_1': 41, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.015610253292145233, 'kernel_size_2': 7, 'num_filters_2': 52}, 'budget': 44.44444444444444, 'working_directory': '.'}
14:31:51 WORKER: done with job (8, 0, 26), trying to register it.
14:31:51 WORKER: registered result for job (8, 0, 26) with dispatcher
14:31:51 DISPATCHER: job (8, 0, 26) finished
14:31:51 DISPATCHER: register_result: lock acquired
14:31:51 DISPATCHER: job (8, 0, 26) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:31:51 job_id: (8, 0, 26)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0012239667652626258, 'num_filters_1': 41, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.015610253292145233, 'kernel_size_2': 7, 'num_filters_2': 52}, 'budget': 44.44444444444444, 'working_directory': '.'}
result: {'loss': -0.6359883316555016, 'info': {'music-speech': 0.6359883316555016, 'config': "{'batch_size': 16, 'kernel_size_1': 5, 'lr': 0.0012239667652626258, 'num_filters_1': 41, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 37, 'weight_decay': 0.015610253292145233, 'kernel_size_2': 7, 'num_filters_2': 52}"}}
exception: None

14:31:51 job_callback for (8, 0, 26) started
14:31:51 DISPATCHER: Trying to submit another job.
14:31:51 job_callback for (8, 0, 26) got condition
14:31:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:31:51 HBMASTER: Trying to run another job!
14:31:51 job_callback for (8, 0, 26) finished
14:31:51 ITERATION: Advancing config (8, 0, 0) to next budget 133.333333
14:31:51 ITERATION: Advancing config (8, 0, 3) to next budget 133.333333
14:31:51 ITERATION: Advancing config (8, 0, 7) to next budget 133.333333
14:31:51 ITERATION: Advancing config (8, 0, 8) to next budget 133.333333
14:31:51 ITERATION: Advancing config (8, 0, 9) to next budget 133.333333
14:31:51 ITERATION: Advancing config (8, 0, 10) to next budget 133.333333
14:31:51 ITERATION: Advancing config (8, 0, 20) to next budget 133.333333
14:31:51 ITERATION: Advancing config (8, 0, 24) to next budget 133.333333
14:31:51 ITERATION: Advancing config (8, 0, 25) to next budget 133.333333
14:31:51 HBMASTER: schedule new run for iteration 8
14:31:51 HBMASTER: trying submitting job (8, 0, 0) to dispatcher
14:31:51 HBMASTER: submitting job (8, 0, 0) to dispatcher
14:31:51 DISPATCHER: trying to submit job (8, 0, 0)
14:31:51 DISPATCHER: trying to notify the job_runner thread.
14:31:51 HBMASTER: job (8, 0, 0) submitted to dispatcher
14:31:51 DISPATCHER: Trying to submit another job.
14:31:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:31:51 DISPATCHER: starting job (8, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:31:51 DISPATCHER: job (8, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:31:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:31:51 WORKER: start processing job (8, 0, 0)
14:31:51 WORKER: args: ()
14:31:51 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.010332471523778256, 'num_filters_1': 82, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.011419450147202371, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 19, 'num_filters_3': 23, 'num_filters_4': 81}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:31:53 DISPATCHER: Starting worker discovery
14:31:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:31:53 DISPATCHER: Finished worker discovery
14:32:53 DISPATCHER: Starting worker discovery
14:32:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:32:53 DISPATCHER: Finished worker discovery
14:33:53 DISPATCHER: Starting worker discovery
14:33:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:33:53 DISPATCHER: Finished worker discovery
14:34:13 WORKER: done with job (8, 0, 0), trying to register it.
14:34:13 WORKER: registered result for job (8, 0, 0) with dispatcher
14:34:13 DISPATCHER: job (8, 0, 0) finished
14:34:13 DISPATCHER: register_result: lock acquired
14:34:13 DISPATCHER: job (8, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:34:13 job_id: (8, 0, 0)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.010332471523778256, 'num_filters_1': 82, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.011419450147202371, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 19, 'num_filters_3': 23, 'num_filters_4': 81}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -4.376638458899803e-05, 'info': {'music-speech': 4.376638458899803e-05, 'config': "{'batch_size': 16, 'kernel_size_1': 7, 'lr': 0.010332471523778256, 'num_filters_1': 82, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.011419450147202371, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 19, 'num_filters_3': 23, 'num_filters_4': 81}"}}
exception: None

14:34:13 job_callback for (8, 0, 0) started
14:34:13 DISPATCHER: Trying to submit another job.
14:34:13 job_callback for (8, 0, 0) got condition
14:34:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:34:13 done building a new model for budget 133.333333 based on 17/31 split
Best loss for this budget:-0.931478





14:34:13 HBMASTER: Trying to run another job!
14:34:13 job_callback for (8, 0, 0) finished
14:34:13 HBMASTER: schedule new run for iteration 8
14:34:13 HBMASTER: trying submitting job (8, 0, 3) to dispatcher
14:34:13 HBMASTER: submitting job (8, 0, 3) to dispatcher
14:34:13 DISPATCHER: trying to submit job (8, 0, 3)
14:34:13 DISPATCHER: trying to notify the job_runner thread.
14:34:13 HBMASTER: job (8, 0, 3) submitted to dispatcher
14:34:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:34:13 DISPATCHER: Trying to submit another job.
14:34:13 DISPATCHER: starting job (8, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:34:13 DISPATCHER: job (8, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:34:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:34:13 WORKER: start processing job (8, 0, 3)
14:34:13 WORKER: args: ()
14:34:13 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0051972724396819525, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.11328002114293537}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:34:53 DISPATCHER: Starting worker discovery
14:34:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:34:53 DISPATCHER: Finished worker discovery
14:35:53 DISPATCHER: Starting worker discovery
14:35:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:35:53 DISPATCHER: Finished worker discovery
14:36:35 WORKER: done with job (8, 0, 3), trying to register it.
14:36:35 WORKER: registered result for job (8, 0, 3) with dispatcher
14:36:35 DISPATCHER: job (8, 0, 3) finished
14:36:35 DISPATCHER: register_result: lock acquired
14:36:35 DISPATCHER: job (8, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:36:35 job_id: (8, 0, 3)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0051972724396819525, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.11328002114293537}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.825637372360563, 'info': {'music-speech': 0.825637372360563, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0051972724396819525, 'num_filters_1': 18, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 17, 'weight_decay': 0.11328002114293537}"}}
exception: None

14:36:35 job_callback for (8, 0, 3) started
14:36:35 DISPATCHER: Trying to submit another job.
14:36:35 job_callback for (8, 0, 3) got condition
14:36:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:36:35 done building a new model for budget 133.333333 based on 17/32 split
Best loss for this budget:-0.931478





14:36:35 HBMASTER: Trying to run another job!
14:36:35 job_callback for (8, 0, 3) finished
14:36:35 HBMASTER: schedule new run for iteration 8
14:36:35 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
14:36:35 HBMASTER: submitting job (8, 0, 7) to dispatcher
14:36:35 DISPATCHER: trying to submit job (8, 0, 7)
14:36:35 DISPATCHER: trying to notify the job_runner thread.
14:36:35 HBMASTER: job (8, 0, 7) submitted to dispatcher
14:36:35 DISPATCHER: Trying to submit another job.
14:36:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:36:35 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:36:35 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:36:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:36:35 WORKER: start processing job (8, 0, 7)
14:36:35 WORKER: args: ()
14:36:35 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0015979579972019017, 'num_filters_1': 49, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.019355955674000377, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 33, 'num_filters_3': 73, 'num_filters_4': 105}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:36:53 DISPATCHER: Starting worker discovery
14:36:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:36:53 DISPATCHER: Finished worker discovery
14:37:53 DISPATCHER: Starting worker discovery
14:37:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:37:53 DISPATCHER: Finished worker discovery
14:38:53 DISPATCHER: Starting worker discovery
14:38:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:38:53 DISPATCHER: Finished worker discovery
14:38:58 WORKER: done with job (8, 0, 7), trying to register it.
14:38:58 DISPATCHER: job (8, 0, 7) finished
14:38:58 WORKER: registered result for job (8, 0, 7) with dispatcher
14:38:58 DISPATCHER: register_result: lock acquired
14:38:58 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:38:58 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0015979579972019017, 'num_filters_1': 49, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.019355955674000377, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 33, 'num_filters_3': 73, 'num_filters_4': 105}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8748226125381289, 'info': {'music-speech': 0.8748226125381289, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0015979579972019017, 'num_filters_1': 49, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.019355955674000377, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 33, 'num_filters_3': 73, 'num_filters_4': 105}"}}
exception: None

14:38:58 job_callback for (8, 0, 7) started
14:38:58 DISPATCHER: Trying to submit another job.
14:38:58 job_callback for (8, 0, 7) got condition
14:38:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:38:58 done building a new model for budget 133.333333 based on 17/33 split
Best loss for this budget:-0.931478





14:38:58 HBMASTER: Trying to run another job!
14:38:58 job_callback for (8, 0, 7) finished
14:38:58 HBMASTER: schedule new run for iteration 8
14:38:58 HBMASTER: trying submitting job (8, 0, 8) to dispatcher
14:38:58 HBMASTER: submitting job (8, 0, 8) to dispatcher
14:38:58 DISPATCHER: trying to submit job (8, 0, 8)
14:38:58 DISPATCHER: trying to notify the job_runner thread.
14:38:58 HBMASTER: job (8, 0, 8) submitted to dispatcher
14:38:58 DISPATCHER: Trying to submit another job.
14:38:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:38:58 DISPATCHER: starting job (8, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:38:58 DISPATCHER: job (8, 0, 8) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:38:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:38:58 WORKER: start processing job (8, 0, 8)
14:38:58 WORKER: args: ()
14:38:58 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005518217232983417, 'num_filters_1': 35, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.061488153630871345, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 120, 'num_filters_3': 77}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-762:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    preds = np.concatenate(preds)
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

14:39:53 DISPATCHER: Starting worker discovery
14:39:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:39:53 DISPATCHER: Finished worker discovery
14:40:53 DISPATCHER: Starting worker discovery
14:40:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:40:53 DISPATCHER: Finished worker discovery
14:41:20 WORKER: done with job (8, 0, 8), trying to register it.
14:41:20 WORKER: registered result for job (8, 0, 8) with dispatcher
14:41:20 DISPATCHER: job (8, 0, 8) finished
14:41:20 DISPATCHER: register_result: lock acquired
14:41:20 DISPATCHER: job (8, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:41:20 job_id: (8, 0, 8)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005518217232983417, 'num_filters_1': 35, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.061488153630871345, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 120, 'num_filters_3': 77}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7980493550436082, 'info': {'music-speech': 0.7980493550436082, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.005518217232983417, 'num_filters_1': 35, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 96, 'weight_decay': 0.061488153630871345, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 120, 'num_filters_3': 77}"}}
exception: None

14:41:20 job_callback for (8, 0, 8) started
14:41:20 DISPATCHER: Trying to submit another job.
14:41:20 job_callback for (8, 0, 8) got condition
14:41:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:41:20 done building a new model for budget 133.333333 based on 17/34 split
Best loss for this budget:-0.931478





14:41:20 HBMASTER: Trying to run another job!
14:41:20 job_callback for (8, 0, 8) finished
14:41:20 HBMASTER: schedule new run for iteration 8
14:41:20 HBMASTER: trying submitting job (8, 0, 9) to dispatcher
14:41:20 HBMASTER: submitting job (8, 0, 9) to dispatcher
14:41:20 DISPATCHER: trying to submit job (8, 0, 9)
14:41:20 DISPATCHER: trying to notify the job_runner thread.
14:41:20 HBMASTER: job (8, 0, 9) submitted to dispatcher
14:41:20 DISPATCHER: Trying to submit another job.
14:41:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:41:20 DISPATCHER: starting job (8, 0, 9) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:41:20 DISPATCHER: job (8, 0, 9) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:41:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:41:20 WORKER: start processing job (8, 0, 9)
14:41:20 WORKER: args: ()
14:41:20 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.019966331739349332, 'num_filters_1': 24, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.01268651489722277, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 26, 'num_filters_3': 16, 'num_filters_4': 16}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-763:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    preds = np.concatenate(preds)
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

14:41:53 DISPATCHER: Starting worker discovery
14:41:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:41:53 DISPATCHER: Finished worker discovery
14:42:53 DISPATCHER: Starting worker discovery
14:42:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:42:53 DISPATCHER: Finished worker discovery
14:43:42 WORKER: done with job (8, 0, 9), trying to register it.
14:43:42 WORKER: registered result for job (8, 0, 9) with dispatcher
14:43:42 DISPATCHER: job (8, 0, 9) finished
14:43:42 DISPATCHER: register_result: lock acquired
14:43:42 DISPATCHER: job (8, 0, 9) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:43:42 job_id: (8, 0, 9)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.019966331739349332, 'num_filters_1': 24, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.01268651489722277, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 26, 'num_filters_3': 16, 'num_filters_4': 16}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': 0.07059198602623018, 'info': {'music-speech': -0.07059198602623018, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.019966331739349332, 'num_filters_1': 24, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 98, 'weight_decay': 0.01268651489722277, 'kernel_size_2': 3, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 26, 'num_filters_3': 16, 'num_filters_4': 16}"}}
exception: None

14:43:42 job_callback for (8, 0, 9) started
14:43:42 DISPATCHER: Trying to submit another job.
14:43:42 job_callback for (8, 0, 9) got condition
14:43:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:43:42 done building a new model for budget 133.333333 based on 17/34 split
Best loss for this budget:-0.931478





14:43:42 HBMASTER: Trying to run another job!
14:43:42 job_callback for (8, 0, 9) finished
14:43:42 HBMASTER: schedule new run for iteration 8
14:43:42 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
14:43:42 HBMASTER: submitting job (8, 0, 10) to dispatcher
14:43:42 DISPATCHER: trying to submit job (8, 0, 10)
14:43:42 DISPATCHER: trying to notify the job_runner thread.
14:43:42 HBMASTER: job (8, 0, 10) submitted to dispatcher
14:43:42 DISPATCHER: Trying to submit another job.
14:43:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:43:42 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:43:42 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:43:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:43:42 WORKER: start processing job (8, 0, 10)
14:43:42 WORKER: args: ()
14:43:42 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.00894888869577269, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.13704363553455187, 'kernel_size_2': 3, 'num_filters_2': 24}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:43:53 DISPATCHER: Starting worker discovery
14:43:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:43:53 DISPATCHER: Finished worker discovery
14:44:53 DISPATCHER: Starting worker discovery
14:44:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:44:53 DISPATCHER: Finished worker discovery
14:45:53 DISPATCHER: Starting worker discovery
14:45:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:45:53 DISPATCHER: Finished worker discovery
14:46:05 WORKER: done with job (8, 0, 10), trying to register it.
14:46:05 WORKER: registered result for job (8, 0, 10) with dispatcher
14:46:05 DISPATCHER: job (8, 0, 10) finished
14:46:05 DISPATCHER: register_result: lock acquired
14:46:05 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:46:05 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.00894888869577269, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.13704363553455187, 'kernel_size_2': 3, 'num_filters_2': 24}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.9042063763133199, 'info': {'music-speech': 0.9042063763133199, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.00894888869577269, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.13704363553455187, 'kernel_size_2': 3, 'num_filters_2': 24}"}}
exception: None

14:46:05 job_callback for (8, 0, 10) started
14:46:05 DISPATCHER: Trying to submit another job.
14:46:05 job_callback for (8, 0, 10) got condition
14:46:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:46:05 done building a new model for budget 133.333333 based on 17/35 split
Best loss for this budget:-0.931478





14:46:05 HBMASTER: Trying to run another job!
14:46:05 job_callback for (8, 0, 10) finished
14:46:05 HBMASTER: schedule new run for iteration 8
14:46:05 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
14:46:05 HBMASTER: submitting job (8, 0, 20) to dispatcher
14:46:05 DISPATCHER: trying to submit job (8, 0, 20)
14:46:05 DISPATCHER: trying to notify the job_runner thread.
14:46:05 HBMASTER: job (8, 0, 20) submitted to dispatcher
14:46:05 DISPATCHER: Trying to submit another job.
14:46:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:46:05 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:46:05 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:46:05 WORKER: start processing job (8, 0, 20)
14:46:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:46:05 WORKER: args: ()
14:46:05 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.016656857643545377, 'num_filters_1': 118, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.0236551740540297, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 77, 'num_filters_3': 17, 'num_filters_4': 38}, 'budget': 133.33333333333331, 'working_directory': '.'}
Exception in thread Thread-765:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    preds = np.concatenate(preds)
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

14:46:53 DISPATCHER: Starting worker discovery
14:46:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:46:53 DISPATCHER: Finished worker discovery
14:47:53 DISPATCHER: Starting worker discovery
14:47:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:47:53 DISPATCHER: Finished worker discovery
14:48:26 WORKER: done with job (8, 0, 20), trying to register it.
14:48:26 WORKER: registered result for job (8, 0, 20) with dispatcher
14:48:26 DISPATCHER: job (8, 0, 20) finished
14:48:26 DISPATCHER: register_result: lock acquired
14:48:26 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:48:26 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.016656857643545377, 'num_filters_1': 118, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.0236551740540297, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 77, 'num_filters_3': 17, 'num_filters_4': 38}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8374050997718544, 'info': {'music-speech': 0.8374050997718544, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.016656857643545377, 'num_filters_1': 118, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.0236551740540297, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 77, 'num_filters_3': 17, 'num_filters_4': 38}"}}
exception: None

14:48:26 job_callback for (8, 0, 20) started
14:48:26 DISPATCHER: Trying to submit another job.
14:48:26 job_callback for (8, 0, 20) got condition
14:48:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:48:26 done building a new model for budget 133.333333 based on 17/36 split
Best loss for this budget:-0.931478





14:48:26 HBMASTER: Trying to run another job!
14:48:26 job_callback for (8, 0, 20) finished
14:48:26 HBMASTER: schedule new run for iteration 8
14:48:26 HBMASTER: trying submitting job (8, 0, 24) to dispatcher
14:48:26 HBMASTER: submitting job (8, 0, 24) to dispatcher
14:48:26 DISPATCHER: trying to submit job (8, 0, 24)
14:48:26 DISPATCHER: trying to notify the job_runner thread.
14:48:26 HBMASTER: job (8, 0, 24) submitted to dispatcher
14:48:26 DISPATCHER: Trying to submit another job.
14:48:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:48:26 DISPATCHER: starting job (8, 0, 24) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:48:26 DISPATCHER: job (8, 0, 24) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:48:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:48:26 WORKER: start processing job (8, 0, 24)
14:48:26 WORKER: args: ()
14:48:26 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001951476654726059, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.08956471111236476, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 21, 'num_filters_3': 16}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:48:53 DISPATCHER: Starting worker discovery
14:48:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:48:53 DISPATCHER: Finished worker discovery
14:49:53 DISPATCHER: Starting worker discovery
14:49:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:49:53 DISPATCHER: Finished worker discovery
14:50:50 WORKER: done with job (8, 0, 24), trying to register it.
14:50:50 WORKER: registered result for job (8, 0, 24) with dispatcher
14:50:50 DISPATCHER: job (8, 0, 24) finished
14:50:50 DISPATCHER: register_result: lock acquired
14:50:50 DISPATCHER: job (8, 0, 24) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:50:50 job_id: (8, 0, 24)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001951476654726059, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.08956471111236476, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 21, 'num_filters_3': 16}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6918195600277562, 'info': {'music-speech': 0.6918195600277562, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.001951476654726059, 'num_filters_1': 23, 'num_layers': 3, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.08956471111236476, 'kernel_size_2': 5, 'kernel_size_3': 5, 'num_filters_2': 21, 'num_filters_3': 16}"}}
exception: None

14:50:50 job_callback for (8, 0, 24) started
14:50:50 DISPATCHER: Trying to submit another job.
14:50:50 job_callback for (8, 0, 24) got condition
14:50:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:50:50 done building a new model for budget 133.333333 based on 17/37 split
Best loss for this budget:-0.931478





14:50:50 HBMASTER: Trying to run another job!
14:50:50 job_callback for (8, 0, 24) finished
14:50:50 HBMASTER: schedule new run for iteration 8
14:50:50 HBMASTER: trying submitting job (8, 0, 25) to dispatcher
14:50:50 HBMASTER: submitting job (8, 0, 25) to dispatcher
14:50:50 DISPATCHER: trying to submit job (8, 0, 25)
14:50:50 DISPATCHER: trying to notify the job_runner thread.
14:50:50 HBMASTER: job (8, 0, 25) submitted to dispatcher
14:50:50 DISPATCHER: Trying to submit another job.
14:50:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:50:50 DISPATCHER: starting job (8, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:50:50 DISPATCHER: job (8, 0, 25) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:50:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:50:50 WORKER: start processing job (8, 0, 25)
14:50:50 WORKER: args: ()
14:50:50 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0010007156784854095, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.07550451721134617, 'kernel_size_2': 7, 'num_filters_2': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
14:50:53 DISPATCHER: Starting worker discovery
14:50:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:50:53 DISPATCHER: Finished worker discovery
14:51:53 DISPATCHER: Starting worker discovery
14:51:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:51:53 DISPATCHER: Finished worker discovery
14:52:53 DISPATCHER: Starting worker discovery
14:52:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:52:53 DISPATCHER: Finished worker discovery
14:53:12 WORKER: done with job (8, 0, 25), trying to register it.
14:53:12 DISPATCHER: job (8, 0, 25) finished
14:53:12 WORKER: registered result for job (8, 0, 25) with dispatcher
14:53:12 DISPATCHER: register_result: lock acquired
14:53:12 DISPATCHER: job (8, 0, 25) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
14:53:12 job_id: (8, 0, 25)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0010007156784854095, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.07550451721134617, 'kernel_size_2': 7, 'num_filters_2': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7901600554875099, 'info': {'music-speech': 0.7901600554875099, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0010007156784854095, 'num_filters_1': 16, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 35, 'weight_decay': 0.07550451721134617, 'kernel_size_2': 7, 'num_filters_2': 26}"}}
exception: None

14:53:12 job_callback for (8, 0, 25) started
14:53:12 DISPATCHER: Trying to submit another job.
14:53:12 job_callback for (8, 0, 25) got condition
14:53:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
14:53:12 done building a new model for budget 133.333333 based on 17/38 split
Best loss for this budget:-0.931478





14:53:12 HBMASTER: Trying to run another job!
14:53:12 job_callback for (8, 0, 25) finished
14:53:12 ITERATION: Advancing config (8, 0, 7) to next budget 400.000000
14:53:12 ITERATION: Advancing config (8, 0, 10) to next budget 400.000000
14:53:12 ITERATION: Advancing config (8, 0, 20) to next budget 400.000000
14:53:12 HBMASTER: schedule new run for iteration 8
14:53:12 HBMASTER: trying submitting job (8, 0, 7) to dispatcher
14:53:12 HBMASTER: submitting job (8, 0, 7) to dispatcher
14:53:12 DISPATCHER: trying to submit job (8, 0, 7)
14:53:12 DISPATCHER: trying to notify the job_runner thread.
14:53:12 HBMASTER: job (8, 0, 7) submitted to dispatcher
14:53:12 DISPATCHER: Trying to submit another job.
14:53:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
14:53:12 DISPATCHER: starting job (8, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
14:53:12 DISPATCHER: job (8, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
14:53:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
14:53:12 WORKER: start processing job (8, 0, 7)
14:53:12 WORKER: args: ()
14:53:12 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0015979579972019017, 'num_filters_1': 49, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.019355955674000377, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 33, 'num_filters_3': 73, 'num_filters_4': 105}, 'budget': 400.0, 'working_directory': '.'}
14:53:53 DISPATCHER: Starting worker discovery
14:53:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:53:53 DISPATCHER: Finished worker discovery
14:54:53 DISPATCHER: Starting worker discovery
14:54:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:54:53 DISPATCHER: Finished worker discovery
14:55:53 DISPATCHER: Starting worker discovery
14:55:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:55:53 DISPATCHER: Finished worker discovery
14:56:53 DISPATCHER: Starting worker discovery
14:56:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:56:53 DISPATCHER: Finished worker discovery
14:57:53 DISPATCHER: Starting worker discovery
14:57:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:57:53 DISPATCHER: Finished worker discovery
14:58:53 DISPATCHER: Starting worker discovery
14:58:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:58:53 DISPATCHER: Finished worker discovery
14:59:53 DISPATCHER: Starting worker discovery
14:59:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
14:59:53 DISPATCHER: Finished worker discovery
15:00:02 WORKER: done with job (8, 0, 7), trying to register it.
15:00:02 DISPATCHER: job (8, 0, 7) finished
15:00:02 WORKER: registered result for job (8, 0, 7) with dispatcher
15:00:02 DISPATCHER: register_result: lock acquired
15:00:02 DISPATCHER: job (8, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
15:00:02 job_id: (8, 0, 7)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0015979579972019017, 'num_filters_1': 49, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.019355955674000377, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 33, 'num_filters_3': 73, 'num_filters_4': 105}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6597777086598344, 'info': {'music-speech': 0.6597777086598344, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0015979579972019017, 'num_filters_1': 49, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 91, 'weight_decay': 0.019355955674000377, 'kernel_size_2': 7, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 33, 'num_filters_3': 73, 'num_filters_4': 105}"}}
exception: None

15:00:02 job_callback for (8, 0, 7) started
15:00:02 DISPATCHER: Trying to submit another job.
15:00:02 job_callback for (8, 0, 7) got condition
15:00:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:00:02 HBMASTER: Trying to run another job!
15:00:02 job_callback for (8, 0, 7) finished
15:00:02 HBMASTER: schedule new run for iteration 8
15:00:02 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
15:00:02 HBMASTER: submitting job (8, 0, 10) to dispatcher
15:00:02 DISPATCHER: trying to submit job (8, 0, 10)
15:00:02 DISPATCHER: trying to notify the job_runner thread.
15:00:02 HBMASTER: job (8, 0, 10) submitted to dispatcher
15:00:02 DISPATCHER: Trying to submit another job.
15:00:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:00:02 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpul.22021139727314577216
15:00:02 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
15:00:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:00:02 WORKER: start processing job (8, 0, 10)
15:00:02 WORKER: args: ()
15:00:02 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.00894888869577269, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.13704363553455187, 'kernel_size_2': 3, 'num_filters_2': 24}, 'budget': 400.0, 'working_directory': '.'}
15:00:53 DISPATCHER: Starting worker discovery
15:00:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:00:53 DISPATCHER: Finished worker discovery
15:01:53 DISPATCHER: Starting worker discovery
15:01:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:01:53 DISPATCHER: Finished worker discovery
15:02:53 DISPATCHER: Starting worker discovery
15:02:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:02:53 DISPATCHER: Finished worker discovery
15:03:53 DISPATCHER: Starting worker discovery
15:03:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:03:53 DISPATCHER: Finished worker discovery
15:04:53 DISPATCHER: Starting worker discovery
15:04:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:04:53 DISPATCHER: Finished worker discovery
15:05:53 DISPATCHER: Starting worker discovery
15:05:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:05:53 DISPATCHER: Finished worker discovery
15:06:51 WORKER: done with job (8, 0, 10), trying to register it.
15:06:51 WORKER: registered result for job (8, 0, 10) with dispatcher
15:06:51 DISPATCHER: job (8, 0, 10) finished
15:06:51 DISPATCHER: register_result: lock acquired
15:06:51 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
15:06:51 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.00894888869577269, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.13704363553455187, 'kernel_size_2': 3, 'num_filters_2': 24}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8784444838124785, 'info': {'music-speech': 0.8784444838124785, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.00894888869577269, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.13704363553455187, 'kernel_size_2': 3, 'num_filters_2': 24}"}}
exception: None

15:06:51 job_callback for (8, 0, 10) started
15:06:51 DISPATCHER: Trying to submit another job.
15:06:51 job_callback for (8, 0, 10) got condition
15:06:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:06:51 HBMASTER: Trying to run another job!
15:06:51 job_callback for (8, 0, 10) finished
15:06:51 HBMASTER: schedule new run for iteration 8
15:06:51 HBMASTER: trying submitting job (8, 0, 20) to dispatcher
15:06:51 HBMASTER: submitting job (8, 0, 20) to dispatcher
15:06:51 DISPATCHER: trying to submit job (8, 0, 20)
15:06:51 DISPATCHER: trying to notify the job_runner thread.
15:06:51 HBMASTER: job (8, 0, 20) submitted to dispatcher
15:06:51 DISPATCHER: Trying to submit another job.
15:06:51 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:06:51 DISPATCHER: starting job (8, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216
15:06:51 DISPATCHER: job (8, 0, 20) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
15:06:51 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:06:51 WORKER: start processing job (8, 0, 20)
15:06:51 WORKER: args: ()
15:06:51 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.016656857643545377, 'num_filters_1': 118, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.0236551740540297, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 77, 'num_filters_3': 17, 'num_filters_4': 38}, 'budget': 400.0, 'working_directory': '.'}
15:06:53 DISPATCHER: Starting worker discovery
15:06:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:06:53 DISPATCHER: Finished worker discovery
Exception in thread Thread-770:
Traceback (most recent call last):
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ahnj/anaconda3/envs/ml4aad/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 152, in train_and_make_prediction
    self.train()
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 195, in train
  File "/home/ahnj/repo/autodl/AutoDL/model.py", line 232, in trainloop
    preds = np.concatenate(preds)
IndexError: index 9223372034707292159 is out of bounds for axis 0 with size 2

15:07:53 DISPATCHER: Starting worker discovery
15:07:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:07:53 DISPATCHER: Finished worker discovery
15:08:53 DISPATCHER: Starting worker discovery
15:08:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:08:53 DISPATCHER: Finished worker discovery
15:09:53 DISPATCHER: Starting worker discovery
15:09:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:09:53 DISPATCHER: Finished worker discovery
15:10:53 DISPATCHER: Starting worker discovery
15:10:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:10:53 DISPATCHER: Finished worker discovery
15:11:53 DISPATCHER: Starting worker discovery
15:11:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:11:53 DISPATCHER: Finished worker discovery
15:12:53 DISPATCHER: Starting worker discovery
15:12:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:12:53 DISPATCHER: Finished worker discovery
15:13:40 WORKER: done with job (8, 0, 20), trying to register it.
15:13:40 WORKER: registered result for job (8, 0, 20) with dispatcher
15:13:40 DISPATCHER: job (8, 0, 20) finished
15:13:40 DISPATCHER: register_result: lock acquired
15:13:40 DISPATCHER: job (8, 0, 20) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
15:13:40 job_id: (8, 0, 20)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.016656857643545377, 'num_filters_1': 118, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.0236551740540297, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 77, 'num_filters_3': 17, 'num_filters_4': 38}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.7711554363797618, 'info': {'music-speech': 0.7711554363797618, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.016656857643545377, 'num_filters_1': 118, 'num_layers': 4, 'optimizer': 'SGD', 'steps_to_train': 61, 'weight_decay': 0.0236551740540297, 'kernel_size_2': 7, 'kernel_size_3': 5, 'kernel_size_4': 5, 'num_filters_2': 77, 'num_filters_3': 17, 'num_filters_4': 38}"}}
exception: None

15:13:40 job_callback for (8, 0, 20) started
15:13:40 DISPATCHER: Trying to submit another job.
15:13:40 job_callback for (8, 0, 20) got condition
15:13:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:13:40 HBMASTER: Trying to run another job!
15:13:40 job_callback for (8, 0, 20) finished
15:13:40 ITERATION: Advancing config (8, 0, 10) to next budget 1200.000000
15:13:40 HBMASTER: schedule new run for iteration 8
15:13:40 HBMASTER: trying submitting job (8, 0, 10) to dispatcher
15:13:40 HBMASTER: submitting job (8, 0, 10) to dispatcher
15:13:40 DISPATCHER: trying to submit job (8, 0, 10)
15:13:40 DISPATCHER: trying to notify the job_runner thread.
15:13:40 HBMASTER: job (8, 0, 10) submitted to dispatcher
15:13:40 DISPATCHER: Trying to submit another job.
15:13:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:13:40 DISPATCHER: starting job (8, 0, 10) on hpbandster.run_0.worker.metagpul.22021139727314577216
15:13:40 DISPATCHER: job (8, 0, 10) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
15:13:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:13:40 WORKER: start processing job (8, 0, 10)
15:13:40 WORKER: args: ()
15:13:40 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.00894888869577269, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.13704363553455187, 'kernel_size_2': 3, 'num_filters_2': 24}, 'budget': 1200.0, 'working_directory': '.'}
15:13:53 DISPATCHER: Starting worker discovery
15:13:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:13:53 DISPATCHER: Finished worker discovery
15:14:53 DISPATCHER: Starting worker discovery
15:14:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:14:53 DISPATCHER: Finished worker discovery
15:15:53 DISPATCHER: Starting worker discovery
15:15:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:15:53 DISPATCHER: Finished worker discovery
15:16:53 DISPATCHER: Starting worker discovery
15:16:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:16:53 DISPATCHER: Finished worker discovery
15:17:53 DISPATCHER: Starting worker discovery
15:17:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:17:53 DISPATCHER: Finished worker discovery
15:18:53 DISPATCHER: Starting worker discovery
15:18:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:18:53 DISPATCHER: Finished worker discovery
15:19:53 DISPATCHER: Starting worker discovery
15:19:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:19:53 DISPATCHER: Finished worker discovery
15:20:53 DISPATCHER: Starting worker discovery
15:20:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:20:53 DISPATCHER: Finished worker discovery
15:21:53 DISPATCHER: Starting worker discovery
15:21:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:21:53 DISPATCHER: Finished worker discovery
15:22:53 DISPATCHER: Starting worker discovery
15:22:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:22:53 DISPATCHER: Finished worker discovery
15:23:53 DISPATCHER: Starting worker discovery
15:23:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:23:53 DISPATCHER: Finished worker discovery
15:24:53 DISPATCHER: Starting worker discovery
15:24:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:24:53 DISPATCHER: Finished worker discovery
15:25:53 DISPATCHER: Starting worker discovery
15:25:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:25:53 DISPATCHER: Finished worker discovery
15:26:53 DISPATCHER: Starting worker discovery
15:26:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:26:53 DISPATCHER: Finished worker discovery
15:27:53 DISPATCHER: Starting worker discovery
15:27:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:27:53 DISPATCHER: Finished worker discovery
15:28:53 DISPATCHER: Starting worker discovery
15:28:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:28:53 DISPATCHER: Finished worker discovery
15:29:53 DISPATCHER: Starting worker discovery
15:29:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:29:53 DISPATCHER: Finished worker discovery
15:30:53 DISPATCHER: Starting worker discovery
15:30:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:30:53 DISPATCHER: Finished worker discovery
15:31:53 DISPATCHER: Starting worker discovery
15:31:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:31:53 DISPATCHER: Finished worker discovery
15:32:53 DISPATCHER: Starting worker discovery
15:32:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:32:53 DISPATCHER: Finished worker discovery
15:33:50 WORKER: done with job (8, 0, 10), trying to register it.
15:33:50 DISPATCHER: job (8, 0, 10) finished
15:33:50 WORKER: registered result for job (8, 0, 10) with dispatcher
15:33:50 DISPATCHER: register_result: lock acquired
15:33:50 DISPATCHER: job (8, 0, 10) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
15:33:50 job_id: (8, 0, 10)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.00894888869577269, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.13704363553455187, 'kernel_size_2': 3, 'num_filters_2': 24}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.8624249682068532, 'info': {'music-speech': 0.8624249682068532, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.00894888869577269, 'num_filters_1': 22, 'num_layers': 2, 'optimizer': 'Adam', 'steps_to_train': 31, 'weight_decay': 0.13704363553455187, 'kernel_size_2': 3, 'num_filters_2': 24}"}}
exception: None

15:33:50 job_callback for (8, 0, 10) started
15:33:50 DISPATCHER: Trying to submit another job.
15:33:50 job_callback for (8, 0, 10) got condition
15:33:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:33:50 HBMASTER: Trying to run another job!
15:33:50 job_callback for (8, 0, 10) finished
15:33:50 start sampling a new configuration.
15:33:50 best_vector: [1, 2, 0.8977836398736704, 0.7449434289878689, 0.16415589068799363, 0, 0.11328871660825186, 0.15708061739048348, 2, 0, 2, 2, 0.664095182518455, 0.21370079337882275, 0.28868159421250594, 0.3983310701425869], 1.3176295481345246e-29, 0.0007589386572392683, -1.3921627400810154e-05
15:33:50 done sampling a new configuration.
15:33:50 HBMASTER: schedule new run for iteration 9
15:33:50 HBMASTER: trying submitting job (9, 0, 0) to dispatcher
15:33:50 HBMASTER: submitting job (9, 0, 0) to dispatcher
15:33:50 DISPATCHER: trying to submit job (9, 0, 0)
15:33:50 DISPATCHER: trying to notify the job_runner thread.
15:33:50 HBMASTER: job (9, 0, 0) submitted to dispatcher
15:33:50 DISPATCHER: Trying to submit another job.
15:33:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:33:50 DISPATCHER: starting job (9, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216
15:33:50 DISPATCHER: job (9, 0, 0) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
15:33:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:33:50 WORKER: start processing job (9, 0, 0)
15:33:50 WORKER: args: ()
15:33:50 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.062455009642816944, 'num_filters_1': 75, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.01600908811321091}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:33:53 DISPATCHER: Starting worker discovery
15:33:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:33:53 DISPATCHER: Finished worker discovery
15:34:53 DISPATCHER: Starting worker discovery
15:34:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:34:53 DISPATCHER: Finished worker discovery
15:35:53 DISPATCHER: Starting worker discovery
15:35:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:35:53 DISPATCHER: Finished worker discovery
15:36:12 WORKER: done with job (9, 0, 0), trying to register it.
15:36:12 DISPATCHER: job (9, 0, 0) finished
15:36:12 WORKER: registered result for job (9, 0, 0) with dispatcher
15:36:12 DISPATCHER: register_result: lock acquired
15:36:12 DISPATCHER: job (9, 0, 0) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
15:36:12 job_id: (9, 0, 0)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.062455009642816944, 'num_filters_1': 75, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.01600908811321091}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6182858236026093, 'info': {'music-speech': 0.6182858236026093, 'config': "{'batch_size': 32, 'kernel_size_1': 7, 'lr': 0.062455009642816944, 'num_filters_1': 75, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 20, 'weight_decay': 0.01600908811321091}"}}
exception: None

15:36:12 job_callback for (9, 0, 0) started
15:36:12 DISPATCHER: Trying to submit another job.
15:36:12 job_callback for (9, 0, 0) got condition
15:36:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:36:12 done building a new model for budget 133.333333 based on 17/39 split
Best loss for this budget:-0.931478





15:36:12 HBMASTER: Trying to run another job!
15:36:12 job_callback for (9, 0, 0) finished
15:36:12 start sampling a new configuration.
15:36:13 best_vector: [1, 1, 0.2486272619631937, 0.7327700284196711, 0.7177257195189958, 0, 0.8831997595328486, 0.22230127472212735, 2, 0, 0, 2, 0.8263488541541963, 0.36078883163414266, 0.24668076671025926, 0.16126547246348322], 6.517016216771089e-30, 0.0015344445475316902, -3.810308342717478e-07
15:36:13 done sampling a new configuration.
15:36:13 HBMASTER: schedule new run for iteration 9
15:36:13 HBMASTER: trying submitting job (9, 0, 1) to dispatcher
15:36:13 HBMASTER: submitting job (9, 0, 1) to dispatcher
15:36:13 DISPATCHER: trying to submit job (9, 0, 1)
15:36:13 DISPATCHER: trying to notify the job_runner thread.
15:36:13 HBMASTER: job (9, 0, 1) submitted to dispatcher
15:36:13 DISPATCHER: Trying to submit another job.
15:36:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:36:13 DISPATCHER: starting job (9, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216
15:36:13 DISPATCHER: job (9, 0, 1) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
15:36:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:36:13 WORKER: start processing job (9, 0, 1)
15:36:13 WORKER: args: ()
15:36:13 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0031423497692592093, 'num_filters_1': 73, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.019463485975200978, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 89, 'num_filters_3': 33, 'num_filters_4': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:36:53 DISPATCHER: Starting worker discovery
15:36:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:36:53 DISPATCHER: Finished worker discovery
15:37:53 DISPATCHER: Starting worker discovery
15:37:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:37:53 DISPATCHER: Finished worker discovery
15:38:36 WORKER: done with job (9, 0, 1), trying to register it.
15:38:36 DISPATCHER: job (9, 0, 1) finished
15:38:36 WORKER: registered result for job (9, 0, 1) with dispatcher
15:38:36 DISPATCHER: register_result: lock acquired
15:38:36 DISPATCHER: job (9, 0, 1) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
15:38:36 job_id: (9, 0, 1)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0031423497692592093, 'num_filters_1': 73, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.019463485975200978, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 89, 'num_filters_3': 33, 'num_filters_4': 26}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6474368036463716, 'info': {'music-speech': 0.6474368036463716, 'config': "{'batch_size': 32, 'kernel_size_1': 5, 'lr': 0.0031423497692592093, 'num_filters_1': 73, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 90, 'weight_decay': 0.019463485975200978, 'kernel_size_2': 7, 'kernel_size_3': 3, 'kernel_size_4': 3, 'num_filters_2': 89, 'num_filters_3': 33, 'num_filters_4': 26}"}}
exception: None

15:38:36 job_callback for (9, 0, 1) started
15:38:36 DISPATCHER: Trying to submit another job.
15:38:36 job_callback for (9, 0, 1) got condition
15:38:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:38:36 done building a new model for budget 133.333333 based on 17/39 split
Best loss for this budget:-0.931478





15:38:36 HBMASTER: Trying to run another job!
15:38:36 job_callback for (9, 0, 1) finished
15:38:36 start sampling a new configuration.
15:38:36 best_vector: [2, 0, 0.07156227383217888, 0.6800522554996474, 0.29315329307563487, 1, 0.6881277362568865, 0.24394886444921643, 0, 1, 0, 2, 0.19078153551477361, 0.13095637465633284, 0.03707436139075038, 0.7285294423143125], 8.01509591360522e-28, 1.2476457060264877e-05, -2.5149303248792017e-06
15:38:36 done sampling a new configuration.
15:38:36 HBMASTER: schedule new run for iteration 9
15:38:36 HBMASTER: trying submitting job (9, 0, 2) to dispatcher
15:38:36 HBMASTER: submitting job (9, 0, 2) to dispatcher
15:38:36 DISPATCHER: trying to submit job (9, 0, 2)
15:38:36 DISPATCHER: trying to notify the job_runner thread.
15:38:36 HBMASTER: job (9, 0, 2) submitted to dispatcher
15:38:36 DISPATCHER: Trying to submit another job.
15:38:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:38:36 DISPATCHER: starting job (9, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216
15:38:36 DISPATCHER: job (9, 0, 2) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
15:38:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:38:36 WORKER: start processing job (9, 0, 2)
15:38:36 WORKER: args: ()
15:38:36 WORKER: kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0013903513012092246, 'num_filters_1': 65, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.020767527300772453, 'kernel_size_2': 3, 'num_filters_2': 23}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:38:53 DISPATCHER: Starting worker discovery
15:38:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:38:53 DISPATCHER: Finished worker discovery
15:39:53 DISPATCHER: Starting worker discovery
15:39:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:39:53 DISPATCHER: Finished worker discovery
15:40:53 DISPATCHER: Starting worker discovery
15:40:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:40:53 DISPATCHER: Finished worker discovery
15:40:58 WORKER: done with job (9, 0, 2), trying to register it.
15:40:58 DISPATCHER: job (9, 0, 2) finished
15:40:58 WORKER: registered result for job (9, 0, 2) with dispatcher
15:40:58 DISPATCHER: register_result: lock acquired
15:40:58 DISPATCHER: job (9, 0, 2) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
15:40:58 job_id: (9, 0, 2)
kwargs: {'config': {'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0013903513012092246, 'num_filters_1': 65, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.020767527300772453, 'kernel_size_2': 3, 'num_filters_2': 23}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6342177296827335, 'info': {'music-speech': 0.6342177296827335, 'config': "{'batch_size': 64, 'kernel_size_1': 3, 'lr': 0.0013903513012092246, 'num_filters_1': 65, 'num_layers': 2, 'optimizer': 'SGD', 'steps_to_train': 72, 'weight_decay': 0.020767527300772453, 'kernel_size_2': 3, 'num_filters_2': 23}"}}
exception: None

15:40:58 job_callback for (9, 0, 2) started
15:40:58 DISPATCHER: Trying to submit another job.
15:40:58 job_callback for (9, 0, 2) got condition
15:40:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:40:58 done building a new model for budget 133.333333 based on 17/40 split
Best loss for this budget:-0.931478





15:40:58 HBMASTER: Trying to run another job!
15:40:58 job_callback for (9, 0, 2) finished
15:40:58 start sampling a new configuration.
15:40:59 best_vector: [0, 0, 0.23746554635894404, 0.4338639314471786, 0.7831389499488546, 0, 0.500419109306441, 0.6263616960142986, 1, 2, 2, 2, 0.06505470518102985, 0.4848810696441138, 0.3534862777300424, 0.9443864895562699], 4.734030804135522e-27, 2.112364793077449e-06, -4.415539270601219e-06
15:40:59 done sampling a new configuration.
15:40:59 HBMASTER: schedule new run for iteration 9
15:40:59 HBMASTER: trying submitting job (9, 0, 3) to dispatcher
15:40:59 HBMASTER: submitting job (9, 0, 3) to dispatcher
15:40:59 DISPATCHER: trying to submit job (9, 0, 3)
15:40:59 DISPATCHER: trying to notify the job_runner thread.
15:40:59 HBMASTER: job (9, 0, 3) submitted to dispatcher
15:40:59 DISPATCHER: Trying to submit another job.
15:40:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:40:59 DISPATCHER: starting job (9, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216
15:40:59 DISPATCHER: job (9, 0, 3) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
15:40:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:40:59 WORKER: start processing job (9, 0, 3)
15:40:59 WORKER: args: ()
15:40:59 WORKER: kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0029849089811170514, 'num_filters_1': 39, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.06530032678681268, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 18, 'num_filters_3': 43, 'num_filters_4': 33}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:41:53 DISPATCHER: Starting worker discovery
15:41:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:41:53 DISPATCHER: Finished worker discovery
15:42:53 DISPATCHER: Starting worker discovery
15:42:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:42:53 DISPATCHER: Finished worker discovery
15:43:21 WORKER: done with job (9, 0, 3), trying to register it.
15:43:21 WORKER: registered result for job (9, 0, 3) with dispatcher
15:43:21 DISPATCHER: job (9, 0, 3) finished
15:43:21 DISPATCHER: register_result: lock acquired
15:43:21 DISPATCHER: job (9, 0, 3) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
15:43:21 job_id: (9, 0, 3)
kwargs: {'config': {'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0029849089811170514, 'num_filters_1': 39, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.06530032678681268, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 18, 'num_filters_3': 43, 'num_filters_4': 33}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.6796110056200326, 'info': {'music-speech': 0.6796110056200326, 'config': "{'batch_size': 16, 'kernel_size_1': 3, 'lr': 0.0029849089811170514, 'num_filters_1': 39, 'num_layers': 4, 'optimizer': 'Adam', 'steps_to_train': 55, 'weight_decay': 0.06530032678681268, 'kernel_size_2': 5, 'kernel_size_3': 7, 'kernel_size_4': 7, 'num_filters_2': 18, 'num_filters_3': 43, 'num_filters_4': 33}"}}
exception: None

15:43:21 job_callback for (9, 0, 3) started
15:43:21 DISPATCHER: Trying to submit another job.
15:43:21 job_callback for (9, 0, 3) got condition
15:43:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:43:21 done building a new model for budget 133.333333 based on 17/41 split
Best loss for this budget:-0.931478





15:43:21 HBMASTER: Trying to run another job!
15:43:21 job_callback for (9, 0, 3) finished
15:43:21 start sampling a new configuration.
15:43:21 done sampling a new configuration.
15:43:21 HBMASTER: schedule new run for iteration 9
15:43:21 HBMASTER: trying submitting job (9, 0, 4) to dispatcher
15:43:21 HBMASTER: submitting job (9, 0, 4) to dispatcher
15:43:21 DISPATCHER: trying to submit job (9, 0, 4)
15:43:21 DISPATCHER: trying to notify the job_runner thread.
15:43:21 HBMASTER: job (9, 0, 4) submitted to dispatcher
15:43:21 DISPATCHER: Trying to submit another job.
15:43:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:43:21 DISPATCHER: starting job (9, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216
15:43:21 DISPATCHER: job (9, 0, 4) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
15:43:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:43:21 WORKER: start processing job (9, 0, 4)
15:43:21 WORKER: args: ()
15:43:21 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.017225702612353698, 'num_filters_1': 30, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.018539950948908028}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:43:53 DISPATCHER: Starting worker discovery
15:43:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:43:53 DISPATCHER: Finished worker discovery
15:44:53 DISPATCHER: Starting worker discovery
15:44:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:44:53 DISPATCHER: Finished worker discovery
15:45:44 WORKER: done with job (9, 0, 4), trying to register it.
15:45:44 DISPATCHER: job (9, 0, 4) finished
15:45:44 WORKER: registered result for job (9, 0, 4) with dispatcher
15:45:44 DISPATCHER: register_result: lock acquired
15:45:44 DISPATCHER: job (9, 0, 4) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
15:45:44 job_id: (9, 0, 4)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.017225702612353698, 'num_filters_1': 30, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.018539950948908028}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.46055392259718697, 'info': {'music-speech': 0.46055392259718697, 'config': "{'batch_size': 128, 'kernel_size_1': 3, 'lr': 0.017225702612353698, 'num_filters_1': 30, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 67, 'weight_decay': 0.018539950948908028}"}}
exception: None

15:45:44 job_callback for (9, 0, 4) started
15:45:44 DISPATCHER: Trying to submit another job.
15:45:44 job_callback for (9, 0, 4) got condition
15:45:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:45:44 done building a new model for budget 133.333333 based on 17/42 split
Best loss for this budget:-0.931478





15:45:44 HBMASTER: Trying to run another job!
15:45:44 job_callback for (9, 0, 4) finished
15:45:44 start sampling a new configuration.
15:45:44 best_vector: [1, 0, 0.14639545046834027, 0.9320208133804643, 0.9439342995685549, 0, 0.7688440783592454, 0.353502758552097, 1, 0, 0, 2, 0.4596903925387922, 0.277550022162025, 0.03502735096297016, 0.3215057280873543], 7.773455467045262e-29, 0.00012864291874307299, -8.57518659423312e-06
15:45:44 done sampling a new configuration.
15:45:44 HBMASTER: schedule new run for iteration 9
15:45:44 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
15:45:44 HBMASTER: submitting job (9, 0, 5) to dispatcher
15:45:44 DISPATCHER: trying to submit job (9, 0, 5)
15:45:44 DISPATCHER: trying to notify the job_runner thread.
15:45:44 HBMASTER: job (9, 0, 5) submitted to dispatcher
15:45:44 DISPATCHER: Trying to submit another job.
15:45:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:45:44 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
15:45:44 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
15:45:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:45:44 WORKER: start processing job (9, 0, 5)
15:45:44 WORKER: args: ()
15:45:44 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.00196241520846064, 'num_filters_1': 111, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.02883484972712214, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 41, 'num_filters_3': 28, 'num_filters_4': 17, 'num_filters_5': 31}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:45:53 DISPATCHER: Starting worker discovery
15:45:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:45:53 DISPATCHER: Finished worker discovery
15:46:53 DISPATCHER: Starting worker discovery
15:46:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:46:53 DISPATCHER: Finished worker discovery
15:47:53 DISPATCHER: Starting worker discovery
15:47:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:47:53 DISPATCHER: Finished worker discovery
15:48:07 WORKER: done with job (9, 0, 5), trying to register it.
15:48:07 DISPATCHER: job (9, 0, 5) finished
15:48:07 WORKER: registered result for job (9, 0, 5) with dispatcher
15:48:07 DISPATCHER: register_result: lock acquired
15:48:07 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
15:48:07 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.00196241520846064, 'num_filters_1': 111, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.02883484972712214, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 41, 'num_filters_3': 28, 'num_filters_4': 17, 'num_filters_5': 31}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.718035139865499, 'info': {'music-speech': 0.718035139865499, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.00196241520846064, 'num_filters_1': 111, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.02883484972712214, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 41, 'num_filters_3': 28, 'num_filters_4': 17, 'num_filters_5': 31}"}}
exception: None

15:48:07 job_callback for (9, 0, 5) started
15:48:07 DISPATCHER: Trying to submit another job.
15:48:07 job_callback for (9, 0, 5) got condition
15:48:07 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:48:07 done building a new model for budget 133.333333 based on 17/43 split
Best loss for this budget:-0.931478





15:48:07 HBMASTER: Trying to run another job!
15:48:07 job_callback for (9, 0, 5) finished
15:48:07 start sampling a new configuration.
15:48:07 best_vector: [3, 2, 0.2827979643195021, 0.711694959150763, 0.5076392794808231, 0, 0.045583896367484375, 0.5234673085274384, 0, 2, 0, 2, 0.8185787683027876, 0.17358458832969292, 0.857931602573085, 0.7253372063340033], 1.5374942386977686e-28, 6.504089412699087e-05, -2.4180646342495695e-05
15:48:07 done sampling a new configuration.
15:48:07 HBMASTER: schedule new run for iteration 9
15:48:07 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
15:48:07 HBMASTER: submitting job (9, 0, 6) to dispatcher
15:48:07 DISPATCHER: trying to submit job (9, 0, 6)
15:48:07 DISPATCHER: trying to notify the job_runner thread.
15:48:07 HBMASTER: job (9, 0, 6) submitted to dispatcher
15:48:07 DISPATCHER: Trying to submit another job.
15:48:07 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:48:07 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216
15:48:07 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
15:48:07 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:48:07 WORKER: start processing job (9, 0, 6)
15:48:07 WORKER: args: ()
15:48:07 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0036778662253347475, 'num_filters_1': 70, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.04797850045116815, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 88, 'num_filters_3': 22}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:48:53 DISPATCHER: Starting worker discovery
15:48:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:48:53 DISPATCHER: Finished worker discovery
15:49:53 DISPATCHER: Starting worker discovery
15:49:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:49:53 DISPATCHER: Finished worker discovery
15:50:29 WORKER: done with job (9, 0, 6), trying to register it.
15:50:29 WORKER: registered result for job (9, 0, 6) with dispatcher
15:50:29 DISPATCHER: job (9, 0, 6) finished
15:50:29 DISPATCHER: register_result: lock acquired
15:50:29 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
15:50:29 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0036778662253347475, 'num_filters_1': 70, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.04797850045116815, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 88, 'num_filters_3': 22}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.7146099824871673, 'info': {'music-speech': 0.7146099824871673, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0036778662253347475, 'num_filters_1': 70, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.04797850045116815, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 88, 'num_filters_3': 22}"}}
exception: None

15:50:29 job_callback for (9, 0, 6) started
15:50:29 DISPATCHER: Trying to submit another job.
15:50:29 job_callback for (9, 0, 6) got condition
15:50:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:50:29 done building a new model for budget 133.333333 based on 17/44 split
Best loss for this budget:-0.931478





15:50:29 HBMASTER: Trying to run another job!
15:50:29 job_callback for (9, 0, 6) finished
15:50:29 start sampling a new configuration.
15:50:30 best_vector: [3, 1, 0.3639700936293832, 0.2739670781828383, 0.00581457646014083, 0, 0.36711153396325785, 0.1051475674221039, 1, 2, 2, 2, 0.41285248475621283, 0.6343713809881392, 0.9022321194311639, 0.16342938979597482], 1.6780238457712662e-28, 5.9593908782647385e-05, -5.382171694674171e-07
15:50:30 done sampling a new configuration.
15:50:30 HBMASTER: schedule new run for iteration 9
15:50:30 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
15:50:30 HBMASTER: submitting job (9, 0, 7) to dispatcher
15:50:30 DISPATCHER: trying to submit job (9, 0, 7)
15:50:30 DISPATCHER: trying to notify the job_runner thread.
15:50:30 HBMASTER: job (9, 0, 7) submitted to dispatcher
15:50:30 DISPATCHER: Trying to submit another job.
15:50:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:50:30 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
15:50:30 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
15:50:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:50:30 WORKER: start processing job (9, 0, 7)
15:50:30 WORKER: args: ()
15:50:30 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0053449074216406, 'num_filters_1': 28, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.013702510362766221}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:50:53 DISPATCHER: Starting worker discovery
15:50:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:50:53 DISPATCHER: Finished worker discovery
15:51:53 DISPATCHER: Starting worker discovery
15:51:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:51:53 DISPATCHER: Finished worker discovery
15:52:52 WORKER: done with job (9, 0, 7), trying to register it.
15:52:52 WORKER: registered result for job (9, 0, 7) with dispatcher
15:52:52 DISPATCHER: job (9, 0, 7) finished
15:52:52 DISPATCHER: register_result: lock acquired
15:52:52 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
15:52:52 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0053449074216406, 'num_filters_1': 28, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.013702510362766221}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.8042109918069797, 'info': {'music-speech': 0.8042109918069797, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0053449074216406, 'num_filters_1': 28, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.013702510362766221}"}}
exception: None

15:52:52 job_callback for (9, 0, 7) started
15:52:52 DISPATCHER: Trying to submit another job.
15:52:52 job_callback for (9, 0, 7) got condition
15:52:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:52:52 done building a new model for budget 133.333333 based on 17/45 split
Best loss for this budget:-0.931478





15:52:52 HBMASTER: Trying to run another job!
15:52:52 job_callback for (9, 0, 7) finished
15:52:52 start sampling a new configuration.
15:52:52 done sampling a new configuration.
15:52:52 HBMASTER: schedule new run for iteration 9
15:52:52 HBMASTER: trying submitting job (9, 0, 8) to dispatcher
15:52:52 HBMASTER: submitting job (9, 0, 8) to dispatcher
15:52:52 DISPATCHER: trying to submit job (9, 0, 8)
15:52:52 DISPATCHER: trying to notify the job_runner thread.
15:52:52 HBMASTER: job (9, 0, 8) submitted to dispatcher
15:52:52 DISPATCHER: Trying to submit another job.
15:52:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:52:52 DISPATCHER: starting job (9, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216
15:52:52 DISPATCHER: job (9, 0, 8) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
15:52:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:52:52 WORKER: start processing job (9, 0, 8)
15:52:52 WORKER: args: ()
15:52:52 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.014156902902859597, 'num_filters_1': 21, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.024195798462853517}, 'budget': 133.33333333333331, 'working_directory': '.'}
15:52:53 DISPATCHER: Starting worker discovery
15:52:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:52:53 DISPATCHER: Finished worker discovery
15:53:53 DISPATCHER: Starting worker discovery
15:53:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:53:53 DISPATCHER: Finished worker discovery
15:54:53 DISPATCHER: Starting worker discovery
15:54:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:54:53 DISPATCHER: Finished worker discovery
15:55:14 WORKER: done with job (9, 0, 8), trying to register it.
15:55:14 WORKER: registered result for job (9, 0, 8) with dispatcher
15:55:14 DISPATCHER: job (9, 0, 8) finished
15:55:14 DISPATCHER: register_result: lock acquired
15:55:14 DISPATCHER: job (9, 0, 8) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
15:55:14 job_id: (9, 0, 8)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.014156902902859597, 'num_filters_1': 21, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.024195798462853517}, 'budget': 133.33333333333331, 'working_directory': '.'}
result: {'loss': -0.5227721205578197, 'info': {'music-speech': 0.5227721205578197, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.014156902902859597, 'num_filters_1': 21, 'num_layers': 1, 'optimizer': 'SGD', 'steps_to_train': 30, 'weight_decay': 0.024195798462853517}"}}
exception: None

15:55:14 job_callback for (9, 0, 8) started
15:55:14 DISPATCHER: Trying to submit another job.
15:55:14 job_callback for (9, 0, 8) got condition
15:55:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
15:55:14 done building a new model for budget 133.333333 based on 17/45 split
Best loss for this budget:-0.931478





15:55:14 HBMASTER: Trying to run another job!
15:55:14 job_callback for (9, 0, 8) finished
15:55:14 ITERATION: Advancing config (9, 0, 5) to next budget 400.000000
15:55:14 ITERATION: Advancing config (9, 0, 6) to next budget 400.000000
15:55:14 ITERATION: Advancing config (9, 0, 7) to next budget 400.000000
15:55:14 HBMASTER: schedule new run for iteration 9
15:55:14 HBMASTER: trying submitting job (9, 0, 5) to dispatcher
15:55:14 HBMASTER: submitting job (9, 0, 5) to dispatcher
15:55:14 DISPATCHER: trying to submit job (9, 0, 5)
15:55:14 DISPATCHER: trying to notify the job_runner thread.
15:55:14 HBMASTER: job (9, 0, 5) submitted to dispatcher
15:55:14 DISPATCHER: Trying to submit another job.
15:55:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
15:55:14 DISPATCHER: starting job (9, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216
15:55:14 DISPATCHER: job (9, 0, 5) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
15:55:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
15:55:14 WORKER: start processing job (9, 0, 5)
15:55:14 WORKER: args: ()
15:55:14 WORKER: kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.00196241520846064, 'num_filters_1': 111, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.02883484972712214, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 41, 'num_filters_3': 28, 'num_filters_4': 17, 'num_filters_5': 31}, 'budget': 400.0, 'working_directory': '.'}
15:55:53 DISPATCHER: Starting worker discovery
15:55:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:55:53 DISPATCHER: Finished worker discovery
15:56:53 DISPATCHER: Starting worker discovery
15:56:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:56:53 DISPATCHER: Finished worker discovery
15:57:53 DISPATCHER: Starting worker discovery
15:57:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:57:53 DISPATCHER: Finished worker discovery
15:58:53 DISPATCHER: Starting worker discovery
15:58:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:58:53 DISPATCHER: Finished worker discovery
15:59:53 DISPATCHER: Starting worker discovery
15:59:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
15:59:53 DISPATCHER: Finished worker discovery
16:00:53 DISPATCHER: Starting worker discovery
16:00:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:00:53 DISPATCHER: Finished worker discovery
16:01:53 DISPATCHER: Starting worker discovery
16:01:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:01:53 DISPATCHER: Finished worker discovery
16:02:03 WORKER: done with job (9, 0, 5), trying to register it.
16:02:03 WORKER: registered result for job (9, 0, 5) with dispatcher
16:02:03 DISPATCHER: job (9, 0, 5) finished
16:02:03 DISPATCHER: register_result: lock acquired
16:02:03 DISPATCHER: job (9, 0, 5) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
16:02:03 job_id: (9, 0, 5)
kwargs: {'config': {'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.00196241520846064, 'num_filters_1': 111, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.02883484972712214, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 41, 'num_filters_3': 28, 'num_filters_4': 17, 'num_filters_5': 31}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.6134386541591028, 'info': {'music-speech': 0.6134386541591028, 'config': "{'batch_size': 32, 'kernel_size_1': 3, 'lr': 0.00196241520846064, 'num_filters_1': 111, 'num_layers': 5, 'optimizer': 'Adam', 'steps_to_train': 79, 'weight_decay': 0.02883484972712214, 'kernel_size_2': 5, 'kernel_size_3': 3, 'kernel_size_4': 3, 'kernel_size_5': 7, 'num_filters_2': 41, 'num_filters_3': 28, 'num_filters_4': 17, 'num_filters_5': 31}"}}
exception: None

16:02:03 job_callback for (9, 0, 5) started
16:02:03 DISPATCHER: Trying to submit another job.
16:02:03 job_callback for (9, 0, 5) got condition
16:02:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:02:03 HBMASTER: Trying to run another job!
16:02:03 job_callback for (9, 0, 5) finished
16:02:03 HBMASTER: schedule new run for iteration 9
16:02:03 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
16:02:03 HBMASTER: submitting job (9, 0, 6) to dispatcher
16:02:03 DISPATCHER: trying to submit job (9, 0, 6)
16:02:03 DISPATCHER: trying to notify the job_runner thread.
16:02:03 HBMASTER: job (9, 0, 6) submitted to dispatcher
16:02:03 DISPATCHER: Trying to submit another job.
16:02:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:02:03 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216
16:02:03 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
16:02:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:02:03 WORKER: start processing job (9, 0, 6)
16:02:03 WORKER: args: ()
16:02:03 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0036778662253347475, 'num_filters_1': 70, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.04797850045116815, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 88, 'num_filters_3': 22}, 'budget': 400.0, 'working_directory': '.'}
16:02:53 DISPATCHER: Starting worker discovery
16:02:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:02:53 DISPATCHER: Finished worker discovery
16:03:53 DISPATCHER: Starting worker discovery
16:03:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:03:53 DISPATCHER: Finished worker discovery
16:04:53 DISPATCHER: Starting worker discovery
16:04:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:04:53 DISPATCHER: Finished worker discovery
16:05:53 DISPATCHER: Starting worker discovery
16:05:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:05:53 DISPATCHER: Finished worker discovery
16:06:53 DISPATCHER: Starting worker discovery
16:06:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:06:53 DISPATCHER: Finished worker discovery
16:07:53 DISPATCHER: Starting worker discovery
16:07:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:07:53 DISPATCHER: Finished worker discovery
16:08:53 WORKER: done with job (9, 0, 6), trying to register it.
16:08:53 WORKER: registered result for job (9, 0, 6) with dispatcher
16:08:53 DISPATCHER: job (9, 0, 6) finished
16:08:53 DISPATCHER: register_result: lock acquired
16:08:53 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
16:08:53 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0036778662253347475, 'num_filters_1': 70, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.04797850045116815, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 88, 'num_filters_3': 22}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8456173227453507, 'info': {'music-speech': 0.8456173227453507, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0036778662253347475, 'num_filters_1': 70, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.04797850045116815, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 88, 'num_filters_3': 22}"}}
exception: None

16:08:53 job_callback for (9, 0, 6) started
16:08:53 job_callback for (9, 0, 6) got condition
16:08:53 DISPATCHER: Trying to submit another job.
16:08:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:08:53 HBMASTER: Trying to run another job!
16:08:53 job_callback for (9, 0, 6) finished
16:08:53 HBMASTER: schedule new run for iteration 9
16:08:53 HBMASTER: trying submitting job (9, 0, 7) to dispatcher
16:08:53 HBMASTER: submitting job (9, 0, 7) to dispatcher
16:08:53 DISPATCHER: trying to submit job (9, 0, 7)
16:08:53 DISPATCHER: trying to notify the job_runner thread.
16:08:53 HBMASTER: job (9, 0, 7) submitted to dispatcher
16:08:53 DISPATCHER: Trying to submit another job.
16:08:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:08:53 DISPATCHER: starting job (9, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216
16:08:53 DISPATCHER: job (9, 0, 7) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
16:08:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:08:53 WORKER: start processing job (9, 0, 7)
16:08:53 WORKER: args: ()
16:08:53 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0053449074216406, 'num_filters_1': 28, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.013702510362766221}, 'budget': 400.0, 'working_directory': '.'}
16:08:53 DISPATCHER: Starting worker discovery
16:08:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:08:53 DISPATCHER: Finished worker discovery
16:09:53 DISPATCHER: Starting worker discovery
16:09:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:09:53 DISPATCHER: Finished worker discovery
16:10:53 DISPATCHER: Starting worker discovery
16:10:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:10:53 DISPATCHER: Finished worker discovery
16:11:53 DISPATCHER: Starting worker discovery
16:11:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:11:53 DISPATCHER: Finished worker discovery
16:12:53 DISPATCHER: Starting worker discovery
16:12:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:12:53 DISPATCHER: Finished worker discovery
16:13:53 DISPATCHER: Starting worker discovery
16:13:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:13:53 DISPATCHER: Finished worker discovery
16:14:53 DISPATCHER: Starting worker discovery
16:14:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:14:53 DISPATCHER: Finished worker discovery
16:15:42 WORKER: done with job (9, 0, 7), trying to register it.
16:15:42 DISPATCHER: job (9, 0, 7) finished
16:15:42 WORKER: registered result for job (9, 0, 7) with dispatcher
16:15:42 DISPATCHER: register_result: lock acquired
16:15:42 DISPATCHER: job (9, 0, 7) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
16:15:42 job_id: (9, 0, 7)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0053449074216406, 'num_filters_1': 28, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.013702510362766221}, 'budget': 400.0, 'working_directory': '.'}
result: {'loss': -0.8410423811058614, 'info': {'music-speech': 0.8410423811058614, 'config': "{'batch_size': 128, 'kernel_size_1': 5, 'lr': 0.0053449074216406, 'num_filters_1': 28, 'num_layers': 1, 'optimizer': 'Adam', 'steps_to_train': 43, 'weight_decay': 0.013702510362766221}"}}
exception: None

16:15:42 job_callback for (9, 0, 7) started
16:15:42 DISPATCHER: Trying to submit another job.
16:15:42 job_callback for (9, 0, 7) got condition
16:15:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:15:42 HBMASTER: Trying to run another job!
16:15:42 job_callback for (9, 0, 7) finished
16:15:42 ITERATION: Advancing config (9, 0, 6) to next budget 1200.000000
16:15:42 HBMASTER: schedule new run for iteration 9
16:15:42 HBMASTER: trying submitting job (9, 0, 6) to dispatcher
16:15:42 HBMASTER: submitting job (9, 0, 6) to dispatcher
16:15:42 DISPATCHER: trying to submit job (9, 0, 6)
16:15:42 DISPATCHER: trying to notify the job_runner thread.
16:15:42 HBMASTER: job (9, 0, 6) submitted to dispatcher
16:15:42 DISPATCHER: Trying to submit another job.
16:15:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
16:15:42 DISPATCHER: starting job (9, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216
16:15:42 DISPATCHER: job (9, 0, 6) dispatched on hpbandster.run_0.worker.metagpul.22021139727314577216
16:15:42 WORKER: start processing job (9, 0, 6)
16:15:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
16:15:42 WORKER: args: ()
16:15:42 WORKER: kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0036778662253347475, 'num_filters_1': 70, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.04797850045116815, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 88, 'num_filters_3': 22}, 'budget': 1200.0, 'working_directory': '.'}
16:15:53 DISPATCHER: Starting worker discovery
16:15:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:15:53 DISPATCHER: Finished worker discovery
16:16:53 DISPATCHER: Starting worker discovery
16:16:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:16:53 DISPATCHER: Finished worker discovery
16:17:53 DISPATCHER: Starting worker discovery
16:17:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:17:53 DISPATCHER: Finished worker discovery
16:18:53 DISPATCHER: Starting worker discovery
16:18:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:18:53 DISPATCHER: Finished worker discovery
16:19:53 DISPATCHER: Starting worker discovery
16:19:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:19:53 DISPATCHER: Finished worker discovery
16:20:53 DISPATCHER: Starting worker discovery
16:20:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:20:53 DISPATCHER: Finished worker discovery
16:21:53 DISPATCHER: Starting worker discovery
16:21:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:21:53 DISPATCHER: Finished worker discovery
16:22:53 DISPATCHER: Starting worker discovery
16:22:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:22:53 DISPATCHER: Finished worker discovery
16:23:53 DISPATCHER: Starting worker discovery
16:23:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:23:53 DISPATCHER: Finished worker discovery
16:24:53 DISPATCHER: Starting worker discovery
16:24:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:24:53 DISPATCHER: Finished worker discovery
16:25:53 DISPATCHER: Starting worker discovery
16:25:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:25:53 DISPATCHER: Finished worker discovery
16:26:53 DISPATCHER: Starting worker discovery
16:26:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:26:53 DISPATCHER: Finished worker discovery
16:27:53 DISPATCHER: Starting worker discovery
16:27:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:27:53 DISPATCHER: Finished worker discovery
16:28:53 DISPATCHER: Starting worker discovery
16:28:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:28:53 DISPATCHER: Finished worker discovery
16:29:53 DISPATCHER: Starting worker discovery
16:29:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:29:53 DISPATCHER: Finished worker discovery
16:30:53 DISPATCHER: Starting worker discovery
16:30:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:30:53 DISPATCHER: Finished worker discovery
16:31:53 DISPATCHER: Starting worker discovery
16:31:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:31:53 DISPATCHER: Finished worker discovery
16:32:53 DISPATCHER: Starting worker discovery
16:32:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:32:53 DISPATCHER: Finished worker discovery
16:33:53 DISPATCHER: Starting worker discovery
16:33:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:33:53 DISPATCHER: Finished worker discovery
16:34:53 DISPATCHER: Starting worker discovery
16:34:53 DISPATCHER: Found 1 potential workers, 1 currently in the pool.
16:34:53 DISPATCHER: Finished worker discovery
16:35:53 WORKER: done with job (9, 0, 6), trying to register it.
16:35:53 DISPATCHER: job (9, 0, 6) finished
16:35:53 WORKER: registered result for job (9, 0, 6) with dispatcher
16:35:53 DISPATCHER: register_result: lock acquired
16:35:53 DISPATCHER: job (9, 0, 6) on hpbandster.run_0.worker.metagpul.22021139727314577216 finished
16:35:53 job_id: (9, 0, 6)
kwargs: {'config': {'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0036778662253347475, 'num_filters_1': 70, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.04797850045116815, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 88, 'num_filters_3': 22}, 'budget': 1200.0, 'working_directory': '.'}
result: {'loss': -0.857015736369978, 'info': {'music-speech': 0.857015736369978, 'config': "{'batch_size': 128, 'kernel_size_1': 7, 'lr': 0.0036778662253347475, 'num_filters_1': 70, 'num_layers': 3, 'optimizer': 'Adam', 'steps_to_train': 14, 'weight_decay': 0.04797850045116815, 'kernel_size_2': 3, 'kernel_size_3': 7, 'num_filters_2': 88, 'num_filters_3': 22}"}}
exception: None

16:35:53 job_callback for (9, 0, 6) started
16:35:53 DISPATCHER: Trying to submit another job.
16:35:53 job_callback for (9, 0, 6) got condition
16:35:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
16:35:53 HBMASTER: Trying to run another job!
16:35:53 job_callback for (9, 0, 6) finished
16:35:53 HBMASTER: shutdown initiated, shutdown_workers = True
16:35:53 WORKER: shutting down now!
16:35:53 DISPATCHER: Dispatcher shutting down
16:35:53 DISPATCHER: discover_workers shutting down
16:35:53 DISPATCHER: 'discover_worker' thread exited
16:35:53 DISPATCHER: Trying to submit another job.
16:35:53 DISPATCHER: job_runner shutting down
16:35:53 DISPATCHER: 'job_runner' thread exited
16:35:53 DISPATCHER: shut down complete
